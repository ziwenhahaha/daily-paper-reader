{
  "label": "2026-02-21",
  "date": "2026-02-21",
  "generated_at": "2026-02-21T17:15:00",
  "count": 7,
  "papers": [
    {
      "paper_id": "202602/21/2602.15169v1-learning-the-s-matrix-from-data-rediscovering-gravity-from-gauge-theory-via-symbolic-regression",
      "section": "quick",
      "title_en": "",
      "authors": "",
      "date": "",
      "pdf": "",
      "score": "",
      "evidence": "",
      "tldr": "",
      "tags": "",
      "abstract_en": "We demonstrate that modern machine-learning methods can autonomously reconstruct several flagship analytic structures in scattering amplitudes directly from numerical on-shell data. In particular, we show that the Kawai--Lewellen--Tye (KLT) relations can be rediscovered using symbolic regression applied to colour-ordered Yang--Mills amplitudes with Mandelstam invariants as input features. Using standard feature-selection techniques, specifically column-pivoted QR factorisation, we simultaneously recover the Kleiss--Kuijf and Bern--Carrasco--Johansson (BCJ) relations, identifying a minimal basis of partial amplitudes without any group-theoretic input. We obtain the tree-level KLT relations with high numerical accuracy up to five external legs, using only minimal theoretical priors, and we comment on the obstacles to generalising the method to higher multiplicity. Our results establish symbolic regression as a practical tool for exploring the analytic structure of the scattering-amplitude landscape, and suggests a general data-driven strategy for uncovering hidden relations in general theories. For comparison, we benchmark this general approach with a recently introduced neural-network based method."
    },
    {
      "paper_id": "202602/21/2602.15603v1-symbolic-recovery-of-pdes-from-measurement-data",
      "section": "quick",
      "title_en": "",
      "authors": "",
      "date": "",
      "pdf": "",
      "score": "",
      "evidence": "",
      "tldr": "",
      "tags": "",
      "abstract_en": "Models based on partial differential equations (PDEs) are powerful for describing a wide range of complex relationships in the natural sciences. Accurately identifying the PDE model, which represents the underlying physical law, is essential for a proper understanding of the problem. This reconstruction typically relies on indirect and noisy measurements of the system's state and, without specifically tailored methods, rarely yields symbolic expressions, thereby hindering interpretability. In this work, we address this issue by considering existing neural network architectures based on rational functions for the symbolic representation of physical laws. These networks leverage the approximation power of rational functions while also benefiting from their flexibility in representing arithmetic operations. Our main contribution is an identifiability result, showing that, in the limit of noiseless, complete measurements, such symbolic networks can uniquely reconstruct the simplest physical law within the PDE model. Specifically, reconstructed laws remain expressible within the symbolic network architecture, with regularization-minimizing parameterizations promoting interpretability and sparsity in case of $L^1$-regularization. In addition, we provide regularity results for symbolic networks. Empirical validation using the ParFam architecture supports these theoretical findings, providing evidence for the practical reconstructibility of physical laws."
    },
    {
      "paper_id": "202602/21/2602.15743v1-physics-informed-data-driven-inference-of-an-interpretable-equivariant-les-model-of-incompressible-fluid-turbulence",
      "section": "quick",
      "title_en": "",
      "authors": "",
      "date": "",
      "pdf": "",
      "score": "",
      "evidence": "",
      "tldr": "",
      "tags": "",
      "abstract_en": "Restrictive phenomenological assumptions represent a major roadblock for the development of accurate subgrid-scale models of fluid turbulence. Specifically, these assumptions limit a model's ability to describe key quantities of interest, such as local fluxes of energy and enstrophy, in the presence of diverse coherent structures. This paper introduces a symbolic data-driven subgrid-scale model that requires no phenomenological assumptions and has no adjustable parameters, yet it outperforms leading LES models. A combination of a priori and a posteriori benchmarks shows that the model produces accurate predictions of various quantities including local fluxes across a broad range of two-dimensional turbulent flows. While the model is inferred using LES-style spatial coarse-graining, its structure is more similar to RANS models, as it employs an additional field to describe subgrid scales. We find that this field must have a rank-two tensor structure in order to correctly represent both the components of the subgrid-scale stress tensor and the various fluxes."
    },
    {
      "paper_id": "202602/21/2602.17082v1-order-of-magnitude-analysis-and-data-based-physics-informed-symbolic-regression-for-turbulent-pipe-flow",
      "section": "quick",
      "title_en": "",
      "authors": "",
      "date": "",
      "pdf": "",
      "score": "",
      "evidence": "",
      "tldr": "",
      "tags": "",
      "abstract_en": "Friction losses in rough pipes are often predicted using semi-empirical correlations, such as the Colebrook-White equation (Colebrook,1939), which do not fully replicate Nikuradse's rough-pipe experiments (1950). This study derives scaling relations for the viscous and turbulent contributions to the streamwise pressure drop through an order-of-magnitude analysis of the Reynolds-averaged Navier-Stokes equations and the kinetic-energy transport equations. These relations impose constraints on the local sensitivity of the pressure drop to factors such as mean velocity, roughness, viscosity, and density through exponent envelopes and serve as a physical prior for symbolic regression. By combining Nikuradse's rough-pipe and smooth-pipe data of Zagarola and Smits (1998), we aim to derive compact correlations for the friction factor that fit experimental data while adhering to the derived constraints. A modified genetic programming engine (GPTIPS2) optimizes model structure and evaluates it based on fitness, complexity, and constraint violation. This method yields interpretable expressions that accurately reproduce friction factors across various roughness levels and Reynolds numbers, validated up to $Re \\sim 10^7$."
    },
    {
      "paper_id": "202602/21/2602.14670v1-factorminer-a-self-evolving-agent-with-skills-and-experience-memory-for-financial-alpha-discovery",
      "section": "quick",
      "title_en": "",
      "authors": "",
      "date": "",
      "pdf": "",
      "score": "",
      "evidence": "",
      "tldr": "",
      "tags": "",
      "abstract_en": "Formulaic alpha factor mining is a critical yet challenging task in quantitative investment, characterized by a vast search space and the need for domain-informed, interpretable signals. However, finding novel signals becomes increasingly difficult as the library grows due to high redundancy. We propose FactorMiner, a lightweight and flexible self-evolving agent framework designed to navigate this complex landscape through continuous knowledge accumulation. FactorMiner combines a Modular Skill Architecture that encapsulates systematic financial evaluation into executable tools with a structured Experience Memory that distills historical mining trials into actionable insights (successful patterns and failure constraints). By instantiating the Ralph Loop paradigm -- retrieve, generate, evaluate, and distill -- FactorMiner iteratively uses memory priors to guide exploration, reducing redundant search while focusing on promising directions. Experiments on multiple datasets across different assets and Markets show that FactorMiner constructs a diverse library of high-quality factors with competitive performance, while maintaining low redundancy among factors as the library scales. Overall, FactorMiner provides a practical approach to scalable discovery of interpretable formulaic alpha factors under the \"Correlation Red Sea\" constraint."
    },
    {
      "paper_id": "202602/21/2602.16166v1-discovering-unknown-inverter-governing-equations-via-physics-informed-sparse-machine-learning",
      "section": "quick",
      "title_en": "",
      "authors": "",
      "date": "",
      "pdf": "",
      "score": "",
      "evidence": "",
      "tldr": "",
      "tags": "",
      "abstract_en": "Discovering the unknown governing equations of grid-connected inverters from external measurements holds significant attraction for analyzing modern inverter-intensive power systems. However, existing methods struggle to balance the identification of unmodeled nonlinearities with the preservation of physical consistency. To address this, this paper proposes a Physics-Informed Sparse Machine Learning (PISML) framework. The architecture integrates a sparse symbolic backbone to capture dominant model skeletons with a neural residual branch that compensates for complex nonlinear control logic. Meanwhile, a Jacobian-regularized physics-informed training mechanism is introduced to enforce multi-scale consistency including large/small-scale behaviors. Furthermore, by performing symbolic regression on the neural residual branch, PISML achieves a tractable mapping from black-box data to explicit control equations. Experimental results on a high-fidelity Hardware-in-the-Loop platform demonstrate the framework's superior performance. It not only achieves high-resolution identification by reducing error by over 340 times compared to baselines but also realizes the compression of heavy neural networks into compact explicit forms. This restores analytical tractability for rigorous stability analysis and reduces computational complexity by orders of magnitude. It also provides a unified pathway to convert structurally inaccessible devices into explicit mathematical models, enabling stability analysis of power systems with unknown inverter governing equations."
    },
    {
      "paper_id": "202602/21/2602.16947v1-beyond-message-passing-a-symbolic-alternative-for-expressive-and-interpretable-graph-learning",
      "section": "quick",
      "title_en": "",
      "authors": "",
      "date": "",
      "pdf": "",
      "score": "",
      "evidence": "",
      "tldr": "",
      "tags": "",
      "abstract_en": "Graph Neural Networks (GNNs) have become essential in high-stakes domains such as drug discovery, yet their black-box nature remains a significant barrier to trustworthiness. While self-explainable GNNs attempt to bridge this gap, they often rely on standard message-passing backbones that inherit fundamental limitations, including the 1-Weisfeiler-Lehman (1-WL) expressivity barrier and a lack of fine-grained interpretability. To address these challenges, we propose SymGraph, a symbolic framework designed to transcend these constraints. By replacing continuous message passing with discrete structural hashing and topological role-based aggregation, our architecture theoretically surpasses the 1-WL barrier, achieving superior expressiveness without the overhead of differentiable optimization. Extensive empirical evaluations demonstrate that SymGraph achieves state-of-the-art performance, outperforming existing self-explainable GNNs. Notably, SymGraph delivers 10x to 100x speedups in training time using only CPU execution. Furthermore, SymGraph generates rules with superior semantic granularity compared to existing rule-based methods, offering great potential for scientific discovery and explainable AI."
    }
  ],
  "errors": []
}
