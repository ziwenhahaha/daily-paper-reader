Title: Differentiable Logical Programming for Quantum Circuit Discovery and Optimization

URL Source: https://arxiv.org/pdf/2602.08880v1

Published Time: Tue, 10 Feb 2026 03:28:47 GMT

Number of Pages: 20

Markdown Content:
# Differentiable Logical Programming for Quantum Circuit Discovery and Optimization 

Antonin Sulc 

> Lawrence Berkeley National Laboratory, Berkeley, California 94720, USA

Designing high-fidelity quantum cir-cuits remains challenging, and current paradigms often depend on heuristic, fixed-ansatz structures or rule-based com-pilers that can be suboptimal or lack gen-erality. We introduce a neuro-symbolic framework that reframes quantum cir-cuit design as a differentiable logic pro-gramming problem. Our model repre-sents a scaffold of potential quantum gates and parameterized operations as a set of learnable, continuous “truth values” or “switches,” s ∈ [0 , 1] N . These switches are optimized via standard gradient descent to satisfy a user-defined set of differentiable, logical axioms (e.g., correctness, simplic-ity, robustness). We provide a theoreti-cal formulation bridging continuous logic (via T-norms) and unitary evolution (via geodesic interpolation), while addressing the barren plateau problem through biased initialization. We illustrate the approach on tasks including discovery of a 4-qubit Quantum Fourier Transform (QFT) from a scaffold of 21 candidate gates. We also re-port a hardware-aware adaptation experi-ment on the 133-qubit IBM Torino proces-sor, where the method improved fidelity by 59.3 percentage points in a localized rout-ing task while adapting to hardware fail-ures. 

## 1 Introduction 

Quantum computation promises to solve prob-lems considered intractable for classical comput-ers, with applications spanning materials science and quantum chemistry, drug discovery, and com-plex optimization problems in areas such as fi-

> Antonin Sulc: asulc@lbl.gov

nance and logistics [1, 2, 3, 4, 5]. However, real-izing this potential depends on our ability to de-sign and execute high-fidelity quantum circuits. In the current noisy intermediate-scale quantum (NISQ) era, this task is constrained; hardware is limited by gate error rates, coherence times, and qubit connectivity, placing a strong emphasis on circuit efficiency and robustness [6]. The central challenge is that finding an optimal quantum circuit for a given task is a notoriously difficult combinatorial search problem. Current approaches to circuit design, while powerful, face fundamental limitations. Manual, human-derived circuits for canonical algorithms like the Quantum Fourier Transform (QFT) or Grover’s search are the product of significant ingenuity but are not generalizable to novel problems, such as simulating an arbi-trary molecular Hamiltonian. Variational Quan-tum Algorithms (VQAs), the dominant NISQ paradigm [7, 8], typically rely on a pre-defined, fixed-structure “ansatz.” The performance of the entire algorithm is critically sensitive to this heuristic design choice. A poor ansatz can lead to an inability to express the solution state or suffer from barren plateaus, where training gra-dients vanish exponentially [9]. While adaptive methods like ADAPT-VQE [10] build an ansatz iteratively, they employ a greedy search that may not find a globally optimal structure. On the optimization front, quantum compil-ers [11] apply pre-programmed, rule-based graph-rewriting identities (e.g., H-H → I). These sys-tems are limited to the set of rules known a priori .Other non-differentiable search methods, such as evolutionary algorithms [12] or SAT solvers for circuit synthesis [13, 14], must rely on heuristic search strategies and cannot leverage the highly-efficient, gradient-based optimization tools that have revolutionized machine learning. Prior work on differentiable quantum architec-

1             

> arXiv:2602.08880v1 [quant-ph] 9 Feb 2026 H
> s1
> Z?
> s2
> CNOT
> s3
> 1. The Scaffold (Input)
> Continuous Relaxation
> ˜Gi(si) = (1 −si)I+siGi
> H
> s1≈1
> Z?
> s2≈0
> CNOT
> s3≈1
> 2. Discovered Circuit (Pruned)
> Logical Axioms (Ltotal )Maximize Fidelity ( Tfid ) & Simplicity ( Tsimp )
> Forward Pass: Construct Unitary Ulearned (s)
> Evaluate U
> Pruning Gradients ( ∇si)

Figure 1: Conceptual overview of the Differentiable Logical Programming framework for quantum circuit design. The entire process, from the logical axioms to the circuit structure, is connected by differentiable operations, allowing for end-to-end optimization using standard gradient-based methods. This workflow unifies discrete structural search and continuous parameter optimization. 

ture search (DQAS) [15] pioneered the use of gradient-based optimization for automated cir-cuit design by representing candidate architec-tures through a probabilistic model over dis-crete gate choices. DQAS demonstrated suc-cess in unitary decomposition, error mitigation, and QAOA layout discovery by estimating gra-dients via Monte Carlo sampling from a pa-rameterized distribution. More recently, Quan-tumDARTS [16] extended this paradigm using Gumbel-Softmax reparameterization [17, 18] to enable end-to-end differentiability without ex-plicit sampling, introducing both macro-search (full circuit) and micro-search (transferable sub-circuit) strategies. While these methods repre-sent significant advances, they treat each circuit placeholder independently and rely on probabilis-tic gate selection rather than continuous struc-tural interpolation. In this work, we introduce a framework that bridges the gap between symbolic logic and dif-ferentiable programming to create a flexible, gradient-based approach to quantum circuit de-sign (Fig. 1). We are inspired by advances in neuro-symbolic reasoning [19] and differentiable architecture search [20]. We treat the existence of each gate in a potential circuit scaffold as a con-tinuous, learnable logical variable si ∈ [0 , 1] . This formulation allows us to use the power of stan-dard automatic differentiation (i.e., autograd) to optimize the discrete structure of a circuit, and its continuous parameters, simultaneously. Un-like DQAS, which uses Monte Carlo gradient es-timation over a probabilistic model, our approach directly interpolates between the identity and gate unitaries via continuous switches, enabling unified structure-parameter optimization through standard backpropagation. The core of our approach is the ability to train the model not on a single, fixed objective func-tion, but on a set of user-defined, differentiable 

logical axioms that define “goodness.” This pro-vides substantial flexibility. By composing differ-ent axioms, the same model can function as (1) a compiler with axioms: Tfid , Tsimp , which seeks a short gate sequence for a target unitary; (2) a “VQE Designer” with axioms: Lenergy , Lsimp ,which learns a compact, parameterized ansatz for a ground state; and (3) a “robust designer” with axioms: Lenergy , Lrob , Lsimp , which performs multi-objective optimization to balance ideal per-formance, noise resilience, and gate count. The main benefit of this framework is its ease of implementation and generality. It recasts a discrete, N P -hard search problem into a continu-ous optimization problem solvable with standard deep learning tools. In this paper, we present the theory of this Differentiable Logical Program-ming (DLP) framework and show that it can dis-cover canonical algorithms, learn compiler opti-mizations, and design multi-objective VQE cir-cuits from first principles. 

2The trajectory toward practical quantum ad-vantage is currently obstructed by a significant disconnect between abstract algorithmic theory and the physical constraints of hardware. Bab-bush et al. [21] formalize this struggle into a five-stage framework. They identify critical bottle-necks, specifically in the discovery of verifiable al-gorithms (Stage I) and the optimization required for fault-tolerant compilation (Stage IV). The au-thors argue that the community faces a “collec-tive action problem,” where the scarcity of useful algorithms and the complexities of resource es-timation threaten to stall the field’s momentum. Crucially, they highlight that simple heuristics for compilation are often insufficient for the emerging early fault-tolerant era. Our work is a methodological response to these challenges. By reframing discrete circuit synthe-sis as a continuous, differentiable logic problem, this framework targets the “scarcity of demon-strated use cases” discussed by the Google Quan-tum AI team. Where the Grand Challenge em-phasizes the need for algorithms that are ro-bust to noise and physically realizable, our DLP model can learn circuit structures under these constraints, including regimes affected by bar-ren plateaus in variational optimization. This perspective suggests that part of the “algorithm search” bottleneck may be addressed with neuro-symbolic architectures that support gradient-based structure learning. 

## 2 Methodology: A Differentiable Logic for Quantum Circuits 

Our framework formalizes circuit discovery as a continuous optimization problem. We first define a scaffold, S = {G1, G 2, . . . , G N }, an ordered list of candidate gate operations that forms a super-set of the (unknown) optimal circuit. 

2.1 The Differentiable Circuit Scaffold 

For each candidate gate Gi ∈ S, we associate a learnable real-valued parameter λi ∈ R, which we refer to as a “structural logit.” The complete set of structural logits forms the learnable parameter vector λ = ( λ1, λ 2, . . . , λ N ) ∈ RN . Each logit is mapped to a continuous “gate switch” si ∈ [0 , 1] 

via the sigmoid function: 

si = σ(λi) = 11 + e−λi . (1) 

This switch si represents the continuous “truth value” of the proposition: “Gate Gi is active in the circuit.” The sigmoid mapping ensures si ∈ [0 , 1] 

while allowing unbounded gradient flow through 

λ.To make the discrete gate selection differen-tiable, we must define an effective gate ˜Gi depen-dent on this continuous switch. We propose two formulations for this interpolation: Linear Relax-ation and Geodesic Interpolation .

Formulation 1: Linear Relaxation. The sim-plest approach, used primarily for its computa-tional efficiency, interpolates linearly between the identity and the gate unitary: 

˜Glin  

> i

(si) = (1 − si)I + siGi. (2) 

While intermediate states si ∈ (0 , 1) are not strictly unitary (potentially dampening the state vector norm), the endpoint solutions ( si ∈ { 0, 1})are guaranteed to be valid quantum gates. We find this method sufficient for shallow depth op-timization. 

Formulation 2: Geodesic Interpolation. For deeper circuits where maintaining strict unitarity is critical to prevent numerical instability (vanish-ing gradients due to norm decay), we define the effective gate via the exponential map, creating a path along the unitary manifold: 

˜Ggeo  

> i

(si) = Gsi 

> i

= exp( −iH isiθ), (3) 

where Gi = e−iH iθ. In this work, we primar-ily employ Linear Relaxation due to its convex-ity properties near the boundaries, but note that Eq. 3 offers a strictly physical alternative. The total learned unitary for the entire scaf-fold, Ulearned , is the ordered product of all ef-fective gates. Note that matrix multiplication is non-commutative; we define the product order to match the circuit diagram (gates 0 . . . N applied left-to-right): 

Ulearned (λ, θ) = ˜GN (sN )·· · ·· ˜G1(s1)· ˜G0(s0), (4) 

where si = σ(λi) and θ denotes any continuous rotation angles in parameterized gates. 

32.2 Core Differentiable Axioms 

The core of our logical programming approach is that the model is trained to satisfy a set of logi-cal axioms, {A k}, which encode the definition of a “good” circuit. Each axiom Ak is formulated as a differentiable predicate Tk ∈ [0 , 1] , which mea-sures its degree of truth. Here we define the pri-mary axioms used throughout this work. 

Correctness (Fidelity). Used for com-piler/synthesis tasks with a known target unitary Utarget . The predicate Tfid measures the normalized squared trace fidelity: 

Tfid (U ) = 1

d2

> ∣∣∣

Tr (U †

> target

U )

> ∣∣∣2

, (5) 

where d = 2 N is the matrix dimension. The cor-responding loss (contradiction) is: 

Lfid = 1 − T fid . (6) 

Correctness (Energy). Used for VQE/QAOA tasks where the goal is to minimize the energy E = ⟨ψ|H|ψ⟩ for a state |ψ⟩ = U |0⟩:

Lenergy (λ, θ) = ⟨0|U (λ, θ)†H U (λ, θ)|0⟩. (7) 

Simplicity (Cost-Weighted). The axiom “The circuit must be simple,” used for pruning. The predicate applies an exponential penalty on the total cost: 

Tsimp (s) = exp 

> (

−α

> N∑
> i=1

cisi

> )

, (8) 

where α is a hyperparameter and ci is the pre-defined cost of gate Gi. In practice, we often use the linear approximation for the loss directly, as it provides a constant, stabilizing gradient: 

Lsimp =

> N∑
> i=1

cisi. (9) 

Additional axioms for entanglement and noise robustness are provided in Appendix 5.2. 

2.3 Gradient Propagation and Barren Plateaus 

The entire model is optimized using standard gra-dient descent. The gradient ∇L propagates back to the structural logits λ (and angle parameters 

θ) via the chain rule. For a structural logit λi,the gradient is: 

∂L

∂λ i

= ∂L

∂s i

· ∂s i

∂λ i

= ∂L

∂s i

· σ(λi)(1 − σ(λi)) , (10) 

where the second factor is the derivative of the sigmoid function. A significant theoretical challenge in vari-ational quantum algorithms is the “Barren Plateau” problem, where the variance of the cost function gradients vanishes exponentially with the number of qubits, Var (∂θL) ∝ O(2 −N ) [9]. This typically occurs when circuits are initialized as random unitary 2-designs. A “polluted” scaf-fold with random initial parameters effectively acts as such a random circuit. To mitigate this, we employ a biased initializa-tion strategy. We initialize the structural logits such that the initial switches are biased towards the identity ( λi ≪ 0 =⇒ si ≈ 0). This ensures the optimization trajectory begins in a region of the landscape with non-vanishing gradients (close to the Identity), effectively “growing” the circuit complexity only as required by the logical axioms. 

## 3 Theoretical Analysis of Linear Relax-ation 

A central component of our Differentiable Logi-cal Programming (DLP) framework is the linear relaxation of the discrete gate choice. We define the effective operation for the i-th candidate gate as: 

˜Gi(si) = (1 − si)I + siUi, si ∈ [0 , 1] . (11) 

For intermediate values si ∈ (0 , 1) , the opera-tor ˜Gi is generally non-unitary, i.e., ˜G† 

> i

˜Gi̸ = I,resulting in a non-physical evolution where the norm of the state vector |ψ⟩ is not preserved. We analyze this formulation as an optimization sur-rogate, establishing bounds on the induced error and the conditions under which the optimizer is driven toward valid quantum circuits. 

3.1 Norm Deviation Bound 

We first quantify the deviation from unitarity for a single interpolated gate. For any unitary Ui

and switch value si ∈ [0 , 1] , the operator ˜Gi(si) = (1 − si)I + siUi satisfies: 

˜G† 

> i

˜Gi = I + si(1 − si)

> (

Ui + U † 

> i

− 2I

> )

. (12) 

4Proof. Expanding directly: 

˜G† 

> i

˜Gi =

> [

(1 − si)I + siU †

> i
> ]

[(1 − si)I + siUi]= (1 − si)2I + si(1 − si)( Ui + U † 

> i

) + s2 

> i

I

=

> [

(1 − si)2 + s2

> i
> ]

I + si(1 − si)( Ui + U † 

> i

)= [1 − 2si(1 − si)] I + si(1 − si)( Ui + U † 

> i

)= I + si(1 − si)

> (

Ui + U † 

> i

− 2I

> )

.

The maximum deviation from unitarity is thus controlled by the factor si(1 − si) ≤ 1/4, which vanishes at the endpoints si ∈ { 0, 1}. In operator norm, this yields:  

> ∥∥∥

˜G† 

> i

˜Gi − I 

> ∥∥∥

≤ si(1 −si)

> ∥∥∥

Ui + U † 

> i

− 2I 

> ∥∥∥

≤ 4si(1 −si),

(13) 

where the second inequality uses ∥Ui +U † 

> i

−2I∥ ≤ 

4 (since the eigenvalues of Ui lie on the unit cir-cle). For a cascade of NS gates with switches s =(s1, . . . , s NS ), the total norm deviation of the state |ψ⟩ = ˜GNS · · · ˜G1|0⟩ can be bounded by: 

|⟨ ψ|ψ⟩ − 1| ≤ 

> NS∏
> i=1

(1 + 4 si(1 − si)) − 1. (14) 

When all switches are near the binary endpoints (i.e., |si − s∗ 

> i

| < ϵ for s∗ 

> i

∈ { 0, 1}), this simplifies to O(NS ϵ), confirming that the non-unitarity is well-controlled in the regime where the optimizer operates after initial convergence. 

3.2 Gradient Stability 

Unlike geodesic interpolation (e−iHsθ ), whose gradient involves the matrix exponential and can suffer from spectral crowding, linear interpolation provides a constant Jacobian: 

∂ ˜Gi

∂s i

= Ui − I, (15) 

independent of si. This ensures that the gradient signal does not vanish as si → 0 (near identity), addressing the “vanishing gradient” problem that plagues parameterized unitary circuits near the identity [9]. The gradient of the full fidelity loss with respect to a structural logit λi is: 

∂Lfid 

∂λ i

= ∂Lfid 

∂ ˜Gi

> ︸ ︷︷ ︸
> chain rule

· (Ui − I)  

> ︸︷︷ ︸
> constant

· si(1 − si)  

> ︸︷︷ ︸
> sigmoid derivative

, (16) 

where the sigmoid derivative si(1 − si) is the only 

si-dependent factor. This means the structural gradient is well-conditioned whenever si is not already saturated at 0 or 1, with the saturation being controlled by the logit initialization. 

3.3 Implicit Binarization by the Fidelity Objec-tive 

We now argue that the fidelity objective Lfid =1 − 1 

> d2

|Tr( U †

> target

Ulearned )|2 implicitly drives the switches toward binary values. Consider a single switch si with all others fixed. The learned uni-tary can be decomposed as Ulearned = A ˜Gi(si)B,where A and B are the products of other effective gates. The fidelity becomes: 

Tfid (si) = 1

d2 |(1 − si)Tr( MI ) + siTr( MU )|2 ,

(17) 

where MI = U †

> target

AB and MU = U †

> target

AU iB.This is a quadratic function in si, whose maxi-mum over [0 , 1] is attained at a boundary point whenever |Tr( MI )|̸ = |Tr( MU )| (i.e., whenever including or excluding the gate makes a differ-ence to fidelity). The simplicity penalty Lsimp = 

> ∑

cisi adds a linear term that further biases to-ward si = 0 , reinforcing binarization. Together, these two forces ensure that at convergence, the switches satisfy si ∈ { 0, 1} up to numerical pre-cision for all gates that meaningfully affect the target fidelity. 

3.4 Summary 

The linear relaxation serves as a valid optimiza-tion surrogate because: (i) the norm deviation is bounded by O(si(1 − si)) per gate and van-ishes at the binary endpoints (Eq. 13); (ii) the constant Jacobian (Eq. 15) provides stable, non-vanishing gradients throughout training; and (iii) the fidelity and simplicity objectives jointly drive the switches toward {0, 1}, where strict unitarity is recovered (Eq. 17). For deep circuits where in-termediate norm decay poses numerical risks, the geodesic interpolation (Eq. 3) provides a strictly unitary alternative. 

3.5 Joint Structure-Parameter Optimization 

The framework is not limited to discrete struc-tural search. Many quantum gates, particu-larly in VQE and QAOA, are parameterized, e.g., 

5Ry(θ). We can incorporate these continuous pa-rameters θ directly into our model. The scaffold S can contain parameterized gates 

Gi(θi). The effective gate definition is thus ex-tended: 

˜Gi(si, θ i) = (1 − si)I + siGi(θi). (18) 

The total learned unitary Ulearned (λ, θ) is now a function of both the structural logits λ (which determine the switches s) and the continuous an-gles θ. The optimization process will learn both simultaneously. This unified approach is a signifi-cant advantage over methods that must alternate between discrete structural updates and continu-ous parameter optimization. 

3.6 A Differentiable Axiom System via T-Norms 

We can interpret the axiom framework theoreti-cally through the lens of Fuzzy Logic. We treat the problem as finding the Maximum Satisfia-bility (MaxSAT) of a logical formula. The to-tal loss function Ltotal corresponds to the nega-tion of the weighted conjunction of our axioms. Using the Lukasiewicz T-norm for conjunction (T (x, y ) = max(0 , x + y − 1) ), the logical con-tradiction is minimized by minimizing the sum of individual violations: 

Ltotal = ∑

> k

wkLk = ∑

> k

wk(1 − T k). (19) 

By optimizing λ (the structural logits determin-ing gate inclusion) and θ (the continuous rotation angles) to minimize Ltotal , the system performs a gradient-based search over the high-dimensional continuous space of circuit architectures, converg-ing on a solution that satisfies the logical propo-sition of a “valid circuit.” 

3.7 Complexity, Scalability, and Limitations 

The computational complexity of this framework has two primary components. The forward pass (constructing Ulearned ) involves NS matrix-matrix multiplications, where NS is the number of gates in the scaffold. The backward pass (comput-ing gradients) has a similar cost. The dominant computational bottleneck is the O(d3) = O(2 3N )

complexity of multiplying the 2N × 2N unitary matrices, where N is the number of qubits. The cost scales linearly with NS .This exponential scaling with qubit count N is the fundamental limitation of all full-state quan-tum simulation methods. It makes the “flat” (non-hierarchical) application of this framework intractable for N ≳ 16 qubits. This limitation is the primary motivation for the Hierarchical Syn-thesis (HS) framework, which we detail in Sec-tion 3.9. 

3.8 Methodology for Complex Problems: Cur-ricula 

A known challenge in high-dimensional optimiza-tion is the presence of poor local minima. These are distinct from barren plateaus (addressed in Section 2.3): while barren plateaus cause gradient magnitudes to vanish exponentially, local min-ima trap the optimizer in suboptimal solutions where gradients exist but point toward inferior configurations. We employ two curriculum learn-ing strategies to guide the optimizer past such local minima toward a global solution. 

Annealing Curriculum (for VQE): For complex VQE problems (e.g., Ising model), opti-mizing H directly can trap the model in a simple, high-energy state. We instead define an annealing path H(t) = (1 − t)Heasy + tH hard , where Heasy 

is a simple, solvable Hamiltonian (e.g., t = 0 ,just the external field) and Hhard is the full tar-get Hamiltonian. By slowly increasing t from 0 to 1 during training, we guide the optimizer from a simple solution to the complex one, successfully avoiding local minima. 

Two-Phase Curriculum (for QAOA): For QAOA depth discovery, we separate “discovery” from “pruning.” It consists of two phases: In Phase 1 (Discovery), we set wsimp = 0 and op-timize only for energy ( L = Lenergy ). This allows the model to “turn on” all potentially useful lay-ers and find the best possible angles, regardless of cost. In Phase 2 (Pruning), we turn on the sim-plicity weight ( wsimp > 0). The optimizer now prunes any layers that do not contribute signifi-cantly to the final energy, discovering the minimal required depth p.

63.9 Methodology for Scalability: Hierarchical Synthesis 

Simulating the full unitary Ulearned (Eq. 4) re-quires matrices of size 2N × 2N , which is in-tractable for N ≳ 16 qubits. To overcome this, we adopt a Hierarchical Synthesis (HS) framework. The HS framework breaks a large N -qubit problem into a series of small, tractable n-qubit sub-problems. 1. Level 0 (Motif Discovery): We first use the DLP framework to discover and optimize a small, fundamental n0-qubit motif, UM0

(e.g., a 2-qubit Bell state circuit). 2. Level 1 (Composition): We “freeze” the dis-covered UM0 and treat it as a new, non-learnable gate. We then promote it to an 

n1-qubit scaffold S1 (e.g., UM0 (q0, q 1) ⊗ Iq2 ). The DLP optimizer then solves this n1-qubit problem, discovering UM1 .3. Level k (Iteration): This process is repeated. The circuit UMk is composed of motifs UMk−1

and other gates. This hierarchical approach ensures that the com-putational complexity at each optimization step k

scales only with the size of the new sub-problem, 

O(2 nk ), rather than the total number of qubits, 

O(2 N ).

3.10 Comparison to Prior Art & Hardware Readiness 

This DLP framework differs significantly from non-differentiable search methods, such as ge-netic algorithms [12] or symbolic SAT-solvers [13, 14]. Those methods must rely on heuristic search strategies or sampling from a discrete space, which can be highly inefficient. By contrast, our framework maps the discrete search space onto a continuous manifold, allowing for the use of highly efficient, gradient-based optimizers that can follow the path of steepest descent. Compared to prior differentiable approaches such as DQAS [15] and QuantumDARTS [16], our method offers several distinctions. DQAS es-timates gradients through Monte Carlo sampling from a probabilistic model over discrete architec-tures, which can be sample-inefficient. Quan-tumDARTS improves upon this with Gumbel-Softmax reparameterization [17, 18] but still frames the problem as probabilistic gate selection at each placeholder. Our approach, by contrast, uses continuous switches si that directly inter-polate the gate unitary with the identity (Eq. 2), enabling true end-to-end differentiability through standard backpropagation. Furthermore, our log-ical axiom framework (Section 2.2) provides a principled way to compose multiple objectives (fidelity, simplicity, robustness) that extends be-yond the single-objective formulations typical of prior QAS methods. The circuits discovered by this method are not guaranteed to be “hardware-native.” For example, a discovered circuit may contain a

CN OT (0 , 3) gate, which is not directly exe-cutable on hardware with only linear connectiv-ity. A final post-compilation and routing pass would still be required. However, the Lsimp ax-iom (Eq. 9) can be made “hardware-aware” by assigning costs ci based on hardware constraints. For example, a native CN OT (0 , 1) could be as-signed ci = 10 , while a non-native CN OT (0 , 3) 

(which requires multiple SWAPs) could be as-signed ci = 70 . This would intrinsically bias the optimizer to discover circuits that are more amenable to a specific target topology. 

## 4 Experiments and Results 

4.1 Experiment 1: Trotter-Step Optimization 

We demonstrate the framework’s capability to perform compiler optimization by discovering a 2nd-order Trotter-Suzuki decomposition from a “polluted” scaffold containing redundant and sub-optimal gates. 

4.1.1 Implementation Details 

We define a target unitary Utarget = e−iH Heis t for a 4-qubit 1D Heisenberg chain with t = 0 .1. The goal is to approximate this evolution using dis-crete gates. We construct a scaffold S containing a mix of valid and invalid operators: 1. Correct 2nd-Order Gates: The optimal sym-metric sequence e−iH odd t/ 2, e−iH even t, and 

e−iH odd t/ 2.2. Distractor Gates: A 1st-order approxima-tion term e−iH odd t, a single-term operator 

e−iH 01 t, and a generic CNOT gate. 

7The DLP model is initialized with all gates “ON” (logits λi = 2 .0, corresponding to si ≈ 0.88 )to simulate a pruning task. We train for 4000 epochs using AdamW optimizer with a learning rate of 0.01. The loss function balances correct-ness (fidelity) and simplicity (gate count): 

L = wfid Lfid + wsimp Lsimp (20) 

where wfid = 5 .0 and wsimp = 0 .3, and the loss terms are defined in Eqs. 6 and 9. This weighting prioritizes finding a high-fidelity solution while exerting constant pressure to remove unnecessary gates. 0 500 1000 1500 2000 2500 3000 3500 4000       

> Epochs
> 0.5
> 1.0
> Fidelity
> Circuit Fidelity ( correct )
> = 0.5 = 0.3 = 0.25 = 0.1 = 0.05 = 0

Figure 2: Circuit fidelity over training. Circuit fidelity (Tfid ) over training epochs for varying noise levels σ. The system consistently converges to high fidelity even under significant noise ( σ = 0 .5). 0 500 1000 1500 2000 2500 3000 3500 4000  

> Epochs
> 0.5
> 0.6
> 0.7
> Score
> Simplicity Score ( simple )

Figure 3: Simplicity score over training. Simplicity score ( Tsimp ) over training epochs. The convergence to a specific score indicates the pruning of redundant gates across all noise levels. 

4.1.2 Evaluation Criteria 

Structural Accuracy: The model must iden-tify and keep only the three gates cor-responding to the 2nd-order decomposition (Uodd (t/ 2) , U even (t), U odd (t/ 2) ) while suppressing all distractors (i.e., si < 0.01 ). 

Fidelity: The fidelity of the discovered circuit must match the theoretical limit of the 2nd-order approximation ( F > 0.999 ). 

Robustness: The discovery process must con-verge to the correct topology even in the presence of noise. 

4.1.3 Evaluation 

To verify the method’s resilience to control and readout errors, we introduced Gaussian noise to the unitary evaluations during training. We per-formed independent trials with noise levels σ ∈{0, 0.05 , 0.1, 0.25 , 0.3, 0.5}. In every trial, includ-ing the highest noise setting ( σ = 0 .5), the DLP model converged to the optimal 3-gate structure (Figs. 2 and 3). The discrete nature of the gate switches ( si ∈ { 0, 1}) acts as a noise filter: once a gate is decisively pruned or selected, small fluc-tuations in the loss landscape due to noise are insufficient to reverse the decision. This “locking-in” effect, combined with the gradient averaging inherent in stochastic optimization, allows the framework to extract the correct symbolic struc-ture even from a noisy signal. Figure 4 illustrates the initial state of the scaffold before optimization, where all candidate gates are active. Figure 5 visualizes the final dis-covered circuit topology for the highest noise level 

σ = 0 .5, demonstrating the consistency of the structural solution. q0

> q1
> q2
> q3
> 0
> 1
> 2
> 3
> U_odd(t/2)
> 0
> 1
> U_even(t)
> 0
> 1
> 2
> 3
> U_odd(t/2)
> 0
> 1
> 2
> 3
> U_odd(t)
> 0
> 1
> U_01(t)
> 0
> 1
> CNOT(0->1)

Figure 4: Initial scaffold configuration. Initial scaffold input with all gates activated. This represents the start-ing point for the pruning task. q0

> q1
> q2
> q3
> 0
> 1
> 2
> 3
> U_odd(t/2)
> 0
> 1
> U_even(t)
> 0
> 1
> 2
> 3
> U_odd(t/2)

Figure 5: Discovered circuit topology. Discovered cir-cuit topology for noise level σ = 0 .5. The framework correctly identifies the 2nd-order Trotter decomposition. 

4.1.4 Cost-Aware Non-Trivial Pruning 

We next tested whether the model can make cost-aware pruning decisions that go beyond simple rule-based pattern matching. 

8Setup: The scaffold is a 14-gate, 5-qubit circuit with two distinct redundancies: (a) a visually ob-vious H-H = I identity (cost = 1.0 + 1.0 = 2.0) and (b) a non-trivial CN OT -CN OT = I identity (cost = 10.0 + 10.0 = 20.0). The target is Utarget 

of the full 14-gate circuit. 

Objective: The axioms are L = wfid Lfid +

wsimp Lsimp (s, c). This is analogous to Eq. 20, but with an explicit dependence on (s, c) in the sim-plicity term, and explicitly tests whether the op-timizer prioritizes removing high-cost redundan-cies. 

Result The model did not prune the obvious, low-cost H-H identity. Instead, it converged on pruning the two CNOT gates, correctly identi-fying the optimization path that yielded a 10 ×

greater reduction in the simplicity loss Lsimp .

4.2 Experiment 2: De Novo Circuit Discovery 

To validate the combinatorial search capabilities of the DLP framework, we conducted an experi-ment targeting the discovery of the 4-qubit Quan-tum Fourier Transform (QFT) circuit from a pol-luted scaffold. The primary motivation was to demonstrate that the model could autonomously extract a canonical algorithmic structure from a high-dimensional, noisy search space. The central challenge lay in the complexity of the input scaffold (Fig. 6 (a)). We constructed a heavily polluted scaffold containing 21 poten-tial gate operations, corresponding to a large dis-crete configuration space (which our method ex-plores via continuous relaxation and gradient de-scent, not brute-force enumeration). This in-put included the 12 gates required for the op-timal QFT, but they were obscured by 9 “pol-luter” gates. These distractors were engineered to be deceptive; they included redundant identity sequences (specifically H-H and CN OT -CN OT 

pairs) and other incorrect “junk” gates, present-ing the optimizer with local minima that a naive pruning method might fail to escape. The goal was to match the target 16 × 16 QFT unitary. The optimization was driven by the com-posite loss function L = wfid Lfid + wsimp Lsimp .This formulation necessitates a delicate balance: the system must maximize logical correctness (Tfid ) while simultaneously responding to the pressure to minimize circuit complexity ( Lsimp ).                

> (a) The input scaffold Swith 21 gates, including hidden identity pairs. q0
> q1
> q2
> q3
> HHXH
> /2
> P (0)
> /4
> P (0)
> /8
> P (0)
> H
> /2
> P (0)
> /4
> P (0)
> /2
> RZH
> /2
> P (0)
> H
> (b) The final discovered circuit, recovering the optimal 12-gate QFT. q0
> q1
> q2
> q3
> H
> /2
> P (0)
> /4
> P (0)
> H
> /8
> P (0) /2
> P (0)
> /4
> P (0)
> H
> /2
> P (0)
> H
> (c) Training dynamics showing convergence of fidelity and cost. 01000 2000 3000 4000 5000 6000 7000 8000
> Epochs
> 0.5
> 1.0
> Total Contr. (Loss)
> 0.0
> 0.5
> 1.0
> Corre. Fidelity (  fid )

Figure 6: De Novo Circuit Discovery Results. The figure illustrates the pruning process for the 4-qubit QFT. (a) The initial state is a “polluted” scaffold where valid gates are mixed with distractors (e.g., H-H,

CN OT -CN OT ). (b) The final circuit topology after optimization, where the model has filtered out the noise to reveal the canonical structure. (c) Training curves indicating that the system maximizes fidelity ( Tfid ) while simultaneously minimizing the simplicity loss ( Lsimp ), optimizing over the discrete configuration space via con-tinuous relaxation. 

4.2.1 Evaluation 

The results, visualized in Fig. 6, demonstrate a decisive convergence to the optimal solution to-gether with the final circuit. The learned struc-tural switches correctly differentiated between es-sential and non-essential operations, converging to si ≈ 1 for all 12 correct QFT gates and si ≈ 0

for all 9 polluter gates. By optimizing over this discrete configuration space via continuous relax-ation, the framework proved its capacity for non-trivial combinatorial optimization. 

4.3 Experiment 3: Noise Resilience Bench-mark Against QuantumDARTS 

We conducted a comprehensive benchmark to validate the framework’s robustness to measure-ment shot noise, comparing DLP against Quan-tumDARTS on the quantum simulation of the stretched Lithium Hydride (LiH) molecule. Shot 

9noise is a fundamental limitation in NISQ devices arising from the finite number of measurement samples available per circuit evaluation. Our ob-jective was to quantify the noise resilience of both architecture search methods under realistic ex-perimental conditions. 

Problem and Formulation 

We modeled the LiH molecule at a stretched bond distance of d = 2 .5 Å, mapped to 4 qubits us-ing an active space reduction (occupied core: Li 1s; active valence: orbitals 1-2). This geome-try exhibits strong static correlation (correlation gap: 2.67 m Eh), making it a challenging test case where Hartree-Fock reference is insufficient. 

Baseline Scaffold: Hardware-efficient ansatz (HEA) with 2 layers of RY , RZ rotations and linear CNOT entanglers, initialized from the Hartree-Fock state |1100 ⟩, yielding a search space of ∼24 structural degrees of freedom. 

Shot Noise Implementation: For each train-ing iteration, we injected Gaussian noise with variance σ2 = Var [H]/n shots to the energy gra-dient, where Var [H] = ⟨ψ|H2|ψ⟩ − ⟨ ψ|H|ψ⟩2 is the observable variance. This models the Central Limit Theorem behavior of finite-shot quantum measurements. 

Curriculum Learning: Soft-Pruning Cur-riculum with 150-epoch warmup ( wsimp = 0)followed by gradual sparsity ramp-up ( wsimp →

0.002 ) over 300 total epochs. 

Noise Levels: We tested six shot regimes: Ex-act (analytical), 10,000, 1,000, 500, 100, and 50 shots, spanning high-fidelity to severely noisy conditions. 

Results Discussion 

Table 1 presents the final ground state errors and circuit sizes discovered under each noise condi-tion. Our approach exhibits 98 .8× lower variance in final energies compared to QuantumDARTS across shot noise levels (std: 2.44 × 10 −4 vs 

2.41 × 10 −2 Ha). This demonstrates that DLP’s sigmoid-based continuous switches provide more 

Table 1: Noise Resilience Comparison: DLP vs QuantumDARTS on LiH ( 2.5 Å).                                               

> Ours QuantumDARTS [16] Shots Energy Error Gates Energy Error Gates (Ha) (mHa) (Ha) (mHa)
> Exact −7.770 52 3.02 9−7.736 24 37 .30 8
> 10,000 −7.770 64 2.91 10 −7.770 39 3.15 9
> 1,000 −7.770 05 3.49 11 −7.770 48 3.07 11
> 500 −7.770 14 3.40 9−7.708 01 65 .53 8
> 100 −7.770 61 2.94 11 −7.769 22 4.32 10
> 50 −7.770 65 2.90 11 −7.770 63 2.91 14

stable gradients under noisy conditions than QuantumDARTS’s Gumbel-Softmax sampling. The lower variance of our method maintains chemical accuracy ( < 5 m Eh error) across all noise regimes, with minimal variation in final energy ( 2.90 m Eh to 3.49 m Eh). At the same time, discovered circuit size remained compact (between 9 and 11 gates), indicating stable ar-chitectural decisions even under severe noise. 

Interpretation: Smooth vs Sharp Decision Boundaries 

The noise resilience of our approach can be at-tributed to the difference in how the two methods interpolate between gate inclusion and exclusion: Our approach uses the sigmoid switch func-tion si = σ(λi), which provides a smooth, convex mapping from logits to gate probabilities. The derivative ∂s i/∂λ i = si(1 − si) is continuous and bounded, providing stable gradients even when the energy signal is noisy. The sigmoid naturally damps extreme gradient updates, acting as an im-plicit regularizer. On the other hand, QuantumDARTS (Gumbel-Softmax) uses reparameterization 

wi = softmax (( αi + gi)/τ ), where gi are Gumbel noise samples, introduces stochastic discrete decisions that are sensitive to gradient noise. At low temperatures ( τ → 0), the argmax behavior creates sharp decision boundaries where small gradient perturbations can flip architectural choices, leading to the observed instability. 

Hardware-Aware Optimization Validation 

As a secondary validation, we tested the frame-work’s ability to avoid non-native gates on a sim-ulated 3-qubit linear topology. The optimizer learned to suppress a non-native CNOT(0,2) gate (cost: 101.0, requiring 2 SWAPs) in favor of 

10 native CNOT(0,1) and CNOT(1,2) connections (cost: 1.0 each), with the non-native gate’s acti-vation probability converging to s0,2 = 0 .089 <

0.1, demonstrating hardware-aware architectural search without explicit rule-based constraints. 

4.4 Experiment 4: Scalable Topology Discov-ery on the Frustrated Heisenberg Chain 

We applied the Hierarchical Synthesis (HS) framework to address the challenge of geomet-ric frustration in quantum many-body systems. While standard ansatzes often rely on nearest-neighbor connectivity, frustrated systems—such as the 1D Heisenberg chain with competing nearest-neighbor ( J1) and next-nearest-neighbor (J2) interactions—require non-local topology to accurately capture the ground state. 

Problem and Formulation 

The objective was to find the ground state of the Hamiltonian: 

H = J1

∑

> i

⃗Si ·⃗ Si+1 + J2

∑

> i

⃗Si ·⃗ Si+2 (21) 

A linear chain topology is insufficient for this sys-tem due to the competing interaction terms. Fur-thermore, optimizing a circuit for a macroscopic system size (e.g., N = 20 ) is computationally in-tractable due to the exponential scaling of the state vector. To overcome this, we formulated the problem using the HS “Divide-and-Conquer” strategy: 

• Stage I (Motif Discovery): We defined a minimal 3-qubit “motif” scaffold ( q0, q 1, q 2). The scaffold included parameterizable rota-tions ( RY , R Z ) and a learnable set of en-tangling gates corresponding to all possi-ble pairwise interactions: nearest-neighbor (q0 − q1, q 1 − q2) and the non-local next-nearest-neighbor ( q0 − q2). 

• Stage II (Hierarchical Compilation): The discovered motif was “frozen” and procedu-rally tiled to construct a linear array for 

N = 20 qubits, bypassing the barren plateau problem associated with global optimization. 

Discovery Results 

In Stage I, the DLP optimizer was tasked with finding the minimal local structure required to q0

> q1
> q2
> 0.436
> RY
> 1.03
> RY
> 0.213
> RY
> 0.33
> RZ
> 0.224
> RZ
> 0.208
> RZ
> J1 (0.99)
> J1 (1.00)
> J2 (1.00)
> 2.03
> RY
> 1.12
> RY
> 2.02
> RY

Figure 7: Autonomously discovered motif for the J1-

J2 Heisenberg model. The DLP framework correctly identified the need for a triangular topology, activating the non-local J2 gate (connection between q0 and q2)alongside standard nearest-neighbor interactions to re-solve geometric frustration. 

resolve the frustration. Fig. 7 illustrates the final discovered motif. The optimization produced two key results: 

• Topological Search: The model au-tonomously identified the necessity of the non-local interaction. As shown in the circuit diagram, the optimizer converged to a topology where the “skip” connection (q0 connected to q2) was fully activated (s ≈ 1.0), alongside the nearest-neighbor connections. This effectively created atriangular connectivity graph required to resolve the geometric frustration. 

• Parameter Optimization: The system simul-taneously optimized the rotation angles, con-verging to an energy of E ≈ − 3.32 for the local block. 

Scalability and Comparison 

In Stage II, the discovered 3-qubit motif was com-piled into a full ansatz for a 20-qubit system. This process generated a physics-informed circuit with a total depth of 216 gates. By leveraging the HS framework, we achieved a result that would have been computationally inaccessible via direct global optimization ( 220 Hilbert space), demon-strating the framework’s capacity to scale physi-cally motivated circuit structures to macroscopic regimes. 

4.5 Experiment 5: Hardware-Aware Optimiza-tion of Geometrically Frustrated Systems 

Motivation A critical bottleneck in the NISQ era is the disconnect between abstract algorith-mic design and physical hardware constraints. 

11 While theoretical ansatzes often assume all-to-all connectivity, physical devices typically possess re-stricted coupling maps (e.g., linear or grid topolo-gies). Mapping a non-native circuit to such hard-ware requires the insertion of SWAP gates, which increases circuit depth and accumulates coherent errors. This challenge is particularly acute in ge-ometrically frustrated systems, such as the J1-J2

Heisenberg model, where competing interactions often require non-local connectivity to resolve the ground state. 

Methodology To address these challenges, we applied the Differentiable Logical Programming (DLP) framework to the 3-qubit J1-J2 Heisen-berg model with parameters J1 = 1 .0 and J2 =0.5. We imposed a strict linear device topology (0 − 1 − 2), rendering the next-nearest-neighbor interaction between qubits 0 and 2 non-native. The optimization objective was defined as a com-posite loss function: 

L = wenergy Lenergy + whw 

∑

i

cisi (22) 

where ci represents the hardware cost. We as-signed a high penalty ( cnon-native = 100 .0) to CNOT gates acting on unconnected qubit pairs 

(0 , 2) , while native gates were assigned a nominal cost ( cnative = 1 .0). We compared the hardware-aware DLP against a standard DLP model opti-mizing purely for energy without topological con-straints. 

Results The results, summarized in Table 2, demonstrate the efficacy of the hardware-aware approach. Both DLP variants successfully nav-igated the energy landscape. The standard DLP achieved near-perfect theoretical conver-gence (99.9–100% ground state overlap). How-ever, it relied heavily on non-native gates (aver-age of 3.0 per circuit), necessitating significant compilation overhead. As shown in Figure 8, this resulted in a post-compilation depth of 37 and a reduced hardware fidelity of 0.853 ± 0.025 due to noise accumulation. The hardware-aware DLP autonomously dis-covered a topology that avoided the non-native connection entirely (0.0 non-native gates). Al-though this trade-off resulted in a marginally higher theoretical energy (96.7% of ground state), the resulting circuits were significantly shallower (Depth 17). This structural efficiency translated to a superior hardware fidelity of 0.957 ± 0.020 .A t-test confirms this improvement is statistically significant ( t = 4 .618 , p = 0 .0099 < 0.05 ). These findings suggest that incorporating hardware con-straints directly into the differentiable logic al-lows the optimizer to find “hardware-native” so-lutions that outperform theoretically optimal but compilation-heavy circuits. 

Table 2: Benchmarking Hardware-Aware Optimiza-tion. Comparison of training energy (theoretical), com-pilation overhead, and final hardware fidelity under a noise model.                     

> Method Ground State Overlap Compiled Depth Hardware Fidelity
> Standard DLP 99 .9–100 %37 0.853 ±0.025
> HW-Aware DLP 96 .7% 17 0.957 ±0.020 DLP
> (HW-Aware)
> DLP
> (Standard)
> ADAPT-VQE
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> Hardware Fidelity
> Fidelity Under Noise
> DLP
> (HW-Aware)
> DLP
> (Standard)
> ADAPT-VQE
> 0.0
> 0.5
> 1.0
> 1.5
> 2.0
> 2.5
> 3.0
> Number of Non-Native Gates
> Hardware Compatibility
> DLP
> (HW-Aware)
> DLP
> (Standard)
> ADAPT-VQE
> 3
> 2
> 1
> 0
> 1
> 2
> Energy
> Ground State Accuracy
> Ground State
> 12.5 15.0 17.5 20.0 22.5 25.0 27.5 30.0
> Number of Active Gates
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> Hardware Fidelity
> Efficiency Frontier
> DLP (HW-Aware)
> DLP (Standard)
> ADAPT-VQE

Figure 8: Fidelity vs. Complexity. The hardware-aware DLP (green) sacrifices a small amount of theoretical en-ergy to drastically reduce circuit depth by avoiding non-native gates. This results in a ≈ 12% improvement in realized fidelity compared to the standard DLP (blue), which suffers from SWAP-induced errors. 

4.6 Experiment 6: Adaptive Compilation on IBM Quantum Hardware 

To validate the practical applicability of the DLP framework beyond simulation, we conducted a series of adaptive routing experiments on IBM Quantum’s ibm_torino backend, a 133-qubit su-perconducting quantum processor. These ex-periments demonstrate that the framework can autonomously detect and respond to hardware degradation using only gradient-based optimiza-tion, without requiring explicit failure detection 

12 0 5 10 15 20 25 30 

> Time (Cycles)
> 0.4
> 0.6
> 0.8
> 1.0
> Fidelity
> DLP (Adaptive)
> Static Baseline
> HW Noise
> 0.01
> 0.02
> 0.03
> 0.04
> Avg Error

Figure 9: Noise-Adaptive Circuit Morphing. Compar-ison of realized circuit fidelity under time-varying hard-ware noise. Both the Static Baseline (Red) and Adaptive DLP (Green) are initialized from an identical optimized state at t = 0 . As the average gate error rate (grey dotted line) drifts over 30 calibration cycles, the Static Baseline passively degrades, with fidelity strictly anticor-related to noise intensity. In contrast, the Adaptive DLP model maintains high fidelity ( ∼ 0.9) by autonomously reconfiguring the circuit topology to avoid temporally noisy edges. 

protocols or manual intervention. 

4.6.1 Noise-Adaptive Circuit Morphing 

Motivation A fundamental challenge in the operation of NISQ devices is the temporal insta-bility of hardware parameters. Device calibration data, such as gate fidelities and coherence times, drift significantly over hours or days due to ther-mal fluctuations, control electronics instability, and two-level system (TLS) defects. Standard compilation workflows typically treat the hard-ware as a static target: a circuit is transpiled once and executed repeatedly. This passive ap-proach leaves the algorithm vulnerable to “cali-bration drift.” 

Methodology We constructed a longitudinal simulation of a 4-qubit Heisenberg model ( H =

∑⃗ Si ·⃗ Si+1 ) evolving over 30 “calibration cycles.” We modeled the hardware environment using a time-varying noise model where the error rates of entangling CNOT gates followed a stochastic random walk superimposed with periodic fluctu-ations, mimicking the diurnal drift often observed in superconducting processors. We compared two control strategies: a Static Baseline , where the circuit is fully optimized at t = 0 and then frozen, and the Adaptive DLP model, which performs sparse fine-tuning updates at each time step t,adjusting both continuous parameters and dis-crete gate switches ( si) to minimize L = ⟨H⟩ +

λ ∑ ci(t)si, where ci(t) represents the instanta-neous noise cost of gate i. Both models began from the exact same pre-optimized state at t = 0 .

Results The results are presented in Figure 9. The Static Baseline fidelity is strictly anticorre-lated with the hardware noise profile, degrad-ing significantly whenever the error rates spike (e.g., cycles 0 − 5 and 20 − 30 ). The Adaptive DLP model demonstrates a distinct decoupling from the underlying hardware variance, consis-tently exceeding the baseline by approximately 15% during high-noise intervals. This stability is achieved by morphing the topology: when the cost of a specific CNOT gate rises due to drift, the gradient penalty drives the associated switch 

si → 0, while the physics loss simultaneously ac-tivates alternative, lower-noise paths to preserve the target unitary. 

4.6.2 Proactive Resource Selection on 133-Qubit IBM Torino 

We validated this morphing capability on real hardware with a GHZ state preparation task (|ψ⟩ = 1√2 (|000 ⟩ + |111 ⟩)) on the 133-qubit 

ibm_torino processor. The model was trained using the Adam optimizer to minimize L = (1 −

FGHZ ) + 0 .5 · (cAsA + cB sB ), where cA was in-creased to 100 at Cycle 3 to simulate a localized hardware failure. The results (Figure 10) reveal an inherent “proactive selection” mechanism: while the fail-ure was scheduled for Cycle 3, the Adaptive DLP model autonomously identified Path B as the high-fidelity route almost immediately during the initial calibration cycles, with the probability of utilizing Path A dropping to near-zero by Cy-cle 1. By locking-in to the more robust path during early iterations, the model maintained a near-ideal fidelity of ≈0.97 throughout the fail-ure region, representing a 59.3 percentage point improvement over the Static Baseline. 

4.6.3 Real-Time Adaptation to Catastrophic Topology Failure 

Setup To test a more severe failure mode, we constructed a “Softmax Router” experiment to generate a 3-qubit entangled state with two re-dundant topological paths: “Path A” ( 0 → 1 →

2) and “Path B” ( 0 → 2 → 1). At time step 

t = 10 , Path A suffered a catastrophic failure (cost spike cA → 100 .0). 

13 0 1 2 3 4 5 6      

> 0.75
> 0.80
> 0.85
> 0.90
> 0.95
> GHZ Fidelity
> Adaptive DLP
> Static Baseline
> Failure Event
> 0123456
> Calibration Cycle
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> Path Probability
> Path A Prob
> Failure Region

Figure 10: Proactive resource selection on the ibm_torino backend. (Top) GHZ fidelity compari-son showing the Adaptive DLP model (green) maintain-ing stable performance ( ∼0.97) while the Static Base-line (red) remains vulnerable to noise. (Bottom) Au-tonomous topology transition where the optimizer drives the probability of the higher-error Path A to near-zero by Cycle 1, effectively preempting the simulated failure event introduced at Cycle 3. 

Results As shown in Figure 11, the Static Baseline suffered an immediate collapse in perfor-mance (Efficiency ≈ 0.0) at the onset of failure. The Adaptive DLP model exhibited immediate resilience: the sudden increase in cost generated a strong gradient signal driving sA → 0, while the physics conservation term drove sB → 1, effec-tively morphing the circuit topology in real-time (Figure 12). The system recovered to a realized efficiency of ≈ 0.74 , mitigating the hardware fail-ure without halting execution for recompilation. 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 

> Cycle (hour)
> 0.0
> 0.5
> 1.0
> Fidelity
> Real-Time Circuit Morphing
> Static
> Adaptive DLP
> Failure

Figure 11: Efficiency comparison. Efficiency compari-son showing the catastrophic failure of the Static Base-line (red) at t = 10 and the rapid recovery of the Adap-tive DLP model (green). 

4.6.4 Hardware Validation on IBM Torino 

We replicated the catastrophic failure experiment on the ibm_torino backend with a 3-qubit GHZ q0

> q1
> q2
> 1.57
> RYq0
> q1
> q2
> 1.57
> RY

(a) Static Baseline (Failed) (b) Adaptive DLP (Rerouted) 

Figure 12: Dynamic Topology Morphing Post-Failure. (a) The Static Baseline remains locked to the failed Path A, leading to zero fidelity. (b) The Adaptive DLP autonomously reroutes to Path B via gradient de-scent. 

state preparation task over 6 calibration cycles. At cycle 3, a 70% fidelity penalty was applied to Path A. The adaptive model used Adam ( η = 0 .5)with 5 training iterations per cycle (512 shots per circuit). During normal operation (cycles 0–2), both models achieved comparable fidelities (74–82%). Upon the simulated failure at cycle 3, the Static Baseline dropped from 81.8% to 39.0%, while the Adaptive DLP exhibited a transient degra-dation to 24.8% before recovering to 97.3% by cycle 4 (Figure 13). By cycle 5, the adaptive model achieved 97.5% fidelity versus 38.2% for the baseline—a 59.3 percentage point improve-ment. The routing probabilities (Figure 14) show complete migration from Path A to Path B within two cycles post-failure, with the entire experi-ment completing in 3.1 minutes wall-clock time across 36 quantum jobs. 0 1 2 3 4 5

> Calibration Cycle
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> GHZ Fidelity
> Adaptive Routing on IBM Quantum Hardware
> Static Baseline
> Adaptive DLP
> Failure Event

Figure 13: Adaptive routing on IBM Quantum hard-ware. Measured GHZ state fidelity across 6 calibration cycles on the ibm_torino backend. The Adaptive DLP model (green) recovers to near-ideal fidelity by cycle 4 af-ter the simulated failure at cycle 3 (vertical dotted line), achieving a 59.3 percentage point improvement over the Static Baseline (red). 

These results provide empirical evidence that differentiable logic programming can function as a form of online adaptive compilation , continu-ously monitoring realized performance via quan-tum measurements and adjusting circuit struc-ture accordingly—a capability that current rule-

14 0 1 2 3 4 5    

> Calibration Cycle
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> Path Probability
> Autonomous Topology Morphing (Real Hardware)
> Path A (0 12)
> Path B (0 21)
> Failure Region

Figure 14: Real-time autonomous topology morph-ing. Evolution of learned routing probabilities on IBM Quantum hardware. Path A (blue) is initially preferred; upon failure detection at cycle 3 (red region), the opti-mizer transitions to Path B (orange), achieving complete rerouting by cycle 4. 

based compilers cannot provide. 

## 5 Conclusion 

We have introduced a Differentiable Logical Pro-gramming (DLP) framework for quantum cir-cuit design, a neuro-symbolic approach that re-casts the NP-hard problem of circuit optimiza-tion into a continuous, gradient-based search. By representing a scaffold of candidate gates as learnable switches s (derived from structural logits λ) and optimizing them to satisfy differ-entiable logical axioms, our method provides a uniquely flexible tool for algorithm design. We have demonstrated that this single, unified frame-work can: (1) function as a “smarter” compiler discovering non-trivial optimizations from first principles; (2) perform de novo circuit discovery, such as the 12-gate 4-qubit QFT; (3) solve joint structural-parametric design problems; (4) scale to larger systems via Hierarchical Synthesis; and (5) perform real-time hardware-aware adaptation to temporal noise and failures, including a 59.3 percentage point fidelity improvement on the 133-qubit IBM Torino processor. While currently focused on scaffold pruning within a fixed gate ordering, future work will ex-tend this to full topological search by incorpo-rating differentiable “Swap Networks.” The flex-ibility of this approach, built on standard auto-matic differentiation libraries, allows for a diverse range of tasks simply by composing different log-ical axioms, providing a potent methodological response to the challenges of the NISQ and early fault-tolerant eras. 

5.1 Limitations and Scope: Fixed-Topology Optimization 

It is important to distinguish between topolog-ical discovery (finding the optimal connectivity graph) and scaffold pruning (optimizing a selec-tion from an ordered list). In this work, we fo-cus on the latter. The DLP framework is cur-rently constrained by the fixed ordering of the in-put scaffold S. If the optimal solution requires a permutation of gates not present in S, the model cannot discover it. However, this constraint is of-ten intentional for the use case of optimizing ex-isting ansatzes , where the ordering is dictated by a template. Future work will extend this to full topological search by incorporating differentiable “Swap Networks.” The primary strength of this approach is its flexibility and ease of implementation. The same core model, built on standard autograd libraries like PyTorch, can solve this diverse range of tasks simply by composing different logical axioms in the loss function. 

5.2 Data and Code Availability 

The source code and data supporting the findings of this study are available from the correspond-ing author upon reasonable request. Scripts for reproducing the experiments will be made pub-licly available upon publication. 

## Acknowledgments 

This work was supported by the Director of the Office of Science of the U.S. Department of En-ergy under Contract No. DE-AC02-05CH11231. 

## References 

[1] Michael A. Nielsen and Isaac L. Chuang. “Quantum computation and quantum infor-mation”. Cambridge University Press. Cam-bridge (2010). 10th anniversary edition. [2] Sam McArdle, Suguru Endo, Alán Aspuru-Guzik, Simon C. Benjamin, and Xiao Yuan. “Quantum computational chemistry”. Re-views of Modern Physics 92 , 015003 (2020). [3] Yudong Cao, Jonathan Romero, Jonathan P. Olson, Matthias Degroote, Peter D. John-son, M. Kieferová, Ian D. Kivlichan, Tim 

15 Menke, Borja Peropadre, Nicolas P. D. Sawaya, Sukin Sim, Libor Veis, and Alán Aspuru-Guzik. “Quantum chemistry in the age of quantum computing”. Chemical Re-views 119 , 10856–10915 (2019). [4] Román Orús, Samuel Mugel, and Enrique Lizaso. “Quantum computing for finance: Overview and prospects”. Reviews in Physics 

4, 100028 (2019). [5] Francesco Bova, Avi Goldfarb, and Roger G. Melko. “Commercial applications of quan-tum computing”. EPJ Quantum Technology 

8, 2 (2021). [6] John Preskill. “Quantum computing in the NISQ era and beyond”. Quantum 2,79 (2018). [7] Alberto Peruzzo, Jarrod R. McClean, Peter Shadbolt, Man-Hong Yung, Xiao-Qi Zhou, Peter J. Love, Alán Aspuru-Guzik, and Jeremy L. O’Brien. “A variational eigenvalue solver on a photonic quantum processor”. Nature Communications 5, 4213 (2014). [8] Edward Farhi, Jeffrey Goldstone, and Sam Gutmann. “A quantum approx-imate optimization algorithm” (2014). arXiv:1411.4028. [9] Jarrod R. McClean, Sergio Boixo, Vadim N. Smelyanskiy, Ryan Babbush, and Hartmut Neven. “Barren plateaus in quantum neural network training landscapes”. Nature Com-munications 9, 4812 (2018). [10] Harper R. Grimsley, Sophia E. Economou, Edwin Barnes, and Nicholas J. Mayhall. “An adaptive variational algorithm for ex-act molecular simulations on a quantum computer”. Nature Communications 10 ,3007 (2019). [11] Seyon Sivarajah, Silas Dilkes, Alexander Cowtan, Will Simmons, Alec Edgington, and Ross Duncan. “t|ket 〉: a retargetable com-piler for nisq devices”. Quantum Science and Technology 6, 014003 (2020). [12] Martin Lukac and Marek Perkowski. “Evolv-ing quantum circuits using genetic al-gorithm”. In Proceedings of the 2002 NASA/DoD Conference on Evolvable Hard-ware. Pages 177–185. IEEE (2002). [13] Matthew Amy, Dmitri Maslov, Michele Mosca, and Martin Roetteler. “A meet-in-the-middle algorithm for fast synthesis of depth-optimal quantum circuits”. Trans. Comp.-Aided Des. Integ. Cir. Sys. 32 ,818–830 (2013). [14] Giulia Meuli, Mathias Soeken, and Giovanni De Micheli. “SAT-based CNOT, T quantum circuit synthesis”. In Reversible Computa-tion (RC 2019). Volume 11497 of Lecture Notes in Computer Science, pages 175–188. Springer (2019). [15] Shi-Xin Zhang, Chang-Yu Hsieh, Shengyu Zhang, and Hong Yao. “Differentiable quan-tum architecture search”. Quantum Science and Technology 7, 045023 (2022). [16] Wenjie Wu, Ge Yan, Xudong Lu, Kaisen Pan, and Junchi Yan. “Quantumdarts: Dif-ferentiable quantum architecture search for variational quantum algorithms”. In Pro-ceedings of the 40th International Confer-ence on Machine Learning. Volume 202 of Proceedings of Machine Learning Research, pages 37745–37764. PMLR (2023). [17] Eric Jang, Shixiang Gu, and Ben Poole. “Categorical reparameterization with Gumbel-Softmax”. In International Conference on Learning Representa-tions (ICLR). (2017). url: https: //openreview.net/forum?id=rkE3y85ee .[18] Chris J. Maddison, Andriy Mnih, and Yee Whye Teh. “The concrete distribu-tion: A continuous relaxation of discrete random variables”. In International Confer-ence on Learning Representations (ICLR). (2017). url: https://openreview.net/ forum?id=S1jE5L5gl .[19] Ryan Riegel, Alexander Gray, Francois Luus, Naweed Khan, Ndivhuwo Makondo, Ismail Yunus Akhalwaya, Haifeng Qian, Ronald Fagin, Francisco Barahona, Udit Sharma, Shajith Ikbal, Hima Karanam, Sumit Neelam, Ankita Likhyani, and San-tosh Srivastava. “Logical neural net-works” (2020). arXiv:2006.13155. [20] Hanxiao Liu, Karen Simonyan, and Yiming Yang. “DARTS: Differentiable architecture search” (2018). arXiv:1806.09055. 

16 [21] Ryan Babbush, Robbie King, Sergio Boixo, William Huggins, Tanuj Khattar, Guang Hao Low, Jarrod R McClean, Thomas O’Brien, and Nicholas C Ru-bin. “The grand challenge of quantum applications” (2025). 

17 Additional Differentiable Axioms 

Here we provide the mathematical forms for additional differentiable predicates T and their corre-sponding loss terms L that supplement the core axioms defined in Section 2.2. 

Entanglement: 

Used for de novo discovery of entangled states. 

• Predicate Tent : Based on the Von Neumann entropy S(ρA) of the reduced density matrix ρA for a bipartite split A|B.

Tent (U ) = 1 − exp( −kS (ρA(U ))) , (23) 

where S(ρA) = −Tr (ρA log 2 ρA) and k is a scaling factor. 

• Contradiction Lent :

Lent = 1 − T ent = exp( −kS (ρA)) . (24) 

This loss term is ≈ 1 for separable states ( S = 0 ) and → 0 for maximally entangled states. 

Robustness (Noise): 

Used for multi-objective, noise-aware optimization. 

• Predicate Enoisy : The average energy under a set of error channels N = {Nj }, representing a noise model. 

Enoisy = 1

|N | 

∑ 

> Nj∈N

⟨ψ|N † 

> j

HN j |ψ⟩, (25) 

where |ψ⟩ = U |0⟩.

• Contradiction Lrob :

Lrob = Enoisy . (26) 

This loss term is used in a multi-objective function, e.g., Ltotal = wE Lenergy + wRLrob + wS Lsimp .

18 Supplementary Experiments 

S1: Robust VQE Ansatz Discovery with Annealing Curriculum 

We applied the DLP framework to the nontrivial problem of finding the ground state for a 4-qubit 1D Ising model. This task is a common benchmark for Variational Quantum Eigensolvers (VQE) because the energy landscape contains a local minimum at E = −4.0 (a simple product state) that can trap gradient-based optimizers, preventing them from reaching the entangled ground state at E ≈ − 4.73 .Our goal was to show that the framework can search this energy landscape and identify a simpler, noise-aware ansatz structure by pruning unnecessary gates from a generic hardware-efficient template. The experiment utilized a scaffold composed of a standard hardware-efficient ansatz (HEA) layer, in-cluding parameterized Ry(θ) and Rz (ϕ) rotation gates and a chain of entangling CN OT operations. To overcome the local minima problem, we employed the Annealing Curriculum strategy (Section 3.8). In-stead of optimizing for the full Hamiltonian H immediately, we trained the model on a time-dependent Hamiltonian H(t), where the interaction term J was slowly ramped from 0 to 1.0 over 8, 000 epochs, see Figure 15 (c). To further test robustness, we injected Gaussian noise ( σ = 0 .1) into the energy evaluation at every step. The optimization was driven by a composite loss function L = Lenergy + wsimp Lsimp , which balanced the minimization of energy with a penalty for circuit complexity. 

Results. As the annealing schedule progressed (epochs 0−8000 ), the system successfully escaped the 

E = −4.0 trap, converging to an energy of E ≈ − 4.83 , which fluctuates around the theoretical ground state of −4.73 due to the injected noise. The structural learning (Fig. 15 (c)) reveals a physically intuitive result: the optimizer systematically pruned the Rz gates (driving their probabilities si → 0)while retaining the Ry and CN OT gates. This indicates the model correctly identified that for this real-valued Hamiltonian, Z-rotations were redundant, thereby autonomously simplifying the ansatz to its most efficient form without human intervention. 

S2: QAOA Depth Discovery 

While the main text focuses on circuit discovery and pruning in fixed scaffolds, this experiment isolates the framework’s ability to tune a discrete hyperparameter: circuit depth. We tasked the model with finding the minimal QAOA (Quantum Approximate Optimization Algo-rithm) depth for a 4-node MaxCut instance, initializing a scaffold with pmax = 3 layers, 

S = [ UC (γ1), U B (β1), . . . , U C (γ3), U B (β3)] .

Using a Two-Phase Curriculum: (1) we first optimized angles for energy with wsimp = 0 , and then (2) applied simplicity pressure with wsimp > 0 to encourage pruning. The optimizer converged to si ≈ 0

for the final ( p = 3 ) layer, indicating that a reduced depth of p = 2 is sufficient for this problem. 

19 (a) Input Scaffold (b) Optimized Scaffold ( σ = 0 .1)q0

## q1

## q2

## q3

> 0

RY

> 0

RY

> 0

RY

> 0

RY

> 0

RZ

> 0

RZ

> 0

RZ

> 0

RZq0

q1

q2

q3

> 1.57

RY

> 2.06

RY

> 2.09

RY

> 2.06

RY0 2000 4000 6000 8000 10000 

Epochs 

> 0.0
> 0.1
> 0.2
> 0.3
> 0.4
> 0.5
> Gate Probability ( si)

Pruning of Rz Gates over Training (Annealing + Noise) 

> Rz(q0)
> Rz(q1)
> Rz(q2)
> Rz(q3)

Figure 15: VQE Discovery Results. (a) The input scaffold represents a standard, over-parameterized ansatz. (b) 

The final circuit structure autonomously discovered by the model. Note that the Rz gates have been removed, leaving a minimal structure of Ry rotations and entangling CN OT s. (c) The evolution of the gate switch probabilities ( si)for the Rz gates. As the curriculum introduces the interaction term J (epochs 0 − 8000 ) and the simplicity weight 

wsimp increases (epoch 8000+ ), the model decisively prunes these redundant operations, converging to a sparse topology while maintaining the ground state energy. 

20