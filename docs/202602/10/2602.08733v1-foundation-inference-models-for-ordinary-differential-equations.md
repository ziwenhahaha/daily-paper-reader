---
title: Foundation Inference Models for Ordinary Differential Equations
title_zh: 常微分方程的基础推理模型
authors: "Maximilian Mauel, Johannes R. Hübers, David Berghaus, Patrick Seifner, Ramses J. Sanchez"
date: 2026-02-09
pdf: "https://arxiv.org/pdf/2602.08733v1"
tags: ["keyword:SR", "query:SR"]
score: 8.0
evidence: 在ODE推断任务中直接与符号回归进行对比
tldr: 针对从噪声轨迹中推断常微分方程（ODE）向量场的难题，本文提出了 FIM-ODE。这是一种预训练的基础推理模型，通过在低阶多项式向量场分布上进行预训练，实现了仅需单次前向传播即可从噪声数据中直接预测向量场。FIM-ODE 在零样本任务中表现优异，且通过微调能快速适应复杂系统，在性能和效率上均优于传统的符号回归和神经 ODE 方法。
motivation: 现有的 ODE 推断方法如符号回归或神经 ODE 通常需要复杂的训练流程或深厚的专业知识，且对系统先验依赖性强。
method: 提出 FIM-ODE 模型，利用神经算子在低阶多项式 ODE 先验分布上进行预训练，实现从噪声轨迹到向量场的直接映射。
result: FIM-ODE 在零样本测试中达到或超过了 ODEFormer 等基准，且微调后的性能显著优于现代神经和高斯过程基准。
conclusion: FIM-ODE 证明了基础模型在低维 ODE 推断中的有效性，为科学建模提供了一种无需复杂调优的高效、稳定工具。
---

## 摘要
常微分方程（ODEs）是科学建模的核心，但从含噪声的轨迹中推断其向量场仍然具有挑战性。目前的方法，如符号回归、高斯过程（GP）回归和神经常微分方程（Neural ODEs），通常需要复杂的训练流程和大量的机器学习专业知识，或者强烈依赖于特定系统的先验知识。我们提出了 FIM-ODE，这是一种预训练的基础推理模型，它通过在单次前向传递中直接从含噪声的轨迹数据预测向量场，从而实现了低维 ODE 推理的摊销。我们在具有低阶多项式向量场的 ODE 先验分布上预训练 FIM-ODE，并使用神经算子表示目标场。FIM-ODE 展现了强大的零样本性能，在多种场景下，尽管使用了更简单的预训练先验分布，其表现仍能与最近的预训练符号基准模型 ODEFormer 持平，且往往更优。预训练还为微调提供了强大的初始化，实现了快速且稳定的自适应，在无需机器学习专业知识的情况下，其性能优于现代神经和 GP 基准模型。

## Abstract
Ordinary differential equations (ODEs) are central to scientific modelling, but inferring their vector fields from noisy trajectories remains challenging. Current approaches such as symbolic regression, Gaussian process (GP) regression, and Neural ODEs often require complex training pipelines and substantial machine learning expertise, or they depend strongly on system-specific prior knowledge. We propose FIM-ODE, a pretrained Foundation Inference Model that amortises low-dimensional ODE inference by predicting the vector field directly from noisy trajectory data in a single forward pass. We pretrain FIM-ODE on a prior distribution over ODEs with low-degree polynomial vector fields and represent the target field with neural operators. FIM-ODE achieves strong zero-shot performance, matching and often improving upon ODEFormer, a recent pretrained symbolic baseline, across a range of regimes despite using a simpler pretraining prior distribution. Pretraining also provides a strong initialisation for finetuning, enabling fast and stable adaptation that outperforms modern neural and GP baselines without requiring machine learning expertise.

---

## 论文详细总结（自动生成）

以下是对论文《Foundation Inference Models for Ordinary Differential Equations》的结构化深入总结：

### 1. 核心问题与整体含义
*   **研究背景**：常微分方程（ODE）是科学建模的基础。从观测到的噪声轨迹中推断底层的向量场（Vector Field）是系统识别的核心任务。
*   **核心问题**：传统方法（如符号回归、高斯过程、神经ODE）存在三大痛点：1) 训练流程复杂，需要针对每个数据集重复优化；2) 对机器学习专业知识要求高；3) 强依赖于系统特定的先验知识。
*   **整体含义**：本文提出了 **FIM-ODE**，这是一种“基础推理模型”（Foundation Inference Model）。其核心逻辑是将推理成本从重复的在线优化转移到离线的预训练阶段。预训练完成后，模型仅需一次前向传播（Single Forward Pass）即可从含噪声的轨迹中直接预测向量场，实现了推理过程的“摊销”（Amortization）。

### 2. 方法论
*   **核心思想**：利用神经算子（Neural Operators）学习一个通用的推理算法，该算法能将离散、含噪声的观测序列映射为连续的向量场函数。
*   **关键技术细节**：
    *   **预训练先验**：在 1-3 维空间内生成大量具有低阶（最高3阶）多项式向量场的 ODE 系统。这种选择基于“简单规则生成复杂模式”的直觉。
    *   **输入表示**：不直接输入原始轨迹，而是构造“转换特征”（Transition Features），包括当前状态 $y_i$、位移 $\Delta y_i$、平方位移 $\Delta y_i^2$ 和时间间隔 $\Delta \tau_i$。
    *   **架构设计**：采用 Encoder-Decoder 结构。
        *   **Encoder**：使用自注意力机制处理不规则采样的多条轨迹，生成置换不变的上下文表示。
        *   **Decoder**：功能性注意力解码器，通过交叉注意力查询任意空间位置 $x$，输出该点的向量场估计 $\hat{f}(x)$。
    *   **归一化**：引入可逆实例归一化（Spatial）和时间对数中心化（Temporal），使模型具备尺度不变性。
    *   **损失函数**：采用带不确定性权重的 L1 损失（基于拉普拉斯似然），同时预测向量场和预测的不确定性，以平衡不同流速区域的贡献。

### 3. 实验设计
*   **数据集/场景**：
    1.  **ODEBench**：包含 61 个经典 ODE 系统（如 Lorenz 吸引子、Van der Pol 振子），涉及非多项式（三角、指数）函数。
    2.  **低数据量 OOD 场景**：Van der Pol (VDP) 和 FitzHugh-Nagumo (FHN) 振子，测试极短轨迹下的预测能力。
    3.  **真实世界数据**：CMU 人体动作捕捉（MoCap）数据库，处理高维投影后的行走和跑步轨迹。
*   **Benchmark 与对比方法**：
    *   **主要基准**：**ODEFormer**（目前最先进的基于 Transformer 的符号回归基础模型）。
    *   **经典方法**：NeuralODE、GPODE、npODE、LatentSDE、GP-DNF、BNeuralODE 等。

### 4. 资源与算力
*   **模型规模**：总参数量约 1300 万（13M），其中 FIM-ODE 核心占 8M，不确定性头部占 5M。
*   **算力消耗**：使用 **4 张 NVIDIA A40 GPU**（每张 48GB 显存），训练时长约为 **5 天**。
*   **预训练规模**：在 60 万个合成多项式 ODE 系统上进行训练。

### 5. 实验数量与充分性
*   **实验规模**：
    *   预训练使用了 60 万组系统，验证集占 10%。
    *   在 ODEBench 上进行了多种噪声水平（$\sigma=0, 0.03, 0.05$）和采样率（$\rho=0, 0.5$）的组合测试。
    *   针对噪声敏感性，在 VDP 和 FHN 任务上重复了 **100 次独立试验**并统计分布。
*   **充分性评价**：实验设计非常充分且客观。不仅对比了零样本（Zero-shot）性能，还探讨了微调（Finetuning）的效果；不仅在合成数据上测试，还跨越到了非多项式系统和真实人体动作数据，验证了模型的泛化边界。

### 6. 主要结论与发现
*   **局部表示的优越性**：FIM-ODE 采用的局部神经算子表示在轨迹重建任务上显著优于 ODEFormer 的全局符号表示，尤其是在处理非多项式系统时。
*   **规模效率**：FIM-ODE 的参数量仅为 ODEFormer 的 1/10，预训练数据量仅为其 1/80，但性能持平甚至更优。
*   **微调的价值**：在极低数据量或严重分布偏移（如人体动作）的情况下，预训练模型提供了极佳的初始化，通过少量微调即可超越所有从头训练的经典基准模型。
*   **简单先验的泛化力**：仅在 3 阶多项式上训练的模型，能够成功推断包含三角函数和分式函数的复杂系统。

### 7. 优点
*   **推理极速**：无需迭代优化，单次前向传播即可获得向量场。
*   **鲁棒性强**：天然支持不规则采样、多轨迹输入和高噪声环境。
*   **易用性高**：为非机器学习专家提供了开箱即用的工具，避免了 Neural ODE 训练中常见的数值不稳定问题。
*   **灵活性**：相比符号回归，它不强求全局解析式，能更好地拟合局部复杂的动力学。

### 8. 不足与局限
*   **维度限制**：目前仅支持最高 3 维系统。由于多项式先验在高维下容易出现数值爆炸（非平稳性），扩展到更高维度存在挑战。
*   **架构硬编码**：最大状态维度在设计时是固定的，缺乏处理任意维度输入的灵活性（未来需引入轴向注意力机制）。
*   **先验偏差**：在极度偏离多项式特征的区域（如具有保守几何结构的单摆），零样本预测可能会引入向原点收缩的偏差。

（完）
