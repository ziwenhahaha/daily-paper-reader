---
title: Enhancing Generalization in Evolutionary Feature Construction for Symbolic Regression through Vicinal Jensen Gap Minimization
title_zh: 通过邻域 Jensen 间隙最小化增强符号回归中演化特征构建的泛化能力
authors: "Hengzhe Zhang, Qi Chen, Bing Xue, Wolfgang Banzhaf, Mengjie Zhang"
date: 2026-02-02
pdf: "https://arxiv.org/pdf/2602.01510v1"
tags: ["keyword:SR", "query:SR"]
score: 10.0
evidence: 基于遗传规划的符号回归特征构建与泛化研究
tldr: 针对符号回归中遗传编程特征构造的过拟合问题，本文提出一种基于邻域Jensen间隙最小化的进化框架。研究证明了邻域风险可分解为经验风险与正则项之和，并据此设计了动态噪声估计和流形侵入检测机制。实验表明，该方法在58个数据集上优于15种主流算法，显著提升了模型的泛化能力。
motivation: 遗传编程在特征构造中容易出现过拟合，限制了其在自动化机器学习中的广泛应用。
method: 提出一种联合优化经验风险与邻域Jensen间隙的进化框架，并引入噪声估计和流形侵入检测机制。
result: 在58个数据集上的实验证明，该方法在泛化性能上优于其他复杂性度量指标及15种主流机器学习算法。
conclusion: 通过最小化邻域Jensen间隙并结合动态正则化策略，可以有效控制符号回归特征构造中的过拟合，提升模型泛化性。
---

## 摘要
近年来，基于遗传编程的特征构建作为一种增强学习性能的自动机器学习技术取得了显著成功。然而，过拟合仍然是限制其更广泛应用的一个挑战。为了提高泛化能力，我们证明了通过噪声扰动或基于 mixup 的数据增强所估计的邻域风险，其上界由经验风险与正则化项（有限差分或邻域 Jensen 间隙）之和构成。利用这一分解，我们提出了一种演化特征构建框架，通过联合优化经验风险和邻域 Jensen 间隙来控制过拟合。由于不同数据集的噪声水平可能有所不同，我们开发了一种噪声估计策略来动态调整正则化强度。此外，为了减轻流形侵入（即数据增强可能生成超出数据流形的不真实样本）的影响，我们提出了一种流形侵入检测机制。在 58 个数据集上的实验结果表明，与其它复杂度度量相比，Jensen 间隙最小化具有显著的有效性。与 15 种机器学习算法的对比进一步表明，采用所提过拟合控制策略的遗传编程实现了优越的性能。

## Abstract
Genetic programming-based feature construction has achieved significant success in recent years as an automated machine learning technique to enhance learning performance. However, overfitting remains a challenge that limits its broader applicability. To improve generalization, we prove that vicinal risk, estimated through noise perturbation or mixup-based data augmentation, is bounded by the sum of empirical risk and a regularization term-either finite difference or the vicinal Jensen gap. Leveraging this decomposition, we propose an evolutionary feature construction framework that jointly optimizes empirical risk and the vicinal Jensen gap to control overfitting. Since datasets may vary in noise levels, we develop a noise estimation strategy to dynamically adjust regularization strength. Furthermore, to mitigate manifold intrusion-where data augmentation may generate unrealistic samples that fall outside the data manifold-we propose a manifold intrusion detection mechanism. Experimental results on 58 datasets demonstrate the effectiveness of Jensen gap minimization compared to other complexity measures. Comparisons with 15 machine learning algorithms further indicate that genetic programming with the proposed overfitting control strategy achieves superior performance.