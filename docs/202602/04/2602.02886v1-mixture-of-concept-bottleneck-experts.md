---
title: Mixture of Concept Bottleneck Experts
title_zh: 概念瓶颈专家混合
authors: "Francesco De Santis, Gabriele Ciravegna, Giovanni De Felice, Arianna Casanova, Francesco Giannini, Michelangelo Diligenti, Mateo Espinosa Zarlenga, Pietro Barbiero, Johannes Schneider, Danilo Giordano"
date: 2026-02-02
pdf: "https://arxiv.org/pdf/2602.02886v1"
tags: ["keyword:SR", "query:SR"]
score: 10.0
evidence: 利用符号回归发现专家函数
tldr: 本研究针对概念瓶颈模型（CBM）预测器形式单一、准确性与适应性受限的问题，提出了概念瓶颈专家混合（M-CBE）框架。该框架通过增加专家数量并引入多样化的函数形式（如线性专家和基于符号回归的专家），扩展了 CBM 的设计空间。实验证明，M-CBE 能在保持可解释性的同时，通过灵活调整专家配置，有效优化预测性能并满足不同用户的需求。
motivation: 传统 CBM 仅使用单一的线性或布尔表达式作为预测器，限制了模型的预测精度和对复杂任务的适应能力。
method: 提出 M-CBE 框架，通过引入多个专家模型及符号回归等多样化函数形式，增强了概念到预测的映射能力。
result: 实验结果显示，改变专家混合规模和函数形式可以显著提升模型在准确性与可解释性权衡中的表现。
conclusion: M-CBE 框架为构建兼具高性能和高可解释性的深度学习模型提供了一种灵活且有效的通用方案。
---

## 摘要
概念瓶颈模型 (CBMs) 通过将预测建立在人类可理解的概念之上来提升可解释性。然而，现有的 CBMs 通常将其任务预测器固定为单一的线性或布尔表达式，这限制了预测准确性以及对多样化用户需求的适应性。我们提出了概念瓶颈专家混合 (M-CBEs)，这是一个在两个维度上对现有 CBMs 进行泛化的框架：专家数量和每个专家的函数形式，从而揭示了设计空间中一个尚未被充分探索的领域。我们通过实例化两个新模型来研究这一领域：线性 M-CBE（学习有限的线性表达式集合）和符号 M-CBE（利用符号回归在用户指定的算子词汇表下从数据中发现专家函数）。实证评估表明，改变混合规模和函数形式为权衡准确性与可解释性提供了一个稳健的框架，能够适应不同的用户和任务需求。

## Abstract
Concept Bottleneck Models (CBMs) promote interpretability by grounding predictions in human-understandable concepts. However, existing CBMs typically fix their task predictor to a single linear or Boolean expression, limiting both predictive accuracy and adaptability to diverse user needs. We propose Mixture of Concept Bottleneck Experts (M-CBEs), a framework that generalizes existing CBMs along two dimensions: the number of experts and the functional form of each expert, exposing an underexplored region of the design space. We investigate this region by instantiating two novel models: Linear M-CBE, which learns a finite set of linear expressions, and Symbolic M-CBE, which leverages symbolic regression to discover expert functions from data under user-specified operator vocabularies. Empirical evaluation demonstrates that varying the mixture size and functional form provides a robust framework for navigating the accuracy-interpretability trade-off, adapting to different user and task needs.

---

## 论文详细总结（自动生成）

这是一份关于论文《Mixture of Concept Bottleneck Experts》（概念瓶颈专家混合）的深度结构化总结：

### 1. 核心问题与整体含义（研究动机和背景）
*   **研究动机**：现有的概念瓶颈模型（CBMs）虽然通过“输入 $\to$ 概念 $\to$ 预测”的二阶段架构提升了可解释性，但其**任务预测器**通常被限制为单一的线性或布尔表达式。这种“一刀切”的设计限制了模型的表达能力（准确率低），且无法适应不同用户对可解释性的个性化需求（如某些用户偏好代数公式，某些偏好逻辑规则）。
*   **核心问题**：如何在保持语义透明度的同时，提升 CBM 预测器的灵活性和准确性？
*   **整体含义**：论文提出了 **M-CBE** 框架，通过引入“专家混合（MoE）”机制，允许模型根据输入动态选择不同的预测函数（专家），并支持自定义函数的数学形式。

### 2. 方法论：核心思想与关键技术
*   **核心思想**：将任务预测器建模为多个“专家”的混合，每个专家是一个基于概念的数学表达式树。通过一个“选择器（Selector）”网络，根据输入特征 $x$ 将样本路由至最合适的专家。
*   **关键技术细节**：
    *   **概率图模型**：联合分布分解为 $p(x, c, t, y) = p(x)p(c|x)p(t|x)p(y|c,t)$。其中 $p(c|x)$ 是概念编码器，$p(t|x)$ 是专家选择器，$p(y|c,t)$ 是基于选定表达式树 $t$ 的任务预测器。
    *   **表达式树（Expression Trees）**：将函数抽象为由算子（如 $+$, $\times$, $\sin$）、变量（概念）和参数组成的图结构。
    *   **两种实例化模型**：
        1.  **Linear M-CBE (Lin-M-CBE)**：学习一组有限的线性表达式，适用于高维概念空间。
        2.  **Symbolic M-CBE (Sym-M-CBE)**：利用**符号回归（Symbolic Regression）**自动从数据中发现复杂的非线性公式。
*   **算法流程（Sym-M-CBE 三阶段训练）**：
    1.  **联合训练**：同时训练概念编码器、选择器和作为占位符的 MLP 专家。
    2.  **符号蒸馏**：利用 PySR 算法，将每个 MLP 专家蒸馏为符合用户定义算子集（如 $\{+, -, \times, \exp\}$）的符号表达式。
    3.  **端到端微调**：替换占位符为符号公式，微调公式参数及前端网络。

### 3. 实验设计
*   **数据集**：
    *   **合成数据**：MNIST-Arith（算术运算）、dSprites-Exp（指数函数）、Pendulum（单摆物理位置）。
    *   **真实数据**：MAWPS（数学应用题）、AWA2（动物分类）、CUB-200（鸟类分类）、CIFAR-10（标签缺失场景）。
*   **Benchmark 与对比方法**：
    *   **基础 CBM**：标准线性 CBM。
    *   **先进变体**：CEM（概念嵌入）、DCR/LICEM（局部解释模型）、CMR（布尔逻辑存储模型）。
    *   **上限**：纯黑盒 DNN。
*   **评估指标**：准确率/MAE（性能）、节点数/深度（复杂性）、干预响应（Intervenability）。

### 4. 资源与算力
*   **算力说明**：论文提到使用了 PyTorch Lightning 框架和 AdamW 优化器。
*   **具体细节**：文中**未明确给出**具体的 GPU 型号、数量或总训练时长。但提到符号回归阶段使用了 PySR，配置为 40 个种群、每个种群 60 个个体，进化 100 代，这通常属于计算密集型任务。

### 5. 实验数量与充分性
*   **实验规模**：涵盖了 9 个不同性质的数据集（分类 vs 回归，合成 vs 真实），每组实验均基于 5 个随机种子取平均值并提供 95% 置信区间。
*   **充分性**：
    *   **消融实验**：对比了不同专家数量（M=1 到 5）的影响。
    *   **鲁棒性分析**：测试了在概念缺失（Incomplete）情况下的表现。
    *   **对比分析**：专门对比了符号回归工具（PySR vs KAN）。
    *   **干预实验**：验证了当人类修正概念预测时，模型性能的提升幅度。
*   **评价**：实验设计非常全面，涵盖了从预测性能到可解释性度量的多个维度，论证较为客观公平。

### 6. 主要结论与发现
*   **帕累托最优**：M-CBE 成功探索了“准确性-可解释性”权衡的新边界，在多个任务中以极低的复杂度达到了黑盒模型的精度。
*   **代数形式的优越性**：在处理高维概念（如 CUB-200 有 112 个概念）时，线性或代数专家比传统的布尔逻辑规则准确率高出多达 65%。
*   **多专家的必要性**：当任务逻辑随输入变化（如 MAWPS）或概念集不完整时，多个专家能显著补偿单一模型的性能损失。
*   **事后适配性**：Sym-M-CBE 允许用户在不重新训练编码器的情况下，通过更换算子库来生成不同风格的解释。

### 7. 优点（亮点）
*   **设计空间泛化**：首次系统性地提出了“专家数量”和“函数形式”两个维度的 CBM 设计平面。
*   **符号回归集成**：将符号回归引入 CBM，使模型能够发现底层的物理定律或数学逻辑（如在 Pendulum 任务中找回了 $\sin$ 函数）。
*   **全局可解释性**：与每条样本产生一个解释的局部模型不同，M-CBE 提供有限个可检查的全局公式，更符合人类审计需求。

### 8. 不足与局限
*   **选择器黑盒化**：虽然专家函数是透明的，但决定“哪个样本去哪个专家”的选择器网络仍然是一个黑盒，用户难以理解路由逻辑。
*   **计算开销**：符号回归（SR）阶段搜索空间巨大，对于极大规模的概念集或复杂的算子库，计算成本较高。
*   **超参数敏感**：专家数量 $M$ 需要预先指定，缺乏自动确定最优专家数的机制。
*   **干预依赖**：模型性能高度依赖概念编码器的质量，若概念预测完全错误，复杂的专家函数也难以挽救。

（完）
