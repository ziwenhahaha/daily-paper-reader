---
title: "SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving"
title_zh: SymPlex：一种用于符号偏微分方程求解的结构感知 Transformer
authors: "Yesom Park, Annie C. Lu, Shao-Ching Huang, Qiyang Hu, Y. Sungtaek Ju, Stanley Osher"
date: 2026-02-03
pdf: "https://arxiv.org/pdf/2602.03816v1"
tags: ["keyword:SR", "query:SR"]
score: 10.0
evidence: 直接探讨了使用结构感知Transformer和强化学习进行偏微分方程的符号求解。
tldr: SymPlex 是一个利用强化学习发现偏微分方程（PDE）解析符号解的框架，无需真实表达式作为监督。其核心是 SymFormer，一种结构感知 Transformer，通过树状相对自注意力和语法约束解码来建模符号依赖并确保语法正确。该方法直接在符号表达式空间操作，能生成可解释、可处理非平滑行为及参数依赖的解，实现了对复杂 PDE 精确符号解的自动发现。
motivation: 传统的数值和神经求解器缺乏可解释性，且难以处理非平滑行为或显式参数依赖，因此需要一种能直接生成符号解析解的方法。
method: 提出 SymPlex 框架，利用强化学习优化由 SymFormer 生成的树状结构候选解，并通过语法约束确保表达式的合法性。
result: 实验证明该方法仅凭 PDE 方程和边界条件即可精确还原非平滑及含参数 PDE 的符号解。
conclusion: SymPlex 证明了深度学习符号化方法在求解 PDE 方面的潜力，为获取高可解释性和精确性的数学解提供了新途径。
---

## 摘要
我们提出了 SymPlex，这是一个强化学习框架，用于在无法获取真值表达式的情况下发现偏微分方程（PDE）的解析符号解。SymPlex 将符号 PDE 求解建模为树状结构决策，并仅利用 PDE 及其边界条件来优化候选解。其核心是 SymFormer，这是一种结构感知 Transformer，它通过树相对自注意力（tree-relative self-attention）对层级符号依赖进行建模，并通过语法约束的自回归解码来强制执行语法有效性，从而克服了基于序列的生成器表达能力有限的问题。与在离散或隐式函数空间中逼近解的数值和神经方法不同，SymPlex 直接在符号表达式空间中运行，从而能够生成可解释且人类可读的解，这些解能够自然地表示非光滑行为和显式参数依赖。实验结果表明，使用基于深度学习的符号方法可以精确恢复非光滑和参数化 PDE 的解。

## Abstract
We propose SymPlex, a reinforcement learning framework for discovering analytical symbolic solutions to partial differential equations (PDEs) without access to ground-truth expressions. SymPlex formulates symbolic PDE solving as tree-structured decision-making and optimizes candidate solutions using only the PDE and its boundary conditions. At its core is SymFormer, a structure-aware Transformer that models hierarchical symbolic dependencies via tree-relative self-attention and enforces syntactic validity through grammar-constrained autoregressive decoding, overcoming the limited expressivity of sequence-based generators. Unlike numerical and neural approaches that approximate solutions in discretized or implicit function spaces, SymPlex operates directly in symbolic expression space, enabling interpretable and human-readable solutions that naturally represent non-smooth behavior and explicit parametric dependence. Empirical results demonstrate exact recovery of non-smooth and parametric PDE solutions using deep learning-based symbolic methods.

---

## 论文详细总结（自动生成）

### 论文总结：SymPlex —— 用于符号偏微分方程求解的结构感知 Transformer

#### 1. 核心问题与整体含义（研究动机和背景）
偏微分方程（PDE）的解析解在科学和工程中至关重要，因为它们提供精确的物理描述、直接的可解释性以及对参数依赖的显式表达。然而，传统的数值方法（如有限差分、有限元）存在离散化误差和数值扩散；神经方法（如 PINNs）虽然灵活，但缺乏可解释性且难以处理非平滑行为。
论文的核心问题是：**如何在没有真值表达式（Ground-truth）作为监督的情况下，自动发现 PDE 的精确符号解析解？** 这是一个离散组合搜索问题，挑战在于符号表达式的树状结构约束以及学习信号的稀疏性（仅能通过 PDE 残差评价）。

#### 2. 方法论：核心思想与关键技术
SymPlex 框架将符号 PDE 求解建模为树状结构的强化学习（RL）决策过程。
*   **SymFormer（结构感知 Transformer）：** 
    *   **树相对自注意力（Tree-Relative Self-Attention）：** 不同于标准 Transformer 处理线性序列，SymFormer 根据抽象语法树（AST）定义节点间的关系（父子、兄弟、祖先等），并将其编码为注意力偏置，使模型能捕捉层级依赖。
    *   **语法约束解码：** 在自回归生成过程中，根据算子的元数（Arity）动态限制可选 Token，确保生成的表达式在数学语法上始终合法。
*   **强化学习框架：**
    *   **奖励机制：** 奖励函数基于 PDE 残差、边界条件（BC）和初始条件（IC）的 $L_2$ 范数。公式定义为 $R = 1 / (1 + \sqrt{Loss})$。
    *   **常数优化：** 在评估奖励前，利用 Adam 优化器对表达式中的连续常数进行梯度下降微调，使离散结构搜索与连续参数拟合解耦。
    *   **多样性感知 Top-k 记忆库：** 存储高奖励解，并通过结构（编辑距离）和语义（数值评估差异）双重过滤确保探索的多样性。
*   **课程学习（Curriculum Learning）：** 分三个阶段训练：1. 仅空间变量；2. 全时空 PDE（固定参数）；3. 包含物理系数的参数化解。

#### 3. 实验设计
*   **测试场景：** 涵盖了三类 PDE 问题：
    1.  **平滑解问题：** 泊松方程（Poisson）、平流方程（Advection）、热传导方程（Heat）。
    2.  **非平滑解问题：** Eikonal 方程、Burgers 方程（包含激波或转折点）。
    3.  **参数化解问题：** 物理系数（如扩散系数 $\kappa$）作为符号变量参与求解。
*   **Benchmark 与对比方法：**
    *   **SSDE：** 基于 RNN 的符号 PDE 求解器。
    *   **FEX：** 确定性树搜索方法。
    *   **PINN+DSR：** 先训练 PINN 再用深度符号回归拟合。
    *   **KAN：** 基于 Kolmogorov-Arnold 网络的符号化方法。
    *   **传统数值方法：** 如 WENO 格式（用于对比非平滑解的精度）。

#### 4. 资源与算力
*   **硬件：** 实验在单台 **NVIDIA GV100 (TITAN V)** GPU 上完成。
*   **训练细节：** 每个阶段最大 500 个 Epoch，若奖励超过 0.99 则提前跳入下一阶段。每次迭代采样 64 个序列。
*   **耗时：** 论文提到虽然训练时间（约 642 秒）长于数值方法，但推理时间极快（微秒级），且存储空间极小（仅需存储简短字符串）。

#### 5. 实验数量与充分性
*   **实验规模：** 针对 7 种以上的不同 PDE 进行了测试，每种方法运行了 **20 个不同的随机种子**以确保结果的统计显著性。
*   **充分性：** 实验不仅对比了符号回归基准，还跨领域对比了数值方法（WENO）和神经方法（PINN），并进行了消融实验（如课程学习的有效性验证）。实验设计客观、公平，涵盖了从简单线性到复杂非线性、从连续到不连续的多种情况。

#### 6. 主要结论与发现
*   **精确恢复：** SymPlex 在所有测试的 PDE 中均实现了 **100% 的符号恢复率（SRR）**，能够找到与解析解完全一致的数学表达式。
*   **处理非平滑性：** 在处理 Burgers 和 Eikonal 方程的转折点时，符号解完全没有数值扩散或震荡，误差为 0，显著优于 WENO 和 PINN。
*   **参数化泛化：** SymPlex 能够发现包含物理参数（如 $\kappa$）的通用解，这意味着一次训练即可得到适用于不同物理环境的解析公式。

#### 7. 优点
*   **结构感知：** SymFormer 显式建模数学树结构，比传统的序列 RNN 或标准 Transformer 更适合处理复杂的嵌套数学公式。
*   **无监督发现：** 仅依赖物理方程本身，无需任何预先生成的真值数据。
*   **高效率推理：** 得到的符号解在推理时比数值格式快几个数量级，且极度节省内存（仅需几个字节存储表达式）。

#### 8. 不足与局限
*   **搜索空间爆炸：** 尽管有课程学习，但在处理极高维（如 10 维以上）或极其复杂的复合函数时，组合搜索空间依然面临巨大挑战。
*   **词汇表依赖：** 求解效果高度依赖于预设的算子库（如是否包含 $\sin, \exp$ 等），如果解包含库之外的特殊函数，则无法精确恢复。
*   **训练成本：** 相比于成熟的数值求解器，其 RL 训练过程仍然相对耗时且对超参数敏感。

（完）
