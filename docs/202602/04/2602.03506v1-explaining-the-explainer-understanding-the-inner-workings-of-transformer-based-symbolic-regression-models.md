---
title: "Explaining the Explainer: Understanding the Inner Workings of Transformer-based Symbolic Regression Models"
title_zh: 解释解释器：理解基于 Transformer 的符号回归模型的内部工作机制
authors: "Arco van Breda, Erman Acar"
date: 2026-02-03
pdf: "https://arxiv.org/pdf/2602.03506v1"
tags: ["keyword:SR", "query:SR"]
score: 10.0
evidence: 直接研究基于 Transformer 的符号回归和电路发现
tldr: 本研究探讨了基于Transformer的符号回归（SR）模型的内部工作机制。针对SR模型生成数学算子的原理尚不明确的问题，作者提出了PATCHES进化电路发现算法，成功识别出28个功能电路。通过因果评估框架验证，研究发现均值修补在识别正确电路方面优于传统的归因方法，为SR模型的机械可解释性研究提供了系统的方法论和新见解。
motivation: 尽管Transformer在符号回归中表现优异，但其内部生成数学算子的机械原理尚未得到深入探索。
method: 提出了一种名为PATCHES的进化电路发现算法，并结合基于忠实度、完整性和最小性的因果评估框架进行验证。
result: 成功分离出28个关键电路，并证明基于性能的均值修补在识别功能电路方面比直接对数归因更具因果可靠性。
conclusion: 该研究确立了符号回归作为机械可解释性研究的重要领域，并为发现和验证模型内部电路提供了原则性的方法。
---

## 摘要
继在多个领域取得成功之后，Transformer 在符号回归（SR）中也表现出了有效性；然而，其生成数学算子的底层内部机制在很大程度上仍未被探索。尽管机械可解释性（mechanistic interpretability）已成功识别出语言和视觉模型中的电路（circuits），但尚未应用于符号回归。在本文中，我们介绍了 PATCHES，这是一种进化电路发现算法，用于识别符号回归中紧凑且正确的电路。利用 PATCHES，我们分离出 28 个电路，首次提供了符号回归 Transformer 的电路级表征。我们通过一个基于忠实性（faithfulness）、完整性（completeness）和最小性（minimality）等关键概念的稳健因果评估框架验证了这些发现。我们的分析表明，结合基于性能评估的均值修补（mean patching）能最可靠地分离出功能正确的电路。相比之下，我们证明了直接 Logit 归因（direct logit attribution）和探测分类器（probing classifiers）主要捕捉的是相关性特征而非因果特征，从而限制了它们在电路发现中的效用。总的来说，这些结果确立了符号回归作为机械可解释性具有高潜力的应用领域，并提出了一种原则性的电路发现方法论。

## Abstract
Following their success across many domains, transformers have also proven effective for symbolic regression (SR); however, the internal mechanisms underlying their generation of mathematical operators remain largely unexplored. Although mechanistic interpretability has successfully identified circuits in language and vision models, it has not yet been applied to SR. In this article, we introduce PATCHES, an evolutionary circuit discovery algorithm that identifies compact and correct circuits for SR. Using PATCHES, we isolate 28 circuits, providing the first circuit-level characterisation of an SR transformer. We validate these findings through a robust causal evaluation framework based on key notions such as faithfulness, completeness, and minimality. Our analysis shows that mean patching with performance-based evaluation most reliably isolates functionally correct circuits. In contrast, we demonstrate that direct logit attribution and probing classifiers primarily capture correlational features rather than causal ones, limiting their utility for circuit discovery. Overall, these results establish SR as a high-potential application domain for mechanistic interpretability and propose a principled methodology for circuit discovery.

---

## 论文详细总结（自动生成）

这是一份关于论文《Explaining the Explainer: Understanding the Inner Workings of Transformer-based Symbolic Regression Models》的结构化深入总结。

---

### 1. 核心问题与整体含义
*   **研究动机**：符号回归（Symbolic Regression, SR）因其能生成显式数学公式而被视为“可解释 AI”的代表。然而，生成这些公式的底层 Transformer 模型本身却是一个“黑盒”。
*   **核心问题**：模型内部是如何决定生成特定数学算子（如 $\sin, \exp, +$）的？是否存在特定的神经元或注意力头组合（即“电路”）负责这些行为？
*   **整体含义**：本研究首次将**机械可解释性（Mechanistic Interpretability, MI）**引入符号回归领域，旨在通过逆向工程手段，识别并验证 Transformer 模型中负责生成数学算子的因果电路。

### 2. 方法论
论文提出了一套名为 **PATCHES** 的框架，包含以下核心环节：

*   **核心思想**：利用因果干预（激活修补）来识别模型中对特定输出起决定性作用的最小组件子集。
*   **关键技术 - PATCHES 算法**：
    *   **进化策略**：不同于传统的贪婪迭代搜索，PATCHES 采用 **CMA-ES（协方差矩阵自适应进化策略）**。它在所有模型组件（注意力头、MLP）上优化一个概率掩码，寻找最优的稀疏子图。
    *   **适应度函数**：$F(C) = |C| + \lambda \sum \max(0, T_i - S_i(C))$。该公式旨在平衡电路的**最小性**（电路大小 $|C|$）与**性能保持**（满足预设的性能阈值 $T_i$）。
*   **因果评估框架**：定义了三个严格的电路正确性标准：
    1.  **忠实性 (Faithfulness)**：仅保留电路组件时，模型能否维持原始行为。
    2.  **完整性 (Completeness)**：移除电路组件后，模型是否彻底丧失该行为。
    3.  **最小性 (Minimality)**：电路中是否不存在任何冗余组件。
*   **修补策略对比**：系统比较了**均值修补 (Mean Patching)**（用数据集均值替换激活）和**重采样修补 (Resample Patching)**（用干扰样本的激活替换）。

### 3. 实验设计
*   **分析对象**：**NeSymReS**（一种经典的基于 Transformer 编码器-解码器的符号回归模型）。
*   **数据集**：针对 8 种数学算子（add, mul, sin, cos, exp, log, pow, tan）分别构建了专用数据集。每个数据集包含 500 个样本（100 个用于电路发现，400 个用于泛化验证）。
*   **对比方法 (Baselines)**：
    *   **迭代修补 (Iterative Patching)**：传统的层级贪婪搜索方法。
    *   **直接 Logit 归因 (Direct Logit Attribution, DLA)**：基于单个组件对输出 Logit 贡献的排序方法。
    *   **探测分类器 (Probing)**：训练线性分类器检查组件是否包含特定信息。
*   **评估指标**：功能性指标（Top-k 准确率）与模型内部指标（归一化 Logit 分数）。

### 4. 资源与算力
*   **原模型训练**：NeSymReS 在 **RTX 2080 GPU** 上训练了 23 个 epoch，耗时约 **3 天**。
*   **电路发现 (PATCHES)**：算法运行 250 代，种群规模为 40。
*   **说明**：论文未详细列出 PATCHES 实验的具体总机时，但强调了均值修补比重采样修补在计算上更高效。

### 5. 实验数量与充分性
*   **实验规模**：
    *   针对 8 种算子在多种配置（修补方式 × 评估指标）下进行了实验，共识别出 **28 个电路**，其中 13 个完全符合所有因果标准。
    *   进行了**泛化性测试**，证明发现的电路在未见过的公式上依然有效。
    *   进行了**探测实验**（每种配置训练 200 个探测模型）以验证因果与相关的区别。
*   **充分性评价**：实验设计非常全面。作者不仅验证了单算子电路，还扩展到了**多标记电路**（如单项式和多项式函数类）。对比实验涵盖了目前 MI 领域的主流技术，论证过程客观、严谨。

### 6. 主要结论与发现
*   **成功分离电路**：首次证明了 SR Transformer 内部存在执行特定数学运算的模块化电路。
*   **方法论优劣**：**均值修补 + 功能评估（准确率）** 是识别正确电路最可靠的方法；而传统的 DLA 和探测（Probing）往往只能捕捉相关性，容易误导电路发现。
*   **算法优势**：PATCHES（基于进化策略）比传统的迭代修补能找到更小、更稳健的电路。
*   **电路特性**：SR 模型的电路相对密集（占模型组件的 40%-78%），这反映了符号回归任务中算子编码的高度复杂性和多语义性。

### 7. 优点
*   **开创性**：填补了符号回归模型机械可解释性研究的空白。
*   **工具创新**：引入进化算法（CMA-ES）解决电路发现中的全局优化问题，优于现有的贪婪搜索。
*   **评估严谨**：建立了一套标准化的因果评估流程，为后续研究提供了方法论参考。

### 8. 不足与局限
*   **模型局限性**：实验仅基于 NeSymReS 这一种架构，尚未在更大规模（如百亿参数）或不同变体（如纯解码器架构）的 SR 模型上验证。
*   **算子偏置**：对于数据集中出现频率极高的算子（如加法），修补技术难以完全“抹除”其特征，导致电路发现的完整性受限。
*   **多语义性挑战**：发现组件在不同电路间存在重叠，说明单个神经元/头可能负责多种功能，这增加了完全解耦的难度。

---
（完）
