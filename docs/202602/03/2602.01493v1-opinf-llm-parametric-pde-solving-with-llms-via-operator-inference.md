---
title: "OpInf-LLM: Parametric PDE Solving with LLMs via Operator Inference"
title_zh: OpInf-LLM：通过算子推断利用大语言模型求解参数化偏微分方程
authors: "Zhuoyuan Wang, Hanjiang Hu, Xiyu Deng, Saviz Mowlavi, Yorie Nakahira"
date: 2026-02-02
pdf: "https://arxiv.org/pdf/2602.01493v1"
tags: ["keyword:SR", "query:SR"]
score: 6.0
evidence: 基于大语言模型的偏微分方程符号推理求解
tldr: 本研究针对大语言模型（LLM）在求解异构偏微分方程（PDE）时面临的执行成功率与数值精度权衡难题，提出了OpInf-LLM框架。该框架将算子推理（Operator Inference）与LLM的自然语言处理能力相结合，仅需少量数据即可实现对未知参数和配置的精确预测。OpInf-LLM通过统一的工具接口降低了计算需求，显著提升了在复杂设置下的求解成功率，为通用化降阶建模提供了新路径。
motivation: 现有的基于LLM的PDE求解方法在处理未知参数和边界条件时，难以在代码执行成功率与数值计算精度之间取得平衡。
method: 提出一种结合算子推理与LLM能力的框架，利用少量样本数据和自然语言接口实现参数化PDE的降阶建模与求解。
result: 该框架在异构设置下实现了极高的执行成功率，并能对未见过的参数配置进行高精度的数值预测。
conclusion: OpInf-LLM证明了将算子推理集成到LLM工具链中，是实现高效、通用且可扩展的偏微分方程求解的有效途径。
---

## 摘要
求解各类偏微分方程（PDEs）是科学与工程领域的基础。大语言模型（LLMs）在代码生成、符号推理和工具使用方面展现出强大的能力，但在异构环境下可靠地求解偏微分方程仍具挑战性。先前关于基于 LLM 的代码生成和基于 Transformer 的 PDE 学习基础模型的研究已取得显著进展。然而，在执行成功率与数值精度之间存在持久的权衡，特别是在需要对未见参数和边界条件进行泛化时。在这项工作中，我们提出了 OpInf-LLM，这是一个基于算子推断的 LLM 参数化偏微分方程求解框架。该框架利用少量解数据，实现了对包括未见参数和配置在内的多种 PDE 实例的准确预测，并与 LLM 无缝集成，支持以自然语言规范化描述 PDE 求解任务。其低计算需求和统一的工具接口进一步确保了在异构环境下的高执行成功率。通过将算子推断与 LLM 的能力相结合，OpInf-LLM 为基于 LLM 的偏微分方程求解中的可泛化降阶建模开辟了新的可能性。

## Abstract
Solving diverse partial differential equations (PDEs) is fundamental in science and engineering. Large language models (LLMs) have demonstrated strong capabilities in code generation, symbolic reasoning, and tool use, but reliably solving PDEs across heterogeneous settings remains challenging. Prior work on LLM-based code generation and transformer-based foundation models for PDE learning has shown promising advances. However, a persistent trade-off between execution success rate and numerical accuracy arises, particularly when generalization to unseen parameters and boundary conditions is required. In this work, we propose OpInf-LLM, an LLM parametric PDE solving framework based on operator inference. The proposed framework leverages a small amount of solution data to enable accurate prediction of diverse PDE instances, including unseen parameters and configurations, and provides seamless integration with LLMs for natural language specification of PDE solving tasks. Its low computational demands and unified tool interface further enable a high execution success rate across heterogeneous settings. By combining operator inference with LLM capabilities, OpInf-LLM opens new possibilities for generalizable reduced-order modeling in LLM-based PDE solving.