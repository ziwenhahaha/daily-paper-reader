Title: Turning mechanistic models into forecasters by using machine learning

URL Source: https://arxiv.org/pdf/2602.04114v1

Published Time: Thu, 05 Feb 2026 01:22:43 GMT

Number of Pages: 47

Markdown Content:
# Turning mechanistic models into forecasters by using machine learning 

## Amit K. Chakraborty 1, Hao Wang 1,* , and Pouria Ramazi 2

> 1

Department of Mathematical and Statistical Sciences & Interdisciplinary Lab for Mathematical Ecology and Epidemiology (ILMEE), University of Alberta, AB, Canada 

> 2

Department of Biological Sciences & Department of Mathematics and Statistics, University of Calgary, AB, Canada 

> *

Corresponding author: hao8@ualberta.ca 

Abstract 

The equations of complex dynamical systems may not be identified by expert knowl-edge, especially if the underlying mechanisms are unknown. Data-driven discovery meth-ods address this challenge by inferring governing equations from time–series data using a library of functions constructed from the measured variables. However, these methods typically assume time-invariant coefficients, which limits their ability to capture evolving system dynamics. To overcome this limitation, we allow some of the parameters to vary over time, learn their temporal evolution directly from data, and infer a system of equa-tions that incorporates both constant and time-varying parameters. We then transform this framework into a forecasting model by predicting the time-varying parameters and substi-tuting these predictions into the learned equations. The model is validated using datasets for Susceptible–Infected–Recovered, Consumer–Resource, greenhouse gas concentration, and Cyanobacteria cell count. By dynamically adapting to temporal shifts, our proposed model achieved a mean absolute error below 3% for learning a time series and below 6% 

for forecasting up to a month ahead. We additionally compare forecasting performance against CNN–LSTM and Gradient Boosting Machine (GBM), and show that our model outperforms these methods across most datasets. Our findings demonstrate that integrating time-varying parameters into data-driven discovery of differential equations improves both modeling accuracy and forecasting performance. 

Keywords— data–driven dynamical systems, time-varying parameters, sparse regression, or-dinary differential equations, mechanistic forecasting, finite-horizon forecast error bounds, ma-chine learning 

AMS subject classifications— 37M05, 37N25, 65L20, 62M45, 92D30, 86A10 1

> arXiv:2602.04114v1 [cs.LG] 4 Feb 2026

# 1 Introduction 

Mechanistic models provide the causal and interpretable governing laws of a system, but many natural systems are too complex to be captured by expert knowledge [1–3]. For example, emissions of greenhouse gases, such as methane and carbon dioxide, are influenced by tem-perature, humidity, wind speed, and other weather variables [4, 5]. In epidemiology, disease incidence is shaped by environmental factors, population density, social behavior, and policy interventions [6–9]. The relationships among the variables in such a high-dimensional system are many, time variant, and unknown, making it nearly infeasible to be described by equations that are based on expert knowledge [10]. A promising alternative is data-driven discovery of the governing equation, often repre-sented as differential equations [11–14]. Unlike mechanistic modeling that relies on predefined assumptions, data-driven approaches adapt to the intrinsic structure of the system, capturing both linear and nonlinear interactions among the system’s variables [13]. A widely used technique for the data-driven discovery of governing equations is the Sparse Identification of Nonlinear Dynamics (SINDy) [12]. SINDy and its variants have been used to uncover dynamical systems of ordinary and partial differential equations (ODEs and PDEs) in fluid dynamics [12, 15–19], biological systems [20–26], mechanical systems [27–29], and climate and environmental modeling [30–32]. It uses sparse regression to identify the minimal set of candidate functions needed to describe the system’s dynamics [12]. Originally developed for systems with constant coefficients, SINDy has since been extended to handle time-varying parameters [14, 33]. Such extensions are needed for systems with evolving dynamics, where temporal changes cannot be accurately represented by fixed parameters [8]. For example, the transmission rate and the death rate in an epidemic model are time-varying and can be estimated by calibrating the model to epidemic data [8, 9, 34]. However, for systems with many variables, it remains unclear how many parameters ex-actly need to be time-varying to capture the data accurately. Identifying only the necessary time-varying parameters can reduce computational cost, prevent overfitting, and improve inter-pretability. Another challenge is to use the resulting system of equations equipped with time-varying parameters in forecasting. Finding the time-series of a time-varying parameter (basically a variable) over past data can be done by model fitting. However, forecasting requires running the model with an initial condition, and this requires the time-series of the parameter in the future [8]. This is shaped by external forces, interactions among variables, and other dynamic factors [8,9]. To address this challenge, machine learning (ML) models were employed to fore-cast time-varying parameters across various fields using their historical time-series and known covariates [34]. In epidemiology, the disease transmission and death rates were forecasted based on policies or weather using epidemic models [8, 9, 35–37]. In climate science, green-house gas drivers were studied by forecasting time-varying parameters [38]. Therefore, once 2a system is modeled with time-varying parameters, they can be forecasted via an ML model using their past values and covariates whose future values are known [34, 39]. The goal of this study is to develop a data-driven framework for discovering ODEs with fixed and time-varying parameters that capture evolving dynamical systems. We implement this framework using a two-stage application of the SINDy algorithm. In the first stage, SINDy is applied to the full time series to identify the variables that actively contribute to the dynamics and their interactions under constant parameter assumptions. In the second stage, the analysis is repeated on shorter temporal intervals, allowing a subset of parameters–selected based on validation performance–to vary over time, while the remaining parameters are held fixed. This procedure yields an ODE model that preserves the underlying mechanistic structure while ac-commodating temporal variability in key processes. To enable forecasting, the identified time-varying parameters are predicted using a machine learning model driven by external covariates that influence the time-varying parameters. These predicted parameters are then substituted into the learned ODEs, allowing to run the model and make forecasts that adapt dynamically to changing conditions. We applied this methodology to two well-known mathematical models–the Susceptible– Infected– Recovered (SIR) model [40] and the Consumer–Resource (CR) model [41]–as well as two real-world datasets: greenhouse gas concentration dynamics in Alberta’s oil sands tailings ponds and cyanobacteria cell counts in lakes across Alberta. We predicted the time-varying parameters using a Random Forest (RF) model informed by weather-related drivers, including air temperature, relative humidity, precipitation, and wind speed. To benchmark the forecasting performance of our proposed approach, we compared it against two widely used data-driven baselines: a hybrid Convolutional Neural Network-Long Short-Term Memory (CNN-LSTM) model and a Gradient Boosting Machine (GBM). 

# 2 Methods 

## 2.1 Problem formulation 

Consider the evolution of a state vector x(t) ∈ Rn for a natural number n ∈ N, described by the dynamical system 

dx(t)

dt = f (x(t), u(t)) , (2.1) where u(t) ∈ Rq, q ∈ N, denotes the input variables and f : Rn × Rq → Rn is an unknown function. Measurements of the state variable are available at m time points t = [ t1, . . . , t m],3resulting in the time-series data 

X =



x(t1)⊤

x(t2)⊤

...

x(tm)⊤

 , (2.2) where m is the number of measurements and the resulting matrix has dimension m × n. The corresponding time derivative data is 

˙X =



˙x(t1)⊤

˙x(t2)⊤

...

˙x(tm)⊤

 . (2.3) Similarly, the time-series data of the inputs is 

U =



u(t1)⊤

u(t2)⊤

...

u(tm)⊤

 .

The library of candidate functions to estimate f (·) is constructed from X and U as 

Θ(X, U) =  1, X, U, (X⊙U), X2, U2, . . . , (Xd−1⊙U), (Xd−2⊙U2), . . . , (X⊙Ud−1), Xd, Ud,

(2.4) where d ∈ N, and the candidate library contains all monomials in x(t) and u(t) of total degree at most d. In addition to polynomial terms, the candidate function library may also include nonlinear bases such as sin( ·), cos( ·), tan( ·), their powers, and other user-defined nonlinear functions. Based on equation (2.1), the derivatives ˙X and the candidate function library Θ(X, U) can be related through 

˙X = Θ(X, U) Ξ, (2.5) where 

Ξ =

h

ξ1 ξ2 . . . ξn

i

is the matrix of unknown coefficient vectors ξk. For a system with n variables and a candidate library Θ(·) of l terms, the coefficient matrix Ξ has dimension l × n. The nonzero entries of 

ξk indicate the active candidate functions contributing to the dynamics of the kth state. Once 4ξk is identified, the nonlinear equation for the kth state is given by 

˙xk = Θ(x, u) ξk, (2.6) where xk is the kth component of x, and Θ(x, u) denotes the vector of candidate functions evaluated at x and u.

Example 2.1.1. Consider n = 2 state variables, i.e., x = [ x1, x 2]⊤, and q = 2 input variables, i.e., u = [ u1, u 2]⊤, and a library with maximum polynomial degree d = 2 . If the variables are measured at time points m = 2 , i.e., t = [ t1, t 2], then 

X2 =  x21(t), x 1x2(t), x 22(t), U2 =  u21(t), u 1u2(t), u 22(t),

and the candidate library has l = 15 terms 

Θ(X, U) = [ 1, x 1(t), x 2(t), u 1(t), u 2(t), x 1x2(t), u 1u2(t), x 1u1(t), x 1u2(t), x 2u1(t), x 2u2(t),x21(t), x 22(t), u 21(t), u 22(t)] .

Suppose the true dynamics are ˙x1 = 0 .6x1 + 0 .2x2u1 and ˙x2 = −0.4x2 + 0 .1u22. Equation 

(2.5) seeks Ξ ∈ R15 ×2, whose columns are coefficient vectors ξk ∈ R15 ×1. In this example, 

ξ1 = [ 0 , 0.6, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, . . . , 0 ] ⊤, ξ2 = [ 0 , 0, −0.4, 0, . . . , 0, 0.1 ] ⊤,

where the nonzero entries identify the active library terms. 

Equation (2.5) can be solved as a sparse regression problem to determine the active coef-ficients Ξ of the candidate nonlinearities Θ(X, U), and a Sparse Identification of Nonlinear Dynamics (SINDy) algorithm was introduced by Brunton et al. (2016) [12]. Early variants of SINDy used L1 regularization term for the regression, which was applied over the entire time domain to uncover systems of equations with constant coefficients [12, 22]. Consequently, Li et al. (2019) [14] proposed a time-varying variant of SINDy, which uncovers the time-varying coefficients of a dynamical system, and Rudy et al. (2017, 2019) [13, 33] implemented Ridge Regression to incorporate an L2 regularization term to the loss function. 

## 2.2 Discovering time-varying dynamics 

The Sequential Threshold Ridge Regression (STRR), which combines Ridge Regression with a sparsity-enforcing thresholding technique described by Rudy et al. (2017, 2019) [13,33], was applied to discover time-varying coefficients Ξ in equation 2.5, following the framework of Li et al. (2019) [14]. First, the input variables u(t) in (2.1) were selected based on prior knowledge, and time series data for all variables ( x(t) and u(t)) were collected (Figure 1a). Each variable’s time 5series was rolled over a number of time points to reduce noise. The derivative ˙X of the state variables was then numerically estimated, and the candidate library Θ(X, U) was constructed (2.4). Active constant coefficients, ξk for the kth state of (2.5), were extracted over the entire train-ing time domain (Figure 1b) using STRR. The STRR method minimizes error with regulariza-tion while enforcing sparsity through an iterative two-step optimization. Ridge Regression was first applied by minimizing the objective function 

arg min 

> ξk

∥ ˙Xk − Θ(X, U)ξk∥22 + λ∥ξk∥22, (2.7) where the term λ∥ξk∥22 represents the regularization component that penalizes nonzero coeffi-cients, controlled by the hyperparameter λ, which helps in avoiding over-fitting. A sparsity-enforcing thresholding step was then applied, where coefficients smaller than a pre-defined threshold τ are set to zero: 

ξi,k =



0 if |ξi,k | < τ ξi,k otherwise (2.8) where ξi,k is i-th entry of ξk. This step removes small, less significant features. Ridge regres-sion was then refitted on the remaining active features (those whose coefficients have not been zeroed out) Θactive (X, U), using the same loss function 

arg min 

> ξk

∥ ˙Xk − Θactive (X, U)ξk∥22 + λ∥ξk∥22. (2.9) This iterative refinement ensures that the model continues to adapt to the most relevant features. The process repeats until the coefficients converge, i.e., the change in the coefficients between two consecutive iterations is smaller than a specified tolerance ϵ:

∥ξ(t) 

> k

− ξ(t−1)  

> k

∥ < ϵ, (2.10) where ξ(t) 

> k

and ξ(t−1)  

> k

are the coefficients at iterations t and t − 1, respectively. The correlations between the active candidate terms ( Θactive (X, U)) and the target vari-able ˙Xk(t) for the kth state were computed (Figure 1c). The top N active candidate terms 

Θtop N showing the highest correlation with ˙Xk(t) were then identified from the candidate set (Θactive (X, U)). The coefficients of Θtop N were selected as time-varying coefficients (referred to as time-varying parameters) (Figure 1c), while the remaining coefficients were kept constant. Furthermore, the bias term was designated as time-varying by default to account for baseline shifts between intervals. To capture the time-varying dynamics of the system (2.1), a window size w was defined and kept fixed over the entire training period. STRR ((2.7)-(2.10)) was applied across each time window [t, t +w] (Figure 1d), with each parameter initialized using its value from the preceding 6interval. This sequential fitting strategy allowed the time-varying parameters to be dynamically adjusted while less impactful parameters remained fixed, capturing essential changes in the model structure and maintaining continuity between intervals. The discovered expression for the kth state can be written as 

˙xk(t) = ξk, 0(t) + X

> zi(t)∈Θtop N

ξk,i (t)zi(t) + X  

> zj(t)/∈Θtop N

¯ξk,j zj (t), (2.11) where ξ(t) are time-varying parameters and ¯ξ are the constant coefficients. Here, zi(t) ∈ Θtop N

denotes the top N active candidate terms and zj (t) ∈ Θactive (X, U) \ Θtop N represents the remaining active terms with fixed coefficients. 

## 2.3 Forecasting from learned dynamics 

To forecast the future dynamics of the state variables, the discovered representation in equa-tion (2.11), which incorporates both fixed and time-varying coefficients, was leveraged. The main idea involves predicting the time-varying parameters, ξ(t), while keeping the constant coefficients, ¯ξ, unchanged. Forecasting is thereby enabled by updating only the components of the model that evolve over time. A ML approach was employed to model the evolution of the time-varying parameters. Dur-ing model development, the time-varying parameters ξ(t) obtained from STRR were piecewise constant over each window of length w. However, during forecasting, the predicted parame-ters were not constrained to remain constant within a window; instead, continuous predictions were produced by the ML model based on the input features. Relevant predictors were used to train the models, with each time-varying parameter designated as a target output (Figure 1e). By combining the forecasted time-varying parameters with the fixed coefficients and the ac-tive candidate terms, the right-hand side of the dynamical model (2.11) was updated, and the forecast of the kth state variable was obtained by 

˙ˆxk(t) = ˆξk, 0(t) + X

> zi(t)∈Θtop N

ˆξk,i (t) zi(t) + X  

> zj(t)/∈Θtop N

¯ξk,j zj (t), (2.12) where ˆξ(t) are the forecasted time-varying parameters and ¯ξ are the constant coefficients. Here, 

zi(t) ∈ Θtop N denotes the top N active candidate terms, and zj (t) ∈ Θactive (X, U) \ Θtop N

represents the remaining active terms with fixed coefficients. 

# 3 Case studies 

We applied the proposed method (Section 2) to four datasets: two simulated from known ODE systems and two empirical. The simulated datasets were generated from 1) the Susceptible-7Figure 1: Schematic of data-driven discovery of governing equations and forecasting from the learned system. a) Time-series data of variables are gathered from natural or simulated systems. b) A sparse regression problem is solved over the whole time series to identify active terms and constant coefficients. Variables in gray represent non-active terms, while variables in blue represent active terms with constant coefficients. Variables in boxes represent generated terms. c) Top N candidate terms are chosen based on the correlation of active candidate terms with the derivative of the state variables. The coefficients of these terms are treated as time-varying parameters. By default, the bias term is also considered time-varying. d) Time series data is split into intervals, and sparse regression is performed within each interval to determine the time-varying parameters of the top candidate terms. Purple represents top candidate terms and their time-varying parameters, while blue indicates terms with constant coefficients. e) A ML model is employed to forecast the time-varying parameters. Inputs are relevant predictors, and outputs are the time-varying parameters. 

Infectious-Recovered (SIR) model and 2) a Consumer-Resource (CR) model. The empirical datasets consisted of 1) Carbon dioxide (CO 2) and methane (CH 4) concentrations measured in Alberta’s oil sands tailings ponds and 2) cyanobacteria cell counts collected from lakes across Alberta. 

## 3.1 SIR model 

The SIR model [40] is a foundation for most disease-spreading models. In this model, the population is categorized into three compartments: susceptible ( S), infectious ( I), and recov-8ered ( R). The susceptible compartment represents individuals who are not yet infected but are at risk of contracting the disease through contact with infectious individuals. The infectious compartment consists of individuals who are actively carrying the disease and can transmit it to others. Lastly, the recovered compartment includes individuals who have recovered from the disease and are assumed to have gained immunity, no longer participating in disease trans-mission. These compartments interact dynamically, with transitions governed by a system of ODEs that model the rates of change in each group over time. The model equations are given by  

> dS (t)
> dt

= Λ − β(t)S(t)I(t) − μS (t), 

> dI (t)
> dt

= β(t)S(t)I(t) − αI (t) − μI (t), 

> dR (t)
> dt

= αI (t) − μR (t),

(3.1) where Λ is the recruitment rate of susceptible populations, β(t) is the time-dependent disease transmission rate, μ is the natural death rate, and α is the recovery rate from the disease. The first two equations of (3.1) are independent of recovered ( R), and the reduced equations are given by  

> dS (t)
> dt

= Λ − β(t)S(t)I(t) − μS (t), 

> dI (t)
> dt

= β(t)S(t)I(t) − αI (t) − μI (t).

(3.2) When a white noise is added to the equations of the SIR model (3.2), then the SIR model with additive white noise has the form [39] 



dS (t) = Λ dt − β(t)S(t)I(t)dt − μS (t)dt + σ1dW 1(t),dI (t) = β(t)S(t)I(t)dt − αI (t)dt − μI (t)dt + σ2dW 2(t),

(3.3) where σi, i = 1 , 2, are the intensities of white noise, and Wi(t), i = 1 , 2, are independent Wiener processes. We used equation (3.3) to simulate the time series of susceptible and infected populations over 1500 days. The model parameters were set as Λ = 100 , α = 0 .1, μ = 0 .1, with initial conditions S0 = 500 and I0 = 7 . The transmission rate β(t) was defined as a combination of sinusoidal functions to capture irregular seasonal peaks by 

β(t) = A + A1 sin( ω1t) + A2 sin( ω2t + π/ 4) + A3 sin( ω3t + π/ 6) sin(0 .005 t), (3.4) where A = 0 .0003 , A1 = 0 .00015 , A2 = 0 .00012 , A3 = 0 .00010 , and the angular frequencies are ω1 = 2 π/ (365 /2) , ω2 = 2 π/ 365 , and ω3 = 2 π/ (365 /2) . Small random fluctuations were added to β(t) at each time step to account for irregular environmental variability, and the values were clipped to remain non-negative. Additive stochasticity was introduced through Wiener processes, dW i ∼ N (0 , √dt ), i = 1 , 2, and the Euler–Maruyama method [42] was used for numerical integration with dt = 0 .01 . Simulations were repeated with noise intensities 9σ1 = σ2 = 0 , 0.1, 0.2, 0.3, and 0.4 to examine the effect of increasing stochasticity on model predictions. The simulated trajectories of S(t) and I(t) were then used to learn the dynamics of the SIR model using time-varying parameters following the proposed method in Section 2. To discover the governing equations, we expressed the system in the form 

 

> dS dt

= f (S, I ), 

> dI dt

= f (S, I ),

(3.5) where the time-varying parameters were systematically selected according to the procedure described in Section 2. 

## 3.2 CR model 

The CR model [41] is a fundamental framework used to study the interactions between two populations: a resource population (e.g., prey or a nutrient source) and a consumer population (e.g., predators or organisms that depend on the resource). This model captures the dynamics of population growth and interactions, providing insights into ecological systems. In this model, the resource population ( R) grows at a rate proportional to its size, governed by the growth rate r. The growth of R is constrained by consumption from the consumer population ( C), which follows a saturating functional response. This response is characterized by the consumption rate a and the half-saturation constant b. Simultaneously, the consumer population ( C) grows through resource consumption but experiences a constant mortality rate 

m. The dynamics of the model are described by the following equations 

 

> dR dt

= rR − aRC  

> 1+ bR

, 

> dC dt

= aRC  

> 1+ bR

− mC. 

(3.6) To incorporate the stochastic fluctuation into the model, we added noise into each of the equations of the system (3.6). The noise-induced CR model has the form 



dR (t) = rR (t)dt − aR (t)C(t)1 + bR (t) dt + σ1dW 1,dC (t) = aR (t)C(t)1 + bR (t) dt − mC (t)dt + σ2dW 2,

(3.7) where σi, i = 1 , 2, are the intensities of white noise, and Wi(t), i = 1 , 2, are independent Wiener processes. We simulated the CR models dynamics using the Euler–Maruyama method, which is well suited for SDEs. The model parameters were chosen as the resource growth rate r = 0 .1, the consumption rate a = 0 .005 , the half-saturation constant b = 0 .001 , and the consumer mortality 10 rate m = 0 .025 . The initial population sizes were set to R0 = 20 for the resource and C0 = 10 

for the consumer. Additive environmental stochasticity was incorporated into both equations through Wiener processes sampled from dW i ∼ N (0 , √dt ), i = 1 , 2, and simulations were repeated across a range of noise intensities, σ1 = σ2 ∈ { 0, 0.5, 1.0, 1.5, 2.0}. The system was simulated over a time horizon of 1500 units with a time step of dt = 0 .01 . After each Euler– Maruyama update, any negative population values were prevented by enforcing small positive lower bounds to maintain biological realism. We used the simulated time series of C and R to learn the dynamics of the CR model using the proposed method described in Section 2. During the learning phase, we assumed that the system could be represented in the general form 

 

> dR dt

= f (C, R ), 

> dC dt

= f (C, R ),

(3.8) where the time-varying parameters were systematically selected following the procedure in Section 2. 

## 3.3 Gas concentration 

CO 2 and CH 4 are two major greenhouse gases, and a significant amount of these gases is found in the oil-sand tailing areas. Our goal is to learn a system of equations that can capture the concentration time-series of CO 2 and CH 4 in Alberta’s oil-sand tailing ponds based on relevant weather conditions and diluent inputs. Additionally, we leveraged the learned equation to predict future concentrations based on estimated weather conditions and diluent inputs. We used two different air monitoring station datasets that contain CO 2 and CH 4 concen-trations, and one nearby meteorological tower dataset by the Wood Buffalo Environmental Association (WBEA) [43], located in the regional municipality of Wood Buffalo in northeast Alberta, Canada. The air monitoring stations we used are AMS-1: Bertha Ganter–Fort McKay (Latitude: 57.189428, Longitude: -111.640583), and AMS-18: Stony Mountain (Latitude: 55.621408, Longitude: -111.172686). The meteorological tower we used is JP104-Site 1004 (Latitude: 57.11901, Longitude: -111.42542). The parameters used in this study and their sources are described in Table 1. Air monitoring station and meteorological tower data can be accessed from [43]. The period of the collected data was from January 2019 to December 2024. Air monitoring stations recorded hourly data with a few missing data. We deleted rows containing missing measures and took the daily average of the recorded data. Both stations measure CO 2 and CH 4 and some common weather variables (AT, RH, WS, WD, PC, and GR) (Table 1). We wanted to keep the same number of weather variables (AT, RH, WS, WD, GR, BP, DEW, PAR, SR, and PC) in each dataset. Therefore, the other weather variables (BP, DEW, PAR, and SR) were considered the same in both datasets which were 11 collected from nearby meteorological tower JP104 (Table 1). To incorporate the source of the hydrocarbons, which are responsible for producing these gases, we used the total diluent lost data from Alberta Energy Regulator (AER) reports [44]. Since it is unknown which monitoring stations capture gases from which exact source tailing pond, we took the summation of monthly reported diluent loss data of all the reported min-ing companies in that region between January 2019 and December 2024. Then we divided it equally throughout the months to get daily diluent estimations.                                               

> Table 1: Variables and data sources used in this case study.
> Variable Abbreviation Unit Data Sources
> Methane CH 4Parts per million (ppm) AMS-1, AMS-18 Carbon Dioxide CO 2Parts per million (ppm) AMS-1, AMS-18 Ambient Temperature AT Degrees Celsius (°C) AMS-1, AMS-18 Relative Humidity RH Percentage (%) AMS-1, AMS-18 Wind Speed WS km h −1AMS-1, AMS-18 Wind Direction WD Degrees ∈[0 ,360) AMS-1, AMS-18 Global radiation GR W m −2AMS-1, AMS-18 Precipitation PC millimeters (mm) AMS-1, AMS-18 Barometric pressure BP mB JP104 Dew point DEW Degrees Celsius (°C) JP104 Photosynthetically active radiation at 16m PAR μmol m −2s−1JP104 Solar radiation SR W m −2JP104 Diluent DIL m3AER

To learn the system of equations, We took up to quadratic terms of the library of candidate nonlinear functions Θ(X, U) (equation (2.4)) to fit the data of each of the gas with a quadratic equation. We considered the diluent lost data as a source of CO 2 and CH 4, and since the gas concentration varies with the weather conditions, we incorporated all the weather variables as input variables in the candidate terms. Additionally, CH 4 can be produced by the chemical reaction of CO 2. Therefore, based on these considerations, we considered the learned system of equations to have the general form 

 

> dCO 2
> dt

= f (DIL, weather variables ), 

> dCH 4
> dt

= f (CO 2, DIL, weather variables ),

(3.9) where the weather variables are AT, RH, WS, WD, GR, BP, DEW, PAR, SR, and PC, described in Table 1. 

## 3.4 Cyanobacteria cell count 

Cyanobacterial blooms are commonly found in freshwater ecosystems and can be highly toxic, posing significant risks to aquatic life, wildlife, and human health through the production of harmful toxins that contaminate water sources. Our goal is the data-driven discovery of an equation of cyanobacteria cell counts and prediction from the discovered equation based on 12 nutrient availability, meteorological conditions, lake features, and watershed data. The dataset includes observations from 78 lakes and reservoirs across Alberta, Canada, spanning the years from 1986 to 2017 [45]. These lakes and reservoirs are situated between lat-itudes 49.3°N and 58.8°N and longitudes 110.0079°W and 119.21667°W [46]. The lake mon-itoring data is collected during May to October, which includes phytoplankton data gathered through the Alberta Lake Monitoring Program. The original lake monitoring dataset contains various parameters such as chemical concentrations in lake water, Secchi depth measurements, lake stratification data, cyanobacteria cell counts, etc, provided by Alberta Environment and Parks (AEP). We used the processed datasets from Heggerud et al. [46], which can be accessed from [45]. We averaged the data based on each year and month from different lakes. The variables used for this case study are described in Table 2.                  

> Table 2: List of variables and their abbreviations used for CB cell count
> Variable Description
> CB cell Cell count of cyanobacteria sampled on the monitoring day PPhosphorus concentration sampled on the monitoring day NNitrogen concentration sampled on the monitoring day SD Secchi depth of lake on the monitoring day ST Stratification state of lake on the monitoring day AT Average daily temperature from the day of monitoring to 2 weeks Before the next available CB sample PC Average daily precipitation from the day of monitoring to 2 weeks Before the next available sample WS Average daily wind speed from the day of monitoring to 2 weeks before the next available sample SR Average daily solar radiation from the day of monitoring to 2 weeks before the next available sample LD Lake depth LE Lake elevation PL % pastureland in watershed CL % cropland in watershed FT % forest in watershed WL % wetland in watershed LWAR Lake-watershed area ratio

We used the method described in section 2 to learn a single equation for CB cell count (CB cell ) based on all the covariates listed in Table 2. The learned equation has the general form of 

dCB cell 

dt = f (CB cell , Lake Monitoring , Meteorology , Lake feature , Watershed features ),

(3.10) where the Lake Monitoring includes P, N, SD, and ST. Meteorology includes AT, PC, WS, and SR. Lake feature includes LD and LE. Watershed features include PL, CL, FT, WL, and LWAR. The CB cell remains in the RHS of the equation to indicate that the new cell count depends on the existing cell count. 13 3.5 Simulated weather data 

Once the system was learned through the time-varying parameters, we used a ML model to forecast these parameters based on weather conditions. In this study, we considered four weather variables-temperature, humidity, wind speed, and precipitation-as predictors of the time-varying parameters. For the gases and CB datasets, these weather variables were avail-able in the dataset and directly used for forecasting. In contrast, for the SIR and CR models, we simulated the corresponding weather variables so that the ML model could be applied in the same way, enabling prediction of the time-varying parameters based on these simulated environmental conditions. We used the Ornstein-Uhlenbeck (OU) process [47] to simulate the time series of the weather variables. The OU process is represented by a stochastic differential equation (SDE) commonly used to model mean-reverting phenomena. The process is described by the equation 

dX (t) = −θX (X(t) − Xmean ) dt + σX dW (t), (3.11) where X(t) represents the state variable (e.g., temperature) at time t, and Xmean is the long-term mean around which the process fluctuates. The parameter θX quantifies the rate of mean reversion, indicating how quickly deviations from the mean are corrected. The term σX rep-resents the intensity of stochastic noise, and dW (t) is the Wiener process, which introduces randomness. To simulate data from the OU process, we discretized the continuous-time equation using the Euler-Maruyama method. The discretized version of the SDE is given by 

Xi+1 = Xi − θX (Xi − Xmean ) ∆ t + σX

√∆t ξ i,

where ∆t is the time increment, ξi are independent standard normal random variables. The weather simulation model was designed with parameter values that closely mimic re-alistic dynamics for temperature, humidity, wind speed, and precipitation over the simulated period. We used a time step of ∆t = 0 .01 , which provides sufficient granularity to capture variations in weather conditions over a total duration of 1500 days. The initial temperature was 20 ◦C, the initial humidity was 60% , the initial wind speed was 10 m /s, and the initial pre-cipitation was 0.2 mm /day . The long-term mean values for each parameter were defined as 

Tmean = 0 ◦C, Hmean = 50% , Wmean = 5 m /s, and Pmean = 0 .1 mm /day . The rates of mean reversion ( θ) were chosen as θT = 0 .1, θH = 0 .05 , θW = 0 .2, and θP = 0 .1. The noise inten-sities were set as σT = 10 , σH = 5 , σW = 1 , and σP = 0 .05 , corresponding to fluctuations in temperature, humidity, wind speed, and precipitation, respectively. Higher noise intensities for temperature and humidity reflect their typically greater variability compared to wind speed and precipitation. Additionally, boundaries were specified for each variable to prevent unrealistic values. Temperature was limited to the range [−20 , 35] ◦C, humidity to [0 , 100]% , wind speed 14 to [0 , 30] m /s, and precipitation to [0 , 100] mm /day .

## 3.6 ML models, error metrics, and cross-validation 

Each variable’s time series was first smoothed using a 30-point rolling window to reduce high-frequency noise. To account for differences in scale across variables, all series were normalized to the range [0 , 1] using min–max scaling, 

X′ = X − Xmin 

Xmax − Xmin 

,

where X′ denotes the normalized variable and Xmin and Xmax are the minimum and maximum values of X, respectively. As a case study, we employed a Random Forest (RF) regression model [48] to predict each time-varying parameter independently from four weather-related covariates: air temperature, relative humidity, wind speed, and precipitation. The RF model was implemented using the 

RandomForestRegressor class from sklearn.ensemble [49]. To ensure ensemble stability, we used 5000 trees ( n_estimators = 5000). Model complexity was controlled by restricting the maximum tree depth to 5 ( max_depth =5), requiring a minimum of 10 samples to split an internal node ( min_samples_split =10), and enforcing at least 5 samples per leaf ( min_samples_leaf =5). The weather variables served as predictors, and each time-varying parameter was treated as a separate target (Figure 1e). For each dataset, the time series was partitioned into training, validation, and testing seg-ments. The testing period was divided into five folds of 30 days each, except for the CB dataset, which consisted of five monthly observations. Temporal ordering was strictly pre-served. For each test fold, a validation fold of equal duration was selected immediately preced-ing the test period (Figure 2). The governing equations were fitted to the training data using equation (2.11), and forecasts were generated using equation (2.12). Model selection was performed using an expanding-window time-series cross-validation strategy (Figure 2). The window length w was varied from 7 to 28 days in increments of 7 (from 5 to 25 in increments of 5 for the CB dataset). Simultaneously, the number of time-varying parameters was varied from zero (fixed-parameter model) up to the full set of active parameters, with the bias term always included. Starting from an initial group of validation folds (e.g., folds 1-5), the validation window was progressively expanded (1-6, 1-7, . . . , 1-9) (Figure 2). For each configuration, performance was assessed using the mean absolute error (MAE), 

MAE = 1

n

> n

X

> i=1

|ˆyi − yi| ,

where yi and ˆyi denote the observed and predicted values, respectively. The configuration minimizing the average validation MAE was selected and used to forecast the subsequent test 15 fold. To examine the influence of interval length and the number of time-varying parameters, simulations were performed on each test fold and the resulting MAEs were computed. Within each fold, the configuration yielding the lowest MAE was identified as the optimal configu-ration and compared with the cross-validation-selected model. For all datasets, we addition-ally compared the proposed time-varying parameter model with a fixed-parameter baseline, in which the entire time series is represented by constant coefficients (Figure 1b) [13]. In both cases, the regularization parameter was set to λ = 0 .01 , the sparsity threshold to τ = 0 .001 ,and the maximum number of iterations to 10,000. To further benchmark our framework, we compared its forecasting performance against two standard machine learning baselines: a hybrid CNN–LSTM model [50–52] and a Gradient Boosting Machine (GBM) [53]. For the CNN–LSTM model, inputs were constructed using sliding windows of length w

days. For each target variable, the predictors consisted of the exogenous covariates over the same w-day interval, while the response comprised the corresponding w-day sequence of the target state, aligned in time. For the SIR and CR datasets, the covariates included air tem-perature (AT), wind speed (WS), precipitation (PC), and relative humidity (RH). For the gas concentration and CB datasets, all weather variables listed in Tables 1 and 2 were used. The CNN–LSTM architecture combines convolutional layers for feature extraction [52] with recurrent memory units [51], and was implemented in TensorFlow/Keras [54, 55]. The architecture consisted of a one-dimensional causal convolutional layer, Conv1D( filters =

F, kernel size = K, activation = ReLU) , followed by a max-pooling layer with pool size 2, an LSTM layer with U hidden units, a dropout layer with rate d, and two fully connected layers: a ReLU-activated dense layer with D units and a final linear output layer producing w outputs (with w = 30 in our experiments). Hyperparameters (F, K, U, D, d ) and the learning rate were selected using a KerasTuner [56] random search to minimize the validation mean squared error (MSE). Training employed the Adam optimizer [57] with early stopping [58] (patience of 10 epochs and restoration of the best-performing weights), using a non-shuffled time-series cross-validation scheme. Within each fold, the most recent block of the training data, matching the test length, was reserved for validation. As an additional baseline, we implemented a GBM model using the same set of predictors as in the CNN–LSTM setup. The GBM input consisted of the exogenous covariates at each time step, and the response was the corresponding target value. The model was trained using 1000 boosting trees, a learning rate of 0.01, a maximum tree depth of 30, and a subsampling ratio of 0.9 to mitigate overfitting. Each terminal node was constrained to contain at least 10 samples. The squared error loss function was used, corresponding to a Gaussian regression framework. 16 Figure 2: Illustration of the sequential, non-overlapping training, testing, and validation scheme used in this study. The training period (red) covers the majority of the time series. The validation window blocks (blue), equal in length to the test window, are positioned immediately before the test period (yellow). For each fold of the test, only the validation window is expanded forward while the training set remains fixed, producing multiple validation folds without expanding or overlapping the training data. 

# 4 Results 

## 4.1 Theoretical guarantees 

In this subsection, we establish theoretical guarantees for three key components of our frame-work: (i) the propagation of errors from the learned equations and the forecasted time-varying parameters to the forecasted states, (ii) error bounds to the split structure of learned and fore-casted equations, and (iii) conditions under which the time-varying parameterisation admits strictly tighter finite-horizon forecast error bounds than any fixed-parameter model built on the same library. Our analysis builds on classical ODE stability theory and sparse equation discovery re-sults [12, 59, 60]. We extend these foundations by deriving finite-horizon forecast error bounds for time-varying parameter models and quantifying error propagation from ML-forecasted pa-rameters to state trajectories. 

4.1.1 Finite-horizon forecast error bounds 

We now quantify how errors in the learned governing equations and in the forecasted time-varying parameters propagate to errors in the forecasted trajectories. Let f : [0 , H ] × Rn → Rn

denotes the (unknown) right-hand side of the true system, 

˙x(t) = f (t, x(t)) , t ∈ [0 , H ],

where H > 0 is a finite time horizon. We assume that f (·) can be uniformly approximated on a compact region by a representation constructed from our candidate library Θ(·).

Assumption 4.1.1 (Lipschitz dynamics and library approximation [12, 59, 60]) . Let D ⊂ Rn

be a compact set containing the trajectories of interest. Assume: (a) (Lipschitz dynamics) For each t ∈ [0 , H ], the map x 7 → f (t, x ) is globally Lipschitz on 

17 D with constant L > 0:

∥f (t, x ) − f (t, y )∥ ≤ L∥x − y∥ for all x, y ∈ D. 

(b) (Library approximation) There exist coefficient functions ξ⋆ : [0 , H ] → Rp and a library vector Θ : D × [0 , H ] → Rp such that 

f (t, x ) − Θ( x, u (t)) ξ⋆(t) ≤ εlib for all (t, x ) ∈ [0 , H ] × D, 

for some εlib ≥ 0.(c) (Bounded library) There exists BΘ > 0 such that ∥Θ( x, u (t)) ∥op ≤ BΘ for all (t, x ) ∈

[0 , H ] × D, where ∥ · ∥ op denotes the denotes the spectral norm. 

Our forecasting pipeline produces estimated time-varying coefficients ˆξ(t) (via STRR on sliding windows, followed by ML model forecasts), and uses the model 

ˆf (t, x ) := Θ( x, u (t)) ˆξ(t).

We assume that the ML model forecasts approximate the ideal coefficient functions ξ⋆(t) with a uniform bound on the forecast horizon. 

Assumption 4.1.2 (Accuracy of coefficient forecasts) . There exists εpar ≥ 0 such that 

sup 

> t∈[0 ,H ]

ˆξ(t) − ξ⋆(t) ≤ εpar .

Under Assumptions 4.1.1-4.1.2, the difference between the true vector field f and the learned-forecasted vector field ˆf is uniformly bounded: 

f (t, x ) − ˆf (t, x ) ≤ εlib + BΘεpar =: δ for all (t, x ) ∈ [0 , H ] × D. 

We now quantify the impact of this bound on the state trajectories. 

Theorem 4.1.1 (Finite-horizon forecast error bound) . Suppose Assumptions 4.1.1 and 4.1.2 hold and let δ = εlib + BΘεpar . Let x : [0 , H ] → D solve the true system ˙x(t) = f (t, x(t)) with initial condition x(0) = x0, and let ˆx : [0 , H ] → D solve the learned system ˙ˆx(t) = ˆf (t, ˆx(t)) 

with the same initial condition ˆx(0) = x0. Then, for all t ∈ [0 , H ],

∥x(t) − ˆx(t)∥ ≤ δL

 eLt − 1 ≤ δL

 eLH − 1.

Proof. Define the error e(t) := x(t) − ˆx(t). Differentiating gives 

˙e(t) = f (t, x (t)) − ˆf (t, ˆx(t)) =  f (t, x (t)) − f (t, ˆx(t))  +  f (t, ˆx(t)) − ˆf (t, ˆx(t)) .

18 Taking norms and applying Assumption 4.1.1(a) and the definition of δ yields 

∥ ˙e(t)∥ ≤ L∥e(t)∥ + δ. 

Let y(t) := ∥e(t)∥. Then y(0) = 0 and 

˙y(t) ≤ Ly (t) + δ for a.e. t ∈ [0 , H ].

By the differential form of Grönwall’s inequality [59, 61], 

y(t) ≤ δL

 eLt − 1 for all t ∈ [0 , H ],

which proves the stated bound. Theorem 4.1.1 is a standard ODE stability result specialised to our library-based represen-tation. It shows that all sources of error in our pipeline enter the state forecast through the single quantity δ = εlib + BΘεpar , combining the approximation error of the library representation and the error of the time-varying parameter forecasts. 

4.1.2 Bounds to the split structure of learned and forecasted equations 

We now specialize the baseline bound to the learned forecasting model in this paper. For ref-erence, we restate the split form of the learned dynamics (2.11) and its forecasting counterpart (2.12). Let 

˙x(t) = ftv (t, x(t)) := Θ top N (x(t), u (t)) ξtv (t) + Θ fix (x(t), u (t)) ¯ξ, (4.1) where Θfix := Θ active \ Θtop N and ¯ξ denotes the fixed coefficient vector for the non-top-n active terms. The forecast model is 

˙ˆx(t) = ˆftv (t, ˆx(t)) := Θ top N (ˆ x(t), u (t)) ˆξtv (t) + Θ fix (ˆ x(t), u (t)) ¯ξ. (4.2) 

Assumption 4.1.3 (Uniform boundedness of the top-n library block) . There exists Btop N > 0

such that 

sup 

> t∈[0 ,H ]

sup 

> x∈D

∥Θtop N (x, u (t)) ∥op ≤ Btop N .

Assumption 4.1.4 (Uniform accuracy of time-varying coefficient forecasts) . There exists εtop N ≥

0 such that 

sup 

> t∈[0 ,H ]

∥ˆξtv (t) − ξtv (t)∥ ≤ εtop N .

Theorem 4.1.2 (Split-model forecast bound: only Θtop N forecast errors enter) . Assume As-sumption 4.1.1a holds for ftv in (4.1) , and Assumptions 4.1.3–4.1.4 hold. Let ˙x solve (4.1) and 

19 b˙x solve (4.2) with the same initial condition x(0) = ˆ x(0) . If x(t), ˆx(t) ∈ D for all t ∈ [0 , H ],then for all t ∈ [0 , H ],

∥x(t) − ˆx(t)∥ ≤ Btop N εtop N

L

 eLt − 1 ≤ Btop N εtop N

L

 eLH − 1.

Proof. For any (t, x ) ∈ [0 , H ] × D, the fixed block cancels exactly: 

ftv (t, x ) − ˆftv (t, x ) = Θ top N (x, u (t))  ξtv (t) − ˆξtv (t).

Hence, by Assumptions 4.1.3–4.1.4, 

sup 

> (t,x )∈[0 ,H ]×D

∥ftv (t, x ) − ˆftv (t, x )∥ ≤ Btop N εtop N .

Apply Theorem 4.1.1 with δ = Btop N εtop N to obtain the stated bound. 

Remark 4.1.1. Theorem 4.1.2 is specific to the split structure of (4.1) –(4.2) : the fixed coef-ficients ¯ξ do not appear in the forcing term of the error bound. Consequently, improving the forecast accuracy of ˆξtv for the selected Θtop N terms directly tightens the finite-horizon state forecast bound, while the fixed block affects the bound only indirectly through the Lipschitz constant L of the resulting vector field. 

4.1.3 When time-varying parameters outperform fixed parameters 

Finally, we compare our time-varying parameterisation with a fixed-parameter model. Let 

Cconst denote the class of constant coefficient vectors 

Cconst := {ξ : [0 , H ] → Rp : ξ(t) ≡ c},

and let C(m)tv denote the class of piecewise constant coefficient functions with at most m subin-tervals: 

C(m)tv := 

n

ξ : [0 , H ] → Rp : ξ(t) = cr for t ∈ Ir, r = 1 , . . . , m 

o

,

where {Ir}mr=1 is a partition of [0 , H ] into m intervals. We quantify how well these classes can approximate the ideal coefficient trajectory ξ⋆(t).

Definition 4.1.1 (Best uniform coefficient approximation errors) . Let 

Econst := inf 

> ξ∈C const

sup 

> t∈[0 ,H ]

∥ξ⋆(t) − ξ(t)∥, E(m)tv := inf 

> ξ∈C (m)tv

sup 

> t∈[0 ,H ]

∥ξ⋆(t) − ξ(t)∥.

Clearly Cconst ⊂ C (m)tv , so E(m)tv ≤ Econst for every m. The next lemma shows that, under mild regularity, the inequality is strict for sufficiently large m whenever ξ⋆(t) is truly time-20 varying. It is a constructive instance of the fact that step functions are dense in C([0 , H ]) with respect to the supremum norm [62, Chapter 2]. 

Assumption 4.1.5 (Regularity and non-stationarity of the true coefficients) . Each component of ξ⋆(t) is continuous on [0 , H ], and ξ⋆ is not constant on [0 , H ] (that is, there exist t1, t 2 with 

ξ⋆(t1)̸ = ξ⋆(t2)). 

Lemma 4.1.1 (Step-function approximation beats constant approximation) . Suppose Assump-tion 4.1.5 holds. Then Econst > 0, and for every 0 < ε < E const there exists an integer mε ≥ 1

such that, for all m ≥ mε,

E(m)tv ≤ ε < E const .

In particular, for all sufficiently large m, we have E(m)tv < E const .Proof. Because ξ⋆ is continuous on the compact interval [0 , H ], it is uniformly continuous. Hence, for any ε > 0, there exists δ > 0 such that ∥ξ⋆(t) − ξ⋆(s)∥ < ε whenever |t − s| < δ .Given such a δ, choose mε large enough that a partition of [0 , H ] into mε subintervals has each interval of length at most δ. Define a piecewise constant function ˜ξ ∈ C (mε)tv by setting 

˜ξ(t) equal to ξ⋆ evaluated at a reference point in each subinterval. By construction, 

sup 

> t∈[0 ,H ]

∥ξ⋆(t) − ˜ξ(t)∥ ≤ ε, 

so E(mε)tv ≤ ε and the same bound holds for all m ≥ mε.To show Econst > 0, note that by Assumption 4.1.5 there exist t1, t 2 such that ξ⋆(t1)̸ =

ξ⋆(t2). Let 

V := ∥ξ⋆(t1) − ξ⋆(t2)∥ > 0.

For any constant vector c ∈ Rp,

V = ∥ξ⋆(t1) − ξ⋆(t2)∥ ≤ ∥ ξ⋆(t1) − c∥ + ∥ξ⋆(t2) − c∥ ≤ 2 sup 

> t∈[0 ,H ]

∥ξ⋆(t) − c∥,

so sup t∈[0 ,H ] ∥ξ⋆(t)−c∥ ≥ V / 2 for every c. Taking the infimum over c yields Econst ≥ V / 2 > 0.Choosing any 0 < ε < E const then gives the claim. We now combine Lemma 4.1.1 with Theorem 4.1.1 to obtain a sufficient condition under which the time-varying parameterisation yields a strictly smaller finite-horizon forecast error bound than any fixed-parameter model. 

Theorem 4.1.3 (When time-varying parameters dominate fixed parameters) . Suppose Assump-tions 4.1.1, 4.1.2, and 4.1.5 hold. Consider two idealised models built on the same library 

Θ:

• a fixed-parameter model with coefficient trajectory ξ⋆ 

> const

∈ C const achieving the error 

Econst ,

21 • a time-varying model with m intervals and coefficient trajectory ξ⋆ 

> tv

∈ C (m)tv achieving the error E(m)tv .let ˆx(m)tv (t) denote the trajectory of the time-varying model 

˙ˆx(t) = Θ(ˆ x(t), u(t)) ξ⋆

> tv

(t), ˆx(m)tv (0) = x0,

with ξ⋆ 

> tv

∈ C (m)tv . For these two models, define 

δconst := εlib + BΘEconst , δ(m)tv := εlib + BΘE(m)tv .

Then, for any H > 0 and any m ≥ mε with E(m)tv < E const , the finite-horizon forecast error bound of the time-varying model satisfies 

sup 

> t∈[0 ,H ]

∥x(t) − ˆx(m)tv (t)∥ ≤ δ(m)tv 

L

 eLH − 1 < δconst 

L

 eLH − 1 ≥ sup 

> t∈[0 ,H ]

∥x(t) − ˆxconst (t)∥.

In particular, for all sufficiently large m, the time-varying parameterisation admits a strictly smaller worst-case finite-horizon forecast error bound than any fixed-parameter model based on the same library. Proof. By Lemma 4.1.1, for all sufficiently large m there exists a time-varying coefficient trajectory ξ⋆ 

> tv

∈ C (m)tv with E(m)tv < E const . For this choice of m we have δ(m)tv < δ const . Applying Theorem 4.1.1 separately to the fixed-parameter and time-varying models gives 

sup 

> t∈[0 ,H ]

∥x(t) − ˆxconst (t)∥ ≤ δconst 

L (eLH − 1) , sup 

> t∈[0 ,H ]

∥x(t) − ˆx(m)tv (t)∥ ≤ δ(m)tv 

L (eLH − 1) ,

and the strict inequality δ(m)tv < δ const yields the claimed ordering of the bounds. Theorem 4.1.3 formalises the intuition that, when the true parameters are non-stationary in time, a sufficiently rich time-varying parameterisation can represent the coefficient trajectory more accurately than any fixed-parameter model and therefore admits strictly tighter worst-case bounds on finite-horizon forecast errors. In practice, our STRR+RF pipeline searches over win-dow lengths and numbers of time-varying parameters, providing a data-driven approximation to the theoretically favourable regime identified above. 

## 4.2 Experiment results 

4.2.1 Learning and reproducing system dynamics 

In the SIR dataset, the time-varying parameter model demonstrated strong capability of cap-turing the dynamics, achieving a MAE of 0.9% for the susceptible ( S) population and 1.7% 22 for the infected ( I) population (Figure 3a). In contrast, the fixed-parameter model yielded sig-nificantly higher errors–29.7% for S and 29.9% for I (Figure 3a). Across all noise levels, the time-varying model consistently maintained an average MAE below 2%, whereas the fixed-parameter model exhibited considerably poorer accuracy, with MAEs ranging from 28% to 33% (SI Appendix Figure 6). For the CR dataset, the time-varying parameter model effectively reproduced the time se-ries dynamics, with an average MAE of 1.9% for the consumer ( C) variable and 2.5% for the resource ( R) variable (Figure 3b). In comparison, the fixed-parameter model performed substantially worse, producing MAEs of 21.5% for C and 31.1% for R (Figure 3b). When examined across varying noise levels, the time-varying model maintained a stable MAE range of 1.6–2.7%, while the fixed-parameter model fluctuated between 11–38% (SI Appendix Fig-ure 6). In the gases dataset, the time-varying parameter approach also exhibited superior perfor-mance, capturing the temporal behavior of CO 2 and CH 4 with MAEs of 1.4% and 1.9%, re-spectively (Figure 3c). Conversely, the fixed-parameter model achieved notably higher MAEs of 16.9% for CO 2 and 9.1% for CH 4 (Figure 3c). Averaged across multiple station datasets, the time-varying model maintained an overall MAE below 3%, while the fixed-parameter counter-part ranged between 11–17% (SI Appendix Figure 6). In the CB dataset, both models performed comparably, with the time-varying and fixed-parameter models producing nearly identical MAEs of 3.51% and 3.53%, respectively (Fig-ure 3d). Sample plots illustrate that the fixed-parameter model generally fails to capture the evolving trends in the time series across most variables in our case studies, with the exception of CH 4

and CB (Figure 10). The model performs well on the CB dataset, which exhibits only a single peak, and moderately on CH 4, which has multiple peaks (SI Appendix Figure 10). In contrast, the time-varying parameter model accurately captures the temporal dynamics for all variables (SI Appendix Figure 10). 

4.2.2 Forecasting system dynamics 

For the SIR dataset, the time-varying parameter model demonstrated strong forecasting skill for both the susceptible ( S) and infected ( I) populations, achieving average MAEs of 10.0% and 9.9%, respectively (Figure 4a). In contrast, the fixed-parameter model yielded substantially higher errors, with MAEs of 13.8% for S and 14.0% for I (Figure 4a). Across all noise levels, the time-varying model consistently maintained MAEs between 9% and 13%, whereas the fixed-parameter model exhibited degraded performance, with errors ranging from 12% to 15% (SI Appendix Figure 7). Purely data-driven baselines performed notably worse in forecasting. The CNN–LSTM model produced MAEs exceeding 21% for both S and I, while the GBM achieved slightly 23 (a) (b) 

(c) (d) 

> Figure 3: Average learning MAEs for the (a) SIR dataset, (b) CR dataset, (c) gases dataset, and (d) CB dataset. Green bars represent the time-varying parameter model, and orange bars represent the fixed-parameter model. MAEs were computed for each variable across different noise levels or monitoring stations within each dataset and then averaged.

lower but still elevated errors of about 21% for both variables (Figure 4a). This performance gap persisted across increasing noise levels, where CNN–LSTM and GBM errors rose sharply relative to the mechanistic models (SI Appendix Figure 7). In the CR dataset, the time-varying parameter model accurately forecasted the dynamics of both the consumer ( C) and resource ( R) variables, achieving average MAEs of 3.9% and 24 5.4%, respectively (Figure 4b). The fixed-parameter model achieved comparable accuracy, with MAEs of 3.9% for C and 5.1% for R (Figure 4b). Across varying noise conditions, both mechanistic models maintained relatively low forecasting errors, generally between 2% and 7% (SI Appendix Figure 7). In contrast, the CNN–LSTM and GBM baselines showed substantially higher errors. The CNN–LSTM yielded MAEs of approximately 18.5% for C and 18.8% for R, while the GBM achieved MAEs of about 18.0% and 15.9%, respectively (Figure 4b). At every noise level, CNN-LSTM and GBM errors remained roughly three to five times larger than those of the mechanistic models (SI Appendix Figure 7). In the gases dataset, the time-varying model effectively forecasted the temporal behavior of 

CO 2 and CH 4, achieving MAEs of 10.4% and 12.0%, respectively (Figure 4c). In contrast, the fixed-parameter model showed higher errors for CH 4, with MAEs 24.5% (Figure 4c). Averaged across multiple stations, the time-varying approach maintained an overall MAE around 11%, whereas the fixed-parameter model ranged from 6% to 27% (SI Appendix Figure 7). The CNN–LSTM and GBM models performed substantially worse, with CNN–LSTM MAEs exceeding 25% for CH 4 and 35% for CO 2, and GBM errors remaining above 16% and 34%, respectively (Figure 4c). Across different stations, the mechanistic time-varying model remained comparatively stable, whereas CNN–LSTM and GBM errors varied between 23% to 34% (SI Appendix Figure 7). For the CB dataset, the time-varying parameter and fixed-parameter models achieved com-parable forecasting performance, with MAEs of 3.0% and 3.3%, respectively (Figure 4d). The CNN-LSTM baseline yielded a MAE of approximately 2.2%, outperforming the mechanistic models, whereas GBM achived MAE of around 10.8%. 

4.2.3 Optimal forecasting beyond cross-validation 

The expanding-window cross-validation approach did not always capture the most effective set of hyperparameters, namely the interval length and number of time-varying parameters, for the time-varying parameter model. For each dataset, there existed distinct configurations that produced superior predictive performance (SI Appendix Table 3, 4, 5, 6). In the SIR dataset, the optimal configuration achieved a MAE of 2.5% for the infected (I) population and 2.2% for the susceptible ( S) population (Figure 5a)–an improvement of approximately 8% compared to the hyperparameters of the expanding-window cross-validation setup. In the CR dataset, the model yielded MAEs of 1.3% for the consumer ( C) and 2.7% for the resource ( R) dynamics (Figure 5b), reflecting an enhancement of around 2%. Similarly, for the gases dataset, the optimal configuration produced MAEs of 5.7% for CH 4

and 2.6% for CO 2 (Figure 5c), marking an improvement of roughly 5% over the expanding-window cross-validation approach. Finally, in the CB dataset, the best-performing configu-ration resulted in an MAE of 0.5% (Figure 5d), which represents a 2.5% gain in predictive 25 (a) (b) 

(c) (d) 

Figure 4: Average forecasting MAEs using the expanding-window cross-validation approach for the (a) SIR dataset, (b) CR dataset, (c) gases dataset, and (d) CB dataset. Green bars represent the time-varying parameter model, orange bars represent the fixed-parameter model, red bars represent the CNN-LSTM model, and purple bars represent the GBM model. MAEs were computed for each variable across different noise levels or monitoring stations within each dataset and then averaged. 

accuracy relative to the expanding-window cross-validation method. Collectively, these results indicate that while the expanding-window cross-validation frame-26 work provides a robust baseline, fine-tuning the interval length and number of time-varying pa-rameters can lead to noticeable improvements in predictive precision across diverse dynamical systems. Sample forecasting plots demonstrate that the time-varying parameter model with opti-mal configuration consistently tracks the observed trajectories across all variables in the case studies, resulting in markedly improved forecasting performance (SI Appendix Figure 11). In contrast, the fixed-parameter model produces forecasts that only moderately match the time series of R, and CH 4, and fails to capture the evolving dynamics in the remaining variables (SI Appendix Figure 11). 27 (a) (b) 

(c) (d) 

Figure 5: Average forecasting MAEs by the time-varying parameter model based on optimal configuration and cross-validation for the (a) SIR dataset, (b) CR dataset, (c) gases dataset, and (d) CB dataset. Green bars represent the error by the model based on the cross-validation (CV) method, and pink bars represent the optimal config-uration forecasting error of the model. MAEs were computed for each variable across different noise levels or monitoring stations within each dataset and then averaged. 

# 5 Discussion 

We present a data-driven framework that couples sparse equation discovery with machine-learned parameter evolution to enable adaptive learning and forecasting of dynamical systems. The results show that allowing a subset of coefficients to vary over time improves both learn-28 ing fidelity and short-term predictive accuracy, particularly for non-stationary processes such as epidemic transmission and environmental gas emissions. Compared with fixed-coefficient sparse regression, the proposed model reduced forecasting MAE by 2-7% across most datasets and maintained training errors below 3%, indicating that temporal parameterization can en-hance model expressiveness without sacrificing interpretability. Traditional ML models are widely used in epidemiological and environmental prediction [63–65]. While these models often achieve strong point forecasts, their black-box structure lim-its mechanistic interpretation [14,31]. In our experiments, two common data-driven forecasters– LSTM-CNN and GBM–produced substantially higher forecasting MAEs and showed greater sensitivity to noise, indicating that such models alone may struggle to generalize when system mechanisms evolve, or external drivers are only partially informative. Rather than viewing this as a weakness of ML itself, this outcome highlights the importance of inductive structure: em-bedding ML-predicted evolving coefficients into discovered differential equations can improve both interpretability and forecasting stability [8, 9]. Our framework operationalizes this by coupling sparse equation learners with RF-predicted time-varying parameters, enabling adap-tive forecasts while preserving dynamical transparency. This integration is especially valuable for evolving natural systems-including influenza transmission, climate-forced ecological inter-actions, atmospheric gas emissions, and cyanobacteria dynamics-where fixed-coefficient or un-constrained ML forecasters may fail to capture transient or non-stationary responses [4,66–68]. The simulated SIR and CR systems provided a controlled comparison between intrinsically non-stationary and approximately stationary parameter regimes. While our framework recov-ered accurate dynamics for both systems, the forecasting benefit of time-varying coefficients was substantially more pronounced in SIR. This outcome is consistent with theoretical ex-pectations: CR trajectories, driven by nearly constant interaction strengths, can be reasonably approximated by fixed coefficients over short horizons, whereas SIR evolution is strongly gov-erned by non-stationary drivers-most critically, a temporally shifting transmission rate. Con-sequently, the fixed-coefficient sparse regression baseline exhibited large forecasting error for SIR, reinforcing the importance of temporal parameterization [8, 34]. Similar advantages of time-varying formulations have been reported in epidemiological and ecological models under seasonal forcing and external perturbations [69, 70]. In the empirical datasets, the time-varying model achieved substantially lower errors in both learning and forecasting the CO 2 and CH 4. The fixed-coefficient sparse model struggled es-pecially with forecasting CH 4, and the LSTM-CNN and GBM baselines struggled with both, reflecting the influence of seasonal cycles and emission fluctuations on atmospheric gas dy-namics. Because environmental systems shift continuously, capturing their behavior requires time-varying representations [71]. In the CB dataset, both models performed similarly during learning, suggesting that some systems can be approximated with fixed parameters; however, the time-varying model consistently outperformed in forecasting. Collectively, these results support a constructive conclusion: equation learners that incorporate time-varying parameters 29 yield more noise-robust and more accurate finite-horizon forecasts than fixed-coefficient sparse regression or standalone ML forecasters In noise-free settings, both sparse models achieved low forecasting MAE, confirming that fixed-coefficient representations can be adequate when dynamics are nearly stationary and data are clean. However, performance diverged under noise and transient dynamical regimes. The time-varying formulation remained stable across both SIR and CR learning intervals, while the fixed-coefficient model exhibited high variance in CR folds, producing substantially larger learning error. Interestingly, the fixed-coefficient model exhibited high learning MAE at certain CR noise levels but lower short-horizon prediction error, as its coefficients converged to long-run averages that smoothed local fluctuations. While such averaging can appear competitive over small forecast windows, it obscures derivative-level dynamics and limits regime-specific generalization. In contrast, learning coefficients on short intervals improves dynamical expres-siveness and reduces cross-fold error, but forecasting accuracy can still degrade if the prediction horizon is not well-aligned with the timescale of coefficient evolution. Forecast accuracy in our framework is conditioned on the predictive skill of the time-varying parameters, which in this study were estimated using a single RF model. Although RF effectively captures nonlinear feature-parameter relationships, forecasting models with evolv-ing dynamics may benefit from predictors with complementary inductive biases or stronger temporal adaptation [72, 73]. Neural networks, Bayesian networks, and hybrid learners have shown promise in modeling complex, noisy, and transient feature-response interactions [8, 9]. Future work should therefore explore multi-baseline or ensemble-based parameter predictors to improve generalization and reduce propagation drift under noise, particularly for rapidly evolving or seasonally forced systems [39, 74]. Although expanding-window cross-validation is standard for hyperparameter selection, it may not identify the best interval length or the most effective number of time-varying parame-ters, as it optimizes for average fold performance rather than segment-specific predictive skill. Our fold-specific evaluation revealed configurations that consistently outperformed the cross-validation-selected model–most notably in the SIR system, where optimal interval alignment reduced forecasting MAE by approximately 8% for both S and I, with additional 2-5% gains observed in the CR, gases, and CB datasets. We further observed that cross-validation error in-creased more sharply in the presence of noise, a known limitation of averaging-based validation that can obscure locally optimal configurations [75, 76]. These findings motivate future work on forecast-aware validation objectives, noise-weighted model selection, and adaptive interval tuning for transient or externally forced dynamics. Candidate terms were initialized using domain knowledge to ensure a well-posed and in-terpretable library. For simulated systems (SIR and CR), where the governing interactions are known, state variables were used directly as candidate functions. For empirical datasets (gases and cyanobacteria, CB), the library was expanded to include measured source variables and weather covariates anticipated to modulate dynamics. Although this design supports strong per-30 formance, further reductions in library size are often possible without degrading forecast skill. Causal selection strategies-such as restricting predictors to the Markov blanket in a Bayesian network [46]–can substantially lower dimensionality while preserving short-horizon accuracy. Because the cost of learning and predicting evolving coefficients scales with the number of active terms, library reduction also bounds the number of time-varying parameters, improving computational efficiency and robustness. Our framework readily accommodates such dataset-specific library adaptation, enabling future integration of automated causal or correlation-based term selection to further enhance scalability and generalization. Although the framework achieved strong learning and forecasting accuracy, the analysis also identifies several opportunities for improvement. First, expanding-window cross-validation, while standard, may miss locally optimal choices of interval length and time-varying parame-ter counts because it prioritizes average fold performance rather than horizon-specific forecast skill. Second, autoregressive ML forecasters exhibit error accumulation over longer horizons, especially under noise or rapid regime shifts, a challenge that can be mitigated through dynam-ical constraints and noise-aware validation objectives. Third, parameter forecasting depends on exogenous drivers (here, four weather covariates); limited variability or measurement error in these inputs can reduce coefficient-forecast reliability, motivating future work on adaptive or expanded driver sets. Fourth, the selection of time-varying parameters is based on top cor-relation (with the bias term always treated as time-varying), which may introduce selection bias and can fail when correlations are transient, noisy, or do not reflect true causal influence. Finally, the candidate library was initialized using prior system knowledge, which ensured in-terpretability but may exclude latent or unobserved drivers; future extensions should investigate automated causal or correlation-based library reduction and selection to enhance scalability and generalization. Collectively, these considerations highlight areas for careful model design and future methodological improvements. 

# Data availability 

All the data and codes used in this study are available in a Zenodo repository [77]. 

# Funding 

Hao Wang’s research was partially supported by the Natural Sciences and Engineering Re-search Council of Canada (Individual Discovery Grant RGPIN-2020-03911 and Discovery Ac-celerator Supplement Award RGPAS-2020-00090) and the Canada Research Chairs program (Tier 1 Canada Research Chair Award). Pouria Ramazi also acknowledges the support from an NSERC Discovery Grant. 31 Acknowledgement 

We would like to thank ILMEE members for providing valuable feedback. We polished spelling, grammar, and general style of this paper using ChatGPT [78]. Computational resources were provided by the Digital Research Alliance of Canada (formerly Compute Canada). 

# Competing interests 

We declare we have no competing interests. 

# References 

[1] Ruth E Baker, Jose-Maria Pena, Jayaratnam Jayamohan, and Antoine Jérusalem. Mech-anistic models versus machine learning, a fight worth fighting for the biological commu-nity? Biology letters , 14(5):20170660, 2018. [2] Yunduo Lan, Sung-Young Shin, and Lan K Nguyen. From shallow to deep: the evolu-tion of machine learning and mechanistic model integration in cancer research. Current Opinion in Systems Biology , 40:100541, 2025. [3] Martin-I Trappe and Ryan A Chisholm. A density functional theory for ecology across scales. Nature Communications , 14(1):1089, 2023. [4] Christina C Small, Sunny Cho, Zaher Hashisho, and Ania C Ulrich. Emissions from oil sands tailings ponds: Review of tailings pond parameters and emission estimates. Journal of Petroleum Science and Engineering , 127:490–501, 2015. [5] Sivakiruthika Natchimuthu, Balathandayuthabani Panneer Selvam, and David Bastviken. Influence of weather variables on methane and carbon dioxide flux from a shallow pond. 

Biogeochemistry , 119:403–413, 2014. [6] Anice C Lowen, Samira Mubareka, John Steel, and Peter Palese. Influenza virus trans-mission is dependent on relative humidity and temperature. PLOS pathogens , 3(10):e151, 2007. [7] Jeffrey Shaman and Melvin Kohn. Absolute humidity modulates influenza survival, trans-mission, and seasonality. Proceedings of the National Academy of Sciences , 106(9):3243– 3248, 2009. [8] Amit K Chakraborty, Hao Wang, and Pouria Ramazi. From policy to prediction: Assess-ing forecasting accuracy in an integrated framework with machine learning and disease models. Journal of Computational Biology , 31(11):1104–1117, 2024. 32 [9] Xiunan Wang, Hao Wang, Pouria Ramazi, Kyeongah Nah, and Mark Lewis. From policy to prediction: Forecasting covid-19 dynamics under imperfect vaccination. Bulletin of Mathematical Biology , 84(9):90, 2022. [10] Julio R Banga and Alejandro F Villaverde. Mechanistic dynamic modelling of biological systems: The road ahead. Current Opinion in Systems Biology , 42:100553, 2025. [11] Wenxiang Song, Shijie Jiang, Gustau Camps-Valls, Mathew Williams, Lu Zhang, Markus Reichstein, Harry Vereecken, Leilei He, Xiaolong Hu, and Liangsheng Shi. Towards data-driven discovery of governing equations in geosciences. Communications Earth & Environment , 5(1):589, 2024. [12] Steven L Brunton, Joshua L Proctor, and J Nathan Kutz. Discovering governing equations from data by sparse identification of nonlinear dynamical systems. Proceedings of the National Academy of Sciences , 113(15):3932–3937, 2016. [13] Samuel H Rudy, Steven L Brunton, Joshua L Proctor, and J Nathan Kutz. Data-driven discovery of partial differential equations. Science advances , 3(4):e1602614, 2017. [14] Shanwu Li, Eurika Kaiser, Shujin Laima, Hui Li, Steven L Brunton, and J Nathan Kutz. Discovering time-varying aerodynamics of a prototype bridge by sparse identification of nonlinear dynamical systems. Physical Review E , 100(2):022220, 2019. [15] Kai Fukami, Takaaki Murata, Kai Zhang, and Koji Fukagata. Sparse identification of nonlinear dynamics with low-dimensionalized flow representations. Journal of Fluid Me-chanics , 926:A10, 2021. [16] Jared L Callaham, Steven L Brunton, and Jean-Christophe Loiseau. On the role of nonlin-ear correlations in reduced-order modelling. Journal of Fluid Mechanics , 938:A1, 2022. [17] Jared L Callaham, Georgios Rigas, Jean-Christophe Loiseau, and Steven L Brunton. An empirical mean-field model of symmetry-breaking in a turbulent wake. Science Advances ,8(19):eabm4786, 2022. [18] Jean-Christophe Loiseau. Data-driven modeling of the chaotic thermal convection in an annular thermosyphon. Theoretical and Computational Fluid Dynamics , 34(4):339–365, 2020. [19] Jean-Christophe Loiseau and Steven L Brunton. Constrained sparse galerkin regression. 

Journal of Fluid Mechanics , 838:42–67, 2018. [20] Bartosz Prokop and Lendert Gelens. From biological data to oscillator models using sindy. Iscience , 27(4), 2024. 33 [21] Niall M Mangan, Steven L Brunton, Joshua L Proctor, and J Nathan Kutz. Inferring biological networks by sparse identification of nonlinear dynamics. IEEE Transactions on Molecular, Biological, and Multi-Scale Communications , 2(1):52–63, 2016. [22] Eurika Kaiser, J Nathan Kutz, and Steven L Brunton. Sparse identification of nonlinear dynamics for model predictive control in the low-data limit. Proceedings of the Royal Society A , 474(2219):20180335, 2018. [23] Xiaojun Wu, MeiLu McDermott, and Adam L MacLean. Data-driven model discovery and model selection for noisy biological systems. bioRxiv , pages 2024–10, 2024. [24] Bartosz Prokop and Lendert Gelens. Data-driven discovery of oscillator models using sindy: Towards the application on experimental data in biology. bioRxiv , pages 2023–08, 2023. [25] Antoine Sandoz, Verena Ducret, Georg A Gottwald, Gilles Vilmart, and Karl Perron. Sindy for delay-differential equations: application to model bacterial zinc response. Pro-ceedings of the Royal Society A , 479(2269):20220556, 2023. [26] Siddharth Prabhu, Srinivas Rangarajan, and Mayuresh Kothare. Data-driven discovery of sparse dynamical model of cardiovascular system for model predictive control. Comput-ers in Biology and Medicine , 166:107513, 2023. [27] Gregor Thiele, Arne Fey, David Sommer, and Jörg Krüger. System identification of a hysteresis-controlled pump system using sindy. In 2020 24th International Conference on System Theory, Control and Computing (ICSTCC) , pages 457–464. IEEE, 2020. [28] Paul Wulff, Nils Gräbner, and Utz von Wagner. Minimal model identification of drum brake squeal via sindy. Archive of Applied Mechanics , 94(10):3101–3117, 2024. [29] Hao Lee, Ruoning Ren, Yifei Qian, and Jacob Rosen. Energy reduction for wear-able pneumatic valve system with sindy and time-variant model predictive control. 

IEEE/ASME Transactions on Mechatronics , 2024. [30] Lin Guo, Xiaokai Yang, Zhonghua Zheng, Nicole Riemer, and Christopher W Tessum. Uncertainty quantification in reduced-order gas-phase atmospheric chemistry modeling using ensemble sindy. arXiv preprint arXiv:2407.09757 , 2024. [31] Javier Rubio-Herrero, Carlos Ortiz Marrero, and Wai-Tong Louis Fan. Modeling atmo-spheric data and identifying dynamics temporal data-driven modeling of air pollutants. 

Journal of Cleaner Production , 333:129863, 2022. 34 [32] Xiaokai Yang, Lin Guo, Zhonghua Zheng, Nicole Riemer, and Christopher W Tes-sum. Atmospheric chemistry surrogate modeling with sparse identification of nonlin-ear dynamics. Journal of Geophysical Research: Machine Learning and Computation ,1(2):e2024JH000132, 2024. [33] Samuel Rudy, Alessandro Alla, Steven L Brunton, and J Nathan Kutz. Data-driven identi-fication of parametric partial differential equations. SIAM Journal on Applied Dynamical Systems , 18(2):643–660, 2019. [34] Xiunan Wang and Hao Wang. Discrete inverse method for extracting disease transmission rates from accessible infection data. SIAM Journal on Applied Mathematics , 84(3):S336– S361, 2023. [35] Arthur Bousquet, William H Conrad, Said Omer Sadat, Nelli Vardanyan, and Youngjoon Hong. Deep learning forecasting using time-varying parameters of the sird model for covid-19. Scientific Reports , 12(1):3030, 2022. [36] Jie Long, AQM Khaliq, and Khaled M Furati. Identification and prediction of time-varying parameters of covid-19 model: a data-driven deep learning approach. Interna-tional Journal of Computer Mathematics , 98(8):1617–1632, 2021. [37] Juping Ji, Shohel Ahmed, and Hao Wang. A hybrid approach to study and fore-cast climate-sensitive norovirus infections in the usa. Journal of Theoretical Biology ,598:112007, 2025. [38] Pathairat Pastpipatkul and Panicha Subsai. Analysis of time-varying coefficients and fore-casting effects between greenhouse gas emissions and its determinants in thailand. In 

Applications of Optimal Transport to Economics and Related Topics , pages 591–604. Springer, 2024. [39] Amit K Chakraborty, Shan Gao, Reza Miry, Pouria Ramazi, Russell Greiner, Mark A Lewis, and Hao Wang. An early warning indicator trained on stochastic disease-spreading models with different noises. Journal of the Royal Society Interface , 21(217):20240199, 2024. [40] William Ogilvy Kermack and Anderson G McKendrick. A contribution to the mathemati-cal theory of epidemics. Proceedings of the Royal Society of London. Series A, Containing papers of a Mathematical and Physical character , 115(772):700–721, 1927. [41] Michael L Rosenzweig and Robert H MacArthur. Graphical representation and stabil-ity conditions of predator-prey interactions. The American Naturalist , 97(895):209–223, 1963. 35 [42] Peter E. Kloeden and Eckhard Platen. Numerical Solution of Stochastic Differential Equa-tions , volume 23 of Stochastic Modelling and Applied Probability . Springer, Berlin, Hei-delberg, 1992. [43] Network Map & Station Data - Wood Buffalo Environmental Association - wbea.org. 

https://wbea.org/data/network-map-station-data/ . [Accessed 06-11-2024]. [44] Alberta Energy Regulator. Alberta mineable oil sands plant statistics. https://www. aer.ca/data-and-performance-reports/statistical-reports/ st39 . [Accessed 01-23-2025]. [45] Christopher M Heggerud. cheggerud/cb-prediction: Nov_10_2023. https://doi. org/10.5281/zenodo.10109225 , 2023. [Accessed 24-01-2024]. [46] Christopher M Heggerud, Jingjing Xu, Hao Wang, Mark A Lewis, Ron W Zurawell, Charlie JG Loewen, Rolf D Vinebrooke, and Pouria Ramazi. Predicting imminent cyanobacterial blooms in lakes using incomplete timely data. Water Resources Research ,60(2):e2023WR035540, 2024. [47] George E. Uhlenbeck and Leonard S. Ornstein. On the theory of the brownian motion. 

Physical Review , 36(5):823–841, 1930. [48] Leo Breiman. Random forests. Machine Learning , 45:5–32, 2001. [49] Fabian Pedregosa et al. Scikit-learn: Machine learning in python. Journal of Machine Learning Research , 12:2825–2830, 2011. [50] Xingjian Shi et al. Convolutional lstm network: A machine learning approach for precip-itation nowcasting. Advances in Neural Information Processing Systems , 28, 2015. [51] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural Computa-tion , 9:1735–1780, 1997. [52] Shaojie Bai, J Zico Kolter, and Vladlen Koltun. An empirical evaluation of generic convo-lutional and recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271 ,2018. [53] Jerome H Friedman. Greedy function approximation: A gradient boosting machine. An-nals of Statistics , 29:1189–1232, 2001. [54] Martín Abadi et al. Tensorflow: A system for large-scale machine learning. Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation , pages 265–283, 2016. 36 [55] François Chollet. Keras. GitHub repository , 2015. https://keras.io .[56] Tom O’Malley et al. Keras tuner, 2019. https://keras.io/keras_tuner .[57] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 , 2014. [58] Lutz Prechelt. Early stopping-but when? Neural Networks: Tricks of the Trade , pages 55–69, 1998. [59] Gerald Teschl. Ordinary Differential Equations and Dynamical Systems . American Math-ematical Society, 2012. [60] Zeyu Zhang and Hayden Schaeffer. On the convergence of the sindy algorithm. Multiscale Modeling & Simulation , 17(3):948–972, 2019. [61] Thomas H. Gronwall. Note on the derivatives with respect to a parameter of the solutions of a system of differential equations. Annals of Mathematics , 20(4):292–296, 1919. [62] Walter Rudin. Real and Complex Analysis . McGraw–Hill, 3rd edition, 1987. [63] Abderrachid Hamrani, Abdolhamid Akbarzadeh, and Chandra A Madramootoo. Machine learning for predicting greenhouse gas emissions from agricultural soils. Science of The Total Environment , 741:140338, 2020. [64] Pi Guo, Tao Liu, Qin Zhang, Li Wang, Jianpeng Xiao, Qingying Zhang, Ganfeng Luo, Zhihao Li, Jianfeng He, Yonghui Zhang, et al. Developing a dengue forecast model using machine learning: A case study in china. PLOS neglected tropical diseases ,11(10):e0005973, 2017. [65] Esha Saha, Oscar Wang, Amit K Chakraborty, Pablo Venegas Garcia, Russell Milne, and Hao Wang. Dispersion based recurrent neural network model for methane monitoring in albertan tailings ponds. Journal of Environmental Management , 395:127748, 2025. [66] Anice C Lowen and John Steel. Roles of humidity and temperature in shaping influenza seasonality. Journal of virology , 88(14):7692–7695, 2014. [67] Angela N Laws. Climate change effects on predator–prey interactions. Current Opinion in Insect Science , 23:28–34, 2017. [68] Shih-Hsien Tseng, Pei Han Feng, and Thi Ha Trang Duong. Apply data science and feature selection techniques to predict carbon dioxide emissions in taiwan. Stochastic Environmental Research and Risk Assessment , pages 1–23, 2025. 37 [69] Adam Spannaus, Theodore Papamarkou, Samantha Erwin, and J Blair Christian. Infer-ring the spread of covid-19: the role of time-varying reporting rate in epidemiological modelling. Scientific Reports , 12(1):10761, 2022. [70] Xiaodong Song, Brett A Bryan, Auro C Almeida, Keryn I Paul, Gang Zhao, and Yin Ren. Time-dependent sensitivity of a process-based ecological model. Ecological Modelling ,265:114–123, 2013. [71] Melkior Ornik and Ufuk Topcu. Learning and planning for time-varying mdps using maximum likelihood estimation. Journal of Machine Learning Research , 22(35):1–40, 2021. [72] Nesreen K Ahmed, Amir F Atiya, Neamat El Gayar, and Hisham El-Shishiny. An em-pirical comparison of machine learning models for time series forecasting. Econometric reviews , 29(5-6):594–621, 2010. [73] Bushra Majeed Muter and Ayat Jasim Mohammed. The future of ai: Assessing the strengths and limitations of deep learning and machine learning. Wisdom Journal For Studies & Research , 4(06):348–374, 2024. [74] Amit K Chakraborty, Reza Miry, Russell Greiner, Mark A Lewis, Hao Wang, Tianyu Guan, and Pouria Ramazi. Deep learning for disease outbreak prediction: a parallel LSTM-CNN model. Journal of the Royal Society Interface , 22(229):20250046, 2025. [75] Stephen Bates, Trevor Hastie, and Robert Tibshirani. Cross-validation: what does it es-timate and how well does it do it? Journal of the American Statistical Association ,119(546):1434–1445, 2024. [76] Christoph Bergmeir, Rob J Hyndman, and Bonsoo Koo. A note on the validity of cross-validation for evaluating autoregressive time series prediction. Computational Statistics & Data Analysis , 120:70–83, 2018. [77] Amit K. Chakraborty. Data and codes: Turning mechanistic models into forecasters by using machine learning, February 2026. [78] OpenAI. Chatgpt, 2023. Large language model used for proofreading assistance. 

# SI Appendix 

38 (a) 

(b) 

(c) 

Figure 6: Average learning MAE across different noise in (a) SIR dataset, (b) CR dataset, and (c) gases dataset. 

39 (a) 

(b) 

(c) 

Figure 7: Average forecasting MAE across different noise in (a) SIR dataset, (b) CR dataset, and (c) gases dataset. 

40 (a) 

(b) 

Figure 8: Simulations of a) CR model and b) SIR model. 

41 (a) 

(b) 

Figure 9: Time series of a) gases dataset and b) CB dataset. 

42 Figure 10: Learning comparison between the time-varying parameter and fixed parameter model across four datasets. First and third columns are learning made by the time-varying parameter model, while the second and fourth columns are learning made by the fixed parameter model. 

43 Figure 11: Forecasting comparison between the time-varying parameter and fixed parameter model across four datasets. First and third columns are predictions made by the time-varying parameter model, while the second and fourth columns are predictions made by the fixed parameter model. 

44 Table 3: Number of time-varying parameters, interval lengths, and MAEs across different test folds using the expanding-window cross-validation (CV) method and the optimal configuration (OC) for each noise setting in the CR model simulations. 

Dataset Noise Variable Fold CV: Interval length CV: Num. of time varying params. CV: MAE test OC: Interval length OC: Num. of time varying params. OC: MAE test CR 0.0 C

1 28 1 1 21 2 0.29 2 28 1 2.02 14 2 0.59 3 28 1 0.93 7 5 0.46 4 28 1 0.1 7 1 0.07 5 28 1 0.21 21 1 0.08 

R

1 28 1 5.22 28 2 1.72 2 28 1 3.79 21 2 2.16 3 28 1 6 14 4 1.07 4 28 1 1.56 7 1 0.16 5 28 1 1.62 14 1 0.16 

0.5 C

1 21 1 2.75 28 1 2.42 2 21 1 5.54 14 2 3.86 3 21 1 1.39 21 6 0.72 4 21 1 2.97 28 1 2.77 5 14 1 4.06 28 2 2.85 

R

1 21 1 1.55 28 1 1.45 2 21 1 5.53 14 4 4.01 3 21 1 1.85 28 4 0.72 4 21 1 15.28 7 2 8.01 5 14 1 4.91 7 2 3.63 

1.0 C

1 28 2 3.1 28 6 1.55 2 28 2 4.48 21 5 2.9 3 28 2 2.38 21 2 1.54 4 28 2 1.06 14 6 0.55 5 28 2 19.81 14 4 0.95 

R

1 28 2 2.77 28 1 2.69 2 28 2 16.36 21 6 10.66 3 28 2 2.3 28 2 2.3 4 28 2 3.5 28 6 1.23 5 28 2 14.45 21 4 3.06 

1.5 C

1 14 1 3.94 7 5 1.18 2 14 1 3.46 21 3 1.04 3 14 1 9.69 7 6 1.45 4 14 1 6.17 28 2 2.69 5 28 1 5.04 14 3 1.08 

R

1 14 1 2.84 21 4 1.54 2 14 1 4.03 14 6 1.62 3 14 1 5.8 21 6 5.39 4 14 1 8.27 14 6 3.62 5 28 1 3.35 28 3 1.21 

2.0 C

1 14 2 1.34 21 1 0.94 2 14 2 4.72 7 5 0.62 3 14 2 3.87 28 2 0.59 4 14 2 1.42 7 1 0.83 5 14 2 5.71 14 3 1.45 

R

1 14 2 6.57 21 6 2.97 2 14 2 2.86 14 5 1.18 3 14 2 10.22 14 3 6.43 4 14 2 1.07 28 5 0.43 5 14 2 4 14 3 0.74 

45 Table 4: Number of time-varying parameters, interval lengths, and MAEs across different test folds using the expanding-window cross-validation (CV) method and the optimal configuration (OC) for each noise setting in the SIR model simulations. 

Dataset Noise Variable Fold CV: Interval length CV: Num. of time varying params. CV: MAE test OC: Interval length OC: Num. of time varying params. OC: MAE test SIR 0.0 I

1 14 6 7.81 28 5 3.42 2 14 6 16.78 28 6 1.67 3 28 6 11.43 28 1 1.78 4 28 6 0.66 28 6 0.66 5 28 6 6.49 28 6 6.49 

S

1 14 6 8.66 28 6 3.61 2 14 6 17.54 28 6 1.26 3 28 6 11 28 1 1.8 4 28 6 1.41 7 1 0.74 5 28 6 8.47 21 4 4.03 

1.0 I

1 21 6 7.83 28 5 3.2 2 21 6 10.75 28 6 1.57 3 28 6 13.98 14 6 2.24 4 21 6 25.82 21 1 0.48 5 28 6 5.08 14 5 1.08 

S

1 21 6 8.08 14 2 1.75 2 21 6 11.88 28 6 0.73 3 28 6 13.2 28 1 2.94 4 21 6 25.76 21 1 0.47 5 28 6 3.69 21 6 3.62 

2.0 I

1 21 6 11.43 14 3 4.16 2 14 3 17.39 28 5 4.06 3 14 3 9.05 28 1 1.28 4 14 3 2.45 7 6 0.26 5 14 3 9.33 21 5 1.42 

S

1 21 6 10.75 7 2 3.16 2 14 3 13.36 21 5 3.11 3 14 3 2.02 28 2 0.79 4 14 3 14.36 7 6 0.31 5 14 3 10.89 21 6 4.29 

3.0 I

1 21 6 12.46 14 4 2.87 2 21 6 12.66 28 4 1.13 3 28 6 7.75 28 1 1.31 4 28 6 2.62 28 5 1.13 5 28 6 8.35 7 6 4.47 

S

1 21 6 10.3 28 4 1.74 2 21 6 12.48 14 4 0.57 3 28 6 8 28 1 1.88 4 28 6 2.48 14 6 0.7 5 28 6 16.5 28 4 5.17 

4.0 I

1 14 1 10.01 14 3 3.05 2 21 6 9.14 28 5 8.06 3 21 6 6.09 28 1 2.71 4 21 6 6.67 28 2 1.32 5 21 6 14.84 14 6 2.46 

S

1 14 1 10.13 21 2 2.48 2 21 6 5.88 21 3 1.19 3 21 6 3.8 21 5 3.07 4 21 6 6.15 21 5 2.38 5 21 6 13.35 14 5 3.97 

46 Table 5: Number of time-varying parameters, interval lengths, and MAEs across different test folds using the expanding-window cross-validation (CV) method and the optimal configuration (OC) for each station in the gases dataset. 

Dataset Station Variable Fold CV: Interval length CV: Num. of time varying params. CV: MAE test OC: Interval length OC: Num. of time varying params. OC: MAE test 

gases AMS1 CH 4

1 7 3 5.68 21 4 1.38 2 7 3 37 14 3 1.52 3 14 3 5.07 14 15 1.13 4 14 3 10.58 7 36 1.02 5 14 3 4.64 14 81 1.27 CO 2

1 7 3 12.56 7 28 3.02 2 7 3 10.91 14 8 2.61 3 14 3 7.99 7 3 2.48 4 14 3 6.47 14 5 2.89 5 14 3 12.54 21 23 2.46 AMS18 CH 4

1 7 96 24.6 7 81 23.78 2 7 99 4.94 7 5 4.51 3 7 99 15.28 14 95 14.08 4 7 99 6.56 28 2 4.61 5 7 99 5.57 7 75 4CO 2

1 7 96 11.16 7 3 2.65 2 7 99 10.9 7 7 1.63 3 7 99 5.75 14 12 3.43 4 7 99 12.2 7 6 3.05 5 7 99 13.86 7 40 1.47 

Table 6: Number of time-varying parameters, interval lengths, and MAEs across different test folds using the expanding-window cross-validation (CV) method and the optimal configuration (OC) for each station in the Cyanobacteria dataset. 

Dataset Region Variable Fold CV: Interval length CV: Num. of time varying params. CV: MAE test OC: Interval length OC: Num. of time varying params. OC: MAE test 

CB AB CB cell 

1 20 103 2.26 15 82 0.07 2 15 55 0.91 25 65 0.29 3 25 64 5.46 25 106 1.74 4 25 64 3.5 15 58 0.26 5 25 60 2.88 10 69 0.15 

47