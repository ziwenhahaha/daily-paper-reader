---
title: Rational ANOVA Networks
title_zh: 有理 ANOVA 网络
authors: "Jusheng Zhang, Ningyuan Liu, Qinhan Lyu, Jing Yang, Keze Wang"
date: 2026-02-03
pdf: "https://arxiv.org/pdf/2602.04006v1"
tags: ["keyword:SR", "query:SR"]
score: 6.0
evidence: 可解释的函数分解和有理逼近，适用于类符号函数发现
tldr: 针对深度神经网络中固定非线性激活函数限制可解释性，以及样条函数模型（如KAN）计算效率低且不稳定的问题，本文提出Rational-ANOVA Network (RAN)。该架构结合了函数ANOVA分解与Padé式有理逼近，通过带正分母约束的可学习有理单元参数化主效应和稀疏成对交互。RAN在保持低阶交互偏差以提升数据效率和可解释性的同时，显著增强了数值稳定性和外推能力，在视觉分类等任务中表现优于同规模的MLP和KAN。
motivation: 旨在解决固定激活函数缺乏灵活性以及现有可学习激活模型（如KAN）在计算效率和数值稳定性方面的不足。
method: 结合函数ANOVA分解与Padé有理逼近，利用强制正分母的可学习有理单元来捕捉主效应和稀疏的成对交互。
result: 在受控函数基准和CIFAR-10视觉任务中，RAN在相同参数和计算预算下达到了优于MLP和可学习激活基准的性能与吞吐量。
conclusion: RAN提供了一种兼具高稳定性、强解释性和优异外推能力的通用架构，是建模低阶交互的高效方案。
---

## 摘要
深度神经网络通常将非线性视为固定的原语（例如 ReLU），这限制了可解释性以及对所诱导函数类的控制粒度。虽然最近的加性模型（如 KAN）尝试使用样条函数来解决这一问题，但它们往往面临计算效率低下和边界不稳定的困扰。我们提出了有理 ANOVA 网络（RAN），这是一种基于函数式 ANOVA 分解和 Padé 式有理逼近的基础架构。RAN 将 f(x) 建模为主效应和稀疏成对交互作用的组合，其中每个组件都由一个稳定的、可学习的有理单元进行参数化。关键在于，我们强制分母严格为正，从而避免了极点和数值不稳定性，同时比多项式基函数更有效地捕捉剧烈转变和近奇异行为。这种 ANOVA 结构为数据效率和可解释性提供了显式的低阶交互偏差，而有理参数化则显著提高了外推能力。在参数和计算预算匹配的情况下，通过受控函数基准测试和视觉分类任务（如 CIFAR-10），RAN 的表现达到或超过了参数匹配的 MLP 和可学习激活基准模型，并具有更好的稳定性和吞吐量。代码可在 https://github.com/jushengzhang/Rational-ANOVA-Networks.git 获取。

## Abstract
Deep neural networks typically treat nonlinearities as fixed primitives (e.g., ReLU), limiting both interpretability and the granularity of control over the induced function class. While recent additive models (like KANs) attempt to address this using splines, they often suffer from computational inefficiency and boundary instability. We propose the Rational-ANOVA Network (RAN), a foundational architecture grounded in functional ANOVA decomposition and Padé-style rational approximation. RAN models f(x) as a composition of main effects and sparse pairwise interactions, where each component is parameterized by a stable, learnable rational unit. Crucially, we enforce a strictly positive denominator, which avoids poles and numerical instability while capturing sharp transitions and near-singular behaviors more efficiently than polynomial bases. This ANOVA structure provides an explicit low-order interaction bias for data efficiency and interpretability, while the rational parameterization significantly improves extrapolation. Across controlled function benchmarks and vision classification tasks (e.g., CIFAR-10) under matched parameter and compute budgets, RAN matches or surpasses parameter-matched MLPs and learnable-activation baselines, with better stability and throughput. Code is available at https://github.com/jushengzhang/Rational-ANOVA-Networks.git.