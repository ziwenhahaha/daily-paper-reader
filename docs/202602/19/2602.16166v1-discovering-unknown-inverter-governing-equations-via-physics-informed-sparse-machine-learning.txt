Title: Discovering Unknown Inverter Governing Equations via Physics-Informed Sparse Machine Learning

URL Source: https://arxiv.org/pdf/2602.16166v1

Published Time: Thu, 19 Feb 2026 01:28:07 GMT

Number of Pages: 13

Markdown Content:
> IEEE TRANSACTIONS ON POWER ELECTRONICS 1

# Discovering Unknown Inverter Governing Equations via Physics-Informed Sparse Machine Learning 

Jialin Zheng, Member, IEEE, Ruhaan Batta, Student Member, IEEE, 

Zhong Liu, Student Member, IEEE, Xiaonan Lu, Member, IEEE 

Abstract —Discovering the unknown governing equations of grid-connected inverters from external measurements holds sig-nificant attraction for analyzing modern inverter-intensive power systems. However, existing methods struggle to balance the identification of unmodeled nonlinearities with the preservation of physical consistency. To address this, this paper proposes a Physics-Informed Sparse Machine Learning (PISML) frame-work. The architecture integrates a sparse symbolic backbone to capture dominant model skeletons with a neural residual branch that compensates for complex nonlinear control logic. Mean-while, a Jacobian-regularized physics-informed training mech-anism is introduced to enforce multi-scale consistency including large/small-scale behaviors. Furthermore, by performing sym-bolic regression on the neural residual branch, PISML achieves a tractable mapping from black-box data to explicit control equations. Experimental results on a high-fidelity Hardware-in-the-Loop platform demonstrate the framework’s superior performance. It not only achieves high-resolution identification by reducing error by over 340 times compared to baselines but also realizes the compression of heavy neural networks into compact explicit forms. This restores analytical tractability for rigorous stability analysis and reduces computational complexity by orders of magnitude. It also provides a unified pathway to convert structurally inaccessible devices into explicit mathemat-ical models, enabling stability analysis of power systems with unknown inverter governing equations. 

Index Terms —Grid-forming inverter, system identification, stability analysis, neural network, physics-informed machine learning, sparse regression. 

I. I NTRODUCTION 

# THE rapid proliferation of inverter-based resources (IBRs) is fundamentally reshaping the landscape of modern power systems [1], [2]. As conventional synchronous machines are increasingly replaced by software-controlled power elec-tronic converters, grid dynamics are now dominated by embed-ded control algorithms rather than intrinsic physical properties such as mechanical or electromagnetic coupling [3], [4]. A critical challenge arises because both grid-following (GFL) and grid-forming (GFM) inverters typically operate with pro-prietary and closed-source control logic, essentially black boxes to grid operators [5], [6]. This structural inaccessibility jeopardizes the effectiveness of traditional stability assessment paradigms, which rely on explicit state-space equations to analyze eigenvalue trajectories and damping characteristics [7]. As a result, a crucial modeling gap is rapidly widening: while inverter penetration continues to increase, theoretical tools for understanding and predicting their dynamic behaviors lag significantly behind [8], [9]. With the deployment of advanced sensing technologies such as phasor measurement units (PMUs) and high-bandwidth impedance measurement systems, massive amounts of high-resolution dynamic data have become available, offering new opportunities to uncover inverter dynamics from observations [10], [11]. However, most existing studies still focus on local linear impedance identification [12]. These methods have evolved from traditional frequency sweeping to real-time signal injection (e.g., chirp signals or pseudo-random binary sequences) and can handle complex scenarios such as parallel inverter configurations through sophisticated decoding networks [13], [14]. While these approaches are effective in fitting observed data, they inherently assume a locally linear time-invariant (LTI) physical structure and thus fail to capture the global consistency of the underlying nonlinear dynamics [15]. As a result, there are still challenges for critical analytical tasks beyond impedance analysis, such as eigenvalue-based stability assessment or transient stability analysis [16]. For grid operators seeking a comprehensive understanding of stability boundaries, relying solely on black-box impedance predictors could be insufficient when large-signal dynamics need to be considered. Consequently, there is a strong need for a data-driven approach capable of discovering explicit control equations governing the system dynamics [17]. From a broader scientific perspective, automatically discov-ering the governing equations of nonlinear systems from exter-nal measurements remains a major interdisciplinary challenge [18]. Early approaches such as equation-free modeling and empirical dynamic modeling established foundational ideas but often encountered difficulties in scalability and robustness when dealing with high-dimensional and noisy data [19]. With the development of symbolic regression and genetic program-ming, researchers began to directly search the mathematical expression space to reconstruct differential equations [20]. In the field of power and energy systems, symbolic regression has shown potential for identifying battery degradation pro-cesses [21] and extracting reduced-order grid dynamics [22]. However, symbolic regression implicitly relies on the strong assumption that a predefined function library is sufficiently complete to describe the unknown physics. This assumption often fails in high-dimensional multi-time-scale control archi-tectures, where the search space grows exponentially and the sensitivity to noise increases significantly [23]. The emergence of Scientific Machine Learning (SciML) introduced a new paradigm by incorporating physical priors into the learning process. Graph Neural Networks (GNNs) have been adopted to capture the topological structure and component interactions within complex power electronic and power system [24]. By explicitly modeling the connectivity, these methods offer scalability to large-scale networks that is difficult to achieve with standard dense layers [25], [26]. Meanwhile, Neural Ordinary Differential Equations (Neural ODEs) and Universal Differential Equations (UDEs) represent  

> arXiv:2602.16166v1 [eess.SY] 18 Feb 2026 IEEE TRANSACTIONS ON POWER ELECTRONICS 2

system dynamics through differentiable neural architectures [27], [28]. These methods have been used to characterize battery thermal behavior, learn grid frequency responses, and predict dynamic features of power electronic devices [15], [29]–[31].Although these approaches are expressive in repre-sentation, purely neural methods often prioritize data fitting, rather than obey physical consistency constraints and guaran-tee physical validity [32]. This may result in models that are accurate in prediction but physically inconsistent in structure. Physics-Informed Neural Networks (PINNs) address this issue by integrating physical laws such as energy conservation into the loss function, thereby enhancing generalization under data-scarce conditions [33]–[35]. However, such constraint enforcement does not necessarily yield interpretable, explicit physical equations, and the learned representations still prove difficult to understand. In summary, the evolution from impedance identification to symbolic regression and SciML represents a continuous effort to bridge the gap between black-box nonlinear systems and interpretable physical modeling. However, each paradigm faces inherent limitations due to assumptions regarding the physical consistency of unknown dynamics [36]. Impedance identification assumes local linearity and ignores global non-linear behavior. Symbolic regression assumes a closed-form function structure and struggles with complexity. Neural net-works (NNs) assume data sufficiency and often sacrifice inter-pretability [37]. Consequently, existing methods frequently fail to maintain consistency across different dynamic scales, lead-ing to nonphysical behaviors such as inaccurate eigenvalues. Therefore, there is an urgent need for a unified framework that ensures nonlinear expressiveness, multi-scale physical consistency, and interpretability. To overcome these limitations, this paper proposes aPhysics-Informed Sparse Machine Learning (PISML) frame-work that defines the equation discovery problem for inverter-based systems. The central idea of PISML is a co-design of interpretability and expressiveness, achieved through ahybrid symbolic–neural structure. The framework decomposes inverter dynamics into a sparse symbolic backbone, capturing analytically tractable physical laws, and a neural residual NN, modeling complex nonlinearities. Beyond this architectural integration, PISML introduces a physics-informed multi-scale consistency training mechanism that enforces agreement be-tween large-signal trajectory behavior and small-signal per-turbation responses. This derivative-level constraint grounds the learned model in physically meaningful Jacobian struc-tures, ensuring that both global and local dynamics remain consistent with the underlying physics. Finally, a symbolic regression process extracts explicit closed-form equations from the trained neural model, bridging the gap between black-box data fitting and analytical modeling. Through this unified formulation, PISML enables interpretable, physically consis-tent, and analytically tractable discovery of inverter control equations directly from measurement data. The main contributions of this paper are summarized as follows: 1) Hybrid neural–symbolic architecture : Integrates a sparse symbolic backbone with neural residual dynamics. This 

> Fig. 1. Problem formulation for identifying grid-connected inverter dynamics.

design decouples dominant physical laws from unmod-eled nonlinearities, balancing explicit interpretability with high-fidelity representation. 2) Multi-Scale Dynamic Consistency : Introduces a physics-informed training strategy via perturbation-response con-straints. This ensures the learned model simultaneously achieves accurate large-signal trajectory reconstruction and physically valid small-signal linearization properties. 3) Interpretable Explicit Discovery : Achieves fidelity-preserving compression of the learned dynamics, transforming over-parameterized neural networks into lightweight symbolic equations. This restores analytical tractability for theoretical stability derivation. The remainder of this paper is organized as follows. Section II presents the problem formulation for governing equation discovery in power electronic systems. Section III introduces the proposed PISML framework. Section IV provides case studies for validation. Finally, Section V concludes the paper. II. P ROBLEM FORMULATION 

A. Dynamics of Grid-connected Inverter 

The dynamic behavior of a grid-connected inverter is gov-erned by an intricate interaction between its physical power stage and its embedded digital control system. As shown in Fig. 1, the inverter dynamics can be described as a continuous-time nonlinear system, in which the time evolution of the state vector x(t) ∈ Rn is defined by a vector field f (·):

˙x(t) = f (x(t), u (t)) = 

 fphy (xphy , x ctrl , u )

fctrl (xphy , x ctrl , u ref )



(1) where xphy represents the physical states (e.g., inductor cur-rents and capacitor voltages), while xctrl denotes the internal control states (e.g., integrator outputs, phase angles of phase-locked loops or virtual oscillators). The term u(t) corresponds to the external excitation such as the grid voltage at the point of common coupling (PCC), and uref denotes internal control references. The subsystem fphy is derived from Kirchhoff’s circuit laws and typically exhibits an analytical and low-order structure. In contrast, the control subsystem fctrl embodies the algorith-mic logic of control strategies, such as grid-following (GFL) or grid-forming (GFM), introducing significant nonlinearities through coordinate transformations, synchronization mecha-nisms, saturation effects, and power computation loops, among other specific control functions. 

B. The Modeling Gap in Traditional Methods 

In real-world applications, a significant information asym-metry persists between inverter manufacturers and system op-erators. While the physical stage dynamics fphy are governed by established circuit laws, the control structure fctrl remains IEEE TRANSACTIONS ON POWER ELECTRONICS 3 

> Fig. 2. Overview of the Physics-Informed Symbolic Machine Learning (PISML) framework. The approach combines a sparse symbolic backbone with a residual neural ODE to capture unknown dynamics. The model is trained using a composite physics-informed loss function ( Ltotal ), followed by a symbolic regression step to extract an explicit, interpretable ODE representation from the neural residue.

strictly proprietary, effectively constituting a black box. Con-ventional data-driven approaches, particularly impedance iden-tification techniques, typically linearize the system trajectory around a specific operating point x0, yielding the approximate form: 

∆ ˙ x ≈ A(x0)∆ x + B(x0)∆ u (2) where A(x0) = ∂f ∂x x0

denotes the Jacobian matrix at the equi-librium. While such impedance-based linearization methods are adequate for local small-signal analysis, they inherently cannot capture the global nonlinear behavior of the vector field f (x). Consequently, these methods prove insufficient for evaluating large-signal dynamics, such as transient stabil-ity assessment, fault ride-through capabilities, and scenarios where source-side intermittence drives the system far from its nominal operating point. The challenge, therefore, extends beyond simple parameter estimation; it demands discovering the explicit functional structure of the governing nonlinear dynamics directly from measurement data. 

C. Mathematical Formulation of the Equation Discovery 

The central objective of this study is to discover the ex-plicit governing equations of an inverter control system from measurement data, as shown in Fig. 1. Given a data set 

D = {tk, x (tk), u (tk)}Kk=0 , (3) comprising discrete measurements of system trajectories, the goal is to identify a model ˆf (x, u ) that satisfies two key requirements. First, it must minimize the trajectory reconstruction error in euclidean norm between the model-predicted and measured states: 

min 

> ˆf

X

> k

Z tk

> t0

ˆf (x(τ ), u (τ )) dτ − xmeas (tk)

> 22

(4) Second, ˆf must be expressed in symbolic closed form to reflect the underlying physical laws. This renders the problem ill-posed, as multiple candidate functions may exhibit identical data-fitting accuracy while representing distinct local Jacobian structures. Therefore, the discovered model must preserve multi-scale dynamic consistency, reproducing both the global nonlinear response and the local linearization characteristics of the true inverter system. III. M ETHODOLOGY : T HE PHYSICS -I NFORMED SPARSE 

MACHINE LEARNING (PISML) F RAMEWORK 

To overcome the trade-off between the interpretability of symbolic regression and the representational power of NNs, this work introduces the PISML framework. As shown in Fig. 2, PISML integrates a hybrid neural-symbolic architecture with a physics-informed multi-scale learning mechanism to enable interpretable model discovery. 

A. Physics-Informed Sparse Symbolic Regression 

The foundation of the proposed approach lies in the parsi-mony hypothesis of power electronic systems [20]. Although the state trajectories of grid-connected inverters exhibit com-plex nonlinear dynamics, their governing equations are not arbitrary mathematical combinations. Instead, they are strictly constrained by electromagnetic principles (e.g., Kirchhoff’s laws) and engineered control architectures (e.g., PI regula-tors). This implies that within the high-dimensional space of potential functions, the true vector field f (x) is composed of a sparse linear combination of a limited set of specific physical interaction terms. To explicitly extract this physical structure from data, this paper proposes a matrix-based sparse regression framework, as shown in Fig. 3. First, the state snapshots sampled at time instants t1, t 2, . . . , t K and their time derivatives are arranged into data matrices X ∈ RK×n and 

˙X ∈ RK×n:

X =



x(t1)T

...

x(tK )T

 , ˙X =



˙x(t1)T

...

˙x(tK )T

 (5) Traditional symbolic regression approaches often employ generic polynomial libraries to approximate nonlinearities, which inevitably leads to over-parameterization and loss of interpretability [20]. To address this, the proposed approach discards generic basis functions and proposes a Domain-Specific Physics-Informed Library construction strategy. A candidate function library Θ(X) is constructed as the direct sum of physical constitutive terms Θphy and control functional terms Θctrl :

Θ(X) = Θphy (X) Θctrl (X) (6) where the physical sub-library Θphy comprises the linear state basis describing the fundamental characteristics of the circuits (e.g., RLC filter networks), covering basic state variables such IEEE TRANSACTIONS ON POWER ELECTRONICS 4     

> Fig. 3. Schematic illustration of the Sparse Identification of Nonlinear Dynamics. The method constructs a library of candidate nonlinear functions Θ(X)
> and employs sparse regression to select the active coefficients Ξthat best describe the time-series data derivatives ˙X, enabling the reconstruction of the underlying governing equations.

as currents idq and voltages vdq . Within the control sub-library 

Θctrl , two critical nonlinear elements are introduced: the bilinear active and reactive power calculation terms Θpower ,defined as p = vdid + vq iq and q = vq id − vdiq , which are essential for capturing GFM or GFL control logic; and the integral state variables ξ = R (xref − x)dt , representing the dynamics of integral controllers. Consequently, the augmented feature library is explicitly formulated as: 

Θ(x) = 

h

1, x 1, . . . , x n

| {z }

> Linear/Physical

, ξ 1, . . . , ξ m

| {z }

> Integral Control

, v did + vq iq

| {z }

> P

, v q id − vdiq

| {z }

> Q

i

(7) Based on this physics-informed library, the sparse symbolic backbone, fsparse (x), postulates that the time derivative ma-trix ˙X can be approximated by a sparse linear combination of these library columns: 

fsparse (x, u ) = ˙X ≈ Θ(X)Ξ (8) where Ξ = [ ξ1, ξ 2, . . . , ξ n] ∈ Rp×n is the coefficient matrix. Each column ξk determines the active terms in the dynamic equation for the k-th state variable. The identification problem is thus cast as a sparse optimization problem: 

Ltraj (Ξ) = min 

> Ξ

12 ∥ ˙X − Θ(X)Ξ ∥2 

> F

+ λ∥Ξ∥1 (9) The ℓ1 regularization term functions as a physical topology selector. By penalizing the cardinality of non-zero terms, this objective function compels the model to discard redundant terms unnecessary for describing the system dynamics. Con-sequently, the resulting non-zero coefficients do not merely achieve accurate data reproduction but explicitly reveal the true physical interconnections and control law structures within the system. 

B. Neural ODE for Residual Dynamics 

While the physics-informed sparse backbone effectively captures the dominant structural dynamics, constructing a truly exhaustive library that encompasses all potential proprietary control logic is practically infeasible and would impose pro-hibitive data requirements due to the combinatorial explo-sion of candidate terms. Consequently, the symbolic model 

fsparse (x, u ) (Eq. 8) serves as a low-order approximation. The discrepancy between the true system dynamics and this sparse backbone is defined as the residual component: 

˙xresid = ˙ xtrue − fsparse (x, u ) (10) This residual term ˙xresid embodies critical high-frequency nonlinear behaviors and unmodeled control logic. To model this residual dynamics, conventional data-driven approaches typically employ discrete-time sequence models, such as Recurrent Neural Networks (RNNs). Fundamentally, these methods learn a discrete mapping xk 7 → xk+1 . However, this formulation is intrinsically bound to the training sampling interval ∆t, lacking the continuous-time definition required for variable step-size integration. Consequently, such models induce discretization errors and fail to interface with standard adaptive ODE solvers [15]. To address this, the proposed framework bypasses the dis-crete mapping and directly parameterizes the continuous-time differential equation of the residual using a neural network. As illustrated in Fig. 4, the system states x and external inputs u

are fed in parallel into both the sparse symbolic module and the neural network module. Specifically, the residual approximator 

N (x, u ; θN N ) is instantiated as a deep Multilayer Perceptron (MLP). Letting z = [ xT , u T ]T denote the concatenated in-IEEE TRANSACTIONS ON POWER ELECTRONICS 5 

> Fig. 4. Architecture of the proposed Neural Residual ODE. This module compensates for the dynamics gap in the sparse backbone by superimposing a learnable neural vector field. The merged derivatives are integrated via a shared ODE solver, enabling direct end-to-end training using trajectory data.

put vector, the layer-wise forward propagation is rigorously defined as: 



h(0) = zh(l) = σ(W (l)h(l−1) + b(l)), l = 1 , . . . , L − 1˙xresid = W (L)h(L−1) + b(L)

(11) where h(l) represents the hidden state vector of the l-th layer, and σ(·) denotes the element-wise nonlinear activation function. The set θN N = {W (l), b (l)}Ll=1 constitutes the learnable weights and biases parameters, with the final output layer mapping directly to the unmodeled residual ˙xresid .The total system dynamics are thus formulated as the superposition of the symbolic vector field and the neural residual vector field: 

˙x(t) = fsparse (x, u ) + N (x, u ; θN N ). (12) This hybrid vector field constitutes a complete ODE system that can be seamlessly embedded into any standard ODE solver. Consequently, the estimated state ˆx(tk) at any time instant tk is obtained by numerically integrating the combined dynamics from the initial condition x(t0):

ˆx(tk) = x(t0) + 

Z tk

> t0

(Θ( x(τ ))Ξ + N (x(τ ); u(τ ); θN N )) dτ 

(13) This formulation implies that the model is no longer bound by a fixed discrete step size; instead, it adaptively adjusts the integration step dτ during both training and inference to match the stiffness of the system dynamics, thereby accurately capturing fast transient processes. During training, the objective was to minimize the discrep-ancy between the solver-predicted trajectories and the ground-truth measurements. To this end, the trajectory reconstruction loss function Ltraj is defined as: 

Ltraj = 1

K

> K

X

> k=1

∥ˆx(tk) − xmeas (tk)∥22 (14) where K denotes the total number of sampling points in the trajectory, xmeas (tk) represents the measured system state at time tk, and ∥ · ∥ 2 denotes the euclidean norm. To enable scalable training, the adjoint sensitivity method [27] is leveraged. This approach computes gradients by solving an augmented ODE backward in time, thereby decoupling  

> Fig. 5. Multi-time-scale physics-informed training mechanism.

memory consumption from integration depth and facilitating efficient end-to-end optimization. 

C. Multi-Time-Scale Physics-Informed Training Mechanism 

The simultaneous optimization of sparse coefficients Ξ

and neural weights θN N presents a severe identifiability challenge. Due to the universal approximation capability of neural networks, unconstrained joint training often leads to the neural component over-parameterizing dominant dynamics that should physically be attributed to the symbolic backbone, causing symbolic degradation. To suppress this competitive in-teraction and enforce physical plausibility, a physics-informed joint training strategy is adopted, as shown in Fig. 5. Within a unified computational graph, Ξ and θN N are optimized simultaneously, where the separation of duties is driven by the interplay between structural sparsity constraints and physical property alignment. To ensure the symbolic backbone prioritizes the capture of dominant physical laws, the joint objective function applies strict ℓ1 regularization on Ξ while incorporating physical guidance derived from the system’s small-signal characteris-tics. This dual mechanism functions as a precision filter: the sparsity constraint condenses global dynamics into compact analytical expressions, while the small-signal Jacobian consis-tency term forces the linearized features of the hybrid model to align with the true physical system. Under this physical guidance, the neural network is implicitly formulated as a IEEE TRANSACTIONS ON POWER ELECTRONICS 6 

> Fig. 6. Schematic of the two-stage identification framework. The Black Box Stage utilizes a neural predictor as a universal smoother to generate high-fidelity synthetic data from noisy samples. This facilitates the White Box Stage, where sparse symbolic regression is applied to the denoised data to recover an interpretable model consisting of a physical backbone and distilled control logic.

residual compensator. It is constrained within the framework of the symbolic backbone, induced to learn only the high-frequency nonlinearities and local disturbances that exceed the representational capacity of the rigid symbolic structure. The total optimization objective integrates macroscopic tra-jectory error, microscopic Jacobian constraints, and a sparsity penalty to jointly regulate both parameter sets: 

Ltotal = Ltraj (θN N , Ξ) + λpert Lpert (θN N , Ξ) + λsparse ∥Ξ∥1

(15) Crucially, the term Lpert introduces physical guidance by rec-tifying the model’s eigenvalues through microscopic Jacobian consistency. The total analytical Jacobian of the hybrid model, computed via Automatic Differentiation, explicitly couples the symbolic coefficients Ξ with the neural weights θN N :

Jmodel (x, Ξ, θ N N ) = Ξ T ∂Θ( x)

∂x + ∂N (x, θ N N )

∂x (16) This analytical Jacobian is aligned with the empirical small-signal response observed in perturbation data: 

Lpert = ∥∆ ˙ xmeas − Jmodel (xmeas , Ξ, θ N N )∆ xmeas ∥2

> F

(17) Through this coupled optimization, PISML ensures that the learned derivative field remains consistent with the true sys-tem’s stability characteristics. This forces Ξ to account for the dominant dynamics that satisfy physical linearization, while 

θN N focuses on rectifying unmodeled residual dynamics with-out compromising the physical interpretability of the symbolic backbone. 

D. Symbolic Explicit Equation Discovery 

While the hybrid PISML model successfully captures complex system dynamics, the neural residual component 

N (x; θ∗ 

> N N

) remains an implicit function encoded within thou-sands of weights and bias. To overcome this barrier, sparse symbolic regression is again applied to the trained NN. This process functions as a symbolic regression mechanism, projecting the high-dimensional neural NN onto a concise set of closed-form mathematical expressions. As illustrated in Fig. 6, this transformation effectively converts the hybrid symbolic/neural model into a computationally efficient and analytically tractable symbolic model, preserving the high fidelity of the neural proxy while recovering the explicit physical structure required for theoretical analysis. The core rationale is to utilize the trained NN as a high-fidelity predictor. Unlike performing symbolic regression di-rectly on raw, noisy measurements, which severely restricts library complexity due to overfitting risks, the NN acts as a universal smoother. It generates a dense, noise-free synthetic dataset (Eq. 3) by interrogating the learned NN: 

yj = N (xj ; θ∗ 

> N N

) (18) This elevation in data quality permits the deployment of an extended function library Θext (x). In contrast to the compact library used for the backbone, Θext (x) is enriched with a comprehensive spectrum of nonlinear candidates, including high-order polynomials, trigonometric functions ( sin , cos ), and rational terms, which are indispensable for characterizing proprietary control logic such as Phase-Locked Loops (PLLs). Leveraging this pristine synthetic data, a secondary sparse regression problem is formulated to identify the explicit struc-ture Ξ∗ 

> resid

of the residual using Eq. 9. Finally, the distilled symbolic residual is merged with the original sparse backbone to yield the discovered governing equation: 

ˆff inal (x) = Θ( x)Ξ ∗ + Θ ext (x)Ξ ∗ 

> resid

(19) This formulation represents a complete, closed-form recon-struction of the underlying system. Crucially, since the neural predictor was trained under Jacobian consistency constraints (Lpert ), the derived explicit equation ˆff inal (x) inherits the correct local stability characteristics, thereby bridging the gap between data-driven modeling and rigorous theoretical analysis. IV. C ASE STUDIES : G RID -C ONNECTED INVERTER WITH 

UNKNOWN GOVERNING EQUATIONS 

A. Case Study Setup 

To comprehensively evaluate the identification capability of the proposed framework under realistic conditions, a high-fidelity Hardware-in-the-Loop (HIL) testing environment is established. The target system comprises a GFM inverter connected to a stiff grid via an LCL filter, a topology widely adopted in modern power electronic-dominated grids. The standard GFM dynamic model, as documented in [38] is adopted; this model features a droop control mechanism with cascaded voltage and current loops. The detailed circuit and control parameters utilized in this study are illustrated in Fig. 7 (a) and listed in Table I, serving as the ground truth for IEEE TRANSACTIONS ON POWER ELECTRONICS 7

TABLE I PARAMETERS OF THE GRID -F ORMING INVERTER TEST SYSTEM 

Parameter Symbol Value Unit 

System Ratings 

Base Power Sbase 500 kVA Base Voltage (Line-Line) Vbase 480 VNominal Frequency fnom 60 Hz 

LCL Filter & Grid Impedance 

Inverter-side Inductance Lf (Li) 0.10 p.u. Inverter-side Resistance Rf (Ri) 0.02 p.u. Filter Capacitance Cf 0.05 p.u. Damping Resistance Rd 0.05 p.u. Grid-side Inductance Lg (Lp) 0.05 p.u. Grid-side Resistance Rg (Rp) 0.01 p.u. 

Control Parameters 

Active Power Droop Gain mp 0.05 p.u. Reactive Power Droop Gain mq 0.05 p.u. Power Filter Cut-off Freq. ωc 10 π rad/s Voltage Loop PI Gains KpV , K iV 0.8, 3.0 -Current Loop PI Gains KpC , K iC 0.2, 4.0 -

validation, although the specific control structure is treated as a black box during the identification process. The data acquisition and training pipeline relies on a hybrid digital-analog platform, as depicted in Fig. 7 (b). The power stage dynamics are emulated on a Typhoon HIL404/604 series real-time simulator, while physical control signals are cap-tured via high-bandwidth oscilloscopes to incorporate realistic measurement noise before being processed on a workstation equipped with an NVIDIA A100 GPU for accelerated PISML training. Data is sampled at 10 kHz. To generate a training data set rich in transient dynamics and prevent the model from overfitting to trivial equilibrium points, random perturbations at the PCC are introduced. These excitations include voltage sags ranging from 0.8 to 1.0 p.u. and phase angle jumps between 5 and 10 degrees, ensuring the learned model remains valid across a wide operating range. The performance of the proposed PISML is benchmarked against three distinct identification paradigms, with imple-mentation details summarized in Table II. The comparative group includes Standard SINDy using a generic polynomial library, representing conventional sparse identification without domain adaptation; Pure Neural ODE, representing a fully 

Fig. 7. Experimental implementation of the proposed framework. (a) Schematic of the single-GFM inverter training pipeline for ODE extraction. (b) The physical hardware experimental platform employed for single-GFM inverter and multi-GFM inverters validation. 

black-box approach lacking physical constraints; and Mod-SINDy. Notably, Mod-SINDy utilizes the physics-informed domain library constructed in this work but relies exclusively on sparse symbolic regression. It effectively serves as the symbolic backbone of the proposed framework, isolating the contribution of the neural residual correction in the ablation analysis. 

B. Trajectory Reconstruction & Generalization 

The trajectory reconstruction capability of the proposed PISML framework is evaluated under data-scarce conditions. To emulate practical limitations in acquiring grid-connected data, the training dataset is strictly limited to 12 trajectories sampled within a conservative operating range of voltage magnitude u ∈ [0 .8, 1.2] p.u. The trained models are then assessed on a severe dynamic test scenario where the system undergoes a large-signal step disturbance dropping to 0.4 p.u. This drastic voltage sag pushes the system state far into the Out-of-Distribution (OOD) region, representing a significantly more rigorous test of generalization than static operating point variations. 

TABLE II COMPARISON OF IDENTIFICATION METHODS AND HYPERPARAMETER SETTINGS 

Method Architecture / Library Optimizer & Regularization Key Settings Baseline A: Library: Polynomial (Degree 2) Solver: STLSQ Threshold: 0.005 Standard SINDy Features: 120 (approx.) Reg: Sparse Thresholding Preproc: MinMaxScaler 

Baseline B: Library: Physics-Informed Solver: Ridge Regression α: 1 × 10 −6

Mod-SINDy Features: Linear + Bilinear Power Reg: L2 Norm Preproc: MinMaxScaler 

Baseline C: Net: MLP (3 Layers) Optimizer: AdamW LR: OneCycle (Max 0.005) Pure NODE Dim: 14 → 128 → 128 → 13 Loss: MSE Epochs: 50 Activation: Tanh Norm: LayerNorm Preproc: StandardScaler 

Proposed: 1) Sparse Backbone: Solver: Ridge ( α = 0 .1) Library: Physics-Based 

PISML 2) Neural Residual: Optimizer: AdamW LR: OneCycle (Max 0.005) Net: MLP (3 Layers) Weight Decay: 1 × 10 −3 Dropout: 0.05 Dim: 14 → 128 → 128 → 13 Norm: LayerNorm Epochs: 50 IEEE TRANSACTIONS ON POWER ELECTRONICS 8                                                                   

> Fig. 8. Comparison of trajectory reconstruction for a GFM inverter. (a) vd.(b) vq.(c) id.(d) iq. The green region ( t < 0.02 s) indicates in-distribution training data, while the red region ( t≥0.02 s) evaluates out-of-distribution (OOD) generalization under a large-signal step disturbance.
> Fig. 9. Trajectory reconstruction for a GFM inverter with nonlinear dual-loop limiting. (a) vd.(b) vq.(c) id.(d) iq. The green region evaluates in-distribution performance, while the red region tests OOD generalization under control saturation. TABLE III ERROR COMPARISON UNDER STANDARD AND SATURATION SCENARIOS
> Method Standard Unknown Sat. IOD (%) OOD (%) IOD (%) OOD (%)
> Std SINDy 29.65 150.36 207.63 934.63 Mod-SINDy 7.10 90.83 68.47 483.03 Pure NODE 6.48 104.82 6.26 120.29
> PISML 0.59 1.94 0.92 2.95
> Note: IOD: In-Distribution (0–0.02s); OOD: Out-of-Distribution (0.02–0.04s). “Unknown Sat.” refers to unmodeled control saturation. The metric is the Relative L2Norm averaged over [id, i q, v d, v q], calculated as ϵ= ( ∥ˆy−y∥2/∥y∥2)×100% , where ˆyis the estimate and yis the ground truth.

The time-domain reconstruction results for the standard GFM model are presented in Fig. 8. Standard SINDy exhibits significant steady-state deviation and transient errors due to the inherent stiffness and multi-time-scale nature of GFM dynamics; the generic polynomial library lacks the capacity to sparsely represent the complex trigonometric couplings and bilinear power terms essential to the control topology. In the OOD region ( t ≥ 0.02 s), the limitations of pure data-driven methods become pronounced. Although the Pure Neural ODE maintains a reasonable approximation within the training distribution, its tracking error increases visibly in the OOD region, confirming its inability to extrapolate dynamics correctly without physical inductive bias. Mod-SINDy, while incorporating physical terms, suffers from library truncation error during deep voltage sags. In contrast, PISML achieves high-fidelity tracking in both regions by leveraging the sparse physical backbone for robust extrapolation and the neural residual for precision. To further probe the limits of identifiability, the methods are evaluated on a GFM system containing unknown non-linear saturation blocks in the control loops, with the corresponding trajectory comparisons illustrated in Fig. 9. As summarized in Table III, both symbolic baselines suffer catastrophic per-formance degradation, yielding OOD errors exceeding 400% .This failure stems from the fundamental inability of basis functions library to represent hard nonlinearities, resulting in erroneous global polynomial fitting. In contrast, the Pure Neural ODE exhibits inherent adaptability to such non-smooth functions due to its universal approximation capability, avoid-ing the divergence observed in symbolic methods. However, PISML achieves the superior performance with an OOD error of only 2.95% . This confirms that the neural residual compo-nent effectively compensates for the hard non-linearities and discontinuous behaviors that the symbolic backbone cannot resolve, while the backbone ensures stability in the linear regions. 

C. Data Efficiency and Noise Robustness 

Subsequently, the data efficiency of the competing paradigms is quantified. Fig. 10 depicts the evolution of reconstruction errors with respect to the training dataset size. Remarkably, Standard SINDy exhibits a counter-intuitive trend where identification performance degrades as data volume increases. This pathology arises because, lacking a complete basis representation for the complex GFM dynamics, the regression algorithm minimizes residuals by overfitting mea-surement noise through high-order polynomials rather than capturing the underlying physics. While Mod-SINDy main-tains stability due to domain-specific priors, it reaches an early performance saturation. Pure NODE adheres to a typical data scaling law, requiring approximately 64 trajectories to match the accuracy that PISML achieves with merely 12. PISML demonstrates superior data efficiency, converging to the noise floor with minimal samples. This efficiency is intrin-sic to its decoupled architecture, where the physical backbone rapidly locks onto dominant dynamics, allowing the neural IEEE TRANSACTIONS ON POWER ELECTRONICS 9                            

> Fig. 10. Comparison of data efficiency across different modeling frameworks.
> (a) IOD relative error versus number of trajectories. (b) OOD relative error versus number of trajectories.
> Fig. 11. Robustness analysis under varying noise conditions. (a) IOD relative error versus noise condition (SNR in dB). (b) OOD relative error versus noise condition. TABLE IV QUANTITATIVE EVALUATION OF DISTRIBUTIONAL SHIFT VIA
> WASSERSTEIN DISTANCE
> Method Wasserstein Dist. Relative Ratio
> (Lower is Better) (vs. PISML-Phy) Baseline A (Std SINDy) 120.5296 544 .1×
> Baseline B (Mod-SINDy) 83.8019 378 .3×
> Baseline C (Pure NODE) 168.4744 760 .6×
> PISML (w/o Constraints) 75.6735 341 .6×
> PISML-Phy (Proposed) 0.2215 1.0 ×
> Note: The Wasserstein Distance (WD) quantifies the discrepancy between the predicted trajectory distribution and the ground truth. The relative ratio indicates how many times larger the distributional error is compared to the proposed PISML-Phy method. A ratio of 1.0×represents the benchmark performance.

component to dedicate its capacity solely to resolving residual mismatches. The robustness against measurement noise is evaluated by training models on raw data corrupted with varying Signal-to-Noise Ratios (SNR) without pre-filtering, as shown in Fig. 11. Symbolic methods reveal a critical vulnerability to noise-induced instability. Standard SINDy diverges rapidly even under moderate noise levels due to derivative noise amplification, where numerical differentiation creates spuri-ous high-magnitude targets for the regression. Although Pure NODE avoids divergence, it tends to overfit high-frequency noise components, resulting in non-physical oscillations. In contrast, PISML demonstrates exceptional noise tolerance. The enforcement of Jacobian regularization combined with the ℓ1

sparsity penalty on physical coefficients acts as a physics-informed filter, effectively suppressing the identification of spurious noise terms while preserving the fidelity of the true system dynamics. 

D. Small-Signal Physical Consistency 

Beyond accurate trajectory reconstruction, preserving small-signal stability is a critical requirement for power electronic modeling. Pure time-domain regression often fails to guarantee the validity of the underlying Jacobian matrix. Therefore, this subsection rigorously evaluates the small-signal behavior of the identified models. For a fair comparison, the baselines utilize their optimal data configurations, with Standard SINDy and Mod-SINDy using 9 trajectories and Pure NODE us-ing 64 trajectories to maximize data-driven potential. The proposed PISML employs only 12 trajectories to highlight data efficiency. The standard PISML and the Physics-informed PISML, denoted as PISML-Phy, are compared to isolate the contribution of the Jacobian regularization mechanism, as detailed in Section III-C. First, a Jacobian linearization of the trained models is performed at an operating point of u = 0.8 p.u., with the resulting eigenvalue distributions illustrated in Fig. 12. Although Pure NODE, Mod-SINDy, and the unconstrained PISML achieve acceptable time-domain fitting, their eigenval-ues exhibit irregular scattering with multiple poles erroneously located in the right-half plane. This spectral pollution implies mathematical instability despite apparent short-term accuracy. A valid control equation must correctly encode the local vector field structure. In contrast, PISML-Phy successfully eliminates these spurious modes. Its eigenvalues cluster tightly around the analytical ground truth and remain strictly within the left-half plane. This confirms that the regularization term Lpert 

effectively constrains the derivative space and forces the neural residual to respect physical stability boundaries. To quantify the discrepancy between the true and identified spectra, the Wasserstein Distance is employed as listed in Table IV. The unconstrained PISML exhibits a Wasserstein metric comparable to the baselines despite superior trajectory reconstruction, indicating limited improvement in small-signal fidelity. However, the introduction of the physical guidance mechanism in PISML-Phy yields a transformative improve-ment, reducing the distance by a factor of over 340. This em-pirical result proves that physical constraints are indispensable for identifying correct derivatives from sparse data. Finally, the robustness of these characteristics is evaluated across varying operating points in Fig. 13. While the spectral error for all methods naturally increases as the system shifts from the IOD to the OOD region, PISML-Phy consistently maintains the lowest distance by orders of magnitude. This demonstrates that the proposed physical constraints ensure the identified NN remains topologically consistent with the true physics across the entire operating envelope. 

E. Interpretable Explicit Equation Discovery 

The ultimate objective of the PISML framework is to transcend the intermediate grey-box representation and achieve fidelity-preserving compression. While the PISML model at-tains high accuracy via the neural residual, it relies on thou-sands of opaque parameters. To restore analytical transparency, the symbolic distillation is performed on the neural residual component and merge it with the symbolic backbone to extract a compact, explicit mathematical structure. The evolution IEEE TRANSACTIONS ON POWER ELECTRONICS 10                      

> Fig. 12. Comparative analysis of small-signal stability and eigenvalue distributions across (a) Std SINDy, (b) Mod SINDy, (c) Pure NODE, (d) PISML, and
> (e) PISML-Phy. Rows (a1)–(e1) show the large-signal trajectory of vd. Rows (a2)–(e2) and (a3)–(e3) illustrate global and magnified eigenvalue distributions, respectively, where grey ’x’ markers denote the analytical ground truth.
> Fig. 13. Robustness analysis of eigenvalue prediction under varying operating points u∈[0 .2,1.2] . The grouped bar chart illustrates the Wasserstein dis-tance (WD) relative to the ground truth for five different modeling frameworks.

of this discovery process is visualized in Fig. 14 (a)–(d). As evidenced by the coefficient heatmaps, the PISML-Phy (Fig. 14b) successfully captures the dominant linear state dependencies, establishing a rigid physical skeleton. Subse-quently, the regression output derived from the neural residual (Fig. 14c) does not produce a dense matrix of spurious terms but selectively identifies the specific nonlinear coupling terms initially unmodeled by the physical backbone. The PISML model (Fig. 14d) seamlessly integrates these components, reconstructing a sparse topology that is structurally isomorphic to the Ground Truth (Fig. 14a). This structural alignment proves that PISML has effectively learned the underlying physical causality rather than merely overfitting the dataset. To validate that this transition from a neural proxy to an explicit equation incurs no loss of dynamic fidelity, a rigorous performance sweep was conducted across a grid voltage range of 0.2 p.u. to 1.0 p.u. As illustrated in the time-domain trajectories of Fig. 14 (e)–(h), the distilled explicit model (dashed lines) exhibits near-perfect overlap with the Ground Truth (solid lines) even under severe voltage dip and recovery scenarios. The quantitative error analysis is detailed in Table V. The results reveal that the regression process incurs negligible information loss, as the average relative errors for active power ( Pf ) and voltage ( vcd ) are merely 0.58% and 0.88%, respectively.Beyond trajectory matching, true interpretability requires the preservation of local stability characteristics. The eigenvalue distributions in Fig. 14 (i)–(l) demonstrate that the modes of the distilled model (marked with ‘x’) align precisely with the Ground Truth (marked with ‘o’). This strict alignment across both low-frequency dominant modes and high-frequency oscillatory modes confirms that the discovered equation accurately reproduces the system’s mi-croscopic differential geometry, allowing the derived explicit form to serve as a reliable instrument for theoretical stability assessment. To rigorously quantify the trade-off between model parsi-mony and predictive capability, a statistical evaluation was performed across different modeling frameworks. As system-atically evaluated in Table VI, converting the neural repre-sentation into symbolic terms delivers transformative benefits. Regarding model complexity, PISML achieves a compression ratio exceeding 250 times by reducing the parameter count from thousands to fewer than fifty coefficients. This extreme sparsity makes the model lightweight enough for embedded DSP controllers. In the trade-off space illustrated in Fig. 15, Standard SINDy falls into the high-error region, while Pure Neural ODE resides in the high-complexity region with poten-tial overfitting risks. Distinct from these approaches, PISML identifies the minimal set of active physical terms, achieving a favorable balance of low complexity and low error. This ensures superior robustness in out-of-distribution scenarios where high-complexity models tend to diverge. IEEE TRANSACTIONS ON POWER ELECTRONICS 11 

Fig. 14. Evaluation of discovered interpretable d equations. (a)–(d) Sparse coefficient matrices for Ground True, PISML-Phy, PISML-Distilled, and Final PISML models. The horizontal axis is categorized into two libraries: the Linear Library comprises the constant bias and 13 state variables ( x0, . . . , x 12 ), while the Nonlinear Library consists of 13 candidate functions including bilinear coupling terms (e.g., xk ∆P ), trigonometric grid voltage terms ( ug cos δ, u g sin δ), and instantaneous power calculation terms. (e)–(h) Comparison of time-domain trajectories for Pf and vcd (Solid: Ground True; Dashed: PISML-Distilled). 

(i)–(l) Global and zoomed eigenvalue distributions, where ’o’ and ’x’ markers denote Ground True and PISML-Distilled modes, respectively. 

Fig. 15. Pareto analysis of model robustness versus complexity, comparing PISML variants against black-box NNs and standard sparse regression base-lines. TABLE V RELATIVE ERROR ANALYSIS OF HYBRID AND DISTILLED MODELS 

UNDER VOLTAGE VARIATIONS 

Grid Voltage 

u (p.u.) 

Hybrid Model Error (%) Distilled Model Error (%) Active Power Voltage vd Active Power Voltage vd

0.2 0.6371 0.4884 0.1457 1.0081 0.4 0.3653 0.2174 0.2086 1.5530 0.6 0.1430 0.8854 0.4157 1.3209 0.8 0.3493 1.0561 0.4206 0.0521 1.0 0.8709 0.1849 0.4034 0.7935 1.2 0.1823 0.3840 1.8943 0.6020 

Average 0.4246 0.5360 0.5814 0.8883 

TABLE VI COMPREHENSIVE EFFICIENCY & F IDELITY COMPARISON 

Metric Pure NODE PISML-Phy PISML-Distilled 

Model Type Black-box Grey-box White-box 

Small-Signal Error High (Unstable) Low Low 

Parameter Count ∼5,000+ ∼5,000+ < 50 (Coeffs) 

Analyticity Intractable Intractable Tractable 

Fig. 16. Schematic diagrams of 3-Buses microgrid topology for validating the interaction between the learned target model and known auxiliary units. 

F. System-Level Integration & Applications 

The definitive advantage of extracting explicit governing equations lies in the capability to integrate the identified model into broader power system simulations. By translating propri-etary black-box devices into a unified mathematical language, PISML empowers grid operators to integrate equipment from diverse manufacturers onto a single platform for full-system analysis. This integration capability ensures that the discovered model is not only accurate for time-domain simulation but also reliable for rigorous theoretical stability assessment. To validate this capability experimentally, a heterogeneous 3-bus microgrid system is constructed, as illustrated in Fig. 16. The topology consists of the identified Target GFM (repre-sented by the PISML-distilled explicit equations) integrated with two Auxiliary GFMs (Aux GFM 1 & 2) possessing known structures and parameters. The detailed system param-eters are listed in Table VII. This setup, implemented on the HIL platform shown in Fig. 7, serves as a rigorous testbed to evaluate the interaction between the ”learned” dynamics and the ”known” physics. First, the accuracy of the PISML model in a multi-converter environment is validated through large-signal disturbance test-IEEE TRANSACTIONS ON POWER ELECTRONICS 12                                                            

> TABLE VII SYSTEM AND CONTROL PARAMETERS CONFIGURATION
> Category Parameter Symbol GFM 1 GFM 2 GFM 3
> Control Active Droop mp0.03 0.06 0.05 Voltage Prop. Gain KpV 1.60 2.00 1.40 Voltage Int. Gain KiV 3.00 4.00 2.00 Current Prop. Gain KpC 0.50 0.30 0.40 Current Int. Gain KiC 4.00 4.00 4.00 Line Line Resistance Rline 0.01 0.01 0.01 Line Inductance Lline 0.001 0.001 0.001 Load Load Resistance Rload 0.9
> Load Inductance Lload 0.4358
> Fig. 17. Experimental validation of system-level transient dynamics in the 3-bus microgrid under a sudden load step. (a1)-(a3) Ground truth output current waveforms measured from the HIL testbench for the Target GFM 1, Aux GFM 2, and Aux GFM 3, respectively. (b1)-(b3) Corresponding current trajectories predicted by the PISML-based hybrid simulation.
> Fig. 18. Experimental validation of system-level transient dynamics in the 3-bus microgrid under a sudden load step. (a1)-(a3) Ground truth output current waveforms measured from the HIL testbench for the Target GFM 1, Aux GFM 2, and Aux GFM 3, respectively. (b1)-(b3) Corresponding current trajectories predicted by the PISML-based hybrid simulation.
> Fig. 19. System-level eigenvalue trajectories (root loci) of the heterogeneous 3-bus microgrid system under control parameter variations. (a)-(b) Impact of varying the voltage proportional gain ( KpV ) of Aux GFM 2 on global and dominant modes. (c)-(d) Impact of varying the current proportional gain (KpC ) of Aux GFM 3.

ing. A sudden load step change is applied at t = 0 .02 s. To rigorously assess the model’s robustness against varying external dynamics, the system response is simulated under different control parameter settings for the auxiliary analytical GFM inverters, as illustrated in Fig. 17 and Fig. 18. In both scenarios, the output current waveforms demonstrate that the hybrid model (PISML Target + Analytical Auxiliaries) closely tracks the HIL ground truth. This consistency confirms that the PISML-derived equation, despite being trained solely on single-unit data, successfully captures the device’s intrinsic port behaviors and correctly reproduces the transient load-sharing dynamics when interacting with the wider grid. Beyond these time-domain results, the explicit nature of the PISML model enables safe and rapid stability assessment for operations that would be hazardous to perform directly on physical hardware. Specifically, before physically connecting a black-box inverter, operators can mathematically analyze how its integration affects global system stability. To demonstrate this, a global eigenvalue analysis of the assembled 3-bus system is conducted. The migration of system eigenvalues is investigated by tuning the control coefficients of the known units—specifically, the voltage proportional gain ( KpV ) and integral gain ( KiV ) of the auxiliary GFMs. As visualized in Fig. 19, the resulting root locus plot reveals the precise trajectory of the system’s dominant modes. This analysis allows operators to identify stability boundaries and optimize the settings of existing assets to accommodate the black-box target. Such theoretical insight, derived directly from the math-ematical integration capability of the PISML model, bridges the methodological gap between data-driven identification and rigorous power system engineering. V. C ONCLUSION 

This paper proposes the PISML framework to bridge the critical modeling gap in power electronics-dominated grids. IEEE TRANSACTIONS ON POWER ELECTRONICS 13 

By synergizing a sparse symbolic backbone with a neural residual branch under Jacobian-regularized physics-informed training, PISML successfully reconciles the inherent con-flict between identifying unmodeled hard non-linearities and preserving physical consistency. Furthermore, the framework advances the fidelity-preserving regression of implicit neural dynamics into compact governing equations restores analytical tractability for algebraic stability design, while drastically reducing complexity for efficient deployment. The framework was rigorously validated on a high-fidelity HIL platform across multiple dimensions, including large-signal trajectory reconstruction, small-signal spectral analysis, and system-level integration capability. Quantitative results confirm that the proposed method reduces identification error by over 340 times compared to symbolic baselines and improves spectral fidelity by two orders of magnitude. By distilling implicit black-box dynamics into explicit control equations, PISML achieves a breakthrough in integration capability, empowering grid oper-ators to integrate proprietary devices into rigorous eigenvalue analysis workflows. Future work will extend this approach to identify complex grid-forming topologies under unstructured grid faults and explore online adaptive implementations. REFERENCES [1] S. Xu et al. , “Review of power system support functions for inverter-based distributed energy resources- standards, control algorithms, and trends,” IEEE Open Journal of Power Electronics , vol. 2, pp. 88–105, 2021. [2] Y. Lin et al. , “Pathways to the next-generation power system with inverter-based resources: Challenges and recommendations,” IEEE Elec-trification Magazine , vol. 10, no. 1, pp. 10–21, 2022. [3] Y. Huang et al. , “Physics insight of the inertia of power systems and methods to provide inertial response,” CSEE Journal of Power and Energy Systems , vol. 8, no. 2, pp. 559–568, 2022. [4] Y. Qi et al. , “Synthetic inertia control of grid-connected inverter con-sidering the synchronization dynamics,” IEEE Transactions on Power Electronics , vol. 37, no. 2, pp. 1411–1421, 2022. [5] M. Nestor et al. , “Data-driven communication and control design for distributed frequency regulation with black-box inverters,” 2025. [Online]. Available: https://arxiv.org/abs/2510.17769 [6] R. Rosso et al. , “Grid-forming converters: Control approaches, grid-synchronization, and future trends—a review,” IEEE Open Journal of Industry Applications , vol. 2, pp. 93–109, 2021. [7] U. Markovic et al. , “Partial grid forming concept for 100% inverter-based transmission systems,” in 2018 IEEE Power & Energy Society General Meeting (PESGM) , pp. 1–5, 2018. [8] N. Hatziargyriou et al. , “Definition and classification of power system stability – revisited & extended,” IEEE Transactions on Power Systems ,vol. 36, no. 4, pp. 3271–3281, 2021. [9] T. C. Green et al. , “Zero-inertia power systems: Data-driven stability assessment,” IEEE Power and Energy Magazine , vol. 18, no. 2, pp. 56– 65, 2020. [10] L. He et al. , “A neural network-based online parameter identification method for fractional-order power electronics,” IEEE Transactions on Circuits and Systems I: Regular Papers , vol. 72, no. 9, pp. 4868–4876, 2025. [11] I. Kamwa et al. , “Pmu configuration for system dynamic performance measurement in large, multiarea power systems,” IEEE Transactions on Power Systems , vol. 17, no. 2, pp. 385–394, 2002. [12] X. Wang et al. , “Unified impedance model of grid-connected voltage-source converters,” IEEE Transactions on Power Electronics , vol. 33, no. 2, pp. 1775–1787, 2018. [13] X. Weng et al. , “Chirp signal injection method and real-time impedance characteristic measurement of electric energy router,” IEEE Journal of Emerging and Selected Topics in Power Electronics , vol. 10, no. 5, pp. 5564–5577, 2022. [14] H. Gong et al. , “Dq-frame impedance measurement of three-phase converters using time-domain mimo parametric identification,” IEEE Transactions on Power Electronics , vol. 36, no. 2, pp. 2131–2142, 2021. [15] J. Zheng et al. , “Latent-feature-informed neural ode modeling for lightweight stability evaluation of black-box grid-tied inverters,” IEEE Transactions on Power Electronics , pp. 1–6, 2025. [16] Y. Gu et al. , “Power system stability with a high penetration of inverter-based resources,” Proc. IEEE , vol. 111, no. 7, pp. 832–853, 2023. [17] J. Zheng et al. , “Neural surrogate solver for efficient edge inference of power electronic hybrid dynamics,” IEEE Transactions on Industrial Electronics , pp. 1–6, 2026. [18] H. Wang et al. , “Scientific discovery in the age of artificial intelligence,” 

Nature , vol. 620, no. 7972, pp. 47–60, 2023. [19] K. Course et al. , “State estimation of a physical system with unknown governing equations,” Nature , vol. 622, no. 7982, pp. 261–267, 2023. [20] S. L. Brunton et al. , “Discovering governing equations from data by sparse identification of nonlinear dynamical systems,” Proceedings of the National Academy of Sciences , vol. 113, no. 15, pp. 3932–3937, 2016. [21] N. Hadifar et al. , “Data-driven modeling of power electronic converters using symbolic regression for digital twin applications,” in 2025 IEEE Electric Ship Technologies Symposium (ESTS) , pp. 135–142, 2025. [22] A. T. Sari´ c et al. , “Symbolic regression for data-driven dynamic model refinement in power systems,” IEEE Transactions on Power Systems ,vol. 36, no. 3, pp. 2390–2402, 2021. [23] X. Shi et al. , “Physical-informed detailed aggregation of wind farm based on symbolic regression: Structure, solution and generalizability,” 

IEEE Transactions on Sustainable Energy , pp. 1–14, 2025. [24] K. Egan et al. , “Automatically discovering ordinary differential equa-tions from data with sparse regression,” Communications Physics , vol. 7, no. 1, p. 20, 2024. [25] Q. Guo et al. , “Physics-informed neural network combined with sparse identification nonlinear dynamics for battery soc estimation,” in 2025 IEEE International Conference on Environment and Electrical Engineer-ing and 2025 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I&CPS Europe) , pp. 1–6, 2025. [26] G. W. Koo et al. , “Efficient algorithm based on sindy-pinn-pso for trans-former air-gap design in obc,” IEEE Transactions on Power Electronics ,vol. 41, no. 1, pp. 56–60, 2026. [27] R. T. Chen et al. , “Neural ordinary differential equations,” Advances in neural information processing systems , vol. 31, 2018. [28] C. Rackauckas et al. , “Universal differential equations for scientific machine learning,” arXiv preprint arXiv:2001.04385 , 2020. [29] Z. Liu et al. , “Dissipation-based dynamics-aware learning scheme for transient stability analysis of networked black-box grid-forming invert-ers,” IEEE Transactions on Power Electronics , vol. 41, no. 3, pp. 3165– 3170, 2026. [30] J. Zheng et al. , “Stability evaluation of black-box grid-forming inverters via physical-informed neural ordinary differential equations,” in 2025 IEEE Energy Conversion Conference Congress and Exposition (ECCE) ,pp. 1–5, 2025. [31] J. Zheng et al. , “Physics-embedded neural odes for sim-to-real edge digital twins of hybrid power electronics systems,” IEEE Transactions on Industrial Electronics , pp. 1–12, 2026. [32] Y. Lian et al. , “Physically consistent multiple-step data-driven predic-tions using physics-based filters,” IEEE Control Systems Letters , vol. 7, pp. 1885–1890, 2023. [33] B. Huang et al. , “Applications of physics-informed neural networks in power systems - a review,” IEEE Transactions on Power Systems , vol. 38, no. 1, pp. 572–588, 2023. [34] G. E. Karniadakis et al. , “Physics-informed machine learning,” Nature Reviews Physics , vol. 3, no. 6, pp. 422–440, 2021. [35] Y. Fassi et al. , “Toward physics-informed machine-learning-based pre-dictive maintenance for power converters—a review,” IEEE Transactions on Power Electronics , vol. 39, no. 2, pp. 2692–2720, 2024. [36] S. Kolev et al. , “Physically consistent state estimation and system identi-fication for contacts,” in 2015 IEEE-RAS 15th International Conference on Humanoid Robots (Humanoids) , pp. 1036–1043, 2015. [37] F.-L. Fan et al. , “On interpretability of artificial neural networks: A survey,” IEEE Transactions on Radiation and Plasma Medical Sciences ,vol. 5, no. 6, pp. 741–760, 2021. [38] N. Pogaku et al. , “Modeling, analysis and testing of autonomous operation of an inverter-based microgrid,” IEEE Transactions on power electronics , vol. 22, no. 2, pp. 613–625, 2007.