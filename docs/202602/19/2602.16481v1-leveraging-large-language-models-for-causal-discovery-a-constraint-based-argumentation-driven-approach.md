---
title: "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach"
title_zh: 利用大语言模型进行因果发现：一种基于约束、论证驱动的方法
authors: "Zihao Li, Fabrizio Russo"
date: 2026-02-18
pdf: "https://arxiv.org/pdf/2602.16481v1"
tags: ["query:sr"]
score: 6.0
evidence: 用于因果发现和结构先验的符号推理与大模型结合
tldr: 本研究提出一种结合大语言模型（LLM）与基于假设的论证（ABA）框架的因果发现方法。该方法将LLM视为“不完美专家”，利用其从变量名称和描述中提取的语义先验知识，并与观测数据中的条件独立性证据进行符号化整合。实验表明，该方法在多个基准测试中达到了最先进性能，并引入了专门的评估协议以缓解LLM的记忆偏差问题。
motivation: 旨在解决传统因果发现方法难以有效融合专家知识的问题，利用LLM蕴含的丰富语义信息辅助因果图构建。
method: 利用基于假设的论证（ABA）框架，将LLM生成的语义结构先验与统计学的条件独立性证据进行逻辑整合与推理。
result: 在标准基准数据集和语义合成图上均实现了最先进（SOTA）的因果发现性能。
conclusion: 通过符号化论证框架整合LLM语义先验与数据证据，能显著提升因果发现的可靠性，并有效应对LLM的记忆偏差挑战。
---

## 摘要
因果发现旨在从数据中揭示因果关系，通常表示为因果图，这对于预测干预效果至关重要。虽然构建规范的因果图需要专家知识，但已有许多统计方法被提出，以利用具有不同形式化保证的观测数据。基于因果假设的论证（Causal Assumption-based Argumentation, ABA）是一个利用符号推理来确保输入约束与输出图之间对应关系的框架，同时提供了一种结合数据与专业知识的规范方法。我们探索了将大语言模型（LLMs）作为 Causal ABA 的不完全专家，从变量名称和描述中提取语义结构先验，并将其与条件独立性证据相结合。在标准基准测试和具有语义基础的合成图上的实验证明了该方法达到了最先进的性能。此外，我们还引入了一种评估协议，以减轻在评估 LLMs 进行因果发现时的记忆偏差。

## Abstract
Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.