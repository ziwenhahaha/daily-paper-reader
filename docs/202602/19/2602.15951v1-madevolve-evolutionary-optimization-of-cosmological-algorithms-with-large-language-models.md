---
title: "MadEvolve: Evolutionary Optimization of Cosmological Algorithms with Large Language Models"
title_zh: MadEvolve：利用大语言模型对宇宙学算法进行演化优化
authors: "Tianyi Li, Shihui Zang, Moritz Münchmeyer"
date: 2026-02-17
pdf: "https://arxiv.org/pdf/2602.15951v1"
tags: ["query:sr"]
score: 8.0
evidence: 宇宙学中用于科学算法发现的进化优化框架
tldr: 本研究开发了名为 MadEvolve 的通用框架，利用大语言模型（LLM）和进化算法自动优化宇宙学算法。该框架在人类基准算法基础上，通过迭代修改代码并结合梯度或非梯度参数优化，显著提升了算法性能。在宇宙学初始条件重建、21cm 前景污染重建及 N 体模拟中的重子物理效应三个任务中，MadEvolve 均实现了超越基准算法的改进，并能自动生成详细的算法创新报告。
motivation: 旨在利用大语言模型自动化发现和优化复杂的科学算法，以解决宇宙学计算中对自由参数和算法逻辑的高效优化需求。
method: 开发了 MadEvolve 框架，通过迭代演化代码逻辑并结合自动微分或无梯度方法优化自由参数，实现算法的持续进化与性能提升。
result: 在宇宙学初始条件重建、21cm 前景重建和重子物理模拟三个应用场景中，该框架均取得了显著优于人类基准算法的性能表现。
conclusion: MadEvolve 证明了 LLM 驱动的进化优化在提升科学计算效率、发现新算法以及自动生成科研报告方面的巨大潜力。
---

## 摘要
我们开发了一个用于发现科学算法的通用框架，并将其应用于计算宇宙学中的三个问题。我们的代码 MadEvolve 与 Google 的 AlphaEvolve 类似，但更强调自由参数及其优化。我们的代码从基准的人类算法实现开始，然后通过对其代码进行迭代更改来优化其性能指标。作为一项进一步的便捷功能，MadEvolve 会自动生成一份报告，对比输入算法与演化后的算法，描述算法创新，并列出自由参数及其功能。我们的代码同时支持自动微分、基于梯度的参数优化以及无梯度优化方法。我们将 MadEvolve 应用于宇宙学初始条件的重建、21cm 前景污染重建以及 N 体模拟中的有效重子物理。在所有案例中，我们都发现其相比基础算法有显著改进。我们将 MadEvolve 及其三个任务在 madevolve.org 上公开。

## Abstract
We develop a general framework to discover scientific algorithms and apply it to three problems in computational cosmology. Our code, MadEvolve, is similar to Google's AlphaEvolve, but places a stronger emphasis on free parameters and their optimization. Our code starts with a baseline human algorithm implementation, and then optimizes its performance metrics by making iterative changes to its code. As a further convenient feature, MadEvolve automatically generates a report that compares the input algorithm with the evolved algorithm, describes the algorithmic innovations and lists the free parameters and their function. Our code supports both auto-differentiable, gradient-based parameter optimization and gradient-free optimization methods. We apply MadEvolve to the reconstruction of cosmological initial conditions, 21cm foreground contamination reconstruction and effective baryonic physics in N-body simulations. In all cases, we find substantial improvements over the base algorithm. We make MadEvolve and our three tasks publicly available at madevolve.org.

---

## 论文详细总结（自动生成）

这是一份关于论文《MadEvolve: Evolutionary Optimization of Cosmological Algorithms with Large Language Models》的结构化总结：

### 1. 核心问题与整体含义
*   **研究背景**：现代宇宙学数据分析依赖复杂的算法（如场重建、相关函数估计等）。传统的人类设计算法在面对海量数据和指数级的参数设计空间时，往往难以达到最优。
*   **研究动机**：虽然深度学习（黑盒模型）表现强劲，但在宇宙学中面临模拟数据量大、缺乏可解释性和泛化性差等问题。
*   **核心问题**：能否开发一个自动化框架，利用大语言模型（LLM）的语义理解能力和演化算法的搜索能力，在保持物理可解释性的前提下，自动发现并优化高性能的科学算法？

### 2. 方法论
*   **核心思想**：MadEvolve 框架将科学算法视为程序，通过 LLM 作为“智能变异算子”对代码进行迭代修改，并结合物理指标进行评估。
*   **关键技术细节**：
    *   **双环优化架构**：
        *   **外环（结构搜索）**：LLM 负责修改算法逻辑（如引入新的物理项、改变滤波方式）。
        *   **内环（参数优化）**：针对 LLM 提出的新算法，自动进行参数微调。支持**自动微分（基于 JAX 和 Adam 优化器）**和**无梯度搜索（针对不可微操作）**。
    *   **种群管理**：采用混合策略，结合 **MAP-Elites**（保持代码多样性）和**岛屿模型（Island Model）**（防止过早收敛）。
    *   **LLM 集成**：使用 UCB1 多臂老虎机算法动态选择表现最好的模型（如 GPT-5, Gemini 3 Pro/Flash 等）。
    *   **自动报告生成**：演化结束后，LLM 会自动分析演化轨迹，对比基准算法，并尝试从物理角度解释改进的原因。

### 3. 实验设计
*   **应用场景与 Benchmark**：
    1.  **BAO 重建**：从后期物质分布恢复初始条件。基准（Baseline）为标准 Zeldovich 重建和目前人类顶尖的迭代重建算法。
    2.  **21cm 前景污染重建**：恢复被射电前景遮蔽的傅里叶模式。基准为潮汐重建（Tidal Reconstruction）算法。
    3.  **N 体模拟中的有效重子物理**：预测热 Sunyaev-Zeldovich (tSZ) 信号。基准为拉格朗日深度学习（LDL）框架。
*   **数据集**：使用 Quijote N 体模拟套件和 CAMELS 流体动力学模拟套件。
*   **评价指标**：傅里叶空间交叉相关系数 $r(k)$、2D 相关系数 $r_{2D}$ 以及 L1 损失函数。

### 4. 资源与算力
*   **硬件环境**：单台工作站，配置为 **AMD Ryzen Threadripper 3960X (24核)**，**256 GB RAM**，以及 **2块 NVIDIA RTX 3090 GPU (24GB VRAM)**。
*   **LLM 资源**：通过 API 调用 Google Gemini 和 OpenAI 的模型。
*   **演化规模**：每个任务运行 233 到 1,165 个世代（Generations）。单个候选算法的评估时间从 10 秒到 30 分钟不等（取决于是否包含自动微分优化循环）。

### 5. 实验数量与充分性
*   **实验规模**：共进行了 4 组主要的演化实验，总计生成并评估了 2,126 个程序。
*   **充分性与公平性**：
    *   实验在独立的测试集（未参与演化的模拟数据）上进行了验证。
    *   针对不同分辨率（256³ vs 512³ 网格）测试了算法的泛化能力。
    *   引入了针对大尺度模式退化的惩罚项，确保算法改进不是通过“奖励作弊（Reward Hacking）”实现的。
    *   对比了多个不同水平的人类基准算法，证明了其在不同起点下的改进能力。

### 6. 主要结论与发现
*   **性能显著提升**：
    *   BAO 重建：相比标准基准提升 **22.8%**，相比顶尖迭代基准提升 **2.8%**。
    *   21cm 重建：性能提升 **30.7%**，几乎完美恢复了丢失的模式。
    *   重子物理预测：测试损失降低了 **63%**。
*   **物理发现**：LLM 独立发现了诸如“各向异性滤波”、“高阶扰动理论修正”和“压力场的乘法分解”等具有物理合理性的策略。
*   **模型贡献**：轻量级模型（如 Gemini 3 Flash）在演化循环中的效率极高，表现甚至不亚于最顶尖的旗舰模型。

### 7. 优点
*   **可解释性强**：不同于黑盒神经网络，演化出的是简洁的 Python 代码，人类科学家可以阅读、理解并进一步改进。
*   **参数效率高**：演化出的算法通常只有不到 10 个自由参数，远少于深度学习模型，且泛化性更好。
*   **自动化程度高**：集成了从代码编写、参数调优到科学报告生成的全流程。

### 8. 不足与局限
*   **代码优雅度**：演化出的代码虽然有效，但往往像“补丁堆砌”，缺乏人类数学推导出的那种简洁美感。
*   **生成成功率**：在复杂任务（如 tSZ 预测）中，代码编译失败率较高（约 45%），浪费了部分算力。
*   **现实数据差距**：目前仅在理想化的模拟数据上进行了测试，尚未考虑真实观测中的复杂系统误差和噪声。
*   **计算瓶颈**：主要的瓶颈在于物理指标的评估速度，而非 LLM 的生成速度。

（完）
