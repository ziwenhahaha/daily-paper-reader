---
title: "Structural Compositional Function Networks: Interpretable Functional Compositions for Tabular Discovery"
title_zh: 结构化组合函数网络：用于表格数据发现的可解释函数组合
authors: Fang Li
date: 2026-01-27
pdf: "https://arxiv.org/pdf/2601.20037v1"
tags: ["keyword:SR", "query:SR"]
score: 6.0
evidence: 用于表格发现的可解释函数组合
tldr: 针对表格数据中深度学习模型性能及可解释性不足的问题，本文提出结构化组合函数网络（StructuralCFN）。该模型通过可微分结构先验引入关系感知归纳偏置，利用自适应门控机制将特征建模为其他特征的数学组合。实验表明，该方法在多个科学和临床数据集上显著优于基线，且能以极小的参数量提取出人类可读的符号化规律。
motivation: 传统神经网络在处理表格数据时忽略了特征间的流形结构依赖，且缺乏科学发现所需的可解释性。
method: 提出一种具有可微分结构先验的架构，通过自适应门控自动发现特征间的数学组合关系，并支持领域知识的直接注入。
result: 在18个基准测试中表现优异，不仅显著提升了预测精度，还实现了比标准模型小10-20倍的极简参数量。
conclusion: StructuralCFN 成功结合了深度学习的灵活性与符号回归的可解释性，为表格数据的科学发现提供了高效且透明的工具。
---

## 摘要
尽管表格数据在高风险领域无处不在，但传统的深度学习架构在保持科学可解释性的同时，往往难以达到梯度提升决策树的性能。标准神经网络通常将特征视为独立的实体，未能利用定义表格分布的内在流形结构依赖关系。我们提出了结构化组合函数网络（StructuralCFN），这是一种通过可微结构先验施加关系感知归纳偏置（Relation-Aware Inductive Bias）的新型架构。StructuralCFN 通过可微自适应门控（Differentiable Adaptive Gating）将每个特征显式建模为其对应特征的数学组合，该机制可自动发现每个关系的优化激活物理特性（例如，注意力式过滤与抑制性极性）。我们的框架支持结构化知识集成（Structured Knowledge Integration），允许将特定领域的关联先验直接注入架构以引导发现。我们在 18 个基准测试集上通过严格的 10 折交叉验证评估了 StructuralCFN，证明了其在科学和临床数据集（如 Blood Transfusion、Ozone、WDBC）上具有显著的统计学改进（p < 0.05）。此外，StructuralCFN 提供了内在符号可解释性（Intrinsic Symbolic Interpretability）：它能将数据流形的控制“定律”恢复为人类可读的数学表达式，同时保持紧凑的参数占用（300-2,500 个参数），比标准深度基准模型小一个数量级以上（10-20 倍）。

## Abstract
Despite the ubiquity of tabular data in high-stakes domains, traditional deep learning architectures often struggle to match the performance of gradient-boosted decision trees while maintaining scientific interpretability. Standard neural networks typically treat features as independent entities, failing to exploit the inherent manifold structural dependencies that define tabular distributions. We propose Structural Compositional Function Networks (StructuralCFN), a novel architecture that imposes a Relation-Aware Inductive Bias via a differentiable structural prior. StructuralCFN explicitly models each feature as a mathematical composition of its counterparts through Differentiable Adaptive Gating, which automatically discovers the optimal activation physics (e.g., attention-style filtering vs. inhibitory polarity) for each relationship. Our framework enables Structured Knowledge Integration, allowing domain-specific relational priors to be injected directly into the architecture to guide discovery. We evaluate StructuralCFN across a rigorous 10-fold cross-validation suite on 18 benchmarks, demonstrating statistically significant improvements (p < 0.05) on scientific and clinical datasets (e.g., Blood Transfusion, Ozone, WDBC). Furthermore, StructuralCFN provides Intrinsic Symbolic Interpretability: it recovers the governing "laws" of the data manifold as human-readable mathematical expressions while maintaining a compact parameter footprint (300--2,500 parameters) that is over an order of magnitude (10x--20x) smaller than standard deep baselines.