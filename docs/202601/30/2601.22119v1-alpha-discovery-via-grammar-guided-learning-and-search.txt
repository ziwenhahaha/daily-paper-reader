Title: Alpha Discovery via Grammar-Guided Learning and Search

URL Source: https://arxiv.org/pdf/2601.22119v1

Published Time: Fri, 30 Jan 2026 02:38:43 GMT

Number of Pages: 24

Markdown Content:
# Alpha Discovery via Grammar-Guided Learning and Search 

Han Yang 1 Dong Hao 1 Zhuohan Wang 2 Qi Shi 3 Xingtong Li 1

## Abstract 

Automatically discovering formulaic alpha fac-tors is a central problem in quantitative finance. Existing methods often ignore syntactic and se-mantic constraints, relying on exhaustive search over unstructured and unbounded spaces. We present AlphaCFG, a grammar-based framework for defining and discovering alpha factors that are syntactically valid, financially interpretable, and computationally efficient. AlphaCFG uses an alpha-oriented context-free grammar to define a tree-structured, size-controlled search space, and formulates alpha discovery as a tree-structured linguistic Markov decision process, which is then solved using a grammar-aware Monte Carlo Tree Search guided by syntax-sensitive value and pol-icy networks. Experiments on Chinese and U.S. stock market datasets show that AlphaCFG outper-forms state-of-the-art baselines in both search ef-ficiency and trading profitability. Beyond trading strategies, AlphaCFG serves as a general frame-work for symbolic factor discovery and refine-ment across quantitative finance, including asset pricing and portfolio construction. 

## 1. Introduction 

1.1. Alpha discovery 

In quantitative finance, alpha factors play a central role in asset management, quantitative trading, and investment decision-making. An alpha factor is an explicit function that maps historical market features, such as prices and volumes, to predictions of future returns. Alpha discovery refers to the systematic identification of such predictive functions from historical data and remains a core challenge due to 

> 1

University of Electronic Science and Technology of China, Chengdu, China 2King’s College London, London, United King-dom 3University of Southampton, Southampton, United Kingdom. Correspondence to: Han Yang <yanghan667@std.uestc.edu.cn >,Dong Hao <haodong@uestc.edu.cn >, Zhuohan Wang <zhuo-han.wang@kcl.ac.uk >, Qi Shi <qi.shi@soton.ac.uk >, Xingtong Li <lixingtong@std.uestc.edu.cn >.

Preprint. January 30, 2026. 

the vast and complex space of possible functional forms. Beyond their practical importance, alpha discovery poses a fundamental machine-learning challenge: identifying sym-bolic functions that are both predictive and interpretable under severe combinatorial constraints. Existing approaches to alpha discovery can be broadly classified into three categories. Heuristic or expert-driven methods rely on financial intuition, such as value factors (e.g., price-to-earnings ratios (Fama & French, 1992)) and momentum factors (e.g., past 12-month returns (Carhart, 1997)), but lack scalability and are quickly arbitraged once widely adopted, reducing predictive accuracy over time. 

Data-driven learning methods , including regression (Bhan-dari et al., 2022; Qin et al., 2017; Dai et al., 2022; Mozaf-fari & Zhang, 2024), tree-based ensembles (Wang et al., 2023; Bisdoulis, 2024), unsupervised learning (Xu, 2025), and reinforcement learning (Lee, 2001), can capture com-plex nonlinear patterns, yet often suffer from limited in-terpretability and overfitting due to their black-box nature. 

Formulaic alpha methods (Zhang et al., 2020) emphasize human-readable mathematical expressions composed of pre-defined operators, offering transparency and interpretability, and have therefore regained recent attention. 

Table 1. Comparison of Alpha Discovery Methods         

> Category Pros Cons
> Heuristic / Expert Intuitive, easy to use Limited, quickly arbitraged Data-driven Learning Captures complex patterns Black-box, less interpretable Formulaic Alpha Interpretable, transparent Computationally expensive

Our work lies at the intersection of data-driven learning and formulaic alpha methods, aiming at the automatic discovery of explainable alpha factors . This problem can be viewed as symbolic regression (Makke & Chawla, 2024), which seeks 

explicit mathematical expressions that fit data while remain-ing interpretable , but is difficult due to its combinatorial search space and semantic equivalence among expressions. Early approaches such as genetic programming (GP) (Zhang et al., 2020) evolve expression trees to optimize information coefficients. More recent methods, including AlphaGen (Yu et al., 2023) and AlphaQCM (Zhu & Zhu, 2025), adopt rein-forcement learning to improve scalability. Existing methods face the following fundamental challenges. (1) Lack of linguistic characterization leads to inefficient search in an unbounded space. Automated discovery of 1

> arXiv:2601.22119v1 [q-fin.CP] 29 Jan 2026 Alpha Discovery via Grammar-Guided Learning and Search

formulaic alphas is fundamentally a problem of searching over mathematical languages, yet existing methods lack an explicit linguistic framework to organize and constrain this search. In the absence of formal grammatical structure, current approaches must explore vast, and often effectively infinite, combinatorial spaces of expressions, relying on ad hoc syntactic checks to ensure validity. This unstructured ex-ploration severely limits sample efficiency, degrades model performance, and incurs substantial computational cost. (2) Semantic redundancy causes systematic waste in learn-ing and search. Many syntactically distinct mathematical sequences correspond to the same underlying semantics, but existing methods mostly encode expressions as linear sequences and treat the variants as independent. As a result, semantically equivalent expressions are repeatedly explored and evaluated, leading to significant redundancy in represen-tation learning and search, and greatly reducing efficiency. 

1.2. Our Work 

We propose AlphaCFG, 1 a general linguistic–learning framework for the automatic discovery of interpretable al-pha factors. The central idea is to treat alpha discovery as a structured language generation and learning problem, rather than an unstructured search over mathematical expressions. By combining formal grammar with learning and search, AlphaCFG provides a principled way to generate, validate, and optimize human-readable alpha factors. In this way, grammar serves as an explicit inductive bias that shapes both the search space and the learning dynamics. (1) Grammar-Constrained Alpha Factors. From alanguage-theoretic perspective, we first formalize the space of alpha factors as a structured mathematical language. We propose two formal languages, α-Syn and α-Sem, that integrate context-free grammar (CFG) with finance do-main–specific knowledge of alpha factors. α-Syn enforces grammatical correctness, while α-Sem further ensures fi-nancial semantic validity. These languages generate alpha expressions recursively in a tree-structured form, making tree-structure–based learning and optimization possible. To control complexity and reduce redundancy, we further en-force (i) length constraints to bound the search space, and (ii) expression-tree pruning to remove syntactically distinct but semantically equivalent factors. (2) Structure Characterization of Alpha Space . Building on this grammar-based language, we cast alpha discovery as a large Tree-Structured Linguistic Markov Decision Process (TSL-MDP), where each state is a partial expression, termi-nal states represent complete alpha factors, and rewards are given by the information coefficient (IC) on real market data.  

> 1Our source code is available at https://github.com/ HanYang544/AlphaCFG

This formulation transforms alpha discovery from unstruc-tured trial-and-error into a principled sequential decision process over the space of formulaic alpha factors. (3) Reinforcing MCTS with Syntax-Aware Learning . Fi-nally, we design a learning and search algorithm that ex-ploits the grammar-induced structure of the TSL-MDP. We employ a grammar-aware Monte Carlo Tree Search (MCTS), in which action selection is guided by a syntax-aware Upper Confidence Bound (UCB) rule. To generalize across the large state space, each partial expression tree is encoded using a Tree-LSTM, yielding structure-aware representa-tions shared by a value network, which estimates expected performance from historical market data, and a policy net-work, which predicts promising alpha expansions. Through reinforced interaction between MCTS and these learned models, AlphaCFG progressively refines its search strategy and discovers high-quality alpha factors efficiently. AlphaCFG is not limited to trading strategies and naturally extends to other quantitative finance tasks, by allowing flex-ible customization of operators, grammatical structures, and objective functions. We use trading as a representative testbed to demonstrate the effectiveness of AlphaCFG. We evaluate AlphaCFG on CSI 300 and S&P 500 stocks, where it consistently outperforms strong baselines across multi-ple metrics, including returns, information coefficient (IC), Sharpe ratio, and maximum drawdown. Our results show that improved grammar design yields faster convergence and higher-quality factors. Moreover, AlphaCFG effectively refines existing factors and improves their predictive perfor-mance , highlighting its utility as a general tool for factor refinement and augmentation. Ablation studies further con-firm the critical roles of grammar design and syntax-based representation learning in effective factor discovery. 

## 2. Problem Formulation 

Consider a market with n stocks over T trading days. On each day t ∈ { 1, 2, . . . , T }, stock i is associated with a feature matrix xt,i ∈ Rm×τ ′

, which records m raw market features (e.g., opening and closing prices, volumes) over τ ′

days. We denote by Xt = ( xt, 1, xt, 2, . . . , xt,n ) the collec-tion of features for all stocks on day t.An alpha factor is a function f : Rm×τ ′

→ R that maps the historical features of a single stock to a scalar score. Apply-ing f cross-sectionally to all stocks on day t yields a factor vector yt = ( yt, 1, . . . , y t,n ) ∈ Rn, where yt,i = f (xt,i )

(illustrated in Figure 6a). These scores are subsequently used to rank stocks or construct portfolios. We focus on formulaic alpha factors, which are explicit mathematical expressions constructed from a predefined set of input features (Table 4), constants (Table 5), and operators (Table 6). These operators and operands are commonly used 2Alpha Discovery via Grammar-Guided Learning and Search 

in quantitative finance (Yang et al., 2020). Representative examples are shown in Figure 6b. 

Evaluation via Information Coefficient. The predictive quality of an alpha factor is evaluated using the Information Coefficient (IC), a standard metric in asset management (Grinold & Kahn, 2000). For a given prediction horizon τ ,the realized τ -day return of stock i observed at day t is 

r(τ ) 

> t,i

= Close t+τ,i 

Close t,i 

− 1, (1) where Close t,i is the closing price of stock i on day t. Let 

r(τ ) 

> t

= ( r(τ ) 

> t, 1

, . . . , r (τ ) 

> t,n

) denote the cross-sectional return vector. The daily IC at day t is defined as the Pearson correlation between factor scores and subsequent returns: 

IC t(yt, r(τ ) 

> t

) =     

> Pni=1 (yt,i −¯yt)( r(τ)
> t,i −r(τ)
> t)

√Pni=1 (yt,i −¯yt)2    

> qPni=1 (r(τ)
> t,i −r(τ)
> t)2

,

where ¯yt = 1

> n

Pni=1 yt,i and r(τ ) 

> t

= 1

> n

Pni=1 r(τ ) 

> t,i

.To assess factor performance over the entire period, we use average daily IC of alpha factor f :

IC( f ) = 1

T

> T

X

> t=1

IC t

 yt, r(τ )

> t

. (2) A higher IC( f ) indicates stronger predictive power. Accord-ingly, the goal of alpha discovery is to identify formulaic factors that maximize IC( f ).In practice, a common and effective strategy is to linearly combine multiple factors. Following AlphaGen (Yu et al., 2023), we optimize the IC of such linear combinations (re-ferred to as a factor pool ). The detailed combination proce-dure is provided in Algorithm 1 in Appendix B.1. 

## 3. Design Language of Interpretable Alphas 

The space of formulaic alpha factors grows combinatori-ally with expression length, rendering brute-force search inefficient. Moreover, a large fraction of candidate expres-sions are either syntactically invalid (i.e., ill-formed operator compositions) or semantically nonsensical (i.e., violating financial or temporal constraints), which severely hampers both efficiency and interpretability. From a machine learning perspective, automated alpha dis-covery is therefore not merely an optimization problem, but fundamentally a language design problem : one must de-fine a hypothesis space that is expressive enough to capture meaningful financial signals, while being sufficiently struc-tured to admit efficient search and learning. In the absence of such structure, existing methods are forced to explore an effectively unbounded symbolic space, leading to severe combinatorial explosion and redundant evaluations. To address these challenges, we introduce a formal lin-guistic characterization of alpha factors based on Context-Free Grammar (CFG) (Chomsky & Sch ¨utzenberger, 1959; Hopcroft & Ullman, 1979). By explicitly specifying the syntactic rules that govern valid alpha expressions, we re-strict the search space to well-formed expressions, enforce operator-operand consistency, and enable tree-based search and learning. This linguistic view allows us to systemati-cally decompose the alpha search space into nested levels of validity, as illustrated in Figure 1. 

Σ∗

Lsyn 

Lsem 

L≤k         

> sem
> Figure 1. Nested spaces of alpha expressions: Σ∗(all symbol sequences), Lsyn (syntactically valid), Lsem (semantically valid), and L≤K
> sem (length-bounded semantic alphas).

3.1. Syntactically-Valid Alpha Language 

We begin by defining a grammar that ensures syntactic valid-ity , which serves as the foundation for the following sections of semantic constraints and learning algorithms. Syntactic validity requires that every generated alpha expres-sion be a well-formed and evaluable symbolic program. It entails two conditions: (i) a well-defined hierarchical struc-ture enforced by prefix notation and recursive nonterminal expansion; and (ii) strictly follow operator arity, so that each operator receives the correct number of operands. These are captured by the following generation rule: 

Expr → Op (Expr , . . . ) | TermSyb , (3) where Expr ∈ N denotes a recursively expandable nonter-minal symbol, Op ∈ T denotes prefix-notation operators, and TermSyb ∈ T denotes terminal symbols which are features and constants. 

Structural Well-Formedness. Formula (3) enforces a 

prefix-notation structure in which each operator Op precedes its operands, eliminating ambiguity in operator precedence and evaluation order. Recursive expansion of Expr enables the construction of complex expressions, while termination is ensured by substituting terminal symbols. Therefore, each valid derivation admits a unique hierarchical representation which we call Abstract Syntax Representation (ASR) . 2

> 2In formal language (Hopcroft & Ullman, 1979), an expression corresponds to an abstract syntax tree (AST); we use the term ASR to distinguish it from the large search tree introduced later.

3Alpha Discovery via Grammar-Guided Learning and Search 

Definition 1. An Abstract Syntax Representation (ASR) is a rooted, ordered tree encoding a single alpha expression, whose internal nodes are operators with arity-matched chil-dren and whose leaves are features, constants, or (in partial derivations) nonterminal symbols. 

Operator Arity Constraints. Syntactic validity also re-quires that all operators be applied with the correct number of operands. We instantiate Op using operator families with fixed arity, reflecting common primitives in quantitative fi-nance. These include unary operators ( UnaryOp ), binary operators ( BinaryOp ), rolling operators ( RollingOp ), paired rolling operators ( PairedRollingOp ), and nullary terminal symbols ( TermSyb ) representing constants and raw features. The resulting production rules are given by:            

> Expr →UnaryOp (Expr )|BinaryOp (Expr ,Expr )
> |RollingOp (Expr ,Expr )
> |PairedRollingOp (Expr ,Expr ,Expr )
> |TermSyb .

(4) All feature symbols and constants are listed in Table 4 and Table 5, respectively, while Table 6 lists all operators to-gether with their arity categories. These rules fully specify the admissible syntactic forms of alpha expressions. We now formally define the context-free grammar that char-acterizes syntactically valid alpha expressions. 

Definition 2 (α-Syn) . The context-free grammar for a syntactically valid alpha language α-Syn is defined as 

G = ( N , T , P, S) where N is the recursively expandable nonterminal symbols, T is the terminal symbols including stock features (Table 4), numerical constants (Table 5), and operators with fixed arity (Table 6), P is the production rules given in Formula 4, which enforce prefix-notation and strict operator-arity consistency, and S is the start symbol. Definition 2 generates the language Lsyn of syntactically valid alpha expressions, as illustrated in Figure 1. 

3.2. Semantically-Interpretable Alpha Language 

While α-Syn guarantees syntactic validity, it does not en-sure semantic soundness in quantitative trading, as syntax alone cannot capture domain-specific financial constraints such as temporal coherence, numerical admissibility, or eco-nomically meaningful operator interactions. Now we refine 

α-Syn in Definition 2 by embedding domain-informed se-mantic constraints directly into the grammar, thereby defin-ing a semantically interpretable alpha language. 

Semantic Constraints. We enforce a set of minimal and widely accepted financial semantic constraints: (i) Rolling window constraint : the window-size operand of RollingOp 

and PairedRollingOp is integer constant; (ii) Non-triviality :expressions cannot consist solely of constants and operators; (iii) Numerical validity : operands must lie within domains consistent with their operators; (iv) Time-series consistency :

PairedRollingOp must operate on two time-varying features; constant operands are disallowed. 

Definition 3 (α-Sem) . A semantic refinement of α-Syn is a context-free grammar G = ( N ′, T ′, P′, S) that shares the same start symbol S as α-Syn. The nonterminal symbols T ′

add Num and Constant. The Terminal symbols T is refined to containing features in Table 4, constant in Table 5 and operators in Table 6. The production rules P′ distinguishes the type of operands by:                         

> Expr →Feature |UnaryOp (Expr )
> |BinaryOp (Expr ,Expr )|BinaryOp (Expr ,Constant )
> |BinaryOp Asym (Constant ,Expr )
> |RollingOp (Expr ,Num )
> |PairedRollingOp (Expr ,Expr ,Num ),
> Num →20 |. . . , Constant → − 0.01 |. . .

The terminal symbols and operators of α-Sem can be revised or extended beyond Table 4, Table 5, and Table 6 to support other domains or tasks in quantitative finance. 

Length Bounded Grammar α-Sem-k. Although α-Sem enforces both syntactic and semantic validity, its recursive production rules can still generate expressions of unbounded depth, leading to an intractable search space. We apply k-bounded constraint , which assign each alpha expression with a length counter k capped at K. Each production rule incurs an incremental cost ∆k (Table 7), and a rule may be applied only if k + ∆ k ≤ K. This constraint yields a bounded semantic grammar α-Sem-k (Algorithm 2). 

3.3. Alpha Space Structure 

Each grammar above ( α-Syn, α-Sem, and α-Sem-k) gen-erates a space of many alpha expressions, corresponding to a formal alpha language , denoted by Lsyn , Lsem , and 

L≤K

> sem

, respectively. These languages are naturally nested, as illustrated in Figure 1, with each successive layer imposing additional constraints and yielding a progressively smaller and more structured hypothesis space for alpha discovery. Among them, the k-bounded semantic grammar α-Sem-k

plays a central role in this work. Bounding the derivation depth while enforcing both syntactic and semantic validity yields a finite yet expressive language L≤K

> sem

, enabling sys-tematic search. A detailed analysis of the space complexity of L≤K 

> sem

is provided in Appendix E. 

Definition 4 (Search Space Structure) . Given a grammar α-Syn, α-Sem, or α-Sem-k, the corresponding alpha language can be represented as a rooted tree. The root node corre-sponds to the start symbol, each edge corresponds to the 4Alpha Discovery via Grammar-Guided Learning and Search  

> Figure 2. The tree-structured search space.

application of a production rule, intermediate nodes repre-sent partially derived expressions, and leaf nodes correspond to fully derived alpha factors. This formulation of Definition 4 fundamentally changes the nature of alpha discovery. Rather than exhaustive searching over the unstructured and infinite symbol space Σ∗, alpha discovery can now be viewed as exploring a tree-structured language space L≤K 

> sem

induced by α-Sem-k. In this view, our alpha discovery reduces to identifying high-quality leaf nodes within a large but well-organized derivation tree. Figure 2 illustrates the structure of the space of all alpha expressions under α-Sem-k. In this tree, each rounded-box node corresponds to an alpha expression, which is equiv-alent to an Abstract Syntax Representation (ASR) shown in the middle of the figure. Within each ASR, grey nodes denote nonterminal symbols, colored nodes denote terminal symbols, and edges represent grammar-driven expansion steps. This tree-structured perspective naturally supports tree-based search and learning algorithms. 

## 4. Reinforced Alpha Language Tree Search 

In the previous section, α-Sem-k induces a large yet well-structured tree of candidate alpha factors, where each leaf corresponds to a complete, evaluable expression. Unlike conventional tree search problems, this space combines (i) explosive early branching, (ii) sharp contraction near a depth bound, and (iii) grammar-driven and formula-dependent actions, resulting in highly non-uniform search dynamics. Moreover, the predictive performance of an alpha is revealed only at terminal nodes, which yields long-horizon depen-dencies and sparse rewards. These challenges make unguided search ineffective and mo-tivate a language-principled decision-making formulation. Accordingly, we cast alpha discovery as a Tree-Structured Linguistic Markov Decision Process (TSL-MDP) and de-velop a reinforcement learning–guided, grammar-aware MCTS framework, supported by syntax-aware represen-tation learning for efficient policy and value estimation. 

4.1. Decision-Making on Large Tree 

With Definition 4, alpha discovery can be viewed as a se-quential decision process over a large derivation tree. Equiv-alently, the task reduces to: (i) selecting a high-quality root-to-leaf path that yields a strong alpha, or (ii) expanding an intermediate node (e.g., a partially specified or masked factor) into a more predictive expression. In this search tree, each complete alpha factor (leaf node) is evaluated by the average IC in Equation (2), computed from historical market data (Figure 2, Algorithm 1). This IC serves as the reward signal and can be propagated backward along the derivation path, assigning value estimates to inter-mediate nodes. Consequently, partial expressions naturally correspond to states, grammar production rules to actions, and derivation steps to state transitions. This perspective leads to a principled formulation of grammar-guided alpha discovery as a Markov Decision Pro-cess, which we term the Tree-Structured Linguistic Markov Decision Process (TSL-MDP) .

Definition 5 (TSL-MDP) . Alpha discovery under α-Sem-k

is a Tree-Structured Linguistic Markov Decision Process TSL-MDP = ⟨S, A, P, R, γ ⟩, where S is the set of partial or complete alpha expressions; A is the set of grammar production rules in Definition 3; P (s′ | s, a ) deterministi-cally applies rule a to expand the leftmost nonterminal in s,yielding a longer alpha expression s′; and reward R(s, a ) is nonzero only when s′ is a complete alpha expression, equal to its IC evaluated on market data. 

4.2. Reinforcement Learning Guided MCTS 

While the tree structure of TSL-MDP makes it amenable to search, classical MCTS becomes ineffective at this scale due to long-horizon dependencies, highly irregular branching, and the absence of intermediate rewards. We embed MCTS into a reinforcement learning framework that is explicitly tailored to grammar-based alpha generation. Specifically, two neural networks are introduced: a policy network that predicts promising grammar production rules conditioned on a partial expression, and a value network that estimates the expected predictive quality of an incomplete alpha. Both networks are driven by a Tree-LSTM encoder (Tai et al., 2015) that consumes the Abstract Syntax Rep-resentation (Definition 1) of the current alpha expression, enabling structure-aware generalization across the vast TSL-MDP state space. Our framework is illustrated in Figure 7. 

Overall Interaction Between RL and MCTS. Starting from the start symbol of α-Sem, alpha generation proceeds iteratively. At each iteration j, we perform I rounds of grammar-aware MCTS guided by the current policy and value networks. The resulting search statistics induce a dis-5Alpha Discovery via Grammar-Guided Learning and Search  

> Figure 3. Grammar-aware reinforcement learning and MCTS, based on alpha representation and value and policy networks.

tribution over different production rules at the root, from which an action is sampled to expand to a node in the next layer of the search tree, which increases the current alpha expression. The expanded node in this new layer then be-comes the new root, and the process repeats until a complete alpha expression is generated. Each completed alpha yields an IC reward, forming a trajectory of grammar decisions. By collecting such trajectories, we iteratively update the policy and value networks via reinforcement learning, resulting in an effective search–learn–search loop. An overview of this interaction is illustrated in Figure 7, with the corresponding pseudocode provided in Algorithm 4. 

MCTS Components. At a given root state j, the MCTS agent incrementally explores a subtree of the TSL-MDP through repeated simulations. Then it executes the following components (see Figure 3 (a) and Appendix B.3 for details). 

Selection. From the root, the MCTS agent repeatedly ap-plies an α-CFG production rule to the leftmost nonterminal symbol until reaching a frontier node which has not yet been expanded. The TSL-MDP exhibits highly irregular branching, with depth-dependent numbers of applicable pro-duction rules. We therefore introduce an adaptive branching factor in the PUCT formulation, where b denotes the number of valid actions at the current state and bref is a normaliza-tion constant given by the maximum branching factor. The ratio 

q bbref modulates the exploration term, emphasizing ex-ploitation for small branching factors and promoting broader exploration for larger ones. Accordingly, we use the adapted PUCT-style selection rule (Silver et al., 2017): 

a∗ = arg max a



Q(s, a ) + cpuct 

q bbref P (s, a )

√P   

> bN(s,b )1+ N(s,a )



Expansion and Evaluation . Upon reaching a frontier node, all valid α-CFG production rules are applied to generate its child states. The resulting node is evaluated using a Tree-LSTM–based value network V (s), which estimates the expected terminal reward of the corresponding partial expression. Meanwhile, a policy network produces a distri-bution P (s, a ) over valid production rules, providing prior guidance for future selections. 

Backpropagation . The evaluation result V (s) is backprop-agated along the selection path, updating Q(s, a ) and visit counts N (s, a ). Iterating these steps allow MCTS agent progressively expands its explored subtree and refines the search statistics over the TSL-MDP (Algorithm 3). 

4.3. Syntax Representation Learning Network Design. The main challenge in TSL-MDP is its vast state space, which requires evaluating both partial and complete alpha expressions as well as policies for expand-ing them. Since each state is naturally represented by an ASR (Definition 1), we employ syntax-aware representa-tion learning that directly encodes structure and semantics, which avoids costly rollout-based evaluations in classical MCTS. Moreover, due to the symmetry of some operators (e.g., commutative operands), there are a large number of isomorphic factor expressions (defined in Definition 6) in TSL-MDP. Syntax-aware representation learning is suitable for addressing these redundancies as it operates directly on ASRs rather than linear sequence. Accordingly, we use a Tree-LSTM encoder (Tai et al., 2015) with two heads: a policy head for predicting production-rule distributions and a value head for estimating terminal rewards (details are provided in Appendix F). As shown in Figure 3 (b), the Tree-LSTM recursively aggregates in-6Alpha Discovery via Grammar-Guided Learning and Search 

Table 2. Evaluation metrics comparison of different methods (5 random seeds). 

CSI300 

Method Rank IC IC Rank ICIR ICIR Sharpe Max Drawdown XGBoost 0.0288 (0.0000) 0.0326 (0.0000) 0.2895 (0.0000) 0.2818 (0.0000) 0.2853 (0.0000) -0.2777 (0.0000) 

LightGBM 0.0539 (0.0029) 0.0296 (0.0014) 0.3963 (0.0247) 0.2649 (0.0395) 0.2680 (0.0666) -0.3271 (0.0177) LSTM 0.0128 (0.0260) 0.0127 (0.0136) 0.0896 (0.2064) 0.1041 (0.1060) 0.1268 (0.0425) -0.3542 (0.0240) TCN 0.0303 (0.0236) 0.0085 (0.0133) 0.2726 (0.1855) 0.0871 (0.1557) 0.0908 (0.0754) -0.2988 (0.0191) ALSTM 0.0138 (0.0076) 0.0105 (0.0067) 0.1194 (0.0540) 0.0950 (0.0550) 0.1372 (0.1113) -0.3475 (0.0501) Transformer 0.0423 (0.0133) 0.0248 (0.0132) 0.3759 (0.0697) 0.2457 (0.0971) 0.1699 (0.1105) -0.3365 (0.0377) gplearn 0.0706 (0.0119) 0.0440 (0.0139) 0.4695 (0.1164) 0.3478 (0.1397) 0.2062 (0.2346) -0.3854 (0.0324) AlphaQCM 0.0811 (0.0046) 0.0525 (0.0048) 0.5334 (0.0296) 0.3874 (0.0121) 0.4363 (0.0610) -0.3605 (0.0339) RPN+PPO(AlphaGen) 0.0837 (0.0070) 0.0477 (0.0086) 0.5724 (0.0343) 0.3531 (0.0574) 0.4978 (0.1478) -0.3497 (0.0423) 

Ablation Studies 

RPN+MCTS 0.0710 (0.0031) 0.0500 (0.0026) 0.5577 (0.0292) 0.4285 (0.0293) 0.5639 (0.1050) -0.3201 (0.0613) 

α-Syn+MCTS 0.0745 (0.0052) 0.0487 (0.0036) 0.5125 (0.0467) 0.3974 (0.0367) 0.4852 (0.1320) -0.3475 (0.0414) 

α-Sem+MCTS 0.0770 (0.0044) 0.0512 (0.0015) 0.5593 (0.0340) 0.4369 (0.0301) 0.5801 (0.1169) -0.3039 (0.0206) 

α-Sem-k+MCTS(AlphaCFG) 0.0865 (0.0060) 0.0577 (0.0029) 0.6036 (0.0537) 0.4505 (0.0249) 0.6459 (0.0612) -0.2963 (0.0289) 

S&P500 

Method Rank IC IC Rank ICIR ICIR Sharpe Max Drawdown XGBoost 0.0140 (0.0000) 0.0104 (0.0000) 0.1535 (0.0000) 0.1456 (0.0000) 0.5883 (0.0000) -0.2543 (0.0000) LightGBM 0.0078 (0.0021) 0.0220 (0.0032) 0.0860 (0.0269) 0.2072 (0.0229) 0.5852 (0.0547) -0.2047 (0.0128) LSTM 0.0131 (0.0077) 0.0219 (0.0040) 0.1157 (0.0786) 0.1847 (0.0419) 0.5601 (0.0546) -0.2345 (0.0142) TCN 0.0198 (0.0040) 0.0166 (0.0020) 0.1358 (0.0190) 0.1340 (0.0133) 0.4973 (0.0271) -0.2396 (0.0175) ALSTM 0.0202 (0.0028) 0.0268 (0.0039) 0.1569 (0.0344) 0.1993 (0.0391) 0.4441 (0.0397) -0.2418 (0.0109) Transformer 0.0106 (0.0049) 0.0185 (0.0036) 0.0828 (0.0433) 0.1806 (0.0361) 0.5979 (0.1163) -0.2512 (0.0070) gplearn 0.0130 (0.0122) 0.0322 (0.0110) 0.0812 (0.0643) 0.1877 (0.0437) 0.8241 (0.1814) -0.2456 (0.0434) AlphaQCM 0.0178 (0.0055) 0.0384 (0.0056) 0.1149 (0.0381) 0.2527 (0.0336) 1.0566 (0.0756) -0.2105 (0.0273) RPN+PPO(AlphaGen) 0.0149 (0.0055) 0.0342 (0.0050) 0.1045 (0.0364) 0.2420 (0.0296) 0.8271 (0.1421) -0.2559 (0.0242) 

Ablation Studies 

RPN+MCTS 0.0309 (0.0054) 0.0385 (0.0031) 0.2447 (0.0234) 0.3308 (0.0344) 0.7992 (0.0854) -0.1957 (0.0140) 

α-Syn+MCTS 0.0111 (0.0017) 0.0272 (0.0047) 0.0913 (0.0087) 0.2335 (0.0356) 0.8046 (0.0322) -0.2286 (0.0186) 

α-Sem+MCTS 0.0265 (0.0011) 0.0413 (0.0030) 0.2075 (0.0108) 0.3360 (0.0162) 0.8315 (0.0855) -0.2243 (0.0225) 

α-Sem-k+MCTS(AlphaCFG) 0.0354 (0.0026) 0.04573 (0.0034) 0.2958(0.0154) 0.4099 (0.0230) 0.8473 (0.0483) -0.1942 (0.0126) 

formation, producing a fixed-dimensional state embedding for each ASR. This embedding is shared by both policy network for production-rule prediction and value network for state-value estimation in MCTS. 

Train and Sampling Procedure. The policy and value net-works are trained jointly using Tree-LSTM representations of TSL-MDP states. Initially, both networks are randomly initialized and used to guide MCTS expansion and evalua-tion. The resulting search statistics define an initial policy for alpha generation, which is then used to: (i) supervise the policy network via imitation of the MCTS-derived ac-tion distribution, and (ii) sample complete alpha expressions whose IC values (from market data) provide supervision for the value network. In subsequent iterations, the updated networks guide new MCTS constructions, and the process repeats until enough alphas have been sampled. 

Diversity-Aware Value Target. Since the ultimate ob-jective is to construct a composite factor IC F (See Algo-rithm 1), generating expressions that are structurally similar to existing factors can reduce pool diversity and degrade overall performance. To mitigate this, we incorporate a diversity-aware adjustment into the value target. Specifi-cally, we define a normalized structural similarity measure 

sim( ·, ·), based on maximum common subtree matching (Sager et al., 2006) between the newly generated ASR fj

corresponding to state sj and any existing ft ∈ F . This similarity penalizes states whose grammatical structures overlap with F. The resulting value target is defined as 

z(sj ) =  1 − max(0 , max  

> ft∈F

sim( ft, f j ))  · IC F . (5) More details about tree similarity can be seen in Section G. 

## 5. Experiments 

Detailed experimental settings, including datasets, compari-son methods, evaluation metrics, and hyperparameters, are provided in the Appendix (Section I.1, Section I.2, Sec-tion I.3, and Section H). Analysis on network architectures and mined factor examples with interpretability discussions are presented in Section I.4 and Section I.6, respectively. 

Comparison of Generation Spaces. We first compare dif-ferent factor generation spaces (Figure 1) to evaluate the impact of language constraints on factor discovery. Specif-ically, we compare three CFG levels with Reverse Polish Notation (RPN) (Krtolica & Stanimirovi ´c, 2004), a com-putation and verification formalism with a non-recursive 7Alpha Discovery via Grammar-Guided Learning and Search 

structure, on the CSI 300 and S&P 500 training datasets. With a pool size of 10 and max length 5, Figure 4 shows the training IC across epochs. Results confirm our analysis in Section 3.3, where more constrained, grammar-defined spaces yield faster convergence and higher-quality factors. Although RPN converges to a performance level close to 

α-Sem, its convergence is noticeably slower. This behavior reflects the limited semantic and length constraints of RPN, whose non-recursive structure restricts its effectiveness for structured factor generation compared to α-Sem. 0 50 100 150 200     

> Epoch
> 0.04 0.06 0.08
> Train IC CSI 300
> 050 100 150 200
> Epoch
> 0.04 0.06 0.08
> Train IC S&P 500
> RPN α-Sem-k α-Sem α-Syn

Figure 4. Comparison of training curves of generation methods. 

Comparison with Existing Alpha Mining Methods. To create a fair comparison environment, we use the optimized hyperparameters from the validation dataset experiments (see details in Appendix I.5) for each method, including our MCTS-based methods ( α-Syn, α-Sem, α-Sem-k and RPN) against existing factor mining methods or prediction mod-els (formulaic: Alphagen, AlphaQCM, GPlearn; ML-based: XGBoost, LightGBM, LSTM, ALSTM, TCN, Transformer). The experiments were conducted separately on the CSI 300 index and the S&P 500 constituents testing data, evaluat-ing both correlation-based metrics and backtesting perfor-mance. The backtesting results are obtained using a single top-k/drop-n strategy to conduct simulated trading based on real stock data (detailed in Appendix I.3). Quantitative results are summarized in Table 2, and cumulative return curves are shown in Figure 5. Overall, our method achieves the best performance across all correlation metrics directly related to the optimization target IC. Ablation studies further demonstrate the indis-pensable roles of syntactic constraints, semantic constraints, and length control. While formulaic factor mining methods generally outperform machine-learning models that directly predict returns in correlation metrics, our approach also achieves strong backtesting performance. Despite not di-rectly optimizing for backtesting objectives, our method con-sistently attains superior Sharpe ratios and lower maximum drawdowns, and achieves the highest overall profitability among all compared methods. 

Improving Traditional Alpha Factors. Beyond directly mining composite factors, our α-Sem-k+MCTS framework can be used to refine existing interpretable alpha factors. We select a set of classic but recently ineffective factors from the GTJA 191 Factor Library and the Alpha101 Fac-tor Library (Kakushadze, 2016). Factors from the GTJA 2021-01 2021-07 2022-01 2022-07 2023-01 2023-07 2024-01 2024-07 2025-01 

> Date
> -20%
> 0%
> 20%
> 40%
> 60%
> Cumulative Return

(a) CSI 300 2021-01 2021-07 2022-01 2022-07 2023-01 2023-07 2024-01 2024-07 2025-01 

> Date
> -20%
> 0%
> 20%
> 40%
> 60%
> 80%
> 100%
> 120%
> Cumulative Return
> XGBoost
> LightGBM
> LSTM
> ALSTM
> TCN
> Transformer
> GP
> Alphagen
> AlphaQCM
> Index
> ours

(b) S&P 500 

Figure 5. Cumulative return comparison in simulated trading 

191 library are refined using the CSI 300 dataset, while Al-pha101 factors are refined using the S&P 500 dataset. By partially masking operators and operands while preserving the left-side structure within half of the original expression length, we optimize these factors using a single-factor re-ward objective (illustrated by the blue path in Figure 2). As shown in Table 3, our framework consistently improves the absolute IC values of many classic factors on the test datasets, demonstrating its effectiveness in strengthening existing alpha signals. 

Table 3. Refinement Results: Test Set IC Before and After Apply-ing α-Sem-k+MCTS framework.             

> GTJA191
> Original: open/Ref(close,1)-1 0.00185 Improved: open/0.1-Cov(volume,high,20) 0.04279 Original: Mean(close,6)-close 0.00482 Improved: Mean(Cov(vwap,volume,20)/(-0.01),20)/0.05 0.04262 Original: close-Ref(close,5) 0.00495 Improved: close-Greater(-0.1,Cov(volume, |vwap |,30)) 0.03872
> Alpha101
> Original: -Corr(open,volume,10) 0.00271 Improved: Corr(open,Log( |open |),40)·CSRank(high) 0.02934 Original: -Rank(CSRank(low),9) 0.01031 Improved: Rank(CSRank(CSRank(Sign(vwap))),30)·CSRank(high) 0.02944 Original: Pow(high· low,0.5)-vwap) 0.00112 Improved: Pow(CSRank( |open |)·open,CSRank(close))-vwap 0.03126

## 6. Conclusion 

AlphaCFG formulates alpha factor discovery as a grammar-guided, syntax-tree–structured search problem that enforces interpretability while enabling efficient integration of rein-8Alpha Discovery via Grammar-Guided Learning and Search 

forcement learning with neural Monte Carlo Tree Search. Beyond trading, the framework naturally extends to other factor-based quantitative finance tasks. More broadly, Al-phaCFG exemplifies grammar-guided symbolic regression, where domain knowledge is encoded directly in the search space rather than learned implicitly from data. A promising direction for future work is to integrate AlphaCFG with large-scale learned priors, such as foundation models over programs or syntax trees, to further accelerate search and improve generalization in structured reasoning problems. 9Alpha Discovery via Grammar-Guided Learning and Search 

## References 

Bhandari, H. N., Rimal, B., Pokhrel, N. R., Rimal, R., Da-hal, K. R., and Khatri, R. K. Predicting stock market index using lstm. Machine Learning with Applications ,9:100320, 2022. Bisdoulis, K.-L. Assets forecasting with feature engineering and transformation methods for lightgbm. arXiv preprint arXiv:2501.07580 , 2024. Carhart, M. M. On persistence in mutual fund performance. 

The Journal of Finance , 52(1):57–82, 1997. Chomsky, N. and Sch ¨utzenberger, M. P. The algebraic theory of context-free languages. In Studies in Logic and the Foundations of Mathematics , volume 26, pp. 118–161. Elsevier, 1959. Dai, W., An, Y., and Long, W. Price change prediction of ultra high frequency financial data based on temporal convolutional network. Procedia Computer Science , 199: 1177–1183, 2022. Fama, E. F. and French, K. R. The cross-section of expected stock returns. The Journal of Finance , 47(2):427–465, 1992. Grinold, R. C. and Kahn, R. N. Active portfolio manage-ment. 2000. Hopcroft, J. E. and Ullman, J. D. Automata Theory, Lan-guages, and Computation . Addison-Wesley, 1979. Jin, L., Doshi-Velez, F., Miller, T., Schuler, W., and Schwartz, L. Unsupervised grammar induction with depth-bounded pcfg. Transactions of the Association for Computational Linguistics , 6:211–224, 2018. Kakushadze, Z. 101 formulaic alphas. Wilmott , (84):72–81, 2016. Krtolica, P. V. and Stanimirovi ´c, P. S. Reverse polish nota-tion method. International Journal of Computer Mathe-matics , 81(3):273–284, 2004. Lee, J. W. Stock price prediction using reinforcement learning. In ISIE 2001. 2001 IEEE International Sym-posium on Industrial Electronics Proceedings (Cat. No. 01TH8570) , volume 1, pp. 690–695. IEEE, 2001. Makke, N. and Chawla, S. Interpretable scientific discovery with symbolic regression: a review. Artificial Intelligence Review , 57(1):2, 2024. Mozaffari, L. and Zhang, J. Predictive modeling of stock prices using transformer model. In Proceedings of the 2024 9th International Conference on Machine Learning Technologies , pp. 41–48, 2024. Qin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., and Cottrell, G. A dual-stage attention-based recurrent neu-ral network for time series prediction. arXiv preprint arXiv:1704.02971 , 2017. Sager, T., Gall, H. C., Pinzger, M., and Bernstein, A. De-tecting similar java classes using tree algorithms. In 

Proceedings of the 2006 ACM Symposium on Applied Computing , pp. 654–661, 2006. Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M., Bolton, A., et al. Mastering the game of go without human knowledge. nature , 550(7676):354–359, 2017. Tai, K. S., Socher, R., and Manning, C. D. Improved seman-tic representations from tree-structured long short-term memory networks. arXiv preprint arXiv:1503.00075 ,2015. Wang, J., Cheng, Q., and Dong, Y. An xgboost-based multivariate deep learning framework for stock index futures price forecasting. Kybernetes , 52(10):4158–4177, 2023. Xu, Q. Unsupervised temporal encoding for stock price prediction through dual-phase learning. In Proceedings of the 2025 International Conference on Economic Man-agement and Big Data Application , pp. 778–784, 2025. Yang, X., Liu, W., Zhou, D., Bian, J., and Liu, T.-Y. Qlib: An ai-oriented quantitative investment platform. arXiv preprint arXiv:2009.11189 , 2020. Yu, S., Xue, H., Ao, X., Pan, F., He, J., Tu, D., and He, Q. Generating synergistic formulaic alpha collections via reinforcement learning. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining , pp. 5476–5486, 2023. Zhang, T., Li, Y., Jin, Y., and Li, J. Autoalpha: an ef-ficient hierarchical evolutionary algorithm for mining alpha factors in quantitative investment. arXiv preprint arXiv:2002.08245 , 2020. Zhu, Z. and Zhu, K. Alphaqcm: Alpha discovery in fi-nance with distributional reinforcement learning. In Forty-second International Conference on Machine Learning ,2025. 10 Alpha Discovery via Grammar-Guided Learning and Search 

## A. Tables 

Table 4. Stock Feature Variables 

Feature Description 

open Opening price high Highest price low Lowest price close Closing price volume Trading volume vwap Volume Weighted Average Price (VWAP) 

Table 5. Constant Parameters 

Nonterminal Values 

Constant −0.1, −0.05 , −0.01 , 0.01 , 0.05 , 0.1

Num 20 , 30 , 40 

Table 6. Formulaic Alpha Factor Operators in Our Framework (the BinaryOp in Formula (4) does not distinguish whether it is symmetric) 

Operator Type Description 

Abs (x) Unary Absolute value, |x|.Sign (x) Unary Returns the sign of x: 1 for positive, -1 for negative, 0 for zero. Log (x) Unary Natural logarithm, log( x).Add (x, y ) Binary Addition, x + y.Mul (x, y ) Binary Multiplication, x · y.Greater (x, y ) Binary Returns the larger of two values: max( x, y ).Less (x, y ) Binary Returns the smaller of two values: min( x, y ).Div (x, y ) Binary-Asym Division, x/y .Pow (x, y ) Binary-Asym Exponentiation, xy .Sub (x, y ) Binary-Asym Subtraction, x − y.CSRank (x) Rolling Cross-sectional ranking (normalizes the rank of x across all stocks on the same day). Rank (x, t ) Rolling Time-series ranking of x over the past t days. WMA (x, t ) Rolling Weighted moving average with weights decaying over time. EMA (x, t ) Rolling Exponential moving average with recursive smoothing. Ref (x, t ) Rolling Value of x from t days ago. Mean (x, t ) Rolling Mean of x over the past t days, 1

> t

Pt−1 

> i=0

x−i.Sum (x, t ) Rolling Sum of x over the past t days, Pt−1 

> i=0

x−i.Std (x, t ) Rolling Standard deviation of x over the past t days. Var (x, t ) Rolling Variance of x over the past t days. Skew (x, t ) Rolling Skewness (measure of asymmetry) of x over the past t

days. Kurt (x, t ) Rolling Kurtosis (measure of tail thickness) of x over the past t

days. Max (x, t ) Rolling Maximum value of x over the past t days. Min (x, t ) Rolling Minimum value of x over the past t days. Med (x, t ) Rolling Median of x over the past t days. Mad (x, t ) Rolling Mean absolute deviation, 1

> t

Pt−1 

> i=0

|x−i − ¯x|.Delta (x, t ) Rolling Difference, x − Ref (x, t ).Cov (x, y, t ) PairedRolling Covariance between x and y over the past t days. Corr (x, y, t ) PairedRolling Pearson correlation coefficient between x and y over the past t days. 

11 Alpha Discovery via Grammar-Guided Learning and Search                                       

> Table 7. Length increments ∆kfor each production rule.
> Production Rules ∆k
> Expr →Feature 0
> Num →20 . . . 0
> Constant → − 0.01 . . . 0
> Expr →UnaryOp (Expr )1
> Expr →BinaryOp (Expr ,Expr )2
> Expr →BinaryOp (Expr ,Constant )2
> Expr →BinaryOp Asym (Constant ,Expr )2
> Expr →RollingOp (Expr ,Num )2
> Expr →PairedRollingOp (Expr ,Expr ,Num )3

## B. Algorithms 

B.1. Linear combination alpha factor algorithm 

The linear combination factor model is defined as 

c(X; F, w ) = 

> n

X

> j=1

wj fj (X) = y, (6) where F = {f1, . . . , f n} denotes the set of factors, w = {w1, . . . , w n} are the weights of factors in linear combination , X

represents the input stock feature data, and y is the combined output. The optimization is conducted by minimizing the loss function 

L(w) = 1

T

> T

X

> t=1

∥yt − rt∥2 (7) where rt is the actual stock return, and yt is the alpha value of linear combination factor. 

Algorithm 1 Incremental Combination Model Optimization 

Input: alpha set F = {f1, . . . , f n}, weights w = {w1, . . . , w n}, new alpha fnew 

Output: optimal alpha subset F ∗, optimal weights w∗, combination IC IC F

F ← F ∪ { fnew }

w ← w ∥ rand() 

for i = 1 to num gradient steps do 

Compute loss L(w) according to Eq. (7) 

w ← GradientDescent (L(w)) 

end for 

p ← arg min i |wi|

F ← F \ { fp}; w ← w \ { wp}

Compute the combination IC: IC F ← IC (F, w )

Return F, w, IC F

B.2. Length control of semantic interpretable alpha factor generator 

Following the intuition of grammar-constrained generation (Jin et al., 2018), we introduce a k-bounded constraint to explicitly limit expression length. The mechanism maintains a counter k for the partial length of the expression and enforces a maximum threshold K. Each production rule has a predefined increment ∆k, representing its contribution to the expression length(see Table 7 for details). A rule is applied only if k + ∆ k ≤ K, thereby guaranteeing that each expansion step remains within the feasible bound. By integrating this length-aware constraint into the derivation procedure, we obtain a bounded variant of α-Sem, denoted as α-Sem-k. The procedure is described in Algorithm 2. 12 Alpha Discovery via Grammar-Guided Learning and Search 

Algorithm 2 α-Sem-k

Input: Grammar G = ( N , T , P, S), maximum length K, rule increments ∆k : Γ → β

Output: Prefix expression tree T

Initialize T as a single-node tree with root S

Set: k ← 0

while T contains a nonterminal node do 

Let u be the first nonterminal node in a pre-order traversal of T

Compute the set of applicable rules: 

A ← { l ∈ P | l is applicable to u and k + ∆ k(l) ≤ K}

Choose rule l : Γ → β from A

Replace node u with children corresponding to β

Update: k ← k + ∆ k(l)

end while Return T

B.3. Algorithm of Four Stages of MCTS Algorithm 3 Grammar-aware MCTS with Branch-adapted PUCT 

Input: root state sroot , policy-value network fθ , iteration count I

Output: improved policy π(a | sroot )

for i = 1 to I do 

s ← sroot 

Initialize empty list of traversed edges E ← [ ] 

while s is not fully expanded do 

b ← number of valid actions from sa∗ ← arg max a

"

Q(s, a ) + cpuct ·

q bbref · P (s, a ) ·√P   

> bN(s,b )1+ N(s,a )

#

Append (s, a ∗) to Es ← apply (s, a ∗)

end while 

sL ← s

(P (sL, ·), V (sL)) ← fθ (sL)

Expand sL using P (sL, ·)

for all (s, a ) ∈ E do 

N (s, a ) ← N (s, a ) + 1 

Q(s, a ) ← 1 

> N(s,a )

P 

> s′|s,a →s′

V (s′)

end for end for 

π(a | sroot ) = N (sroot ,a )1/T   

> P
> b∈A(sroot )N(sroot ,b )1/T

Return π(a | sroot )

Assume that at a certain iteration i, our MCTS has already explored a portion of the TSL-MDP, denoted by an agent Mi.This agent corresponds to a subtree of the large TSL-MDP, sharing the same root, and Mi has obtained policy for this partial subtree. For example, at simulation Mi, the subtree agent Mi shown on the left in Figure 3 has already been explored. This subtree starts as only a root when i = 0 , and is intended to expand toward the full TSL-MDP tree as i increases, eventually reaching iteration i = I.

Selection. First, within Mi, starting from root of the subtree, the MCTS agent repeatedly selects an α-CFG production rule at each incomplete alpha expression (each round-box node), and replaces its leftmost nonterminal symbol (the dark black arrows in Figure 3), which goes to a new incomplete alpha expression (a child round-box node). This repeats until it reaches 13 Alpha Discovery via Grammar-Guided Learning and Search 

a “frontier” alpha expression that has a child not yet included in Mi (e.g., node (1) in Figure 3). The TSL-MDP has two key features: (1) different nonterminal symbols have different numbers of production rules, and (2) the number of valid production rules decreases sharply near the bottom of the search tree due to the length control in B.2. To address this, we adopt a production rule selection function analogous to PUCT (Silver et al., 2017). 

a∗ = arg max  

> a

Q(s, a ) + cpuct ·

q bbref · P (s, a ) ·

pP  

> b

N (s, b )1 + N (s, a )

!

, (8) Here, Q(s, a ) is the value of selecting production rule a for formula s, and P (s, a ) is the probability of selecting a under s.

b is the number of branches at the current depth, and bref is the branch balance constant (defined by the maximum number of branches) Eq. (8) balances irregular branching through the adaptive term pb/b ref : smaller branching factors emphasize exploitation, while larger ones promote broader exploration. 

Expansion. After finding such a frontier alpha expression node, the MCTS agent will execute a certain production rule on it, generating a new alpha expression which has not yet been covered by Mi (e.g., round-box node (2) in Figure 3), and also attaching all the corresponding possible production rules to this new alpha expression (e.g., the two arrows attached to node (2)). The probabilities for executing available production rules for expression s follow the distribution P (s).

Evaluation. Since the newly expanded alpha expression is at the head of the current agent Mt and remains incomplete, the existing policy cannot assess its quality. Thus, MCTS requires a method to evaluate it. Given the vastness of the TSL-MDP, traditional simulation-based evaluation is infeasible. Moreover, as shown in Definition 1, the expressions at any state in TSL-MDP are small tree structures (i.e., the small trees inside each round-box in Figure 3). Therefore, in the next section, we design a Tree-LSTM–based representation learning method to construct a value network for V (s), as well as a policy network P (s, a ) over any expression. 

Backpropagation. The result V (s) of evaluation is backpropagated from the path of selection (the path directed by black arrow in the third tree of Figure 3). Mean value of each edge in the path is updated by V (s) and visit count N (s, a ) of each edge in the path increases by one. The MCTS agent Mi executes the above procedures at each iteration i (Algorithm 3 shows the procedure of MCTS search.). Since one node is expanded at each step, the MCTS agent Mi will eventually cover enough nodes and edges of the TSL-MDP. The resulting search assigns a basic value to every node and obtain a basic policy for the TSL-MDP, which two can be used to further optimize the policy. 

## C. Supplement to Problem Formulation 

Figure 6a illustrates the calculation process of an alpha factor. For a period of T trading days, we compute the alpha factor for each stock using an alpha factor function 

yt = ( yt, 1, . . . , y t,n ) ∈ Rn,

which takes as input the feature data of n stocks over the current day t and the previous τ ′ − 1 days. The resulting values represent the score of each stock for the current day, i.e., the alpha factor. These alpha values are subsequently used for stock selection and the formulation of trading strategies. Figure 6b shows an example of formulaic factor: The factor Sum(Sub( vwap, 1) , 2d) computes the sum of the most recent two days of VWAP values after subtracting 1 from each. To obtain the factor value on Wednesday, the operator first evaluates Sub( vwap, 1) for Tuesday and Wednesday and then aggregates them: (2 − 1) + (3 − 1) = 3 . This output serves as the alpha signal, the predicted return for Wednesday which is subsequently used in downstream stock-selection or portfolio-construction procedures. 14 Alpha Discovery via Grammar-Guided Learning and Search     

> (a) Illustration of an alpha factor. (b) An example of a formulaic factor.
> Figure 6. Alpha example.

## D. Reinforcement Learning Framework 

We present pseudo-code of MCTS combined with reinforcement learning method (Algorithm 4). This is a reinforcement learning-based factor mining method designed to automatically discover a combination of factors from stock market data that can effectively predict stock returns. Specifically, the algorithm initializes a set of factors, their corresponding weights, and a policy-value network. In the process of obtaining data through reinforcement learning, it employs a MCTS policy to generate actions for each state, thereby constructing a multi-step factor generation path. The final state of the path is parsed into a computable alpha expression, evaluated using the IC F as the reward signal. The reward is given along with the optimization of the factor combination F. The actual value for each step along the path, denoted as zt is computed based on IC F and the similarity between the newly generated factor and existing ones, following the formulation in Equation (5) in Section 4.3. After generating multi-step factor paths in each iteration, the policy and value networks are trained using the collected path data (sj , π (a|sj ), z j ) stored in a replay buffer, where sj is the state vector encoded by TreeLSTM, π(a|sj ) is the policy from MCTS, and zt is shown above. After training, the networks are redeployed to guide a new round of search. Through iterative training and exploration, the IC of the learned factor combination is progressively improved. The algorithm outputs the final optimized factor combination set along with its corresponding weights when the IC shows no more significant improvement. The overall workflow of this algorithm is illustrated in Figure 7 in the following page, while a specific illustration of its MCTS component Algorithm 3 is in Figure 3, and the illustration of its neural network part is in Figure 3 (b).  

> Figure 7. The overall framework of AlphaCFG.

15 Alpha Discovery via Grammar-Guided Learning and Search 

Algorithm 4 Alpha Mining via Reinforcement Learning 

Input: stock trend dataset Y = {yt}

Output: optimal alpha subset F ∗, optimal weights w∗

Initialize alpha set F and weights w

Initialize policy-value network fθ and replay buffer D

for each epoch do for each factor path search do 

Initialize empty trajectory E ← [ ] 

for j = 0 to J do 

Append state sj to Esroot ← sj

π(a | sj ) ← π(a | sroot )

Sample action aj ∼ π(a | sj )

sj+1 ← apply (sj , a j )

end for 

fj ← parse (sJ )

Obtain reward IC F using Algorithm 1 

Reward Assignment for j = 0 to J do 

z(sj ) ←



1 − max  0, max ft∈F sim( ft, f j )

· IC F

D ← D ∪ { (sj , π (a | sj ), z (sj )) }

end for end for Network Update for each gradient step do 

Sample minibatch B ⊂ DLθ = ( z(st) − Vθ (st)) 2 − P 

> a

π(a | st) log Pθ (a | st) + c∥θ∥2

θ ← θ − η∇θ Lθ

end for end for Return F ∗, w ∗

## E. Search Space Complexity 

To compare the sizes of expression search spaces under different generation methods, we study three methods from a combinatorial perspective: (i) a purely exponential baseline (arbitrary combination of all symbols corresponding to Σ∗); (ii) α-Syn (corresponding to Lsyn ); (iii) α-Sem (corresponding to Lsyn ). All three methods share the same parameter sets (operator types, number of features, constants, etc.), but progressively impose stricter constraints, resulting in smaller search spaces. We set the following notation: the size of the unary operator set is |U |, the size of the binary operator set is |B|, the size of the asymmetric binary operator set is |Basym |, the size of the rolling operator set is |R|, the size of the paired rolling operator set is |Rpair |, the number of features is |F| , the number of constant parameters is |C| , and the number of rolling-window parameters is |N | .

E.1. Unstructured Space Σ∗

The method of arbitrary symbol combination (referred to ) takes one symbol equally at each step from all available symbols. Let the total number of symbols be: 

r = |F| + |C| + |N | + |U | + |B| + |Basym | + |R| + |Rpair |.

Then the number of sequences of length n is rn = rn, and the cumulative size is P 

> i≤n

ri = Θ( rn).

16 Alpha Discovery via Grammar-Guided Learning and Search 

E.2. Syntactically Legal Space Lsyn 

We introduce syntax constraints to ensure that generated expressions are all syntactically valid. We consider the grammar 

α-Syn: 

Expr → UnaryOp (E) | BinaryOp (E, E ) | RollingOp (E, E ) | PairedRollingOp (E, E, E ) | TermSyb .

Let hn be the number of valid expressions of length n. The terminal set size is: T = |F| + |C| + |N | .

Define operator cardinalities: U = |U |, Q = |B| + |Basym |, R = |R|, P = |Rpair |, respectively(The meanings of the notations are as shown in D). The recurrence formula is: h1 = T, and for n ≥ 2:

hn = U h n−1 + ( Q + R)

> n−2

X

> i=1

hi hn−1−i + P X

> i+j+k=n−1
> i,j,k ≥1

hihj hk.

The subsequent derivation of an explicit form from this recurrence becomes rather cumbersome. Since the technical steps mirror the usual treatment of general cubic functional equations, we omit the full derivation here. 

E.3. Semantically Legal Space Lsem 

α-Sem introduces more constraints on constants, argument types, and rolling windows: 

Expr → Feature | UnaryOp (Expr )

| BinaryOp (Expr , Expr ) | BinaryOp (Expr , Constant )

| BinaryOp Asym (Constant , Expr ) | RollingOp (Expr , Num )

| PairedRollingOp (Expr , Expr , Num ),

Num → 20 | · · · , Constant → − 0.01 | · · · 

Let fn denotes the number of valid expressions of length n.The recurrence formula becomes 

fn = |U | fn−1 (unary) 

+ |B|

> n−2

X

> i=1

fifn−1−i (binary) 

+ |B| |C| fn−2 (binary + right constant) 

+ |Basym | |C| fn−2 (asymmetric binary + left constant) 

+ |R| |N | fn−2 (rolling) 

+ |Rpair | |N | 

> n−3

X

> i=1

fifn−2−i (paired rolling) .

The recurrence formula is similar, and compared with α-Syn, recurrence of α-Sem includes more convolution terms and more realistic constraints, providing a more accurate operator usage. In the following, we present the overall analysis. Because the expression length is unbounded, the search spaces of all three generation methods are infinite. Therefore, the comparison does not concern the total size of each space, but rather the size of the finite subspace consisting of expressions whose length is at most n.17 Alpha Discovery via Grammar-Guided Learning and Search 

For each grammar, the production rules yield a recurrence for the number of expressions of exact length n ) ( rn, h n, f n), and accumulating these values from 1 to n gives the size of the corresponding truncated subspace. By computing these cumulative counts and plotting their growth as functions of n, we can directly compare how quickly the reachable portions of the three search spaces expand. 

E.4. Empirical Verification 

Based on the recurrence formulas, We compute the cumulative counts of {rn}, {hn}, and {fn} for n = 1 ∼ N , and plot their growth curves to visualize differences between the three methods (shown in Figure 8). Since all three methods yield inherently infinite search spaces, we further design α-Sem-k based on Algorithm 2, which can be seen as the red dotted line in Figure 8. The results are consistent with the analysis in Figure 1, which further strengthens the superiority of our approach in theory. Figure 8 explains the core of the superiority of our method: By introducing constraints of syntax and semantics, We get an infinite set containing only valid factors. In actual factor search tasks, we cannot exhaust this space that exploring a finite subset is realistic. Therefore, We utilize the recursive feature of CFG and further designed α-Sem-k capable of generating factors of only a finite length. Ultimately, we reduced the complexity of the search space from an exponential level to a constant level, making this task solvable. 0 10 20 30 40 50 Length 

10 0

10 22 

10 43 

10 65 

> Counts

KCumulative Count w.r.t. Expression Length (Log Scale)  

> *
> syn
> sem
> Figure 8. Comparison of cumulative search space sizes of different grammar levels.

## F. Details of Tree-LSTM 

Starting from ASR leaf nodes, the Tree-LSTM recursively aggregates child hidden and cell states through gating (input, forget, output), combining them with the node’s input embedding. This bottom-up process continues until the root, yielding a fixed-dimensional state vector that encodes both the syntax and operator-specific dependencies of the entire expression. Thus, the Tree-LSTM transforms variable-sized trees into single vectors while preserving structural and semantic information. In our α-CFG, operators are different: ( i) symmetric operators, where order is irrelevant, and ( ii )asymmetrical (order-sensitive) operators, where order must be preserved. Tree-LSTM naturally supports both cases through two variants: the N-ary Tree-LSTM, which uses position-sensitive parameters to encode child order, and the Child-Sum Tree-LSTM, which aggregates child states by their mean to provide order-invariant representations. Based on these, we tailor aggregation strategies: for symmetric binary operators ( Expr → BinaryOp (Expr , Expr )) we adopt Child-Sum to avoid redundant encodings; for paired rolling operators ( Expr → PairedRollingOp (Expr , Expr , Num )) we first apply unordered aggregation to operands and then use N-ary encoding to incorporate the time-window parameter; and for all other operators we employ standard N-ary encoding. Such operation can address the problem of isomorphic redundancy of alpha factors defined in Definition 6.The resulting tree embeddings are treated as input to be given into the policy and value heads to predict next-rule probabilities and estimated state value. 18 Alpha Discovery via Grammar-Guided Learning and Search 

F.1. N-ary Tree-LSTM (Position-Sensitive) 

Let node j have N children with hidden states h1, . . . , hN , input xj , output hidden state hj and cell state cj :

ij = σ W (i)xj +

> N

X

> k=1

U (i) 

> k

hk + b(i)

!

fjk = σ



W (f )xj + U (f ) 

> k

hk + b(f )

, k = 1 , . . . , N 

oj = σ W (o)xj +

> N

X

> k=1

U (o) 

> k

hk + b(o)

!

uj = tanh W (u)xj +

> N

X

> k=1

U (u) 

> k

hk + b(u)

!

cj = ij ⊙ uj +

> N

X

> k=1

fjk ⊙ ck

hj = oj ⊙ tanh( cj )

F.2. Child-Sum Tree-LSTM 

Let node j have a set of children C(j) with hidden states hk, k ∈ C(j):

˜hj = 1

|C(j)|

X

> k∈C(j)

hk

ij = σ



W (i)xj + U (i) ˜hj + b(i)

fjk = σ



W (f )xj + U (f )hk + b(f )

, k ∈ C(j)

oj = σ



W (o)xj + U (o) ˜hj + b(o)

uj = tanh 



W (u)xj + U (u) ˜hj + b(u)

cj = ij ⊙ uj + X

> k∈C(j)

fjk ⊙ ck

hj = oj ⊙ tanh( cj )

## G. Calculation of Tree Similarity 

Definition 6 (Isomorphism of ASR(Tree)) . ASR T1 and T2 are isomorphic only if: 1. The label of root nodes must be the same; 2. Recursively check each child node, the labels of the child nodes are equivalent: for asymmetrical operations, the order of the subtrees must be preserved; for symmetrical operations (Binary type operators in Table 6) or partially symmetrical operations (Corr, Cov, where the order of the first two operands’ child nodes doesn’t matter), the order of the subtrees doesn’t matter as long as the operands match; 3. Recursively check that all child nodes and their structures are isomorphic. Given two alpha factor expresions(partial or completed), they correspond to two ASRs T1 and T2 which are also two trees. Let Sub (T ) denote the set of all subtrees of T , where each subtree is induced by a child of node in T along with all its descendant nodes (including the child node itself). Let N (T ) denote the total number of subtrees in T , recursively defined as: 

N (T ) = 1 + X 

> c∈Children (T)

N (c).

19 Alpha Discovery via Grammar-Guided Learning and Search 

The normalized similarity between the two ASR is defined as: 

sim( T1, T 2) = max t1∈Sub (T1)

> t2∈Sub (T2)

css( t1, t 2)max ( N (T1), N (T2)) ,

where the numerator represents the size of the largest isomorphic subtree shared by T1 and T2, i.e., the number of matching nodes in the largest common subtree. Tree isomorphism is defined formally in Definition 6. If no such isomorphic subtree exists, then css( t1, t 2) = 0 .The denominator max( N (T1), N (T2)) corresponds to the number of nodes in the larger of the two trees, serving as an upper bound for the size of any common subtree. Intuitively, it reflects the maximum number of matching nodes that could be achieved if one tree were a subtree of the other, or if the two trees were structurally identical. As such, the denominator defines the maximum potential scale of a common subtree, and serves to normalize the matching node count in the numerator. This ensures that the resulting similarity score lies within the standardized range [0 , 1] , thereby facilitating both quantitative analysis and intuitive comparison of structural similarity between expression trees. 

## H. AlphaCFG Framework Parameter Setting for Experiment 

H.1. MCTS Parameters 

• Exploration Parameter : The exploration-exploitation trade-off parameter in the UCT formula is set to c = 1 .• MCTS Simulations : 64 simulations are performed per state. • MCTS Parallelism: 8 parallel simulations are used to speed up the exploration. • Eval Batch Size: 2 evaluations using network are carried out simultaneously each time. • Branch balance coefficient: 40 

H.2. Network Architecture Feature Extractor (Tree-LSTM) :• Embedding Dimension: 128. • Hidden Size: 128. • Dropout Rate: 0.1. 

Policy Network :• Input: Features extracted by the feature extractor (Tree-LSTM). • Hidden Layers: 

– Layer 1: Fully connected layer with 128 input features and 64 output features. 

– Layer 2: Fully connected layer with 64 input features and 128 output features (embedding dimension). • Activation Function: Softmax 

Value Network :• Input: Features extracted by the feature extractor (Tree-LSTM). • Hidden Layers: 

– Layer 1: Fully connected layer with the embedding dimension (128) as input and 64 output features. 

– Layer 2: Fully connected layer with 64 input features and 64 output features. • Activation Functions: ReLU activation functions applied to the hidden layers. • Output: A fully connected layer with a single output value without activation function. 20 Alpha Discovery via Grammar-Guided Learning and Search 

H.3. Optimizer and Training Parameters 

• Optimizer: Adam optimizer with default settings • Learning Rate: A learning rate of 10 −4.• Batch Size: 64. • Number of factor trajectories in an iteration: 100(2*50). • Training Iterations: 100 iterations. • Batch Size for Training: 64. • Replay Buffer Size: 20,000. • Early Stopping Criteria: Early stopping based on validation performance, with a threshold of 20% iterations without improvement. 

## I. More Results of Experiment 

We evaluate the proposed framework on both the China A-share and U.S. equity markets. Our experiments are designed to: (1) demonstrate that the proposed context-free grammar provides practical advantages over linear generation methods (e.g., Reverse Polish Notation) for representing and generating alpha factors; (2) validate that the syntax representation learning method using Tree-LSTM to encode state outperforms linear network architectures; (3) evaluate the performance of the grammar-aware discovery framework across multiple metrics in comparison with existing factor-mining methods; (4) assess whether the alpha factors discovered by our model deliver superior trading performance in realistic backtesting scenarios; and (5) examine how our model enhances the performance of existing classical factors. 

I.1. Data 

For the A-share market, we adopt the constituent stocks of the CSI 300 index, and for the U.S. market, we use the constituent stocks of the S&P 500 index. The dataset is temporally partitioned into three subsets: the training set (2010-01-01 to 2017-12-31), the validation set (2018-01-01 to 2019-12-31), and the testing set (2021-01-01 to 2024-12-31). To avoid distortions caused by abnormal market volatility and structural irregularities during the COVID-19 pandemic, data from calendar year 2020 are excluded by design. Six raw stock-level features are used as model inputs: 

{open , close , high , low , volume , vwap }. Formulaic alpha factors are constructed by applying arithmetic operators to these base features under the grammar constraints described earlier. The prediction target for factors is the 20-day forward return, computed using closing prices for both buying and selling, i.e., R(20)  

> t

= Ref(close , −20) close − 1.

I.2. Comparison Methods 

We evaluate three variants of grammar-constrained factor discovery method: (i) α-Syn (generation constrained solely by syntactic rules) (ii) α-Sem (generation constrained by both syntactic and semantic rules) (iii) α-Sem-k (generation further restricted by a length-bounding mechanism in Algorithm 2). To further validate the grammar effectiveness, we also incorporate Reverse Polish Notation (RPN). (Specifically for α-Syn , we constrain the rolling window size to be an integer constant in α-Syn to facilitate smooth training.) For a broader performance assessment of the entire framework, we compare our method against two state-of-the-art factor mining baselines: AlphaGen (Yu et al., 2023) and AlphaQCM (Zhu & Zhu, 2025). Both employ RPN, with AlphaGen using Proximal Policy Optimization (PPO) and AlphaQCM using distributed reinforcement learning. Additionally, GPlearn (Zhang et al., 2020) is included as a symbolic-regression baseline, which generates formula trees through genetic programming. All of the above factor generation methods optimize the Information Coefficient (IC) of the linear combination of factors. To further validate our approach, we include several widely used machine learning models as additional baselines: XG-Boost (Wang et al., 2023), LightGBM (Bisdoulis, 2024), LSTM (Bhandari et al., 2022), ALSTM (Qin et al., 2017), TCN (Dai et al., 2022), and Transformer (Mozaffari & Zhang, 2024).The hyperparameters of these models are set according to the benchmark configurations provided by Qlib (Yang et al., 2020). To mitigate the impact of randomness, all models are trained and evaluated 5 times with different fixed random seeds. 21 Alpha Discovery via Grammar-Guided Learning and Search 

I.3. Evaluation Metrics 

We evaluate factor effectiveness from two complementary perspectives: correlation metrics, including IC, RankIC, ICIR, and RankICIR, capture the statistical relationship between factors and future returns. Backtesting metrics, which are obtained by investment simulation using a top-k/drop-n strategy (see the next paragraph for details ), including MaxDD and Sharpe, assess the profitability and risk characteristics of factors in simulated trading (see Table 8 for details). Top-k/drop-n strategy is applied to simulate actual trading operations: for each trading day, we first ranked stocks based on their factor prediction scores, then selected the top k stocks from the sorted list. To balance return potential and trading costs, we adopted an equal-weight allocation approach while limiting daily portfolio adjustments to a maximum of n stocks. In our experiment, we set k = 60 and n = 5 , ensuring sufficient portfolio diversification while controlling transaction costs. Table 8 provides the specific calculation methods for all evaluation metrics. 

Table 8. Summary of Evaluation Metrics                                      

> Category Metric Name Abbrev. Formula Description
> Correlation Metrics Information Coefficient IC IC = ρ(αi, R i)Pearson correlation between factor values αiand future returns Ri.Rank Information Coefficient RankIC RankIC = ρ(r(αi), r (Ri)) Spearman correlation after ranking; r(·)is the rank function. Information Ratio ICIR ICIR = IC
> σIC
> Ratio of mean IC to its volatility, measuring prediction stability. Rank Information Ratio RankICIR RankICIR = RankIC
> σRankIC
> Ratio of mean RankIC to its volatility, evaluating rank correlation stability. Backtesting Metrics Maximum Drawdown MaxDD MaxDD = max t
> Pmax (0 , t )−Pt
> Pmax (0 , t )
> Largest peak-to-trough decline in backtest; Ptis NAV,
> Pmax (0 , t ) = max s≤tPs.Sharpe Ratio Sharpe Sharpe = E[rp−rf]
> σrp
> × √NAnnualized excess return per unit risk; rp: daily return, rf:risk-free rate, N: 252 (trading days).

I.4. Comparison of Different Network Architectures 

We conducted comparative experiments under different network architectures (Transformer, LSTM, CNN) while keeping other conditions constant. With a pool size of 10 and max length 5, Figure 9 shows training IC across epochs. Results demonstrate the effectiveness and superiority of syntax representation learning. Tree-LSTM not only extracts the structural and semantic information of expressions but also reduces redundancy caused by isomorphic forms (Definition 6). 0 50 100 150 200 

Epoch 

0.07 0.08 0.09 

> Train IC

CSI 300 

0 50 100 150 200 

Epoch 

0.06 0.07 0.08 

> Train IC

S&P 500 

Tree-LSTM Transformer LSTM CNN 

Figure 9. Comparison of training curves of different network architectures. 

22 Alpha Discovery via Grammar-Guided Learning and Search 

I.5. Optimization of Combined Factor Parameters on the Validation Set 

To obtain the optimized combined factor parameters, we conducted experiments on the validation set for two dimensions: 

Maximum Length of Individual Factors (Max Length) and Factor Pool Size (Pool Size) (results shown in Figure 10). Specifically, we first fix the maximum length of individual factors and then evaluate the valid IC for different pool sizes {1, 5, 10, 20, 30 } to select the optimal pool size. After selecting the optimal pool size under α-Sem-k, we fix it and then explore different values of the maximum length of individual factors {5, 10, 15, 20, 25 } to identify the best configuration. 1 5 10 20 30 Pool Size 0.01 0.02 0.03 0.04 0.05 0.06 0.07 Valid IC             

> CSI300:Validation IC vs. Pool Size 1510 20 30 Pool Size Valid IC
> S&P 500:Validation IC vs. Pool Size 510 15 20 25 Max Length 0.03 0.04 0.05 0.06 0.07 Valid IC
> CSI300:Validation IC vs. Max Length 510 15 20 25 Max Length Valid IC
> S&P 500:Validation IC vs. Max Length GP RPN+PPO(alphagen) α-Sem-k+MCTS α-Sem+MCTS RPN+MCTS α-Syn+MCTS

Figure 10. Valid IC of various generation approaches. 

Finally, we obtain the best combined factor parameters: 

CSI 300: 

• RPN+MCTS: Max Length: 10; Pool Size: 20 • α-Syn: Max Length: 10; Pool Size: 20 • α-Sem: Max Length: 10; Pool Size: 10 • α-Sem-k: Max Length: 10; Pool Size: 10 • RPN+PPO: Max Length: 20; Pool Size: 20 

S&P 500: 

• RPN+MCTS: Max Length: 20; Pool Size: 20 • α-Syn: Max Length: 10; Pool Size: 20 • α-Sem: Max Length: 10; Pool Size: 20 • α-Sem-k: Max Length: 10; Pool Size: 20 23 Alpha Discovery via Grammar-Guided Learning and Search 

• RPN+PPO: Max Length: 20; Pool Size: 20 The optimization objective of the GP method using a combined model has little effect (the generated combined factors are highly similar), so only the single-factor IC is used as its optimization objective. 

I.6. Case Study of the interpretability of formulaic factors 

Table 9 shows an example of alpha factors generated by our framework, tested on the CSI 300 index constituents. The mined factors exhibit strong interpretability grounded in market microstructure theory. For example, the factor Log( |Std((0.05-volume),40) |) measures the volatility of inverse trading volume over a 40-day window. This factor gauges the temporal variability of illiquidity, which may signal market stress or substantial price impact. Another example, Cov(volume,vwap,40), captures the co-movement between trading volume and the volume-weighted average price in past 40 days. A high covariance indicates strong directional consensus, potentially reflecting persistent momentum or, conversely, price reversals. 

Table 9. Top 10 Ranked Alphas and Their Weights                       

> #Alpha Expression Weight
> 1Mean(Corr(Sum(open,40),(high-volume),20),20) -0.00889 2volume -0.01278 3Std(close,40) 0.01778 4Pow(Med(Cov(high,low,30),30),0.1) 0.01411 5Delta(Log( |Min(high,30)/0.01 |),30) -0.01649 6Cov((-0.1-Sum(close,40)),volume,20)+low -0.01649 70.01Greater(-0.1/Corr(high,close,30),volume) -0.00823 8Log( |Std((0.05-volume),40) |)0.01224 9Greater(-0.01,Log( |Log( |low |)|)) -0.04616 10 Cov(volume,vwap,40) -0.01412

24