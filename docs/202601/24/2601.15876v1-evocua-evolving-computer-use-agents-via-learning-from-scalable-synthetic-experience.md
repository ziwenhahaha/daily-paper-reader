<div class="paper-title-row">
<h1 class="paper-title-zh">EvoCUA：通过可扩展合成经验学习演化计算机使用智能体</h1>
<h1 class="paper-title-en">EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience</h1>
</div>

<div class="paper-meta-row">
<div class="paper-meta-left">
<p><strong>Authors</strong>: Taofeng Xue, Chong Peng, Mianqiu Huang, Linsen Guo, Tiancheng Han, Haozhe Wang, Jianing Wang, Xiaocheng Zhang, Xin Yang, Dengchang Zhao, Jinrui Ding, Xiandi Ma, Yuchen Xie, Peng Pei, Xunliang Cai, Xipeng Qiu</p>
<p><strong>Date</strong>: 2026-01-22</p>
<p><strong>PDF</strong>: <a href="https://arxiv.org/pdf/2601.15876v1" target="_blank">https://arxiv.org/pdf/2601.15876v1</a></p>
<p><strong>Tags</strong>: <span class="tag-label tag-green">EOH</span></p>
<p><strong>Score</strong>: 6.0</p>
</div>
<div class="paper-meta-right">
<p><strong>Evidence</strong>: 策略优化的进化循环</p>
<p><strong>TLDR</strong>: 本研究针对原生计算机使用智能体（CUA）受限于静态数据规模、难以处理长程任务因果动态的问题，提出了EvoCUA。该模型将数据生成与策略优化整合进自我持续的进化循环中，利用可验证合成引擎生成多样化任务，并通过大规模异步沙盒演练获取经验。通过迭代进化学习策略，EvoCUA能强化成功路径并从失败中自我纠正。实验显示其在OSWorld基准上达到56.7%的成功率，刷新了开源SOTA记录，证明了该进化范式的有效性与可扩展性。</p>
</div>
</div>

<div class="paper-glance-section">
<h2 class="paper-glance-title">速览</h2>
<div class="paper-glance-row">
<div class="paper-glance-col">
<div class="paper-glance-label">Motivation</div>
<div class="paper-glance-content">现有的静态数据集模仿学习范式难以捕捉长程计算机任务中的复杂因果动态，限制了智能体能力的进一步提升。</div>
</div>
<div class="paper-glance-col">
<div class="paper-glance-label">Method</div>
<div class="paper-glance-content">提出一种进化循环机制，结合可验证的任务合成引擎与大规模异步沙盒基础设施，通过迭代学习不断优化策略并从失败中自我纠正。</div>
</div>
<div class="paper-glance-col">
<div class="paper-glance-label">Result</div>
<div class="paper-glance-content">在OSWorld基准测试中取得56.7%的成功率，显著超越了OpenCUA-72B和UI-TARS-2等国内外领先模型，刷新了开源SOTA。</div>
</div>
<div class="paper-glance-col">
<div class="paper-glance-label">Conclusion</div>
<div class="paper-glance-content">基于可扩展合成经验的进化学习范式为提升原生智能体能力提供了一条稳健且具有良好泛化性的技术路径。</div>
</div>
</div>
</div>

---


## 摘要
原生计算机使用智能体（CUA）的开发代表了多模态人工智能的一次重大飞跃。然而，其潜力目前正受到静态数据规模扩展限制的瓶颈制约。现有的主要依赖于对静态数据集进行被动模仿的范式，难以捕捉长程计算机任务中固有的复杂因果动态。在这项工作中，我们介绍了 EvoCUA，一种原生计算机使用智能体模型。与静态模仿不同，EvoCUA 将数据生成和策略优化整合到一个自给自足的演化循环中。为了缓解数据稀缺问题，我们开发了一个可验证的合成引擎，能够自主生成多样化的任务并配以可执行的验证器。为了实现大规模经验获取，我们设计了一个可扩展的基础设施，用于编排数以万计的异步沙盒演练。基于这些海量轨迹，我们提出了一种迭代演化学习策略，以高效地内化这些经验。该机制通过识别能力边界来动态调节策略更新——在强化成功例程的同时，通过错误分析和自我修正将失败轨迹转化为丰富的监督信息。在 OSWorld 基准测试上的实证评估表明，EvoCUA 达到了 56.7% 的成功率，刷新了开源模型的最先进水平。值得注意的是，EvoCUA 显著优于之前的最佳开源模型 OpenCUA-72B (45.0%)，并超越了领先的闭源模型，如 UI-TARS-2 (53.1%)。至关重要的是，我们的结果强调了该方法的泛化性：由经验学习驱动的演化范式在不同规模的基础模型上均能产生一致的性能提升，为提升原生智能体能力建立了一条稳健且可扩展的路径。
## Abstract
The development of native computer-use agents (CUA) represents a significant leap in multimodal AI. However, their potential is currently bottlenecked by the constraints of static data scaling. Existing paradigms relying primarily on passive imitation of static datasets struggle to capture the intricate causal dynamics inherent in long-horizon computer tasks. In this work, we introduce EvoCUA, a native computer use agentic model. Unlike static imitation, EvoCUA integrates data generation and policy optimization into a self-sustaining evolutionary cycle. To mitigate data scarcity, we develop a verifiable synthesis engine that autonomously generates diverse tasks coupled with executable validators. To enable large-scale experience acquisition, we design a scalable infrastructure orchestrating tens of thousands of asynchronous sandbox rollouts. Building on these massive trajectories, we propose an iterative evolving learning strategy to efficiently internalize this experience. This mechanism dynamically regulates policy updates by identifying capability boundaries -- reinforcing successful routines while transforming failure trajectories into rich supervision through error analysis and self-correction. Empirical evaluations on the OSWorld benchmark demonstrate that EvoCUA achieves a success rate of 56.7%, establishing a new open-source state-of-the-art. Notably, EvoCUA significantly outperforms the previous best open-source model, OpenCUA-72B (45.0%), and surpasses leading closed-weights models such as UI-TARS-2 (53.1%). Crucially, our results underscore the generalizability of this approach: the evolving paradigm driven by learning from experience yields consistent performance gains across foundation models of varying scales, establishing a robust and scalable path for advancing native agent capabilities.