<div class="paper-title-row">
<h1 class="paper-title-zh">ZENITH：自动化的梯度范数感知随机优化</h1>
<h1 class="paper-title-en">ZENITH: Automated Gradient Norm Informed Stochastic Optimization</h1>
</div>

<div class="paper-meta-row">
<div class="paper-meta-left">
<p><strong>Authors</strong>: Dhrubo Saha</p>
<p><strong>Date</strong>: 2026-01-21</p>
<p><strong>PDF</strong>: <a href="https://arxiv.org/pdf/2601.15212v1" target="_blank">https://arxiv.org/pdf/2601.15212v1</a></p>
<p><strong>Tags</strong>: <span class="tag-label tag-green">EOH</span> <span class="tag-label tag-green">EAA</span></p>
<p><strong>Score</strong>: 7.0</p>
</div>
<div class="paper-meta-right">
<p><strong>Evidence</strong>: 利用训练历史的时间演化进行自动优化</p>
<p><strong>TLDR</strong>: 针对深度学习模型训练中学习率（LR）调节繁琐及现有自适应优化器开销大的问题，本文提出ZENITH优化器。该方法利用梯度范数的时间演化自动调整学习率，无需额外计算和内存开销。实验证明，ZENITH在图像分类、目标检测等多种视觉任务中，不仅在准确率上优于基准，且训练速度更快，并能与正则化良好兼容，显著提升泛化性能。</p>
</div>
</div>

<div class="paper-glance-section">
<h2 class="paper-glance-title">速览</h2>
<div class="paper-glance-row">
<div class="paper-glance-col">
<div class="paper-glance-label">Motivation</div>
<div class="paper-glance-content">现有的学习率调度依赖人工调参，而自适应优化器存在计算开销大、与正则化不兼容及学习率选择次优等问题。</div>
</div>
<div class="paper-glance-col">
<div class="paper-glance-label">Method</div>
<div class="paper-glance-content">提出ZENITH优化器，通过分析梯度范数随时间演化的历史信息来自动调整学习率。</div>
</div>
<div class="paper-glance-col">
<div class="paper-glance-label">Result</div>
<div class="paper-glance-content">在多项计算机视觉基准测试中，ZENITH在更短的训练时间内实现了比基准算法更高的测试准确率和mAP。</div>
</div>
<div class="paper-glance-col">
<div class="paper-glance-label">Conclusion</div>
<div class="paper-glance-content">ZENITH是一种高效、自动化的随机优化算法，在保持零额外开销的同时显著提升了模型的训练效率和泛化能力。</div>
</div>
</div>
</div>

---


## 摘要
训练深度计算机视觉模型通常需要对学习率 (LR) 调度进行人工监督或超参数调优。虽然现有的自适应优化器可以自动调度学习率，但它们往往面临计算和内存开销大、与正则化不兼容以及学习率选择并非最优等问题。在这项工作中，我们提出了 ZENITH（Zero-overhead Evolution using Norm-Informed Training History，基于范数感知训练历史的零开销演化）优化器，它利用梯度范数的时间演化来调整学习率。涵盖 6 种 CNN 架构和 6 个基准测试的图像分类实验表明，与基准方法相比，ZENITH 在更短的实际运行时间（wall-clock time）内实现了更高的测试准确率。在 MS COCO 数据集上，使用 R-CNN 系列模型进行的物体检测、关键点检测和实例分割任务中，它也取得了更优的平均精度均值 (mAP)。此外，它与正则化的兼容性进一步提升了模型的泛化能力。
## Abstract
Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.