Title: Vehicle Routing with Finite Time Horizon using Deep Reinforcement Learning with Improved Network Embedding

URL Source: https://arxiv.org/pdf/2601.15131v1

Published Time: Thu, 22 Jan 2026 02:02:38 GMT

Number of Pages: 8

Markdown Content:
# Vehicle Routing with Finite Time Horizon using Deep Reinforcement Learning with Improved Network Embedding 

## Ayan Maity 1, Sudeshna Sarkar 2

> 1

Department of Computer Science and Engineering, IIT Kharagpur Email: ayanmaity201@kgpian.iitkgp.ac.in 

> 2

Department of Computer Science and Engineering, IIT Kharagpur Email: sudeshna@cse.iitkgp.ac.in 

## Abstract 

In this paper, we study the vehicle routing problem with a finite time horizon. In this routing problem, the objec-tive is to maximize the number of customer requests served within a finite time horizon. We present a novel routing net-work embedding module which creates local node embed-ding vectors and a context-aware global graph representa-tion. The proposed Markov decision process for the vehi-cle routing problem incorporates the node features, the net-work adjacency matrix and the edge features as components of the state space. We incorporate the remaining finite time horizon into the network embedding module to provide a proper routing context to the embedding module. We inte-grate our embedding module with a policy gradient-based deep Reinforcement Learning framework to solve the ve-hicle routing problem with finite time horizon. We trained and validated our proposed routing method on real-world routing networks, as well as synthetically generated Eu-clidean networks. Our experimental results show that our method achieves a higher customer service rate than the ex-isting routing methods. Additionally, the solution time of our method is significantly lower than that of the existing meth-ods. 

## Introduction 

Vehicle Routing Problems (VRP) are a widely recognized class of combinatorial optimization problems that have been extensively studied (Baty et al. 2024). Vehicle routing has applications in transportation, logistics, delivery systems and urban planning. Different variants of the vehicle routing problem (VRP) have been studied in the past, such as Capacitated VRP (Toth and Vigo 2014), VRP with finite horizon (Zhang et al. 2023), electric vehicle routing problem (Tang et al. 2023), VRP with time windows (Schneider, Stenger, and Goeke 2014), etc. In this study, we consider the Vehicle Routing Problem with a Finite Time Horizon (VRP-FTH) (Zhang et al. 2023). In the VRP-FTH, a single vehicle departs from a depot, serves a subset of customers, and returns to the depot within a finite service time. Since not all customers can be visited within this time horizon, the objective is to find a trip route to maximize the number of customers served. Customer re-quests may be deterministic (known beforehand) or stochas-tic (received during the trip). Until recently, most of the existing methods to solve the VRP-FTH used traditional optimization methods. The tra-ditional optimization-based routing method include genetic algorithm (Wang, Golden, and Wasil 2008), integer pro-gram models (Klapp, Erera, and Toriello 2018), tabu search-based metaheuristic (Ferrucci and Bock 2015), approximate dynamic programming algorithm (Kullman, Goodson, and Mendoza 2021), multiple knapsack approximation (Zhang et al. 2023) etc. However, exact methods are computation-ally expensive, while heuristic methods, though faster, typi-cally yield suboptimal solutions (Tang et al. 2023). Recent studies have explored reinforcement learning (RL)-based routing models (Kool, Van Hoof, and Welling 2018; Lin, Ghaddar, and Nathwani 2021; Gama and Fernan-des 2021) for the VRP-FTH. Lin, Ghaddar, and Nathwani (2021) proposed a structure2vec-based framework, while Kool, Van Hoof, and Welling (2018) introduced a multi-head attention model to solve different variants of the VRP. The existing RL-based methods only create local node embed-dings and they do not generate a global graph embedding based on the current routing context. Additionally, most of the existing methods rely solely on Euclidean networks and vertex coordinates, which fail to capture real-world graph structures where paths are not necessarily straight lines. In this paper, we propose a graph attention networks-based routing network embedding module which takes the graph adjacency matrix and the edge features into account to produce the node embedding vectors and the global graph embedding vector. We integrate the routing network embed-ding module with a policy network-based routing agent to solve the VRP-FTH instances. The major contributions of this paper are as follows: 1. We propose a novel routing network embedding module which generates local node encoding vectors along with a global graph representation vector to facilitate better un-derstanding of the current routing context. Our proposed network embedding module consists of Graph Attention Networks with edge features and Cross-Attention. 2. We incorporate the remaining time horizon into the graph embedding module to improve the quality of the global graph representation.   

> arXiv:2601.15131v1 [cs.AI] 21 Jan 2026 Vehicle Depot
> Served Customer Unserved Customer
> Route

Figure 1: Vehicle Routing with Finite Time Horizon 

## Problem Definition 

The vehicle routing problem with finite time horizon (VRP-FTH) (Zhang et al. 2023) is defined on a complete and di-rected routing network G = ( V, E ), where V is the set of nodes and E is the set of edges. The set of nodes V con-tains a depot ( vd) and a set of customer nodes ( C). Each edge (i, j ) has a travel time ti,j associated with it. A sin-gle vehicle starts at the depot, visits a number of customers and returns to the depot within a finite time horizon U . A set of deterministic customers Cd is known at the start of the trip. New customer requests are received during the trip till K timesteps. The objective is to visit and serve as many customers as possible and return to the depot within the fi-nite horizon U . If it represents the node visited at timestep 

t, T is the total number of timesteps and R = ( i1, i 2, ..., i T )

represents the route followed by the vehicle, the objective function is mathematically expressed as: 

max  

> R=( i1,...,i T)
> T

X

> t=1

1[it ∈ C ] subject to  

> T−1

X

> j=1

tij ,i j+1 ≤ U (1) where the function 1[.] is an indicator function. Figure 1 shows an example of the VRP-FTH. 

## Related Work 

The VRP-FTH has been extensively studied in previous works, often under different names. In particular, the VRP-FTH with deterministic customers has been referred to as the Orienteering Problem (Vansteenwegen and Gunawan 2019), the Selective Travelling Salesman Problem (Derya, Dinler, and Kec ¸eci 2020) etc. On the other hand, the VRP-FTH with stochastic customers has been referred to as the Dynamic Vehicle Routing Problem with Stochastic Requests (Zhang et al. 2023), the Dynamic Customer Acceptance in Delivery Routing (Ulmer and Thomas 2020), etc. We can broadly categorize different vehicle routing meth-ods into two categories: Traditional Optimization-based Methods and Reinforcement Learning-based methods .

Traditional Optimization-based Routing Methods 

Until recently, most of the vehicle routing methods were based on traditional optimization techniques. 

Traditional Methods for VRP with Finite Horizon. 

Kara, Bicakci, and Derya (2016) studied the vehicle rout-ing problem with finite horizon and proposed an integer lin-ear programming program model to solve the routing prob-lem. However, they only considered small-scale routing in-stances. Ferrucci and Bock (2015) proposed a tabu search-based metaheuristic algorithm for dynamic vehicle routing with time horizon and time windows. However, this tabu search-based method is not suitable for large-scale routing instances. Ulmer and Thomas (2020) addressed vehicle routing for customer acceptance using a meso-parametric value func-tion approximation method. Ulmer et al. (2020) formulated the stochastic dynamic vehicle routing using a route-based Markov decision process (MDP). As a result of the route-based MDP, the state space size increases exponentially with the inclusion of the route plan. Urrutia-Zambrana, Tirado, and Mateos (2021) presented a variable neighbourhood search algorithm to solve the VRP with finite horizon. On large routing instances, the variable neighbourhood search algorithm is highly prone to get stuck in local optimal values. Zhang et al. (2023) addressed dynamic vehicle routing with stochastic requests using a route-based MDP and a mul-tiple knapsack-based value function approximation. How-ever, the route-based MDP leads to a large state space and high solution time. Xu et al. (2024) proposed a genetic algorithm-based rout-ing method to solve the orienteering problem. However, the solution time of the genetic algorithm is relatively high as compared to the reinforcement learning-based methods. 

Traditional Methods for Other VRP Variants. Chen et al. (2020) considered the vehicle routing problem with time windows and proposed an adaptive large neighbour-hood search algorithm to solve the problem. Louati et al. (2021) proposed mixed integer programming models to solve vehicle routing problems with pickup and delivery. However, the solution time is impractical for real-time use. Jia, Mei, and Zhang (2021) formulated the capacitated electric vehicle routing problem as a bilevel optimization problem and presented an improved ant colony optimization method to solve the problem. Maroof, Ayvaz, and Naeem (2024) presented a hybrid genetic algorithm for vehicle rout-ing problems with time windows. For large routing net-works, the genetic algorithm-based methods generally pro-duce sub-optimal results. 

Reinforcement Learning-based Routing Methods 

In recent times, Reinforcement Learning (RL) has emerged as a promising approach to solve sequential decision making problems. 

RL Methods for VRP with Finite Horizon. Kool, Van Hoof, and Welling (2018) proposed a multi-head atten-tion model with the REINFORCE method for vehicle rout-ing. However, relying solely on node coordinates limits its ability to represent real road networks, where paths are not necessarily straight lines. Lin, Ghaddar, and Nathwani (2021) proposed a deep re-inforcement learning-based method to solve the electric ve-hicle routing problem with time windows. Their proposed structure2vec (S2V) node embedding module only consid-ers the node coordinates and binary adjacency matrix, which reduces the capacity of the model to represent real road net-work. Gama and Fernandes (2021) presented a pointer network-based policy gradient method to solve the vehicle routing with time windows and finite time horizon. However, similar to Lin, Ghaddar, and Nathwani (2021), they only considered Euclidean networks and the node coordinates are used as input features. Hildebrandt, Thomas, and Ulmer (2023) proposed a pol-icy gradient RL framework for the stochastic dynamic ve-hicle routing problem. However, the absence of network en-coding limits its ability to effectively capture the routing net-work structure. 

RL Methods for Other VRP Variants. Basso et al. (2022) considered the dynamic stochastic vehicle routing problem and presented a tabular safe reinforcement learning method to solve the problem. However, this method is only applicable on small routing instances due to its memory and time requirement. Tang et al. (2023) developed a transformer-based policy gradient approach for energy-efficient EV routing, but it is restricted to Euclidean networks and ignores real-world edge features. Mozhdehi, Mohammadizadeh, and Wang (2024) pro-posed an edge-enhanced transformer-based graph embed-ding model for the electric vehicle routing problem with time windows. Maity and Sarkar (2025) introduced a Deep Q-Network–based electric vehicle routing approach em-ploying a graph convolutional network for embedding. Traditional heuristic methods often yield suboptimal so-lutions, while exact methods are computationally expen-sive. Most RL-based routing approaches are limited to Eu-clidean networks, ignoring network structure. Moreover, the existing RL-based routing methods do not produce useful context-aware global graph representation vectors to help the agent understand the global routing context. 

## Methodology 

This section presents our proposed graph attention networks-based routing network embedding module and the policy network-based routing framework. Figure 2 shows our proposed routing framework. The vehicle routing problem with finite time horizon (VRP-FTH) is formulated as a Markov decision process (MDP). In our MDP for the VRP-FTH, the state space in-corporates the routing network state which contains node features, sparse adjacency matrix and edge features. We propose a novel routing network embedding mod-ule which creates the node embedding vectors as well as a context-aware global graph embedding vector. Finally, we present a policy network consisting of the net-work embedding module, the context vector and the com-patibility layer to solve the VRP-FTH. 

Markov Decision Process 

The VRP-FTH is formulated as a Markov Decision Pro-cess (MDP) with defined states, actions, and rewards. Unlike existing deep RL methods that use only node coordinates (Tang et al. 2023; Kool, Van Hoof, and Welling 2018), our formulation incorporates node features, a sparse adjacency matrix, and edge features to better capture the network struc-ture. 1. State : The state of the agent ( st) contains the routing net-work state ( snt ) and the vehicle state ( svt ): st = {snt , s vt }.The routing network state ( snt ) consists of three compo-nents: (a) Node features ( X): The node feature of a node v con-tains the travel time costs to reach the other nodes from 

v and it also contains whether v is the depot or a cus-tomer node. (b) Adjacency matrix ( A): As the routing network in our problem is a complete and directed graph, we create a binary adjacency matrix using k-nearest neighbours (KNN) of each node. (c) Edge features ( e): In our problem, the edge feature eij 

for the edge (i, j ) is computed as: eij = 1 − t′ 

> ij

, where 

t′ 

> ij

is the min-max normalized travel time for the edge 

(i, j ).The routing network state is: snt = ( X, A, e ).The current vehicle state is composed of the current lo-cation ( it), the set of active customer requests ( Ct) and the remaining time horizon ( τt): svt = ( it, C t, τ t).2. Action : The action at at a state st is the next node to visit. 3. Reward Function : The agent receives a unit positive re-ward for every customer it visits. The agent is penal-ized if it does not complete the trip within the time horizon U . The reward function R(st, a t) for the state 

st = {snt , s vt = ( it, C t, τ t)} and action at is given by: 

R(st, a t) = 



+1 , if it ∈ Ct and τt > 0

−M, if it̸ = depot and τt ≤ 00, otherwise (2) where U is the time horizon, τt is the remaining time and 

M is the failure penalty that the agent receives if it fails to complete the trip within U . We heuristically compute the value of penalty M as the total number of customers in the routing instance: M = |C| .

Routing Network Embedding Module 

A reliable and effective vehicle routing method requires routing network representations that capture both node-level features and global routing context to enable optimal decision-making. However, existing deep RL methods lack context-aware global graph embeddings (Tang et al. 2023). We propose a novel routing network module using Graph Attention Networks (GAT) (Veliˇ ckovi´ c et al. 2017) with Edge features and Cross-Attention mechanism. The GAT layers produce the node encoding vectors and we introduce a Cross-Attention-based global graph embedding vector to represent the global routing context. GAT-        

> Edge
> Cross
> Attention
> Network Embedding Module
> Graph Embedding Vector
> Current node embedding vector
> Compatibility
> Policy
> Adjacency Matrix ( )
> Node Features ( )
> Edge Features ( )
> Routing Network State ( )
> GAT-
> Edge
> Active Customer Request ( )
> Current location ( )
> Remaining Time Horizon ( )
> Vehicle State ( )
> Routing Network
> Next Node
> to Visit
> Active Customers Embedding
> Remaining Time Embedding
> Context Vector

Figure 2: Policy Network with GAT-based routing network embedding module (PG-GAT-Edge) 

Graph Attention Networks with Edge Features (GAT-Edge). Consider a graph G = ( V, E ) with the node fea-tures X, the binary adjacency matrix A and edge features 

e. The definitions of X, A and e for the VRP-FTH are pro-vided in the MDP. A Graph Attention Networks (GAT) layer takes A, X and e as inputs. First, the GAT layer computes attention scores ˆαij for each edge (i, j ) ∈ E:

ˆαij = ReLU (aT [W X i|| W X j ]) (3) where W is a learnable weight matrix to linearly transform the initial node features X and a is a learnable weight vector for the the graph attention layer. To incorporate the edge features, the attention scores ( ˆαij )are multiplied with the edge features ( eij ) to produce the edge-induced attention score ( αeij ): 

αeij = softmax (ˆ αij ∗ eij ) (4) The edge-induced attention scores αeij are used as weight values to combine the neighbouring node features and com-pute the node embedding vectors h(1) . The node embedding vector h(1)  

> i

for node i is computed as: 

h(1)  

> i

= σ( X 

> k∈N (i)

αeik W X k) (5) where σ is the sigmoid function and N (i) is the set of neigh-bouring nodes of node i.We apply two GAT-Edge layers and use residual connec-tions to compute the final node embedding vectors. The sec-ond GAT-Edge layer produces h(2) . The final node embed-ding vectors h is computed by residually adding h(1) with 

h(2) :

h = h(1) + h(2) (6) 

Global Graph Embedding using Cross-Attention Mecha-nism. While GAT-Edge layers capture local node features, global routing context is also highly important. We intro-duce a Cross-Attention layer that combines GAT-Edge node embeddings with the current vehicle state (including U ) to generate a global graph embedding. In the proposed cross-attention layer, the query vector Qt

is generated from the vehicle state ( svt ) as shown in Equa-tion 7 and the node embedding vectors h act as both the key vectors and value vectors. The attention scores αt are gener-ated from the query vector and the node embedding vector as shown in Equation 8. Finally, to compute the global net-work embedding vector hG, we linearly combine the value vectors (i.e. node embedding vectors h) using the attention scores, which is shown in Equation 9: 

Qt = Wq · svt (7) 

αt = softmax (Qt · hT ) (8) 

hG = X

> k

αtkhk (9) where Wq is a learnable weight matrix and hk is the node embedding vector for node k. hG is the context-aware global graph embedding vector. The routing network embedding module architecture is shown in Figure 2. Additionally, we compute an active customer embedding vector ( hCt ) to represent the set of active customer requests in the following way: 

hCt = X

> j∈Ct

hj (10) where Ct is the set of active customer requests. 

Compatibility and Masking Layer 

We create a context vector HC by concatenating the graph embedding vector hG, the current node embedding vector 

hit , the active customer requests embedding vector hCt and the linear embedding the remaining time horizon τ : HC =[hG, h it , h Ct , τ ].We compute the compatibility of the context vector HC

and all the node in the routing network through a single-head attention layer: 

ui = C · tanh ( qT ki

√dk

) (11) where q = W QHC , ki = W K hi, W Q and W K are learn-able parameters, dk is the length of the query vector q and C

is a constant. To get the probabilities for each node from the compati-bility values, we use a mask and a softmax activation layer (Tang et al. 2023). At each timestep, the masking rules are: 1. All the previously visited nodes are masked. 2. An unvisited node v is masked if the agent cannot visit 

v and return directly to depot within the remaining time horizon. The probability vector for visiting different nodes are cal-culated in the following way: 

pi = softmax (ui + Z · M ask i) (12) where pi is the probability to visit node i, M ask i is the masking vector for node i and Z is a large negative num-ber. 

Policy Gradient-based Routing Method 

The routing agent is implemented using a policy network that incorporates the routing network embedding mod-ule. The policy network includes a GAT-Edge and Cross-Attention-based embedding module, a context vector, and a compatibility layer. The network state snt and vehicle state 

svt serve as inputs. The embedding module produces node embeddings ( h) and a global graph embedding ( hG), which are combined with active customer and remaining time em-beddings to form the context vector HC . The compatibility layer then maps HC to the policy π(st, a t).We train the policy network using the REINFORCE Pol-icy Gradient (PG) algorithm (Williams 1992). The policy gradient loss function is: 

J(θ) = Eπ [Gt log (π(st|at; θ))] (13) where θ is the set of policy network weights and Gt is the re-turn or reward-to-go from the state-action pair (st, a t). The gradient of the loss is computed as: 

∇θ J(θ) = Eπ [Gt ∇log (π(st|at; θ))] (14) Figure 2 depicts our proposed policy network-based rout-ing method architecture. We refer to our proposed routing method as Policy Gradient with GAT-Edge (PG-GAT-Edge). 

## Experimental Results 

In this section, we present the routing network instances, the experimental setup and the results of our experiments. 

Routing Network Datasets 

We have used synthetic Euclidean networks (Lin, Ghaddar, and Nathwani 2021), Vienna city networks (Zhang et al. 2023), and newly created Eastern Massachusetts highway networks for our experiments. Our routing network datasets are as follows: 1. Euclidean Routing Network (EN) : We generated random Euclidean routing networks comprising 50 and 100 cus-tomers (EN-50 and EN-100) following the methodology of Lin, Ghaddar, and Nathwani (2021). Two network types were considered: deterministic (all customer re-quests are known at the start), and stochastic (half of the requests arrive during the trip). The time horizons were set to 24 hours for deterministic and 18 hours for stochas-tic instances. 2. Eastern Massachusetts Highway Road Network (EMA Network) : We created the Eastern Massachusetts High-way routing instances from the OpenStreetMap. The EMA network dataset contains 50-customer instances (EMA-50), 100-customer instances (EMA-100) and 150-customer instances (EMA-150). We created both de-terministic (all customers are known at the start) and stochastic instances (half of the requests arrive during the trip). The time horizon ( U ) is 24 hours. 3. Vienna City Network : Following the experimental setup provided by Zhang et al. (2023), we generated the Vienna city routing instances from the Vienna city network, with 160 customers (Vienna-160) and 300 customers (Vienna-300). The time horizon ( U ) is 10 hours. 

Baseline Models 

We have compared our proposed routing method with five existing routing methods: 1. Genetic Algorithm (GA) : We implemented the Genetic Algorithm to solve the VRP-FTH as presented in Ma-roof, Ayvaz, and Naeem (2024). We considered the fol-lowing hyper-parameters: population size = 100, number of generations = 1000, mutation rate = 0.01. 2. Variable Neighbourhood Search (VNS) : We implemented the Variable Neighbourhood Search algorithm as pro-posed in Urrutia-Zambrana, Tirado, and Mateos (2021) to solve the vehicle routing problem with finite horizon. 3. Mulitple Knapsack-based Approximation (MKA) :Zhang et al. (2023) proposed a multiple knapsack approximation-based approach for the VRP-FTH, com-bining a potential-based offline planner with an online knapsack method. We compare our method with this method only on the Vienna city network instances. 4. Deep RL with Transformer (DRL-Transformer) : The deep RL with transformer method was proposed by Tang et al. (2023). This method uses transformer to encode the routing network information. They use the policy gradi-ent algorithm to train the agent. 5. Deep RL with Structure2Vec (DRL-S2V) : Lin, Ghaddar, and Nathwani (2021) proposed the DRL-S2V method which includes a structure2vec model to compute the node embedding vectors. They have also used the policy gradient algorithm. 

Experimental Setting 

In our policy network, the network embedding module con-tains two GAT-Edge layers with 4 attention heads and 64-dimensional embedding vectors and the context vector ( HC )Method Customers Served (%) Determinstic Stochastic EN-50 EN-100 EN-50 EN-100                     

> GA (Maroof, Ayvaz, and Naeem 2024) 48.8 25.8 ––VNS (Urrutia-Zambrana, Tirado, and Mateos 2021) 37.8 19.9 ––DRL-Transformer (Tang et al. 2023) 56.8 24.8 52.4 26.2 DRL-S2V (Lin, Ghaddar, and Nathwani 2021) 41.1 17.5 23.7 18.4
> PG-GAT-Edge (Proposed Method) 75.2 48.0 71.3 40.9

Table 1: Customer Service Rate (%) for Different Routing Methods on Euclidean Routing Networks                                     

> Method Customers Served (%) Deterministic Stochastic EMA-50 EMA-100 EMA-150 EMA-50 EMA-100 EMA-150
> GA (Maroof, Ayvaz, and Naeem 2024) 72.9 39.1 26.9 –––VNS (Urrutia-Zambrana, Tirado, and Mateos 2021) 61.1 32.5 21.8 –––DRL-Transformer (Tang et al. 2023) 74.1 46.1 27.3 28.7 22.0 33.6 DRL-S2V (Lin, Ghaddar, and Nathwani 2021) 60.7 37.4 21.7 48.0 22.8 31.6
> PG-GAT-Edge (Proposed Method) 86.6 57.5 41.7 94.5 49.8 56.2

Table 2: Customer Service Rate (%) for Different Routing Methods on EMA highway networks           

> Method Customers Served (%) Vienna-160 Vienna-300
> MKA (Zhang et al. 2023) 27.7 13.9 DRL-Transformer (Tang et al. 2023) 42.3 25.8 DRL-S2V (Lin, Ghaddar, and Nathwani 2021) 27.4 12.5
> PG-GAT-Edge (Proposed Method) 47.9 28.2

Table 3: Customer Service Rate (%) for Different Routing Methods on the Stochastic Vienna City Routing Networks                                    

> Method Solution Time (s) EMA-50 EMA-100 EMA-150 Vienna-160 Vienna-300
> MKA (Zhang et al. 2023) –––26.59 70.1 GA (Maroof, Ayvaz, and Naeem 2024) 6.79 7.52 7.88 ––VNS (Urrutia-Zambrana, Tirado, and Mateos 2021) 1.13 1.34 2.4 ––DRL-Transformer (Tang et al. 2023) 0.58 0.77 1.88 1.40 3.48 DRL-S2V (Lin, Ghaddar, and Nathwani 2021) 0.46 0.63 1.77 0.92 2.94
> PG-GAT-Edge 0.45 0.63 1.03 0.78 1.85

Table 4: Average Solution Time on Different Routing Networks is projected into a 256-dimensional vector before computing the compatibility layer. 

Results 

Table 1 presents the customer service rate results of the PG-GAT-Edge method and other baseline methods on the Eu-clidean routing instances. The PG-GAT-Edge method im-proves the customer service by 59.2% on the determinis-tic Euclidean instances and by 46.0% on the stochastic in-stances compared to the other methods. Table 2 shows the customer service rate results of differ-ent routing methods on the EMA highway routing instances. The PG-GAT-Edge method outperforms all the other meth-ods on each of the instances. We present the customer ser-vice results on the Vienna city routing instances in Table 3. On the Vienna stochastic instances, we observe that our pro-posed method achieves 72.9% more customer service rate on Vienna-160 instances and 102.8% more customer service rate on the Vienna-300 instances than the Multiple Knapsack Approximation method (Zhang et al. 2023). Table 4 presents the solution time (i.e. decision time) of different method on the EMA instances and the Vienna in-stances. It is observed that the solution time of PG-GAT-Edge is significantly less than most of the other methods. Additionally, as the network size grows, the solution time gap between our method and the other methods increase. Our experimental results demonstrate that the proposed method improves customer service rates on both real-world and randomly generated Euclidean networks. These results highlight the importance of the graph embedding module, (a) Vienna-160 (b) Euclidean Network-50 

Figure 3: Customer Service Rate (%) under different time horizon ( U , in hours) for PG-GAT-Edge (Our method) and DRL-Transformer (Tang et al. 2023) on Vienna-160 and EN-50 as most of the existing deep RL methods using only node coordinates fail to properly capture the network structure. Our GAT-Edge-based routing network embedding module effectively understands the underlying graph structure and the edge features. Additionally, incorporating the edge fea-tures significantly improves our model’s performance. 

Effects of Different Finite Horizons 

We compared the customer service rates under varying time horizons ( U ) for DRL-Transformer and PG-GAT-Edge on Vienna-160 and EN-50 instances. As shown in Figure 3, PG-GAT-Edge consistently outperforms DRL-Transformer across all U values. Figure 3b shows this performance gap widens with increasing U .The smallest value of the finite horizon ( U ) at which the routing agent is able to serve 100% of the customer requests, represents the minimum time required to serve all the cus-tomers and complete the trip. Therefore, by suitably modi-fying the MDP in our VRP framework, the proposed rout-ing method can be extended to other variants of the Vehicle Routing Problem, such as time-minimization VRP, distance-minimization VRP and VRP with time windows. 

Ablation Study      

> Method Customers Served (%)
> PG-GAT without Edge Features 83.2 PG-GAT-Edge without Global Graph Embedding 76.4 PG-GAT-Edge without Finite Horizon in Embedding 78.2
> PG-GAT-Edge (Proposed Method) 86.6

Table 5: Ablation Study for Edge Features, Global Graph Embedding and Finite Horizon in Graph Embedding on the EMA-50 instances Table 5 presents an ablation study for the edge features, the global graph embedding module and the incorporation of finite horizon in the embedding module. We observe that the incorporation of edge features in the GAT layers improved the routing results by 4.1%. The customer service rate of PG-GAT-Edge without the global graph embedding (GE) module is 11.8% lower than the proposed method. Similarly, we observe that the incor-poration of the finite horizon in the graph embedding module improved the customer service rate by 10.7%. These ablation study results prove that the proposed Cross-Attention-based global graph embedding module and the inclusion of finite horizon in the embedding help our pro-posed model achieve better customer service rate. 

## Conclusion 

In this paper, we proposed a deep RL-based routing method with a GAT-Edge-based network representation module to solve the VRP-FTH. We created a novel routing network embedding module using GAT-Edge and Cross-Attention mechanism, which is capable of extracting important local network features as wells as a global network representation. The incorporation of the finite horizon (and other current ve-hicle state components) in the graph embedding module en-abled the agent take better routing decisions. We integrated the graph embedding module with a policy network-based routing method. The main results of this paper can be sum-merised as: 1. Our method improves the customer service rate by 57.7% on EMA networks and by 11.2% on Vienna networks compared to the other methods. 2. PG-GAT-Edge improves customer service by 52.6% on Euclidean instances compared to other methods. 3. The solution time of our proposed method is 90.64% less than genetic algorithm and 35.4% less than the DRL-Transformer method. In future work, research efforts could be made to extend the proposed deep RL-based framework for vehicle fleet routing. References 

Basso, R.; Kulcs´ ar, B.; Sanchez-Diaz, I.; and Qu, X. 2022. Dynamic stochastic electric vehicle routing with safe rein-forcement learning. Transportation research part E: logis-tics and transportation review , 157: 102496. Baty, L.; Jungel, K.; Klein, P. S.; Parmentier, A.; and Schif-fer, M. 2024. Combinatorial Optimization-Enriched Ma-chine Learning to Solve the Dynamic Vehicle Routing Prob-lem with Time Windows. Transportation Science , 58(4): 708–725. Chen, R.; Liu, X.; Miao, L.; and Yang, P. 2020. Electric vehi-cle tour planning considering range anxiety. Sustainability ,12(9): 3685. Derya, T.; Dinler, E.; and Kec ¸eci, B. 2020. Selective gener-alized travelling salesman problem. Mathematical and Com-puter Modelling of Dynamical Systems , 26(1): 80–118. Ferrucci, F.; and Bock, S. 2015. A general approach for controlling vehicle en-route diversions in dynamic vehicle routing problems. Transportation Research Part B: Method-ological , 77: 76–87. Gama, R.; and Fernandes, H. L. 2021. A reinforcement learning approach to the orienteering problem with time windows. Computers & Operations Research , 133: 105357. Hildebrandt, F. D.; Thomas, B. W.; and Ulmer, M. W. 2023. Opportunities for reinforcement learning in stochastic dy-namic vehicle routing. Computers & operations research ,150: 106071. Jia, Y.-H.; Mei, Y.; and Zhang, M. 2021. A bilevel ant colony optimization algorithm for capacitated electric ve-hicle routing problem. IEEE transactions on cybernetics ,52(10): 10855–10868. Kara, I.; Bicakci, P. S.; and Derya, T. 2016. New formula-tions for the orienteering problem. Procedia Economics and Finance , 39: 849–854. Klapp, M. A.; Erera, A. L.; and Toriello, A. 2018. The dy-namic dispatch waves problem for same-day delivery. Euro-pean Journal of Operational Research , 271(2): 519–534. Kool, W.; Van Hoof, H.; and Welling, M. 2018. At-tention, learn to solve routing problems! arXiv preprint arXiv:1803.08475 .Kullman, N. D.; Goodson, J. C.; and Mendoza, J. E. 2021. Electric vehicle routing with public charging stations. Trans-portation Science , 55(3): 637–659. Lin, B.; Ghaddar, B.; and Nathwani, J. 2021. Deep rein-forcement learning for the electric vehicle routing problem with time windows. IEEE Transactions on Intelligent Trans-portation Systems , 23(8): 11528–11538. Louati, A.; Lahyani, R.; Aldaej, A.; Mellouli, R.; and Nusir, M. 2021. Mixed integer linear programming models to solve a real-life vehicle routing problem with pickup and delivery. 

Applied Sciences , 11(20): 9551. Maity, A.; and Sarkar, S. 2025. Electric vehicle routing with stochastic customers using deep reinforcement learning and graph convolutional networks. Journal of Intelligent Trans-portation Systems , 1–17. Maroof, A.; Ayvaz, B.; and Naeem, K. 2024. Logistics Op-timization Using Hybrid Genetic Algorithm (HGA): A So-lution to the Vehicle Routing Problem With Time Windows (VRPTW). IEEE Access , 12: 36974–36989. Mozhdehi, A.; Mohammadizadeh, M.; and Wang, X. 2024. Edge-direct: A deep reinforcement learning-based method for solving heterogeneous electric vehicle routing problem with time window constraints. arXiv preprint arXiv:2407.01615 .Schneider, M.; Stenger, A.; and Goeke, D. 2014. The electric vehicle-routing problem with time windows and recharging stations. Transportation science , 48(4): 500–520. Tang, M.; Zhuang, W.; Li, B.; Liu, H.; Song, Z.; and Yin, G. 2023. Energy-optimal routing for electric vehicles us-ing deep reinforcement learning with transformer. Applied Energy , 350: 121711. Toth, P.; and Vigo, D. 2014. Vehicle routing: problems, methods, and applications . SIAM. Ulmer, M. W.; Goodson, J. C.; Mattfeld, D. C.; and Thomas, B. W. 2020. On modeling stochastic dynamic vehicle rout-ing problems. EURO Journal on Transportation and Logis-tics , 9(2): 100008. Ulmer, M. W.; and Thomas, B. W. 2020. Meso-parametric value function approximation for dynamic customer accep-tances in delivery routing. European Journal of Operational Research , 285(1): 183–195. Urrutia-Zambrana, A.; Tirado, G.; and Mateos, A. 2021. Variable neighborhood search to solve the generalized orien-teering problem. International Transactions in Operational Research , 28(1): 142–167. Vansteenwegen, P.; and Gunawan, A. 2019. Orienteering problems. EURO advanced tutorials on operational re-search , 1. Veliˇ ckovi´ c, P.; Cucurull, G.; Casanova, A.; Romero, A.; Lio, P.; and Bengio, Y. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 .Wang, X.; Golden, B. L.; and Wasil, E. A. 2008. Using a ge-netic algorithm to solve the generalized orienteering prob-lem. In The vehicle routing problem: latest advances and new challenges , 263–274. Springer. Williams, R. J. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Ma-chine learning , 8: 229–256. Xu, N.; Duan, D.-T.; Yang, Q.; Hu, X.-M.; Zhou, C.-J.; Zheng, Z.-L.; Zhao, J.-M.; and Jeon, S.-W. 2024. Adapted Genetic Algorithm for Orienteering Problem. In 2024 11th International Conference on Machine Intelligence Theory and Applications (MiTA) , 1–8. IEEE. Zhang, J.; Luo, K.; Florio, A. M.; and Van Woensel, T. 2023. Solving large-scale dynamic vehicle routing problems with stochastic requests. European Journal of Operational Re-search , 306(2): 596–614.