# PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression
# PolySHAP：利用交互感知的多项式回归扩展 KernelSHAP

**Authors**: Fabian Fumagalli, R. Teal Witter, Christopher Musco \
**Date**: 2026-01-26 \
**PDF**: https://arxiv.org/pdf/2601.18608v1 \
**Tags**: <span class="tag-label tag-green">SR</span> \
**Score**: 6.0 \
**Evidence**: 用于特征交互的多项式回归 \
**TLDR**: 利用多项式回归扩展KernelSHAP，以捕获非线性特征交互从而提高可解释性。

---

## 速览
**TLDR**：PolySHAP 通过引入高阶多项式回归改进了 KernelSHAP，并为配对采样技术提供了理论支撑。 \
**Motivation**：传统的 KernelSHAP 采用线性近似，无法有效捕捉特征间的非线性交互作用。 \
**Method**：提出 PolySHAP 方法，利用高阶多项式拟合博弈函数，并证明了二阶 PolySHAP 与配对采样的等价性。 \
**Result**：在多个基准数据集上实现了更精确的 Shapley 值估计，并从理论上保证了估计的一致性。 \
**Conclusion**：该研究提升了 Shapley 值的计算效率与精度，并为配对采样这一启发式方法提供了首个强有力的理论解释。

---

## Abstract
Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.   In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.   Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.

## 摘要
Shapley 值已成为可解释人工智能（XAI）中核心的博弈论工具。然而，对于具有 $d$ 个特征的模型，精确计算 Shapley 值需要 $2^d$ 次博弈评估。Lundberg 和 Lee 的 KernelSHAP 算法已成为避免这种指数级成本的领先方法。KernelSHAP 通过将博弈近似为线性函数来估计 Shapley 值，该函数使用针对随机特征子集的少量博弈评估进行拟合。在这项工作中，我们通过高阶多项式近似博弈来扩展 KernelSHAP，从而捕捉特征之间的非线性交互。我们提出的 PolySHAP 方法在各种基准数据集上产生了经验上更好的 Shapley 值估计，并且我们证明了这些估计是一致的。此外，我们将我们的方法与配对采样（对偶采样，antithetic sampling）联系起来，这是一种普遍用于 KernelSHAP 以提高经验准确性的改进方法。我们证明了配对采样输出的 Shapley 值近似值与二阶 PolySHAP 完全相同，而无需拟合二阶多项式。据我们所知，这一发现为配对采样启发式方法的卓越实际表现提供了第一个强有力的理论依据。