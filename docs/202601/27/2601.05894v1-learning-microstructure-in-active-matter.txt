Title: Learning microstructure in active matter

URL Source: https://arxiv.org/pdf/2601.05894v1

Published Time: Mon, 12 Jan 2026 02:01:16 GMT

Number of Pages: 13

Markdown Content:
# Learning microstructure in active matter 

Writu Dasgupta, 1 Suvendu Mandal, 1, ‚àó Aritra K. Mukhopadhyay, 1 and Benno Liebchen 1, ‚Ä†

> 1

Institute for Condensed Matter Physics, Technische Universit¬® at Darmstadt, Hochschulstra√üe 8, 64289 Darmstadt, Germany. 

Understanding microstructure in terms of closed-form expressions is an open challenge in nonequi-librium statistical physics. We propose a simple and generic method that combines particle-resolved simulations, deep neural networks and symbolic regression to predict the pair-correlation function of passive and active particles. Our analytical closed-form results closely agree with Brownian dy-namics simulations, even at relatively large packing fractions and for strong activity. The proposed method is broadly applicable, computationally efficient, and can be used to enhance the predictive power of nonequilibrium continuum theories and for designing pattern formation. 

The question how macroscopic phenomenon arise from microscopic interactions is central to phenomena across physics, chemistry, and biology, with examples ranging from phase transition [1‚Äì4] and glass formation [5‚Äì7], to colloidal self-assembly [8], fluid diffusion in porous ma-terials [9], and the self-organization of proteins in the crowded cellular cytosol [10]. In equilibrium systems, the radial distribution function (RDF), g( r), describes the particle density around a central test particle as a function of distance r. Besides characterizing structure, g( r) plays a pivotal role in relating microscopic structure to macroscopic thermodynamic properties, e.g., via the virial and the energy equation [11‚Äì13]. Beyond that, g( r) serves as a key ingredient to understand the col-lective dynamics of dense and supercooled liquids [6, 7], with subtle variations in its oscillatory shape indicating transitions such as re-entrant glass transition in colloidal-polymer mixtures [14] or dynamic slowdown due to con-finements [15]. Thus, g( r) is not merely a geometric descriptor but a predictive function, linking microscopic structure to macroscopic thermodynamics and collective dynamics, which is essential for understanding complex material properties. Recently, microstructure-informed theoretical frame-works have been extended to nonequilibrium systems such as active matter, featuring a continuous energy input. Active systems, including self-propelled col-loids [16‚Äì29], bacterial colonies [30‚Äì39], and active fil-aments [40‚Äì46], exhibit collective phenomena such as motility-induced phase separation (MIPS) [47‚Äì56], flock-ing [57‚Äì60], and anomalous rheology [61]. Central to these behaviors is the pair correlation function g( r, Œ∏ ), which captures both spatial ( r) and orientational ( Œ∏)correlations that can arise from self-propulsion. For in-stance, the emergence of an orientational asymmetry in the RDF induces MIPS [62], explains flocking by turn-ing away [63], and plays a crucial role in quantifying ac-tive stresses exerted on passive probe particles in active baths [64]. The anisotropic RDF also enables predic-tions of MIPS breakdown in anisotropic systems, as well as the emergence and coexistence of polar and nematic order [65]. Contrasting its fundamental importance, determining g( r) and g( r, Œ∏ ) is often challenging. In equilibrium, both for simple and complex fluids, classical Density Func-tional Theory (DFT) provides a powerful tool for de-riving g( r) from a free energy functional F[œÅ] [66, 67]. However, such functionals are exactly known only for very few cases (in equilibrium) [11], and generalizations to predict the structure of active systems via dynamical density functional theory are often unreliable far from equilibrium. While recent machine-learning approaches can determine remarkable representations of F[œÅ] from data [66, 68‚Äì70], they also remain rooted in a (near-)equilibrium framework. Accordingly, for active matter, we are currently lack-ing a general method to predict g( r, Œ∏ ), in particular, in terms of closed-form expressions that are required for the development of continuum theories. Currently, pioneer-ing existing works either (i) use linearized Dean-equation approaches that offer analytical expressions in the dilute limit but break down at higher densities [71], where the full anisotropic structure becomes essential, (ii) angularly average g( r, Œ∏ ), erasing anisotropy [72], or (iii) rely on computational approaches [62, 65, 73, 74]. To address the gap in our understanding of g( r, Œ∏ ), we introduce a simple and generic method that learns (anisotropic) structure from simulations and translates them into interpretable closed-form expressions, that contain the full dependence on system parameters. These results can be used in the future to develop analytical theories predicting collective behavior in active matter beyond the low density regime. 

Model. We consider a two-dimensional system of N =8 √ó 10 4 overdamped active or passive Brownian particles (ABPs or PBPs) and denote the position and orientation of the i-th particle by ri and Œ∏i, respectively. Each par-ticle has a diameter œÉ, self-propels with velocity v0, and has a translational diffusion coefficient Dt. To satisfy the fluctuation-dissipation relation in the equilibrium limit for Newtonian solvents, we fix the rotational diffusion coefficient to Dr = 3 Dt/œÉ 2. The particles interact via a purely repulsive Weeks‚ÄìChandler‚ÄìAndersen (WCA) po-tential UWCA (r), defined as 4 œµ[( œÉ/r )12 ‚àí (œÉ/r )6] + œµ for 

r < 21/6œÉ and zero otherwise, where r is the interparticle distance and œµ defines the interaction strength. Subse-

> arXiv:2601.05894v1 [cond-mat.soft] 9 Jan 2026

2g(r, Œ∏, œÜ, Pe)                       

> Time
> a) Simulation b) Data generation c) DNN d) Symbolic regression e) Results
> exp (‚Ñ±(r,Œ∏,œÜ)sin (ùí¢ (r,Œ∏,œÜ,Pe))+c
> exp
> √ó
> r
> Œ∏
> Pe
> œÜ
> r
> g
> g(r, Œ∏, œÜ, Pe)
> r
> c
> +
> +
> œÜ
> Œ∏√ó
> sin
> r
> r
> Pe
> FIG. 1. Schematic illustration of the proposed method. (a) Brownian dynamics simulations of active Brownian particles as a function of time, packing fraction œÜ, and P¬¥ eclet number Pe. (b) From these snapshots, we compute the radial distribution function, either isotropic g( r) (passive or angle-averaged) or fully anisotropic g( r, Œ∏ ) (active). (c) A deep neural network learns the mapping ( r, Œ∏, œÜ, Pe) 7‚Üíg( r, Œ∏ ), providing a smooth, differentiable surrogate for the simulation-measured microstructure. (d) Symbolic regression converts the learned surrogate into compact, closed-form analytical expressions. (e) These analytical formulas accurately reproduce near-contact peaks, coordination-shell oscillations, and activity-induced microstructure, offering ready-to-use structural input for nonequilibrium theory.

quently, we non-dimensionalize the system by choosing the length unit ru = œÉ and the time unit tu = œÉ2/D t

(three times the persistence time 1 /D r ). This leads to 

r‚àó = r/r u and t‚àó = t/t u. In these units, the equations of motion are Àôr‚àó 

> i

= Pe pi + Fint ‚àó 

> i

+ ‚àö2 Œæ‚àó 

> i

(t‚àó), (1) ÀôŒ∏i = ‚àö6 Œ∑‚àó 

> i

(t‚àó), (2) where Pe = v0œÉ/D t is the P¬¥ eclet number, pi =(cos Œ∏i, sin Œ∏i), and Fint ‚àó 

> i

is the dimensionless interac-tion force. The Gaussian noises Œæ‚àó and Œ∑‚àó have zero mean and unit variance. We integrate Eqs. (1)‚Äì(2) using LAMMPS [75] with time step ‚àÜ t‚àó = 5 √ó 10 ‚àí5 in a square domain of side length L‚àó = 256 with periodic bound-ary conditions. The control parameters are Pe and the packing fraction œÜ = N œÄ/ (4 L‚àó2) and Œµ‚àó whose precise value is rather unimportant for the emerging collective behavior. We generate a dataset for œÜ ‚àà [0 .20 , 0.50] and Pe ‚àà [5 , 45] (Pe = 0: in the equilibrium case) at fixed 

œµ‚àó = 256. For each, ( œÜ, Pe) pair, we extract 20 statisti-cally independent snapshots from our simulations. From these configurations, we compute g( r‚àó, Œ∏ ) with radial and angular resolution of ‚àÜ r‚àó = 0 .025 and ‚àÜ Œ∏ = 4 ‚ó¶.

Deep learning framework. To determine g( r, Œ∏ ), we now describe our learning approach, which we later exploit to create a dense dataset as required for the construction of an analytical closed-form expression for g( r, Œ∏ ). We use the mentioned 20 snapshots for each ( œÜ, Pe) combination to train a feed-forward deep neural network (DNN) as a surrogate model for predicting g( r, Œ∏ ) in both active and passive systems. The network takes as input the features ( r, Œ∏, œÜ, Pe) and outputs g( r, Œ∏, œÜ, Pe) (see Fig. 1). For isotropic systems, the angular coordinate 

Œ∏ is omitted. Training is carried out using the AdamW optimizer [76] with a learning rate of 5 √ó 10 ‚àí4 for 100 epochs (see Supplemental Material (SM) for details of DNN architecture, learning, and loss functions). The DNN achieves root mean square error (RMSE) of 10 ‚àí2

for passive systems and between 10 ‚àí2 and 10 ‚àí1 for active systems (see SM for details). Following DNN training, we apply symbolic regres-sion to the DNN predictions, allowing for continuous in-put data across area fractions and P¬¥ eclet numbers. We perform symbolic regression by evolving populations of mathematical expressions to minimize a loss function pe-nalized by expression complexity [77] (see SM for details). 

Equilibrium microstructure from data. To test our approach, we first explore g( r) in equilibrium for (al-most) hard disks, realized via a steeply repulsive WCA potential [78]. For such systems, the Percus‚ÄìYevick (PY) closure of the Ornstein‚ÄìZernike (OZ) equation pro-vides accurate predictions of g( r) [11, 79](e.g. analytical Wertheim solution in 3D [80]; semi-analytical solution in 2D [81].) We use the 2D solution as a benchmark of our learning approach. We now predict g(r) directly from a relatively small number of simulations and ask: Can a neural network generalize the structural trends of g( r)smoothly across varying area fractions and make predic-tions beyond the trained data? Figure 2 exhibits this result. The DNN was trained on a range of area fractions œÜ =0.2, 0.25 , 0.30 , 0.35 , 0.40 , 0.45 , 0.50 and successfully extended its predictions to non-trained area fractions, e.g., at œÜ = 0 .23 and œÜ = 0 .43 for which we determine g( r) from simulations as test cases. For instance, at 3g(r)

# r /œÉ      

> FIG. 2. Equilibrium microstructure learned from data.
> Radial distribution function g( r) of passive Brownian particles at two non-trained packing fractions, œÜ= 0 .23 and œÜ= 0 .43. Symbols represent Brownian dynamics simulation data, the blue dashed line shows predictions from the trained deep neu-ral network (learned), and the black solid line corresponds to the Percus‚ÄìYevick (PY) reference solution. Red solid lines represent analytical predictions from Eq. (3).

œÜ = 0 .23, the DNN captures the characteristic features of a moderately dense fluid, i.e., an initial near-contact peak followed by weak oscillations. As the area fraction increases to œÜ = 0 .43, the first peak value increases, and subsequent oscillations intensify, signaling enhanced medium-range order. Remarkably, the predicted g( r)captures these features quantitatively, matching the PY solution and reproducing subtle details such as changes in peak widths and trough depths. The low root mean square error (RMSE ‚â≤ 0.03 across area fractions [see SM]) confirms that the DNN has learned structural principles, not just memorized specific data points. Having established that the DNN can reliably learn equilibrium structure, we now ask: Can we translate the learned mapping ( r, œÜ ) 7 ‚Üí g( r, œÜ ) into a useful analytical expression? To explore this, we apply symbolic regres-sion to the DNN‚Äôs predictions, generating dense datasets across œÜ = 0 .2 to œÜ = 0 .5, yielding a closed-form expres-sion for g( r): g( r) = exp k1(k2œÜ) r sin  r2(œÜ + 1)  

√ó cos k3  exp k4rk5  (3) where ki with i ‚àà [1 , 2, . . . , 5] are constants (see SM). While this result is much simpler than known semi-analytical results in 2D [81] and celebrated 3D re-sults [80], it accurately captures the near-contact peak, coordination-shell oscillations, and their attenuation [see œÜ = 0.45 

> g(r)

r /œÉ    

> FIG. 3. Activity-induced angle-averaged microstruc-ture. Validation of analytical predictions from Eq. (4) for various P¬¥ eclet numbers at a fixed area fraction œÜ= 0 .45. Solid lines represent analytical predictions, dashed lines rep-resent learned results from the trained deep neural network, and symbols denote simulation data.

Fig. 2]. The expression also recovers the correct low-density limit g( r) ‚Üí 1 as œÜ ‚Üí 0 and remains in good agreement with simulation results at low packing frac-tions (0 ‚â§ œÜ < 0.2) (see SM), despite the limitation of our training data for œÜ ‚â• 0.2. 

Active systems: Radial structure g( r). Unlike equi-librium systems, active matter lacks a unified theoretical framework (such as the minimization of the free energy functional) to obtain g( r), making them a challenging case for theory. In addition, active particles feature ad-ditional orientational degree of freedom (self-propulsion direction) and activity parameters (P¬¥ eclet number). We now ask: How effective is the combination of DNN and symbolic regression to predict the microstructure of ac-tive Brownian particles in terms of g( r)? Figure 3 exemplarily shows the learned microstruc-ture for two non-trained state points. For œÜ = 0 .3 and Pe = 15, g( r) exhibits a near-contact peak and damped oscillations qualitatively similar to equilibrium systems. At higher activity, Pe = 45, the near-contact peak be-comes more pronounced (see inset of Fig. 3), and oscilla-tions shift in amplitude and spacing, reflecting the com-petitive dynamics between activity and steric repulsion. The DNN captures this behavior across all considered area fractions and P¬¥ eclet numbers (see SM). Symbolic regression then converts the learned radial dependence into a compact representation: g( r) = pexp[ A(r, œÜ, Pe) B(r, œÜ, Pe)] , (4) where A and B are relatively simple nonlinear functions 4œÜ = 0.45                    

> œÜ=0.30
> Pe =35
> Pe =15
> a) b) c)
> e) d) f)
> g(r)g(r)
> r/œÉ
> r/œÉ
> Simulation Learned
> FIG. 4. Anisotropic microstructure of active Brownian particles. Angle-resolved pair correlation function g( r, Œ∏ )of active Brownian particles (ABPs) obtained from Brownian-dynamics simulations [(a), (d)] for ( œÜ, Pe) = (0 .45 ,15) and (œÜ, Pe) = (0 .30 ,35), respectively, and from deep neural network (learned) predictions [(c),(f)] for the same state points. Both simulations and learned predictions reveal a pronounced anisotropic microstructure, characterized by particle accumulation in front of a reference active particle ( Œ∏= 180 ‚ó¶) and depletion in its wake ( Œ∏= 0 ‚ó¶). The central panels [(b), (e)] show radial cuts along the propulsion direction ( Œ∏= 180 ‚ó¶), demonstrating quantitative agreement between simulation data, learned predictions, and the analytical predictions obtained from Eq. (5) over the full radial range.

(see SM). Eq. (4) offers a nonequilibrium prediction for g( r), that works even at relatively large Pe, œÜ. This re-sult encapsulates how the packing fraction sets the base-line coordination-shell structure, while activity amplifies near-contact correlations and reshapes the oscillatory de-cay (see Fig. 3). 

Active systems: Anisotropic structure g( r, Œ∏ ). While the angle-averaged g( r) captures how activity modifies the average packing of particles, a defining characteristic of active matter lies in its directional nature [82]. The angle-resolved correlation g( r, Œ∏ ) reveals this directional-ity by conditioning neighbor statistics along the propul-sion axis of a reference particle. In active systems, parti-cles ‚Äúpush‚Äù into the surrounding medium, accumulating neighbors in the direction of motion, while leaving a de-pleted wake behind (see Fig. 4). This asymmetry plays a critical role, e.g., in the theoretical framework for active stresses [64] and MIPS [62]. Figure 4 compares learned results for g( r, Œ∏ ) with re-sults from Brownian dynamics simulations. Heatmaps illustrate the characteristic accumulation of particles at 

Œ∏ = 180 ‚ó¶ (the direction of propulsion) and depletion at Œ∏ = 0 ‚ó¶ (the rear). As both packing fraction œÜ and P¬¥ eclet number Pe increase, the anisotropy becomes more pronounced, signaling the onset of a stronger ‚Äúblocking mechanism‚Äù, leading to the slowdown of particles in re-gions of enhanced density, which is at the heart of the emergence of MIPS [47, 62]. Also, here, the DNN not only reproduces the qualitative trends but also accurately captures the radial localization of anisotropy near con-tact, which gradually weakens at larger separations. Using the quasi-continuous dataset available from the DNN, symbolic regression is employed to construct a compact, analytical form for g( r, Œ∏ ). The resulting ex-pression is: g( r, Œ∏ ) = r exp[ F(r, Œ∏, œÜ ) sin G(r, Œ∏, œÜ, Pe) ‚àí c0] + c1, (5) where F and G are nonlinear functions, and c0, c1 are fitted constants (all provided in the SM). This formula-tion retains the key anisotropic features, systematically strengthening with increasing activity and area fraction. The central panel of Fig. 4 offers an additional valida-tion of the analytical prediction, extracting radial cuts along the propulsion direction Œ∏ = 180 ‚ó¶ (see SM for 

Œ∏ = 0 ‚ó¶, 90 ‚ó¶, 270 ‚ó¶). These cuts show that the DNN, as well as Eq. (5), capture the near-contact peak and oscil-latory behavior with remarkable accuracy. 

Conclusions. We introduced a simple and generic method that combines particle-resolved simulations, deep 5neural networks (DNNs), and symbolic regression to pre-dict microstructure in terms of analytical closed-form ex-pressions. Beyond providing an efficient surrogate for simulations, our work paves the road towards structure-informed nonequilibrium theory. The generic character of the presented method invites a broad range of ap-plications, e.g., to active systems with short-range at-tractions [67], in external potentials, and in confine-ment [83], as well as to sheared glassy and granular ma-terials [84‚Äì86]. Finally, the closed-form expressions could inform novel inverse design strategies [87, 88], and mo-tivate a new wave of developments to predict dynamical properties directly from structural information in non-equilibrium systems [89, 90]. 

ACKNOWLEDGMENTS 

B.L. and A.K.M. acknowledge funding by the Deutsche Forschungsgemeinschaft (DFG, German Research Foun-dation) in the framework of the collaborative research center Multiscale Simulation Methods for Soft-Matter Systems (TRR 146) under Project No. 233630050.  

> ‚àó

suvendu.mandal@pkm.tu-darmstadt.de  

> ‚Ä†

benno.liebchen@pkm.tu-darmstadt.de [1] J.-P. Hansen and L. Verlet, Phase transitions of the lennard-jones system, Phys. Rev. 184 , 151 (1969). [2] T. Kanai, N. Boon, P. J. Lu, E. Sloutskin, A. B. Schofield, F. Smallenburg, R. van Roij, M. Dijkstra, and D. A. Weitz, Crystallization and reentrant melting of charged colloids in nonpolar solvents, Phys. Rev. E 91 , 030301 (2015). [3] C. P. Royall, P. Charbonneau, M. Dijkstra, J. Russo, F. Smallenburg, T. Speck, and C. Valeriani, Colloidal hard spheres: Triumphs, challenges, and mysteries, Rev. Mod. Phys. 96 , 045003 (2024). [4] P. M. Reis, R. A. Ingale, and M. D. Shattuck, Crystalliza-tion of a Quasi-Two-Dimensional Granular Fluid, Phys. Rev. Lett. 96 , 258001 (2006). [5] E. R. Weeks and D. A. Weitz, Properties of Cage Re-arrangements Observed near the Colloidal Glass Transi-tion, Phys. Rev. Lett. 89 , 095704 (2002). [6] A. Banerjee, S. Sengupta, S. Sastry, and S. M. Bhat-tacharyya, Role of Structure and Entropy in Determining Differences in Dynamics for Glass Formers with Differ-ent Interaction Potentials, Phys. Rev. Lett. 113 , 225701 (2014). [7] M. K. Nandi, A. Banerjee, C. Dasgupta, and S. M. Bhat-tacharyya, Role of the Pair Correlation Function in the Dynamical Transition Predicted by Mode Coupling The-ory, Phys. Rev. Lett. 119 , 265502 (2017). [8] M. Klokkenburg, R. P. A. Dullens, W. K. Kegel, B. H. Ern¬¥ e, and A. P. Philipse, Quantitative Real-Space Analy-sis of Self-Assembled Structures of Magnetic Dipolar Col-loids, Phys. Rev. Lett. 96 , 037203 (2006). [9] C. Bousige, P. Levitz, and B. Coasne, Bridging scales in disordered porous media by mapping molecular dynamics onto intermittent Brownian motion, Nat. Commun. 12 ,1043 (2021). [10] S. von B¬® ulow, M. Siggel, M. Linke, and G. Hummer, Dynamic cluster formation determines viscosity and dif-fusion in dense protein solutions, Proc. Natl. Acad. Sci. U. S. A. 116 , 9843 (2019). [11] J.-P. Hansen and I. R. McDonald, Theory of simple liq-uids: With applications to soft matter (Academic press, 2013). [12] I. Pihlajamaa and L. M. C. Janssen, Comparison of in-tegral equation theories of the liquid state, Phys. Rev. E 

110 , 044608 (2024). [13] A. E. Stones, R. P. Dullens, and D. G. Aarts, Model-Free Measurement of the Pair Potential in Colloidal Fluids Using Optical Microscopy, Phys. Rev. Lett. 123 , 098002 (2019). [14] K. N. Pham, A. M. Puertas, J. Bergenholtz, S. U. Egel-haaf, A. Moussa¬® ƒ±d, P. N. Pusey, A. B. Schofield, M. E. Cates, M. Fuchs, and W. C. K. Poon, Multiple Glassy States in a Simple Model System, Science 296 , 104 (2002). [15] S. Mandal, S. Lang, M. Gross, M. Oettel, D. Raabe, T. Franosch, and F. Varnik, Multiple reentrant glass transitions in confined hard-sphere glasses, Nat. Com-mun. 5, 4435 (2014). [16] C. Kurzthaler, C. Devailly, J. Arlt, T. Franosch, W. C. K. Poon, V. A. Martinez, and A. T. Brown, Probing the Spatiotemporal Dynamics of Catalytic Janus Particles with Single-Particle Tracking and Differential Dynamic Microscopy, Phys. Rev. Lett. 121 , 078001 (2018). [17] J. Palacci, S. Sacanna, A. P. Steinberg, D. J. Pine, and P. M. Chaikin, Living Crystals of Light-Activated Col-loidal Surfers, Science 339 , 936 (2013). [18] F. Ginot, I. Theurkauff, D. Levis, C. Ybert, L. Boc-quet, L. Berthier, and C. Cottin-Bizonne, Nonequilib-rium Equation of State in Suspensions of Active Colloids, Phys. Rev. X 5, 011004 (2015). [19] C. Bechinger, R. Di Leonardo, H. L¬® owen, C. Reichhardt, G. Volpe, and G. Volpe, Active particles in complex and crowded environments, Rev. Mod. Phys. 88 , 045006 (2016). [20] R. Golestanian, T. B. Liverpool, and A. Ajdari, Design-ing phoretic micro- and nano-swimmers, New J. Phys. 9,126 (2007). [21] J. Palacci, C. Cottin-Bizonne, C. Ybert, and L. Bocquet, Sedimentation and Effective Temperature of Active Col-loidal Suspensions, Phys. Rev. Lett. 105 , 088304 (2010). [22] A. Scagliarini and I. Pagonabarraga, Unravelling the role of phoretic and hydrodynamic interactions in active col-loidal suspensions, Soft Matter 16 , 8893 (2020). [23] R. Garcia-Millan, J. Sch¬® uttler, M. E. Cates, and S. A. Loos, Optimal Closed-Loop Control of Active Particles and a Minimal Information Engine, Phys. Rev. Lett. 135 ,088301 (2025). [24] A. Z¬® ottl and H. Stark, Emergent behavior in active col-loids, J. Phys.: Condens. Matter 28 , 253001 (2016). [25] S. Thutupalli, D. Geyer, R. Singh, R. Adhikari, and H. A. Stone, Flow-induced phase separation of active particles is controlled by boundary conditions, Proc. Natl. Acad. Sci. U.S.A. 115 , 5403 (2018). [26] M. A. Fernandez-Rodriguez, F. Grillo, L. Alvarez, M. Rathlef, I. Buttinoni, G. Volpe, and L. Isa, Feedback-6

controlled active brownian colloids with space-dependent rotational dynamics, Nat. Commun. 11 , 4223 (2020). [27] W. F. Paxton, K. C. Kistler, C. C. Olmeda, A. Sen, S. K. St. Angelo, Y. Cao, T. E. Mallouk, P. E. Lammert, and V. H. Crespi, Catalytic Nanomotors: Autonomous Move-ment of Striped Nanorods, J. Am. Chem. Soc. 126 , 13424 (2004). [28] J. R. Howse, R. A. L. Jones, A. J. Ryan, T. Gough, R. Vafabakhsh, and R. Golestanian, Self-Motile Colloidal Particles: From Directed Propulsion to Random Walk, Phys. Rev. Lett. 99 , 048102 (2007). [29] J. Grauer, F. Schmidt, J. Pineda, B. Midtvedt, H. L¬® owen, G. Volpe, and B. Liebchen, Active droploids, Nat. Com-mun. 12 , 6005 (2021). [30] H. P. Zhang, A. Be‚Äôer, E.-L. Florin, and H. L. Swinney, Collective motion and density fluctuations in bacterial colonies, Proc. Natl. Acad. Sci. U.S.A. 107 , 13626 (2010). [31] H. H. Wensink, J. Dunkel, S. Heidenreich, K. Drescher, R. E. Goldstein, H. L¬® owen, and J. M. Yeomans, Meso-scale turbulence in living fluids, Proc. Natl. Acad. Sci. U.S.A. 109 , 14308 (2012). [32] F. Peruani, J. Starru√ü, V. Jakovljevic, L. S√∏gaard-Andersen, A. Deutsch, and M. B¬® ar, Collective Motion and Nonequilibrium Cluster Formation in Colonies of Gliding Bacteria, Phys. Rev. Lett. 108 , 098102 (2012). [33] S. Gonzalez La Corte, C. A. Stevens, G. C¬¥ arcamo-Oyarce, K. Ribbeck, N. S. Wingreen, and S. S. Datta, Morphogenesis of bacterial cables in polymeric environ-ments, Sci. Adv. 11 , eadq7797 (2025). [34] Z. You, D. J. Pearce, A. Sengupta, and L. Giomi, Geome-try and Mechanics of Microdomains in Growing Bacterial Colonies, Phys. Rev. X 8, 031065 (2018). [35] J. Dhar, A. L. P. Thai, A. Ghoshal, L. Giomi, and A. Sen-gupta, Self-regulation of phenotypic noise synchronizes emergent organization and active transport in confluent microbial environments, Nat. Phys. 18 , 945 (2022). [36] M. K. Faluweki, J. Cammann, M. G. Mazza, and L. Goehring, Active Spaghetti: Collective Organization in Cyanobacteria, Phys. Rev. Lett. 131 , 158303 (2023). [37] Y. I. Yaman, E. Demir, R. Vetter, and A. Kocabas, Emer-gence of active nematics in chaining bacterial biofilms, Nat. Commun. 10 , 2285 (2019). [38] A. I. Curatolo, N. Zhou, Y. Zhao, C. Liu, A. Daerr, J. Tailleur, and J. Huang, Cooperative pattern formation in multi-component bacterial systems through reciprocal motility regulation, Nat. Phys. 16 , 1152 (2020). [39] P. Guillamat, J. Ign¬¥ es-Mullol, and F. Sagu¬¥ es, Taming ac-tive turbulence with patterned soft interfaces, Nat. Com-mun. 8, 564 (2017). [40] K. Kruse and F. J¬® ulicher, Actively Contracting Bundles of Polar Filaments, Phys. Rev. Lett. 85 , 1778 (2000). [41] S. Mandal, C. Kurzthaler, T. Franosch, and H. L¬® owen, Crowding-Enhanced Diffusion: An Exact Theory for Highly Entangled Self-Propelled Stiff Filaments, Phys. Rev. Lett. 125 , 138002 (2020). [42] V. Schaller, C. Weber, C. Semmrich, E. Frey, and A. R. Bausch, Polar patterns of driven filaments, Nature 467 ,73 (2010). [43] B. Lemma, N. P. Mitchell, R. Subramanian, D. J. Needle-man, and Z. Dogic, Active Microphase Separation in Mix-tures of Microtubules and Tip-Accumulating Molecular Motors, Phys. Rev. X 12 , 031006 (2022). [44] T. Sanchez, D. Welch, D. Nicastro, and Z. Dogic, Cilia-Like Beating of Active Microtubule Bundles, Science 

333 , 456 (2011). [45] M. Serra, L. Lemma, L. Giomi, Z. Dogic, and L. Mahade-van, Defect-mediated dynamics of coherent structures in active nematics, Nat. Phys. 19 , 1355 (2023). [46] R. Sinaasappel, K. Prathyusha, H. Tuazon, E. Mirzahos-sein, P. Illien, S. Bhamla, and A. Deblais, Particle Sweep-ing and Collection by Active and Living Filaments, Phys. Rev. X 16 , 011003 (2026). [47] M. E. Cates and J. Tailleur, Motility-Induced Phase Separation, Annu. Rev. Condens. Matter Phys. 6, 219 (2015). [48] A. K. Omar, H. Row, S. A. Mallory, and J. F. Brady, Mechanical theory of nonequilibrium coexistence and motility-induced phase separation, Proc. Natl. Acad. Sci. U.S.A. 120 , e2219900120 (2023). [49] T. Speck, J. Bialk¬¥ e, A. M. Menzel, and H. L¬® owen, Effec-tive Cahn-Hilliard Equation for the Phase Separation of Active Brownian Particles, Phys. Rev. Lett. 112 , 218304 (2014). [50] J. Stenhammar, A. Tiribocchi, R. J. Allen, D. Maren-duzzo, and M. E. Cates, Continuum Theory of Phase Separation Kinetics for Active Brownian Particles, Phys. Rev. Lett. 111 , 145702 (2013). [51] Y. Fily and M. C. Marchetti, Athermal Phase Separa-tion of Self-Propelled Particles with No Alignment, Phys. Rev. Lett. 108 , 235702 (2012). [52] S. Mandal, B. Liebchen, and H. L¬® owen, Motility-Induced Temperature Difference in Coexisting Phases, Phys. Rev. Lett. 123 , 228001 (2019). [53] R. Wittmann and J. M. Brader, Active Brownian par-ticles at interfaces: An effective equilibrium approach, EPL 114 , 68004 (2016). [54] N. de Macedo Biniossek, H. L¬® owen, T. Voigtmann, and F. Smallenburg, Static structure of active Brownian hard disks, J. Phys.: Condens. Matter 30 , 074001 (2018). [55] P. Digregorio, D. Levis, A. Suma, L. F. Cugliandolo, G. Gonnella, and I. Pagonabarraga, Full Phase Diagram of Active Brownian Disks: From Melting to Motility-Induced Phase Separation, Phys. Rev. Lett. 121 , 098003 (2018). [56] C. B. Caporusso, L. F. Cugliandolo, P. Digregorio, G. Gonnella, D. Levis, and A. Suma, Dynamics of Motility-Induced Clusters: Coarsening beyond Ostwald Ripening, Phys. Rev. Lett. 131 , 068201 (2023). [57] B. Liebchen and D. Levis, Collective behavior of chiral active matter: Pattern formation and enhanced flocking, Phys. Rev. Lett. 119 , 058002 (2017). [58] L. Caprini and H. L¬® owen, Flocking without Alignment Interactions in Attractive Active Brownian Particles, Phys. Rev. Lett. 130 , 148202 (2023). [59] K. L. Kreienkamp and S. H. L. Klapp, Synchronization and exceptional points in nonreciprocal active polar mix-tures, Commun. Phys. 8, 307 (2025). [60] K. L. Kreienkamp and S. H. Klapp, Nonreciprocal Align-ment Induces Asymmetric Clustering in Active Mixtures, Phys. Rev. Lett. 133 , 258303 (2024). [61] J. Toner, The Physics of Flocking: Birth, Death, and Flight in Active Matter (Cambridge University Press, 2024). [62] J. Bialk¬¥ e, H. L¬® owen, and T. Speck, Microscopic theory for the phase separation of self-propelled repulsive disks, EPL 103 , 30008 (2013). [63] S. Das, M. Ciarchi, Z. Zhou, J. Yan, J. Zhang, and R. Alert, Flocking by Turning Away, Phys. Rev. X 14 ,7

031008 (2024). [64] S. Paul, A. Jayaram, N. Narinder, T. Speck, and C. Bechinger, Force Generation in Confined Active Flu-ids: The Role of Microstructure, Phys. Rev. Lett. 129 ,058001 (2022). [65] R. Gro√ümann, I. S. Aranson, and F. Peruani, A particle-field approach bridges phase separation and collective motion in active matter, Nat. Commun. 11 , 5365 (2020). [66] J. Dijkman, M. Dijkstra, R. van Roij, M. Welling, J.-W. van de Meent, and B. Ensing, Learning Neural Free-Energy Functionals with Pair-Correlation Match-ing, Phys. Rev. Lett. 134 , 056103 (2025). [67] F. Samm¬® uller and M. Schmidt, Determining the chemical potential via universal density functional learning (2025), arXiv:2506.15608 [cond-mat]. [68] F. Samm¬® uller, S. Hermann, D. de las Heras, and M. Schmidt, Neural functional theory for inhomogeneous fluids: Fundamentals and applications, Proc. Natl. Acad. Sci. USA 120 , e2312484120 (2023). [69] A. Simon and M. Oettel, Machine Learning ap-proaches to classical density functional theory (2024), arXiv:2406.07345 [cond-mat]. [70] S. M. Kampa, F. Samm¬® uller, M. Schmidt, and R. Evans, Metadensity Functional Theory for Classical Fluids: Ex-tracting the Pair Potential, Phys. Rev. Lett. 134 , 107301 (2025). [71] A. Poncet, O. B¬¥ enichou, V. D¬¥ emery, and D. Nishiguchi, Pair correlation of dilute active Brownian particles: From low-activity dipolar correction to high-activity algebraic depletion wings, Phys. Rev. E 103 , 012605 (2021). [72] T. F. F. Farage, P. Krinninger, and J. M. Brader, Effec-tive interactions in active Brownian suspensions, Phys. Rev. E 91 , 042310 (2015). [73] A. P. Solon, Y. Fily, A. Baskaran, M. E. Cates, Y. Kafri, M. Kardar, and J. Tailleur, Pressure is not a state func-tion for generic active fluids, Nat. Phys. 11 , 673 (2015). [74] S. Br¬® oker, M. te Vrugt, and R. Wittkowski, Collective dynamics and pair-distribution function of active Brow-nian ellipsoids in two spatial dimensions, Commun. Phys. 

7, 238 (2024). [75] A. P. Thompson, H. M. Aktulga, R. Berger, D. S. Bolin-tineanu, W. M. Brown, P. S. Crozier, P. J. in ‚Äôt Veld, A. Kohlmeyer, S. G. Moore, T. D. Nguyen, R. Shan, M. J. Stevens, J. Tranchida, C. Trott, and S. J. Plimpton, LAMMPS - a flexible simulation tool for particle-based materials modeling at the atomic, meso, and continuum scales, Comput. Phys. Commun. 271 , 108171 (2022). [76] I. Loshchilov and F. Hutter, Decoupled Weight Decay Regularization (2019), arXiv:1711.05101 [cs]. [77] M. Cranmer, Interpretable Machine Learning for Science with PySR and SymbolicRegression.jl (2023). [78] J. A. Bollinger, A. Jain, and T. M. Truskett, How Local and Average Particle Diffusivities of Inhomogeneous Flu-ids Depend on Microscopic Dynamics, J. Phys. Chem. B 

119 , 9103 (2015). [79] J. K. Percus and G. J. Yevick, Analysis of Classical Sta-tistical Mechanics by Means of Collective Coordinates, Phys. Rev. 110 , 1 (1958). [80] M. S. Wertheim, Exact Solution of the Percus-Yevick In-tegral Equation for Hard Spheres, Phys. Rev. Lett. 10 ,321 (1963). [81] M. Adda-Bedia, E. Katzav, and D. Vella, Solution of the Percus-Yevick equation for hard disks, J. Chem. Phys. 

128 , 184508 (2008). [82] M. t. Vrugt, B. Liebchen, and M. E. Cates, What exactly is ‚Äòactive matter‚Äô ? (2025), arXiv:2507.21621 [cond-mat]. [83] K. NygÀö ard, R. Kjellander, S. Sarman, S. Chodankar, E. Perret, J. Buitenhuis, and J. F. van der Veen, Anisotropic Pair Correlations and Structure Factors of Confined Hard-Sphere Fluids: An Experimental and Theoretical Study, Phys. Rev. Lett. 108 , 037802 (2012). [84] M. Fuchs and M. E. Cates, Theory of Nonlinear Rheology and Yielding of Dense Colloidal Suspensions, Phys. Rev. Lett. 89 , 248304 (2002). [85] W. T. Kranz, F. Frahsa, A. Zippelius, M. Fuchs, and M. Sperl, Rheology of Inelastic Hard Spheres at Finite Density and Shear Rate, Phys. Rev. Lett. 121 , 148002 (2018). [86] O. D‚ÄôAngelo, M. Sperl, and W. T. Kranz, Rheological Regimes in Agitated Granular Media under Shear, Phys. Rev. Lett. 134 , 148202 (2025). [87] J. Lee, D. Park, M. Lee, H. Lee, K. Park, I. Lee, and S. Ryu, Machine learning-based inverse design methods considering data characteristics and design space size in materials design and manufacturing: a review, Mater. Horiz. 10 , 5436 (2023). [88] Q. Wang and L. Zhang, Inverse design of glass struc-ture with deep graph neural networks, Nat. Commun. 

12 , 5359 (2021). [89] L. Stricker, P. M. Derlet, A. F. Demir¬® ors, H. R. Vutukuri, and J. Vermant, Unifying Atoms and Colloids near the Glass Transition through Bond-Order Topology, Phys. Rev. Lett. 132 , 218202 (2024). [90] I. Svetlizky and Y. Roichman, Spatial Crossover Between Far-From-Equilibrium and Near-Equilibrium Dynamics in Locally Driven Suspensions, Phys. Rev. Lett. 127 ,038003 (2021). [91] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cour-napeau, M. Brucher, M. Perrot, and E. Duchesnay, Scikit-learn: Machine learning in Python, Journal of Ma-chine Learning Research 12 , 2825 (2011). [92] P. J. Huber, Robust Estimation of a Location Parameter, Ann. Math. Stat. 35 , 73 (1964). [93] Y. Bengio, J. Louradour, R. Collobert, and J. Weston, Curriculum learning, in Proc. 26th Annu. Int. Conf. Mach. Learn. , ICML ‚Äô09 (Association for Computing Ma-chinery, New York, NY, USA, 2009) pp. 41‚Äì48. [94] A. M. Ikotun, A. E. Ezugwu, L. Abualigah, A. B., and H. J., K-means clustering algorithms: A comprehensive review, variants analysis, and advances in the era of big data, Inf. Sci. 622 , 178‚Äì210 (2023). [95] O. Rainio, J. Teuho, and R. Kl¬¥ en, Evaluation metrics and statistical tests for machine learning, Sci Rep 14 ,6086 (2024). 1

# Supplemental Material: Learning microstructure in active matter 

Writu Dasgupta, 1 Suvendu Mandal, 1 Aritra K. Mukhopadhyay, 1 and Benno Liebchen 1 

> 1Institute for Condensed Matter Physics, Technische Universit¬® at Darmstadt, Hochschulstra√üe 8, 64289 Darmstadt, Germany.
> DEEP LEARNING FRAMEWORK Data Preprocessing and Architecture

To predict the pair correlation function g, we employ a feed-forward deep neural network (DNN). The com-plexity of the input space varies across the three studied regimes: (i) passive Brownian particles (inputs: pack-ing fraction œÜ, distance r), (ii) isotropic active Brown-ian particles (inputs: P¬¥ eclet number Pe, œÜ, r), and (iii) anisotropic active Brownian particles (inputs: Pe, œÜ, r,relative angle Œ∏). As discussed in the main text, We generate a dataset using LAMMPS simulations [75] for œÜ ‚àà [0 .20 , 0.50] and Pe ‚àà [5 , 45]. For each ( œÜ, Pe), we extract 20 statisti-cally independent snapshots from our simulations. From these configurations, we compute g( r, Œ∏ ) with radial and angular resolution of ‚àÜ r = 0 .025 and ‚àÜ Œ∏ = 4 ‚ó¶. We nor-malize the simulation data to ensure numerical stability during training. The input features are scaled as follows: the distance r and packing fraction œÜ are used directly, as they naturally fall within sufficiently localized ranges (r/œÉ ‚àà [0 , 5], œÜ ‚àà [0 , 1]). The P¬¥ eclet number, which varies comparatively strongly (Pe ‚àà [5 , 45]), is normal-ized via Min-Max scaling [91] to the range [0 , 1]. The target variable g is log-transformed. This transformation prevents the high-magnitude values associated with the first coordination shell (where g( r) can exceed 20) from disproportionately dominating the loss function gradient and provoking instabilities. The network architecture consists of three (for pas-sive and Isotropic active Brownian system) or four (for anisotropic active Brownian system) fully connected hid-den layers, each containing 256 neurons, and utilizes ReLU (only on the input layer) and LeakyReLU (applied on the hidden layers to get rid of the vanishing gradient problem). We utilize the AdamW optimizer [76] with a learning rate of 5 √ó 10 ‚àí4 (that progressively decays in case of curriculum learning for anisotropic system) and a weight decay of 1 √ó 10 ‚àí4. Extensive hyperparameter optimization confirms that this configuration provides an excellent balance between model expressivity and gener-alization capabilities. 

> Loss Functions and Curriculum Learning

We tailor the loss function to the physical complex-ity of the system. For passive and angle-averaged active systems, we minimize the Mean Squared Error (MSE). However, the anisotropic case introduces significant non-linearity and outliers due to the explicit Œ∏-dependence. To mitigate this, we employ a Smooth L1 Loss (Huber loss [92]) function that handles those few outliers quite well without skewing the model disproportionately. To accelerate convergence and avoid local minima, we implement a curriculum learning strategy [93]. We par-tition the training data into three regimes based on ac-tivity: low activity (Pe ‚â§ 25), intermediate activity (25 < Pe ‚â§ 35), and high activity (Pe > 35) (see fig: S1). The model is trained sequentially on these subsets for 100 epochs, progressively reducing the learning rate as the complexity of the input regime increases. 

> SYMBOLIC REGRESSION IMPLEMENTATION

We utilize the PySR software package [77] to dis-cover analytical closed-form expressions that describe the DNN-generated surrogates. To ensure computational tractability, we do not train on the raw simulation data but rather on the smoothed predictions of the DNN, as specified in the following. 

> Dataset Selection and Subsampling

While the passive and isotropic active cases allow for manageable dataset sizes ( < 10 4 data points), the anisotropic case requires careful subsampling from the DNN predictions to avoid excessive computational costs. We generate a synthetic dataset covering the relevant pa-rameter space ( œÜ, Pe) with radial cutoffs extending to 3 œÉ

to capture the second coordination shell. To reduce the dataset from 10 5 to a target of 10 4

points while preserving structural details, we employ an importance-weighted subsampling strategy that priori-tizes peak regions. We subsequently apply K-means clus-tering [94] to select representative points from the sub-sampled distribution. 

> Model Configuration

The symbolic regression evolves over 2 √ó 10 4 iterations of 20 different population samples. We constrain the search space by limiting the maximum equation complex-ity to approximately 50 operations and a tree depth of 8. The operator pool includes standard algebraic functions, exponentials, and trigonometric functions, with a con-straint preventing nested calls of the same operator (e.g., 2a)  b)  c)     

> Pe < 25
> Train Train Train
> 35 < Pe < 25 Pe > 35
> Test Test Test

FIG. S1. Loss curves in curriculum learning: Training and testing (inset) loss plotted against epoch number for (a) low (Pe ‚â§ 25), (b) intermediate (25 < Pe ‚â§ 35), and (c) high activity (Pe > 35). g(r)

# r /œÉ

FIG. S2. Equilibrium radial distribution function for various packing fractions. Symbols represent the 2D Percus-Yevick (PY) solutions, while solid lines correspond to the analytical expression derived through symbolic regression Eq. (S1) for each packing fraction. 

sin(sin( x))). The optimization objective is the minimiza-tion of the MSE between the candidate expression and the DNN predictions. If the algorithm fails to converge to a satisfactory expression within the iteration limit, we utilize a ‚Äòwarm start‚Äô procedure, re-initializing the search with the parameters of the best-performing equa-tions from the previous run. 

EVALUATION METRICS 

To provide a robust assessment of model performance, we report three complementary error metrics [95] . Be-low, we evaluate all three metrics for a given set of N

simulation reference values {yi}Ni=1 and model predictions 

{ÀÜyi}Ni=1 , obtained either from the DNNs or from PySR: 1. Mean Absolute Error (MAE): 

MAE = 1

N

> N

X

> i=1

|yi ‚àí ÀÜyi|

The MAE quantifies the average magnitude of the error. It provides an intuitive measure of the typi-cal discrepancy and is less sensitive to outliers than quadratic metrics. 2. Root Mean Square Error (RMSE): 

RMSE = 

vuut 1

N

> N

X

> i=1

(yi ‚àí ÀÜyi)2

The RMSE penalizes large deviations heavily. This metric is particularly critical for assessing per-formance near the first coordination shell, where structural peaks are sharp and difficult to capture. 3. Coefficient of Determination ( R2): 

R2 = 1 ‚àí

PNi=1 (yi ‚àí ÀÜyi)2

PNi=1 (yi ‚àí ¬Øy)2

where ¬Ø y is the mean of the reference data. The R2

score measures the fraction of variance captured by the model. A value near 1 indicates that the model reproduces both the mean behavior and the struc-tural fluctuations of the pair correlation function. Taken together, these three metrics provide a compre-hensive characterization of predictive performance: MAE reflects typical absolute accuracy, RMSE highlights sen-sitivity to large localized errors, and R2 quantifies how well the overall structure and variance of the data are captured. 

PASSIVE BROWNIAN PARTICLES 

The symbolic regression yields the following closed-form expression, valid for œÜ ‚àà [0 .2, 0.5]: 3a)  b)  c)       

> FIG. S3. Evaluation metrics for the passive Brownian system. The metrics are plotted as a function of packing fraction
> œÜ.(a) Mean Absolute Error (MAE) and (b) Root Mean Square Error (RMSE) remain of order O(10 ‚àí2), indicating high accuracy. (c) The coefficient of determination R2remains near unity. Blue circles denote DNN predictions; red squares denote symbolic regression results.

g( r) = exp 

 (0 .296 œÜ)r sin( r2(œÜ + 1)) 0.141 



√ó cos 48 .933 exp  ‚àí1.568 r26 .302  . (S1) To evaluate the validity of this analytical expression, we compare it with the 2D PY solutions (see Fig. S2). The closed-form expression demonstrates good agree-ment with the 2D PY solutions. Figure S3 illustrates the performance metrics for the passive case. As expected, we find that the DNN consis-tently achieves lower prediction errors (MAE and RMSE 

‚àº O (10 ‚àí2)) compared to symbolic regression, but with a remarkably small performance gap. This gap reflects the trade-off between the high expressive capacity of the DNN and the interpretability constraint of the symbolic model. While the symbolic model is quantitatively less precise, it successfully captures the dominant structural features‚Äîspecifically the periodicity and decay of the co-ordination shells. For both models, accuracy degrades moderately as œÜ approaches 0.5. 

> ACTIVE BROWNIAN PARTICLES (ISOTROPIC)

For the angle-averaged active case, the inclusion of ac-tivity leads to the following analytical expression: g( r) = pexp [ A(r, œÜ, Pe) B(r, œÜ, Pe)] , (S2) where the auxiliary functions are given as: 

A(r, œÜ, Pe) = ‚àí1.217 r1‚àír (Pe œÜ)0.164 

+ 1.533(27 .690 ‚àí œÜ)( r‚àí29 .139 r)

r , (S3) 

B(r, œÜ, Pe) = ‚àöœÜ ‚àí 64 .653 

r24 .784 ‚àí 1.265 

r

‚àí 0.989 ‚àíPe œÜr cos( r2.223 ). (S4) Figure S4 compares the learned (DNN) model predic-tions against simulation data for varying P¬¥ eclet numbers, demonstrating that the symbolic expression captures the shift in peak heights induced by activity. We observe that errors increase systematically with both activity and density (see Fig. S5). The largest de-viations occur in the high-activity, intermediate-density regime (Pe ‚âà 35 , œÜ ‚âà 0.45), where motility-induced clus-tering creates sharp structural features that are challeng-ing for the symbolic regression to capture fully. Neverthe-less, the symbolic model retains qualitative fidelity also in this parameter regime. 

> ANISOTROPIC PAIR CORRELATION FUNCTION

The anisotropic pair correlation function g( r, Œ∏ ) rep-resents the most complex scenario, requiring the model to resolve directional symmetry breaking. The symbolic regression identifies the following functional form: g( r, Œ∏ ) = r exp 

(" 

œÜ +  3.295 ‚àí cos Œ∏ (0 .777 ‚àí œÜ)

sin 

 0.071 

r ‚àí 1.072 

#

√ó sin 

"

œÜ + Pe ‚àó + r

0.175 ‚àí

cos Œ∏ ‚àí sin   ‚àír

> 0.010



7.828 

#

‚àí 1.275 

)

+ 0 .328 . (S5) where, Pe ‚àó is the (min-max) scaled P¬¥ eclet number. To validate the physical consistency of our models, we ana-lyze cross-sections at varying angles (see Fig. S6). The front direction ( Œ∏ = 180 ‚ó¶) exhibits maximal particle ac-cumulation due to persistent self-propulsion, while the rear ( Œ∏ = 0 ‚ó¶) shows depletion. Crucially, the compari-son between the lateral directions Œ∏ = 90 ‚ó¶ and Œ∏ = 270 ‚ó¶4a)        

> g(r)
> r/œÉ
> r/œÉr/œÉ
> g(r)
> g(r)
> g(r)
> g(r)
> r/œÉ
> r/œÉr/œÉ

e) c) 

d)  f) b) 

FIG. S4. Comparison of model predictions for active Brownian particles with isotropy. The pair correlation function g( r) is plotted against normalized distance r/œÉ for Pe = 15 (a,c,e) and Pe = 45 (b,d,f) at varying packing fractions. The symbol represents simulation data, blue dashed line denotes the learned (DNN) model prediction, and red solid line represents analytical expression given by Eq. S2, derived through symbolic regression. a)  c)  e)  

> b) f) d)

FIG. S5. Performance heatmaps for the isotropic active system. Evaluation metrics are shown as a function of P¬¥ eclet number Pe and packing fraction œÜ. Panels (a, c, e) display the MAE, RMSE, and R2 for the DNN model, while (b, d, f) show the corresponding metrics for symbolic regression. Color intensity scales with the magnitude of the error. 5f)             

> œÜ=0.30
> œÜ=0.45
> Pe = 15.0
> Pe = 35.0
> r/œÉ
> r/œÉ
> g(r)g(r)
> e)
> d)
> œÜ=0.30
> œÜ=0.45
> Pe = 15.0
> Pe = 35.0
> r/œÉ
> r/œÉ
> g(r)g(r)
> c)
> b)
> œÜ=0.30
> œÜ=0.45
> Pe = 15.0
> Pe = 35.0
> r/œÉ
> r/œÉ
> g(r)g(r)
> a)

FIG. S6. Anisotropic pair correlation function cross-sections. The radial dependence of g( r, Œ∏ ) is plotted along specific angular directions: (a, b) rear Œ∏ = 0 ‚ó¶, (c, d) lateral Œ∏ = 90 ‚ó¶, and (e, f) lateral Œ∏ = 270 ‚ó¶ ; (front Œ∏ = 180 ‚ó¶ is shown in the main text). Top panels correspond to ( œÜ, Pe) = (0 .45 , 15), and bottom panels to ( œÜ, Pe) = (0 .30 , 35). Black circles: simulation; blue dashed line: DNN; red line: symbolic regression. The symmetry between 90 ‚ó¶ and 270 ‚ó¶ confirms the physical consistency of the learned models. a)  c)  e)  

> f) b) d)

FIG. S7. Performance heatmaps for the anisotropic active system. Evaluation metrics for g( r, Œ∏ ) are plotted against Pe and œÜ. Panels (a, c, e) show the DNN performance, while (b, d, f) display the symbolic regression performance. Errors are generally higher than in the isotropic case due to the complexity of directional correlations. 6demonstrates that both the DNN and the symbolic equa-tion respect the mirror symmetry of the system. The evaluation metrics indicate that while error mag-nitudes are higher than in the isotropic cases, the DNN maintains high accuracy (Fig. S7). The symbolic regres-sion captures the essential angular modulation and the dominant radial structure, offering a tractable analyti-cal approximation for the highly non-linear anisotropic microstructure.