Title: Symbolically regressing dark matter halo profiles using weak lensing

URL Source: https://arxiv.org/pdf/2601.05203v1

Published Time: Fri, 09 Jan 2026 02:22:30 GMT

Number of Pages: 21

Markdown Content:
> MNRAS 000 , 1â€“21 (2026) Preprint 9 January 2026 Compiled using MNRAS L ATEX style file v3.2

# Symbolically regressing dark matter halo profiles using weak lensing 

# Alicia MartÃ­n, 1â˜… Tariq Yasin, 1 Deaglan J. Bartlett, 1,2 Harry Desmond 3 and Pedro G. Ferreira 1

> 1Astrophysics, University of Oxford, Oxford, OX1 3RH, United Kingdom
> 2CNRS & Sorbonne UniversitÃ©, Institut dâ€™Astrophysique de Paris (IAP), UMR 7095, 98 bis bd Arago, F-75014 Paris, France
> 3Institute of Cosmology & Gravitation, University of Portsmouth, Portsmouth, PO1 3FX, United Kingdom
> Accepted XXX. Received YYY; in original form ZZZ

ABSTRACT 

The structure of dark matter haloes is often described by radial density profiles motivated by cosmological simulations. These are typically assumed to have a fixed functional form (e.g. NFW), with some free parameters that can be constrained with observations. However, relying on simulations has the disadvantage that the resulting profiles depend on the dark matter model and the baryonic physics implementation, which are highly uncertain. Instead, we present a method to constrain halo density profiles directly from observations. This is done using a symbolic regression algorithm called Exhaustive Symbolic Regression (ESR). ESR searches for the optimal analytic expression to fit data, combining both accuracy and simplicity. We apply ESR to a sample of 149 galaxy clusters from the HSC-XXL survey to identify which functional forms perform best across the entire sample of clusters. We identify density profiles that statistically outperform NFW under a minimum-description-length criterion. Within the radial range probed by the weak-lensing data ( ğ‘… âˆ¼ 0.3 âˆ’ 3 hâˆ’1 Mpc), the highest-ranked ESR profiles exhibit shallow inner behaviour and a maximum in the density profile. However, the inner slope itself remains weakly constrained due to limited signal at small radii. As a practical application, we show how the best-fitting ESR models can be used to obtain enclosed mass estimates. We find masses that are, on average, higher than those derived using NFW, highlighting a source of potential bias when assuming the wrong density profile. These results have important knock-on effects for analyses that utilise clusters, for example cosmological constraints on ğœ 8 and Î©m from cluster abundance and clustering. Beyond the HSC dataset, the method is readily applicable to any data constraining the dark matter distribution in galaxies and galaxy clusters, such as other weak lensing surveys, galactic rotation curves, or complementary probes. 

Key words: methods: data analysis â€“ gravitational lensing: weak â€“ dark matter 

1 INTRODUCTION 

In the Î›CDM picture, structure grows hierarchically. Small primor-dial fluctuations are amplified by gravity, first forming small haloes and then, through accretion and mergers, building ever larger systems that eventually virialise. At the top of this hierarchy sit galaxy clus-ters. They are the most massive bound objects in the Universe and are strongly dark-matter dominated (Allen et al. 2011). As such, they are natural laboratories for testing the properties of dark matter and, more broadly, for probing possible departures from standard gravity (Kravtsov & Borgani 2012). Consequently, clusters are powerful cosmological probes. Their abundance, when combined with robust mass calibration, places tight constraints on parameters such as the matter density, Î©m, and the am-plitude of fluctuations, ğœ 8 (Vikhlinin et al. 2009; Abbott et al. 2020). Beyond abundance statistics, their internal mass profiles encode their specific assembly histories. These imprints are visible in structural features like the splashback radius (Diemer & Kravtsov 2014; More et al. 2015) and in the scaling relations that connect baryons to the total gravitational field (Chan & DelPopolo 2020; Tian et al. 2020, 2024; Mistele et al. 2025). Therefore, characterising the density pro- 

> â˜…E-mail: alicia.martin@physics.ox.ac.uk

files of clusters informs both the astrophysics of structure formation and the underlying cosmological model. For decades, large-volume cosmological simulations have been the primary tool for studying the structure of dark matter haloes. Early 

ğ‘ -body simulations consistently showed that haloes exhibit a steep power-law increase in density toward the centre, known as a â€œcuspâ€ (Dubinski & Carlberg 1991; Navarro et al. 1997). This initial finding appeared to be universal across different simulations and consistent over a wide range of halo masses, concentrations, and cosmological models, and was captured by the Navarro-Frenk-White (NFW) profile (Navarro et al. 1997) 

ğœŒ (ğ‘Ÿ ) = ğœŒ 0

ğ‘Ÿ /ğ‘Ÿ ğ‘  (1 + ğ‘Ÿ /ğ‘Ÿ ğ‘  )2 , (1) where ğœŒ 0 is a characteristic density and ğ‘Ÿ ğ‘  a scale radius. The NFW profile follows a double power law that transitions from ğœŒ (ğ‘Ÿ ) âˆ ğ‘Ÿ âˆ’1

at small radii to ğœŒ (ğ‘Ÿ ) âˆ ğ‘Ÿ âˆ’3 at large radii. However, the notion of a universal NFW profile was challenged by later, higher-resolution dark matter-only simulations, which revealed more diversity in inner density slopes. For example, the Aquarius (Navarro et al. 2004) and Via Lactea II (Diemand et al. 2007) simu-lations found that the logarithmic slope becomes progressively shal-lower than âˆ’1 toward the centre. In contrast, Moore et al. (1998) reported a steeper inner slope of ğœŒ (ğ‘Ÿ ) âˆ¼ ğ‘Ÿ âˆ’1.4. More recent high- 

> Â©2026 The Authors
> arXiv:2601.05203v1 [astro-ph.CO] 8 Jan 2026

# 2 A. MartÃ­n et al. 

resolution simulations appear to support this steeper behaviour, find-ing ğœŒ (ğ‘Ÿ ) âˆ¼ ğ‘Ÿ âˆ’1.5 (Delos et al. 2019; Delos 2025), which they refer to as a â€œprompt cuspâ€. This wider class of generalised NFW models suggests that factors such as numerical convergence, initial condi-tions or analysis techniques may still influence the inferred inner slope. This disagreement has also motivated the development of alterna-tive, more flexible density models. In particular, the Einasto profile (Einasto 1965), which assumes a power-law form for the logarithmic density slope ( d ln ğœŒ /d ln ğ‘Ÿ âˆ ğ‘Ÿ ğ›¼ ) rather than for the density itself, was advocated by Navarro et al. (2004) and Merritt et al. (2005). Us-ing high-resolution ğ‘ -body simulations these works and subsequent studies (Merritt et al. 2006; Gao et al. 2008; Navarro et al. 2010; Ludlow et al. 2013) showed that the Einasto model provides a better fit to halo density profiles than NFW, especially in the inner regions. Beyond collisionless dynamics, hydrodynamical simulations fur-ther broaden the possibilities: gas cooling and the assembly of the brightest cluster galaxy (BCG) can contract the dark matter and steepen inner slopes (Blumenthal et al. 1986; Laporte et al. 2012), whereas energetic feedback from active galactic nuclei can counteract or even flatten the central profile (Martizzi et al. 2013a; Peirani et al. 2017). These processes occur on scales close to current resolution limits and are modelled with subgrid prescriptions, so inferred inner slopes can depend on both numerical set-ups and baryonic physics choices (Crain et al. 2015; Sorini et al. 2025). Another limitation of simulation-based profiles is that they are phenomenological: they are simple, low-parameter functions cali-brated to match the output of collisionless ğ‘ -body simulations, rather than solutions derived from a fundamental theory. In recent years, however, progress has been made towards a first-principles under-standing. For example, Pontzen & Governato (2013) developed an analytical framework to study the phase space distribution of cold dark matter particles based on entropy considerations. Their frame-work reproduces the shallower inner cusp and steep outer decline, in qualitative agreement with simulated haloes. More recently, Banik & Bhattacharjee (2025) showed that the NFW profile might emerge as an attractor solution to a self-consistent theory for collisionless relaxation. While these works offer some insight on why such pro-files might appear in cold dark matter simulations, their theoretical motivation is still incomplete. More significantly, observational data often challenge the uni-versality of the NFW profile, particularly regarding its cuspy inner structure. On galactic scales, observations of dwarf and low-surface-brightness galaxies suggest a flatter inner density shape, even reach-ing a constant density region known as a â€œcoreâ€ (Flores & Primack 1994; Moore 1994; de Blok et al. 2001). On cluster scales, the pic-ture is more complex. While stacked lensing generally favours cuspy profiles in the 0.1â€“2 Mpc regime (Umetsu et al. 2016), detailed anal-yses combining strong lensing with stellar kinematics sometimes prefer shallower slopes within the inner 10 â€“50 kpc (Sand et al. 2002; Newman et al. 2011). Interpreting these potential tensions is difficult. They may arise from observational systematics within the standard Î›CDM frame-work, such as triaxiality, miscentering, or non-thermal pressure sup-port (Corless & King 2007; Johnston et al. 2007a; Lau et al. 2009). Alternatively, they may point to new physics. For example, allowing for self-interacting dark matter (SIDM) can naturally produce core-like profiles that deviate from the standard collisionless prediction (Spergel & Steinhardt 2000; Rocha et al. 2013; Ragagnin et al. 2024; Zeng et al. 2025). These uncertainties highlight the risks of imposing fixed density templates on observational data. When a single parametric form is as-sumed, any deviation in the underlying density profile can propagate directly into biased mass or concentration estimates. For example, in cluster mass calibration, forcing an NFW profile onto a halo that has been modified by baryonic feedback or is in a non-equilibrium state can skew the inferred total mass. Such model-dependent systematics are a leading explanation for the tension between cluster weak-lensing masses and those inferred from Planck CMB observations (von der Linden et al. 2014b; Hoekstra et al. 2015; Blanchard & IliÄ‡ 2021). These issues emphasise the need for approaches that allow the data to determine the form of the density profile. To address this, we propose a data-driven alternative: deriving density profiles directly from observations using Symbolic Regres-sion (SR; see Kronberger et al. 2024a, for a recent review). SR is a supervised machine learning method which tries to find the best analytical function to describe a given dataset. It searches the math-ematical space of functions, fitting them to the data to identify the most accurate models. Importantly, it balances accuracy with sim-plicity, helping to avoid over-fitting and returning functions that are both interpretable and generalisable. In particular, we use a novel SR algorithm called Exhaustive Sym-bolic Regression (hereafter ESR; Bartlett et al. 2024). Unlike other heuristic or evolutionary approaches, ESR explores all possible math-ematical models up to a specified functional complexity (defined to be equal to the number of nodes in the tree representation of a func-tion), ensuring that the best model to describe the data is always evaluated provided it is within that complexity limit. ESR combines simplicity and accuracy by using the Minimum Description Length (MDL) principle, which ranks functions according to the number of bits of information required to encode the data with the help of the function. In MartÃ­n et al. 2025, we tested the approach on mock weak lensing excess surface density (ESD) data of synthetic clusters with NFW profiles. Motivated by real data, we assigned each ESD data point a constant fractional uncertainty and varied this uncertainty and the number of clusters to probe how data precision and sample size affect model selection. For fractional errors around 5 per cent, we showed that ESR recovers the NFW profile even for a low number of samples. At higher uncertainties representative of current surveys, simpler functions are favoured over NFW, although NFW typically remains within the top âˆ¼ 10 models. In this paper, we extend this analysis to real observations by apply-ing ESR to stacked weak lensing (WL) measurements from a sample of 149 galaxy clusters observed by the Hyper Suprime-Cam (HSC) survey (Adami et al. 2018). Our goal is to find the analytical profiles that best reproduce the ESDs of this cluster sample and test whether NFW remains among the highest-ranked profiles, or whether the ob-servational data favour alternative functional forms. We can further use the ESR-derived profiles to estimate properties of the clusters, such as the enclosed mass. By averaging over all plausible models, this mass estimate is insensitive to profile assumptions and therefore more robust than those obtained from traditional NFW fitting, which in general have an unknown systematic errors associated with the fixed profile. While this work focuses on clusters, the methodology is readily applicable to the full range of data constraining the dark matter distribution around galaxies, groups, and clusters, as well as many other astrophysical observables. The paper is structured as follows. In Section 2, we give a de-scription of the WL shear data used in this study and the calculation of ESD profiles from it. Section 3 summarises the ESR algorithm, while Section 4 describes how to use ESR to model the ESD profiles and the specific settings used to optimise parameters and estimate  

> MNRAS 000 , 1â€“21 (2026)

# Symbolically regressing dark matter halo profiles using weak lensing 3

their uncertainties. The results are presented in Section 5, followed by the discussion in Section 6 and conclusion in Section 7. Throughout this paper, we assume a spatially flat Î›CDM cosmol-ogy with Î©m = 0.28 , Î©Î› = 0.72 and a value of the Hubble constant of ğ» 0 = 100 â„ km s âˆ’1 Mpc âˆ’1 with â„ = 0.7 following the HSC Ã—XXL weak-lensing analysis (Umetsu 2020a). We use log to denote the natural logarithm. 

2 WEAK LENSING DATA 2.1 Cluster and Lensing Catalogues 

In this work, we largely follow the cluster selection and WL data processing of Umetsu et al. (2020). Our analysis is based on a sample of X-ray selected galaxy groups and clusters from the XMM-XXL survey. We use spectroscopically confirmed systems from the XXL DR2 catalogue presented in Adami et al. (2018); Mandelbaum et al. (2018a); Medezinski et al. (2018). WL measurements for these systems are sourced from the first-year data release of the Hyper Suprime-Cam (HSC) Subaru Strategic Pro-gram survey (HSC-SSP; Aihara et al. 2018). The HSC-SSP survey provides deep optical imaging in five broad bands ( ğ‘”ğ‘Ÿğ‘–ğ‘§ğ‘¦ ). Galaxy shape measurements for this catalogue were derived from the co-added ğ‘– -band images using the re-Gaussianisation method (Hirata & Seljak 2003). This ğ‘– -band imaging was performed under exceptional seeing conditions (median FWHM â‰ƒ 0.6â€²â€² ). We use the shear cata-logue produced for the â€œArcturusâ€ field, which covers 137 deg 2 over 

6 sky patches. After masking bright stars and other artefacts, this area is reduced to 29 .5 deg 2.We select XXL clusters that fall within the HSC-SSP footprint, resulting in a total overlapping sky area of 21 .4 deg 2. Following the criteria in Mandelbaum et al. (2018b), which requires clusters to be within a comoving separation of ğ‘… min = 0.3 â„âˆ’1 Mpc of the lensing data, our final sample consists of 149 spectroscopically confirmed XXL clusters. The background source galaxies in this matched field have a weighted number density of âˆ¼ 22 .1 galaxies arcmin âˆ’2 and a mean redshift of 0.82 (Miyatake et al. 2019). 

2.2 Shear-to-ESD estimator 

Weak gravitational lensing induces coherent distortions in the shapes of background galaxies as a result of the deflection of light by fore-ground mass. This effect is sensitive to both baryonic and dark matter and gives a direct probe of the projected mass distribution of a lens. The shape distortion is quantified by the shear, ğ›¾ , which can be decomposed into the tangential component ğ›¾ + and the 45 â—¦-rotated component ğ›¾ Ã— . The tangential shear ğ›¾ + is directly related to the az-imuthally averaged surface mass density Î£(ğ‘… ) through (Bartelmann & Schneider 2001) 

ğ›¾ + = âŸ¨Î£(< ğ‘… )âŸ© âˆ’ Î£(ğ‘… )

Î£cr 

â‰¡ Î”Î£ (ğ‘… )

Î£cr 

, (2) where ğ‘… is the projected radius from the lens centre, Î”Î£ (ğ‘… ) is the ESD and âŸ¨Î£(< ğ‘… )âŸ© is the average surface density within ğ‘… , given by 

âŸ¨Î£(< ğ‘… )âŸ© = 2

ğ‘… 2

âˆ« ğ‘… 

> 0

Î£(ğ‘… â€²)ğ‘… â€²dğ‘… â€² . (3) The critical surface density Î£cr is 

Î£cr = ğ‘ 2

4ğœ‹ğº ğ· A (ğ‘§ ğ‘  )(1 + ğ‘§ l)2 ğ· A (ğ‘§ l)ğ· ğ´ (ğ‘§ l, ğ‘§ s) , (4) where ğ‘ is the speed of light, ğº is the gravitational constant, ğ‘§ l is the lens redshift, ğ‘§ s is the source redshift, and ğ· A is the angular diameter distance. The factor (1 + ğ‘§ l)2 converts to comoving surface mass density. To estimate the ESD, we stack the WL signals of background galaxies centred on the X-ray peak position of each cluster. The ESD, 

Î”Î£ (ğ‘… ), is then measured as a function of comoving cluster-centric radius ğ‘… , using ğ‘ = 9 radial bins of equal logarithmic spacing from 

ğ‘… min = 0.3 â„âˆ’1 Mpc to ğ‘… max = 3 â„âˆ’1 Mpc (Medezinski et al. 2018; Miyatake et al. 2019). The ensemble ESD estimator for a radial bin ğ‘– is given by 

Î”Î£ (ğ‘… ğ‘– ) = 12R ( ğ‘… ğ‘– )

Ãğ‘™,ğ‘  âˆˆğ‘– ğ‘¤ ğ‘™ğ‘  ğ‘’ +,ğ‘™ğ‘  [âŸ¨ Î£cr ,ğ‘™ğ‘  âŸ©] âˆ’1

[1 + ğ¾ (ğ‘… ğ‘– )] Ãğ‘™,ğ‘  âˆˆğ‘– ğ‘¤ ğ‘™ğ‘  

, (5) where the sum is taken over all lens-source pairs ( ğ‘™, ğ‘  ) where the source galaxy ğ‘  lies within the ğ‘– -th radial bin relative to the lens ğ‘™ .Here, ğ‘’ +,ğ‘™ğ‘  is the tangential ellipticity of the source galaxy. The term âŸ¨Î£cr ,ğ‘™ğ‘  âŸ©âˆ’1 is the lensing strength for each lens-source pair, computed by averaging over the full photometric redshift (photo-z) probability distribution function (PDF) of the source galaxy, ğ‘ƒ ğ‘  (ğ‘§ ).The statistical weight, ğ‘¤ ğ‘™ğ‘  , is defined as: 

ğ‘¤ ğ‘™ğ‘  = (âŸ¨ Î£âˆ’1 

> ğ‘ğ‘Ÿ ,ğ‘™ğ‘ 

âŸ©) 2 1

ğœ 2 

> ğ‘’,ğ‘ 

+ ğ‘’ 2rms ,ğ‘  

, (6) where ğœ ğ‘’,ğ‘  is the shape measurement uncertainty and ğ‘’ rms ,ğ‘  is the root mean squared ellipticity (or shape noise) per component. This estimator incorporates corrections for two systematic effects: multiplicative bias and shear responsivity. The multiplicative correc-tion factor, denoted as 1+ğ¾ , compensates for any systematic under- or over-estimation of the shear magnitude. This bias arises mainly from imperfect modelling of the point-spread function (PSF) and other measurement effects (Kaiser et al. 1995). In HSC, it is mitigated using a Gaussianiation technique (Mandelbaum et al. 2018a), but a small residual bias remains. For an ensemble of galaxies, this residual is incorporated through a scale-dependent correction factor (Murray et al. 2022): 

1 + ğ¾ (ğ‘… ğ‘– ) =

Ãğ‘™,ğ‘  âˆˆğ‘– ğ‘¤ ğ‘™ğ‘  (1 + ğ‘š ğ‘  )

Ãğ‘™,ğ‘  âˆˆğ‘– ğ‘¤ ğ‘™ğ‘  

, (7) where ğ‘š ğ‘  is the multiplicative bias factor for an individual source galaxy ğ‘  and ğ¾ is the weighted average of this multiplicative bias for the ensemble. The second correction accounts for the shear responsivity, R. This term corrects for the fact that galaxy ellipticities are a noisy proxy for the true gravitational shear. It is calculated for each radial bin ğ‘… ğ‘– 

as: 

R ( ğ‘… ğ‘– ) = 1 âˆ’

Ãğ‘™,ğ‘  âˆˆğ‘– ğ‘¤ ğ‘™ğ‘  ğ‘’ 2

> rms, s

Ãğ‘™,ğ‘  âˆˆğ‘– ğ‘¤ ğ‘™ğ‘  

. (8) Typically, a value of R â‰ˆ 0.84 is used to account for this in HSC WL analyses (Medezinski et al. 2018). The statistical precision of these measurements is set by the co-variance of the binned shear profile, which generally receives three contributions (Gruen et al. 2015; Umetsu et al. 2016): 

C = Cshape + Clss + Cint . (9) Here, Cshape represents the diagonal covariance due to statistical shape noise. The variance in bin ğ‘– is given by (Miyaoka et al. 2018) 

ğœ 2 

> shape

(ğ‘… ğ‘– ) = 14R2 (ğ‘… ğ‘– )

1

[1 + ğ¾ (ğ‘… ğ‘– )] 2 Ãğ‘– ğ‘¤ ğ‘– 

. (10)  

> MNRAS 000 , 1â€“21 (2026)

# 4 A. MartÃ­n et al. 

The dominant term in this expression is the total weight of source galaxies in the bin, Ãğ‘– ğ‘¤ ğ‘– . This sum is roughly proportional to the number of galaxies in the bin, ğ‘ gal (ğ‘… ğ‘– ). For logarithmic radial bins, the area of each annulus ğ´ ğ‘– scales with radius. Assuming a uniform distribution of background sources, the number of galaxies per bin scales with the area of that bin, ğ‘ gal (ğ‘… ğ‘– ) âˆ ğ´ ğ‘– âˆ ğ‘… 2 

> ğ‘–

. The shape noise variance in Eq. (10) is therefore ğœ 2 

> shape

âˆ 1/ğ‘ gal âˆ 1/ğ‘… 2 

> ğ‘–

. This means the uncertainty (standard deviation) has a radial dependence of: 

ğœ shape (ğ‘… ğ‘– ) âˆ 1âˆšï¸ 

ğ‘ gal (ğ‘… ğ‘– ) âˆ 1

ğ‘… ğ‘– 

. (11) This 1/ğ‘… trend is a key feature of the data: the innermost bins have the largest uncertainties, while the outermost bins are the most precisely measured. The additional terms, Clss and Cint , represent the contribution from uncorrelated large-scale structure along the line of sight (Hoek-stra 2003), and the intrinsic variations in the lensing signal at fixed halo mass, arising from scatter in concentration, halo triaxiality, and correlated structures (Gruen et al. 2015). Their relative importance depends on the scales probed. As found in Miyatake et al. (2019), the total uncertainty per cluster is dominated by the shape noise at 

ğ‘… â‰² 3 â„âˆ’1 Mpc, beyond which the contribution from Clss becomes more important. The contribution from Cint matters most in the clus-ter core (Miyatake et al. 2019) but remains subdominant at all radii for our weak-lensing measurements. Since our analysis focuses on the regime where the error is shape-noise dominated, as shown in Umetsu (2020a), we restrict the covariance treatment to the Cshape 

component. This approximation captures the leading contribution to the statistical uncertainty without significantly biasing the results. We further discuss the validity of this assumption in Section 6.3.2. We show the signal-to-noise ratio (SNR) distribution for the HSC-XXL cluster sample in Fig. 1, as well as examples of the measured ESD for a high-, medium- and low-SNR cluster. The SNR is defined as SNR = âŸ¨ğ‘‘ âŸ©/ ğœ âŸ¨ğ‘‘ âŸ© with 

âŸ¨ğ‘‘ âŸ© =

Ãğ‘ ğ‘– =1 Î”Î£ + (ğ‘… ğ‘– )/ ğœ 2 

> shape

(ğ‘… ğ‘– )

Ã ğ‘– = 1ğ‘ 1/ğœ 2 

> shape

(ğ‘… ğ‘– ) , (12) 

ğœ âŸ¨ğ‘‘ âŸ© = 1âˆšï¸ƒ Ãğ‘ ğ‘– =1 1/ğœ 2 

> shape

(ğ‘… ğ‘– )

. (13) We follow Umetsu et al. (2016) in choosing this linear definition over the commonly used quadratic signal-to-noise ratio SNR ğ‘ â‰¡[Ã(Î”Î£ ğ‘– /ğœ shape ,ğ‘– )2]1/2, as the quadratic form is always positive and therefore tends to yield spuriously high values when the measurement is noise-dominated. Our chosen linear estimator is a weighted average and can therefore take negative or positive signs. It retains the sign of the measured ESD, so SNR < 0 flags objects with an overall negative 

Î”Î£ .

3 EXHAUSTIVE SYMBOLIC REGRESSION 

Symbolic Regression (SR) is a machine-learning approach designed to find mathematical expressions to fit a given dataset. Unlike con-ventional regression, which relies on optimising parameters for a pre-defined expression, SR tries to uncover both the structure of the model and its parameters directly from the data. The aim is to find functions that accurately fit the data, but are also easy to interpret and generalise, giving some insight into the physical processes that gen-erated the data (Koza 1992; Schmidt & Lipson 2009); see Kronberger et al. (2024a) for a recent review. To do this, SR begins by selecting a set of mathematical operators (e.g. ğ‘¥ , +, âˆ’, Ã—, sin , exp , log ) and combines them to generate candidate expressions. We define the complexity of an equation as the number of operators, parameters and variables it contains. Each candidate is then evaluated against the data and ranked according to a likelihood or loss function. In recent years, a variety of SR algorithms have been developed. The most common approach is based on genetic programming (Tur-ing 1950; Goldberg 1994; Cranmer 2020), in which simpler expres-sions that perform well are mutated or combined to create more complex candidates. These methods attempt to optimise the search process by avoiding trying sub-optimal solutions. Other approaches to SR include physics-motivated algorithms that exploit symmetries in the data (Udrescu & Tegmark 2020; RenÃ© BrolÃ¸s et al. 2021; Keren et al. 2023), as well as methods that incorporate neural networks to guide the search for optimal equations (Petersen et al. 2019; Kim et al. 2020; Valipour et al. 2021). However, these machine learning methods are not infalli-ble (La Cava et al. 2021; Bartlett et al. 2024; Kronberger et al. 2024b). Since they do not explore the entire space of possible func-tions, but rather focus on subsets deemed optimal, there is always a risk that the best solution may be missed. This uncertainty makes it difficult to assess the robustness of results obtained through SR. To address this, a new algorithm called Exhaustive Symbolic Re-gression (ESR) was developed 1 (Bartlett et al. 2024). Given a basic set of operators, ESR systematically considers every possible com-bination of operators that generate functions of a given complexity. This brute-force method is currently the only algorithm capable of guaranteeing that the optimal solution is found (within a given max-imum complexity), since it considers all possible options within the allowed space. As such, it is particularly useful for solving simple problems where the best models are of low complexity (Desmond et al. 2023; Sousa et al. 2024). At higher complexity, as the number of equations increases, ESR becomes more computationally expen-sive, but it can still serve as a good starting point for other stochastic methods. ESR is described in detail in Bartlett et al. (2024); here, we outline its main stages. First, it generates candidate models and optimises their free parameters according to a likelihood function. Second, it ranks these models using an information-theory-based metric called the Minimum Description Length (MDL). 

3.1 Generating functions 

To generate mathematical expressions, ESR begins by defining a basic set of operators. We consider three different types of operators: binary (e.g. +, Ã—), unary (e.g. exp , log ) and nullary (parameters and variables). By representing these operators as nodes, functions can be visualised as trees (Petersen et al. 2019). The complexity of a function, previously defined as the number of operators and parameters, corresponds also to the number of nodes required to express an equation. Given a chosen level of complexity, ESR generates all possible trees with that number of nodes. It then populates the trees with all combinations of operators from the operator set, ensuring that connections follow the rules for binary, unary, and nullary operators. In ESR, the choice of complexity and the operator set are the only degrees of freedom. In this project, we use the following operator   

> 1https://github.com/deaglanbartlett/esr
> MNRAS 000 , 1â€“21 (2026)

# Symbolically regressing dark matter halo profiles using weak lensing 5             

> Figure 1. Example weak-lensing ESD measurements for three clusters spanning the range of SNRs in the XXLâ€“HSC sample. The first three panels show clusters with low (Cluster XLSSC 77 , SNR =âˆ’0.1), medium (Cluster XLSSC 101 , SNR =3.4), and high (Cluster XLSSC 91 , SNR =7.4) weak-lensing SNRs. Points denote the measured ESD ( Î”Î£ ) with associated shape-noise uncertainties and the blue dashed marks Î”Î£ = 0. The fourth panel shows the distribution of weak-lensing SNR for all clusters in the sample. The median SNR is 1.25 .

set: 

{ğ‘¥, ğ‘, inv , exp , log , +, Ã—, âˆ’, /, power }, (14) where inv (ğ‘¥ ) â‰¡ 1/ğ‘¥ , and power (ğ‘, ğ‘ ) â‰¡ ğ‘ ğ‘ .Once all possible trees are generated, the next step is to simplify the expressions and remove duplicates. Many expressions can be mathematically equivalent (for example, log (ğ‘ğ‘¥ ) = log (ğ‘ ) + log (ğ‘¥ )

for ğ‘, ğ‘¥ > 0), so eliminating duplicates ensures that each candidate function is unique and avoids redundant computation. We then op-timise parameters of the surviving candidate functions to find their maximum-likelihood values on the dataset in question. The method to achieve this is described in more detail in Section 4.2. The number of possible functions grows rapidly with increasing complexity, so in practice there is a limit to how complex the expres-sions can be. In our case, we consider functions up to and including complexity 10 , corresponding to a total of 134239 unique candidate expressions. 

3.2 Ranking functions 

Once a list of all possible mathematical models has been generated and fitted to the data, we require an appropriate metric to rank func-tions based on the quality of the fit. The simplest option is to rank functions according to the likelihood they give the data, L, which quantifies how accurately they reproduce the data. However, using just the likelihood is prone to overfitting: more complex functions tend to describe the data better but are more difficult to extrapolate to other datasets. Plotting each function on a complexity-likelihood plane, the functions that achieve the highest likelihood at each complexity form what is known as the Pareto front .These functions are referred to as Pareto optimal . The Pareto front defines a set of optimal trade-offs but it does not provide a principled way of choosing one function over another within that set. To obtain a one-dimensional ordering of the models, we need a metric that maximises the likelihood while penalising complex hypotheses. In ESR, this is done by using the Minimum Description Length 

principle (MDL, Rissanen 1978; GrÃ¼nwald 2007; GrÃ¼nwald & Roos 2019). MDL states that the best mathematical description of a dataset is the one that compresses the information the most, i.e. the function requiring the fewest units of information to encode both the model and the data. This is represented by the total Description Length ,

ğ¿ (ğ· ) = ğ¿ (ğ· |ğ» ) + ğ¿ (ğ» ), which consists of two terms: (i) ğ¿ (ğ· |ğ» ) measures how accurately the hypothesis ğ» fits the data ğ· . It describes the residuals of the data around the functionâ€™s expectation. This is related to the likelihood L via ğ¿ (ğ· |ğ» ) = âˆ’ log L

under a Shannonâ€“Fano coding scheme (Cover 1999). (ii) ğ¿ (ğ» ) accounts for the complexity of the hypothesis ğ» , pe-nalising models with more operators and free parameters, especially those that have to be specified to high precision. Together, these terms ensure that overly simple functions (with low ğ¿ (ğ» )) are penalised for poor accuracy, while overly complex functions (with potentially low ğ¿ (ğ· |ğ» )) are discouraged to prevent overfitting. The full expression for ğ¿ (ğ· ) relevant for SR is derived in Bartlett et al. (2024) and is given by 

ğ¿ (ğ· ) = ğ¿ (ğ· |ğ» ) + ğ¿ (ğ» )

= âˆ’ log L( Ë†ğœƒ ) + ğ‘˜ log (ğ‘› ) + ğ‘ log (2) + 

> ğ‘

âˆ‘ï¸ 

> ğ‘–

log (| Ë†ğœƒ ğ‘– |/ Î”ğ‘– )+âˆ‘ï¸ 

> ğ‘—

log (ğ‘ ğ‘— ),

(15) where ğ‘˜ is the number of nodes to represent the function, ğ‘› is the number of unique operators, ğ‘ is the number of free parameters, 1/Î”ğ‘– 

is the precision with which parameter ğ‘– is specified and ğ‘ ğ‘— are constant natural numbers appearing in the function simplification process. The hat notation indicates evaluation at the maximum likelihood point and we denote the ğ‘ free parameters of the function as {ğœƒ ğ‘– }. Eq. (15) can be interpreted as an approximation to the Bayesian evidence under a certain choice of parameter prior and function prior (Bartlett et al. 2023). In the MDL metric, the balance between accuracy and simplicity depends on the strength of the data. With more data and greater preci-sion, the likelihood term becomes more important than the complex-ity term. This means that with stronger data, the need for precision outweighs the penalty for complexity.  

> MNRAS 000 , 1â€“21 (2026)

# 6 A. MartÃ­n et al. 

3.3 Priors on functions 

The functions generated by ESR are purely mathematical expres-sions, without any inherent physical motivation. As a result, many of these functions exhibit structures that we do not often see in physical laws. For example, an expression such as ğ‘¥ ğ‘¥ ğ‘¥ 

is fairly simple accord-ing to Eq. (15) and appears in the set of equations generated by ESR, but is unlikely to be relevant in most physics scenarios. To guide ESR toward physically meaningful expressions, we can introduce a prior that encodes domain-specific knowledge about the types of equations typically encountered in physics. We achieve this by training a language model on a dataset of equations, allowing it to learn patterns and up-weight functions containing combinations of operators that are common in the dataset and hence more likely to be theoretically plausible. In particular, we use a Katz back-off model 2 (Katz 2003; Bartlett et al. 2023). This is a probabilistic method originally developed in natural language processing to estimate the likelihood of word sequences. In our context, we instead use it to assign probabilities to sequences of mathematical operators based on their occurrence in a training corpus of equations. To do this, the Katz model breaks down each candidate equation into ğ‘› -grams: sequences of ğ‘› consecutive operators. It then examines how often each ğ‘› -gram appears in the training set of equations. If a sequence appears frequently in the set, it is assigned a high probability. However, when an operator sequence is not found, the model â€œbacks offâ€ to a shorter ğ‘› -gram until a match is achieved. This approach ensures that even expressions not explicitly present in the training set receive a non-zero probability, based on the frequency of occurrence of their components in the training set. For full details on the method see Bartlett et al. (2023). By incorporating the Katz back-off model into ESR, we modify the MDL metric. Without the back-off model, the MDL contains the structural complexity term ğ‘˜ log ğ‘› , which can be interpreted as a prior on the function that favours functions with fewer operators and distinct types of operator. This is combined with (an approximation to) the Bayesian evidence to achieve the total probability of the function (the negative logarithm of which is given by Eq. (15)). When the Katz model is included, this prior is replaced with âˆ’ log Î , where 

Î  is the probability assigned to the function by the Katz model. This corresponds to assigning a shorter codelength to functions that are more common in the training corpus. In this way, the model favours equations that not only fit the data well but are also structurally consistent with functions that have found utility in physics. Here, we study ğ‘› -grams up to ğ‘› = 10 , corresponding to the high-est complexity considered for the functions. The corpus of equations we used for training the Katz model is taken from Bartlett et al. (2023). It includes the equations in the Feynman Symbolic Regres-sion Database (Udrescu & Tegmark 2020), which were selected from the Feynman Lectures on Physics (Feynman 1963), and a selection of 41 equations taken from pages linked to Wikipediaâ€™s â€œList of scientific equations named after peopleâ€ (GuimerÃ  et al. 2020).   

> 2We use the implementation designed for SR given at https://github. com/deaglanbartlett/katz .

4 METHODS 4.1 Modeling the ESD from 3D Mass Profiles 

To interpret the measured ESD in terms of the underlying matter distribution, we must connect Î”Î£ (ğ‘… ) to the three-dimensional mass density, ğœŒ (ğ‘Ÿ ).This can be done by projecting the density profile, ğœŒ (ğ‘Ÿ ), along the line of sight, ğ‘§ , to obtain the two-dimensional surface mass density, 

Î£(ğ‘… ):

Î£(ğ‘… ) =

âˆ« âˆâˆ’âˆ 

ğœŒ 

âˆšï¸ 

ğ‘… 2 + ğ‘§ 2



dğ‘§, (16) where ğ‘… is the projected radius, ğ‘§ is the line-of-sight coordinate and 

ğ‘Ÿ 2 = ğ‘… 2 + ğ‘§ 2. Here, we assume that the mass distribution is spheri-cally symmetric. The ESD can then be computed from its definition in Eq. (2). For practical calculations, it is convenient to use a com-putationally simpler expression that avoids nested integrals (Cromer et al. 2022): 

Î”Î£ (ğ‘… ) = 4

ğ‘… 2

âˆ« ğ‘… 

> 0

dğ‘Ÿ ğ‘Ÿ 2 ğœŒ (ğ‘Ÿ ) âˆ’ 4ğ‘… 

âˆ« ğœ‹ /20

dğœƒ ğœŒ (ğ‘… sec ğœƒ )

4 sin ğœƒ + 3 âˆ’ cos (2ğœƒ ) .

(17) In principle, the total excess surface density Î”Î£ (ğ‘… ), had contri-butions from different components: the one-halo dark matter term, baryonic components, and the two-halo term. However, within the radial range probed in this analysis ( 0.3 â‰¤ ğ‘… â‰¤ 3.0 â„âˆ’1Mpc ), the sig-nal is dominated by the one-halo term. The two-halo term becomes significant only at scales spanning several virial radii, extending be-yond our outer limit, while the baryonic contribution is restricted to the innermost regions. We discuss these components and the validity of these approximations further in Section 6.3. Therefore, we define 

ğœŒ (ğ‘Ÿ ) as the density profile of the one-halo term. 

4.2 Function Optimisation and Parameter Estimation 

A key step in ESR is to optimise the free parameters of each candidate expression. ESR defines the best-fit parameters as those that max-imise the likelihood of the data. We use an uncorrelated Gaussian likelihood of the form 

âˆ’ log L =âˆ‘ï¸ 

> ğ‘–

 Î”Î£ model (ğ‘… ğ‘– ) âˆ’ Î”Î£ obs 

> ğ‘–

2

2ğœ 2

> ğ‘–

, (18) where Î”Î£ model (ğ‘… ğ‘– ) is the model-predicted ESD profile derived from the ESR expressions using Eq. (17). {Î”Î£ obs  

> ğ‘–

} are the set of observed ESD at projected radii {ğ‘… ğ‘– } measured using the estimator in Eq. (5). Finally, the statistical uncertainties {ğœ ğ‘– } are the errors from our ESD measurement. We use ğœ ğ‘– = ğœ shape (ğ‘… ğ‘– ) as defined in Eq. (10). Two conditions are forced when optimising functions for them to be considered a viable density model: (i) Positive density: the density function must be positive within the domain of the data, ensuring that the enclosed mass increases with radius. (ii) Exclusion of profiles with constant terms: Any function con-taining constant terms in the density, such as ğœŒ (ğ‘Ÿ ) = ğœƒ 0, is excluded. Constant terms have no impact on the ESD (as can be seen from Eq. (17)). Including such profiles introduces redundancy, as they provide the same ESD as functions without the constant term but are more complex. Therefore, we do not consider them. These conditions are imposed during optimisation, with parameter  

> MNRAS 000 , 1â€“21 (2026)

# Symbolically regressing dark matter halo profiles using weak lensing 7

values that violate them being assigned a likelihood of 0 and hence being discarded. The numerical optimisation for local parameters is performed us-ing a combination of two algorithms. The first is the BFGS algo-rithm (Broyden 1970; Fletcher 1970; Goldfarb 1970; Shanno 1970; Nocedal & Wright 2006), which is a gradient-descent method. The gradients are computed using automatic differentiation with JAX 

(Bradbury et al. 2018). While BFGS is fast and effective for well-behaved functions with a clear global minimum, it sometimes gets stuck in local minima when the objective function is more complex. To mitigate this problem, we repeat the optimisation ğ‘ iter times with different random starting points and select the best result. We select random starting values for each ğœƒ ğ‘– from a uniform distribution within the range [âˆ’ 10 , 10 ]. A solution is considered reliable if it converges to the same likelihood value at least ğ‘ conv times. If, after running the algorithm for ğ‘ iter times, it fails to converge to a solution ğ‘ conv times, we run a second minimisation routine: the Nelder-Mead algorithm (Nelder & Mead 1965), which is a derivative-free, simplex search method. We find that this method is less likely to get lost in local minima as it makes larger jumps in parameter space. It does, however, take significantly longer to converge, which is the reason we do not use it from the outset. The Nelder-Mead algorithm is also run ğ‘ iter times and considered reliable if it converges to the same solution in ğ‘ conv of them. After both optimisation stages, we examine the resulting parameter values. If any parameter exceeds 10 5 or falls below 10 âˆ’5, we repeat the Nelder-Mead optimisation in log-space to enable a more effective search of regions with very large or small parameter values. We found this routine to be the most effective at locating global minima, even for functions that are less well-behaved. For the ex-amples shown here, we set ğ‘ iter = 800 for BFGS and ğ‘ iter = 700 

for Nelder-Mead . We choose ğ‘ conv = 20 ğ‘ + 80 , where ğ‘ is the number of free parameters to be optimised. This scaling takes into account the increased difficulty of finding the global optimum in higher-dimensional spaces. Finally, to reduce the computational cost, we used a two-stage filtering strategy for complexities greater than 6. First, we evaluated the full library of functions on the subset of 10 clusters with the highest SNRs. We then selected the top 1000 performing functions from this subset and optimised them across the full sample of clusters. To ensure that we were not missing any important functions, we took the next 300 functions (i.e., those ranked 1001 to 1300 for the 

10 clusters) and performed the full-sample optimisation on this set. We confirmed that none of these models appeared in the final top 

100 ranking for the full sample. Given that our results focus on the highest-ranked models (see Section 5), this test confirms that the filtering strategy is robust and that the excluded functions are indeed suboptimal and need not be considered. 

4.3 Uncertainty estimation 

The final step in computing the description length ğ¿ (ğ· ) is to deter-mine the parameter precision, given by 1/Î”. This is the only degree of freedom in the expression of the MDL. Increasing Î”ğ‘– (i.e., specify-ing ğœƒ ğ‘– with lower precision) reduces the parameter codelength term, 

log (| ğœƒ ğ‘– |/ Î”ğ‘– ), but at the same time increases the log-likelihood term by deviating from the best-fit parameter value. In ESR, the Î”ğ‘– values for each parameter are estimated from the Hessian matrix of the log-likelihood. As shown in Bartlett et al. (2024), the form of Î”ğ‘– that minimises the overall description length is 

Î”ğ‘– = (12 /ğ¼ ğ‘–ğ‘– )1/2, where ğ¼ ğ‘– ğ‘— â‰¡ âˆ’ ğœ• ğ‘– ğœ• ğ‘— log L| Ë†ğœƒ . This approach, which relies on the diagonal elements of the observed Fisher matrix to          

> Figure 2. Illustration of parameter uncertainty estimation from the conditional likelihood L ( ğœƒ ğ‘– ). The red dashed line marks the maximum-likelihood (ML) estimate, and the shaded region corresponds to the 68% confidence interval. For our analysis, we define a symmetric uncertainty Â±Ë†ğœ (blue dashed lines), where Ë†ğœ is set to the larger of the two distances from the ML value to the boundaries of the 68% confidence interval.

determine parameter precision, assumes that the likelihood function is approximately Gaussian near its maximum. However, our model imposes constraints, such as enforcing a positive density profile, which can introduce sharp boundaries in the likelihood surface. In such cases, this Laplace approximation may not provide a reliable estimate of Î”ğ‘– .To handle these cases, we determine Î”ğ‘– directly from the like-lihood surface. We fix all parameters except ğœƒ ğ‘– to their maximum likelihood (ML) values and compute the conditional (profile) likeli-hood L( ğœƒ ğ‘– |ğœƒ ğ‘— â‰ ğ‘– = Ë†ğœƒ ğ‘— ). To estimate the uncertainty of this profile, we integrate the likelihood function for ğœƒ ğ‘– outward from the ML point in both directions, until the cumulative probability reaches 68% . If the likelihood has a hard cutoff on one side, we treat that cutoff as one of the integration limits. Since ESR requires symmetric uncertainty, we take the largest of the two one-sided as the standard deviation ğœ ğ‘– ,and define Î”ğ‘– = âˆš12 Â· ğœ ğ‘– . Fig. 2 illustrates this procedure, showing how ğœ ğ‘– is obtained by integrating outward from the ML value and then selecting the largest of the two resulting intervals. In some cases, it might happen that |ğœƒ ğ‘– |/ Î”ğ‘– < 1, meaning that the ML estimate of a parameter is indistinguishable from 0 within the uncertainty tolerance. In these situations, we set these parameters to 0, recalculate the likelihood, and reduce the parameter count ğ‘ 

by one. Since this occurs only when a parameter is already poorly constrained, the overall effect on ğ¿ (ğ· ) is minimal. Furthermore, if setting a parameter to 0 causes the entire density profile to be 0,we also set all remaining parameters to 0 and reduce the number of parameters to 0.

4.4 Handling Multiple Datasets: Global vs. Local Parameters 

So far, we have described how ESR can be used to identify the best-fitting expression for a single dataset. However, since we are interested in studying dark matter halo profiles across a range of galaxy clusters, we want to be able to combine different datasets. This requires finding a systematic way to combine the results from individual clusters to evaluate overall model performance. There are different ways to do this, depending on how the model parameters are treated. One approach is to fit the free parameters separately for each cluster and then combine the results. This involves applying ESR independently to each dataset and obtaining a separate fit of the density profile for each cluster. To compute a combined  

> MNRAS 000 , 1â€“21 (2026)

# 8 A. MartÃ­n et al. 

ğ¿ (ğ· ) across the full sample, we sum the likelihood contributions from each cluster while counting complexity terms only once. This yields a total ğ¿ (ğ· ) given by 

ğ¿ (ğ· ) = âˆ’

> ğ‘

âˆ‘ï¸ 

> ğ‘ =1

log L (ğ‘ ) + ğ‘˜ log (ğ‘› ) + ğ‘ Â· ğ‘ log (2)+

> ğ‘

âˆ‘ï¸ 

> ğ‘ =1
> ğ‘

âˆ‘ï¸ 

> ğ‘– =1

log (| ğœƒ (ğ‘ ) 

> ğ‘–

|/ Î”(ğ‘ ) 

> ğ‘–

) + âˆ‘ï¸ 

> ğ‘—

log (ğ‘ ğ‘— ).

(19) In this case, since all clusters have the same functional form, we only need a single copy of the â€œstructural complexityâ€ terms (e.g. ğ‘˜ log ğ‘› ), and thus this is not simply the sum of the individual description lengths of each cluster. Alternatively, we can consider the possibility that a subset of pa-rameters is shared across all galaxy clusters; we refer to these as 

global parameters. These act as universal constants across the full sample, representing the shared features in the shape of the dark mat-ter density profile. An example of a parameter that could be treated as global is the inner slope of the density profile in the generalised NFW form. This approach of allowing for shared global parameters has been developed in other symbolic regression analyses, for ex-ample Tenachi et al. 2024; Russeil et al. 2024; Sen Fong & Motani 2024; Russeil et al. 2025. Introducing global parameters results in a lower total likelihood, since there are fewer degrees of freedom to fit each dataset. However, it also reduces the number of free parameters and thus the overall model complexity, which may make such models preferable under the MDL framework. Ideally, one would like to allow some parameters to be global while others remain galaxy-specific in an attempt to find the overall lowest description length models. This allows the data itself to determine which model structure is appropriate. The description length then becomes 

ğ¿ (ğ· ) = âˆ’

> ğ‘

âˆ‘ï¸ 

> ğ‘ =1

log L (ğ‘ ) + ğ‘˜ log (ğ‘› ) + ( ğ‘ Â· ğ‘ â„“ + ğ‘ g) log (2)+

> ğ‘

âˆ‘ï¸ 

> ğ‘ =1
> ğ‘ â„“

âˆ‘ï¸ 

> ğ‘– =1

log (| ğœƒ (ğ‘ ) 

> ğ‘–

|/ Î”(ğ‘ ) 

> ğ‘–

) + 

> ğ‘ g

âˆ‘ï¸ 

> ğ‘˜ =1

log (| ğœƒ âˆ— 

> ğ‘˜

|/ Î”âˆ— 

> ğ‘˜

)+âˆ‘ï¸ 

> ğ‘—

log (ğ‘ ğ‘— ),

(20) where ğ‘ â„“ and ğ‘ g are the number of local and global parameters, respectively, (with ğ‘ = ğ‘ â„“ +ğ‘ g) and the âˆ— indicates global parameters. Testing all possible combinations of global and local parameters is computationally very expensive. Instead, we use a two-step procedure to identify which combinations are worth trying. First, we fit each cluster independently, allowing parameters to vary between clusters. This ensures the best possible likelihood for each function. Then, we evaluate whether â€œglobalisingâ€ some of the parameters can reduce the 

ğ¿ (ğ· ) enough to make the function a preferred model. We estimate the maximum possible gain in ğ¿ (ğ· ) under the best-case assumption that the likelihood remains unchanged upon globalisation. This upper bound is given by max (Î”ğ¿ ) = max (ğ¿ â„“ âˆ’ ğ¿ g)

=

> ğ‘

âˆ‘ï¸ 

> ğ‘ =1
> ğ‘ g

âˆ‘ï¸ 

> ğ‘– =1

log 



|ğœƒ (ğ‘ ) 

> ğ‘–

|/ Î”(ğ‘ )

> ğ‘–



+ ğ‘ g (ğ‘ âˆ’ 1) log 2 , (21) where the maximum gain corresponds to the minium possible contri-bution of the term Ãğ‘ g 

> ğ‘˜ =1

log (| ğœƒ âˆ— 

> ğ‘˜

|/ Î”âˆ— 

> ğ‘˜

). This minimum cost is achieved when a parameterâ€™s magnitude equals its resolution ( |ğœƒ ğ‘– | = Î” ğ‘– ). The ESR framework enforces this as a lower limit, as any parameter with a value smaller than its resolution ( |ğœƒ ğ‘– | < Î”ğ‘– ) is considered non-significant and is â€œsnappedâ€ to zero. If the maximum gain is enough to situate the candidate expression in the top 10 ranked functions we then perform the optimisation with global parameters. We choose this cut-off of rank 10 for practical reasons. First, this matches the number of functions that we report in our final analysis (see Ta-ble 1). Second, the description length ğ¿ (ğ· ) drops rapidly for lower-ranked functions, meaning they have negligible posterior probability (âˆ exp (âˆ’ ğ¿ (ğ· )) ) and hence do not justify the extra computational cost of re-optimisation. From a total search space of 134 ,239 unique functions, our method identified 1411 candidate expressions for globalisation. These can-didates correspond to 867 distinct functional forms with various combinations of global and local parameters. 

4.5 Optimising global parameters 

Unlike optimising purely local parameters, specific to each cluster, studying a combination of local and global parameters requires a different approach. One possible method is to perform a single op-timisation over all ğ‘ g + ğ‘ Â· ğ‘ â„“ parameters, where ğ‘ = 149 is the number of clusters. However, in such a high-dimensional space, the optimiser often struggles to find the global optimum. Instead, we use a two-step nested optimisation. The first optimisa-tion searches for suitable global parameter values. For each trial set of global parameters, a secondary optimiser adjusts the local parame-ters for each cluster independently using ğ‘ iter = 20 and an ğ‘ conv = 5.This process repeats until the global optimiser converges 10 times to the same global values. This method is more computationally expen-sive than a single optimisation, since local parameters are optimised even for suboptimal global values. However, it improves overall con-vergence by breaking the problem into smaller, lower-dimensional sub-problems. For local parameter optimisation, we use the BFGS algorithm which is fast and generally effective in lower-dimensional settings. Global parameters are optimised using Nelder-Mead, which does not require gradient information and is more robust for exploring the global parameter space. 

5 RESULTS 5.1 Best-performing DM profiles 

We show in Table 1 the best-performing density profiles obtained using ESR across all galaxy clusters. The functions are ranked using Eq. (15). The description length is decomposed into three compo-nents: residuals between the data and the function, complexity of the functional form, and parameter contributions (as detailed in the ta-ble footnote). For comparison, we also include the ranking obtained using the Katz prior. In that case, the total description length is com-puted using the residual and parameter terms, with the structural complexity term replaced by the value from the Katz column. We find that the function rankings are very similar under both criteria. Since we are using a dataset of 149 galaxy clusters, the residual and parameter terms, both of which scale linearly with the number of clusters, dominate over the complexity term. With more data, the complexity penalty becomes less important, since overfitting is increasingly disfavoured by the data itself. As a consequence, adopting a Katz prior produces only minor differences in the final  

> MNRAS 000 , 1â€“21 (2026)

# Symbolically regressing dark matter halo profiles using weak lensing 9

rankings. For this reason, in the rest of the paper we focus on the rankings obtained without the Katz prior. We also report in Table 1 the relative probability ğ‘ƒ ( ğ‘“ ğ‘– | ğ· ) of each model with respect to all other candidates. In the MDL framework, the ğ¿ (ğ· ) of model ğ‘– (i.e. function ğ‘“ ğ‘– ) is (up to an additive constant) the negative logarithm of its probability given the data, hence ğ‘ƒ ( ğ‘“ ğ‘– |

ğ· ) âˆ exp (âˆ’ ğ¿ (ğ· )ğ‘– ). We therefore convert the ğ¿ (ğ· ) for each function 

ğ‘“ ğ‘– into a relative probability: 

ğ‘ƒ ( ğ‘“ ğ‘– |ğ· ) = exp (âˆ’ ğ¿ (ğ· )ğ‘– )

Ã ğ‘— exp  âˆ’ğ¿ (ğ· ) ğ‘— 

 , (22) where the sum is over all functions we analysed up to complexity 

10 . This shows that the relative probability is dominated by the first model, which carries 0.835 of the weight. For reference, Table 1 also lists several common dark matter den-sity profiles alongside their ranking. For complexities above 6, we do not evaluate the full ESR function set on every cluster. Instead, we run all functions on the 10 clusters with the highest signal-to-noise ratio, and then apply only a subset of the best-performing functions from this stage to the full cluster sample. This approach is sufficient to identify the best-fitting functions, but it may omit some lower-ranked candidates which would therefore not be included in this ranking. This implies that the reference profiles might in fact rank worse if the full set were exhaustively evaluated. Table 1 already includes func-tions both with purely local parameters and with combinations of local and global parameters. The ranking reflects the full description length including accounting for loval versus global as described in Section 4. The NFW profile is included in two different parametrisations. NFW 1 uses a more standard form, written as ğœŒ (ğ‘Ÿ ) = ğœƒ 0/( ğ‘Ÿ (| ğœƒ 1 | + 

ğ‘Ÿ )2). However, for 11 clusters, the parameter precision for ğœƒ 1 gives 

Î”1 â‰¥ ğœƒ 1, causing ESR to snap ğœƒ 1 to 0. This results in a profile of the form ğœŒ (ğ‘Ÿ ) âˆ 1/ğ‘Ÿ 3 which no longer reflects the behaviour of an NFW profile. To avoid this, NFW 2 uses an alternative form 

ğœŒ (ğ‘Ÿ ) = ğœƒ 0/( ğ‘Ÿ (1/| ğœƒ 1 | + ğ‘Ÿ )2). In this parametrisation, ğœŒ (ğ‘Ÿ ) â†’ 0 as 

ğœƒ 1 â†’ 0, which preserves the expected NFW behaviour when the scale radius becomes very small. Usually, when ESR finds two vari-ants of the same function, it retains only the one with the better description length. However, because the NFW 1 variant with a snapped parameter is not representative of the standard NFW profile, we have chosen to present both variants in our results. Among the commonly used profiles, the best-performing after NFW 1 is the isothermal sphere. This is not due to a higher likelihood; rather, for 130 out of the 149 clusters, the model parameters are snapped to 0, resulting in a smaller overall description length. The model effectively behaves as an isothermal sphere for the high-SNR clusters and as a null profile for the remainder. The generalised NFW (gNFW) profile introduces an additional free parameter, ğœƒ 2, which controls the outer slope of the density pro-file (Evans & An 2006). In principle, the extra flexibility should im-prove the likelihood relative to the standard NFW model. In practice, however, ESR often snaps poorly constrained parameters to zero for clusters with low signal-to-noise. After snapping, the resulting like-lihood can in fact be worse than that of the standard NFW model. Fitting a three-parameter profile locally to clusters that have only 9

radial data points is therefore prone to overfitting and leads to param-eters that are either weakly constrained or whose constraints likely reflect overfitting. We find a very broad and highly skewed distribu-tion of inferred ğœƒ 2 values, with many clusters favouring extreme and seemingly unphysical outer slopes. As a result, per-cluster estimates of ğœƒ 2 should be interpreted cautiously. We have also included the Dekel-Zhao model (Freundlich et al. 2020) (DZ in Table 1) and the Einasto (Einasto 1965) and Burkert (Burkert 1995) profiles, which have more flexible shapes but perform worse. More importantly, the best-fitting functions found by ESR consis-tently outperform the standard dark matter profiles in both likelihood and total description length while using the same number of free parameters as NFW. Interestingly, no functions with more than 2 pa-rameters were ranked among the top solutions. This suggests that the constraining power of the current dataset is limited to constraining only two free parameters effectively. This also explains why stan-dard profiles with more than two parameters are systematically less preferred by the MDL framework. Fig. 3 shows the best description length, ğ¿ (ğ· ), and the negative log-likelihood, âˆ’ log (L) , at each model complexity. For each metric, the results are normalised by subtracting the global minimum value, so that the globally best functions appear at 0 and worse-performing functions appear higher up. The plot shows that the common dark matter density profiles are Pareto-dominated by the functions dis-covered by ESR. Note that beyond complexity 7, the improvement in description length is small; however, complexity 10 remains the best. Further improvement may be possible at complexities higher than 

10 , which is currently beyond the scope of ESR. As expected, the negative log-likelihood continues to decrease with added complexity. For completeness, we note that the function with the single best raw likelihood is a 4-parameter, complexity-10 model: 

ğœŒ (ğ‘Ÿ ) = ğœƒ 1

ğœƒ 0 + ğ‘Ÿ + ğœƒ 2

> ğœƒ 3

. (23) The behaviour of this expression is sensitive to the signs and magni-tudes of the parameters. The term ğœƒ 1/( ğœƒ 0 + ğ‘Ÿ ) introduces a potential divergence when ğœƒ 0 + ğ‘Ÿ â†’ 0, which can occur at a finite radius if ğœƒ 0

is negative. Conversely, a zero in the density occurs at the radius at which ğœƒ 1/( ğœƒ 0 + ğ‘Ÿ ) + ğœƒ 2 = 0. Both features, a divergence and zero-density shells, appear for some clusters in the set depending on the fitted parameter values. These behaviours are allowed by the formula and such narrow spikes or zeros are difficult to detect numerically and avoid during fitting. Although this model attains the best raw likelihood among all expressions considered, it is not ranked as a top solution because it is penalised for its high number of free param-eters. This shows how a highly flexible expressions that can overfit noisy data are naturally down-weighted by MDL. All functions in Table 1 use local parameters. To the list of best-fitting functions with local parameters, we applied Eq. (21) to identify functions and parameters worth globalising. This produced a list of 

2905 functions and parameter combinations. Table 2 lists the best-performing functions that include some global parameters and their corresponding rankings. This table also includes the gNFW profile with the inner power slope treated as a global parameter. The best value of the global parameter ğœƒ 2 found is 3.61 Â± 0.05 .Interestingly, the best-fitting functions with global parameters are generally simpler. This is because global parameters force the func-tion to fit all clusters at once using the exact same values. While complex functions are usually more flexible, locking their parameters makes them too rigid to handle the differences between individual clusters. Simpler functions, by contrast, work better here because they capture the general average of the sample rather than struggling to fit the unique details of each cluster. The top-ranking function from this set is found at rank 38 in the full list of functions where any parameter can be global or local, indicating the globalising parameters does not lower the description lengths of good functions in this case. This is perhaps unsurprising given the mathematical form of the best-fitting profiles. Global pa-rameters are expected to be useful when they describe a feature of the  

> MNRAS 000 , 1â€“21 (2026)

# 10 A. MartÃ­n et al. 

Rank Rank Katz ğœŒ (ğ‘Ÿ )/ 10 12 ğ‘€ âŠ™ Mpc âˆ’3 Complexity ğ‘ƒ ( ğ‘“ |ğ· ) Description Length Residual 1 Parameters 2 Function 3 Katz 4 Total Total Katz 1 1 1/( ğœƒ 0 (ğ‘Ÿ | ğœƒ 1 | ) ğ‘Ÿ 2 ) 10 0.84 601.4 223.5 16.1 16.8 841.0 841.6 2 5 1/( ğœƒ 0 (âˆ’ ğ‘Ÿ + | ğœƒ 1 |ğ‘Ÿ ğ‘Ÿ ) ) 10 0.16 620.0 204.8 17.9 25.1 842.6 849.8 3 3 ( | ğœƒ 0ğ‘Ÿ |ğ‘Ÿ Â· | ğœƒ 1 | ) âˆ’ğ‘Ÿ 10 0.01 601.3 229.1 16.1 17.3 846.5 847.7 4 20 1/( ğœƒ 0 (ğ‘Ÿ ğ‘Ÿ | ğœƒ 1 | ) ğ‘Ÿ ) 10 4.7 Ã— 10 âˆ’5 622.3 212.3 16.1 25.7 850.7 860.4 5 2 (1/( ğ‘Ÿ 2 | ğœƒ 0 | ) ) ğ‘Ÿ /ğœƒ 1 10 4.2 Ã— 10 âˆ’5 615.7 219.1 16.1 11.0 850.8 845.7 6 8 ğ‘Ÿ 2/( ğœƒ 0 | ğœƒ 1 |ğ‘Ÿ ) 9 3.5 Ã— 10 âˆ’5 616.5 222.1 12.5 15.5 851.0 854.0 7 7 (ğ‘Ÿ 1/ğ‘Ÿ |1/ğœƒ 0 | ) ğ‘Ÿ /ğœƒ 1 10 2.0 Ã— 10 âˆ’5 623.3 212.7 16.1 16.9 851.6 852.4 8 13 ğ‘Ÿ /( | ğœƒ 0 |ğ‘Ÿ | ğœƒ 1 | ) ğ‘Ÿ 9 5.1 Ã— 10 âˆ’6 622.2 216.3 14.5 17.4 853.0 855.9 9 4 ( | ğœƒ 0 |ğ‘Ÿ | ğœƒ 1 |/ ğ‘Ÿ ) âˆ’ğ‘Ÿ 10 4.1 Ã— 10 âˆ’6 605.2 231.9 16.1 12.2 853.2 849.2 10 16 ğ‘Ÿ /( ğœƒ 0 | ğœƒ 1 |ğ‘Ÿ ) 7 3.9 Ã— 10 âˆ’6 623.8 219.8 9.7 14.1 853.2 857.7 

... ... ... ... ... ... ... ... ... ... ...

221 338 NFW 1: ğœƒ 0/( ğ‘Ÿ ( | ğœƒ 1 | + ğ‘Ÿ )2 ) 9 âˆ¼ 10 âˆ’28 685 .3 206 .8 24 .0 12 .6 904 .7 916 .2

903 895 Isothermal: ğœƒ 0/ğ‘Ÿ 2 5 âˆ¼ 10 âˆ’56 944 .5 19 .0 5.5 5.3 968 .9 968 .7

2436 2361 NFW 2: ğœƒ 0/( ğ‘Ÿ (1/| ğœƒ 1 | + ğ‘Ÿ )2 ) 9 âˆ¼ 10 âˆ’110 939 .1 126 .9 26 .0 12 .6 1092 .0 1078 .6

2964 2925 gNFW: ğœƒ 0/( ğ‘Ÿ ( | ğœƒ 1 | + ğ‘Ÿ ) ğœƒ 2 ) 9 âˆ¼ 10 âˆ’159 793 .8 384 .1 26 .9 19 .4 1204 .7 1197 .3

3251 3251 Einasto: ğœƒ 0 exp ( ğœƒ 1ğ‘Ÿ ğœƒ 2 ) 8 âˆ¼ 10 âˆ’209 953 .2 355 .1 12 .9 11 .6 1321 .2 1319 .9

3507 3509 Burkert: ğœƒ 0/( ( ğœƒ 1 + ğ‘Ÿ ) ( ğœƒ 1 + ( ğ‘Ÿ )2 ) 13 < 10 âˆ’300 707 .9 1310 .1 31 .2 20 .7 2038 .7 2049 .2

3528 3527 DZ: ğœƒ 0/( ğ‘Ÿ ğœƒ 1 ( ğœƒ 2 + ğ‘Ÿ 1/2 )2(3.5âˆ’ ğœƒ 1 ) ) 17 0 850 .8 1275 .0 41 .7 32 .5 2167 .53 2158 .3 

> 1

âˆ’ Ãğ‘ log L (ğ‘ ) ( Ë†ğœ½ ) 2 ğ‘ log (2) + Ãğ‘ ğ‘ =1

Ãğ‘ ğ‘– =1 log ( | ğœƒ (ğ‘ ) 

> ğ‘–

|/ Î”(ğ‘ ) 

> ğ‘–

) 3 ğ‘˜ log ğ‘› + Ã ğ‘— log (ğ‘ ğ‘— ) 4 âˆ’ log Î  + Ã ğ‘— log (ğ‘ ğ‘— )

Table 1. Top functions found by ESR applied to the sample of 149 HSC galaxy clusters, ranked by total description length. The total description length is decomposed in three terms: the accuracy term (â€œResidualsâ€), the parameters complexity term (â€œParameterâ€) and the structural complexity term (â€œFunctionâ€). To calculate the total description length using the Katz prior (â€œTotal Katzâ€), we replace the â€œFunctionâ€ column with the â€œKatzâ€ column. All functions presented here use exclusively local (i.e. separate per-cluster) parameters. For each model we also report the relative probability ğ‘ƒ ( ğ‘“ ğ‘– |ğ· ), obtained by normalising 

exp (âˆ’ ğ¿ (ğ· )ğ‘– ) over all functions. We additionally include several commonly used literature profiles: NFW (Navarro et al. 1997), generalised NFW (gNFW; Evans & An 2006), Einasto (Einasto 1965), Burkert (Burkert 1995), and Dekelâ€“Zhao (Freundlich et al. 2020)), written in the ESR functional language and evaluated using the same description-length formalism. . 

profile itself rather than individual clusters, such as a simple scaling or powers of the radius. However, in the best-fitting functions, the parameters do not correspond to simple scaling relations or power laws, so cluster-specific parameters perform better. 

5.2 Properties of the best-fitting ESR functions 

All of the functions in Table 1 provide a good fit to the data, but their physical interpretation is not necessarily clear. Two general features stand out when examining the shapes. First, most functions tend to 

0 as ğ‘Ÿ â†’ âˆ as expected, although their inner behaviour can differ from one profile to the other. Second, most of these functions are not analytically integrable, making it impossible to obtain a closed-form expression for the enclosed mass. Commonly used profiles such as Einasto do not provide a closed-form expression for the enclosed mass, so the lack of an analytical mass estimate is not in itself a drawback. However, for practical appli-cations it is often useful to work with profiles that are both analytically integrable and reasonably simple while still having competitive fits. Table 3 lists some of these profiles. In general, these functions have lower complexity than the best-fitting ones and are easier to han-dle analytically, while still greatly outperforming literature functions such as NFW. We are going to highlight a few profiles from this list and illustrate their properties and potential drawbacks. The first profile we focus on is the highest-ranked function in Table 3 (ranked 6th overall): 

ğœŒ (ğ‘Ÿ ) = ğ‘Ÿ 2

ğœƒ 0 |ğœƒ 1 |ğ‘Ÿ = ğœŒ 0ğ‘Ÿ 2 exp (âˆ’ ğœ†ğ‘Ÿ ), (24) The second expression provides a more intuitive re-parameterisation with a normalization ğœŒ 0 = 1/ğœƒ 0 and a decay constant ğœ† = ln |ğœƒ 1 |

(assuming |ğœƒ 1 | â‰  0). The profile rises as ğ‘Ÿ 2 from the origin before being cut off by an exponential decay. Its enclosed mass profile is given by: 

ğ‘€ (ğ‘… ) = 96 ğœ‹ğœŒ 0

ğœ† 5



1 âˆ’ ğ‘’ âˆ’ğœ†ğ‘… 



1 + ğœ†ğ‘… + (ğœ†ğ‘… )2

2 + (ğœ†ğ‘… )3

6 + (ğœ†ğ‘… )4

24 

 

.

(25) The primary physical drawback of this function is the unphysical â€œholeâ€ at its centre, where ğœŒ (0) = 0. We find that this feature is common among the analytically integrable profiles discovered by SR (see Table 3). Therefore, we also highlight a second profile that solves this issue. This profile is ranked third in Table 3 (rank 21 overall) and has the form 

ğœŒ (ğ‘Ÿ ) = 1

ğ‘Ÿ + ğ‘Ÿ ğœƒ 0 |ğœƒ 1 |ğ‘Ÿ = 1

ğ‘Ÿ + ğ‘Ÿ ğ‘Ÿ â˜…

exp (âˆ’ ğœ†ğ‘Ÿ ) . (26) This profile diverges as ğœŒ (ğ‘Ÿ ) âˆ¼ 1/ğ‘Ÿ for small ğ‘Ÿ , similar to the inner cusp of an NFW profile. Here, the second form is a more physically intuitive re-parameterisation, where the decay constant is ğœ† = ln |ğœƒ 1 |

and the scale radius is ğ‘Ÿ â˜… = ğœƒ 0. This profileâ€™s behaviour is well-aligned with standard halo models: it diverges as ğœŒ (ğ‘Ÿ ) âˆ¼ 1/ğ‘Ÿ for small ğ‘Ÿ , creating an inner cusp similar to an NFW profile, while the second term ensures a rapid exponential decay at large radii. A potential problem with this function derived by ESR is that it is not dimensionally consistent. We can approach this in two ways. The first option is to introduce a constant of proportionality, which transforms the expression into a physical three-parameter model: 

ğœŒ (ğ‘Ÿ ) = ğ´ ğ‘Ÿ + ğµğ‘Ÿ exp (âˆ’ ğœ†ğ‘Ÿ ) (27) 

MNRAS 000 , 1â€“21 (2026) Symbolically regressing dark matter halo profiles using weak lensing 11 

No. Rank ğœŒ (ğ‘Ÿ )/ 10 12 ğ‘€ âŠ™ Mpc âˆ’3 Complexity Description Length Residual 1 Parameters 2 Function 3 Katz Total Total Katz 1 38 | ğœƒ 0 |âˆ’| ğœ½ 1 |ğ‘Ÿ 6 753.98 105.06 14.48 5.68 873.53 879.21 2 49 (ğ‘Ÿ | ğœƒ 0 | ) âˆ’1/| ğœ½ 1 |ğ‘Ÿ 9 753.32 106.05 20.92 19.02 880.30 899.32 3 50 (ğ‘Ÿ |1/ğœƒ 0 | ) |ğœ½ 1 |âˆ’ğ‘Ÿ 8 756.02 104.80 19.71 19.67 880.53 900.20 4 53 (ğ‘Ÿ |1/ğœƒ 0 | ) |ğœ½ 1 |ğ‘Ÿ 7 759.10 109.16 14.48 11.67 882.75 894.42 5 54 ğ‘Ÿ ğœƒ 0 /ğœ½ 1 5 761.11 112.73 9.70 7.85 883.54 891.39 

... ... ... ... ... ... ... ... ... ...

â€“ 2335 gNFW ğœƒ 0/( ğ‘Ÿ ( | ğœƒ 1 | + ğ‘Ÿ )ğœ½ 2 ) 9 888 .83 158 .47 26 .88 19 .42 1074 .18 1066 .72 

â€“ 3289 gNFW 1/( ğœƒ 0ğ‘Ÿ ( | ğœƒ 1 | + ğ‘Ÿ )ğœ½ 2 ) 9 679 .85 661 .56 29 .19 20 .74 1370 .60 1362 .15 

Table 2. Top-ranked functions with some global parameters. The information displayed is the same as in Table 1. Parameters set to global are highlighted in bold red. For comparison, the gNFW with ğœƒ 2 as a global parameter is also included. The â€œRankâ€ column shows each functionâ€™s position relative to the complete list of all models analysed in this work. No. Rank ğœŒ (ğ‘Ÿ )/ 10 12 ğ‘€ âŠ™ Mpc âˆ’3 Complexity Description Length Residual 1 Parameters 2 Function 3 Katz Total Total Katz 1 6 ğ‘Ÿ 2/( ğœƒ 0 | ğœƒ 1 |ğ‘Ÿ ) 9 616.47 222.08 12.48 15.47 851.03 854.02 2 9 ğ‘Ÿ /( ğœƒ 0 | ğœƒ 1 |ğ‘Ÿ ) 7 623.76 219.76 9.70 14.14 853.22 857.66 3 21 1/ğ‘Ÿ + ğ‘Ÿ /( ğœƒ 0 | ğœƒ 1 |ğ‘Ÿ ) 10 623.64 217.88 17.92 19.60 859.44 861.12 4 22 1/( ğœƒ 0 Â· ( ğ‘Ÿ + ( ğœƒ 1 âˆ’ ğ‘Ÿ )/ ğ‘Ÿ ) ) 10 399.38 442.62 17.92 15.54 859.92 857.54 5 32 (ğ‘Ÿ âˆ’2 + ğ‘Ÿ /ğœƒ 0 )/ ğœƒ 1 10 641.83 214.02 16.09 10.33 871.94 866.18 

Table 3. This table presents a subset of functions that are analytically integrable and thus have analytical mass profiles. As in Table 2, the â€œRankâ€ column shows each functionâ€™s position relative to the complete list of all models analysed in this work. 

Figure 3. Best-fitting functions at ecah complexity according to the change in description length, Î”ğ¿ (ğ· ), and the likelihood, L, relative to the corre-sponding minima. The markers show the position in the ğ¿ (ğ· ) plane (red) and likelihood plane (blue) of some common dark matter halo profiles. The Burkert and Dekel-Zhao profiles are not included here for clarity, since they have very poor ğ¿ (ğ· ). Only the ğ¿ (ğ· ) values without the Katz prior are shown, since including the Katz prior produces very similar results. The two NFW points correspond to two parametrisations used in the analysis. NFW 1 is the standard form, ğœŒ (ğ‘Ÿ ) = ğœƒ 0/( ğ‘Ÿ ( | ğœƒ 1 | + ğ‘Ÿ )2 ) and NFW 2 is 

ğœŒ (ğ‘Ÿ ) = ğœƒ 0/( ğ‘Ÿ (1/| ğœƒ 1 | + ğ‘Ÿ )2 ).

where ğ´ , ğµ , and ğœ† are the three free parameters to fit. While this ensures that the equation is now physically valid, adding a third parameter increases the complexity term of the ğ¿ (ğ· ). Specifically, optimising Eq. (27) across all clusters yields a residual negative log-likelihood of âˆ’ log L â‰ˆ 573 .32 . This represents an improvement over Eq. (26) due to the modelâ€™s added flexibility. However, the complexity penalty for the extra parameter outweighs this gain, resulting in a total description length of ğ¿ (ğ· ) = 1740 .63 . The alternative is to interpret the numerical coefficients in the ESR expression as having implicit dimensions that balance the equation. While this avoids adding new parameters, it effectively â€œhard-codesâ€ the units of the data into the function constants, so the equation is no longer unit-agnostic. The corresponding integrated mass profile ğ‘€ (ğ‘Ÿ ) is given by: 

ğ‘€ (ğ‘Ÿ ) = 2ğœ‹ ğ´ğ‘Ÿ 2 + 24 ğœ‹ğµ ğœ† 4 âˆ’ 4ğœ‹ğµğ‘’ âˆ’ğœ†ğ‘Ÿ 

 ğ‘Ÿ 3

ğœ† + 3ğ‘Ÿ 2

ğœ† 2 + 6ğ‘Ÿ ğœ† 3 + 6

ğœ† 4



. (28) For the HSC dataset, these profiles offer a good compromise, pro-viding a competitive fit while retaining the practical advantages of an analytical mass profile. Fig. 4 illustrates the shape of the best-fitting models: the top three from Table 1 and the analytically integrable profile in Eq. (24). The cluster shown in the top panel is XLSSC 91 , which has a relatively high SNR of 7.41 , while the bottom panel shows cluster XLSSC 101 ,with a lower SNR of 3.40 . This allows us to compare the behaviour of the models for both high- and medium-SNR clusters. An interesting feature of the ESR fits is the presence of a local maximum in the ESD within the range of the data. Unlike traditional models that usually have a smooth, monotonic decline, the data seems to prefer functions that allow for this turning point. Physically, this implies central regions where the density is either flat (core-like behaviour) or even decreasing at small radii. The data seems to prefer these inner behaviours rather than steep central cusps. The flexibility of the models also allows this feature to be placed at different radii. As the turnover is placed further away form the clusters also develops a more extended core. However, the radial position of this feature suggests that it is also influenced by how measurement uncertainties vary with projected radius, ğ‘… . As shown in Eq. (11), the shape noise of the signal scales 

MNRAS 000 , 1â€“21 (2026) 12 A. MartÃ­n et al. 

roughly as ğœ Î”Î£ âˆ 1/ğ‘… . This 1/ğ‘… trend is clearly visible in the data shown in Fig. 4: the error bars are largest in the innermost radial bins and become progressively tighter at larger ğ‘… . Since the likelihood term weights each data point by its inverse variance ( 1/ğœ 2

> Î”Î£

), the fit is more driven by the high-precision data points at large radii. As such, the data prefer functions that accurately capture the outer behaviour over constraining the inner shape. For example, for clusters with a high SNR like XLSSC 91 (top panels in Fig. 4) the maximum is placed close to the centre. For clusters with a lower SNR like XLSSC 101 (bottom panels in Fig. 4), the maximum shifts outward to better fit the data in the cluster outskirts. This also explains the significant diversity of inner slopes among the top-ranked functions, as the current data lack the constraining power to distinguish between different profile functions at small radii. The analytically integrable profile from Eq. (26) provides an in-teresting example of this behaviour. Mathematically, the 1/ğ‘Ÿ term is expected to dominate the 3D density profile ( ğœŒ ) at both very large and very small radii. Its influence at large radii ( ğ‘Ÿ â‰³ 1 Mpc) is evident in Fig. 4 (right panels). However, the 1/ğ‘Ÿ divergence at small radii is not visible within most of the plotted range. For the best-fit parameters found by ESR, the second term, ğ‘Ÿ /( ğœƒ 0 |ğœƒ 1 |ğ‘Ÿ ), dominates the profileâ€™s shape throughout the intermediate region ( 0.01 â‰² ğ‘Ÿ â‰² 1 Mpc). This term is responsible for the â€œbumpâ€ and the subsequent turnover seen in the density plot. The 1/ğ‘Ÿ inner cusp only begins to dominate at extremely small radii (approximately ğ‘Ÿ â‰² 10 âˆ’2 Mpc). 

5.3 Enclosed mass estimation 

A practical application of the ESR-derived functions is to calcu-late the enclosed mass of the clusters. This is interesting because it avoids the need to rely on a single assumed density profile, as is often done with NFW. Instead, we take advantage of the set of best-fitting functions identified by ESR and their respective posterior probabil-ities to produce mass estimates that effectively marginalise over the uncertain functional form of the density profile. To combine models, we use a weighting scheme based on the description length, ğ¿ (ğ· ). We convert the ğ¿ (ğ· ) for each function 

ğ‘“ ğ‘– into a normalised probability weight, the relative probability, 

ğ‘ƒ ( ğ‘“ ğ‘– |ğ· ), (see Eq. (22)). This weighting ensures that models pro-viding the most efficient description of the data contribute more, while those with poorer ğ¿ (ğ· )s are suppressed. We include functions in the average until the cumulative probability reaches 0.9999 , which corresponds to the first six entries in Table 1. For each of these top-ranking models, we quantify the param-eter uncertainties by sampling the posterior distributions using a Hamiltonian Monte Carlo (HMC) algorithm (Neal 2011). This is implemented with the NumPyro package (Phan et al. 2019), which utilises the efficient No-U-Turn Sampler (NUTS) (Hoffman & Gelman 2014). We adopt uniform priors in logarithmic pa-rameter space. Specifically, each model parameter is sampled as 

log 10 |ğ‘ ğ‘– | âˆ¼ U ( log 10 Ë†ğ‘ ğ‘– âˆ’ 5ğœ ğ‘– , log 10 Ë†ğ‘ ğ‘– + 5ğœ ğ‘– ), where Ë†ğ‘ ğ‘– and ğœ ğ‘– are the ESR optimiser best-fit and its associated uncertainty, respectively. We run two independent chains with 2000 warm-up steps and 6000 

samples. We confirm that the chains have converged by calculating the Gelman-Rubin statistic ( Ë†ğ‘… ) for all parameters and requiring it to be less than 1.01 (Gelman & Rubin 1992). From each posterior sample we compute the corresponding en-closed mass profile. We define the enclosed mass of a cluster as the mass within a radius ğ‘Ÿ 200 , where the mean enclosed density is equal to 200 times the critical density ğœŒ crit (ğ‘§ ) at the cluster redshift ğ‘§ . The enclosed mass at this radius is defined as ğ‘€ 200 . We determine the value of ğ‘Ÿ 200 for each sample by numerically solving this condition and then evaluate ğ‘€ 200 at that radius. However, for certain functional forms or specific parameter combinations sampled by the HMC al-gorithm, the mean density never reaches the 200 ğœŒ crit threshold (for instance, if the profile flattens). Since ğ‘Ÿ 200 is mathematically unde-fined in these cases, these samples are considered unphysical and are discarded. This procedure yields, for each function and each cluster, a pos-terior distribution of ğ‘€ 200 . Finally, we combine the distributions across all functions by weighting each posterior mass estimate ac-cording to the ğ‘ƒ ( ğ‘“ ğ‘– |ğ· ) of its parent function. Specifically, if function 

ğ‘“ ğ‘– has a model probability ğ‘ƒ ( ğ‘“ ğ‘– |ğ· ) and ğ‘› ğ‘– retained HMC samples, then each mass draw for ğ‘“ ğ‘– is assigned a weight ğ‘ƒ ( ğ‘“ ğ‘– |ğ· )/ ğ‘› ğ‘– . The resulting weighted distribution provides our final posterior for ğ‘€ 200 ,from which we report the mean and the 16 th/ 84 th percentiles as uncertainty bounds. For comparison, we repeat the same procedure using the NFW pro-file with the parametrisation NFW 1, given by ğœƒ 0/( ğ‘Ÿ (| ğœƒ 1 | + ğ‘Ÿ )2). The top panel in Fig. 5 shows the weighted mean values of enclosed mass obtained from our best-fitting functions against the corresponding NFW estimates. We restrict the plot to clusters with an SNR > 2.5.These are a subset of 30 clusters that provide sufficiently reliable signals. In the low-SNR regime (SNR â‰¤ 2.5), the data lack statis-tical power to meaningfully constrain mass models. This is evident from the standard NFW fits; for instance, for 11 of these low-SNR clusters, the NFW fit collapses to a trivial ğœŒ = 0 solution. In cases where such zero-snapping does not occur, fits to this low-SNR data result in extremely broad or unconstrained posterior distributions for 

ğ‘€ 200 . We therefore focus only on this high-SNR subset to plot the correlation between the two mass estimates. In the figure, the 1:1 relation is shown as a dashed black line. We also fit a linear relation between our marginalised ESR mass ( ğ‘€ mESR )and the NFW mass ( ğ‘€ NFW ) in base-10 logarithmic space (dex). The model is given by: 

log 10 ğ‘€ mESR = ğ›¼ + ğ›½ log 10 ğ‘€ NFW . (29) We include a Gaussian intrinsic scatter ğœ int . We perform this regres-sion using the Python package roxy 3 (Bartlett & Desmond 2023), which implements the "Marginalised Normal Regression" (MNR) algorithm. This method is specifically chosen because, as demon-strated by Bartlett & Desmond (2023), it provides unbiased results by robustly accounting for measurement uncertainties in both the ğ‘¥ 

and ğ‘¦ variables, the intrinsic scatter and the unknown distribution of the â€œtrueâ€ ğ‘¥ -values. For the inputs, roxy requires symmetric errors. We therefore de-fine the uncertainty in the logarithm of each mass estimate as half the difference between its 84 th and 16 th percentiles. We place im-proper uniform priors on the intercept ğ›¼ and slope ğ›½ , and an improper uniform prior on ğœ int . The latent true ğ‘¥ -values are modelled with a Gaussian hyperprior, with its mean and width also inferred using improper flat hyperpriors. We ran the sampler with 700 warm-up steps followed by 5000 production samples, which yielded effective sample sizes ğ‘› eff > 2900 and Gelman-Rubin statistics Ë†ğ‘… = 1.00 for all inferred parameters. From this fit, we recover a slope of ğ›½ = 0.75 Â± 0.50 , an intercept of ğ›¼ = 3.53 Â± 6.87 , and an intrinsic scatter of 0.29 Â± 0.17 dex. While the slope is shallower than unity, it remains statistically consistent with a 1 : 1 relation given the large uncertainty. Combined with the consistency of the intercept with 0, we conclude that both mass estimates yield consistent results. Performing the same regression on   

> 3https://github.com/deaglanbartlett/roxy
> MNRAS 000 , 1â€“21 (2026)

# Symbolically regressing dark matter halo profiles using weak lensing 13            

> Figure 4. Plots of the top 2best-fitting functions, together with the top analytically integrable functions discussed in the text. The NFW profile is also shown for comparison. The top panels correspond to cluster XLSSC 91 , which has the highest SNR in the sample, while the bottom panels show cluster XLSSC 101 ,which is a medium SNR cluster. These two clusters are also shown in Fig. 1. Left panels: ESD fits to the data. The horizontal dashed line marks zero. Right panels: Corresponding density profiles plotted over a wide radial range. The vertical dashed lines indicate the radial range covered by the data. Shaded regions represent the 68% credible intervals derived from the posterior parameter distributions.

the full sample of all clusters yields very similar results with a slope again consistent with 1.This consistency demonstrates that our model-averaging technique produces physically reasonable mass estimates comparable to the standard NFW approach. The bottom panel of Fig. 5 shows the dis-tribution of the logarithmic mass ratios, ğ›¿ ğ‘– = log 10 (ğ‘€ mESR /ğ‘€ NFW ),which quantifies the relative deviations between the two masses. This shows the stacked posterior on this ratio over all clusters in the high-SNR sample, where the width of each posterior is derived by propagating the uncertainty on ğ›¿ ğ‘– from the (uncorrelated) uncertain-ties on both mass estimates under a Gaussian approximation. The final distribution is centred near zero (indicated by the dashed black line), confirming that our method does not introduce a significant systematic bias compared to the standard NFW model. The median of the stacked distribution is âŸ¨ğ›¿ âŸ© = 0.17 +0.93  

> âˆ’0.69

dex (solid red line), indicating that masses derived by ESR are on average higher than the NFW masses. We note that the MDL function has a relative probability of 0.835 

(see Fig. 4). Consequently, this single profile is the dominant driver of the fit. To asses the influence of the MDL function in the mass inference, we compute the ratio ğ›¿ ğ‘€ ğ·ğ¿,ğ‘– = log 10 (ğ‘€ mESR /ğ‘€ MDL ),where ğ‘€ MDL denotes the enclosed masses inferred using the highest-ranked MDL model. The stacked distribution then has a median of 

âŸ¨ğ›¿ âŸ© = 0.06 dex, showing that MDL-only masses are very similar to the model-averaged ESR masses. We can also compare the precision of NFW masses to the weighted-ESR masses. To do this, we examine the relative uncertain-ties. On average, the fractional uncertainties of ESR-derived masses are 9% larger than those of NFW. This increase has two contributions: the statistical uncertainty within each model and the additional vari- 

> MNRAS 000 , 1â€“21 (2026)

# 14 A. MartÃ­n et al.                    

> Figure 5. Comparison of enclosed mass estimates, ğ‘€ mESR , obtained from the weighted combination of our best-fitting functions against those derived from the standard NFW profile, ğ‘€ NFW for XXL clusters with a signal-to-noise ratio (SNR) higher than 2.5. The top panel shows the results in logâ€“ log space. The dashed black line indicates the 1:1 relation, while the solid red line shows the best-fit linear relation obtained using the roxy package, with the shaded region representing the 1ğœ confidence interval. The bottom panel shows the stacked posterior distribution of the logarithmic mass ration
> ğ›¿ ğ‘– =log 10 (ğ‘€ mESR /ğ‘€ NFW ). Each cluster contributes its individual posterior, built by propagating the uncorrelated uncertainties on both mass estimates under a Gaussian approximation. The black dashed line shows the 1 : 1
> relation and the solid red line marks median of the stacked distribution,
> âŸ¨ğ›¿ âŸ©=0.17 dex.

ance from averaging over different profile shapes. To separate these effects, we compare the uncertainties of the NFW masses directly to those obtained from the MDL model alone. We find that MDL masses are 1% larger than those derived from NFW, implying that the domi-nant source of the increased ESR uncertainty comes from averaging between different models. In other words, NFW yields slightly tighter model-specific constraints, but the broader uncertainties in the ESR masses reflect the additional model uncertainty accounted for by the profile averaging. We note, however, that the mass estimates for some of the clus-ters are lower than the values obtained by Umetsu et al. 2020. The difference is a consequence of the different modelling assumptions. In Umetsu et al. 2020, informative log-uniform priors are imposed directly on the halo mass and concentration, which favour physically reasonable solutions even for clusters with data consistent with zero. In contrast, our approach does not impose priors on physical param-eters such as halo mass or concentration. Instead, the optimisation is driven by the likelihood, and the subsequent posterior sampling ex-plores the region around the best-fit value. Consequently, our method is free to explore regions of the parameter space that may be dis-favoured by physical priors in other works, if that is where the global minimum of the data lies. on the mass and concentration, our method fits all model pa-rameters freely. This means that the optimiser finds the values that best fit the data, without being constrained to regions expected by the cosmological model. While this can give different mass esti-mates than prior-informed methods, it provides a more direct mea-sure of the information contained in the data itself. More impor-tantly, the same methodology was applied to both the NFW and ESR-weighted masses, ensuring that the comparison shown in Fig. 5 is self-consistent and presents a fair comparison of the modelsâ€™ per-formance on the data. This also highlights a more general methodological point. Relying solely on a single profile, such as NFW, carries a risk: if that chosen model is not a perfect description of the true halo structure, the re-sulting mass estimates may be systematically biased and reflect the priors (both functional and parametric) rather than the information contained in the data itself. We have shown here that not impos-ing any functional priors yields masses that are higher on average. The flexibility of our multi-model approach, with models motivated by the minimum description length principle, is that it can mitigate this model-selection bias by averaging over a set of plausible den-sity profiles. In the Bayesian context this is called Bayesian model averaging. 

5.4 Evidence for a universal profile 

Another interesting question we can address using ESR and the MDL principle is whether the data favour a universal density profile across all clusters, or whether a better description is obtained by allowing each cluster to have its own profile. Up to this point, our analysis has enforced a single profile shared by all clusters, while only varying global and local parameters. Here, we test what happens if we allow more than one functional form to describe the density profile of dark matter haloes. To account for the possibility that different clusters are described by different profiles we modify the total description length to include the information cost of assigning a specific function to each cluster. The total description length becomes: 

ğ¿ (ğ· ) =

> ğ‘

âˆ‘ï¸ 

> ğ‘ =1

ğ¿ ğ‘,ğ‘š (ğ‘ ) +âˆ‘ï¸ 

> ğ‘š âˆˆ M

Î¦ğ‘š + ğ¿ assign , (30) where ğ‘š (ğ‘ ) âˆˆ { 1, . . . , ğ‘€ } denotes the profile assigned to cluster ğ‘ ,and M is the set of ğ‘€ distinct profiles actually used in the sample. The per-cluster term ğ¿ ğ‘,ğ‘š is the residuals plus parameters contribution evaluated for cluster ğ‘ under profile ğ‘š , such that 

ğ¿ (ğ· )ğ‘,ğ‘š = âˆ’ log L( Ë†ğœƒ m) + ğ‘ ğ‘š log (2) + 

> ğ‘ ğ‘š

âˆ‘ï¸ 

> ğ‘–

log (| Ë†ğœƒ ğ‘š,ğ‘– |/ Î”(ğ‘ ) 

> ğ‘š,ğ‘–

).

(31) This is the same as the usual Eq. (15) just excluding the structural (function) penalty. The structural penalty is then counted once per distinct profile with the term Ã Î¦ğ‘š , where Î¦ğ‘š = ğ‘˜ Â·log ğ‘› +Ã ğ‘— log (ğ‘ ğ‘— )

as before (see Eq. (15)) and the sum is calculated over the ğ¾ unique profiles used across the sample. Finally, ğ¿ assign encodes the cost of communicating which cluster uses which profile, encoding the â€œlabelâ€ for each cluster. To minimise this cost, we use a coding scheme that assigns shorter binary labels to profiles that appear frequently in the population and longer labels  

> MNRAS 000 , 1â€“21 (2026)

# Symbolically regressing dark matter halo profiles using weak lensing 15 

to rare ones (Shannon 1948). Formally, let ğ‘› ğ‘š denote the number of clusters assigned to profile ğ‘š (where Ãğ‘š ğ‘› ğ‘š = ğ‘ ). If we assign a binary label of length ğ‘™ ğ‘š to profile ğ‘š , the total cost of transmitting the assignment vector for all ğ‘ clusters is 

ğ¿ assign =

> ğ¾

âˆ‘ï¸ 

> ğ‘š =1

ğ‘› ğ‘š ğ‘™ ğ‘š . (32) To ensure that a continuous string of these binary labels can be parsed into a unique sequence of profiles, we use a prefix-free code (MacKay 2003). This requirement imposes Kraftâ€™s inequality on the code lengths, given by Ã ğ‘’ âˆ’ğ‘™ ğ‘š â‰¤ 1 (Cover & Thomas 2006). Min-imising the total cost ğ¿ assign subject to this constraint gives the opti-mal Shannon code lengths, 

ğ‘™ ğ‘š = âˆ’ log (ğ‘› ğ‘š /ğ‘ ), (33) which essentially corresponds to using shorter codes for more fre-quent labels (Shannon 1948). This gives a total assignment cost of 

ğ¿ (ğ· )assign = âˆ’âˆ‘ï¸ 

> ğ‘š

ğ‘› ğ‘š log (ğ‘› ğ‘š /ğ‘ ). (34) This is zero if all clusters share one profile and increases as more profiles are added. It penalises models that require a more complex or less uniform assignment of profiles across clusters. With this scheme, we try the two alternatives: 

5.4.1 Per-cluster profile 

First, we test the â€œper-clusterâ€ assignment, where each of the ğ‘ = 149 

clusters is free to select its own functional form. Because each cluster contains only 9 radial data points, minimising the full description length on an individual basis tends to favour trivial solutions (i.e., 

ğœŒ = 0). To avoid this, we instead select the function that minimises the sum of the residuals and parameter costs for each cluster. This ensures that the fits remain penalised for unnecessary parameters, but prevents the selection from being driven entirely by the functional complexity term. Once each cluster has selected its preferred function, we calculate the total description length, including the costs of encoding the func-tional forms and the assignment vector. This approach yields a total description length of ğ¿ (ğ· ) = 1752 .27 , which is significantly worse than that of the best universal profile ( ğ¿ (ğ· ) = 840 .95 ), as shown in Table 4. Statistically, this model fails because the assignment cost ( ğ¿ assign )is extremely high ( 518 .71 nats). Given total freedom, the sample â€œfragmentsâ€ into ğ‘€ = 51 unique profiles. While the fit quality (the 

Ã ğ¿ (ğ· )ğ‘ğ‘š term) is better than for the universal profile â€“ as expected from the fact that we are choosing functions that minimise this quan-tity â€“ the functional cost from specifying different functions and the assignment term result is a worse total description length. Physically, this result is consistent with the expectation that dark matter haloes are largely self-similar. Enforcing a common profile increases the statistical power to constrain the functional form, which far outweighs the flexibility gained by fitting clusters independently. 

5.4.2 Two-profile mixture model 

A natural compromise between the universal model and the unre-stricted per-cluster assignment is to limit the flexibility to a small number of distinct profiles. In this scenario, we allow the sample to be described by a mixture of just two functions, where each cluster selects the best option from a pair of candidates. In practice, we test all possible pairs formed from the 20 best-performing functions listed in Table 1. For each pair, every cluster independently selects the function that minimises the sum of the residual and parameter costs. We then compute the total description length of the entire sample, including the structural costs of the two functions and the assignment entropy. The optimal pair identified by this search consists of the 2nd and 

3rd highest-ranked profiles from the universal analysis: 

ğœŒ 2 (ğ‘Ÿ ) = 1/( ğœƒ 0 (âˆ’ ğ‘Ÿ + | ğœƒ 1 |ğ‘Ÿ ğ‘Ÿ 

)) , ğœŒ 3 (ğ‘Ÿ ) = (| ğœƒ 0ğ‘Ÿ |ğ‘Ÿ Â· | ğœƒ 1 |) âˆ’ğ‘Ÿ .

Because these already dominate the ranking (and because the next-best pairs correspond to combinations of the top few functions) we do not expect lower-ranked functions to outperform this combination. It may seem counter-intuitive that the top-ranked universal profile is absent from this optimal pair, as it represents the best single-model compromise between accuracy and simplicity. However, inspection of Table 1, shows that the functions at ranks 2 and 3 offer comple-mentary advantages. The profile ğœŒ 2 has lowest parameter description length ( 204 .8) in the top set. Conversely, ğœŒ 3 has the lowest residuals (601 .3) and thus the highest likelihood. By partitioning the sample, the mixture model of these two profiles provides a better description length than including the rank 1 function. For the optimal pair, the total description length is ğ¿ (ğ· ) = 861 .71 .This is a massive improvement over the per-cluster model ( ğ¿ (ğ· ) =

1752 .27 ), but it is still worse than the single universal profile ( ğ¿ (ğ· ) =

840 .95 ). As expected, the Ã ğ¿ (ğ· )ğ‘ğ‘š term gives a better value than the best universal profile. However, this gain is outweighed by the penalties associated with the cost from having to specify two functional forms and encoding their assignments across the sample. In this case, ğœŒ 2 is selected by 62 clusters and ğœŒ 3 by 87 clusters, giving an assignment cost of ğ¿ assign = 101 .17 . Therefore, the single universal profile re-mains the simplest and statistically preferred description of the entire sample. This analysis could be extended in different ways. First, one could explore mixtures of three or more profiles ( ğ‘€ â‰¥ 3). Second, the optimisation strategy itself could be refined. Currently, we use this approach where each cluster selects the profile that minimises its local fit (residuals + parameters). A more rigorous approach would be to perform a global optimisation, searching for the specific as-signment of clusters to profiles that minimises the total mixed-model description length directly. However, given the dominance of the uni-versal profile and the rapidly increasing penalties for assignment and structure, these more complex models are unlikely to outperform the single-profile solution. 

6 DISCUSSION 6.1 Interpretation of the ESR results 

In this work, we have presented an empirical derivation of dark matter density profiles using ESR. One of our main findings is that when the data are allowed to choose from a broad range of profiles, NFW is not among the best-fitting models. We have found other two-parameter models (such as the analytically integrable profiles in Eq. (24) and Eq. (26)) that the data prefers. This shows that functions with only two free parameters are sufficient to describe the current data, while also suggesting that HSC-XXL weak-lensing data favour density profiles that deviate systematically from the standard NFW shape. Although data with a SNR or extended radial coverage might  

> MNRAS 000 , 1â€“21 (2026)

# 16 A. MartÃ­n et al.                                            

> Model Type Residuals + Parameters Function Cost Assignment Cost Total ğ¿ (ğ· )
> Ãğ¿ (ğ· )ğ‘ğ‘š
> ÃÎ¦ğ‘š ğ¿ assign
> Universal ( ğ‘€ =1)824.85 16.09 0.00 840.95
> Two profiles ( ğ‘€ =2)769.05 34.01 101.17 904.23 Per-Cluster ( ğ‘€ =51 )633.70 538.08 518.71 1752.27
> Table 4. Comparison of total description length for different profileâ€“assignment models. Here ğ‘€ denotes the number of distinct density profiles allowed in the model: ğ‘€ =1corresponds to a single universal profile shared by all clusters, ğ‘€ =2allows clusters to choose between two profiles, and ğ‘€ =51 is the perâ€“cluster model in which each cluster is free to select its own functional form. The table reports the contributions from the residuals + parameter terms, the structural (function) costs for all unique profiles used, and the assignment cost required to encode which clusters use which profile. All values are given in nats. The total description length is shown in the final column.

prefer more complex functional forms, two parameters are optimal by the MDL criterion for this weak lensing dataset. This raises the question whether the deviation from the NFW form is a property of the data or an artefact of the method. We addressed this in MartÃ­n et al. 2025, where we validated the method using synthetic clusters generated from an NFW profile. These mock clusters were modelled to closely resemble the HSC-XXL sample used here in radial sampling and mass distribution. Modelling the noise as a fractional uncertainty across the data, we tested different noise conditions and data quantities. Since ESR exhaustively explores the functional space up to the specified complexity, the NFW profile is always evaluated at complexity 9. The question, therefore, is whether the MDL metric correctly identifies it as the optimal function. We found that ESR reliably identifies NFW among the top ten functions even when the ESD measurements have fractional uncertainties as large as 80% (for searches up to complexity 9). This shows that the generating function is identifiable under the MDL framework even in the presence of substantial statistical noise, provided that the dominant systematics are properly accounted for. In contrast, when applying the methodology to the real cluster sample (and extending the search to complexity 10 ), the NFW pro-file is not found among the top-performing functions. Even if we restrict the analysis to complexity 9 and remove all complexity 10 

functions, the NFW profile ranks only 129 th, with a relative proba-bility (Eq. (22)) of ğ‘ƒ ( ğ‘“ ğ‘ ğ¹ğ‘Š |ğ· ) âˆ¼ 10 âˆ’24 . Consequently, the fact that NFW is highly ranked in controlled mocks but disfavoured in the real data strongly suggests that the true density profiles of these clusters do deviate from the NFW form. That said, the form of the preferred profiles and their physical origin must be interpreted with care. One possible interpretation is that the underlying dark-matter distribution may still resemble an NFW-like profile, but baryonic physics modifies the total mass density in ways that shift the preferred functional form away from pure NFW. For example, energetic AGN feedback can evacuate gas from the central regions of clusters, producing a depletion feature in the total mass profile (Popolo et al. 2019; Martizzi et al. 2013b; Arjona-GÃ¡lvez et al. 2024). Such processes could potentially generate structures similar to the central holes or turnovers seen in some of the best-fitting ESR models. However, it is important to take into account the intrinsic sensitivity of the data. The weak lensing data has a limited constraining power at small radii compared to cluster outskirts. Weak-lensing uncertainties decrease roughly as 1/ğ‘… due to the radial scaling of the source-galaxy shape noise. As a consequence, ESR naturally favours functions that perform well in the outer regions of clusters, where the data have smaller uncertainties. Given this, while baryonic modification could play a role, the lensing data alone cannot unambiguously attribute the observed functional differences to any specific physical process. We discuss this further in Section 6.3. A further strength of our approach is its transparency in the low-signal-to-noise regime. Standard single-profile fits can return appar-ently well-defined mass estimates even when the ESD measurements are statistically consistent with zero signal, because the posteriors are shaped largely by the assumed profile. In contrast, ESR correctly identifies such cases as unconstrained and consistent with a null density. 

6.2 Broader implications 

Galaxy clusters are among the most powerful cosmological probes as their abundance as a function of mass and redshift is sensitive to the amplitude of matter fluctuations ( ğœ 8) and the matter density (Î©m) (Allen et al. 2011). The constraining power of cluster abun-dance measurements, however, is limited by the accuracy of mass calibration (Vikhlinin et al. 2009; Rozo et al. 2010). Because cluster masses are not observed directly, survey analyses rely on observable proxies, such as X-ray luminosity, optical richness, or the Sunyaevâ€“ Zelâ€™dovich (SZ) signal (Pratt et al. 2009; Planck Collaboration 2016). To map these measurements to an underlying mass measurements, scaling relations between the survey observable and cluster mass must be carefully calibrated (Giodini et al. 2013; von der Linden et al. 2014b). Weak gravitational lensing is commonly used to calibrate this mass proxies, as it measures the total gravitating matter and is independent of the dynamical state of the cluster gas. Nevertheless, weak lensing analyses still rely on modelling assumptions, like the choice of a parametric density profile, which can introduce systematic biases if the assumed form does not adequately describe the true mass distribution. The potential biases introduced by profile mis-specifications have previously been investigated by simulations. For example, Becker & Kravtsov 2011 and von der Linden et al. 2014a demonstrated that fitting an NFW profile to more realistic, triaxial, or substructured halos typically results in a negative mass bias of approximately 5âˆ’10 

per cent. Here, we have shown how this systematic might also arise in obser-vational data. We computed ğ‘€ 200 using the best-fitting ESR functions and compared these estimates to the masses obtained from NFW fits. We find that the distribution of mass ratios log 10 (ğ‘€ mESR /ğ‘€ NFW ) has a median logarithmic offset of 0.17 dex, indicating that imposing an NFW fit can underestimate cluster masses (see Section 5.3). How-ever, we note that this offset is accompanied by substantial intrinsic scatter, with a broad 16thâ€“84th percentile range, indicating that the magnitude of the bias varies from cluster to cluster. If not accounted for, such profile-induced systematics could prop- 

> MNRAS 000 , 1â€“21 (2026)

# Symbolically regressing dark matter halo profiles using weak lensing 17 

agate into the halo mass function, biasing cluster abundance and clustering analyses (e.g. Vikhlinin et al. 2009; Tinker et al. 2008). This, in turn, affects inferred cosmological parameters, including ğœ 8

and Î©m (Allen et al. 2011). Cluster abundance measurements are also used to constrain extensions to the Î›CDM model, such as sum of the neutrino masses or the dark energy equation of state (Planck Collaboration 2020; Bocquet et al. 2019). These parameters affect the growth of the structure and, as such, are partially degenerate with uncertainties in the mass calibration. Halo mass also determines the halo bias that governs the large-scale clustering of galaxy clusters. Consequently, profile-induced mass biases can propagate into clustering and cross-correlation anal-yses (e.g. clusterâ€“galaxy or clusterâ€“CMB lensing correlations). Using a more model-agnostic approach to mass estimation also enables a self-consistent calibration at multiple overdensities. The NFW profile and other standard parametric models enforce a fixed relation between ğ‘€ 200 , ğ‘€ 500 and the underlying density profile by construction. ESR allows these quantities to be derived directly from the data, allowing self-consistent but not artificially constrained mass estimates across different radial ranges. Beyond mass calibration, enforcing a fixed parametric density pro-file can also bias inferences about cluster internal structure (Becker & Kravtsov 2011). Parametric fits implicitly impose specific relations between mass, concentration, and inner density slope, potentially masking real variations in cluster profiles (Dutton & MacciÃ² 2014; Umetsu 2020b). In contrast, more model-independent reconstruc-tions, such as ESR, provide a framework for identifying departures from standard parametric forms. This departures can be identified as signatures of baryonic processes (eg. feedback, gas cooling ...) that modify the underlying dark-matter distribution. This can help in separating the contributions from baryons and dark matter, and test feedback models that make predictions for how baryons reshape dark-matter haloes. More broadly, by not enforcing a specific dark matter model, ESR can help constrain the nature of dark matter itself. The NFW profile is derived from Cold Dark Matter (CDM) simulations, while model-independent methods can help identify non-CDM features, such as extended cores predicted by Self-Interacting Dark Matter (SIDM; Spergel & Steinhardt 2000; Rocha et al. 2013). While we do not attempt to distinguish between dark matter models in this work, we see that ESR-preferred functions seem to prefer shallower inner profiles which highlight the importance of allowing such features to be identified instead of excluded by construction. Model-independent reconstructions may also enable the identifi-cation of other halo features not captured by NFW-like profiles, such as the splashback radius (Diemer & Kravtsov 2014; More et al. 2015), when applied to data with sufficient radial coverage and signal-to-noise. 

6.3 Methodological caveats and extensions 

6.3.1 ESR and algorithmic improvements 

There are only two degrees of freedom in ESR. One relates to the choice of operators used in the search. Here, we have used a mini-mal set of basic operators: {ğ‘¥, ğ‘, inv , exp , log , +, Ã—, âˆ’, /, power }. One could, in principle, extend this set by including additional operators. Nevertheless, all the commonly used dark matter profiles that we tested can be constructed from this operator set. Therefore, the cho-sen basis is sufficient for comparing these models to alternative func-tional forms, even though yet-better functions may be constructed using operators that we do not consider. Nonetheless, it is interesting to consider how ESR could be ex-tended to reach higher complexities. A fully exhaustive search at these levels is computationally prohibitive with the current algo-rithm. Instead, one possible approach is to use a stochastic search, seeded with the functions found by ESR. Alternatively, a determinis-tic approach could be used to systematically explore functions in the neighbourhood of those already found by ESR. By systematically adding operators to the high-performing functions already identi-fied, this approach focuses on a targeted region of function space that is more likely to contain well-fitting profiles. In this way, the exploration remains â€œexhaustiveâ€ within this relevant region, as all reasonable extensions of the best functions are considered, rather than relying on purely random sampling. Regarding parameter optimisation, we employed a combination of optimisation methods to balance accuracy and computational cost. For functions above complexity 6, we first optimised all candidates for a small subset of clusters, identified the best-performing expressions, and then optimised only this refined set across the full sample. In other words, we targeted the most promising functions rather than exhaustively optimising every candidate. As detailed in Section 4.2,we verified that this strategy was sufficient to identify the best-fitting profiles by confirming that the selected functions included a large number of high-performing models, and that those excluded were suboptimal. To ensure robustness, we repeated optimisations using multiple initial conditions and confirmed that the global minimum was consistently recovered. Other parameter-optimisation strategies could also be incorpo-rated into ESR in future work. For example, global optimisation algorithms such as Differential Evolution (Storn & Price 1997), Simulated Annealing (Kirkpatrick et al. 1983), or Particle Swarm Optimisation (Kennedy & Eberhart 1995) provide efficient ways of exploring multi-modal likelihood surfaces and could complement the current optimisation scheme. 

6.3.2 Extensions and systematics in cluster analysis 

Another important consideration is the treatment of systematics in the data. In this work we effectively model the total mass profile within the radial range probed, implicitly assuming that the bary-onic contribution is small compared to the dark matter component. This is justified for cluster-scale weak-lensing analyses, where the baryonic massâ€”arising primarily from the BCG and the intracluster mediumâ€”is typically subdominant at radii ğ‘… â‰³ 100 kpc, contribut-ing around 1/6th of the total mass. (Umetsu 2020a). Nevertheless, baryons can be modelled explicitly using auxiliary data (Beauch-esne et al. 2025; Allingham et al. 2024) and added to the modelling scheme. An alternative option to this is simply to interpret the ESR-derived profiles as total mass profiles, without attempting to separate dark matter and baryons. Similarly, we have assumed that the two-halo term can be ignored at the scales studied following Umetsu et al. (2020). They found the two-halo termâ€™s contribution to the stacked ESD profile to be negligible across their entire radial range (see their Fig. 4). Even at their outermost datapoint ( ğ‘… â‰ˆ 3 â„âˆ’1Mpc), the two-halo term remained roughly an order of magnitude smaller than the fitted one-halo component. Since our analysis uses the same data and reaches comparable scales, this approximation is well justified. Beyond this empirical motivation, there is also a more fundamental methodological consideration: standard implementation of the two halo-term assume a Î›CDM population with an NFW density profile and a massâ€“concentration relation calibrated on simulations. Given that the goal of this work is to infer dark matter density profiles  

> MNRAS 000 , 1â€“21 (2026)

# 18 A. MartÃ­n et al. 

directly from the data, adopting a two-halo term computed under NFW assumptions would be inconsistent. In principle, one could compute a self-consistent two-halo term for each candidate profile, but this would be computationally expensive. In the near-term, the most practical option would be to test the stability of the preferred profiles against the radial range of the data (e.g., by re-fitting with the outermost bins removed). Our model also relies on two other standard simplifying assump-tions that could be expanded upon in future work. First, we assume spherical symmetry for the clusters. Incorporating triaxiality as a free parameter within ESR could provide a more realistic description of cluster shapes. Second, we assume that the cluster centre is known. In practice, the true centre can be uncertain, and misentering can affect the inferred inner profile. In the southern XXL field, where a BCG catalogue is available, we tested centring on the BCG instead of the X-ray peak and found that this did not remove the dips observed towards the centre of the ESD profiles in many clusters. ESR could naturally incorporate the cluster centre as an additional parameter, constrained by informative priors from X-ray, optical, or SZ obser-vations. Relaxing these assumptions would provide a more flexible modelling framework and can improve the fidelity of the inferred profiles when higher quality-data becomes available. 

6.4 Comparison to literature 

There have been other attempts to discover density profiles without reliance on the NFW model. In the observational domain, several studies have tried to recover mass density profiles directly from data. For example, a number of works have focused on moving beyond fixed analytic profiles by using non-parametric or semi-parametric techniques. These include the free-form radial reconstructions (e.g., Johnston et al. 2007b; Mistele & Durakovic 2024), which move be-yond fixed analytic assumptions by allowing the data to determine the profile shape. Interestingly, such reconstructions often give enclosed-mass estimates that are close to those obtained from standard NFW fits (Mistele et al. 2025). We find a similar behaviour here, with ESR masses being on average slightly higher than NFW-derived masses. That said, our analysis is sufficiently precise to reveal clearly that NFW is not the best profile. A key advantage of these non-parametric methods is their com-putational efficiency which makes them significantly cheaper to run than the exhaustive search performed by ESR. However, while they minimise modelling assumptions, they result in binned numerical estimates rather than closed-form analytic expressions. As such, they lack the ability to extrapolate the density profile beyond the radial range of the data, which is a unique advantage of the symbolic re-gression approach presented here. Furthermore, these methods often require specific binning choices or regularisation schemes that can be difficult to interpret physically, and it would be difficult to inte-grate them into cosmological analyses which assume analytic forms for cluster halo density profiles. Having a functional form is clearly useful for summarising the dark matter distribution within a larger analysis. Beyond these profile-modelling efforts, other work has focused on cluster mass calibration by bypassing the density profile entirely and learning a direct mapping from weak-lensing maps to halo mass. For instance, Gupta et al. (2018) used Convolutional Neural Networks (CNNs) to infer cluster masses from weak-lensing maps, achieving high predictive accuracy. However, these â€œblack boxâ€ approaches function as non-linear calibrators for the specific simulation physics they were trained on. They implicitly assume the halo structure fol-lows the standard Î›CDM predictions rather than testing the validity of those predictions. While they excel at parameter estimation (e.g., 

ğ‘€ 200 ), they do not provide a mathematical description of the halo structure itself. Finally, a number of recent studies have focused on learning the mapping between haloes and their density profiles using ğ‘ -body simulations. These approaches aim to link the final density field to the haloesâ€™ evolutionary histories. For example, Lucie-Smith et al. (2022a,b) used deep neural networks and autoencoders to compress latent representations of density profiles. This approach performs a dimensionality reduction trying to find the minimal latent compo-nents to describe a halo. This is conceptually similar to minimising an information criterion, as we do with the MDL metric, though it primarily optimises the number of describing variables rather than the complexity of the functional form itself. Building on this, Lucie-Smith et al. (2024) investigated which features of the mass accretion history most strongly influence the final shape of the profile. However, while a trained neural network technically constitutes a closed-form mathematical function (composed of matrix operations), it remains a â€œblack boxâ€ containing thousands of parameters. Unlike the sym-bolic expressions we derive, these networks do not output simple, interpretable analytic formulae. Within the specific context of symbolic regression, Thing & Koksbang (2025) recently presented a comprehensive benchmark of symbolic regression algorithms applied to synthetic cosmologi-cal datasets, including dark matter halo profiles. Their results high-lighted that while data-driven algorithms can successfully recover profile shapes (such as NFW or cored models) from high-precision data, they are sensitive to noise and data quality. Our analysis differs from this in both scope and application. While Thing & Koksbang (2025) assessed the ability of heuristic algorithms to locate the NFW functional form within a vast search space, we use an exhaustive search (ESR) on observational data. Since ESR explicitly evaluates every function up to complexity 10 , the NFW profile is by defini-tion included as a possible model. Consequently, the question is not whether the algorithm succeeds in considering and evaluating NFW (an issue of reliability of the algorithm), but rather whether or not NFW scores highly (an issue with the data and its error model). Our finding that NFW is not the preferred model represents a robust sta-tistical rejection based on the data, rather than a failure of the search algorithm to locate the function. 

6.5 Future applications and datasets 

A natural next step is to apply this method to upcoming weak-lensing datasets that offer higher signal-to-noise ratios or larger sample sizes. Surveys such as the Dark Energy Survey (DES; Abbott et al. 2018), 

Euclid (Laureijs et al. 2011) or CLASH (Postman et al. 2012), could provide more stringent constraints on halo profiles and allow a direct comparison with the HSCâ€“XXL results. Such data would also test whether the functional forms identified here are stable across different cluster samples observed with different instruments and depth. There is no need to limit ourselves to data coming from WL. The framework presented here can be applied to any dataset that con-strains the radial distribution of dark matter in galaxies or galaxy clusters. The core idea is simple: use symbolic regression to gen-erate candidate expressions for the density profile ğœŒ (ğ‘Ÿ ), compute the corresponding observables and rank the models using the MDL principle. Kinematic data, such as galactic rotation curves from the SPARC database (Lelli et al. 2016) or integral-field spectroscopy from MaNGA (Bundy et al. 2015), would provide powerful complemen-tary constraints. These data are highly sensitive to the small galactic  

> MNRAS 000 , 1â€“21 (2026)

# Symbolically regressing dark matter halo profiles using weak lensing 19 

radii ( ğ‘Ÿ â‰² 0.1 Mpc) that WL cannot constrain. This is particularly relevant to our finding that the HSC dataâ€™s inner profile is uncon-strained due to large ESD errors. Other multi-wavelength probes, such as X-ray or SZ observations of the intracluster medium, could also be studied independently. Moreover, combining different datasets is straightforward. ESR naturally accounts for differences in the number of data points and measurement precision; one simply needs to combine the description lengths from each probe, in a similar way to what was done here for multiple galaxy clusters, to perform a joint analysis. Another interesting direction is to study profile evolution with redshift. By applying ESR to cluster samples split into redshift bins, one could test whether the preferred functional forms evolve with cosmic time. Finally, ESR can be directly applied to simulations. Since NFW itself comes from ğ‘ -body simulations, it would be interesting to test whether ESR recovers NFW or identifies alternative functional forms already in simulated data and to compare these to the profiles preferred by observations. Such a comparison could also help under-stand where baryonic physics or other effects may drive differences between dark matter-only simulations and reality. 

7 CONCLUSIONS 

The NFW profile has long served as the standard model for de-scribing dark matter halos, but it remains a phenomenological fit to simulation data rather than a theory-driven prediction or empirically favoured function. In this work, we apply Exhaustive Symbolic Re-gression (ESR) to derive dark matter density profiles directly from observations. In particular, we apply the method to the HSCâ€“XXL dataset of 149 galaxy clusters. This enables a data-driven exploration of possible halo profiles without imposing a fixed parametric form. Our conclusions are as follows: 

â€¢ ESR discovers functions that statistically outperform common dark matter profiles (e.g., NFW, Einasto, Burkert) in terms of both accuracy and simplicity. Notably, the data favour functions with only two free parameters. Profiles requiring more parameters are gener-ally penalised by the MDL metric, suggesting that the current weak lensing data cannot robustly constrain more than two structural pa-rameters. We specifically highlight two analytically integrable pro-files that outperform NFW: the exponential decay with a central hole given in Eq. (24) and the cuspy profile presented in Eq. (26). 

â€¢ The weak lensing data we use primarily constrain the outer halo, leaving the inner profile poorly constrained. Due to the weak-lensing shape noise decaying roughly as 1/ğ‘… for radial bins, the data naturally prefer fitting functions that fit well on the outer range of the data. 

â€¢ Despite the limited inner sensitivity, ESR consistently selects profiles with shallow central behaviour and a maximum in the ESD within the range of the data. The radius at which the maximum appears varies across clusters, shifting inward for high-SNR systems and outward for lower SNR clusters. For these low-SNR systems, the inner measurements are consistent with zero, so any non-trivial features in the ESD are only required at larger radii. 

â€¢ We used the best-fitting ESR models to calculate the enclosed mass of the clusters ( ğ‘€ 200 ). These are inferred by averaging over the ensemble of high-performing ESR functions and give physically reasonable values that are largely consistent with standard NFW results although a bit higher on average. 

â€¢ We used the best-fitting ESR functions to infer cluster masses (ğ‘€ 200 ) by marginalising over profile shape. These ESR-derived masses are broadly consistent in trend with NFW estimates, but are systematically higher on average. The median logarithmic mass ratio is 0.17 dex, which would imply that NFW underestimates masses by 

â‰ˆ 48% relative to ESR. Although the distribution is broad (16thâ€“ 84th percentile range of [âˆ’ 0.52 , 1.10 ] dex), this shows that using the wrong profile can introduce bias in mass inferences. 

â€¢ We tested whether allowing different clusters to adopt different functional is statistically preferred to having a universal profile. We tried both allowing for a different profile per-cluster and allowing each cluster to choose between just two profiles. Allowing multiple models performs worse in description length than a single universal profile due to the penalties associated with specifying multiple functions and encoding their assignments. This is consistent with the expected self-similarity of cluster haloes. 

â€¢ The ESR framework is readily applicable to any other dataset that constrains the full distribution of matter, including constraints from galaxy kinematics, X-ray observables, the thermal SZ effect and multi-wavelength combinations. Studying these complementary probes would help better constrain the inner regions of clusters and galaxies and test whether the structural features that we see here remain preferred. 

â€¢ Our results depend on the maximum complexity of the functions considered. Here, we have used ESR to complexity 10 . Future devel-opments in symbolic regression could extend this search to higher complexities, helping to determine whether the features identified here persist as the optimal profiles or whether the true minimum of the description length (maximum of the posterior probability) lies at higher complexity. ESR provides a flexible and fully data-driven framework for de-riving, comparing, and interpreting dark matter halo profiles. By re-placing fixed analytic assumptions with a systematic function search governed by MDL, it offers a powerful approach for connecting ob-servations to empirical models of dark matter structure. 

ACKNOWLEDGEMENTS 

We thank Gary Mamon, Richard Stiskalek and Keiichi Umetsu for useful discussions. AM acknowledges support financial support for a DPhil stu-dentship from the Department of Physics at Oxford. TY ac-knowledges the support of a UKRI Frontiers Research Grant [EP/X026639/1], which was selected by the European Research Council. DJB was supported by the Simons Collaboration on â€œLearn-ing the Universeâ€ and is supported by Schmidt Sciences through The Eric and Wendy Schmidt AI in Science Fellowship. HD is sup-ported by a Royal Society University Research Fellowship (grant no. 211046). PGF acknowledges support from STFC and the Beecroft Trust. This work used the Glamdring cluster at the University of Oxford. Additionally, we used resources provided by the Cambridge Ser-vice for Data Driven Discovery (CSD3) operated by the University of Cambridge Research Computing Service (www.csd3.cam.ac.uk), provided by Dell EMC and Intel using Tier-2 funding from the En-gineering and Physical Sciences Research Council (capital grant EP/P020259/1), and DiRAC funding from the Science and Tech-nology Facilities Council (www.dirac.ac.uk). 

DATA AVAILABILITY 

The data underlying this article will be shared on reasonable request to the corresponding author.  

> MNRAS 000 , 1â€“21 (2026)

# 20 A. MartÃ­n et al. 

REFERENCES 

Abbott T. M. C., et al., 2018, Phys. Rev. D, 98, 043526 Abbott T. M. C., et al., 2020, Phys. Rev. D, 102, 023509 Adami C., Giles P., Koulouridis et al., 2018, Astronomy & Astrophysics, 620, A5 Aihara H., et al., 2018, PASJ, 70, S8 Allen S. W., Evrard A. E., Mantz A. B., 2011, ARA&A, 49, 409 Allingham J. F. V., et al., 2024, Monthly Notices of the Royal Astronomical Society, 528, 1711â€“1736 Arjona-GÃ¡lvez E., Di Cintio A., Grand R. J. J., 2024, Astronomy &amp; Astrophysics, 690, A286 Banik U., Bhattacharjee A., 2025, arXiv preprint arXiv:2506.02104 Bartelmann M., Schneider P., 2001, Physics Reports, 340, 291â€“472 Bartlett D. J., Desmond H., 2023, The Open Journal of Astrophysics, 6, 42 Bartlett D., Desmond H., Ferreira P., 2023, in Proceedings of the Companion Conference on Genetic and Evolutionary Computation. pp 2402â€“2411 Bartlett D. J., Desmond H., Ferreira P. G., 2024, IEEE Trans. Evol. Computat., 28, 950 Beauchesne B., et al., 2025, A comprehensive separation of dark matter and baryonic mass components in galaxy clusters I: Mass constraints from Abell S1063 ( arXiv:2509.07762 ), https://arxiv.org/abs/2509. 07762 

Becker M. R., Kravtsov A. V., 2011, The Astrophysical Journal, 740, 25 Blanchard A., IliÄ‡ S., 2021, Astronomy &amp; Astrophysics, 656, A75 Blumenthal G. R., Faber S. M., Flores R., Primack J. R., 1986, ApJ, 301, 27 Bocquet S., et al., 2019, The Astrophysical Journal, 878, 55 Bradbury J., et al., 2018, JAX: composable transformations of Python+NumPy programs, http://github.com/google/jax 

Broyden C. G., 1970, IMA Journal of Applied Mathematics, 6, 76 Bundy K., et al., 2015, ApJ, 798, 7 Burkert A., 1995, The Astrophysical Journal, 447 Chan M. H., DelPopolo A., 2020, Monthly Notices of the Royal Astronomical Society, 492, 5865â€“5869 Corless V. L., King L. J., 2007, Monthly Notices of the Royal Astronomical Society, 380, 149 Cover T. M., 1999, Elements of information theory. John Wiley & Sons Cover T. M., Thomas J. A., 2006, Elements of Information Theory, 2nd edn. Wiley, Hoboken, NJ Crain R. A., et al., 2015, Monthly Notices of the Royal Astronomical Society, 450, 1937 Cranmer M., 2020, Pysr: Fast & parallelized symbolic regression in python/julia, http://doi.org/10.5281/zenodo.4041459 

Cromer D., Battaglia N., Miyatake H., Simet M., 2022, J. Cosmology As-tropart. Phys., 2022, 034 Delos M. S., 2025, arXiv preprint arXiv:2506.03240 Delos M. S., Bruff M., Erickcek A. L., 2019, Physical Review D, 100, 023523 Desmond H., Bartlett D. J., Ferreira P. G., 2023, Mon. Not. R. Astron. Soc., 521, 1817 Diemand J., Kuhlen M., Madau P., 2007, The Astrophysical Journal, 667, 859 Diemer B., Kravtsov A. V., 2014, ApJ, 789, 1 Dubinski J., Carlberg R., 1991, Astrophysical Journal, Part 1 (ISSN 0004-637X), vol. 378, Sept. 10, 1991, p. 496-503. Research supported by Pittsburgh Supercomputing Center and NSERC., 378, 496 Dutton A. A., MacciÃ² A. V., 2014, MNRAS, 441, 3359 Einasto J., 1965, Trudy Astrofizicheskogo Instituta Alma-Ata, 5, 87 Evans N. W., An J. H., 2006, Phys. Rev. D, 73, 023524 Feynman R. P., 1963, (No Title), 1, 46 Fletcher R., 1970, The Computer Journal, 13, 317 Flores R. A., Primack J. R., 1994, ApJ, 427, L1 Freundlich J., et al., 2020, MNRAS, 499, 2912 Gao L., Navarro J. F., Cole S., Frenk C. S., White S. D. M., Springel V., Jenkins A., Neto A. F., 2008, Monthly Notices of the Royal Astronomical Society, 387, 536â€“544 Gelman A., Rubin D. B., 1992, Statistical Science, 7, 457 Giodini S., Lovisari L., Pointecouteau E., Ettori S., Reiprich T. H., Hoekstra H., 2013, Space Sci. Rev., 177, 247 Goldberg D. E., 1994, Communications of the ACM, 37, 113 Goldfarb D., 1970, Mathematics of Computation, 24, 23 Gruen D., Seitz S., Becker M., Friedrich O., Mana A., 2015, Monthly Notices of the Royal Astronomical Society, 449, 4264 GrÃ¼nwald P. D., 2007, The minimum description length principle. MIT press GrÃ¼nwald P. D., Roos T., 2019, International journal of mathematics for industry, 11, 1930001 GuimerÃ  R., Reichardt I., Aguilar-Mogas A., Massucci F. A., Miranda M., PallarÃ¨s J., Sales-Pardo M., 2020, Science Advances, 6, eaav6971 Gupta A., Reichardt C. L., Benson B. A., 2018, The Astrophysical Journal, 862, 22 Hirata C., Seljak U., 2003, Monthly Notices of the Royal Astronomical Soci-ety, 343, 459 Hoekstra H., 2003, Monthly Notices of the Royal Astronomical Society, 339, 1155 Hoekstra H., Herbonnet R., Muzzin A., Babul A., Mahdavi A., Viola M., Cacciato M., 2015, Monthly Notices of the Royal Astronomical Society, 449, 685â€“714 Hoffman M. D., Gelman A., 2014, in Journal of Machine Learning Research. pp 1593â€“1623 Johnston D. E., et al., 2007a, arXiv e-prints Johnston D. E., et al., 2007b, Cross-correlation Weak Lensing of SDSS galaxy Clusters II: Cluster Density Profiles and the Massâ€“Richness Relation (arXiv:0709.1159 ), https://arxiv.org/abs/0709.1159 

Kaiser N., Squires G., Broadhurst T., 1995, The Astrophysical Journal, 449, 460 Katz S., 2003, IEEE transactions on acoustics, speech, and signal processing, 35, 400 Kennedy J., Eberhart R., 1995, in Proceedings of IEEE International Confer-ence on Neural Networks. pp 1942â€“1948 Keren L. S., Liberzon A., Lazebnik T., 2023, Scientific Reports, 13, 1249 Kim S., Lu P. Y., Mukherjee S., Gilbert M., Jing L., ÄŒeperiÄ‡ V., SoljaÄiÄ‡ M., 2020, IEEE transactions on neural networks and learning systems, 32, 4166 Kirkpatrick S., Gelatt C., Vecchi M., 1983, Science, 220, 671 Koza J. R., 1992, Genetic Programming: On the Programming of Computers by Means of Natural Selection. MIT Press, Cambridge, MA Kravtsov A. V., Borgani S., 2012, ARA&A, 50, 353 Kronberger G., Burlacu B., Kommenda M., Winkler S. M., Affenzeller M., 2024a, Symbolic Regression. Chapman & Hall / CRC Press Kronberger G., Olivetti de Franca F., Desmond H., Bartlett D. J., Kammerer L., 2024b, in Affenzeller M., Winkler S. M., Kononova A. V., Trautmann H., TuÅ¡ar T., Machado P., BÃ¤ck T., eds, Parallel Problem Solving from Nature â€“ PPSN XVIII. Springer Nature Switzerland, Cham, pp 273â€“289 La Cava W., Burlacu B., Virgolin M., et al., 2021, Advances in neural infor-mation processing systems, 2021, 1 Laporte C. F., White S. D., Naab T., Ruszkowski M., Springel V., 2012, Monthly Notices of the Royal Astronomical Society, 424, 747 Lau E. T., Kravtsov A. V., Nagai D., 2009, The Astrophysical Journal, 705, 1129 Laureijs R., et al., 2011, arXiv e-prints Lelli F., McGaugh S. S., Schombert J. M., 2016, The Astronomical Journal, 152, 157 Lucie-Smith L., Peiris H. V., Pontzen A., Nord B., Thiyagalingam J., Piras D., 2022a, Physical Review D, 105 Lucie-Smith L., Adhikari S., Wechsler R. H., 2022b, Monthly Notices of the Royal Astronomical Society, 515, 2164â€“2177 Lucie-Smith L., Peiris H. V., Pontzen A., 2024, Phys. Rev. Lett., 132, 031001 Ludlow A. D., et al., 2013, Monthly Notices of the Royal Astronomical Society, 432, 1103â€“1113 MacKay D. J. C., 2003, Information Theory, Inference, and Learning Algo-rithms. Cambridge University Press, Cambridge, UK Mandelbaum R., Miyatake H., Hamana T., Lanusse F., Leauthaud A., et al., 2018a, Publications of the Astronomical Society of Japan, 70, S25 Mandelbaum R., Lanusse F., Leauthaud A., et al., 2018b, Monthly Notices of the Royal Astronomical Society, 481, 3170 Martizzi D., Teyssier R., Moore B., 2013a, Monthly Notices of the Royal Astronomical Society, 432, 1947 Martizzi D., Teyssier R., Moore B., 2013b, Monthly Notices of the Royal MNRAS 000 , 1â€“21 (2026) Symbolically regressing dark matter halo profiles using weak lensing 21 

Astronomical Society, 432, 1947 MartÃ­n A., Yasin T., Bartlett D. J., Desmond H., Ferreira P. G., 2025, Constraining dark matter halo profiles with symbolic regression (arXiv:2511.23073 ), https://arxiv.org/abs/2511.23073 

Medezinski E., Battaglia N., Umetsu K., et al., 2018, Publications of the Astronomical Society of Japan, 70, S28 Merritt D., Navarro J. F., Ludlow A., Jenkins A., 2005, The Astrophysical Journal, 624, L85â€“L88 Merritt D., Graham A., Moore B., Diemand J., TerziÄ‡ B., 2006, The Astro-nomical Journal, 132, 2685â€“2700 Mistele T., Durakovic A., 2024, The Open Journal of Astrophysics, 7 Mistele T., Lelli F., McGaugh S., Schombert J., Famaey B., 2025, The Open Journal of Astrophysics, 8 Miyaoka K., et al., 2018, Publications of the Astronomical Society of Japan, 70, S22 Miyatake H., et al., 2019, The Astrophysical Journal, 875, 63 Moore B., 1994, Nature, 370, 629 Moore B., Governato F., Quinn T., Stadel J., Lake G., 1998, The Astrophysical Journal, 499, L5 More S., Diemer B., Kravtsov A. V., 2015, ApJ, 810, 36 Murray C., Bartlett J. G., Artis E., Melin J.-B., 2022, MNRAS, 512, 4785 Navarro J. F., Frenk C. S., White S. D., 1997, The Astrophysical Journal, 490, 493 Navarro J. F., Hayashi E., Power C., et al., 2004, Monthly Notices of the Royal Astronomical Society, 349, 1039 Navarro J. F., et al., 2010, Monthly Notices of the Royal Astronomical Society, 402, 21 Neal R. M., 2011, in Brooks S., Gelman A., Jones G., Meng X.-L., eds, , Handbook of Markov Chain Monte Carlo. Chapman & Hall / CRC Nelder J. A., Mead R., 1965, The computer journal, 7, 308 Newman A. B., Treu T., Ellis R. S., Sand D. J., 2011, The Astrophysical Journal Letters, 728, L39 Nocedal J., Wright S., 2006, Numerical Optimization, 2 edn. Springer Peirani S., et al., 2017, Monthly Notices of the Royal Astronomical Society, 472, 2153 Petersen B. K., Landajuela M., Mundhenk T. N., Santiago C. P., Kim S. K., Kim J. T., 2019, arXiv preprint arXiv:1912.04871 Phan D., Pradhan N., Jankowiak M., 2019, arXiv preprint arXiv:1912.11554 Planck Collaboration 2016, Astron. Astrophys., 594, A24 Planck Collaboration 2020, Astronomy & Astrophysics, 641, A6 Pontzen A., Governato F., 2013, Monthly Notices of the Royal Astronomical Society, 430, 121 Popolo A. D., Delliou M. L., Lee X., 2019, Correlations in the matter distribution in CLASH galaxy clusters ( arXiv:1808.02136 ), https: //arxiv.org/abs/1808.02136 

Postman M., Coe D., BenÃ­tez N., et al. 2012, The Astrophysical Journal Supplement Series, 199, 25 Pratt G. W., Croston J. H., Arnaud M., BÃ¶hringer H., 2009, A&A, 498, 361 Ragagnin A., Meneghetti M., Calura F., Despali G., Dolag K., Fischer M. S., Giocoli C., Moscardini L., 2024, Astronomy &amp; Astrophysics, 687, A270 RenÃ© BrolÃ¸s K., Vieira Machado M., Cave C., Kasak J., Stentoft-Hansen V., Galindo Batanero V., Jelen T., Wilstrup C., 2021, arXiv e-prints, pp arXivâ€“2104 Rissanen J., 1978, Automatica, 14, 465 Rocha M., Peter A. H. G., Bullock J. S., Kaplinghat M., Garrison-Kimmel S., OÃ±orbe J., Moustakas L. A., 2013, Monthly Notices of the Royal Astronomical Society, 430, 81â€“104 Rozo E., et al., 2010, ApJ, 708, 645 Russeil E., et al., 2024, in Proceedings of GECCO 2024. https://arxiv. org/abs/2402.04298 

Russeil E., de FranÃ§a F. O., Malanchev K., Moinard G., Cherrey M., 2025, arXiv e-prints Sand D. J., Treu T., Ellis R. S., 2002, The Astrophysical Journal, 574, L129 Schmidt M., Lipson H., 2009, Science, 324, 81 Sen Fong K., Motani M., 2024, in Proceedings of AISTATS 2024. https:// proceedings.mlr.press/v238/sen-fong24a/sen-fong24a.pdf 

Shanno D. F., 1970, Mathematics of Computation, 24, 647 Shannon C. E., 1948, Bell System Technical Journal, 27, 379 Sorini D., Bose S., Pakmor R., Hernquist L., Springel V., Hadzhiyska B., HernÃ¡ndez-Aguayo C., Kannan R., 2025, Monthly Notices of the Royal Astronomical Society, 536, 728 Sousa T., Bartlett D. J., Desmond H., Ferreira P. G., 2024, Phys. Rev. D, 109, 083524 Spergel D. N., Steinhardt P. J., 2000, Physical review letters, 84, 3760 Storn R., Price K., 1997, Journal of Global Optimization, 11, 341 Tenachi W., Ibata R., FranÃ§ois T. L., Diakogiannis F. I., 2024, Astrophysical Journal Letters Thing M., Koksbang S., 2025, Journal of Cosmology and Astroparticle Physics, 2025, 040 Tian Y., Umetsu K., Ko C.-M., Donahue M., Chiu I.-N., 2020, The Astro-physical Journal, 896, 70 Tian Y., Ko C.-M., Li P., McGaugh S., Poblete S. L., 2024, Astronomy &amp; Astrophysics, 684, A180 Tinker J., Kravtsov A. V., Klypin A., Abazajian K., Warren M., Yepes G., GottlÃ¶ber S., Holz D. E., 2008, The Astrophysical Journal, 688, 709â€“728 Turing A. M., 1950, Mind, 59, 433 Udrescu S.-M., Tegmark M., 2020, Science Advances, 6, eaay2631 Umetsu K., 2020a, A&ARv, 28, 7 Umetsu K., 2020b, A&ARv, 28, 7 Umetsu K., Zitrin A., Gruen D., Merten J., Donahue M., Postman M., 2016, The Astrophysical Journal, 821, 116 Umetsu K., et al., 2020, ApJ, 890, 148 Valipour M., You B., Panju M., Ghodsi A., 2021, arXiv preprint arXiv:2106.14131 Vikhlinin A., et al., 2009, Astrophys. J., 692, 1060 Zeng Z. C., et al., 2025, Till the core collapses: the evolution and properties of self-interacting dark matter subhalos ( arXiv:2310.09910 ), https: //arxiv.org/abs/2310.09910 

de Blok E., McGaugh S., Rubin V., 2001, arXiv e-prints, pp astroâ€“ph/0107366 von der Linden A., et al., 2014a, MNRAS, 439, 2 von der Linden A., et al., 2014b, Monthly Notices of the Royal Astronomical Society, 443, 1973â€“1978 This paper has been typeset from a TEX/L ATEX file prepared by the author. MNRAS 000 , 1â€“21 (2026)