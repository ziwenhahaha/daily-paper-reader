Title: Discovering the Gell-Mann-Okubo Formula with Kolmogorov-Arnold Networks

URL Source: https://arxiv.org/pdf/2601.01495v1

Published Time: Tue, 06 Jan 2026 02:02:32 GMT

Number of Pages: 10

Markdown Content:
# Discovering the Gell-Mann–Okubo Formula with Kolmogorov-Arnold Networks 

Jian-Yao He, 1 Xun Chen, 1, 2, ∗ Xiao-Yan Zhu, 3, † and Wen Luo 1, ‡

> 1

School of Nuclear Science and Technology, University of South China Hengyang, No 28, West Changsheng Road, Hengyang City, Hunan Province, China. 

> 2

INFN – Istituto Nazionale di Fisica Nucleare – Sezione di Bari, Via Orabona 4, 70125 Bari, Italy 

> 3

School of Mathematics and Physics, University of South China, No. 28, West Changsheng Road, Hengyang City, Hunan Province, China. 

Uncovering physical laws from experimental data is a fundamental goal of theoretical physics. In this work, we apply the spline-based, interpretable Kolmogorov–Arnold Network (KAN) to ex-plore the algebraic structure underlying the baryon octet and decuplet mass spectra. Within a symbolic regression framework and without imposing theoretical priors, KAN autonomously re-covers the classical Gell-Mann–Okubo mass relations and accurately extracts the associated SU(3) symmetry-breaking parameters. Compared to conventional fitting approaches, this method achieves comparable predictive accuracy while offering substantially improved interpretability and analytic transparency. Our results demonstrate the potential of KAN as a powerful tool for symbolic dis-covery in hadron physics and for bridging data-driven modeling with fundamental physical laws. 

Introduction: Within the Standard Model, hadrons— composite particles made of quarks bound by the strong interaction—are described by Quantum ChromoDynam-ics (QCD). As a non‑Abelian gauge theory, QCD success-fully accounts for phenomena such as color confinement and asymptotic freedom [1–9], yet its non‑perturbative regime, which dominates the hadron spectrum, remains analytically challenging. Even so, the hadron mass spec-trum exhibits patterns that reflect the underlying SU(3) flavor symmetry [10–12]. In the 1960s, Gell‑Mann and Ne’eman introduced the Eightfold Way classification, or-ganizing the rapidly expanding set of experimentally dis-covered hadrons into octets and decuplets according to symmetry principles [10–12]. This framework indirectly led to the quark model, in which baryons and mesons are understood as three‑quark states and quark–antiquark pairs, respectively. The first observation of the exotic candidate X(3872) in 2003 challenged this simple three-quark picture. Since then, numerous exotic candidates have been reported at major high‑energy accelerators [13–22], motivating efforts to develop more general mass formulas capable of describing these new states and pre-dicting future ones. Within a single SU(3) multiplet, small mass splittings arise from differences in the up, down, and strange quark masses. To quantify this effect, Gell‑Mann and Okubo proposed the well‑known GMO mass formula [12], which serves both as a valuable phe-nomenological tool and as a benchmark for testing fla-vor‑symmetry breaking effects. In recent years, machine learning (ML) has made sig-nificant advances across a wide range of disciplines. In physics, ML has been used to explore theoretical frame-works [23] and to analyze high-energy phenomena [24– 37]. Machine learning (ML) techniques enable the ex-traction of physical information from high-dimensional    

> ∗chenxun@usc.edu.cn
> †xyzhu0128@163.com
> ‡wenluo-ok@163.com

data—tasks that are often difficult to accomplish us-ing traditional methods. Neural networks, in particu-lar, excel at approximating nonlinear mappings and un-covering hidden patterns in both experimental and sim-ulated data. In addition, physics-informed neural net-works (PINNs) [38, 39] and their extensions embed phys-ical constraints directly into the learning process, thereby bridging the gap between data-driven models and theo-retical frameworks. Among emerging neural network architectures, the Kolmogorov–Arnold Network (KAN) [40, 41] stands out for its interpretability and symbolic regression capabili-ties. Inspired by the Kolmogorov–Arnold representation theorem, KAN replaces the fixed weights of conventional neural networks with learnable univariate functions, en-abling it to represent complex multivariate relationships in a form that is both flexible and analytically tractable. By expressing learned relations in explicit symbolic form, KAN explicitly addresses the black-box limitation of con-ventional neural networks and enables transparent phys-ical interpretation. Unlike traditional neural networks [42], symbolic regression methods [43, 44], or genetic al-gorithms [45], KAN combines the expressive power of neural networks with the interpretability of symbolic re-gression, while offering higher sample efficiency and bet-ter integration of physical priors. Applications of KAN in physics are steadily expanding; for example, it has been used to model and compute the heavy-quark po-tential via holographic methods combined with lattice QCD data [46]. Such successes highlight KAN’s consid-erable potential for tackling complex scientific problems [46–49]. In this study, we employ a KAN-based symbolic re-gression approach to analyze baryon mass data from SU(3) octets and decuplets. Our objectives are: (i) to re-cover the Gell‑Mann–Okubo (GMO) formula [10–12] us-ing modern data‑driven techniques; (ii) to assess its gen-eralization capability across different SU(3) multiplets; and (iii) to demonstrate how KAN can bridge machine learning and interpretable physics. Notably, we not only 

> arXiv:2601.01495v1 [hep-ph] 4 Jan 2026

2successfully reconstruct the classical GMO formula [10– 12] but also uncover hidden relationships among quan-tum numbers within the octet and decuplet, offering new perspectives on flavor‑symmetry breaking. 

Framework: In the section, we will introduce the de-tailed training progress. The fundamental structure is presented below: 1. Input data: In this study, we use the baryon masses of the SU(3) octet and decuplet as the primary input data. To alleviate the limitations imposed by the small sample size, we employ a physics-motivated perturba-tive data-augmentation strategy. Specifically, by fix-ing the relevant group-theoretical quantum numbers — such as isospin ( I) and hypercharge ( Y )— we introduce controlled variations to the baryon masses ( M ) within their experimental uncertainties, thereby generating ad-ditional samples that remain consistent with SU(3) sym-metry. The mass values are taken from the Particle Data Group (PDG) in Table I [50]. For each baryon, multiple perturbed samples are drawn from the corresponding un-certainty interval, resulting in augmented datasets con-sisting of 1000 samples each for the octet and decuplet. This procedure preserves the underlying symmetry struc-ture while allowing the KAN neural network [40, 41] to effectively learn intrinsic mass-distribution patterns, pro-viding high-quality input for symbolic regression. Based on this dataset, we apply KAN for symbolic re-gression to explore hidden relationships between baryon masses and quantum numbers. In the decuplet anal-ysis, KAN autonomously identifies the simplest math-ematical expression consistent with both the data and the symmetry constraints, revealing a clear linear depen-dence of baryon masses on quantum numbers—fully con-sistent with the expected equal-spacing behavior. This data-driven discovery not only validates the effective-ness of SU(3) flavor symmetry but also demonstrates that the KAN model can recover fundamental linear re-lations from experimental data without prior assump-tions. Building on this linear pattern, we further perform symbolic regression to reconstruct the explicit functional form of the decuplet Gell-Mann–Okubo formula. For the octet analysis, we adopt the same preprocess-ing and stratified sampling procedures as in the decuplet case, applying KAN symbolic regression to investigate the quadratic relationship between hypercharge( Y ) and isospin( I). The model extracts a compact and physi-cally interpretable expression that accurately captures the observed dependence of octet baryon masses on Y

and I. This relation serves as the foundation for fitting the complete Gell‑Mann–Okubo formula, which is suc-cessfully recovered through further symbolic regression. The final symbolic expressions obtained for both the octet and decuplet exhibit high accuracy and inter-pretability, and remain fully consistent with theoretical expectations of SU(3) flavor-symmetry breaking [10–12]. 2. Model Selection: To ensure that the symbolic regres-sion model is both physically interpretable and capable of accurately capturing the SU(3) baryon mass patterns, we implemented a systematic model-selection process. Initially, a custom-parameterized model was trained and evaluated, followed by iterative adjustments of the training parameters to improve accuracy. Simultane-ously, model pruning was performed based on structural visualizations to remove redundant components and en-hance efficiency. The refined model was then retrained, and this cycle of tuning and pruning continued until the evaluation metrics met the desired threshold. Upon achieving satisfactory performance, symbolic re-gression [44] was applied. Constrained by the Physics Filter, the regression avoided overly complex functional forms, yielding a physically interpretable expression: 

f (Y, I ) = a Y + b

[

I(I + 1) − 14 Y 2

]

+ c. (1) where a, b, and c are free parameters determined from the data. 3. SU(3)-consistent generalization: We assess generaliza-tion in the sense of SU(3) multiplet consistency, both at the level of symbolic structure and representation-wide coverage. For the model, a nontrivial requirement is that a single invariant symbolic form be shared by all mem-bers of a given multiplet—for instance, the KAN-based regression of the Gell–Mann–Okubo relation for octet baryons retains a consistent functional structure across all multiplet members. For the data, the model must perform reliably for all baryons within a given SU(3) rep-resentation. The separately trained decuplet model, for example, fits all members from ∆ to Ω while naturally reproducing the expected equal-spacing pattern charac-teristic of the decuplet. 4. Loss function: Model performance is evaluated using the mean squared error [51–56] (MSE), defined as MSE = 1

n

> n

∑

> i=1

(ˆ yi − yi)2. (2) This metric measures the average squared deviation be-tween predictions and observations. During training, nu-merical gradient descent with a chosen learning rate min-imizes the MSE, optimizing model parameters for accu-racy. In symbolic regression [44], optimization extends beyond parameter fitting to include structural discovery. Thus, MSE not only quantifies prediction error but also facilitates the joint evolution of model structure and pa-rameter convergence. 5. Training progress of decuplet baryons: Regarding the decuplet baryons, To explore possible latent linear pat-terns among the SU(3) decuplet baryons, we applied a KAN-based symbolic regression to their experimen-tal mass data. Rather than prescribing a predefined functional form, the network autonomously searched for the simplest mathematical expression consistent with the data and symmetry constraints. After training, the re-sulting symbolic form revealed a clear linear dependence between baryon masses and their quantum numbers, con-sistent with the expected equal-spacing behavior within the decuplet. 3

TABLE I. Baryon multiplet properties under SU(3) flavor symmetry. Masses (in MeV/ c2) represent isospin-averaged values from PDG database [50], with uncertainties spanning the full range of observed states within each multiplet. De-cuplet states ( JP = 3 /2+) and octet states ( JP = 1 /2+)are distinguished by their spin-parity quantum numbers and quark composition.                                                 

> Name Symbol I Y Mass (MeV/c²) Octet
> Nucleons N121939 ±1
> Lambda baryons Λ001116 ±1
> Sigma baryons Σ101193 ±4
> Xi baryons Ξ12-1 1318 ±3
> Decuplet
> Delta baryons ∆3211232 ±2
> Sigma baryons Σ∗101385 ±3
> Xi baryons Ξ∗12-1 1533 ±2
> Omega baryon Ω0 -2 1672 ±1

This data-driven discovery not only reaffirms the valid-ity of the SU(3) flavor symmetry but also demonstrates the ability of the KAN model to recover fundamental lin-ear relations directly from empirical data without prior assumptions. The extracted formula provides a quan-titative bridge between the group-theoretic structure of the decuplet and the experimentally observed mass spec-trum. This figure 1 illustrates the KAN neural network ar-chitecture employed to investigate the linear relations in the decuplet, which consists of two hidden layers. As shown in Table II, the final results were obtained after two rounds of training and pruning. Beyond these two it-erations, further training produced no change in the loss function, indicating that the model had converged. The final formula obtained for decuplet baryons is: 1.Model train 

> 2.Model prune
> Set symbolic
> Best fitting formula: X
> Best fitting formula: X
> Output symbolic formula
> Y=2I-2

FIG. 1. This figure illustrates the process of using a KAN neural network to uncover linear relationships among decuplet baryons. 

Y10 = 2 I10 − 2. (3) Building on the identified linear patterns within the SU(3) decuplet, we performed symbolic regression to re-

TABLE II. training log of decuplet linear 

Step train loss test loss 

1 4.05 × 10 −2 4.29 × 10 −2

2 3.25 × 10 −10 1.73 × 10 −10 

cover the explicit functional dependence between baryon masses and their quantum numbers. Using experimen-tal data from PDG [50], the KAN model was trained to learn this mapping in a data-driven yet physically con-strained manner. The regression converged rapidly with low loss, indicating that the network effectively captured the underlying symmetry structure. Further, to obtain the GMO formula for the decuplet, we constructed a KAN with a (2,3,1) architecture, cor-responding to the number of nodes in the input, hid-den, and output layers, respectively, as shown in figure 2. The input variables are hypercharge Y and isospin I,and the output is the mass M . During training, the reg-ularization parameters and learning rate were adjusted adaptively after each iteration to reduce the loss to an appropriate level. At the same time, the model auto-matically identified and removed redundant or ineffective branches, thereby improving generalization and reducing computational complexity. Through pruning, the net-work structure was simplified, retaining only the paths that contributed to the final symbolic regression. After ten training iterations, as shown in Table III, the loss function exhibited no further change, indicating that the model had converged. The analytical expression obtained from symbolic re-gression is: 

F (x1, x 2) = −871 .53( −0.1x1 − 1) 2 + 0 .05( x1 + 1) 2

+ 22 .04( −x2 − 0.24) 2 − 2.81( −0.7x2 − 1) 2 + 2231 .5.

(4) Split the arithmetic expression in the parentheses, and After splitting and retaining two decimal places, the ex-pression becomes: 

F (x1, x 2) = −8.67 x21 − 174 .21 x1 + 20 .66 x22

+ 6 .65 x2 + 1358 .48 . (5) According to the constraints of the GMO formula, com-bining with the relation Y10 = 2 I10 − 2, we proceed to simplify the expression step-by-step to approximate the target form. The detailed derivation is as follows: First, let x1 = Y10 and x2 = I10 , and substitute it into the equation and rearrange each term: 

F (Y10 , I 10 ) = 20 .66 I210 + 20 .66 I10 − 14 .01 I10 

− 8.67 Y 210 − 174 .21 Y10 + 1358 .48 . (6) Next, extract the common factor Y10 (Y10 + 1) from the 

Y10 -related terms and adjust the remaining components: 

F (Y10 , I 10 ) = 20 .66 I10 (I10 + 1) − 181 .215 Y10 

− 8.67 Y 210 + 1344 .47 . (7) 4F(x1,x2)=355.79(0.39-x2)2 

+142.62(1-0.66x1)2+918.77 

Model 

train 

Model 

train 

Model 

prune 

Prevent 

overfitting 

Final model train 

Set symbolic 

The 1st layer best fitting formula:X 

The 0th layer best fitting formula:X 2 Output 

Symbolic 

formula 

F(Y,I)=-871.53(-0.1Y-1) 2+0.05(Y+1) 2+

22.04(-I-0.24) 2-2.81(-0.7I-1) 2+2231.5 

FIG. 2. This figure illustrates the key process of using a KAN neural network to discover the Gell-Mann–Okubo formula for decuplet baryons. including only the essential steps such as key training, pruning, and symbolic regression. F(x1,x2)=355.79(0.39-x2)2 

+142.62(1-0.66x1)2+918.77 

Model train 

Model prune Model 

prune 

Final 

model 

train 

Final 

model 

prune 

Set symbolic 

The 1st layer 

Best fitting 

formula:X 

The 0th layer 

Best fitting 

formula:X 

Output 

symbolic 

formula 

## M = 1382.16 - 146.71Y 

FIG. 3. This figure illustrates the core process of using a KAN neural network to discover the equal spacing rule among decuplet baryons, including only the essential steps such as key training, pruning, and symbolic regression. 

To achieve a more compact expression, adjust the co-efficients of terms involving Y10 and I10 (I10 + 1) :

F (Y10 , I 10 ) = − 90 .5Y 210 − 672 .27 Y10 + 689 .73 + 348 .03 I10 (I10 + 1) .

= − 253 .5Y 210 − 1650 .27 Y10 − 614 .27 + 1000 .03 I10 (I10 + 1) .

(8) To obtain a form similar to Eq. (1), and taking into account the constraint Y10 = 2 I10 − 2, we can simplify the above expression to the following form: 

M10 = − 5550 .27 Y10 − 903 .5Y 210 

+ 3600 .03 I10 (I10 + 1) − 5814 .27 . (9) This result not only validates the physical interpretabil-ity of the KAN-based regression but also highlights its potential as a tool for uncovering the underlying physi-cal patterns encoded in the data. 5                                                              

> TABLE III. Training log of the decuplet GMO.
> Step train loss test loss
> 11.11 ×10 −31.15 ×10 −3
> 21.30 ×10 −31.27 ×10 −3
> 31.51 ×10 −31.61 ×10 −3
> 41.65 ×10 −21.73 ×10 −2
> 52.52 ×10 −22.37 ×10 −2
> 67.60 ×10 −47.28 ×10 −4
> 75.02 ×10 −44.78 ×10 −4
> 84.37 ×10 −34.20 ×10 −3
> 94.02 ×10 −43.75 ×10 −4
> 10 9.90 ×10 −49.80 ×10 −4

The equal‑spacing rule is a remarkably simple yet strik-ing consequence of the GMO mass formula for the baryon decuplet. It states that within the decuplet, each de-crease of one unit in strangeness S(corresponding to the addition of a strange quark s) leads to an approximately constant increase in the particle’s mass. We can verify this with experimental data: 1. The mass difference from ∆ (S=0) to Σ∗ (S=-1): 

M (Σ ∗) − M (∆) ≈ 1385 − 1232 = 153 MeV/c 2.

2. The mass difference from Σ∗ (S=-1) to Ξ∗ (S=-2): 

M (Ξ ∗) − M (Σ ∗) ≈ 1533 − 1385 = 148 MeV/c 2.

3. The mass difference from Ξ∗ (S=-2) to Ω− (S=-3): 

M (Ω −) − M (Ξ ∗) ≈ 1672 − 1533 = 139 MeV/c 2.

As can be seen, these three mass differences are very close, all around 140 – 150 MeV/c 2. This linear, equally spaced mass relationship is the equal spacing rule of the decuplet. Consequently, the GMO formula reduces to a linear relation, 

M = M0 + aY. (10) Here, M is the baryon mass, and M0 and a are con-stants parametrizing the SU(3) symmetric contribution and its leading symmetry breaking, respectively. Simi-larly, we use KAN to train the data in Table I [50] to validate the equal‑spacing rule [10–12] in the baryon de-cuplet. We perform symbolic regression directly on the data to test whether a linear relation between baryon mass M and hypercharge Y can be recovered. The pro-cedure mirrors the previous setup, with minor adjust-ments to target linearity: the model is initialized with a single‑node input layer, a five‑node hidden layer, and a single‑node output layer. The overall training follows the same workflow, but we impose stricter accuracy require-ments and therefore conduct multiple training rounds. The detailed procedure is illustrated in the figure 3. Af-ter 10 training iterations, as illustrated in Table IV, the model approached convergence and symbolic regression was performed, yielding the following expression: 

M10 = 1382 .16 − 146 .71 Y10 . (11) After calculation, the root mean square error (RMSE) is approximately 3.530, and the coefficient of determination 

R2 is approximately 0.99954. Simultaneously, we observe the spontaneous emergence of a “dominant–correction” hierarchy. Through additive composition, the model ef-fectively decouples the fitting task: smooth activation functions (right) capture the leading-order physical de-pendence, whereas irregular ones (left) act as numerical residual compensators for local fluctuations. Although these perturbative terms lack intuitive symbolic forms, they are essential for maintaining high regression accu-racy by offsetting minor errors. This synergistic mecha-nism demonstrates KAN’s ability to adaptively balance sparse physical representation with numerical precision.                                                               

> TABLE IV. training log of The equal-spacing rule for the baryon decuplet
> Step train loss test loss
> 16.43 ×10 −36.26 ×10 −3
> 28.09 ×10 −37.60 ×10 −3
> 32.34 ×10 −32.46 ×10 −3
> 41.08 ×10 −39.93 ×10 −4
> 55.04 ×10 −44.74 ×10 −4
> 62.09 ×10 −32.03 ×10 −3
> 78.73 ×10 −48.03 ×10 −4
> 86.57 ×10 −45.95 ×10 −4
> 96.92 ×10 −47.10 ×10 −4
> 10 1.85 ×10 −41.87 ×10 −4

6. Training progress of octet baryons: For the octet baryons, in order to uncover their hidden nonlinear inter-relationships, we conducted a second‑stage analysis us-ing the same preprocessing and stratified sampling pro-cedures as in the decuplet case, applied to the SU(3) octet data. Through the KAN symbolic regression work-flow, we focus on the relationship between hypercharge 

Y and isospin I among the octet members. Figure 4 il-lustrates the KAN architecture employed for this task, which is identical to that used in deriving the linear re-lation for the decuplet, although the training procedure and the function fitting differ. As shown in Table V, the model converged after five training iterations. Finally, symbolic regression was applied to the model, yielding the the relationship between Y and I.6Model train Best fitting  

> formula: X 2
> Best fitting
> formula: X
> Set symbolic
> Output symbolic formula
> Y=1.0-4.0(0.5-I) 2

FIG. 4. This figure illustrates the process of using a KAN neural network to uncover binary relationships among octet baryons. 

Y 28 = 1 .0 − 4.0(0 .5 − I8)2. (12) 

TABLE V. training log of octet binary 

Step train loss test loss 

1 5.35 × 10 −2 5.35 × 10 −2

2 8.09 × 10 −2 8.04 × 10 −2

3 9.67 × 10 −2 1.02 × 10 −1

4 0.00 0.00 

Then, we proceed to employ KAN to search for the GMO formula of the octet. The initial neural network ar-chitecture was identical to that used for the decuplet, but the parameter adjustments during training differed from the previous setup, with the detailed procedure shown in figure 5. After eight training iterations, the loss function exhibited no further change, and the model was therefore considered converged, as summarized in Table VI. The figure retains only the key stages of training—such as pruning, and optimization. Finally, symbolic regression was applied to the model, yielding the initial expression of the octet GMO formula: 

F (x1, x 2) = 355 .79(0 .39 − x2)2

+ 142 .62(1 − 0.66 x1)2 + 918 .76 . (13) After splitting and retaining two decimal places, simul-taneously, replace x1 with Y8 and x2 with I8. the initial expression is obtained: 

F (Y8, I 8) = 62 .13 Y 28 + 355 .79 I28

− 188 .26 Y8 − 277 .52 I8 + 1115 .50 . (14) To align the coefficients of I28 and I8, combine the ex-pression above, and temporarily substitute Y 28 for 0.25 Y 28

(i.e., the relation 0.25 Y 28 = I8 − I28 ). The I8-related terms can be integrated into the original expression through the following transformation: 

39 .135 I8 + 39 .135 I28 − 39 .135 I8

− 39 .135 I28 − 277 .52 I8 + 355 .79 I28

= 39 .135 I8(I8 + 1) − 316 .655 I8 + 316 .655 I28

= 39 .135 I8(I8 + 1) − 316 .655 I8(1 − I8)= 39 .135 I8(I8 + 1) − 316 .655 · 0.25 Y 28

= 39 .135 I8(I8 + 1) − 79 .16375 Y 28 .

(15) Substitute the above result into the original expression and consolidate all coefficients to obtain the form: 

F (Y8, I 8) = 39 .135 I8(I8 + 1) − 79 .16375 Y 28 − 188 .26 Y8

+ 62 .13 Y 28 + 1115 .50 = 39 .14 I8(I8 + 1) − 17 .03 Y 28 −

188 .26 Y8 + 1115 .50 .

(16) Finally, replace F (Y8, I 8) with M8 to obtain the final form: 

M8 = − 188 .26 Y8 + 39 .14 I8(I8 + 1) 

− 17 .03 Y 28 + 1115 .50 . (17) 

TABLE VI. training log of octet GMO 

Step train loss test loss 

1 1.27 × 10 −2 1.29 × 10 −2

2 4.60 × 10 −3 4.60 × 10 −3

3 7.87 × 10 −4 7.85 × 10 −4

4 8.79 × 10 −3 8.81 × 10 −3

5 4.04 × 10 −3 4.05 × 10 −3

6 3.64 × 10 −9 1.37 × 10 −9

7 5.19 × 10 −8 5.32 × 10 −10 

8 2.92 × 10 −11 9.99 × 10 −13 

7. Output: For the SU(3) decuplet baryons (as shown in the decuplet section of Table VII), KAN-based symbolic regression first identifies a linear dependence between Y

and I, which is then incorporated into the GMO expres-sion. After algebraic simplification, the complete decu-plet GMO relation is obtained, naturally containing the equal-spacing rule and showing excellent agreement with experimental results. For the SU(3) octet baryons (as shown in the octet section of Table VII), the method reveals a multivari-ate correlation between Y and I. Substituting this rela-tion into the symbolic GMO expression yields a compact and interpretable octet GMO formula, consistent with the empirical mass hierarchy. 

Conclusion and outlook : In this work, we employ KAN to perform symbolic regression on experimental baryon mass data from SU(3) octets and decuplets, with the dual aims of rediscovering the GMO mass formulas and re-fining their functional forms directly from data. Given 7F(x1,x2)=355.79(0.39-x2)2 

+142.62(1-0.66x1)2+918.77                                

> Model train Model prune
> Final
> model
> train
> Final
> model
> prune
> Set symbolic
> The 1st layer
> Best fitting
> formula:X
> The 0th layer
> Best fitting
> formula:X 2
> Output
> Symbolic
> formula F(Y,I)=355.79(0.39-I) 2
> +142.62(1-0.66Y) 2+918.77
> FIG. 5. This figure illustrates the process of using a KAN neural network to uncover the Gell-Mann–Okubo formula for octet baryons. TABLE VII. The table presents all the results for the decu-plet and octet baryons obtained in this study using the KAN neural network.
> Decuplet
> Relation
> Y10 = 2 I10 −2
> M10 =−5550 .27 Y10 −903 .5Y210 + 3600 .03 I10 (I10 + 1) −5814 .27
> M10 (equal −spacing ) = 1382 .16 −146 .71 Y10
> Octet
> Relation
> Y28= 1 .0−4.0(0 .5−I8)2
> M8=−188 .26 Y8+ 39 .14 I8(I8+ 1) −17 .03 Y28+ 1115 .50

the limited sample size, while preserving SU(3) structure, we use a physically informed, perturbation‑based data augmentation procedure that perturbs baryon masses within reported experimental uncertainties while holding group‑theoretical quantum numbers (e.g., isospin I and hypercharge Y ) fixed; mass values are taken from the PDG and related literatures [10–12, 57, 58]. Model per-formance, monitored via MSE, guides adaptive tuning of regularization and learning‑rate parameters and informs pruning decisions that remove redundant branches and retain only paths relevant for symbolic extraction. Applying this workflow, KAN consistently extracts compact, physically interpretable symbolic expressions. For the octet, the network uncovers a multivariate rela-tion between Y and I that serves as the basis for recover-ing the octet GMO formula; the extracted symbolic form generalizes across N , Λ, Σ, and Ξ. For the decuplet, KAN autonomously finds a simplest‑form linear dependence of mass on quantum numbers and, building on that linear pattern, reconstructs an explicit decuplet GMO expres-sion that reproduces the expected equal‑spacing rule from 

∆ to Ω. These invariant symbolic forms capture inter-nal SU(3) flavor‑symmetry breaking patterns and outper-form purely numerical fits by revealing analytic structure and hidden relations among multiplet quantum numbers. More broadly, the physical significance of this study lies in demonstrating the possibility of reconstructing un-derlying physical symmetries directly from experimen-tal observations. Using KAN, we independently identify the SU(3) flavor symmetry governing the hadron mass spectrum, together with its symmetry-breaking patterns, without introducing prior group-theoretical assumptions. This approach provides a model-independent framework for quantitatively characterizing symmetry-breaking ef-fects induced by quark mass differences, and establishes an interpretable, data-driven paradigm for exploring un-known regularities in hadron spectra in regimes where a complete analytic theory is not yet available. Beyond validating SU(3) expectations, our re-sults demonstrate KAN’s advantage as a data-driven, assumption-light method for rediscovering empirical mass formulas. The approach suggests several promis-ing directions, including applying KAN to more intri-cate hadron spectra and exotic states [13, 59–63], inte-grating QCD inputs or expanded experimental datasets [57, 58, 64–80] to further refine symbolic forms, and im-proving symbolic-regression pipelines to enhance inter-pretability and predictive power in high-energy physics. Overall, our findings highlight KAN’s potential to bridge data-driven modeling and interpretable physical laws. 8

ACKNOWLEDGMENTS 

This work is supported by the National Natural Sci-ence Foundation of China (NSFC) Grant Nos: 12405154, and the European Union – Next Generation EU through the research grant number P2022Z4P4B “SOPHYA -Sustainable Optimised PHYsics Algorithms: fundamen-tal physics to build an advanced society” under the program PRIN 2022 PNRR of the Italian Ministero dell’Università e Ricerca (MUR). 

REFERENCES 

[1] D. J. Gross and F. Wilczek, Ultraviolet behavior of non-abelian gauge theories, Physical Review Letters 30 , 1343 (1973). [2] H. D. Politzer, Reliable perturbative results for strong interactions?, Physical Review Letters 30 , 1346 (1973). [3] C. G. Callan Jr, Broken scale invariance in scalar field theory, Physical Review D 2, 1541 (1970). [4] K. Symanzik, Small distance behaviour in field theory and power counting, Communications in Mathematical Physics 18 , 227 (1970). [5] V. Vanyashin and M. Terent’ev, The vacuum polarization of a charged vector field, Sov. Phys. JETP 21 , 375 (1965). [6] I. Khriplovich, GREEN’S FUNCTIONS IN THEORIES WITH NON-ABELIAN GAUGE GROUP. , Tech. Rep. (Inst. of Nuclear Physics, Novosibirsk, USSR, 1969). [7] H. Fritzsch, M. Gell-Mann, and H. Leutwyler, Advan-tages of the color octet gluon picture, Physics Letters B 

47 , 365 (1973). [8] D. J. Gross and F. Wilczek, Asymptotically free gauge theories. i, Physical Review D 8, 3633 (1973). [9] H. D. Politzer, Asymptotic freedom: An approach to strong interactions, Physics Reports 14 , 129 (1974). [10] M. Gell-Mann, The eightfold way: A theory of strong interaction symmetry, in The Eightfold Way (CRC Press, 2018) pp. 11–57. [11] S. Okubo, Note on unitary symmetry in strong interac-tions, Progress of Theoretical Physics 27 , 949 (1962). [12] M. Gell-Mann, Symmetries of baryons and mesons, in 

The eightfold way (CRC Press, 2018) pp. 216–233. [13] H.-X. Chen, W. Chen, X. Liu, and S.-L. Zhu, The hidden-charm pentaquark and tetraquark states, Physics Re-ports 639 , 1 (2016). [14] Y.-R. Liu, H.-X. Chen, W. Chen, X. Liu, and S.-L. Zhu, Pentaquark and tetraquark states, Progress in Particle and Nuclear Physics 107 , 237 (2019). [15] H.-X. Chen, W. Chen, X. Liu, Y.-R. Liu, and S.-L. Zhu, A review of the open charm and open bottom systems, Reports on Progress in Physics 80 , 076201 (2017). [16] Y. Dong, A. Faessler, and V. E. Lyubovitskij, Descrip-tion of heavy exotic resonances as molecular states using phenomenological lagrangians, Progress in Particle and Nuclear Physics 94 , 282 (2017). [17] R. F. Lebed, R. E. Mitchell, and E. S. Swanson, Heavy-quark qcd exotica, Progress in Particle and Nuclear Physics 93 , 143 (2017). [18] F.-K. Guo, C. Hanhart, U.-G. Meißner, Q. Wang, Q. Zhao, and B.-S. Zou, Hadronic molecules, Reviews of Modern Physics 90 , 015004 (2018). [19] R. M. Albuquerque, J. M. Dias, K. Khemchandani, A. M. Torres, F. S. Navarra, M. Nielsen, and C. M. Zanetti, Qcd sum rules approach to the x, y and z states, Journal of Physics G: Nuclear and Particle Physics 46 , 093002 (2019). [20] Y. Yamaguchi, A. Hosaka, S. Takeuchi, and M. Tak-izawa, Heavy hadronic molecules with pion exchange and quark core couplings: a guide for practitioners, Journal of Physics G: Nuclear and Particle Physics 47 , 053001 (2020). [21] F.-K. Guo, X.-H. Liu, and S. Sakai, Threshold cusps and triangle singularities in hadronic reactions, Progress in Particle and Nuclear Physics 112 , 103757 (2020). [22] N. Brambilla, S. Eidelman, C. Hanhart, A. Nefediev, C.-P. Shen, C. E. Thomas, A. Vairo, and C.-Z. Yuan, The xyz states: experimental and theoretical status and per-spectives, Physics reports 873 , 1 (2020). [23] S. J. Wetzel, R. G. Melko, J. Scott, M. Panju, and V. Ganesh, Discovering symmetry invariants and con-served quantities by interpreting siamese neural net-works, Physical Review Research 2, 033499 (2020). [24] Y. D. Hezaveh, L. P. Levasseur, and P. J. Marshall, Fast automated analysis of strong gravitational lenses with convolutional neural networks, Nature 548 , 555 (2017). [25] S. Soma, L. Wang, S. Shi, H. Stöcker, and K. Zhou, Re-constructing the neutron star equation of state from ob-servational data via automatic differentiation, Physical Review D 107 , 083028 (2023). [26] L.-G. Pang, K. Zhou, N. Su, H. Petersen, H. Stöcker, and X.-N. Wang, An equation-of-state-meter of quantum chromodynamics transition from deep learning, Nature communications 9, 210 (2018). [27] X. Chen and M. Huang, Machine learning holographic black hole from lattice qcd equation of state, Physical Review D 109 , L051902 (2024). [28] A. Radovic, M. Williams, D. Rousseau, M. Kagan, D. Bonacorsi, A. Himmel, A. Aurisano, K. Terao, and T. Wongjirad, Machine learning at the energy and inten-sity frontiers of particle physics, Nature 560 , 41 (2018). [29] D. Guest, K. Cranmer, and D. Whiteson, Deep learn-ing and its application to lhc physics, Annual Review of Nuclear and Particle Science 68 , 161 (2018). [30] K. Albertsson, P. Altoe, D. Anderson, M. Andrews, J. P. Araque Espinosa, A. Aurisano, L. Basara, A. Bevan, W. Bhimji, D. Bonacorsi, et al. , Machine learning in high energy physics community white paper, in Journal of Physics: Conference Series , Vol. 1085 (IOP Publish-ing, 2018) p. 022008. [31] J. Kim, G. Pederiva, and A. Shindler, Machine learn-ing mapping of lattice correlated data, Physics Letters B 

856 , 138894 (2024). 9

[32] K. Zhou, L. Wang, L.-G. Pang, and S. Shi, Exploring qcd matter in extreme conditions with machine learning, Progress in Particle and Nuclear Physics 135 , 104084 (2024). [33] G. Aarts, K. Fukushima, T. Hatsuda, A. Ipp, S. Shi, L. Wang, and K. Zhou, Physics-driven learning for in-verse problems in quantum chromodynamics, Nature Re-views Physics 7, 154 (2025). [34] L. Jiang, L. Wang, and K. Zhou, Deep learning stochastic processes with qcd phase transition, Physical Review D 

103 , 116023 (2021). [35] X. Chen and M. Huang, Flavor dependent critical end-point from holographic qcd through machine learning, Journal of High Energy Physics 2025 , 1 (2025). [36] M. Mansouri, K. B. Fadafan, and X. Chen, Holographic complex potential of a quarkonium from deep learning, arXiv preprint arXiv:2406.06285 (2024). [37] W.-C. Dai, O.-Y. Luo, B. Chen, X. Chen, X.-Y. Zhu, and X.-H. Li, Extracting transport properties of quark-gluon plasma from the heavy-quark potential with neu-ral networks in a holographic model, arXiv preprint arXiv:2503.10213 (2025). [38] M. Raissi, P. Perdikaris, and G. E. Karniadakis, Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations, Journal of Computational physics 378 , 686 (2019). [39] P.-H. Chiu, J. C. Wong, C. Ooi, M. H. Dao, and Y.-S. Ong, Can-pinn: A fast physics-informed neural net-work based on coupled-automatic–numerical differentia-tion method, Computer Methods in Applied Mechanics and Engineering 395 , 114909 (2022). [40] Z. Liu, Y. Wang, S. Vaidya, F. Ruehle, J. Halver-son, M. Soljačić, T. Y. Hou, and M. Tegmark, Kan: Kolmogorov-arnold networks, arXiv preprint arXiv:2404.19756 (2024). [41] Z. Liu, P. Ma, Y. Wang, W. Matusik, and M. Tegmark, Kan 2.0: Kolmogorov-arnold networks meet science, arXiv preprint arXiv:2408.10205 (2024). [42] Z. Liu and M. Tegmark, Machine learning conserva-tion laws from trajectories, Physical Review Letters 126 ,180604 (2021). [43] S.-M. Udrescu and M. Tegmark, Ai feynman: A physics-inspired method for symbolic regression, Science ad-vances 6, eaay2631 (2020). [44] M. Schmidt and H. Lipson, Distilling free-form natural laws from experimental data, science 324 , 81 (2009). [45] Z. Zhang, R. Ma, J. Hu, and Q. Wang, Approach the gell-mann-okubo formula with machine learning, Chinese Physics Letters 39 , 111201 (2022). [46] O.-Y. Luo, X. Chen, F.-P. Li, X.-H. Li, and K. Zhou, Neural network modeling of heavy-quark potential from holography, The European Physical Journal C 85 , 637 (2025). [47] N. R. Panczyk, O. F. Erdem, and M. I. Radaideh, Open-ing the black-box: Symbolic regression with kolmogorov-arnold networks for energy applications, arXiv preprint arXiv:2504.03913 (2025). [48] C. Guo, L. Sun, S. Li, Z. Yuan, and C. Wang, Physics-informed kolmogorov–arnold network with chebyshev polynomials for fluid mechanics, Physics of Fluids 37 

(2025). [49] H. Hao, X. Zhang, B. Li, and A. Zhou, A first look at kolmogorov-arnold networks in surrogate-assisted evo-lutionary algorithms, arXiv preprint arXiv:2405.16494 (2024). [50] K. Nakamura, Review of particle physics, Journal of Physics G: Nuclear and Particle Physics 37 (2010). [51] T. Hastie, R. Tibshirani, J. Friedman, et al. , The ele-ments of statistical learning (2009). [52] C. M. Bishop, Pattern recognition and machine learning by Christopher M. Bishop , Vol. 400 (Springer Science+ Business Media, LLC Berlin, Germany:, 2006). [53] I. Goodfellow, Y. Bengio, A. Courville, and Y. Bengio, 

Deep learning , Vol. 1 (MIT press Cambridge, 2016). [54] S. Geman, E. Bienenstock, and R. Doursat, Neural net-works and the bias/variance dilemma, Neural computa-tion 4, 1 (1992). [55] K. P. Murphy, Machine learning: a probabilistic perspec-tive (MIT press, 2012). [56] T. Hastie, R. Tibshirani, and J. Friedman, An introduc-tion to statistical learning, (2009). [57] Y.-F. Liu, W.-J. Xing, X.-Y. Wu, G.-Y. Qin, S. Cao, and H. Xing, Heavy and light flavor jet quenching in different collision systems at energies available at the cern large hadron collider, Physical Review C 105 , 044904 (2022). [58] S. Katel, H. Li, Z. Zhao, R. Kansal, F. Mokhtar, and J. Duarte, Learning symmetry-independent jet represen-tations via jet-based joint embedding predictive architec-ture, arXiv preprint arXiv:2412.05333 (2024). [59] H. Garcilazo and A. Valcarce, Exotic heavy hadrons, Symmetry 17 , 1324 (2025). [60] T. Hyodo, Study of hadron interactions and composite-ness, arXiv preprint arXiv:2503.15376 (2025). [61] G. Yang, J. Ping, and J. Segovia, Tetra-and penta-quark structures in the constituent quark model, Symmetry 12 ,1869 (2020). [62] W.-T. Lyu, L.-J. Liu, and E. Wang, Evidence of the open-flavor tetraquark tc¯s2 in the process b+ → d∗− d+ 

> s

π+,arXiv preprint arXiv:2501.02839 (2025). [63] P. D. Collins and E. J. Squires, Regge poles in particle physics , Vol. 45 (Springer, 2006). [64] K. G. Wilson, Confinement of quarks, Physical review D 

10 , 2445 (1974). [65] S. Durr, Z. Fodor, J. Frison, C. Hoelbling, R. Hoffmann, S. D. Katz, S. Krieg, T. Kurth, L. Lellouch, T. Lippert, 

et al. , Ab initio determination of light hadron masses, Science 322 , 1224 (2008). [66] Y. Aoki, T. Blum, G. Colangelo, S. Collins, M. D. Morte, P. Dimopoulos, S. Dürr, X. Feng, H. Fukaya, M. Golter-man, et al. , Flag review 2021, The European Physical Journal C 82 , 869 (2022). [67] A. Bazavov, T. Bhattacharya, C. DeTar, H.-T. Ding, S. Gottlieb, R. Gupta, P. Hegde, U. Heller, F. Karsch, E. Laermann, et al. , Equation of state in (2+ 1)-flavor qcd, Physical Review D 90 , 094503 (2014). [68] S. He, L. Li, Z. Li, and S.-J. Wang, Gravitational waves and primordial black hole productions from gluodynam-ics by holography, Science China Physics, Mechanics & Astronomy 67 , 240411 (2024). [69] L. Zhang and M. Huang, Holographic cold dense matter constrained by neutron stars, Physical Review D 106 ,096028 (2022). [70] Y. Chen, D. Li, and M. Huang, The dynamical holo-graphic qcd method for hadron physics and qcd mat-ter, Communications in Theoretical Physics 74 , 097201 (2022). 10 

[71] R. Li, S. Han, Z. Lin, L. Wang, K. Zhou, and S. Shi, Towards constraining qcd phase transitions in neutron star interiors: Bayesian inference with tov linear response analysis, arXiv preprint arXiv:2501.15810 (2025). [72] K. Zhou, G. Endrődi, L.-G. Pang, and H. Stöcker, Re-gressive and generative neural networks for scalar field theory, Physical Review D 100 , 011501 (2019). [73] X. Chen, D. Li, and M. Huang, Criticality of qcd in a holographic qcd model with critical end point, Chinese Physics C 43 , 023105 (2019). [74] X. Chen, L. Zhang, D. Li, D. Hou, and M. Huang, Gluo-dynamics and deconfinement phase transition under ro-tation from holography, Journal of High Energy Physics 

2021 , 1 (2021). [75] X. Chen, D. Li, D. Hou, and M. Huang, Quarkyonic phase from quenched dynamical holographic qcd model, Journal of High Energy Physics 2020 , 1 (2020). [76] L. Zhu, X. Chen, K. Zhou, H. Zhang, and M. Huang, Bayesian inference of the critical end point in a (2+ 1)-flavor system from holographic qcd, Physical Review D 

112 , 026019 (2025). [77] W.-J. Xing, S. Cao, G.-Y. Qin, and X.-N. Wang, Flavor hierarchy of jet energy correlators inside the quark-gluon plasma, Physical Review Letters 134 , 052301 (2025). [78] S. Cao and X.-N. Wang, Jet quenching and medium re-sponse in high-energy heavy-ion collisions: a review, Re-ports on Progress in Physics 84 , 024301 (2021). [79] W.-J. Zhang, Z. Zhang, J. Hu, B.-N. Lu, J.-Y. Pang, and Q. Wang, Machine learning unveils the power law of finite-volume energy shifts, Chinese Physics Letters (2025). [80] H.-A. Zeng, L. Wang, and M. Huang, HoloNet: Toward a Unified Einstein-Maxwell-Dilaton Framework of QCD, (2025), arXiv:2512.06044 [hep-lat].