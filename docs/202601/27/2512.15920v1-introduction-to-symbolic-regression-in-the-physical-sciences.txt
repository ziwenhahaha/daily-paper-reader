Title: Introduction to Symbolic Regression in the Physical Sciences

URL Source: https://arxiv.org/pdf/2512.15920v1

Published Time: Fri, 19 Dec 2025 01:08:36 GMT

Number of Pages: 8

Markdown Content:
royalsocietypublishing.org/journal/rspa 

# Review 

Article submitted to journal 

Keywords: 

symbolic regression, physics 

Author for correspondence: 

Deaglan J. Bartlett, Harry Desmond, Pedro G. Ferreira, Gabriel Kronberger e-mail: deaglan.bartlett@physics.ox.ac.uk, e-mail: harry.desmond@port.ac.uk, e-mail: pedro.ferreira@physics.ox.ac.uk, e-mail: Gabriel.Kronberger@fh-hagenberg.at 

# Introduction to the Special Issue on Symbolic Regression in the Physical Sciences 

# Deaglan J. Bartlett 1, Harry Desmond 2,Pedro G. Ferreira 1, Gabriel Kronberger 3

1 Astrophysics, University of Oxford, Denys Wilkinson Building, Keble Road, Oxford OX1 3RH, UK 

2Institute of Cosmology & Gravitation, University of Portsmouth, Dennis Sciama Building, Portsmouth, PO1 3FX, UK 

3Heuristic and Evolutionary Algorithms Laboratory, University of Applied Sciences Upper Austria, Softwarepark 11, 4232 Hagenberg, Austria 

Symbolic regression (SR) has emerged as a powerful method for uncovering interpretable mathematical relationships from data, offering a novel route to both scientific discovery and efficient empirical modelling. This article introduces the Special Issue on Symbolic Regression for the Physical Sciences, motivated by the Royal Society discussion meeting held in April 2025. The contributions collected here span applications from automated equation discovery and emergent-phenomena modelling to the construction of compact emulators for computationally expensive simulations. The introductory review outlines the conceptual foundations of SR, contrasts it with conventional regression approaches, and surveys its main use cases in the physical sciences, including the derivation of effective theories, empirical functional forms and surrogate models. We summarise methodological considerations such as search-space design, operator selection, complexity control, feature selection, and integration with modern AI approaches. We also highlight ongoing challenges, including scalability, robustness to noise, overfitting and computational complexity. Finally we emphasise emerging directions, particularly the incorporation of symmetry constraints, asymptotic behaviour and other theoretical information. Taken together, the papers in this Special Issue illustrate the accelerating progress of SR and its growing relevance across the physical sciences.    

> ©The Authors. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/ by/4.0/, which permits unrestricted use, provided the original author and source are credited.
> arXiv:2512.15920v1 [cs.LG] 17 Dec 2025 2royalsocietypublishing.org/journal/rspa Proc R Soc A 0000000
> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

# 1. Introduction: Symbolic Regression and the Royal Society Meeting 

Symbolic Regression (SR) is emerging as a powerful computational methodology with significant potential to advance research across the physical sciences. This approach, distinct from conventional regression techniques that fit parameters to a predefined model structure, aims to uncover the underlying mathematical expressions that best describe observed data. By navigating the vast space of possible equations, SR offers a pathway both to create highly efficient predictive models and, more profoundly, to discover novel scientific laws or relationships from empirical evidence. Automatically finding equations that fit observational data has been a topic of interest in AI research since the early beginnings. Early symbolic and heuristic systems for rule-based equation discovery include Lenat’s Automatic Mathematician [1], BACON [2], ABACUS [3], or LAGRANGE [4] for algebraic differential equations. Genetic programming (GP) is an evolutionary algorithm and was introduced in the 90s and popularised by Koza [5]. Modern implementations of GP for symbolic regression are for example PySR [6] or PyOperon [7]. Later, evolutionary and rule-based approaches were combined in systems such as AI Feynman [8], or AI Descartes [9]. Systems relying on deep learning and reinforcement learning include EQL [10] and uDSR [11]. More recently, several different approaches based on end-to-end learning, transformers, and foundational models have been proposed. At its core, symbolic regression endeavors to identify a functional form, f , such that y =

f (x1, x 2, . . . , x n) optimally describes the relationship between a set of input variables {xi} and an output variable y, based on a given dataset. Unlike traditional regression methods where the structure of f (e.g., linear, polynomial of a certain degree) is assumed a priori, SR algorithms, explore a diverse range of mathematical operators (e.g., arithmetic operations, trigonometric functions, exponentials, logarithms) and their combinations to construct candidate equations. The primary output of SR is not just a set of parameters, but one or more explicit mathematical formulae. This inherent transparency is a key advantage, as the discovered equations are, in principle, human-interpretable. This interpretability allows scientists to gain insights into the underlying mechanisms of the system under study, validate the discovered models against existing theories, and potentially reveal previously unknown connections between variables. Furthermore, SR models, by capturing the intrinsic structure of the data, may exhibit superior generalisation capabilities, particularly when extrapolating beyond the range of the training data. The growing interest in SR and equation discovery methods in particular in the physical sciences has led us to organize the discussion meeting on Symbolic Regression in the Physical Sciences which was held in April 2025 at the Royal Society in London. The gathering assembled a group of researchers at the interface of machine learning and the physical sciences, aiming to develop symbolic regression methods and use them to learn physical laws or simplified models directly from experimental or observational data. Applications across domains illustrated the versatility of SR, for example deriving constitutive laws for metallic materials under deformation, accelerating cosmological modelling and learning dark-matter halo profiles from kinematic data. In this special issue we have collected research articles from the presenters at the discussion meeting. This introductory article outlines the main uses of SR, the evolving methodological frontier and the challenges that constitute the primary concerns of SR researchers moving forwards. 

# 2. Symbolic Regression for Scientific Discovery: The Quest for Physical Laws 

The most ambitious application of symbolic regression is in automated scientific discovery for extracting fundamental physical laws or novel descriptive equations directly from experimental 3 royalsocietypublishing.org/journal/rspa Proc R Soc A 0000000 

> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

or observational data. The goal here is to find simple, yet accurate, mathematical formulae that capture the essence of complex datasets. This aligns with the principle of parsimony, or Occam’s Razor, which favors simpler explanations. SR algorithms often incorporate complexity penalties or simplicity priors to guide the search towards more concise and natural equations. Compact equations are more likely to represent true underlying relationships rather than mere overfitting. Challenges in this domain are numerous, including the presence of noise in data, the potential for observational biases, the vastness of the search space for equations, and the difficulty in objectively defining “simplicity” or “interpretability”. While the prospect of SR uncovering entirely new, fundamental laws of physics on par with general relativity or quantum mechanics is tempered by the understanding that many such foundational principles may have already been established, significant opportunities remain. The frontier for SR-driven discovery is particularly rich in areas characterised by emergent phenomena, where complex behaviours arise from the interactions of many simpler components, and where deriving macroscopic laws from microscopic descriptions is often intractable. Examples of such situations in the physical sciences include: • Astrophysics: The Universe presents a plethora of complex systems, from plasma dynamics in stellar atmospheres and accretion disks to the formation of galaxies and the large-scale structure of the cosmic web. Highly nonlinear physics couples a vast range of scales, making such processes extremely difficult to simulate. SR can be applied to observational (e.g., light curves, spectra, cosmological surveys) or simulated data to find new relationships governing these phenomena, potentially leading to improved models for stellar evolution, galaxy dynamics, or the properties of exoplanetary atmospheres. • Condensed Matter Physics: This field abounds with complex many-body systems exhibiting rich emergent behaviours, such as superconductivity, topological phases, or complex magnetic orderings. SR could help identify effective theories or phenomenological laws that describe these macroscopic properties from experimental measurements (e.g., transport, spectroscopic data) or from data generated by detailed microscopic simulations that are too complex to yield direct analytical insight. • Engineering: SR can be employed to derive equations predicting performance metrics from design parameters in the design of complex systems (e.g., electrical motors, chemical reactors), to find constitutive models for materials, or to find optimal control strategies for dynamic processes. In these domains, SR is not necessarily seeking to overturn established fundamental laws but rather to discover the specific mathematical forms that govern the emergent behavior within a particular context, often providing crucial links between microscopic physics and macroscopic observables. 

# 3. Symbolic Regression for Empirical Modeling 

Beyond the pursuit of fundamental laws, symbolic regression serves as a highly effective tool for fitting functions to data and generating empirical formulae. In many scientific and engineering contexts, the primary need is for a compact, accurate mathematical model that captures the observed relationships, even if it does not represent a physical law. SR can produce such empirical models that are often more insightful and easier to use than nonparametric or overparameterized (deep) models. A particularly valuable attribute of SR in this context is its potential for robust extrapolation. Because SR aims to find the actual functional form of the relationship, if it succeeds in capturing even an approximation of the true underlying physics, the resulting model may extrapolate more reliably to unseen regions of the parameter space than models that merely interpolate based on local data patterns. This is crucial for making predictions under novel conditions or for understanding system behavior beyond the experimentally accessible range. However, like 4 royalsocietypublishing.org/journal/rspa Proc R Soc A 0000000 

> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

all extrapolation, this capability must be approached with caution, as a model that performs well on training data can still fail dramatically outside that domain if the discovered functional form is not truly representative of the underlying process. Simplicity priors and the minimum description length principle for SR play an important role in this context. 

# 4. Symbolic Regression for Emulation in Physical Systems 

An important example of creating fitting formulae is the development of emulators, also known as surrogate models. Many physical phenomena are described by complex, high-dimensional, and computationally intensive simulations derived from first-principles theories (e.g., quantum mechanics, fluid dynamics, general relativity). Running these simulations for extensive parameter sweeps, uncertainty quantification, or real-time control can be prohibitively expensive. Symbolic regression offers a compelling solution by generating fast and accurate mathematical approximations of these complex simulations. These emulators, expressed as relatively simple equations, can reproduce the input-output behavior of the original simulation with high fidelity but at a fraction of the computational cost. For instance, SR can be used to derive analytical expressions for material properties that normally require demanding quantum mechanical calculations, or to create compact models of cosmology simulations, or to approximate solutions to partial differential equations governing fluid flow. The benefit of SR-derived emulators extends beyond mere speed. Because the emulator is an explicit mathematical formula, it can provide insights into the sensitivity of the system’s outputs to various input parameters, potentially revealing dominant physical effects or simplifying assumptions that might not be obvious from the full simulation. These effective descriptions of complex physics are invaluable for rapid design exploration, optimisation, and inverse problem solving, where numerous model evaluations are necessary. Unlike many alternative emulation tools such as neural networks, the outputs of SR are succinct mathematical expressions. These can be easily coded in any programming language and potentially be used even on resource-constrained hardware, such as embedded devices, e.g. for online control. 

# 5. Methodological Aspects 

The successful application of symbolic regression requires careful consideration of several methodological aspects. It is not a universal panacea, and its effectiveness is highly dependent on the nature of the problem and the way the search is conducted. A crucial first step is strategic problem selection. SR is most likely to yield significant benefits when the goal is to obtain a potentially interpretable, explicit mathematical model, when there is a reasonable expectation that a concise underlying relationship exists. In situations where predictive accuracy is the sole concern and interpretability is secondary, or when a large number of potentially interrelated input variables have to be considered, other machine learning techniques such as deep neural networks might be more appropriate. These much larger models however require larger data volumes for training. While SR can work with smaller datasets, noisy or insufficient data may lead to spurious or overly complex equations and overfitting. The inherent complexity of the physical system under study also impacts the application of SR. Highly complex systems with many interacting variables may not be amenable to description by simple, low-dimensional equations. In such cases, appropriate feature engineering, dimensionality reduction, or focusing on specific, well-constrained aspects of the system might be necessary. GP exhibits implicit feature selection through evolutionary selective pressure, which allows to identify the most relevant input variables for low-dimensional equations from high-dimensional datasets automatically. However, the scalability of current SR algorithms can also be a limitation in situations where a large number of input variables must be captured in a large model, or when searching for large mathematical expressions. Here new developments for the automatic identification of functions or hierarchical, modular structures are of interest to facilitate more compressed and compact descriptions. 5 royalsocietypublishing.org/journal/rspa Proc R Soc A 0000000 

> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Furthermore, the definition and constraining of the search space through the set of mathematical building blocks (variables, constants, operators) and the rules for combining them, is a critical determinant of SR’s success. An overly restrictive search space might preclude the discovery of the more likely equations, while an excessively large space can render the search computationally intractable or increase the risk of finding complex equations that overfit the data. The choice of basis functions should ideally be guided by domain knowledge about the system being modeled. 

# 6. The Evolving Frontier of Symbolic Regression 

The field of symbolic regression is dynamic, with ongoing research aimed at enhancing its power, scope, and reliability. Two particularly promising future directions involve the integration of prior scientific knowledge and the synergistic combination with recent AI technologies such as deep learning, reinforcement learning or large language models (LLMs). In this context, SR is a prime candidate where hybrid symbolic, sub-symbolic and neural AI systems may be especially helpful. A significant advancement in SR is the ability to move beyond purely data-driven approaches by incorporating existing scientific knowledge and physical constraints directly into the search process. This can improve the efficiency of the search and the physical plausibility of the discovered equations. Examples of such prior knowledge include: • Symmetries: Imposing known symmetries of the system (e.g., translational, rotational, parity) on the candidate equations. • Conservation laws: Requiring that the discovered equations respect known conservation principles (e.g., conservation of energy, momentum, or mass). • Known asymptotic behaviors or boundary conditions: Guiding the search towards functions that satisfy known limits or conditions. • Partial or incomplete theoretical models: Using SR to discover missing terms or functional forms within an otherwise established theoretical framework. • Dimensional homogeneity: Ensuring that all terms in an equation have consistent physical units. Explicit incorporation of such constraints effectively reduces the search space and steers algorithms towards more meaningful and physically sound solutions. The combination of symbolic regression with foundation models such as large language models represents a nascent but highly promising avenue for future development. Foundation models, trained on vast corpora of text or code, possess remarkable capabilities in natural language understanding, generation, and even rudimentary reasoning. This opens up several possibilities for enhancing SR: • Hypothesis generation: LLMs could analyse scientific literature or problem descriptions to suggest relevant physical variables, potential functional forms, or applicable physical principles, thereby helping to define and constrain the search space for SR. • Interpretation and explanation: LLMs could translate the often complex mathematical expressions discovered by SR into intuitive natural language explanations, making the results more accessible to a broader scientific audience or aiding in the formulation of new hypotheses. • Code generation: LLMs can assist in the practical aspects of SR by generating code to set up SR experiments, implement the discovered models in simulation environments, or interface SR algorithms with data acquisition systems. • Bridging data and background knowledge: LLMs could generate or formalize constraints and search drivers for SR based on background knowledge such as qualitative rules or existing theory. Compact, causal models produced by SR could then be integrated with the help of LLMs into a broader simulation framework. This synergy could potentially 6 royalsocietypublishing.org/journal/rspa Proc R Soc A 0000000 

> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

bridge the gap between purely data-driven discovery and theory-driven simulation, enabling more powerful and flexible modeling of complex physical phenomena. 

# 7. The Meeting 

The meeting on Symbolic Regression in the Physical Sciences , held on the 28 th and 29 th of April, 2025, was a snapshot of the current state of affairs in the field and attempted to cover a broad range of topics. Methodology was at the forefront with a number of talks presenting novel techniques for searching, classifying and, most notably, introducing a level of statistical rigour which has been mostly absent in the field. Harry Desmond presented the main ideas behind Exhaustive Symbolic Regression and advocated for the use of Descripion Length as a particularly useful approach for ranking expressions, while Roger Guimerá explained the strategy behind the Bayesian Machine Scientist, invoking the similarity between Bayesian model selection and Statistical Physics. Cristina Cornelio advocated for two algorithms – AI-Descartes and AI-Hilbert – which incorporate some of the axiomatic and formal proof methods inherent in mathematics, and Geoffrey Bomarito presented the strengths of introducing posterior sampling in genetic programming searches for optimal expressions. Bogdan Burlacu presented a novel approach for duplicate detection using Zobrist hashing while, with similar motivation, Fabricio Olivetti de Franca proposed the use of equality graphs as a compact way of storing expressions which can facilitate the identifying of recurrences. Etienne Russeil presented his approach for using multiple data sets to go from independent experiments to general laws. There was an opportunity in the meeting to discuss fully developed packages with impressive results: Miles Cranmer presented PySR, a widely used genetic programming based symbolic regression code, J. Nathan Kutz advocated for the use of SHRED, applying sparse regression in the latent space, and William La Cava discussed his multi-objective symbolic regression framework, BRUSH, and model interpretability in the medical domain. A key aspect of the workshop was a close look at applications. As well as the examples presented in the previous papers, Deaglan Bartlett showed how analytic emulators for the power spectrum of large scale structure were far more effective than current, neural net based ones. Tariq Yasin showed how ESR could be used to infer analytic profiles directly from weak lensing data from clusters. Evgeniya Kabliman deployed SR to determine analytic expressions for the material properties of metallic alloys, while Steven Abel was able to construct efficient emulators for beyond-standard-model physics. Finally, Andrei Constantin unearthed an intriguing statistical property in the mathematical formulation of physical laws, akin to Zipf’s law in the analysis of written texts. 

# 8. Challenges and Outlook 

Despite its successes and immense potential, symbolic regression faces ongoing challenges. Scalability to high-dimensional problems remains difficult because the space of possible expressions grows rapidly with the number of inputs. Robustness to noise, outliers, and systematic measurement errors is essential for extracting genuine physical insight rather than reproducing artefacts. Computational limits also constrain the feasibility of searching large expression spaces, motivating the development of more efficient heuristics and search strategies. The risk of identifying mathematically correct but physically meaningless expressions persists. Domain knowledge therefore remains important for formulating well-posed problems, selecting appropriate operators and constraints, and assessing whether discovered relations correspond to genuine mechanisms rather than spurious correlations. Incorporating prior knowledge through existing fits, physical symmetries, or analytically motivated extrapolation behaviour can also reduce the effective search space and improve efficiency compared with purely exploratory approaches. 7 royalsocietypublishing.org/journal/rspa Proc R Soc A 0000000 

> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

The Royal Society meeting highlighted these issues in detail. Participants emphasised that traditional fit metrics such as mean-squared error are insufficient for assessing the usefulness of a symbolic model, as good interpolation does not guarantee sensible extrapolation or physical plausibility. Additional criteria such as interpretability, simplicity, and robustness under uncertainty were viewed as essential, with approaches like Minimum Description Length providing a principled mechanism for complexity control. There was also sustained discussion about how uncertainty in the data propagates into symbolic expressions, and the need for methods that provide confidence assessments and identify the regimes in which a discovered model can be trusted. The meeting further stressed that symbolic regression’s computational and combinatorial burdens remain fundamental constraints. Even with constrained operator sets or bounded expression complexity, the problem is formally NP-hard, and exhaustive methods face clear trade-offs between optimality, cost, and functional flexibility. Hierarchical or hybrid modelling approaches, in which global structure is shared and dataset-specific parameters vary locally, were proposed as one way to extend the applicability of symbolic regression while mitigating some of these challenges. 

# 9. Conclusion 

Symbolic regression stands as a distinctive and increasingly powerful tool in the arsenal of computational science. Its unique ability to derive explicit mathematical models from data endows it with a dual role: it is both a powerful engine for fundamental scientific discovery, particularly in understanding complex emergent phenomena, and a practical instrument for creating robust empirical formulae and efficient emulators. The emphasis on interpretability and the generation of new knowledge sets SR apart from many other machine learning paradigms. The path forward for symbolic regression in the physical sciences involves continued algorithmic innovation to address challenges of scalability and robustness, deeper integration of domain-specific knowledge to guide the discovery process, creative synergies with complementary AI technologies like large language models, and increasing application to real-world problems in the physical sciences. As these developments unfold, symbolic regression is poised to play an increasingly influential role in accelerating the pace of discovery and deepening our understanding of the complex mathematical tapestry that underlies the physical world. 

# References 

1. Lenat DB. 1977 Automated theory formation in mathematics. In Proceedings of the 5th International Joint Conference on Artificial Intelligence - Volume 2 IJCAI’77 pp. 833–842 San Francisco, CA, USA. Morgan Kaufmann Publishers Inc. 2. Langley P, Bradshaw GL, Simon HA. 1981 BACON.5: the discovery of conservation laws. In 

Proceedings of the 7th International Joint Conference on Artificial Intelligence - Volume 1 IJCAI’81 pp. 121–126 San Francisco, CA, USA. Morgan Kaufmann Publishers Inc. 3. Falkenhainer BC, Michalski RS. 1986 Machine Learning 1, 367–401. (10.1023/a:1022866732136) 4. Dzeroski S, Todorovski L. 1995 Discovering dynamics: From inductive logic programming to machine discovery. Journal of Intelligent Information Systems 4, 89–108. (10.1007/bf00962824) 5. Koza JR. 1992 Genetic Programming: On the Programming of Computers by Means of Natural Selection . MIT Press. 6. Cranmer M. 2023 Interpretable Machine Learning for Science with PySR and SymbolicRegression.jl. (10.48550/ARXIV.2305.01582) 7. Burlacu B, Kronberger G, Kommenda M. 2020 Operon C++: an efficient genetic programming framework for symbolic regression. In Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion GECCO ’20 p. 1562–1570 New York, NY, USA. Association for Computing Machinery. (10.1145/3377929.3398099) 8. Udrescu SM, Tegmark M. 2020 AI Feynman: A physics-inspired method for symbolic regression. Science Advances 6, eaay2631. (10.1126/sciadv.aay2631) 8 royalsocietypublishing.org/journal/rspa Proc R Soc A 0000000 

> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

9. Cornelio C, Dash S, Austel V, Josephson TR, Goncalves J, Clarkson KL, Megiddo N, El Khadir B, Horesh L. 2023 Combining data and theory for derivable scientific discovery with AI-Descartes. Nature Communications 14 . (10.1038/s41467-023-37236-y) 10. Sahoo S, Lampert C, Martius G. 2018 Learning Equations for Extrapolation and Control. In Dy J, Krause A, editors, Proceedings of the 35th International Conference on Machine Learning 

vol. 80 Proceedings of Machine Learning Research pp. 4442–4450. PMLR. 11. Landajuela M, Lee CS, Yang J, Glatt R, Santiago CP, Aravena I, Mundhenk T, Mulcahy G, Petersen BK. 2022 A Unified Framework for Deep Symbolic Regression. In Koyejo S, Mohamed S, Agarwal A, Belgrave D, Cho K, Oh A, editors, Advances in Neural Information Processing Systems vol. 35 pp. 33985–33998. Curran Associates, Inc.