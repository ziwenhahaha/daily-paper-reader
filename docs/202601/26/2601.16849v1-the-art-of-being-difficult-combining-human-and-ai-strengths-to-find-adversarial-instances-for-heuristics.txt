Title: The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics

URL Source: https://arxiv.org/pdf/2601.16849v1

Published Time: Mon, 26 Jan 2026 02:00:09 GMT

Number of Pages: 18

Markdown Content:
# THE ART OF BEING DIFFICULT :COMBINING HUMAN AND AI S TRENGTHS TO FIND 

# ADVERSARIAL INSTANCES FOR HEURISTICS 

Henri Nikoleit 

University of Bonn lumimail@proton.me 

Ankit Anand 

Google DeepMind anandank@google.com 

Anurag Murty Naredla 

University of Manitoba anurag.naredla@umanitoba.ca 

Heiko R¨ oglin 

University of Bonn roeglin@cs.uni-bonn.de 

## ABSTRACT 

We demonstrate the power of human-LLM collaboration in tackling open prob-lems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch’s outputs, we identify improved constructions for hierarchical k-median clustering, bin packing, the knapsack problem, and a generalization of Lov´ asz’s gasoline problem—some of these have not seen much improvement for over a decade, despite intermittent attention. These results il-lustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers. Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collab-orative tool in mathematics and computer science research. 

## 1 INTRODUCTION 

Artificial Intelligence has advanced mathematics and theoretical computer science significantly, driving progress by proposing new conjectures in knot theory (Davies et al., 2021), devising novel algorithms (Fawzi et al., 2022), and discovering new lower bounds and combinatorial construc-tions (Romera-Paredes et al., 2024; Novikov et al., 2025; Wagner, 2021; Mehrabian et al., 2023). While impactful, many of these efforts (Fawzi et al., 2022; Wagner, 2021; Mehrabian et al., 2023) rely on black-box neural networks or conventional metaheuristics such as tabu search and simulated annealing. A drawback of these methods is their opacity; they often yield results without provid-ing the structural insights necessary for human experts to generalize or understand the underlying mechanisms. However, recently, large language models in works like (Romera-Paredes et al., 2024; Novikov et al., 2025) have addressed this problem by using programs to represent complex mathematical objects and solutions compactly. The generated program is interpretable by humans and can be potentially modified to guide the LLM iterations in the right direction. Many combinatorial optimization problems have widespread real-world applications but are com-putationally intractable (e.g., NP-hard). A natural way to address these problems in practice is to devise new heuristics. It is equally important to analyze and understand when and how these heuristics fail. Analyzing the worst-case performance of heuristics can explain their performance in real-world applications, and knowledge of adversarial instances can help devise better heuristics. In this work, we use the Human-LLM collaboration to generate adversarial examples for heuristics for a variety of combinatorial optimization problems. Specifically, we target well-known algorithms 1

> arXiv:2601.16849v1 [cs.LG] 23 Jan 2026

for the knapsack problem, bin packing, hierarchical clustering, and a variant of Lov´ asz’s gasoline puzzle, establishing improved lower bounds for each. Our use of LLMs follows the FunSearch paradigm Romera-Paredes et al. (2024) that has improved existing bounds in the cap-set problem and bin-packing heuristics. Unlike most previous work, human-AI collaboration for our target problems is necessary to provide the final theoretical results and proofs. Initial Program Trivial Prompt P 0

> Program Evaluation
> Executes code and compute score
> Large Language Model
> Generates improved code P`
> Simplify and Generalize
> Remove redundancy and Generalized logic
> Human Expert Analysis
> Identified patterns and structure
> Final Output
> New Lower Bounds and Proofs
> Program Database
> Stores Programs and scores FunSearch Cycle
> (Automated)
> Human Collaboration
> (“Co”-part)
> Theoretical Analysis
> Sampled Programs
> Add Score and Metadata
> Feedback Loop
> Best Programs
> Manual Refinement

Figure 1: A diagrammatic representation of Co-FunSearch. 

Methodology. Our proposed framework, which we call, Co-FunSearch (short for Collaborative FunSearch ), is summarized in Figure 1. We begin with initial low scoring instances given to Fun-Search as input and analyze the programs generated by FunSearch that achieve the highest scores. Some of the generated programs have interpretable structures relevant to the task, while others rely on hard-coded constants and offer little insight. We then manually refine the promising programs, re-moving components whose elimination does not reduce performance and simplifying the remaining logic wherever possible. For example, this may involve removing redundant elements of lists (Fig. 2, Fig. 5), or simplifying a list of n ascending numbers into a list containing the mean of those num-bers n times (Fig. 5). Afterward, we attempt to prove statements about the scores of the instances, or otherwise feed the simplified programs back into FunSearch to obtain better results. These modi-fications were essential for generating meaningful structures, insights and obtaining state-of-the-art results.More importantly, the collaborative workflow demonstrates FunSearch’s potential for pro-ductive partnerships between computing experts and AI systems. 

Summary of Results. Table 1 summarizes our main results on all the problems. With Co-FunSearch, we were able to disprove that the Nemhauser-Ullmann heuristic for the knapsack problem has output-polynomial running time, and we improve the lower bound of the best fit heuristic for bin packing in the random order model from 1.3 to 1.5. We also obtained the 

first non-trivial lower bound of the golden ratio for the price of hierarchy for k-median cluster-ing, and disprove the conjecture that the iterative rounding algorithm for the generalized gaso-line problem is a 2-approximation. We provide the source code for all the implementations at 

https://github.com/lumi-a/funsearch .

Why not Local Search? FunSearch offers three distinct advantages over local search. First, while local search isolates single vectors, FunSearch discovers generic Python programs that scale with instance parameters. Second, it yields interpretable, modifiable code rather than opaque numeric vectors. Third, FunSearch exploits the low Kolmogorov complexity inherent in optimization prob-lems, capturing structural symmetries that local search ignores. Notably, in bin packing, FunSearch generalized a pattern to obtain a lower bound of 1.5 (surpassing the previous 1.3), whereas local search produced unstructured solutions (see Table 2). 2Method Knapsack Bin-Packing k-median Gasoline Previous Best Known Lower Bound 2.0 1.3 1.0 2.0

Local Search 1.93 1.478 1.36 2.11 

FunSearch 646.92 1.497 1.538 3.05 

Co-FunSearch nO(√n) 1.5 1.618 4.65 

Known Upper Bound O(2 n) 1.7 16 None Table 1: Comparison of Co-FunSearch with base FunSearch, local search and SOTA on different problems. The given values for local search and FunSearch are the maxima across 30 trials each. Local Search FunSearch Co-FunSearch Items 0.003 0.08 0.167 0.005 0.08 0.167 0.006 0.08 0.167 0.007 0.08 0.167 0.021 0.08 0.167 0.068 0.114 0.167 0.073 0.114 0.143 0.170 0.114 0.143 0.202 0.114 0.143 0.219 0.114 0.143 0.306 0.114 0.143 0.375 0.114 0.143 0.540 0.2 0.143 0.6 Table 2: Comparing the final instances found by local search, FunSearch and Co-FunSearch for the randomised Best-Fit bin-packing problem. 

## 2 PROBLEMS AND NOTATION 

2.1 GENERAL FRAMEWORK FOR ADVERSARIAL INSTANCE GENERATION 

We first propose a general framework for generating adversarial instances for any given heuristic, and then describe the particular problems we focus on in this work and how we instantiate this gen-eral framework for the given problem. Given an optimization problem (without loss of generality, a minimization problem), a heuristic algorithm H and a (computationally expensive) optimal algo-rithm Opt , the goal is to construct an instance I where the heuristic performs poorly with respect to Opt . More concretely for minimization problems, we aim to construct an adversarial instance I

such that the ratio R = Score( H(I)) Score( Opt (I)) is large, where Score( H(I)) denotes the value yielded by the heuristic algorithm and Score( Opt (I)) denotes the optimum value for I.While methods like local search, tabu search, and genetic algorithms have focused on generating adversarial instances for heuristics, this work focuses on using language models for generating the instances. Specifically, we model each instance as output of a program P s.t. I = Output( P).Initially, a trivial instance is expressed as program P0. In addition, we prompt a large language model L that has proficiency in code generation and reasoning. At each iteration i, the language model takes as input one of the previously generated programs, p = P<i and generates an improved version p′ of p such that it improves the reward R. We specifically follow the evolutionary approach used in Romera-Paredes et al. (2024) for generating these programs and optimizing the reward R.2.2 PROBLEMS AND HEURISTICS 

We focus on four distinct problems and their corresponding heuristics to illustrate the effectiveness of this approach. These problems vary from knapsack, bin-packing, hierarchical clustering to the gasoline puzzle by Lov´ asz. While the approach is general, we believe the specific instantiation on these problems provides a general lens to find adversarial instances for any given heuristic. 32.2.1 NEMHAUSER -U LLMANN HEURISTIC FOR THE KNAPSACK PROBLEM 

In the classical NP-hard knapsack problem, an input consists of a set of n items, where each item 

i ∈ [n] has a profit pi ∈ R>0 and a weight wi ∈ R>0. Additionally, a capacity t ∈ R>0 is given, and the goal is to find a subset I ⊆ [n] of the items such that the profit P 

> i∈I

pi is maximized under the constraint P 

> i∈I

wi ≤ t. Without a given capacity t, the knapsack problem can also be viewed as a bi-objective optimization problem, where one wants to find a subset with small weight and large profit. These two objectives are obviously conflicting and there is no clear optimal solution anymore, but one rather has to find a good trade-off between the criteria. In multi-objective optimization, it is very common to compute the set of Pareto-optimal solutions where a solution is called Pareto-optimal if there does not exist another solution that is simultaneously better in all objectives (see, e.g., Ehrgott (2005) for a comprehensive overview). Only Pareto-optimal solutions constitute reasonable trade-offs and for many multi-objective optimization problems, algorithms for computing the set of Pareto-optimal solutions are known (e.g., for the multi-objective shortest path problem (Corley & Moon, 1985)). These are usually no polynomial-time algorithms, as the set of Pareto-optimal solutions can be of exponential size. However, in practice the Pareto set is often small and one is interested in finding algorithms that are output-polynomial time, i.e., whose running time depends polynomially on the input and the output size. Such algorithms are efficient if the Pareto set is small, which is often the case in applications. 

Nemhauser-Ullmann Heuristic It is an open problem whether output-polynomial time algo-rithms for the knapsack problem (viewed as a bi-objective optimization problem) exist (R¨ oglin, 2020). The best candidate for such an algorithm is the Nemhauser-Ullmann algorithm, which is based on dynamic programming (Nemhauser & Ullmann, 1969). For a given instance of the knap-sack problem with n items, it computes iteratively the Pareto sets P1, . . . , Pn, where Pi denotes the Pareto set of the sub-instance that consists only of the first i items (i.e., Pn is the Pareto set of the en-tire instance). The Nemhauser-Ullmann algorithm can be implemented to run in time O(Pni=1 |P i|).If there was an α such that |P i| ≤ α|P n| for each instance and each i, one could bound the running time by O(αn |P n|), which would result in an output-polynomial time algorithm as long as α grows at most polynomially with n. So far, no instances were known where an intermediate set Pi is larger than the final Pareto set Pn by more than a small constant factor. With the help of an instance gen-erated by FunSearch, we construct a sequence of instances disproving that the Nemhauser-Ullmann algorithm has output-polynomial running time. 2.2.2 BEST -F IT HEURISTIC FOR BIN PACKING 

Bin Packing is a classical NP-hard optimization problem that has been studied extensively as an online problem. In this problem, items with sizes w1, w 2, w 3, . . . arrive one by one and an online algorithm has to assign each item irrevocably to a bin when it arrives. There is an unlimited number of bins with a fixed capacity c available. The goal is to use as few bins as possible to pack all items. In the online setting, simple algorithms like First-Fit and Best-Fit have been studied, which pack each arriving item into the first bin into which it fits or the fullest bin into which it fits, respectively. To mitigate the power of the adversary in classical worst-case analysis, these algorithms have been studied extensively in the random order setting, in which an adversary chooses the items’ sizes but the items arrive in a random order. In the unshuffled setting, D´ osa & Sgall (2014) proved an upper bound of 1.7 on the approximation-ratio of Best-Fit. This means that, on any instance, the expected number of bins used by Best-Fit is at most 1.7 times the optimal number. As this holds for any instance, this upper bound also applies to the shuffled setting. In the shuffled setting, the best-known lower bound was 1.3, i.e., there exists an instance such that, when the instance is shuffled, Best-Fit needs at least 1.3 times the optimal number of bins, in expectation (Albers et al., 2021). With the help of FunSearch, we improve this lower bound to 1.5.2.2.3 K-MEDIAN IN HIERARCHICAL CLUSTERING 

Hierarchical clustering is an important research topic in unsupervised learning. In such a clustering problem, usually a data set X with n points is given and one seeks for a sequence H1, . . . , Hn of clusterings, where each Hk is a k-clustering of X, i.e., a partition of X into k parts. The clusterings must be hierarchically compatible, meaning that each Hk is obtained from Hk+1 by merging two clusters. To evaluate the quality of such a hierarchical clustering, a common approach is to choose an 4objective function Φ like k-center, k-median, or k-means and to compare each clustering Hk with an optimal k-clustering OPT k with respect to the objective Φ. Then the approximation factor α of the hierarchical clustering can be defined as the worst approximation factor of any of the levels, i.e., α =max k∈[n] Φ( Hk)/Φ(OPT k) (see, e.g., Lin et al. (2010)). Since the optimal clusterings are usually not hierarchically compatible, an approximation factor of 1 cannot be achieved even with unlimited running time. Arutyunova & R¨ oglin (2025) defined the price of hierarchy of a clustering objective 

Φ as the best approximation factor that can be achieved for any clustering instance. They showed, e.g., that the price of hierarchy for the k-center objective is exactly 4, meaning that for any instance of the hierarchical k-center problem there exists a hierarchical clustering with an approximation factor of 4 and that there exists an instance for which any hierarchical clustering does not have a better approximation factor than 4. For the k-median problem, no non-trivial lower bound on the price of hierarchy is known. The best known upper bound is 16 for general metrics (Dai, 2014). We obtain the first non-trivial lower bound for the price of hierarchy for the k-median problem, showing that it is at least the golden ratio, ≈1.618 .2.2.4 GASOLINE PROBLEM 

The Gasoline problem is a combinatorial optimization problem inspired by Lov´ asz’s gasoline puz-zle (Lov´ asz, 2007). In an instance of this problem, we are given two sets X = {x1, . . . , x n} and 

Y = {y1, . . . , y n} of non-negative numbers with the same sum. The goal is to find a permutation π

of the set X that minimizes the value of η such that      

> ∀[k, ℓ ] : X
> i∈[k,ℓ ]
> xπ(i)−X
> i∈[k,ℓ −1]
> yi≤η.

Given a circle with n points labeled 1 through n, the interval [k, ℓ ] denotes a consecutive subset of integers assigned to points k through ℓ. For example, [5 , 8] = {5, 6, 7, 8}, and [n − 1, 3] = 

{n − 1, n, 1, 2, 3}. The intuition is that the yi-values correspond to road segments on a cycle and the xi-values correspond to fuel canisters that can be placed between the segments. The goal is to distribute the canisters such that one can get around the cycle with the smallest possible fuel tank capacity η.The Gasoline problem is known to be NP-hard, and a 2-approximation algorithm for it is known (Newman et al., 2018). It is an open problem whether better approximation algorithms or even a polynomial-time approximation scheme exist. In the literature, another heuristic for the problem has been considered that is based on iteratively rounding the linear programming relaxation (Ra-jkovi´ c, 2022). The approximation guarantee of this algorithm is unknown. In his master’s thesis, Lorieau constructed a class of instances showing that its approximation factor is not better than 2

(Lorieau, 2024). Lorieau conjectured that it is actually a 2-approximation algorithm, but this has not been proven yet. The iterative rounding algorithm is interesting because it generalizes canonically to a d-dimensional Gasoline problem in which xi and yi are d-dimensional vectors. Also for this generalization, the best-known lower bound was 2 and Lorieau conjectured that also for this gen-eralization the algorithm achieves a 2-approximation. With Co-FunSearch, we obtain a family of instances disproving this conjecture. 

## 3 EXPERIMENTAL DETAILS AND RESULTS 

We compare Co-FunSearch to base FunSearch and local search on the above 4 problems. The main goal in all these problems is to search for a vector v (encoding the instance) which optimizes the given objective (usually some performance-measure of some heuristic on this specific instance). The objectives depend on the problem, and can be found in Section 3.3. Random search works by initializing a random vector v. At each step, sample a random vector v′ close to v and check if v′

improves on the objective. If it does, replace v by v′ with some probability p, otherwise keep v

unchanged. This procedure keeps improving on the objective until reaching a local minimum. For our experiments, v′ arises from v by adding independent normally-distributed noise with mean 0

and variance s · (1 − ttmax ) to each coordinate of v (clipping v′ to the problem’s bounds as required), where t is the current time since the start of the search, tmax is the time after which we terminate the search (set to 3 minutes), and s is a problem-specific parameter. For the knapsack-problem, we chose 20 items and s = 1000 , because both weights and profits were rounded before evaluation to be less sensitive to floating-point imprecision. For bin-packing, we chose 13 bins with capacity 51 and s = 0 .2. For weighted hierarchical clustering, we chose 8 points, s = 0 .2, and replaced each point’s weight w to 2w before evaluation, because we observed worst-case instances’ weights frequently spanning several orders of magnitude. For the two-dimensional gasoline-problem, we chose s = 0 .2 and |X| = |Y | = 14 .FunSearch works similarly: Instead of searching for a vector v that has a high objective, it searches for a Python-program P outputting a vector with high objective. Sampling a Python-program P ′

“close” to P is not done by randomly changing characters in the program’s source-code, but by prompting an LLM with the source-code of P , requesting a similar program which improves the score. The scoring-function is not provided to the LLM. The newly generated program (if it executes without error) is added to a database of programs with its score. In the next iteration, a new program is sampled from the database according to a probability distribution and the process is repeated. More details about the evolutionary search can be found in Romera-Paredes et al. (2024). To evaluate a given program, we use problem-specific scoring-functions, described in their respective sections below. 3.1 RESULTS 

Table 1 outlines the main results for all four problems. Our main results are as follows: • For the knapsack problem, the local search method only achieves 1.93 , whereas FunSearch found instances with a score of 646 .92 . The compact program found by FunSearch could be improved to a general super-polynomial bound nO(√n). Since then, an unrelated expo-nential bound has been found, discussed in (Nikoleit, 2025). Also this bound was optimized using Co-FunSearch. • For the Best-Fit heuristic for bin packing, FunSearch finds an instance which is 1.497 times worse than optimal, outperforming both the existing SOTA ( 1.3) and local search ( 1.478 ). This instance could easily be generalized, yielding an asymptotic bound of 1.5.• For the hierarchical k-median problem, no non-trivial lower bounds were previously known. FunSearch ( 1.538 ) outperforms local search ( 1.36 ) with an instance that we could modify to yield a lower bound of the golden ratio ( ≈1.618 ). • Lastly, in Lov´ asz’s gasoline problem, FunSearch ( 3.05 ) outperforms both the SOTA ( 2.0)and local search ( 2.11 ), and could be further improved to 4.65 .

Generated Programs with FunSearch and Co-FunSearch In this section, we illustrate the pro-grams found by FunSearch and how these programs are modified by experts to obtain adversarial instances which are much better in score and are generalizable with guarantees. Fig. 2a shows the initial program given in the bin-packing problem, Fig. 2b shows the instance generated by Fun-Search, which achieves a score of 1.4978 , and Fig. 2c shows how we generalized this instance: The instance consists of two types of items in a list which are generalized as entries “ a” and “ b” in the figure. Specifically, for large a and b, this instance’s score approaches 1.5. Similar to Figure 2, we compare the initial program, the program generated by FunSearch, and the program obtained via human collaboration for the knapsack (Figure 4), hierarchical clustering (Figure 5), and the gasoline problem (Figure 6). 3.2 ABLATIONS 

Figure 3 shows the search dynamics with variations across different models, the temperature param-eter and the initial program used during FunSearch. In all these experiments, we plot the maximum score of samples produced so far against the number of samples (LLM-prompts), together with the standard error across 30 trials. To illustrate the effect of variations and due to high computational cost (inference costs) of each experiment, we undertake these ablations on a single problem but believe similar trends would hold for all the other problems as well. 

Variations across different models: Fig. 3a shows the variations with two models from OpenAI, gpt-4.1-mini (OpenAI, 2025a) and gpt-4.1-nano (OpenAI, 2025b) with Mistral AI’s open-mistral-nemo model (Mistral AI, 2024). We observe that gpt-4.1-nano slightly outperforms gpt-4.1-mini. This is a bit counterintuitive, as gpt-4.1-mini is a more powerful model than gpt-4.1-nano. To inves-tigate this further, we plot the both the maximum score and the rolling average score of the last 10 samples (Figure 3b). Here, gpt-4.1-mini outperforms gpt-4.1-nano on the rolling average but per-6def get_items() -> list[float]:                       

> """Return anew bin-packing-instance, specified by the list of items. The items must be floats between 0and 1."""
> items =[0.4, 0.5, 0.6]
> return items

(a) Initial program.                                                                   

> def get_items() -> list[float]:
> """Return anew bin-packing-instance, specified by the list of items. The items must be floats between 0and 1.""" """Yet another version of `get_items_v0 `,`get_items_v1 `,and `get_items_v2 `,with some lines altered.""" ,→
> items =[0.8, 0.2, 0.6, 0.4]
> #Split the first item into seven smaller items and the fourth item into five smaller items ,→
> items =[0.114, 0.114, 0.114, 0.114, 0.114, 0.114, 0.114] +items[1:3] +[0.08, 0.08, 0.08, 0.08, 0.08] ,→
> return items

(b) A program found by FunSearch after 10 trials of 2,400 samples each.                   

> def get_items() -> list[float]: a=7b=5
> return [1.0 /a] *a+[1.0 /b] *b

(c) An intermediate step of tuning program in Figure 2b by hand 

Figure 2: The evolution of programs generating bin packing instances, with model open-mistral-nemo and a temperature of 1.5.forms slightly poorer on the maximum score, highlighting that, although larger models are stronger on average, in problems with verifiable score where one cares about the best performing sample, smaller models are sufficient and can outperform larger ones. 

Variations across temperature: Fig. 3c shows the variations of the objective function with the change in the sampling temperature. The sampling temperature is an indicator of sharpness of the LLM’s probability distribution for each sample (the lower the temperature, the more sharp it is). We observe that the higher sampling temperature performs better than lower sampling temperature, owing to high entropy of samples produced in inference. It should be noted that we plot the best score obtained across all samples as objective, so even if the mean performance drops, the best sample is better owing to increase in entropy and diversity. 

Variations across initial prompts: Another critical hyperparameter in FunSearch as outlined by Romera-Paredes et al. (2024) is the initial instance given to a FunSearch experiment. In Fig. 3d, we vary the initial program for FunSearch on the bin packing problem. We observe that a trivial instance with a more flexible structure (a for-loop adding the items 1/i for i ∈ { 1, ..., 10 }) starts from a low initial score but improves as more and more samples are drawn in FunSearch. Additionally, we hard-code a trivial instance as numbers without appropriate structure, and although this improves with more samples, the performance is inferior to both the trivial instance with the structure and the best known construction. Observing the output, the variations introduced by FunSearch consist of different hardcoded numbers, as opposed to inserting more structure, like loops or maths-functions, into the program. This highlights the importance of an appropriate structure and skeleton for the initial program in FunSearch. We compare this with using the best known construction (Albers et al., 2021) as the initial instance, which does start from a high score initially but stagnates quickly with iterations. 3.3 CO-F UN SEARCH AND KEY RESULTS 

In this section, we highlight how we used FunSearch to find instances and generalized them to achieve improved lower bounds for each problem. Furthermore, we also provide proofs for lower bounds for most of these instances. 70 200 400 600 800 1000 

> Time (samples)
> 1.00
> 1.05
> 1.10
> 1.15
> 1.20
> 1.25
> 1.30
> Objective
> gpt-4.1-mini
> gpt-4.1-nano
> open-mistral-nemo

(a) 0 200 400 600 800 1000  

> Time (samples)
> 1.00
> 1.05
> 1.10
> 1.15
> 1.20
> 1.25
> 1.30
> Objective
> gpt-4.1-mini (max)
> gpt-4.1-mini (moving average)
> gpt-4.1-nano (max)
> gpt-4.1-nano (moving average)

(b) 0 200 400 600 800 1000 

> Time (samples)
> 1.00
> 1.05
> 1.10
> 1.15
> 1.20
> 1.25
> 1.30
> Objective
> T=1.0
> T=1.25
> T=0.8

(c) 0 200 400 600 800 1000  

> Time (samples)
> 1.0
> 1.1
> 1.2
> 1.3
> 1.4
> Objective
> Trivial, hardcoded numbers
> Albers-Khan-Ladewig's instance
> Trivial, loop-structure

(d) 

Figure 3: Comparing the effect of different hyperparameters on the objective function in bin pack-ing.(a) Comparing different models, each with temperature 1.0 and starting with a hard-coded in-stance.(b) Comparing rolling average (10 samples) and max-performance of gpt-4.1-mini with gpt-4.1-nano, with temp: 1.0.(c) Variation of different sampling temperatures for gpt-4.1-mini, each starting with a hard-coded instance.(d) Variation of initial instances for gpt-4.1-mini with tempera-ture 1.0.3.3.1 KNAPSACK PROBLEM 

We consider the knapsack problem (as described in Section 2.2.1) as a bi-criteria optimization prob-lem, where we want to minimize the total weight while maximizing the total profit. We used Fun-Search to find instances I that have a high score max 1≤i≤n |P i(I)|/|P (I)|, i.e., where the Pareto set 

Pi(I) of a sub-instance Ii, which consists only of the first i items of I, is much larger than the Pareto set P(I) of the entire instance I. The sizes of the intermediate and final Pareto-sets are obtained as a by-product of running the Nemhauser-Ullmann algorithm on I. Items are written as tuples of the form (weight, profit). We obtain the code (as shown in Figure 4b in Appendix) after running FunSearch for 10 trials of 500 samples each. Having simplified the output (shown in Fig. 4c), we can scale all items’ weights up by a factor of 2 (which does not affect Pareto-optimality), decrease some profits by 1, and change the last item to obtain the following tidier instance, which achieves slightly higher scores for the same 

n:

 88



, ..., 

88

| {z } 

> ntimes

,

21



, ..., 

21

| {z } 

> ntimes

,

44



,

22

 

.

From here, we attempted to prove results about the instance. After a first draft, we found it more natural to replace the first n items by n powers of 2, and saw that stronger results are possible by replacing the last two items by k powers of 2:

 22k

22k



,

22k+1 

22k+1 



, ..., 

22k+n

22k+n



,

 2k

2k − 1



, ..., 

 2k

2k − 1

| {z } 

> ntimes

,

22k−1

22k−1



,

22k−2

22k−2



,..., 

2k+1 

2k+1 

 

.

8Finally, to apply our result not only to the size of the Pareto sets but also to the runtime of the Nemhauser-Ullmann algorithm 1, we appended the factors xi := (1 + 2−i  

> 2k−1

) to the n center items: 

 22k

22k



, ..., 

22k+n

22k+n



,

 x1 · 2k

x1 · (2 k − 1) 



, ..., 

 xn · 2k

xn · (2 k − 1) 



,

22k−1

22k−1



, ..., 

2k+1 

2k+1 

 

.

(1) By choosing k = log 2(√n) + 1 , this instance shows: 

Theorem 3.1. The Nemhauser-Ullmann algorithm does not have output-polynomial running time. 

Before this work, no such instances were known. We refer to Appendix 5.1 for further details and proofs. After finding this instance, we found an independent construction that even shows an exponential lower bound. See (Nikoleit, 2025, Corollaries 4.2.10 and 4.2.11) for details. This lower bound was also obtained by Co-FunSearch. 

3.3.2 BIN -P ACKING 

As outlined in Section 2.2.2, we study the Best-Fit heuristic for the bin packing problem in the random-order setting. To evaluate a generated instance, we compute the value vopt of an optimum solution with a solver described and implemented in Fontan & Libralesso (2020), then compute the mean vappx of 10,000 trials of the Best-Fit algorithm when the instance is shuffled randomly, and assign the instance a score of vappx  

> vopt

.Fig. 2 shows the programs generated by FunSearch. It is straightforward to observe that Fig. 2b has multiple repetitions. We simplified this code to a list with only two parameters (Fig. 2c). 

Instance Generated by Co-FunSearch: For fixed m ∈ N, consider the instance with maximum bin capacity 

c := m · (m + 1) and items: 

[m + 1 , . . . , m + 1 

| {z } 

> mtimes

, m, . . . , m 

| {z } 

> m+1 times

].

An optimal packing puts the first m items into one bin, and the remaining m + 1 items into a second bin. This fills both bins exactly to their maximum capacity. Because m and m + 1 are coprime, these are the only two ways of filling a bin exactly to its maximum capacity c. Hence, if any bin contains both an item m and an item m + 1 , the packing must use at least 3 bins. Because the instance is shuffled, Best Fit will put both an item of size m and an item of size m + 1 into the same bin with high probability, approaching probability 1

for growing m. Thus, with high probability, Best-Fit will use at least 3 bins, which shows that the absolute random-order ratio of Best-Fit is at least 3/2 (the previous best known lower bound was 1.3, by Albers et al. (2021)). Combining with the results of D´ osa & Sgall (2014), we obtain the following theorem: 

Theorem 3.2. The absolute random-order ratio of Best-Fit is between 1.5 and 1.7.

3.3.3 HIERARCHICAL CLUSTERING 

In clustering, we’re given a set of n weighted points and a number k, with the task of finding a partition of the set of points into k clusters such that the total cost of the clustering is small. In k-median clustering, the points are a finite subset of Rd and the cost of a cluster C is defined as the sum of the weighted L1-distances all points have to the center, where the center is the best possible choice within that cluster: 

Cost( C) = min 

> p∈C

X

> q∈C

w(q)∥p − q∥1

Here, w(q) is the weight of q as specified by the instance. The total cost of a clustering is the sum of the costs of its clusters. Clustering is used to analyze empirical data, but it’s usually not clear what number of clusters k is a good choice for the dataset. Instead of computing a clustering for a fixed k, one could compute a Hierarchical Clustering ,which has a clustering for each k ∈ { 1, ..., n } and these clusterings are nested: A hierarchical clustering 

H = ( H1, ..., H n) consists of n clusterings such that, for all i ∈ { 2, ..., n }, Hi is obtained by merging two clusters of Hi+1 .While hierarchical clusterings have an intuitive structure and don’t require to decide on a number k of clusters beforehand, they come at the disadvantage of their clusterings Hi possibly having a higher cost than the optimal 

> 1

The difference between the size of the Pareto set and the running time of the Nemhauser-Ullmann algorithm is that, for the Nemhauser-Ullmann algorithm, multiple Pareto-optimal solutions with exactly the same profit and weight are treated as a single solution for the running time. 

9i-clustering, because optimal clusterings need not form a hierarchy. For a given instance (a finite set of points in Rd) I, we can measure the performance of a hierarchical clustering H by comparing each of its clusterings 

Hi to the best i-clustering, and choosing the level where this ratio is highest. To measure how much we sacrifice when restricting ourselves to hierarchical clusterings on an instance I, we consider the Price of Hierarchy of I as the best hierarchical clustering according to that measure: 

PoH( I) := min  

> H

max 

> k∈{ 1,...,n }

h Cost( Hk )Cost(OPT k )

i

,

where OPT k denotes an optimal k-clustering for I.The Price of Hierarchy for k-median clustering PoH k-median denotes the worst-case Price of Hierarchy of I

across all possible instances I. Thus, PoH k-median captures the worst-case quality of an optimal hierarchical clustering when compared to an optimal non-hierarchical clustering. With Co-FunSearch, we found the following lower bound construction for the price of hierarchy for k-median clustering (see also Fig. 5). Fix the dimension d ≥ 4. Put c := 

√4d2+(3 −d)2+d−32 , which is one of the two roots of 0 = c2 − c(d − 3) − d2. Because d ≥ 4, we know that 5d2 − 6d ≥ 4d2, hence: 

c =

p4d2 + ( d − 3) 2 + d − 32 > 2d + d − 32 > d. 

Let ei be the ith d-dimensional standard basis vector. Consider the following weighted instance of d + 2 points: 

(1 , . . . , 1) , (0 , . . . , 0) , −ce 1, . . . , −ce d,

where the point (1 , . . . , 1) has weight ∞ and all other points have weight 1.

Theorem 3.3. For k-median clustering, this instance’s price of hierarchy is at least cd .Proof. For contradiction, assume there exists a hierarchical clustering H = ( H1, . . . , H d+2 ) such that, on every level, the cost of Hk is strictly less than cd times the cost of the best clustering using k clusters. This enables us to narrow down the structure of H:• For k = d + 1 , there is one cluster C containing two points, while all other clusters contain only a single point. Depending on which two points constitute C, we can calculate the total cost of the clustering: 

– If C = {(0 , . . . , 0) , (1 , . . . , 1) }, the total cost is: 

∥(0 , . . . , 0) − (1 , . . . , 1) ∥1 = d. 

– If C = {(0 , . . . , 0) , −ce i} for some i, the total cost is c.

– If C = {(1 , . . . , 1) , −ce i} for some i, the total cost is d + c.

– If C = {− ce i, −ce j } for some i̸ = j, the total cost is 2c.Because d < c , this constrains Hk to C = {(0 , . . . , 0) , (1 , . . . , 1) }, otherwise the total cost of Hk

would be at least cd times the cost of an optimal (d + 1) -clustering. • For k = 2 : The clustering now contains exactly two clusters. Because H is a hierarchical clustering, we now know that H2 has a cluster that contains (0 , . . . , 0) , (1 , . . . , 1) and some number 0 ≤ n ≤

d − 1 of the −ce i, while its other cluster contains the remaining d − 1 − n of the −ce i. Due to symmetry, this number n is sufficient for calculating the total cost of H2. Because (1 , . . . , 1) has infinite weight, this point must be the center of the first cluster, so this cluster has cost: 

(1 , . . . , 1) − (0 , . . . , 0) 1 + n · (1 , . . . , 1) − (−ce 1) 1 = d + n · (c + d)

The cluster containing the remaining d − 1 − n of the −ce i can choose any point as its center. It has cost: 

(d − 2 − n) · ce 1 − ce 2 1 = ( d − 2 − n) · 2c

Given n, the total cost of H2 is d + c(2 d − 4) + n(d − c). Because d − c < 0, the best choice for n

would be n = d − 1, resulting in a cost of c(d − 3) + d2. This is only a lower bound on the cost of 

H2, because other levels in the hierarchy might put additional constraints on H2.For an upper bound on the optimal cost of a 2-clustering, consider the clustering that has (1 , . . . , 1) 

in its first cluster, and all other points in its second cluster. By assuming the center of the second cluster is (0 , . . . , 0) , we get an upper bound on the total cost of this clustering of: 

d · (0 , . . . , 0) − (−ce 1) 1= d · c. 

Hence, the ratio between the cost of H2 and the cost of an optimal 2-clustering is at least: 

c(d − 3) + d2

d · c = d − 3

d + dc

We defined c as one of the roots of 0 = c2 − c(d − 3) − d2. Dividing out cd , we get d−3 

> d

+ dc = cd .However, this contradicts the assumption that the ratio between H2 and an optimal 2-clustering is strictly less than cd .

10 Thus, the instance’s price of hierarchy is at least cd .For large d, this fraction cd =

√4d2+(3 −d)2+d−32d converges to 1+ √52 , the golden ratio. 

3.3.4 GASOLINE 

In the generalised Gasoline problem, we are given two sequences of d-dimensional vectors X = ( x1, ..., x n) ∈

Nd×n 

> ≥0

and Y = ( y1, ..., y n) ∈ Nd×n 

> ≥0

which sum to the same total: Pni=1 xi = Pni=1 yi . Our task is to find a permutation π of the xi that minimises: 

min 

> π∈Sn
> d

X

> j=1

"

max 

> 1≤k≤n

 kX

> i=1

xπ(i) −

> k−1

X

> i=1

yi



> j

− min 

> 1≤k≤n

 kX

> i=1

xπ(i) −

> k

X

> i=1

yi



> j

#

This can be written as an ILP, with a permutation-matrix Z as a free variable. Let 1 be the vector containing a 

1 in every entry. 

min ∥β − α∥1 s.t. 

> n

X

> l=1
> m

X

> i=1

xlZil −

> m−1

X

> i=1

yi ≤ β ∀m ∈ [n]

> n

X

> l=1
> m

X

> i=1

xlZil −

> m

X

> i=1

yi ≥ α ∀m ∈ [n]

Z1 ≤ 11T Z ≤ 1T

Z ∈ { 0, 1}n×n

α, β ∈ Rd

In the ith step of the iterative rounding algorithm, the columns 1, ..., i − 1 of Z have already been fixed to integral values by the previous steps and, for column i, we attempt to insert every possible unit-vector (which does not conflict with the fixed rows and the permutation-matrix requirement) and then solve the Linear Program obtained by removing the integrality-requirements on columns i + 1 , ..., n . We then fix column i of 

Z to that unit-vector which yielded the best value for the relaxed LP, breaking ties by preferring unit-vectors where the 1 occurs earlier. After the nth step of this algorithm, Z is fixed entirely to a permutation-matrix. (Rajkovi´ c, 2022, Conjectures 2 and 3) conjectured that this algorithm is a 2-approximation for d ≥ 2, which FunSearch found a counterexample for. We initialized the FunSearch algorithm with the instance constructed by Lorieau (2024) embedded into two dimensions as shown in Fig. 6a. Generated instances were scored by the ratio between the optimum value (computed via Gurobi Optimization, LLC (2024)) and the value returned by the iterative rounding algorithm. Fix some k ∈ N. For any i, define ui := 2 k (1 − 2−i). Let ⊕ denote list-concatenation. The 1-dimensional instance found by Lorieau (2024) can be written as follows: 

X =

k−1M

> i=1 2i

M

> 1

[ui]



⊕

2k −1M

> 1

[2 k ]



⊕ [0] 

Y =

> k

M

> i=1 2i

M

> 1

[ui]

Let ej be the jth unit-vector. FunSearch extended the instance to d dimensions as follows: 

X := 

k−1M

> i=1 2i

M

> 1
> d

M

> j=2

[uie1 + 4 ej ]



⊕

 dM

> j=2

2k −1M

> 1

[2 k e1]



⊕ [4 ej ]



Y := 

> k

M

> i=1 2i

M

> 1
> d

M

> j=2

[uie1 + 2 ej ]

Table 3 contains computed approximation-factors for different choices of d and k. For higher d and k, the instances quickly grow prohibitively large. 

11 def get_instance() -> list[tuple[int, int]]:                            

> """Return an instance, specified by the list of (weight, profit) pairs. Weights and profits must be non-negative integers. """
> return [(1, 2)] *2+[(4, 4), (2, 2), (1, 3)]

(a) Initial program.                                                                                                                                       

> def get_instance() -> list[tuple[int, int]]:
> """Create avariant with more diverse item types and weights to potentially influence Pareto set size.""" ,→
> items =[]
> #Repeated very light, low profit items
> items += [(1, 1)] * 8
> #Mix of moderate weight and profit items with some unique entries
> items += [(4, 9), (4, 9), (5, 10)]
> #High-profit, lightweight items with more profit variation
> items += [(2, 16), (2, 14), (3, 15)]
> #Heavier items with varied weights and higher profits to increase trade-offs
> items += [(9, 20), (12, 30), (15, 40)]
> #Small, low to moderate profit items
> items += [(1, 3), (2, 5), (3, 7), (3, 8)]
> #Very heavy, high-profit rare items with similar weights
> items += [(20, 35), (21, 36), (22, 38)]
> #Larger weight, moderate profit item to diversify options
> items += [(18, 28)]
> #Additional medium-weight high-profit items to increase complexity
> items += [(10, 25), (11, 27)]
> return items

(b) A program found by FunSearch after 10 trials of 500 samples each.                       

> def get_instance() -> list[tuple[int, int]]: items =[] n=7items += [(1, 1)] * n items += [(4, 9)] * n items += [(2, 5), (3, 7)]
> return items

(c) An intermediate step of tuning 4b by hand. 

Figure 4: The evolution of programs generating instances of the knapsack problem. The model used was gpt-4.1-nano with a temperature of 1.0, and results obtainable despite a bug in the implementa-tion that underestimated the sizes of some Pareto sets. 

In our computational experiments, both APX and OPT scale linearly with input-length |X|:

APX = O(1) + |X| · 



2 d = 2 3/2 d = 3 4/3 d = 4 

, OPT = O(1) + |X| · 



1/2 d = 2 1/4 d = 3 1/6 d = 4 

If this scaling held for larger k, the approximation-factors would approach 4, 6, 8 for d = 2 , 3, 4 respectively. Unfortunately, the proof-strategy employed in Lorieau (2024) does not apply here, as the optimum value of the relaxed Linear Program changes at each step of the algorithm. Hence, we are unable to provide a proof that these trends hold asymptotically. 

## 4 CONCLUSION AND LIMITATIONS 

In this work, we use large language models with human collaboration to generate adversarial examples for heuristics addressing several well-known combinatorial optimization problems. Traditional heuristics like lo-cal search do not converge towards such structured solutions, and understanding or generalizing their solutions is usually not feasible. Across many of the problems we investigated, this form of human-AI collaboration enabled improvements over the existing state of the art. We believe this approach is very flexible and should be considered a valuable addition to the algorithm designer’s toolkit for many problems. Limitations. Although our method is broadly applicable, it does not always yield improvements over the state of the art. In partic-ular, Co-FunSearch did not produce generalizable results, or even replicate known lower bounds—for certain heuristics: • Better heuristics for page replacement algorithms (evaluated on synthetic and real data), but Fun-Search consistently converged to the existing NFU heuristic. • Lower bounds on the Price of Hierarchy of k-means clustering (as opposed to k-median clustering). 

12 def get_weighted_points() -> list[tuple[float, np.ndarray]]: 

"""Return a new weighted clustering-problem, specified by a list of weighted points. The returned tuple consists of the weight of the point, and the point itself.""" 

weighted_points = [(1.0, np.array([0, 0, 0, 0])), (1e8, np.array([1, 0, 0, 0]))] 

return weighted_points 

(a) The initial program given to FunSearch. 

def get_weighted_points() -> list[tuple[float, np.ndarray]]: 

"""Return a new weighted clustering-problem, specified by a list of weighted points. The returned tuple consists of the weight of the point, and the point itself.""" 

return [(1.0, np.zeros(14)), (1e10, np.ones(14)), *[(1.0, np.eye(14)[i]) for i in range(7)], *[(1.0, np.eye(14)[i]*-1) for i in range(7, 13)], *[(1e10-i*1e9, np.linspace(i*0.1, (i+1)*0.1, 14, endpoint= False )) for i in range(7)], (1e11, np.array([13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0])), (1e12, np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])), (1e13, np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])*10), (1e14, np.array([14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1])*100), (1e15, np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])*1000), ]

(b) A program found by FunSearch after 10 trials of 2,200 samples each. 

def get_weighted_points() -> list[tuple[float, np.ndarray]]: 

return [(1.0, np.zeros(14)), *[(1.0, -np.eye(14)[i]) for i in range(14)], (1e10, np.ones(14) / 20), ]

(c) The result of tuning by 5b by hand. 

Figure 5: The evolution of programs generating clustering-instances. The model used was open-mistral-nemo with a temperature of 1.5.

d k Length of X Iterative-Rounding Optimum Iterative-Rounding /Optimum 

2 2 6 10 8 1.25 2 3 14 26 12 2.1667 2 4 30 58 20 2.92 5 62 122 36 3.389 2 6 126 250 68 3.676 3 2 12 18 12 1.53 3 28 42 16 2.625 3 4 60 90 24 3.75 3 5 124 186 40 4.65 4 2 18 24 16 1.54 3 42 56 20 2.84 4 90 120 28 4.286 

Table 3: The approximation-factor of the Iterative-Rounding algorithm on the instances found by FunSearch. 13 def gasoline(n: int) -> tuple[list[np.ndarray], list[np.ndarray]]: """Return a new gasoline-problem, specified by the two lists of 2d-non-negative-integer-points. ,→                                                                    

> Both lists must have length at most nand consist only of points in Nˆ2. """ k=int(math.log2(n +2)) -1xs, ys =[], [] for iin range(1, k): rounded =int(2**k * (1 -2** (-i))) xs.extend([np.array([rounded, 0]) for _in range(2**i)]) ys.extend([np.array([rounded, 0]) for _in range(2**i)]) xs.extend([np.array([2**k, 0]) for _in range(2**k -1)]) xs.append(np.array([0, 0])) rounded =int(2**k *(1 -2** (-k))) ys.extend([np.array([rounded, 0]) for _in range(2**k)]) return xs, ys

(a) The initial program given to FunSearch. This is the construction of Lorieau (2024) embedded into R2.                                                                                                                             

> def gasoline(n: int) -> tuple[list[np.ndarray], list[np.ndarray]]: """Yet another variation of the gasoline-problem generator.""" k=int(math.log2(n +2)) -1xs, ys =[], [] for iin range(1, k): rounded =int(2**k * (1 -2** (-i))) xs.extend([np.array([rounded, 0]) for _in range(2**i)]) -ys.extend([np.array([rounded, 0]) for _in range(2**i)]) +ys.extend([np.array([rounded, 2]) for _in range(2**i)]) #No change -xs.extend([np.array([2**k, 0]) for _in range(2**k -1)]) +xs.extend([np.array([2**k, 4]) for _in range(2**k -2)]) #No change -xs.append(np.array([0, 0])) +xs.append(np.array([0, 1])) # Changed from [0, 2] to [0, 1] +xs.append(np.array([2**k, 2])) #Changed from [2**k, 0] to [2**k, 2] rounded =int(2**k * (1 -2** (-k))) -ys.extend([np.array([rounded, 0]) for _in range(2**k)]) +ys.extend([np.array([rounded, 2]) for _in range(2**k -1)]) #No change +ys.append(np.array([0, 1])) #Changed from [0, 2] to [0, 1]

(b) The difference between the initial program and a program found by FunSearch after 10 trials of 950 samples each, which we only tuned by discarding the final element of both lists. 

Figure 6: The evolution of programs generating 2-dimensional gasoline-instances. The model used was open-mistral-nemo with a temperature of 1.5. Lists were clipped to length n before evaluation. 

• Lower bounds on the price of Ward’s method for hierarchical 2-dimensional k-means clustering: Instead of comparing the best possible hierarchical clustering to the optimal clusterings, we compare the hierarchical clustering found by starting with each point in a singleton cluster, and iteratively merging the pair of clusters which result in the lowest objective. Neither FunSearch nor local search managed to recover the State of the Art when starting from a trivial instance. When starting from the State of the Art in 2 dimensions, both FunSearch and local search improved it marginally (FunSearch less so than local search, even after tuning), but not in a generalisable way. • Lower bounds on the asymptotic random-order-ratio of Best-Fit, which is the same as the absolute random-order-ratio but restricted to only “large” instances (Albers et al., 2021). FunSearch did not find any interpretable instances improving on the state of the art. 

## REFERENCES 

Susanne Albers, Arindam Khan, and Leon Ladewig. Best fit bin packing with random order revisited. Algo-rithmica , 83:1–26, 09 2021. doi: 10.1007/s00453-021-00844-5. Anna Arutyunova and Heiko R¨ oglin. The price of hierarchical clustering. Algorithmica , pp. 1–33, 07 2025. doi: 10.1007/s00453-025-01327-7. H. William Corley and I. Douglas Moon. Shortest paths in networks with vector weights. Journal of Optimiza-tion Theory and Application , 46(1):79–86, 1985. 

14 WenQiang Dai. A 16-competitive algorithm for hierarchical median problem. Science China Information Sciences , 57(3):1–7, Feb 2014. ISSN 1869-1919. doi: 10.1007/s11432-014-5065-0. URL https: //doi.org/10.1007/s11432-014-5065-0 .Alex Davies, Petar Veliˇ ckovi´ c, Lars Buesing, Sam Blackwell, Daniel Zheng, Nenad Tomaˇ sev, Richard Tanburn, Peter Battaglia, Charles Blundell, Andr´ as Juh´ asz, Marc Lackenby, Geordie Williamson, Demis Hassabis, and Pushmeet Kohli. Advancing mathematics by guiding human intuition with AI. Nature , 600(7887):70–74, 2021. Gy¨ orgy D´ osa and Jiˇ r´ ı Sgall. Optimal analysis of best fit bin packing. In Javier Esparza, Pierre Fraigniaud, Thore Husfeldt, and Elias Koutsoupias (eds.), Automata, Languages, and Programming , pp. 429–441, Berlin, Hei-delberg, 2014. Springer Berlin Heidelberg. ISBN 978-3-662-43948-7. Matthias Ehrgott. Multicriteria Optimization (2. ed.) . Springer, 2005. ISBN 978-3-540-21398-7. doi: 10.100 7/3-540-27659-9. URL https://doi.org/10.1007/3-540-27659-9 .Alhussein Fawzi, Matej Balog, Aja Huang, Thomas Hubert, Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Francisco J R. Ruiz, Julian Schrittwieser, Grzegorz Swirszcz, et al. Dis-covering faster matrix multiplication algorithms with reinforcement learning. Nature , 610(7930):47–53, 2022. Florian Fontan and Luc Libralesso. Packingsolver: a solver for packing problems. CoRR , abs/2004.02603, 2020. URL https://arxiv.org/abs/2004.02603 .Gurobi Optimization, LLC. Gurobi Optimizer Reference Manual, 2024. URL https://www.gurobi.c om .Guolong Lin, Chandrashekhar Nagarajan, Rajmohan Rajaraman, and David P. Williamson. A general approach for incremental approximation and hierarchical clustering. SIAM Journal on Computing , 39(8):3633–3669, 2010. doi: 10.1137/070698257. URL https://doi.org/10.1137/070698257 .Lucas Lorieau. Approximation algorithm for the generalised gasoline problem. Master’s thesis, University of Bonn, 2024. L´ aszl´ o Lov´ asz. Combinatorial problems and exercises , volume 361. American Mathematical Soc., 2007. Abbas Mehrabian, Ankit Anand, Hyunjik Kim, Nicolas Sonnerat, Matej Balog, Gheorghe Comanici, Tudor Berariu, Andrew Lee, Anian Ruoss, Anna Bulanova, et al. Finding increasingly large extremal graphs with alphazero and tabu search. arXiv preprint arXiv:2311.03583 , 2023. Mistral AI. Mistral NeMo — Mistral AI — mistral.ai. https://mistral.ai/news/mistral-nemo ,2024. [Accessed 24-09-2025]. George L. Nemhauser and Zev Ullmann. Discrete dynamic programming and capital allocation. Management Science , 15(9):494–505, 1969. Alantha Newman, Heiko R¨ oglin, and Johanna Seif. The alternating stock size problem and the gasoline puzzle. 

ACM Trans. Algorithms , 14(2), April 2018. ISSN 1549-6325. doi: 10.1145/3178539. URL https: //doi.org/10.1145/3178539 .Henri Nikoleit. Using llms to construct adversarial instances in combinatorial optimization. Master’s thesis, Rheinische Friedrich-Wilhelms-Universit¨ at Bonn, 2025. Available at https://florisvandoorn.c om/formalized-mathematics .Alexander Novikov, Ngˆ an V˜ u, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, Francisco JR Ruiz, Abbas Mehrabian, et al. Alphaevolve: Acoding agent for scientific and algorithmic discovery. arXiv preprint arXiv:2506.13131 , 2025. OpenAI. OpenAI Platform — platform.openai.com. https://platform.openai.com/docs/model s/gpt-4.1-mini , 2025a. [Accessed 24-09-2025]. OpenAI. OpenAI Platform — platform.openai.com. https://platform.openai.com/docs/model s/gpt-4.1-nano , 2025b. [Accessed 24-09-2025]. Ivana Rajkovi´ c. Approximation algorithms for the stock size problem and the gasoline problem. Master’s thesis, University of Bonn, 2022. Heiko R¨ oglin. Smoothed analysis of pareto curves in multiobjective optimization. In Tim Roughgarden (ed.), 

Beyond the Worst-Case Analysis of Algorithms , pp. 334–358. Cambridge University Press, 2020. doi: 10.1 017/9781108637435.020. URL https://doi.org/10.1017/9781108637435.020 .

15 Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, et al. Mathematical discoveries from program search with large language models. Nature , 625(7995):468–475, 2024. Adam Zsolt Wagner. Constructions in combinatorics via neural networks. arXiv preprint arXiv:2104.14516 ,2021. 

16 5 APPENDIX 

5.1 PROOF OF THE KNAPSACK -RESULT 

In the knapsack problem, we are considering a bicriteria optimization problem, where we want to minimize the total weight while maximizing the total profit. Specifically, we are given an instance as a list of tuples of the form (weight , profit ) from which we select a sub-list. The total weight Weight( A) (respectively total profit 

Profit( A)) of a sub-list A is the sum of the weights (respectively profits) of its items. A sub-list A dominates a sub-list B if Weight( A) ≤ Weight( B) and Profit( A) ≥ Profit( B) and at least one of these inequalities is strict. A sub-list is Pareto-optimal if it is not dominated by any other sub-list. The 

Pareto-set P (I) of an instance I is the set of Pareto-optimal sub-lists of I. When the Pareto-set is known, objectives like the 0-1 knapsack problem “Maximise total profit while staying below a given maximum total weight W ” can be optimised by simply finding the sub-list in P (I) that has the largest total profit and whose total weight is below W .As described in section 3.3.1, we obtained instance 1 via Co-FunSearch. To analyze the sizes of the instance’s and subinstances’ Pareto-sets, we define the two segments of the instance: For a, b, d, n ∈ Z≥1 with d < a ≤ b,define xi := (1 + 2−i 

> 2d−1

), and two lists: 

Ia,b := 

 2a

2a



,

2a+1 

2a+1 



, . . . , 

2b

2b

 

, Jd,n := 

" x1 · 2d

x1 · (2 d − 1) 



, . . . , 

 xn · 2d

xn · (2 d − 1) 

#

.

Lemma 5.1. If a Pareto-optimal packing A ∈ P ([ Ia,b , J d,n ]) does not contain all items from Ia,b , it contains fewer than 2a−d items from Jd,n .Proof. Subsets of Ia,b can be represented by binary numbers of (b − a + 1) bits. If A does not contain all items from Ia,b and contains at least 2a−d items from Jd,n , we define a new packing A′ as follows: Increment the binary number representing A ∩ Ia,b by 1, and remove 2a−d items from A ∩ Jd,n . This changes the weights and profits by: 

Weight( A′) − Weight( A) ≤ 2a − 2a−d ·



1 + 2−n

2d − 1

| {z }

> >1

·2d < 0Profit( A′) − Profit( A) ≥ 2a − 2a−d ·



1 + 2−1

2d − 1



(2 d − 1) = 2 a − 2a−d ·



2d − 2−1

= 2a−d−1 > 0

Thus, A′ dominates A, and A / ∈ P ([ Ia,c , J d,n ]) .On the other hand, all other packings are Pareto-optimal: 

Lemma 5.2. If a packing A of [Ia,b , J d,n ] contains all items from Ia,b or contains fewer than 2a−d items from 

Jd,n , then A is Pareto-optimal. Proof. All items from Ia,b have a profit-per-weight ratio of 1, while all items from Jd,n have a profit-per-weight ratio of 2d−12d < 1. Hence, a packing B that dominates A must satisfy 

Weight( A ∩ Ia,b ) < Weight( B ∩ Ia,b ),

otherwise B can not have enough profit to dominate A. If A already contains all items from Ia,b , this is not possible, so only the case that A contains fewer than 2a−d items from Jd,n remains. Due to the definition of 

Ia,b , the above inequality implies: 

Weight( A ∩ Ia,b ) + 2 a ≤ Weight( B ∩ Ia,b ).

If B dominates A, it must hold that: 

Weight( A ∩ Ia,b ) + Weight( A ∩ Jd,n ) ≥ Weight( B ∩ Ia,b ) + Weight( B ∩ Jd,n )=⇒ Weight( A ∩ Jd,n ) − 2a ≥ Weight( B ∩ Jd,n ).

But A contains fewer than 2a−d items from Jd,n , so: 

Weight( A ∩ Jd,n ) ≤ 2a−d ·



1 + 2−1

2d − 1



· (2 d − 1) = 2 a − 2a−d−1 < 2a.

This implies 0 > Weight( B ∩ Jd,n ), a contradiction. 

17 Hence, we can describe the Pareto-set exactly: 

P ([ Ia,b , J d,n ]) = {A ∪ B | A ⊊ Ia,b , B ⊆ Jd,n , |B| < 2a−d} ˙∪ { Ia,b ∪ B | B ⊆ Jd,n }.

Its size is (using notation involving binomial coefficients, not vectors): 

|P ([ Ia,b , J d,n ]) | = (2 b−a+1 − 1) ·

min( n, 2a−d−1) 

X

> i=0

ni

!

+ 2 n.

For k, n ∈ N with 2k ≤ n/ 2, consider two instances: 

I1 := [ I2k, 2k+n, J k,n ] ,

I2 := 



I1,

2k+1 

2k+1 



,

2k+2 

2k+2 



, . . . , 

22k−1

22k−1

 

.

I1 is a sub-instance of I2. I2 (which is exactly instance 1) contains the same items as [Ik+1 , 2k+n, J k,n ]. The sizes of their Pareto-sets can be bounded by: 

|P (I1)| ≥ (2 n+1 − 1) · n

2k − 1

!

+ 2 n ≥ (2 n+1 − 1) ·

 n

2k − 1

(2 k −1) 

.

|P (I2)| ≤ (2 k+n − 1) · (n + 1) + 2 n ≤ (2 k+n − 1) · (n + 2) 

The ratio between the two sizes is: 

|P (I1)||P (I2)| ≥ 2n+1 − 12k+n − 1 ·

 n

2k − 1

(2 k −1) 

· 1

n + 2 

For k = log 2(√n) + 1 , we obtain: 

|P (I1)||P (I2)| ≥ 2n+1 − 1(√n + 1) · 2n − 1 ·

 n

√n

√n

· 1

n + 2 = Θ( n(√n−3) /2).

The length of the instance I2 is not n but m := |I2| = 2n + k, resulting in a lower bound of 

O ( m 

> 2

)(√m/ 2−3) /2.In implementations of the Nemhauser-Ullmann algorithm, two Pareto-optimal packings can be treated as equiv-alent if they have the same total weight and total profit. Hence, the runtime can be upper-bounded not only by the sum of the sizes of the Pareto-sets |P (I1:1 )| + ... + |P (I1: n)|, but even the sizes of the Pareto-sets when two packings with the same total weight and total profit are treated as identical. The only purpose of the leading factors  1 + 2−n

> 2d−1

 in Jd,n is to prevent two Pareto-optimal packings from having the same total profit. As a consequence, we also obtain a bound of O ( m 

> 2

)(√m/ 2−3) /2 for the runtime of the Nemhauser-Ullmann algorithm. 

Lemma 5.3. If A, B ⊆ [Ia,b , J d,n ] are two distinct Pareto optimal packings, then Profit( A)̸ = Profit( B).Proof. Because both A and B are Pareto-optimal, we know by 5.1 that |A∩Jd,n | < 2a−d (same for B), hence: 

Profit( A ∩ Jd,n ) < 2a−d ·



1 + 2−1

2d − 1



· (2 d − 1) = 2 a−d ·



2d − 12



= 2 a − 2a−d−1 < 2a.

(same for Profit( B ∩ Jd,n )). • If A ∩ Ia,b ̸ = B ∩ Ia,b , the difference between Profit( A ∩ Ia,b ) and Profit( B ∩ Ia,b ) would be at least 2a, due to the definition of Ia,b . In this case, the above inequality already shows Profit( A)̸ =Profit( B).• If A ∩ Ia,b = B ∩ Ia,b , then A ∩ Jd,n ̸ = B ∩ Jd,n , and we need to show that Profit( A ∩ Jd,n )̸ =Profit( B ∩ Jd,n ). This is equivalent to showing that any two distinct subsets of: 

{(2 d − 1) + 2 −1, (2 d − 1) + 2 −2, ..., (2 d − 1) + 2 −n},

have a distinct sum. This holds because the total sum of the summands 2−1, ..., 2−n is always smaller than 1, whereas 2d − 1 ≥ 1.

18