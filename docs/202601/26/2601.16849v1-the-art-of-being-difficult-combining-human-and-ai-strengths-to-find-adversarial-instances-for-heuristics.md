# The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics
# 制造困难的艺术：结合人类与 AI 的优势寻找启发式算法的对抗实例

**Authors**: Henri Nikoleit, Ankit Anand, Anurag Murty Naredla, Heiko Röglin \
**Date**: 2026-01-23 \
**PDF**: https://arxiv.org/pdf/2601.16849v1 \
**Tags**: <span class="tag-label tag-green">LNS</span> <span class="tag-label tag-green">EOH</span> <span class="tag-label tag-green">EAA</span> \
**Score**: 9.0 \
**Evidence**: 通过 FunSearch 和大模型进行启发式算法进化 \
**TLDR**: 利用人机协作和 FunSearch 进化出组合优化问题的最先进启发式算法。

---

## 速览
**TLDR**：本研究展示了人类与大模型协作在寻找组合优化启发式算法对抗实例及提升理论下界方面的强大潜力。 \
**Motivation**：旨在通过生成对抗实例来探索启发式算法的性能极限，解决理论计算机科学中长期停滞的组合优化难题。 \
**Method**：采用人类专家迭代优化 FunSearch 算法输出的方法，将大模型生成的初步模式转化为严谨的数学构造。 \
**Result**：在分层 k-中值聚类、装箱、背包等问题上均获得了目前最优的下界，打破了部分领域维持十余年的研究僵局。 \
**Conclusion**：大模型是科研中的强力协作工具，能提供关键初始洞察，而人类专家的监督与提炼对于实现数学严谨性至关重要。

---

## Abstract
We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lovász's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.   Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.

## 摘要
我们展示了人类与大语言模型（LLM）协作在解决理论计算机科学开放性问题中的力量。聚焦于组合优化，我们对 FunSearch 算法 [Romera-Paredes et al., Nature 2023] 的输出进行精炼，从而推导出标准启发式算法的最先进下界。具体而言，我们的目标是生成这些启发式算法表现不佳的对抗实例。通过对 FunSearch 的输出进行迭代，我们确定了层级 $k$-中值聚类、装箱问题、背包问题以及 Lovász 汽油问题推广形式的改进构造——尽管这些问题一直受到间歇性的关注，但其中一些在十多年内都没有取得显著进展。这些结果说明了专家监督如何有效地从基于 LLM 的进化方法中推断出算法见解，从而打破长期存在的障碍。我们的研究结果表明，虽然 LLM 提供了关键的初始模式，但人类的专业知识对于将这些模式转化为数学上严谨且富有洞察力的构造至关重要。这项工作强调了 LLM 是数学和计算机科学研究中强大的协作工具。

---

## 论文详细总结（自动生成）

这篇论文由波恩大学、Google DeepMind 和曼尼托巴大学的研究人员共同完成，探讨了如何通过人类专家与大语言模型（LLM）的协作来解决理论计算机科学中的开放性问题。

以下是对该论文的结构化深入总结：

### 1. 论文的核心问题与整体含义
*   **研究动机**：在理论计算机科学（TCS）中，分析启发式算法的“最坏情况”性能至关重要。然而，寻找能让算法表现最差的“对抗实例”通常极具挑战，许多经典问题的理论下界已停滞十多年未有进展。
*   **核心问题**：传统的自动化搜索方法（如局部搜索）生成的实例往往是“黑盒”向量，缺乏结构化洞察，人类难以从中总结出通用的数学规律。
*   **整体含义**：论文提出了一种**人机协作模式（Co-FunSearch）**，利用 LLM 生成可读的代码，再由人类专家提炼其中的算法逻辑，从而突破了多个组合优化问题的理论瓶颈。

### 2. 论文提出的方法论：Co-FunSearch
核心思想是将 DeepMind 之前的 **FunSearch**（基于代码进化的搜索）与**人类专家干预**相结合。
*   **自动化循环（FunSearch Cycle）**：
    1.  **初始程序**：提供一个生成简单实例的 Python 函数。
    2.  **LLM 进化**：LLM（如 GPT-4）根据当前得分最高的程序生成改进版代码。
    3.  **评估与存储**：执行代码计算对抗得分（如启发式结果与最优解的比值），并将高分程序存入数据库。
*   **人类协作环节（“Co” Part）**：
    1.  **模式识别**：专家观察高分程序，识别出 LLM 使用的结构（如特定的数值序列或循环逻辑）。
    2.  **简化与泛化**：手动剔除冗余代码，将硬编码的常数转化为参数化的数学公式。
    3.  **理论证明**：基于简化后的构造，推导出严谨的数学证明，确立新的理论下界。
    4.  **反馈循环**：将简化后的逻辑重新喂给 FunSearch，引导其在更有希望的方向上搜索。

### 3. 实验设计
*   **目标问题（场景）**：
    1.  **背包问题（Knapsack）**：针对 Nemhauser-Ullmann 启发式算法，寻找使其 Pareto 解集爆炸的实例。
    2.  **装箱问题（Bin Packing）**：针对随机顺序下的 Best-Fit 算法，寻找其近似比下界。
    3.  **层级聚类（Hierarchical Clustering）**：针对 k-中值（k-median）目标，寻找层级代价与最优代价比值的下界。
    4.  **汽油问题（Gasoline Problem）**：针对迭代舍入算法，验证其近似保证。
*   **Benchmark 与对比方法**：
    *   **SOTA**：各领域目前已知的最佳理论下界。
    *   **局部搜索（Local Search）**：传统的数值优化方法。
    *   **基础 FunSearch**：无人类干预的自动化搜索。

### 4. 资源与算力
*   **模型使用**：实验使用了 OpenAI 的 `gpt-4.1-mini`、`gpt-4.1-nano` 以及 Mistral AI 的 `open-mistral-nemo`。
*   **算力细节**：文中**未明确说明**具体的 GPU 型号或总训练时长。但提到了实验规模，例如针对每个问题运行 10 次试验，每次试验包含 500 到 2400 个样本（LLM 提示词调用）。

### 5. 实验数量与充分性
*   **实验规模**：针对四个完全不同的组合优化领域进行了深入研究，每个领域都给出了具体的代码演化过程和最终的数学构造。
*   **消融实验**：作者对模型类型（Mini vs Nano）、采样温度（Temperature）、初始提示词结构（硬编码 vs 循环结构）进行了对比实验。
*   **充分性评价**：实验设计较为充分。通过 30 次重复试验来消除随机性影响，并展示了从“随机代码”到“结构化数学构造”的完整演化路径，客观地证明了人类干预在其中的必要性。

### 6. 论文的主要结论与发现
*   **打破理论僵局**：
    *   **背包问题**：证明了 Nemhauser-Ullmann 算法的运行时间不是输出多项式级的（此前为悬而未决的问题）。
    *   **装箱问题**：将 Best-Fit 算法在随机顺序下的下界从 **1.3 提升至 1.5**。
    *   **层级聚类**：获得了 k-中值层级聚类的第一个非平凡下界——**黄金分割比 ($\approx 1.618$)**。
    *   **汽油问题**：证伪了关于迭代舍入算法是 2-近似的猜想，找到了比值为 **4.65** 的反例。
*   **人机协作的价值**：LLM 擅长发现初步的、杂乱的模式，而人类擅长将这些模式转化为严谨的数学语言。

### 7. 优点
*   **可解释性强**：与生成“黑盒”数据的算法不同，该方法生成的是 Python 代码，人类可以直接阅读并理解其构造逻辑。
*   **理论与实践结合**：不仅通过 AI 找到了高分实例，还最终给出了严谨的数学定理和证明。
*   **灵活性**：该框架（Co-FunSearch）可以轻易迁移到其他需要寻找对抗实例或极端构造的数学问题中。

### 8. 不足与局限
*   **对专家的依赖**：该方法并非完全自动化，仍需要具备深厚理论功底的专家来识别代码中的模式，普通用户难以复现这种“洞察力”。
*   **覆盖范围有限**：作者承认在某些问题上（如 k-means 聚类、页面置换算法）未能取得突破，说明该方法并非万能。
*   **验证成本**：对于某些复杂问题（如高维汽油问题），验证 LLM 生成的实例是否真的是最优解需要极大的计算开销（如调用 Gurobi 求解器），这限制了搜索的规模。

（完）
