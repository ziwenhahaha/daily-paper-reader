---
title: Simple Baselines are Competitive with Code Evolution
title_zh: 简单基准在代码演化任务中具有竞争力
authors: "Yonatan Gideoni, Sebastian Risi, Yarin Gal"
date: 2026-02-18
pdf: "https://arxiv.org/pdf/2602.16805v1"
tags: ["query:sr"]
score: 7.0
evidence: 用于数学边界和程序搜索的代码演化技术
tldr: 本研究挑战了当前代码演化技术的复杂性，指出利用大模型进行代码变异和搜索的复杂流水线往往缺乏与简单基准的对比。通过在数学边界寻找、智能体架构设计和机器学习竞赛三个领域的实验，研究发现简单的基准方法在性能上足以匹配甚至超越复杂的演化算法。研究揭示了搜索空间设计和评估严谨性对结果的决定性影响，并为未来代码演化研究提出了更具经济性和可靠性的评估实践建议。
motivation: 旨在探究复杂的代码演化流水线是否真的优于简单的基准方法，并识别当前研究在评估和设计上的缺陷。
method: 在数学边界发现、智能体架构设计和机器学习竞赛三个领域，对比了两种简单基准与多种复杂代码演化方法的表现。
result: 实验结果显示，简单基准在所有测试领域中均达到或超过了复杂演化方法的性能水平。
conclusion: 代码演化的成功主要取决于搜索空间的设计和领域知识的引入，而非演化流水线本身的复杂程度，且亟需更严谨的评估方法。
---

## 摘要
代码演化（Code evolution）是一类依赖大语言模型，通过演化或变异现有代码来搜索可能计算机程序的技术。许多提出的代码演化流水线表现出了令人印象深刻的性能，但通常缺乏与更简单基准的比较。我们在三个领域测试了两个简单基准的表现：寻找更好的数学边界、设计智能体支架（agentic scaffolds）以及机器学习竞赛。我们发现，在所有这三个领域中，简单基准的表现都达到或超过了更为复杂的方法。通过分析这些结果，我们发现了代码演化在开发和使用过程中的各种缺陷。对于数学边界问题，问题的搜索空间和提示词中的领域知识是决定搜索性能上限和效率的主要因素，而代码演化流水线则是次要的。因此，寻找改进边界的主要挑战在于设计良好的搜索空间（这由领域专家完成），而非搜索过程本身。在设计智能体支架时，我们发现支架的高方差结合小数据集导致选择了次优支架，结果是手工设计的多数投票支架表现最好。我们提出了更好的评估方法，在保持代码演化经济可行性的同时，减少了评估的随机性。最后，我们讨论了在未来工作中实现更严谨的代码演化的途径和最佳实践。

## Abstract
Code evolution is a family of techniques that rely on large language models to search through possible computer programs by evolving or mutating existing code. Many proposed code evolution pipelines show impressive performance but are often not compared to simpler baselines. We test how well two simple baselines do over three domains: finding better mathematical bounds, designing agentic scaffolds, and machine learning competitions. We find that simple baselines match or exceed much more sophisticated methods in all three. By analyzing these results we find various shortcomings in how code evolution is both developed and used. For the mathematical bounds, a problem's search space and domain knowledge in the prompt are chiefly what dictate a search's performance ceiling and efficiency, with the code evolution pipeline being secondary. Thus, the primary challenge in finding improved bounds is designing good search spaces, which is done by domain experts, and not the search itself. When designing agentic scaffolds we find that high variance in the scaffolds coupled with small datasets leads to suboptimal scaffolds being selected, resulting in hand-designed majority vote scaffolds performing best. We propose better evaluation methods that reduce evaluation stochasticity while keeping the code evolution economically feasible. We finish with a discussion of avenues and best practices to enable more rigorous code evolution in future work.