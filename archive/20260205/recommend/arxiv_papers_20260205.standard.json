{
  "mode": "standard",
  "generated_at": "2026-02-05T04:31:02.594969+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 1,
    "deep_divecandidates": 3,
    "deep_cap": 6,
    "deep_selected": 3,
    "quick_candidates": 1,
    "quick_skim_target": 11,
    "quick_selected": 1
  },
  "deep_dive": [
    {
      "id": "2602.04114v1",
      "title": "Turning mechanistic models into forecasters by using machine learning",
      "abstract": "The equations of complex dynamical systems may not be identified by expert knowledge, especially if the underlying mechanisms are unknown. Data-driven discovery methods address this challenge by inferring governing equations from time-series data using a library of functions constructed from the measured variables. However, these methods typically assume time-invariant coefficients, which limits their ability to capture evolving system dynamics. To overcome this limitation, we allow some of the parameters to vary over time, learn their temporal evolution directly from data, and infer a system of equations that incorporates both constant and time-varying parameters. We then transform this framework into a forecasting model by predicting the time-varying parameters and substituting these predictions into the learned equations. The model is validated using datasets for Susceptible-Infected-Recovered, Consumer--Resource, greenhouse gas concentration, and Cyanobacteria cell count. By dynamically adapting to temporal shifts, our proposed model achieved a mean absolute error below 3\\% for learning a time series and below 6\\% for forecasting up to a month ahead. We additionally compare forecasting performance against CNN-LSTM and Gradient Boosting Machine (GBM), and show that our model outperforms these methods across most datasets. Our findings demonstrate that integrating time-varying parameters into data-driven discovery of differential equations improves both modeling accuracy and forecasting performance.",
      "authors": [
        "Amit K. Chakraborty",
        "Hao Wang",
        "Pouria Ramazi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.DS"
      ],
      "published": "2026-02-04 01:00:08+00:00",
      "link": "https://arxiv.org/pdf/2602.04114v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 9.0,
      "llm_evidence_en": "data-driven discovery of governing equations from time-series",
      "llm_evidence_cn": "从时间序列中进行数据驱动的控制方程发现",
      "llm_evidence": "从时间序列中进行数据驱动的控制方程发现",
      "llm_tldr_en": "A method to infer dynamical systems with time-varying parameters, extending standard equation discovery techniques.",
      "llm_tldr_cn": "一种推断具有时变参数的动力系统的方法，扩展了标准的方程发现技术。",
      "llm_tldr": "一种推断具有时变参数的动力系统的方法，扩展了标准的方程发现技术。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.04492v1",
      "title": "Discovering Mechanistic Models of Neural Activity: System Identification in an in Silico Zebrafish",
      "abstract": "Constructing mechanistic models of neural circuits is a fundamental goal of neuroscience, yet verifying such models is limited by the lack of ground truth. To rigorously test model discovery, we establish an in silico testbed using neuromechanical simulations of a larval zebrafish as a transparent ground truth. We find that LLM-based tree search autonomously discovers predictive models that significantly outperform established forecasting baselines. Conditioning on sensory drive is necessary but not sufficient for faithful system identification, as models exploit statistical shortcuts. Structural priors prove essential for enabling robust out-of-distribution generalization and recovery of interpretable mechanistic models. Our insights provide guidance for modeling real-world neural recordings and offer a broader template for AI-driven scientific discovery.",
      "authors": [
        "Jan-Matthis Lueckmann",
        "Viren Jain",
        "Michał Januszewski"
      ],
      "primary_category": "q-bio.NC",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-04 12:33:29+00:00",
      "link": "https://arxiv.org/pdf/2602.04492v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 9.0,
      "llm_evidence_en": "LLM-based tree search for mechanistic model discovery in neuroscience",
      "llm_evidence_cn": "基于大模型树搜索的神经科学机制模型发现",
      "llm_evidence": "基于大模型树搜索的神经科学机制模型发现",
      "llm_tldr_en": "Uses LLM-based tree search to autonomously discover interpretable mechanistic models of neural activity.",
      "llm_tldr_cn": "利用基于大模型的树搜索自主发现神经活动的、可解释的机制模型。",
      "llm_tldr": "利用基于大模型的树搜索自主发现神经活动的、可解释的机制模型。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.04529v1",
      "title": "Landscape-aware Automated Algorithm Design: An Efficient Framework for Real-world Optimization",
      "abstract": "The advent of Large Language Models (LLMs) has opened new frontiers in automated algorithm design, giving rise to numerous powerful methods. However, these approaches retain critical limitations: they require extensive evaluation of the target problem to guide the search process, making them impractical for real-world optimization tasks, where each evaluation consumes substantial computational resources. This research proposes an innovative and efficient framework that decouples algorithm discovery from high-cost evaluation. Our core innovation lies in combining a Genetic Programming (GP) function generator with an LLM-driven evolutionary algorithm designer. The evolutionary direction of the GP-based function generator is guided by the similarity between the landscape characteristics of generated proxy functions and those of real-world problems, ensuring that algorithms discovered via proxy functions exhibit comparable performance on real-world problems. Our method enables deep exploration of the algorithmic space before final validation while avoiding costly real-world evaluations. We validated the framework's efficacy across multiple real-world problems, demonstrating its ability to discover high-performance algorithms while substantially reducing expensive evaluations. This approach shows a path to apply LLM-based automated algorithm design to computationally intensive real-world optimization challenges.",
      "authors": [
        "Haoran Yin",
        "Shuaiqun Pan",
        "Zhao Wei",
        "Jian Cheng Wong",
        "Yew-Soon Ong",
        "Anna V. Kononova",
        "Thomas Bäck",
        "Niki van Stein"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-02-04 13:18:45+00:00",
      "link": "https://arxiv.org/pdf/2602.04529v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 8.0,
      "llm_evidence_en": "combines Genetic Programming with LLMs for function generation",
      "llm_evidence_cn": "结合遗传编程与大语言模型进行函数生成",
      "llm_evidence": "结合遗传编程与大语言模型进行函数生成",
      "llm_tldr_en": "An automated algorithm design framework using Genetic Programming and LLMs to decouple discovery from high-cost evaluation.",
      "llm_tldr_cn": "一种结合遗传编程和LLM的自动化算法设计框架，旨在将算法发现与高成本评估解耦。",
      "llm_tldr": "一种结合遗传编程和LLM的自动化算法设计框架，旨在将算法发现与高成本评估解耦。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2602.04006v1",
      "title": "Rational ANOVA Networks",
      "abstract": "Deep neural networks typically treat nonlinearities as fixed primitives (e.g., ReLU), limiting both interpretability and the granularity of control over the induced function class. While recent additive models (like KANs) attempt to address this using splines, they often suffer from computational inefficiency and boundary instability. We propose the Rational-ANOVA Network (RAN), a foundational architecture grounded in functional ANOVA decomposition and Padé-style rational approximation. RAN models f(x) as a composition of main effects and sparse pairwise interactions, where each component is parameterized by a stable, learnable rational unit. Crucially, we enforce a strictly positive denominator, which avoids poles and numerical instability while capturing sharp transitions and near-singular behaviors more efficiently than polynomial bases. This ANOVA structure provides an explicit low-order interaction bias for data efficiency and interpretability, while the rational parameterization significantly improves extrapolation. Across controlled function benchmarks and vision classification tasks (e.g., CIFAR-10) under matched parameter and compute budgets, RAN matches or surpasses parameter-matched MLPs and learnable-activation baselines, with better stability and throughput. Code is available at https://github.com/jushengzhang/Rational-ANOVA-Networks.git.",
      "authors": [
        "Jusheng Zhang",
        "Ningyuan Liu",
        "Qinhan Lyu",
        "Jing Yang",
        "Keze Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-03 20:46:00+00:00",
      "link": "https://arxiv.org/pdf/2602.04006v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Interpretable functional decomposition and rational approximation for symbolic-like function discovery",
      "llm_evidence_cn": "可解释的函数分解和有理逼近，适用于类符号函数发现",
      "llm_evidence": "可解释的函数分解和有理逼近，适用于类符号函数发现",
      "llm_tldr_en": "Proposes Rational-ANOVA Networks for interpretable function modeling using rational units and ANOVA decomposition.",
      "llm_tldr_cn": "提出有理ANOVA网络，利用有理单元和ANOVA分解进行可解释函数建模。",
      "llm_tldr": "提出有理ANOVA网络，利用有理单元和ANOVA分解进行可解释函数建模。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    }
  ]
}