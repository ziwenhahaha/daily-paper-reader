{
  "mode": "standard",
  "generated_at": "2026-02-03T04:33:50.202206+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 1,
    "deep_divecandidates": 2,
    "deep_cap": 6,
    "deep_selected": 2,
    "quick_candidates": 6,
    "quick_skim_target": 11,
    "quick_selected": 6
  },
  "deep_dive": [
    {
      "id": "2602.01510v1",
      "title": "Enhancing Generalization in Evolutionary Feature Construction for Symbolic Regression through Vicinal Jensen Gap Minimization",
      "abstract": "Genetic programming-based feature construction has achieved significant success in recent years as an automated machine learning technique to enhance learning performance. However, overfitting remains a challenge that limits its broader applicability. To improve generalization, we prove that vicinal risk, estimated through noise perturbation or mixup-based data augmentation, is bounded by the sum of empirical risk and a regularization term-either finite difference or the vicinal Jensen gap. Leveraging this decomposition, we propose an evolutionary feature construction framework that jointly optimizes empirical risk and the vicinal Jensen gap to control overfitting. Since datasets may vary in noise levels, we develop a noise estimation strategy to dynamically adjust regularization strength. Furthermore, to mitigate manifold intrusion-where data augmentation may generate unrealistic samples that fall outside the data manifold-we propose a manifold intrusion detection mechanism. Experimental results on 58 datasets demonstrate the effectiveness of Jensen gap minimization compared to other complexity measures. Comparisons with 15 machine learning algorithms further indicate that genetic programming with the proposed overfitting control strategy achieves superior performance.",
      "authors": [
        "Hengzhe Zhang",
        "Qi Chen",
        "Bing Xue",
        "Wolfgang Banzhaf",
        "Mengjie Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "published": "2026-02-02 00:46:16+00:00",
      "link": "https://arxiv.org/pdf/2602.01510v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 10.0,
      "llm_evidence_en": "Directly addresses generalization and overfitting in Symbolic Regression using evolutionary feature construction.",
      "llm_evidence_cn": "直接针对符号回归中的泛化和过拟合问题，采用了演化特征构建方法。",
      "llm_evidence": "直接针对符号回归中的泛化和过拟合问题，采用了演化特征构建方法。",
      "llm_tldr_en": "Proposes a framework to improve Symbolic Regression generalization by minimizing the vicinal Jensen gap.",
      "llm_tldr_cn": "提出了一种通过最小化邻域Jensen间隙来提高符号回归泛化能力的演化特征构建框架。",
      "llm_tldr": "提出了一种通过最小化邻域Jensen间隙来提高符号回归泛化能力的演化特征构建框架。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.02311v1",
      "title": "Introns and Templates Matter: Rethinking Linkage in GP-GOMEA",
      "abstract": "GP-GOMEA is among the state-of-the-art for symbolic regression, especially when it comes to finding small and potentially interpretable solutions. A key mechanism employed in any GOMEA variant is the exploitation of linkage, the dependencies between variables, to ensure efficient evolution. In GP-GOMEA, mutual information between node positions in GP trees has so far been used to learn linkage. For this, a fixed expression template is used. This however leads to introns for expressions smaller than the full template. As introns have no impact on fitness, their occurrences are not directly linked to selection. Consequently, introns can adversely affect the extent to which mutual information captures dependencies between tree nodes. To overcome this, we propose two new measures for linkage learning, one that explicitly considers introns in mutual information estimates, and one that revisits linkage learning in GP-GOMEA from a grey-box perspective, yielding a measure that needs not to be learned from the population but is derived directly from the template. Across five standard symbolic regression problems, GP-GOMEA achieves substantial improvements using both measures. We also find that the newly learned linkage structure closely reflects the template linkage structure, and that explicitly using the template structure yields the best performance overall.",
      "authors": [
        "Johannes Koch",
        "Tanja Alderliesten",
        "Peter A. N. Bosman"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-02-02 16:42:30+00:00",
      "link": "https://arxiv.org/pdf/2602.02311v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 10.0,
      "llm_evidence_en": "Directly addresses GP-GOMEA for symbolic regression and linkage learning",
      "llm_evidence_cn": "直接针对符号回归中的GP-GOMEA和连锁学习进行改进",
      "llm_evidence": "直接针对符号回归中的GP-GOMEA和连锁学习进行改进",
      "llm_tldr_en": "Improves GP-GOMEA for symbolic regression by rethinking linkage learning and the impact of introns.",
      "llm_tldr_cn": "通过重新思考连锁学习和内含子的影响，改进了用于符号回归的GP-GOMEA算法。",
      "llm_tldr": "通过重新思考连锁学习和内含子的影响，改进了用于符号回归的GP-GOMEA算法。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2602.02351v1",
      "title": "Artificial Intelligence and Symmetries: Learning, Encoding, and Discovering Structure in Physical Data",
      "abstract": "Symmetries play a central role in physics, organizing dynamics, constraining interactions, and determining the effective number of physical degrees of freedom. In parallel, modern artificial intelligence methods have demonstrated a remarkable ability to extract low-dimensional structure from high-dimensional data through representation learning. This review examines the interplay between these two perspectives, focusing on the extent to which symmetry-induced constraints can be identified, encoded, or diagnosed using machine learning techniques.   Rather than emphasizing architectures that enforce known symmetries by construction, we concentrate on data-driven approaches and latent representation learning, with particular attention to variational autoencoders. We discuss how symmetries and conservation laws reduce the intrinsic dimensionality of physical datasets, and how this reduction may manifest itself through self-organization of latent spaces in generative models trained to balance reconstruction and compression. We review recent results, including case studies from simple geometric systems and particle physics processes, and analyze the theoretical and practical limitations of inferring symmetry structure without explicit inductive bias.",
      "authors": [
        "Veronica Sanz"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-02 17:15:52+00:00",
      "link": "https://arxiv.org/pdf/2602.02351v1",
      "tags": [
        "query:SR"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "Explores discovering structure and symmetries in physical data, a core application area for symbolic regression.",
      "llm_evidence_cn": "探索发现物理数据中的结构和对称性，这是符号回归的核心应用领域。",
      "llm_evidence": "探索发现物理数据中的结构和对称性，这是符号回归的核心应用领域。",
      "llm_tldr_en": "Reviews AI methods for learning and discovering physical symmetries and structures from data.",
      "llm_tldr_cn": "综述了从数据中学习和发现物理对称性及结构的AI方法。",
      "llm_tldr": "综述了从数据中学习和发现物理对称性及结构的AI方法。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2602.00731v1",
      "title": "Neuro-symbolic AI for Predictive Maintenance (PdM) -- review and recommendations",
      "abstract": "In this document we perform a systematic review the State-of-the-art in Predictive Maintenance (PdM) over the last five years in industrial settings such as commercial buildings, pharmaceutical facilities, or semi-conductor manufacturing. In general, data-driven methods such as those based on deep learning, exhibit higher accuracy than traditional knowledge-based systems. These systems however, are not without significant limitations. The need for large labeled data sets, a lack of generalizibility to new environments (out-of-distribution generalization), and a lack of transparency at inference time are some of the obstacles to adoption in real world environments. In contrast, traditional approaches based on domain expertise in the form of rules, logic or first principles suffer from poor accuracy, many false positives and a need for ongoing expert supervision and manual tuning. While the majority of approaches in recent literature utilize some form of data-driven architecture, there are hybrid systems which also take into account domain specific knowledge. Such hybrid systems have the potential to overcome the weaknesses of either approach on its own while preserving their strengths. We propose taking the hybrid approach even further and integrating deep learning with symbolic logic, or Neuro-symbolic AI, to create more accurate, explainable, interpretable, and robust systems. We describe several neuro-symbolic architectures and examine their strengths and limitations within the PdM domain. We focus specifically on methods which involve the use of sensor data and manually crafted rules as inputs by describing concrete NeSy architectures. In short, this survey outlines the context of modern maintenance, defines key concepts, establishes a generalized framework, reviews current modeling approaches and challenges, and introduces the proposed focus on Neuro-symbolic AI (NESY).",
      "authors": [
        "Kyle Hamilton",
        "Ali Intizar"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "published": "2026-01-31 13:47:27+00:00",
      "link": "https://arxiv.org/pdf/2602.00731v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Discusses neuro-symbolic AI which is a broader field encompassing symbolic regression techniques.",
      "llm_evidence_cn": "讨论了神经符号AI，这是一个包含符号回归技术的更广泛领域。",
      "llm_evidence": "讨论了神经符号AI，这是一个包含符号回归技术的更广泛领域。",
      "llm_tldr_en": "Reviews neuro-symbolic AI for predictive maintenance, highlighting the integration of data-driven and symbolic methods.",
      "llm_tldr_cn": "综述了用于预测性维护的神经符号AI，强调了数据驱动与符号方法的结合。",
      "llm_tldr": "综述了用于预测性维护的神经符号AI，强调了数据驱动与符号方法的结合。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.01322v1",
      "title": "PolySAE: Modeling Feature Interactions in Sparse Autoencoders via Polynomial Decoding",
      "abstract": "Sparse autoencoders (SAEs) have emerged as a promising method for interpreting neural network representations by decomposing activations into sparse combinations of dictionary atoms. However, SAEs assume that features combine additively through linear reconstruction, an assumption that cannot capture compositional structure: linear models cannot distinguish whether \"Starbucks\" arises from the composition of \"star\" and \"coffee\" features or merely their co-occurrence. This forces SAEs to allocate monolithic features for compound concepts rather than decomposing them into interpretable constituents. We introduce PolySAE, which extends the SAE decoder with higher-order terms to model feature interactions while preserving the linear encoder essential for interpretability. Through low-rank tensor factorization on a shared projection subspace, PolySAE captures pairwise and triple feature interactions with small parameter overhead (3% on GPT2). Across four language models and three SAE variants, PolySAE achieves an average improvement of approximately 8% in probing F1 while maintaining comparable reconstruction error, and produces 2-10$\\times$ larger Wasserstein distances between class-conditional feature distributions. Critically, learned interaction weights exhibit negligible correlation with co-occurrence frequency ($r = 0.06$ vs. $r = 0.82$ for SAE feature covariance), suggesting that polynomial terms capture compositional structure, such as morphological binding and phrasal composition, largely independent of surface statistics.",
      "authors": [
        "Panagiotis Koromilas",
        "Andreas D. Demou",
        "James Oldfield",
        "Yannis Panagakis",
        "Mihalis Nicolaou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-01 16:34:45+00:00",
      "link": "https://arxiv.org/pdf/2602.01322v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Polynomial decoding for feature interactions in autoencoders",
      "llm_evidence_cn": "自动编码器中特征交互的多项式解码",
      "llm_evidence": "自动编码器中特征交互的多项式解码",
      "llm_tldr_en": "Uses polynomial terms to model feature interactions, aligning with symbolic/algebraic representation discovery.",
      "llm_tldr_cn": "使用多项式项对特征交互建模，符合符号/代数表示发现的思路。",
      "llm_tldr": "使用多项式项对特征交互建模，符合符号/代数表示发现的思路。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.01493v1",
      "title": "OpInf-LLM: Parametric PDE Solving with LLMs via Operator Inference",
      "abstract": "Solving diverse partial differential equations (PDEs) is fundamental in science and engineering. Large language models (LLMs) have demonstrated strong capabilities in code generation, symbolic reasoning, and tool use, but reliably solving PDEs across heterogeneous settings remains challenging. Prior work on LLM-based code generation and transformer-based foundation models for PDE learning has shown promising advances. However, a persistent trade-off between execution success rate and numerical accuracy arises, particularly when generalization to unseen parameters and boundary conditions is required. In this work, we propose OpInf-LLM, an LLM parametric PDE solving framework based on operator inference. The proposed framework leverages a small amount of solution data to enable accurate prediction of diverse PDE instances, including unseen parameters and configurations, and provides seamless integration with LLMs for natural language specification of PDE solving tasks. Its low computational demands and unified tool interface further enable a high execution success rate across heterogeneous settings. By combining operator inference with LLM capabilities, OpInf-LLM opens new possibilities for generalizable reduced-order modeling in LLM-based PDE solving.",
      "authors": [
        "Zhuoyuan Wang",
        "Hanjiang Hu",
        "Xiyu Deng",
        "Saviz Mowlavi",
        "Yorie Nakahira"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02 00:04:50+00:00",
      "link": "https://arxiv.org/pdf/2602.01493v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "LLM-based symbolic reasoning for PDE solving",
      "llm_evidence_cn": "基于大语言模型的偏微分方程符号推理求解",
      "llm_evidence": "基于大语言模型的偏微分方程符号推理求解",
      "llm_tldr_en": "Proposes OpInf-LLM, a framework using LLMs for symbolic reasoning and operator inference to solve parametric PDEs.",
      "llm_tldr_cn": "提出OpInf-LLM框架，利用大语言模型的符号推理能力和算子推断来求解参数化偏微分方程。",
      "llm_tldr": "提出OpInf-LLM框架，利用大语言模型的符号推理能力和算子推断来求解参数化偏微分方程。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.01516v1",
      "title": "White-Box Neural Ensemble for Vehicular Plasticity: Quantifying the Efficiency Cost of Symbolic Auditability in Adaptive NMPC",
      "abstract": "We present a white-box adaptive NMPC architecture that resolves vehicular plasticity (adaptation to varying operating regimes without retraining) by arbitrating among frozen, regime-specific neural specialists using a Modular Sovereignty paradigm. The ensemble dynamics are maintained as a fully traversable symbolic graph in CasADi, enabling maximal runtime auditability. Synchronous simulation validates rapid adaptation (~7.3 ms) and near-ideal tracking fidelity under compound regime shifts (friction, mass, drag) where non-adaptive baselines fail. Empirical benchmarking quantifies the transparency cost: symbolic graph maintenance increases solver latency by 72-102X versus compiled parametric physics models, establishing the efficiency price of strict white-box implementation.",
      "authors": [
        "Enzo Nicolas Spotorno",
        "Matheus Wagner",
        "Antonio Augusto Medeiros Frohlich"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "published": "2026-02-02 01:05:30+00:00",
      "link": "https://arxiv.org/pdf/2602.01516v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Fully traversable symbolic graph for white-box neural ensemble and auditability",
      "llm_evidence_cn": "用于白盒神经集成和可审计性的全遍历符号图",
      "llm_evidence": "用于白盒神经集成和可审计性的全遍历符号图",
      "llm_tldr_en": "Presents a white-box NMPC architecture using symbolic graphs to enable runtime auditability in vehicular systems.",
      "llm_tldr_cn": "提出一种使用符号图的白盒NMPC架构，实现车辆系统的运行时审计。",
      "llm_tldr": "提出一种使用符号图的白盒NMPC架构，实现车辆系统的运行时审计。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.02172v1",
      "title": "Neural Network Machine Regression (NNMR): A Deep Learning Framework for Uncovering High-order Synergistic Effects",
      "abstract": "We propose a new neural network framework, termed Neural Network Machine Regression (NNMR), which integrates trainable input gating and adaptive depth regularization to jointly perform feature selection and function estimation in an end-to-end manner. By penalizing both gating parameters and redundant layers, NNMR yields sparse and interpretable architectures while capturing complex nonlinear relationships driven by high-order synergistic effects. We further develop a post-selection inference procedure based on split-sample, permutation-based hypothesis testing, enabling valid inference without restrictive parametric assumptions. Compared with existing methods, including Bayesian kernel machine regression and widely used post hoc attribution techniques, NNMR scales efficiently to high-dimensional feature spaces while rigorously controlling type I error. Simulation studies demonstrate its superior selection accuracy and inference reliability. Finally, an empirical application reveals sparse, biologically meaningful food group predictors associated with somatic growth among adolescents living in Mexico City.",
      "authors": [
        "Jiuchen Zhang",
        "Ling Zhou",
        "Peter Song"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-02 14:45:57+00:00",
      "link": "https://arxiv.org/pdf/2602.02172v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "interpretable regression framework for function estimation",
      "llm_evidence_cn": "用于函数估计的可解释回归框架",
      "llm_evidence": "用于函数估计的可解释回归框架",
      "llm_tldr_en": "Proposes NNMR for sparse, interpretable function estimation and high-order effect discovery.",
      "llm_tldr_cn": "提出NNMR框架，用于稀疏、可解释的函数估计和高阶协同效应发现。",
      "llm_tldr": "提出NNMR框架，用于稀疏、可解释的函数估计和高阶协同效应发现。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    }
  ]
}