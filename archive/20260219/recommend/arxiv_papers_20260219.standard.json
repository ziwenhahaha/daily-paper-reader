{
  "mode": "standard",
  "generated_at": "2026-02-19T19:31:46.028525+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 1,
    "deep_divecandidates": 2,
    "deep_cap": 6,
    "deep_selected": 2,
    "quick_candidates": 7,
    "quick_skim_target": 11,
    "quick_selected": 7
  },
  "deep_dive": [
    {
      "id": "2602.16166v1",
      "title": "Discovering Unknown Inverter Governing Equations via Physics-Informed Sparse Machine Learning",
      "abstract": "Discovering the unknown governing equations of grid-connected inverters from external measurements holds significant attraction for analyzing modern inverter-intensive power systems. However, existing methods struggle to balance the identification of unmodeled nonlinearities with the preservation of physical consistency. To address this, this paper proposes a Physics-Informed Sparse Machine Learning (PISML) framework. The architecture integrates a sparse symbolic backbone to capture dominant model skeletons with a neural residual branch that compensates for complex nonlinear control logic. Meanwhile, a Jacobian-regularized physics-informed training mechanism is introduced to enforce multi-scale consistency including large/small-scale behaviors. Furthermore, by performing symbolic regression on the neural residual branch, PISML achieves a tractable mapping from black-box data to explicit control equations. Experimental results on a high-fidelity Hardware-in-the-Loop platform demonstrate the framework's superior performance. It not only achieves high-resolution identification by reducing error by over 340 times compared to baselines but also realizes the compression of heavy neural networks into compact explicit forms. This restores analytical tractability for rigorous stability analysis and reduces computational complexity by orders of magnitude. It also provides a unified pathway to convert structurally inaccessible devices into explicit mathematical models, enabling stability analysis of power systems with unknown inverter governing equations.",
      "authors": [
        "Jialin Zheng",
        "Ruhaan Batta",
        "Zhong Liu",
        "Xiaonan Lu"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-18 03:46:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16166v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 9.0,
      "llm_evidence_en": "Sparse symbolic backbone for discovering governing equations in power systems",
      "llm_evidence_cn": "用于发现电力系统控制方程的稀疏符号主干网络",
      "llm_evidence": "用于发现电力系统控制方程的稀疏符号主干网络",
      "llm_tldr_en": "Proposes a physics-informed sparse machine learning framework to discover unknown governing equations for inverters.",
      "llm_tldr_cn": "提出一种物理告知的稀疏机器学习框架，用于发现逆变器的未知控制方程。",
      "llm_tldr": "提出一种物理告知的稀疏机器学习框架，用于发现逆变器的未知控制方程。",
      "llm_tags": [
        "query:sr"
      ],
      "matched_query_tag": "query:sr",
      "matched_query_text": "Symbolic regression for scientific discovery and physical law extraction",
      "matched_requirement_id": "req-3"
    },
    {
      "id": "2602.15951v1",
      "title": "MadEvolve: Evolutionary Optimization of Cosmological Algorithms with Large Language Models",
      "abstract": "We develop a general framework to discover scientific algorithms and apply it to three problems in computational cosmology. Our code, MadEvolve, is similar to Google's AlphaEvolve, but places a stronger emphasis on free parameters and their optimization. Our code starts with a baseline human algorithm implementation, and then optimizes its performance metrics by making iterative changes to its code. As a further convenient feature, MadEvolve automatically generates a report that compares the input algorithm with the evolved algorithm, describes the algorithmic innovations and lists the free parameters and their function. Our code supports both auto-differentiable, gradient-based parameter optimization and gradient-free optimization methods. We apply MadEvolve to the reconstruction of cosmological initial conditions, 21cm foreground contamination reconstruction and effective baryonic physics in N-body simulations. In all cases, we find substantial improvements over the base algorithm. We make MadEvolve and our three tasks publicly available at madevolve.org.",
      "authors": [
        "Tianyi Li",
        "Shihui Zang",
        "Moritz Münchmeyer"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "cs.LG"
      ],
      "published": "2026-02-17 19:06:52+00:00",
      "link": "https://arxiv.org/pdf/2602.15951v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 8.0,
      "llm_evidence_en": "Evolutionary optimization for scientific algorithm discovery in cosmology",
      "llm_evidence_cn": "宇宙学中用于科学算法发现的进化优化框架",
      "llm_evidence": "宇宙学中用于科学算法发现的进化优化框架",
      "llm_tldr_en": "MadEvolve uses LLMs and evolutionary optimization to discover and refine scientific algorithms in cosmology.",
      "llm_tldr_cn": "MadEvolve利用大模型和进化优化在宇宙学领域发现并改进科学算法。",
      "llm_tldr": "MadEvolve利用大模型和进化优化在宇宙学领域发现并改进科学算法。",
      "llm_tags": [
        "query:sr"
      ],
      "matched_query_tag": "query:sr",
      "matched_query_text": "Symbolic regression for scientific discovery and physical law extraction",
      "matched_requirement_id": "req-3"
    }
  ],
  "quick_skim": [
    {
      "id": "2602.16316v1",
      "title": "A Graph Meta-Network for Learning on Kolmogorov-Arnold Networks",
      "abstract": "Weight-space models learn directly from the parameters of neural networks, enabling tasks such as predicting their accuracy on new datasets. Naive methods -- like applying MLPs to flattened parameters -- perform poorly, making the design of better weight-space architectures a central challenge. While prior work leveraged permutation symmetries in standard networks to guide such designs, no analogous analysis or tailored architecture yet exists for Kolmogorov-Arnold Networks (KANs). In this work, we show that KANs share the same permutation symmetries as MLPs, and propose the KAN-graph, a graph representation of their computation. Building on this, we develop WS-KAN, the first weight-space architecture that learns on KANs, which naturally accounts for their symmetry. We analyze WS-KAN's expressive power, showing it can replicate an input KAN's forward pass - a standard approach for assessing expressiveness in weight-space architectures. We construct a comprehensive ``zoo'' of trained KANs spanning diverse tasks, which we use as benchmarks to empirically evaluate WS-KAN. Across all tasks, WS-KAN consistently outperforms structure-agnostic baselines, often by a substantial margin. Our code is available at https://github.com/BarSGuy/KAN-Graph-Metanetwork.",
      "authors": [
        "Guy Bar-Shalom",
        "Ami Tavory",
        "Itay Evron",
        "Maya Bechler-Speicher",
        "Ido Guy",
        "Haggai Maron"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-18 09:53:53+00:00",
      "link": "https://arxiv.org/pdf/2602.16316v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "learning on Kolmogorov-Arnold Networks (KANs) as an alternative to MLPs",
      "llm_evidence_cn": "在KAN网络上进行学习，作为MLP的替代方案",
      "llm_evidence": "在KAN网络上进行学习，作为MLP的替代方案",
      "llm_tldr_en": "Proposes a graph meta-network for learning on Kolmogorov-Arnold Networks, which are relevant to symbolic tasks.",
      "llm_tldr_cn": "提出了一种用于在KAN网络上学习的图元网络，KAN与符号化任务相关。",
      "llm_tldr": "提出了一种用于在KAN网络上学习的图元网络，KAN与符号化任务相关。",
      "llm_tags": [
        "query:sr"
      ],
      "matched_query_tag": "query:sr",
      "matched_query_text": "Comparison of genetic programming and neural symbolic regression techniques",
      "matched_requirement_id": "req-4",
      "quick_tier": "7"
    },
    {
      "id": "2602.16000v1",
      "title": "Imaging-Derived Coronary Fractional Flow Reserve: Advances in Physics-Based, Machine-Learning, and Physics-Informed Methods",
      "abstract": "Purpose of Review Imaging derived fractional flow reserve (FFR) is rapidly evolving beyond conventional computational fluid dynamics (CFD) based pipelines toward machine learning (ML), deep learning (DL), and physics informed approaches that enable fast, wire free, and scalable functional assessment of coronary stenosis. This review synthesizes recent advances in CT and angiography based FFR, with particular emphasis on emerging physics informed neural networks and neural operators (PINNs and PINOs) and key considerations for their clinical translation. Recent Findings ML/DL approaches have markedly improved automation and computational speed, enabling prediction of pressure and FFR from anatomical descriptors or angiographic contrast dynamics. However, their real-world performance and generalizability can remain variable and sensitive to domain shift, due to multi-center heterogeneity, interpretability challenges, and differences in acquisition protocols and image quality. Physics informed learning introduces conservation structure and boundary condition consistency into model training, improving generalizability and reducing dependence on dense supervision while maintaining rapid inference. Recent evaluation trends increasingly highlight deployment oriented metrics, including calibration, uncertainty quantification, and quality control gatekeeping, as essential for safe clinical use. Summary The field is converging toward imaging derived FFR methods that are faster, more automated, and more reliable. While ML/DL offers substantial efficiency gains, physics informed frameworks such as PINNs and PINOs may provide a more robust balance between speed and physical consistency. Prospective multi center validation and standardized evaluation will be critical to support broad and safe clinical adoption.",
      "authors": [
        "Tanxin Zhu",
        "Emran Hossen",
        "Chen Zhao",
        "Michele Esposito",
        "Jiguang Sun",
        "Weihua Zhou"
      ],
      "primary_category": "physics.med-ph",
      "categories": [
        "physics.med-ph",
        "cs.LG"
      ],
      "published": "2026-02-17 20:46:25+00:00",
      "link": "https://arxiv.org/pdf/2602.16000v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Physics-informed neural networks for scientific discovery in medicine",
      "llm_evidence_cn": "用于医学科学发现的物理信息神经网络",
      "llm_evidence": "用于医学科学发现的物理信息神经网络",
      "llm_tldr_en": "Reviews physics-informed and ML methods for coronary flow assessment and physical law integration.",
      "llm_tldr_cn": "综述了用于冠状动脉血流评估的物理信息神经网络与机器学习方法，涉及物理规律集成。",
      "llm_tldr": "综述了用于冠状动脉血流评估的物理信息神经网络与机器学习方法，涉及物理规律集成。",
      "llm_tags": [
        "query:sr"
      ],
      "matched_query_tag": "query:sr",
      "matched_query_text": "Symbolic regression for scientific discovery and physical law extraction",
      "matched_requirement_id": "req-3",
      "quick_tier": "6"
    },
    {
      "id": "2602.16551v1",
      "title": "Automated Extraction of Mechanical Constitutive Models from Scientific Literature using Large Language Models: Applications in Cultural Heritage Conservation",
      "abstract": "The preservation of cultural heritage is increasingly transitioning towards data-driven predictive maintenance and \"Digital Twin\" construction. However, the mechanical constitutive models required for high-fidelity simulations remain fragmented across decades of unstructured scientific literature, creating a \"Data Silo\" that hinders conservation engineering. To address this, we present an automated, two-stage agentic framework leveraging Large Language Models (LLMs) to extract mechanical constitutive equations, calibrated parameters, and metadata from PDF documents. The workflow employs a resource-efficient \"Gatekeeper\" agent for relevance filtering and a high-capability \"Analyst\" agent for fine-grained extraction, featuring a novel Context-Aware Symbolic Grounding mechanism to resolve mathematical ambiguities. Applied to a corpus of over 2,000 research papers, the system successfully isolated 113 core documents and constructed a structured database containing 185 constitutive model instances and over 450 calibrated parameters. The extraction precision reached 80.4\\%, establishing a highly efficient \"Human-in-the-loop\" workflow that reduces manual data curation time by approximately 90\\%. We demonstrate the system's utility through a web-based Knowledge Retrieval Platform, which enables rapid parameter discovery for computational modeling. This work transforms scattered literature into a queryable digital asset, laying the data foundation for the \"Digital Material Twin\" of built heritage.",
      "authors": [
        "Rui Hu",
        "Yue Wu",
        "Tianhao Su",
        "Yin Wang",
        "Shunbo Hu",
        "Jizhong Huang"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-02-18 15:53:15+00:00",
      "link": "https://arxiv.org/pdf/2602.16551v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "Automated extraction of mechanical constitutive equations from scientific literature",
      "llm_evidence_cn": "从科学文献中自动提取机械本构方程",
      "llm_evidence": "从科学文献中自动提取机械本构方程",
      "llm_tldr_en": "Uses LLMs to extract physical laws and equations from scientific papers for engineering applications.",
      "llm_tldr_cn": "利用大语言模型从科学文献中提取物理方程和本构模型，用于工程仿真。",
      "llm_tldr": "利用大语言模型从科学文献中提取物理方程和本构模型，用于工程仿真。",
      "llm_tags": [
        "query:sr"
      ],
      "matched_query_tag": "query:sr",
      "matched_query_text": "Symbolic regression for scientific discovery and physical law extraction",
      "matched_requirement_id": "req-3",
      "quick_tier": "7"
    },
    {
      "id": "2602.16117v1",
      "title": "Solving BDNK diffusion using physics-informed neural networks",
      "abstract": "In this work, we reformulate the relativistic BDNK (Bemfica-Disconzi-Noronha-Kovtun) diffusion equation in flux-conservative form, and solve the resulting equations in $(1+1)$D using both a second-order Kurganov-Tadmor finite volume scheme and physics-informed neural networks (PINNs). In particular, we introduce the SA-PINN-ACTO framework, which combines the self-adaptive PINN technique with an exact enforcement of initial and periodic boundary conditions through an algebraic transform of the network's raw output, allowing the network to focus solely on minimizing the PDE residual. We test both approaches on smooth and discontinuous initial data, for both trivial and dynamically evolving velocity and temperature BDNK backgrounds, and for two characteristic speeds. The SA-PINN-ACTO method matches the converged Kurganov-Tadmor solutions for smooth profiles, while for discontinuous profiles the errors increase, reflecting an expected limitation of PINNs near sharp gradients.",
      "authors": [
        "Vicente Chomalí-Castro",
        "Nick Clarisse",
        "Nicki Mullins",
        "Jorge Noronha"
      ],
      "primary_category": "nucl-th",
      "categories": [
        "nucl-th",
        "astro-ph.HE",
        "gr-qc"
      ],
      "published": "2026-02-18 00:58:19+00:00",
      "link": "https://arxiv.org/pdf/2602.16117v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Physics-informed neural networks for solving relativistic diffusion equations",
      "llm_evidence_cn": "用于求解相对论扩散方程的物理信息神经网络",
      "llm_evidence": "用于求解相对论扩散方程的物理信息神经网络",
      "llm_tldr_en": "Uses PINNs to solve complex relativistic diffusion equations, relevant to scientific discovery and physical laws.",
      "llm_tldr_cn": "利用物理信息神经网络求解复杂的相对论扩散方程，涉及物理规律的数值发现。",
      "llm_tldr": "利用物理信息神经网络求解复杂的相对论扩散方程，涉及物理规律的数值发现。",
      "llm_tags": [
        "query:sr"
      ],
      "matched_query_tag": "query:sr",
      "matched_query_text": "Symbolic regression for scientific discovery and physical law extraction",
      "matched_requirement_id": "req-3",
      "quick_tier": "6"
    },
    {
      "id": "2602.16317v1",
      "title": "CADEvolve: Creating Realistic CAD via Program Evolution",
      "abstract": "Computer-Aided Design (CAD) delivers rapid, editable modeling for engineering and manufacturing. Recent AI progress now makes full automation feasible for various CAD tasks. However, progress is bottlenecked by data: public corpora mostly contain sketch-extrude sequences, lack complex operations, multi-operation composition and design intent, and thus hinder effective fine-tuning. Attempts to bypass this with frozen VLMs often yield simple or invalid programs due to limited 3D grounding in current foundation models. We present CADEvolve, an evolution-based pipeline and dataset that starts from simple primitives and, via VLM-guided edits and validations, incrementally grows CAD programs toward industrial-grade complexity. The result is 8k complex parts expressed as executable CadQuery parametric generators. After multi-stage post-processing and augmentation, we obtain a unified dataset of 1.3m scripts paired with rendered geometry and exercising the full CadQuery operation set. A VLM fine-tuned on CADEvolve achieves state-of-the-art results on the Image2CAD task across the DeepCAD, Fusion 360, and MCB benchmarks.",
      "authors": [
        "Maksim Elistratov",
        "Marina Barannikov",
        "Gregory Ivanov",
        "Valentin Khrulkov",
        "Anton Konushin",
        "Andrey Kuznetsov",
        "Dmitrii Zhemchuzhnikov"
      ],
      "primary_category": "cs.GR",
      "categories": [
        "cs.GR"
      ],
      "published": "2026-02-18 09:54:57+00:00",
      "link": "https://arxiv.org/pdf/2602.16317v1",
      "tags": [
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "program evolution and genetic-based editing for CAD",
      "llm_evidence_cn": "用于CAD的程序演化和基于遗传的编辑",
      "llm_evidence": "用于CAD的程序演化和基于遗传的编辑",
      "llm_tldr_en": "An evolution-based pipeline that grows CAD programs toward industrial complexity using VLM-guided edits.",
      "llm_tldr_cn": "一种基于演化的流水线，通过VLM引导的编辑使CAD程序达到工业级复杂度。",
      "llm_tldr": "一种基于演化的流水线，通过VLM引导的编辑使CAD程序达到工业级复杂度。",
      "llm_tags": [
        "query:sr"
      ],
      "matched_query_tag": "query:sr",
      "matched_query_text": "Comparison of genetic programming and neural symbolic regression techniques",
      "matched_requirement_id": "req-4",
      "quick_tier": "6"
    },
    {
      "id": "2602.16473v1",
      "title": "Synthesis and Verification of Transformer Programs",
      "abstract": "C-RASP is a simple programming language that was recently shown to capture concepts expressible by transformers. In this paper, we develop new algorithmic techniques for automatically verifying C-RASPs. To this end, we establish a connection to the verification of synchronous dataflow programs in Lustre, which enables us to exploit state-of-the-art model checkers utilizing highly optimized SMT-solvers. Our second contribution addresses learning a C-RASP program in the first place. To this end, we provide a new algorithm for learning a C-RASP from examples using local search. We demonstrate efficacy of our implementation for benchmarks of C-RASPs in the literature, in particular in connection to the following applications: (1) transformer program optimization, and (2) constrained learning of transformer programs (based on a partial specification).",
      "authors": [
        "Hongjian Jiang",
        "Matthew Hague",
        "Philipp Rümmer",
        "Anthony Widjaja Lin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.FL",
        "cs.LO"
      ],
      "published": "2026-02-18 14:04:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16473v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "learning programs from examples using local search and verification",
      "llm_evidence_cn": "通过局部搜索和验证从示例中学习程序",
      "llm_evidence": "通过局部搜索和验证从示例中学习程序",
      "llm_tldr_en": "Develops techniques for synthesizing and verifying transformer-based programs from examples.",
      "llm_tldr_cn": "开发了从示例中合成和验证基于Transformer的程序的技术。",
      "llm_tldr": "开发了从示例中合成和验证基于Transformer的程序的技术。",
      "llm_tags": [
        "query:sr"
      ],
      "matched_query_tag": "query:sr",
      "matched_query_text": "Comparison of genetic programming and neural symbolic regression techniques",
      "matched_requirement_id": "req-4",
      "quick_tier": "6"
    },
    {
      "id": "2602.16481v1",
      "title": "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach",
      "abstract": "Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.",
      "authors": [
        "Zihao Li",
        "Fabrizio Russo"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-18 14:15:21+00:00",
      "link": "https://arxiv.org/pdf/2602.16481v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Symbolic reasoning and LLMs for causal discovery and structural priors",
      "llm_evidence_cn": "用于因果发现和结构先验的符号推理与大模型结合",
      "llm_evidence": "用于因果发现和结构先验的符号推理与大模型结合",
      "llm_tldr_en": "Combines symbolic reasoning with LLMs to perform causal discovery from observational data and expert knowledge.",
      "llm_tldr_cn": "结合符号推理与大模型，从观测数据和专家知识中进行因果发现。",
      "llm_tldr": "结合符号推理与大模型，从观测数据和专家知识中进行因果发现。",
      "llm_tags": [
        "query:sr"
      ],
      "matched_query_tag": "query:sr",
      "matched_query_text": "Comparison of genetic programming and neural symbolic regression techniques",
      "matched_requirement_id": "req-4",
      "quick_tier": "6"
    }
  ]
}