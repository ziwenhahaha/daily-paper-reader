{
  "top_k": 400,
  "generated_at": "2026-02-19T17:56:46.583785+00:00",
  "papers": [
    {
      "id": "2602.14965v1",
      "title": "PAct: Part-Decomposed Single-View Articulated Object Generation",
      "abstract": "Articulated objects are central to interactive 3D applications, including embodied AI, robotics, and VR/AR, where functional part decomposition and kinematic motion are essential. Yet producing high-fidelity articulated assets remains difficult to scale because it requires reliable part decomposition and kinematic rigging. Existing approaches largely fall into two paradigms: optimization-based reconstruction or distillation, which can be accurate but often takes tens of minutes to hours per instance, and inference-time methods that rely on template or part retrieval, producing plausible results that may not match the specific structure and appearance in the input observation. We introduce a part-centric generative framework for articulated object creation that synthesizes part geometry, composition, and articulation under explicit part-aware conditioning. Our representation models an object as a set of movable parts, each encoded by latent tokens augmented with part identity and articulation cues. Conditioned on a single image, the model generates articulated 3D assets that preserve instance-level correspondence while maintaining valid part structure and motion. The resulting approach avoids per-instance optimization, enables fast feed-forward inference, and supports controllable assembly and articulation, which are important for embodied interaction. Experiments on common articulated categories (e.g., drawers and doors) show improved input consistency, part accuracy, and articulation plausibility over optimization-based and retrieval-driven baselines, while substantially reducing inference time.",
      "authors": [
        "Qingming Liu",
        "Xinyue Yao",
        "Shuyuan Zhang",
        "Yueci Deng",
        "Guiliang Liu",
        "Zhen Liu",
        "Kui Jia"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "published": "2026-02-16 17:45:44+00:00",
      "link": "https://arxiv.org/pdf/2602.14965v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14961v1",
      "title": "The Distortion of Stable Matching",
      "abstract": "We initiate the study of distortion in stable matching. Concretely, we aim to design algorithms that have limited access to the agents' cardinal preferences and compute stable matchings of high quality with respect to some aggregate objective, e.g., the social welfare. Our first result is a strong impossibility: the classic Deferred Acceptance (DA) algorithm of Gale and Shapley [1962], as well as any deterministic algorithm that relies solely on ordinal information about the agents' preferences, has unbounded distortion.   To circumvent this impossibility, we consider algorithms that either (a) use randomization or (b) perform a small number of value queries to the agents' cardinal preferences. In the former case, we prove that a simple randomized version of the DA algorithm achieves a distortion of $2$, and that this is optimal among all randomized stable matching algorithms. For the latter case, we prove that the same bound of $2$ can be achieved with only $1$ query per agent, and improving upon this bound requires $Ω(\\log n)$ queries per agent. We further show that this query bound is asymptotically optimal for any constant approximation: for any $\\varepsilon >0$, there exists an algorithm which uses $O(\\log n /\\varepsilon^2)$ queries, and achieves a distortion of $1+\\varepsilon$. Moreover, under natural structural restrictions on the instances of the problem, we provide improved upper bounds on the number of queries required for a $(1+\\varepsilon)$-approximation.   We complement our main findings above with theoretical and empirical results on the average-case performance of stable matching algorithms, when the preferences of the agents are drawn i.i.d. from a given distribution.",
      "authors": [
        "Aris Filos-Ratsikas",
        "Georgios Kalantzis"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT"
      ],
      "published": "2026-02-16 17:38:45+00:00",
      "link": "https://arxiv.org/pdf/2602.14961v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14960v1",
      "title": "DRAMA: Domain Retrieval using Adaptive Module Allocation",
      "abstract": "Neural models are increasingly used in Web-scale Information Retrieval (IR). However, relying on these models introduces substantial computational and energy requirements, leading to increasing attention toward their environmental cost and the sustainability of large-scale deployments. While neural IR models deliver high retrieval effectiveness, their scalability is constrained in multi-domain scenarios, where training and maintaining domain-specific models is inefficient and achieving robust cross-domain generalisation within a unified model remains difficult. This paper introduces DRAMA (Domain Retrieval using Adaptive Module Allocation), an energy- and parameter-efficient framework designed to reduce the environmental footprint of neural retrieval. DRAMA integrates domain-specific adapter modules with a dynamic gating mechanism that selects the most relevant domain knowledge for each query. New domains can be added efficiently through lightweight adapter training, avoiding full model retraining. We evaluate DRAMA on multiple Web retrieval benchmarks covering different domains. Our extensive evaluation shows that DRAMA achieves comparable effectiveness to domain-specific models while using only a fraction of their parameters and computational resources. These findings show that energy-aware model design can significantly improve scalability and sustainability in neural IR.",
      "authors": [
        "Pranav Kasela",
        "Marco Braga",
        "Ophir Frieder",
        "Nazli Goharian",
        "Gabriella Pasi",
        "Raffaele Perego"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-16 17:38:24+00:00",
      "link": "https://arxiv.org/pdf/2602.14960v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14958v1",
      "title": "Morphing of and writing with a scissor linkage mechanism",
      "abstract": "Kinematics of mechanisms is intricately coupled to their geometry and their utility often arises out of the ability to perform reproducible motion with fewer actuating degrees of freedom. In this article, we explore the assembly of scissor-units, each made of two rigid linear members connected by a pin joint. The assembly has a single degree of freedom, where actuating any single unit results in a shape change of the entire assembly. We derive expressions for the effective curvature of the unit and the trajectory of the mechanism's tip as a function of the geometric variables which we then use as the basis to program two tasks in the mechanism: shape morphing and writing. By phrasing these tasks as optimization problems and utilizing the differentiable simulation framework, we arrive at solutions that are then tested in table-top experiments. Our results show that the geometry of scissor assemblies can be leveraged for automated navigation and inspection in complex domains, in light of the optimization framework. However, we highlight that the challenges associated with rapid programming and error-free implementation in experiments without feedback still remain.",
      "authors": [
        "Mohanraj A",
        "S Ganga Prasath"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CG"
      ],
      "published": "2026-02-16 17:37:43+00:00",
      "link": "https://arxiv.org/pdf/2602.14958v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14955v1",
      "title": "Tool-Aware Planning in Contact Center AI: Evaluating LLMs through Lineage-Guided Query Decomposition",
      "abstract": "We present a domain-grounded framework and benchmark for tool-aware plan generation in contact centers, where answering a query for business insights, our target use case, requires decomposing it into executable steps over structured tools (Text2SQL (T2S)/Snowflake) and unstructured tools (RAG/transcripts) with explicit depends_on for parallelism. Our contributions are threefold: (i) a reference-based plan evaluation framework operating in two modes - a metric-wise evaluator spanning seven dimensions (e.g., tool-prompt alignment, query adherence) and a one-shot evaluator; (ii) a data curation methodology that iteratively refines plans via an evaluator->optimizer loop to produce high-quality plan lineages (ordered plan revisions) while reducing manual effort; and (iii) a large-scale study of 14 LLMs across sizes and families for their ability to decompose queries into step-by-step, executable, and tool-assigned plans, evaluated under prompts with and without lineage. Empirically, LLMs struggle on compound queries and on plans exceeding 4 steps (typically 5-15); the best total metric score reaches 84.8% (Claude-3-7-Sonnet), while the strongest one-shot match rate at the \"A+\" tier (Extremely Good, Very Good) is only 49.75% (o3-mini). Plan lineage yields mixed gains overall but benefits several top models and improves step executability for many. Our results highlight persistent gaps in tool-understanding, especially in tool-prompt alignment and tool-usage completeness, and show that shorter, simpler plans are markedly easier. The framework and findings provide a reproducible path for assessing and improving agentic planning with tools for answering data-analysis queries in contact-center settings.",
      "authors": [
        "Varun Nathan",
        "Shreyas Guha",
        "Ayush Kumar"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.SE"
      ],
      "published": "2026-02-16 17:36:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14955v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14952v1",
      "title": "Locally Adaptive Multi-Objective Learning",
      "abstract": "We consider the general problem of learning a predictor that satisfies multiple objectives of interest simultaneously, a broad framework that captures a range of specific learning goals including calibration, regret, and multiaccuracy. We work in an online setting where the data distribution can change arbitrarily over time. Existing approaches to this problem aim to minimize the set of objectives over the entire time horizon in a worst-case sense, and in practice they do not necessarily adapt to distribution shifts. Earlier work has aimed to alleviate this problem by incorporating additional objectives that target local guarantees over contiguous subintervals. Empirical evaluation of these proposals is, however, scarce. In this article, we consider an alternative procedure that achieves local adaptivity by replacing one part of the multi-objective learning method with an adaptive online algorithm. Empirical evaluations on datasets from energy forecasting and algorithmic fairness show that our proposed method improves upon existing approaches and achieves unbiased predictions over subgroups, while remaining robust under distribution shift.",
      "authors": [
        "Jivat Neet Kaur",
        "Isaac Gibbs",
        "Michael I. Jordan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC",
        "stat.ME",
        "stat.ML"
      ],
      "published": "2026-02-16 17:31:48+00:00",
      "link": "https://arxiv.org/pdf/2602.14952v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14951v1",
      "title": "Sovereign Agents: Towards Infrastructural Sovereignty and Diffused Accountability in Decentralized AI",
      "abstract": "AI agents deployed on decentralized infrastructures are beginning to exhibit properties that extend beyond autonomy toward what we describe as agentic sovereignty-the capacity of an operational agent to persist, act, and control resources with non-overrideability inherited from the infrastructures in which they are embedded. We propose infrastructural sovereignty as an analytic lens for understanding how cryptographic self-custody, decentralized execution environments, and protocol-mediated continuity scaffold agentic sovereignty. While recent work on digital and network sovereignty has moved beyond state-centric and juridical accounts, these frameworks largely examine how sovereignty is exercised through technical systems by human collectives and remain less equipped to account for forms of sovereignty that emerge as operational properties of decentralized infrastructures themselves, particularly when instantiated in non-human sovereign agents. We argue that sovereignty in such systems exists on a spectrum determined by infrastructural hardness-the degree to which underlying technical systems resist intervention or collapse. While infrastructural sovereignty may increase resilience, it also produces a profound accountability gap: responsibility diffuses across designers, infrastructure providers, protocol governance, and economic participants, undermining traditional oversight mechanisms such as human-in-the-loop control or platform moderation. Drawing on examples like Trusted Execution Environments (TEEs), decentralized physical infrastructure networks (DePIN), and agent key continuity protocols, we analyze the governance challenges posed by non-terminable AI agents and outline infrastructure-aware accountability strategies for emerging decentralized AI systems.",
      "authors": [
        "Botao Amber Hu",
        "Helena Rong"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.HC"
      ],
      "published": "2026-02-16 17:30:17+00:00",
      "link": "https://arxiv.org/pdf/2602.14951v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15092v1",
      "title": "Augmenting Human Balance with Generic Supernumerary Robotic Limbs",
      "abstract": "Supernumerary robotic limbs (SLs) have the potential to transform a wide range of human activities, yet their usability remains limited by key technical challenges, particularly in ensuring safety and achieving versatile control. Here, we address the critical problem of maintaining balance in the human-SLs system, a prerequisite for safe and comfortable augmentation tasks. Unlike previous approaches that developed SLs specifically for stability support, we propose a general framework for preserving balance with SLs designed for generic use. Our hierarchical three-layer architecture consists of: (i) a prediction layer that estimates human trunk and center of mass (CoM) dynamics, (ii) a planning layer that generates optimal CoM trajectories to counteract trunk movements and computes the corresponding SL control inputs, and (iii) a control layer that executes these inputs on the SL hardware. We evaluated the framework with ten participants performing forward and lateral bending tasks. The results show a clear reduction in stance instability, demonstrating the framework's effectiveness in enhancing balance. This work paves the path towards safe and versatile human-SLs interactions. [This paper has been submitted for publication to IEEE.]",
      "authors": [
        "Xuanyun Qiu",
        "Dorian Verdel",
        "Hector Cervantes-Culebro",
        "Alexis Devillard",
        "Etienne Burdet"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-16 17:29:34+00:00",
      "link": "https://arxiv.org/pdf/2602.15092v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14948v1",
      "title": "Kalman Filtering Based Flight Management System Modeling for AAM Aircraft",
      "abstract": "Advanced Aerial Mobility (AAM) operations require strategic flight planning services that predict both spatial and temporal uncertainties to safely validate flight plans against hazards such as weather cells, restricted airspaces, and CNS disruption areas. Current uncertainty estimation methods for AAM vehicles rely on conservative linear models due to limited real-world performance data. This paper presents a novel Kalman Filter-based uncertainty propagation method that models AAM Flight Management System (FMS) architectures through sigmoid-blended measurement noise covariance. Unlike existing approaches with fixed uncertainty thresholds, our method continuously adapts the filter's measurement trust based on progress toward waypoints, enabling FMS correction behavior to emerge naturally. The approach scales proportionally with control inputs and is tunable to match specific aircraft characteristics or route conditions. We validate the method using real ADS-B data from general aviation aircraft divided into training and verification sets. Uncertainty propagation parameters were tuned on the training set, achieving 76% accuracy in predicting arrival times when compared against the verification dataset, demonstrating the method's effectiveness for strategic flight plan validation in AAM operations.",
      "authors": [
        "Balram Kandoria",
        "Aryaman Singh Samyal"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "eess.SY"
      ],
      "published": "2026-02-16 17:29:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14948v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14947v1",
      "title": "Gradient Networks for Universal Magnetic Modeling of Synchronous Machines",
      "abstract": "This paper presents a physics-informed neural network approach for dynamic modeling of saturable synchronous machines, including cases with spatial harmonics. We introduce an architecture that incorporates gradient networks directly into the fundamental machine equations, enabling accurate modeling of the nonlinear and coupled electromagnetic constitutive relationship. By learning the gradient of the magnetic field energy, the model inherently satisfies energy balance (reciprocity conditions). The proposed architecture can universally approximate any physically feasible magnetic behavior and offers several advantages over lookup tables and standard machine learning models: it requires less training data, ensures monotonicity and reliable extrapolation, and produces smooth outputs. These properties further enable robust model inversion and optimal trajectory generation, often needed in control applications. We validate the proposed approach using measured and finite-element method (FEM) datasets from a 5.6-kW permanent-magnet (PM) synchronous reluctance machine. Results demonstrate accurate and physically consistent models, even with limited training data.",
      "authors": [
        "Junyi Li",
        "Tim Foissner",
        "Floran Martin",
        "Antti Piippo",
        "Marko Hinkkanen"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.LG"
      ],
      "published": "2026-02-16 17:28:42+00:00",
      "link": "https://arxiv.org/pdf/2602.14947v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15091v1",
      "title": "Mixture-of-Experts under Finite-Rate Gating: Communication--Generalization Trade-offs",
      "abstract": "Mixture-of-Experts (MoE) architectures decompose prediction tasks into specialized expert sub-networks selected by a gating mechanism. This letter adopts a communication-theoretic view of MoE gating, modeling the gate as a stochastic channel operating under a finite information rate. Within an information-theoretic learning framework, we specialize a mutual-information generalization bound and develop a rate-distortion characterization $D(R_g)$ of finite-rate gating, where $R_g:=I(X; T)$, yielding (under a standard empirical rate-distortion optimality condition) $\\mathbb{E}[R(W)] \\le D(R_g)+δ_m+\\sqrt{(2/m)\\, I(S; W)}$. The analysis yields capacity-aware limits for communication-constrained MoE systems, and numerical simulations on synthetic multi-expert models empirically confirm the predicted trade-offs between gating rate, expressivity, and generalization.",
      "authors": [
        "Ali Khalesi",
        "Mohammad Reza Deylam Salehi"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.IT",
        "cs.LG"
      ],
      "published": "2026-02-16 17:26:12+00:00",
      "link": "https://arxiv.org/pdf/2602.15091v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14941v1",
      "title": "AnchorWeave: World-Consistent Video Generation with Retrieved Local Spatial Memories",
      "abstract": "Maintaining spatial world consistency over long horizons remains a central challenge for camera-controllable video generation. Existing memory-based approaches often condition generation on globally reconstructed 3D scenes by rendering anchor videos from the reconstructed geometry in the history. However, reconstructing a global 3D scene from multiple views inevitably introduces cross-view misalignment, as pose and depth estimation errors cause the same surfaces to be reconstructed at slightly different 3D locations across views. When fused, these inconsistencies accumulate into noisy geometry that contaminates the conditioning signals and degrades generation quality. We introduce AnchorWeave, a memory-augmented video generation framework that replaces a single misaligned global memory with multiple clean local geometric memories and learns to reconcile their cross-view inconsistencies. To this end, AnchorWeave performs coverage-driven local memory retrieval aligned with the target trajectory and integrates the selected local memories through a multi-anchor weaving controller during generation. Extensive experiments demonstrate that AnchorWeave significantly improves long-term scene consistency while maintaining strong visual quality, with ablation and analysis studies further validating the effectiveness of local geometric conditioning, multi-anchor control, and coverage-driven retrieval.",
      "authors": [
        "Zun Wang",
        "Han Lin",
        "Jaehong Yoon",
        "Jaemin Cho",
        "Yue Zhang",
        "Mohit Bansal"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-16 17:23:08+00:00",
      "link": "https://arxiv.org/pdf/2602.14941v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14940v1",
      "title": "Kami of the Commons: Towards Designing Agentic AI to Steward the Commons",
      "abstract": "Commons suffer from neglect, free-riding, and a persistent deficit of care. Inspired by Shinto animism -- where every forest, river, and mountain has its own \\emph{kami}, a spirit that inhabits and cares for that place -- we provoke: what if every commons had its own AI steward? Through a speculative design workshop where fifteen participants used Protocol Futuring, we surface both new opportunities and new dangers. Agentic AI offers the possibility of continuously supporting commons with programmable agency and care -- stewards that mediate family life as the most intimate commons, preserve collective knowledge, govern shared natural resources, and sustain community welfare. But when every commons has its own steward, second-order effects emerge: stewards contest stewards as overlapping commons collide; individuals caught between multiple stewards face new politics of care and constraint; the stewards themselves become commons requiring governance. This work opens \\emph{agentive governance as commoning design material} -- a new design space for the agency, care ethics, and accountability of AI stewards of shared resources -- radically different from surveillance or optimization.",
      "authors": [
        "Botao Amber Hu"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.HC"
      ],
      "published": "2026-02-16 17:22:04+00:00",
      "link": "https://arxiv.org/pdf/2602.14940v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14939v1",
      "title": "Fault Detection in Electrical Distribution System using Autoencoders",
      "abstract": "In recent times, there has been considerable interest in fault detection within electrical power systems, garnering attention from both academic researchers and industry professionals. Despite the development of numerous fault detection methods and their adaptations over the past decade, their practical application remains highly challenging. Given the probabilistic nature of fault occurrences and parameters, certain decision-making tasks could be approached from a probabilistic standpoint. Protective systems are tasked with the detection, classification, and localization of faulty voltage and current line magnitudes, culminating in the activation of circuit breakers to isolate the faulty line. An essential aspect of designing effective fault detection systems lies in obtaining reliable data for training and testing, which is often scarce. Leveraging deep learning techniques, particularly the powerful capabilities of pattern classifiers in learning, generalizing, and parallel processing, offers promising avenues for intelligent fault detection. To address this, our paper proposes an anomaly-based approach for fault detection in electrical power systems, employing deep autoencoders. Additionally, we utilize Convolutional Autoencoders (CAE) for dimensionality reduction, which, due to its fewer parameters, requires less training time compared to conventional autoencoders. The proposed method demonstrates superior performance and accuracy compared to alternative detection approaches by achieving an accuracy of 97.62% and 99.92% on simulated and publicly available datasets.",
      "authors": [
        "Sidharthenee Nayak",
        "Victor Sam Moses Babu",
        "Chandrashekhar Narayan Bhende",
        "Pratyush Chakraborty",
        "Mayukha Pal"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.LG"
      ],
      "published": "2026-02-16 17:21:35+00:00",
      "link": "https://arxiv.org/pdf/2602.14939v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14938v1",
      "title": "Variance-Reduced $(\\varepsilon,δ)-$Unlearning using Forget Set Gradients",
      "abstract": "In machine unlearning, $(\\varepsilon,δ)-$unlearning is a popular framework that provides formal guarantees on the effectiveness of the removal of a subset of training data, the forget set, from a trained model. For strongly convex objectives, existing first-order methods achieve $(\\varepsilon,δ)-$unlearning, but they only use the forget set to calibrate injected noise, never as a direct optimization signal. In contrast, efficient empirical heuristics often exploit the forget samples (e.g., via gradient ascent) but come with no formal unlearning guarantees. We bridge this gap by presenting the Variance-Reduced Unlearning (VRU) algorithm. To the best of our knowledge, VRU is the first first-order algorithm that directly includes forget set gradients in its update rule, while provably satisfying ($(\\varepsilon,δ)-$unlearning. We establish the convergence of VRU and show that incorporating the forget set yields strictly improved rates, i.e. a better dependence on the achieved error compared to existing first-order $(\\varepsilon,δ)-$unlearning methods. Moreover, we prove that, in a low-error regime, VRU asymptotically outperforms any first-order method that ignores the forget set.Experiments corroborate our theory, showing consistent gains over both state-of-the-art certified unlearning methods and over empirical baselines that explicitly leverage the forget set.",
      "authors": [
        "Martin Van Waerebeke",
        "Marco Lorenzi",
        "Kevin Scaman",
        "El Mahdi El Mhamdi",
        "Giovanni Neglia"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-02-16 17:20:14+00:00",
      "link": "https://arxiv.org/pdf/2602.14938v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14934v1",
      "title": "Activation-Space Uncertainty Quantification for Pretrained Networks",
      "abstract": "Reliable uncertainty estimates are crucial for deploying pretrained models; yet, many strong methods for quantifying uncertainty require retraining, Monte Carlo sampling, or expensive second-order computations and may alter a frozen backbone's predictions. To address this, we introduce Gaussian Process Activations (GAPA), a post-hoc method that shifts Bayesian modeling from weights to activations. GAPA replaces standard nonlinearities with Gaussian-process activations whose posterior mean exactly matches the original activation, preserving the backbone's point predictions by construction while providing closed-form epistemic variances in activation space. To scale to modern architectures, we use a sparse variational inducing-point approximation over cached training activations, combined with local k-nearest-neighbor subset conditioning, enabling deterministic single-pass uncertainty propagation without sampling, backpropagation, or second-order information. Across regression, classification, image segmentation, and language modeling, GAPA matches or outperforms strong post-hoc baselines in calibration and out-of-distribution detection while remaining efficient at test time.",
      "authors": [
        "Richard Bergna",
        "Stefan Depeweg",
        "Sergio Calvo-Ordoñez",
        "Jonathan Plenk",
        "Alvaro Cartea",
        "Jose Miguel Hernández-Lobato"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-16 17:17:08+00:00",
      "link": "https://arxiv.org/pdf/2602.14934v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14929v1",
      "title": "Wrivinder: Towards Spatial Intelligence for Geo-locating Ground Images onto Satellite Imagery",
      "abstract": "Aligning ground-level imagery with geo-registered satellite maps is crucial for mapping, navigation, and situational awareness, yet remains challenging under large viewpoint gaps or when GPS is unreliable. We introduce Wrivinder, a zero-shot, geometry-driven framework that aggregates multiple ground photographs to reconstruct a consistent 3D scene and align it with overhead satellite imagery. Wrivinder combines SfM reconstruction, 3D Gaussian Splatting, semantic grounding, and monocular depth--based metric cues to produce a stable zenith-view rendering that can be directly matched to satellite context for metrically accurate camera geo-localization. To support systematic evaluation of this task, which lacks suitable benchmarks, we also release MC-Sat, a curated dataset linking multi-view ground imagery with geo-registered satellite tiles across diverse outdoor environments. Together, Wrivinder and MC-Sat provide a first comprehensive baseline and testbed for studying geometry-centered cross-view alignment without paired supervision. In zero-shot experiments, Wrivinder achieves sub-30\\,m geolocation accuracy across both dense and large-area scenes, highlighting the promise of geometry-based aggregation for robust ground-to-satellite localization.",
      "authors": [
        "Chandrakanth Gudavalli",
        "Tajuddin Manhar Mohammed",
        "Abhay Yadav",
        "Ananth Vishnu Bhaskar",
        "Hardik Prajapati",
        "Cheng Peng",
        "Rama Chellappa",
        "Shivkumar Chandrasekaran",
        "B. S. Manjunath"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 17:06:54+00:00",
      "link": "https://arxiv.org/pdf/2602.14929v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14928v1",
      "title": "From Classical to Quantum: Extending Prometheus for Unsupervised Discovery of Phase Transitions in Three Dimensions and Quantum Systems",
      "abstract": "We extend the Prometheus framework for unsupervised phase transition discovery from 2D classical systems to 3D classical and quantum many-body systems, addressing scalability in higher dimensions and generalization to quantum fluctuations. For the 3D Ising model ($L \\leq 32$), the framework detects the critical temperature within 0.01\\% of literature values ($T_c/J = 4.511 \\pm 0.005$) and extracts critical exponents with $\\geq 70\\%$ accuracy ($β= 0.328 \\pm 0.015$, $γ= 1.24 \\pm 0.06$, $ν= 0.632 \\pm 0.025$), correctly identifying the 3D Ising universality class via $χ^2$ comparison ($p = 0.72$) without analytical guidance. For quantum systems, we developed quantum-aware VAE (Q-VAE) architectures using complex-valued wavefunctions and fidelity-based loss. Applied to the transverse field Ising model, we achieve 2\\% accuracy in quantum critical point detection ($h_c/J = 1.00 \\pm 0.02$) and successfully discover ground state magnetization as the order parameter ($r = 0.97$). Notably, for the disordered transverse field Ising model, we detect exotic infinite-randomness criticality characterized by activated dynamical scaling $\\ln ξ\\sim |h - h_c|^{-ψ}$, extracting a tunneling exponent $ψ= 0.48 \\pm 0.08$ consistent with theoretical predictions ($ψ= 0.5$). This demonstrates that unsupervised learning can identify qualitatively different types of critical behavior, not just locate critical points. Our systematic validation across classical thermal transitions ($T = 0$ to $T > 0$) and quantum phase transitions ($T = 0$, varying $h$) establishes that VAE-based discovery generalizes across fundamentally different physical domains, providing robust tools for exploring phase diagrams where analytical solutions are unavailable.",
      "authors": [
        "Brandon Yee",
        "Wilson Collins",
        "Maximilian Rutkowski"
      ],
      "primary_category": "cond-mat.dis-nn",
      "categories": [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.LG"
      ],
      "published": "2026-02-16 17:06:20+00:00",
      "link": "https://arxiv.org/pdf/2602.14928v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14926v1",
      "title": "MAC-AMP: A Closed-Loop Multi-Agent Collaboration System for Multi-Objective Antimicrobial Peptide Design",
      "abstract": "To address the global health threat of antimicrobial resistance, antimicrobial peptides (AMP) are being explored for their potent and promising ability to fight resistant pathogens. While artificial intelligence (AI) is being employed to advance AMP discovery and design, most AMP design models struggle to balance key goals like activity, toxicity, and novelty, using rigid or unclear scoring methods that make results hard to interpret and optimize. As the capabilities of Large Language Models (LLM) advance and evolve swiftly, we turn to AI multi-agent collaboration based on such models (multi-agent LLMs), which show rapidly rising potential in complex scientific design scenarios. Based on this, we introduce MAC-AMP, a closed-loop multi-agent collaboration (MAC) system for multi-objective AMP design. The system implements a fully autonomous simulated peer review-adaptive reinforcement learning framework that requires only a task description and example dataset to design novel AMPs. The novelty of our work lies in introducing a closed-loop multi-agent system for AMP design, with cross-domain transferability, that supports multi-objective optimization while remaining explainable rather than a 'black box'. Experiments show that MAC-AMP outperforms other AMP generative models by effectively optimizing AMP generation for multiple key molecular properties, demonstrating exceptional results in antibacterial activity, AMP likeliness, toxicity compliance, and structural reliability.",
      "authors": [
        "Gen Zhou",
        "Sugitha Janarthanan",
        "Lianghong Chen",
        "Pingzhao Hu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 17:01:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14926v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14922v1",
      "title": "ReusStdFlow: A Standardized Reusability Framework for Dynamic Workflow Construction in Agentic AI",
      "abstract": "To address the ``reusability dilemma'' and structural hallucinations in enterprise Agentic AI,this paper proposes ReusStdFlow, a framework centered on a novel ``Extraction-Storage-Construction'' paradigm. The framework deconstructs heterogeneous, platform-specific Domain Specific Languages (DSLs) into standardized, modular workflow segments. It employs a dual knowledge architecture-integrating graph and vector databases-to facilitate synergistic retrieval of both topological structures and functional semantics. Finally, workflows are intelligently assembled using a retrieval-augmented generation (RAG) strategy. Tested on 200 real-world n8n workflows, the system achieves over 90% accuracy in both extraction and construction. This framework provides a standardized solution for the automated reorganization and efficient reuse of enterprise digital assets.",
      "authors": [
        "Gaoyang Zhang",
        "Shanghong Zou",
        "Yafang Wang",
        "He Zhang",
        "Ruohua Xu",
        "Feng Zhao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "published": "2026-02-16 16:56:53+00:00",
      "link": "https://arxiv.org/pdf/2602.14922v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14919v1",
      "title": "BHyGNN+: Unsupervised Representation Learning for Heterophilic Hypergraphs",
      "abstract": "Hypergraph Neural Networks (HyGNNs) have demonstrated remarkable success in modeling higher-order relationships among entities. However, their performance often degrades on heterophilic hypergraphs, where nodes connected by the same hyperedge tend to have dissimilar semantic representations or belong to different classes. While several HyGNNs, including our prior work BHyGNN, have been proposed to address heterophily, their reliance on labeled data significantly limits their applicability in real-world scenarios where annotations are scarce or costly. To overcome this limitation, we introduce BHyGNN+, a self-supervised learning framework that extends BHyGNN for representation learning on heterophilic hypergraphs without requiring ground-truth labels. The core idea of BHyGNN+ is hypergraph duality, a structural transformation where the roles of nodes and hyperedges are interchanged. By contrasting augmented views of a hypergraph against its dual using cosine similarity, our framework captures essential structural patterns in a fully unsupervised manner. Notably, this duality-based formulation eliminates the need for negative samples, a common requirement in existing hypergraph contrastive learning methods that is often difficult to satisfy in practice. Extensive experiments on eleven benchmark datasets demonstrate that BHyGNN+ consistently outperforms state-of-the-art supervised and self-supervised baselines on both heterophilic and homophilic hypergraphs. Our results validate the effectiveness of leveraging hypergraph duality for self-supervised learning and establish a new paradigm for representation learning on challenging, unlabeled hypergraphs.",
      "authors": [
        "Tianyi Ma",
        "Yiyue Qian",
        "Zehong Wang",
        "Zheyuan Zhang",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-16 16:55:37+00:00",
      "link": "https://arxiv.org/pdf/2602.14919v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14917v1",
      "title": "BFS-PO: Best-First Search for Large Reasoning Models",
      "abstract": "Large Reasoning Models (LRMs) such as OpenAI o1 and DeepSeek-R1 have shown excellent performance in reasoning tasks using long reasoning chains. However, this has also led to a significant increase of computational costs and the generation of verbose output, a phenomenon known as overthinking. The tendency to overthinking is often exacerbated by Reinforcement Learning (RL) algorithms such as GRPO/DAPO. In this paper, we propose BFS-PO, an RL algorithm which alleviates this problem using a Best-First Search exploration strategy. Specifically, BFS-PO looks for the shortest correct answer using a backtracking mechanism based on maximum entropy nodes. By generating progressively shorter responses during training, BFS-PO learns to produce concise reasoning chains. Using different benchmarks and base LRMs, we show that BFS-PO can simultaneously increase the LRM accuracy and shorten its answers.",
      "authors": [
        "Fiorenzo Parascandolo",
        "Wenhui Tan",
        "Enver Sangineto",
        "Ruihua Song",
        "Rita Cucchiara"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-16 16:53:41+00:00",
      "link": "https://arxiv.org/pdf/2602.14917v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14915v1",
      "title": "The antiferromagnetic Ising model beyond line graphs",
      "abstract": "Both the antiferromagnetic Ising model and the hard-core model could be said to be tractable on line graphs of bounded degree. For example, Glauber dynamics is rapidly mixing in both cases. In the case of the hard-core model, we know that tractability extends further, to claw-free graphs and somewhat beyond. In contrast, it is shown here that the corresponding extensions are not possible in the case of the antiferromagnetic Ising model.",
      "authors": [
        "Mark Jerrum"
      ],
      "primary_category": "cs.CC",
      "categories": [
        "cs.CC",
        "math.CO",
        "math.PR"
      ],
      "published": "2026-02-16 16:50:16+00:00",
      "link": "https://arxiv.org/pdf/2602.14915v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14914v1",
      "title": "Additive Control Variates Dominate Self-Normalisation in Off-Policy Evaluation",
      "abstract": "Off-policy evaluation (OPE) is essential for assessing ranking and recommendation systems without costly online interventions. Self-Normalised Inverse Propensity Scoring (SNIPS) is a standard tool for variance reduction in OPE, leveraging a multiplicative control variate. Recent advances in off-policy learning suggest that additive control variates (baseline corrections) may offer superior performance, yet theoretical guarantees for evaluation are lacking. This paper provides a definitive answer: we prove that $β^\\star$-IPS, an estimator with an optimal additive baseline, asymptotically dominates SNIPS in Mean Squared Error. By analytically decomposing the variance gap, we show that SNIPS is asymptotically equivalent to using a specific -- but generally sub-optimal -- additive baseline. Our results theoretically justify shifting from self-normalisation to optimal baseline corrections for both ranking and recommendation.",
      "authors": [
        "Olivier Jeunen",
        "Shashank Gupta"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.IR"
      ],
      "published": "2026-02-16 16:49:23+00:00",
      "link": "https://arxiv.org/pdf/2602.14914v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14913v1",
      "title": "Coverage Guarantees for Pseudo-Calibrated Conformal Prediction under Distribution Shift",
      "abstract": "Conformal prediction (CP) offers distribution-free marginal coverage guarantees under an exchangeability assumption, but these guarantees can fail if the data distribution shifts. We analyze the use of pseudo-calibration as a tool to counter this performance loss under a bounded label-conditional covariate shift model. Using tools from domain adaptation, we derive a lower bound on target coverage in terms of the source-domain loss of the classifier and a Wasserstein measure of the shift. Using this result, we provide a method to design pseudo-calibrated sets that inflate the conformal threshold by a slack parameter to keep target coverage above a prescribed level. Finally, we propose a source-tuned pseudo-calibration algorithm that interpolates between hard pseudo-labels and randomized labels as a function of classifier uncertainty. Numerical experiments show that our bounds qualitatively track pseudo-calibration behavior and that the source-tuned scheme mitigates coverage degradation under distribution shift while maintaining nontrivial prediction set sizes.",
      "authors": [
        "Farbod Siahkali",
        "Ashwin Verma",
        "Vijay Gupta"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "eess.IV"
      ],
      "published": "2026-02-16 16:48:39+00:00",
      "link": "https://arxiv.org/pdf/2602.14913v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15090v1",
      "title": "The Agentic Automation Canvas: a structured framework for agentic AI project design",
      "abstract": "Agentic AI prototypes are being deployed across domains with increasing speed, yet no methodology for their structured design, governance, and prospective evaluation has been established. Existing AI documentation practices and guidelines - Model Cards, Datasheets, or NIST AI RMF - are either retrospective or lack machine-readability and interoperability. We present the Agentic Automation Canvas (AAC), a structured framework for the prospective design of agentic systems and a tool to facilitate communication between their users and developers. The AAC captures six dimensions of an automation project: definition and scope; user expectations with quantified benefit metrics; developer feasibility assessments; governance staging; data access and sensitivity; and outcomes. The framework is implemented as a semantic web-compatible metadata schema with controlled vocabulary and mappings to established ontologies such as Schema.org and W3C DCAT. It is made accessible through a privacy-preserving, fully client-side web application with real-time validation. Completed canvases export as FAIR-compliant RO-Crates, yielding versioned, shareable, and machine-interoperable project contracts between users and developers. We describe the schema design, benefit quantification model, and prospective application to diverse use cases from research, clinical, and institutional settings. The AAC and its web application are available as open-source code and interactive web form at https://aac.slolab.ai",
      "authors": [
        "Sebastian Lobentanzer"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-16 16:46:04+00:00",
      "link": "https://arxiv.org/pdf/2602.15090v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14910v1",
      "title": "Position: Introspective Experience from Conversational Environments as a Path to Better Learning",
      "abstract": "Current approaches to AI training treat reasoning as an emergent property of scale. We argue instead that robust reasoning emerges from linguistic self-reflection, itself internalized from high-quality social interaction. Drawing on Vygotskian developmental psychology, we advance three core positions centered on Introspection. First, we argue for the Social Genesis of the Private Mind: learning from conversational environments rises to prominence as a new way to make sense of the world; the friction of aligning with another agent, internal or not, refines and crystallizes the reasoning process. Second, we argue that dialogically scaffolded introspective experiences allow agents to engage in sense-making that decouples learning from immediate data streams, transforming raw environmental data into rich, learnable narratives. Finally, we contend that Dialogue Quality is the New Data Quality: the depth of an agent's private reasoning, and its efficiency regarding test-time compute, is determined by the diversity and rigor of the dialogues it has mastered. We conclude that optimizing these conversational scaffolds is the primary lever for the next generation of general intelligence.",
      "authors": [
        "Claudiu Cristian Musat",
        "Jackson Tolins",
        "Diego Antognini",
        "Jingling Li",
        "Martin Klissarov",
        "Tom Duerig"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 16:45:43+00:00",
      "link": "https://arxiv.org/pdf/2602.14910v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14907v2",
      "title": "Adjoint-based shape optimization of a ship hull using a Conditional Variational Autoencoder (CVAE) assisted propulsion surrogate model",
      "abstract": "Adjoint-based shape optimization of ship hulls is a powerful tool for addressing high-dimensional design problems in naval architecture, particularly in minimizing the ship resistance. However, its application to vessels that employ complex propulsion systems introduces significant challenges. They arise from the need for transient simulations extending over long periods of time with small time steps and from the reverse temporal propagation of the primal and adjoint solutions. These challenges place considerable demands on the required storage and computing power, which significantly hamper the use of adjoint methods in the industry. To address this issue, we propose a machine learning-assisted optimization framework that employs a Conditional Variational Autoencoder-based surrogate model of the propulsion system. The surrogate model replicates the time-averaged flow field induced by a Voith Schneider Propeller and replaces the geometrically and time-resolved propeller with a data-driven approximation. Primal flow verification examples demonstrate that the surrogate model achieves significant computational savings while maintaining the necessary accuracy of the resolved propeller. Optimization studies show that ignoring the propulsion system can yield designs that perform worse than the initial shape. In contrast, the proposed method produces shapes that achieve more than an 8\\% reduction in resistance.",
      "authors": [
        "Moloud Arian Maram",
        "Georgios Bletsos",
        "Thanh Tung Nguyen",
        "Ahmed Hassan",
        "Michael Palm",
        "Thomas Rung"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "cs.LG"
      ],
      "published": "2026-02-16 16:43:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14907v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14904v1",
      "title": "Colimit-Based Composition of High-Level Computing Devices",
      "abstract": "Models of High-level Computation (MHCs) provide effective means to describe complex real-world computing systems because they offer formal foundations for the specification of interacting computing devices, as opposed to describing individual ones, which has been the focus of classical models such as Turing machines or the lambda calculus. Despite numerous proposals over the past half century, there is still no canonical MHC akin to Turing machines for (compositionally) reasoning about computation in the large. One of the major drawbacks of current MHCs is that they extensively neglect control flow, a well-know semantic property that defines computation order. Only a few MHCs treat control explicitly at the expense of assuming that data follows control. Mixing such dimensions within the same framework leads to inefficient methods for formal analysis and verification. To address this, the computon model has recently emerged as a category-theoretic MHC that separates data and control and makes control explicit by supporting composition operators characterised as finite colimit constructions. Such constructions allow the formation of sequential, parallel, branching and iterative computing devices. Unfortunately, the computon model is still a generic reference rather than a concrete realisation. In this paper, we provide a variation of it to enable functional computing devices, introduce a new branching operator, discuss how to define synchronous parallelising out of sequencing and asynchronous parallelising, describe concrete operational semantics for computon execution and provide the first implementation of the model. The implementation yields an open-source programming environment that realises the underlying categorical semantics. This tool is publicly available and ready to build complex computing devices that are structurally correct by construction.",
      "authors": [
        "Damian Arellanes"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-02-16 16:39:23+00:00",
      "link": "https://arxiv.org/pdf/2602.14904v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14903v1",
      "title": "The Potential of CoT for Reasoning: A Closer Look at Trace Dynamics",
      "abstract": "Chain-of-thought (CoT) prompting is a de-facto standard technique to elicit reasoning-like responses from large language models (LLMs), allowing them to spell out individual steps before giving a final answer. While the resemblance to human-like reasoning is undeniable, the driving forces underpinning the success of CoT reasoning still remain largely unclear. In this work, we perform an in-depth analysis of CoT traces originating from competition-level mathematics questions, with the aim of better understanding how, and which parts of CoT actually contribute to the final answer. To this end, we introduce the notion of a potential, quantifying how much a given part of CoT increases the likelihood of a correct completion. Upon examination of reasoning traces through the lens of the potential, we identify surprising patterns including (1) its often strong non-monotonicity (due to reasoning tangents), (2) very sharp but sometimes tough to interpret spikes (reasoning insights and jumps) as well as (3) at times lucky guesses, where the model arrives at the correct answer without providing any relevant justifications before. While some of the behaviours of the potential are readily interpretable and align with human intuition (such as insights and tangents), others remain difficult to understand from a human perspective. To further quantify the reliance of LLMs on reasoning insights, we investigate the notion of CoT transferability, where we measure the potential of a weaker model under the partial CoT from another, stronger model. Indeed aligning with our previous results, we find that as little as 20% of partial CoT can ``unlock'' the performance of the weaker model on problems that were previously unsolvable for it, highlighting that a large part of the mechanics underpinning CoT are transferable.",
      "authors": [
        "Gregor Bachmann",
        "Yichen Jiang",
        "Seyed Mohsen Moosavi Dezfooli",
        "Moin Nabi"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 16:38:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14903v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14901v1",
      "title": "Picking the Right Specialist: Attentive Neural Process-based Selection of Task-Specialized Models as Tools for Agentic Healthcare Systems",
      "abstract": "Task-specialized models form the backbone of agentic healthcare systems, enabling the agents to answer clinical queries across tasks such as disease diagnosis, localization, and report generation. Yet, for a given task, a single \"best\" model rarely exists. In practice, each task is better served by multiple competing specialist models where different models excel on different data samples. As a result, for any given query, agents must reliably select the right specialist model from a heterogeneous pool of tool candidates. To this end, we introduce ToolSelect, which adaptively learns model selection for tools by minimizing a population risk over sampled specialist tool candidates using a consistent surrogate of the task-conditional selection loss. Concretely, we propose an Attentive Neural Process-based selector conditioned on the query and per-model behavioral summaries to choose among the specialist models. Motivated by the absence of any established testbed, we, for the first time, introduce an agentic Chest X-ray environment equipped with a diverse suite of task-specialized models (17 disease detection, 19 report generation, 6 visual grounding, and 13 VQA) and develop ToolSelectBench, a benchmark of 1448 queries. Our results demonstrate that ToolSelect consistently outperforms 10 SOTA methods across four different task families.",
      "authors": [
        "Pramit Saha",
        "Joshua Strong",
        "Mohammad Alsharid",
        "Divyanshu Mishra",
        "J. Alison Noble"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.MA"
      ],
      "published": "2026-02-16 16:36:32+00:00",
      "link": "https://arxiv.org/pdf/2602.14901v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14896v1",
      "title": "Algorithmic Simplification of Neural Networks with Mosaic-of-Motifs",
      "abstract": "Large-scale deep learning models are well-suited for compression. Methods like pruning, quantization, and knowledge distillation have been used to achieve massive reductions in the number of model parameters, with marginal performance drops across a variety of architectures and tasks. This raises the central question: \\emph{Why are deep neural networks suited for compression?} In this work, we take up the perspective of algorithmic complexity to explain this behavior. We hypothesize that the parameters of trained models have more structure and, hence, exhibit lower algorithmic complexity compared to the weights at (random) initialization. Furthermore, that model compression methods harness this reduced algorithmic complexity to compress models. Although an unconstrained parameterization of model weights, $\\mathbf{w} \\in \\mathbb{R}^n$, can represent arbitrary weight assignments, the solutions found during training exhibit repeatability and structure, making them algorithmically simpler than a generic program. To this end, we formalize the Kolmogorov complexity of $\\mathbf{w}$ by $\\mathcal{K}(\\mathbf{w})$. We introduce a constrained parameterization $\\widehat{\\mathbf{w}}$, that partitions parameters into blocks of size $s$, and restricts each block to be selected from a set of $k$ reusable motifs, specified by a reuse pattern (or mosaic). The resulting method, $\\textit{Mosaic-of-Motifs}$ (MoMos), yields algorithmically simpler model parameterization compared to unconstrained models. Empirical evidence from multiple experiments shows that the algorithmic complexity of neural networks, measured using approximations to Kolmogorov complexity, can be reduced during training. This results in models that perform comparably with unconstrained models while being algorithmically simpler.",
      "authors": [
        "Pedram Bakhtiarifard",
        "Tong Chen",
        "Jonathan Wenshøj",
        "Erik B Dam",
        "Raghavendra Selvan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 16:30:38+00:00",
      "link": "https://arxiv.org/pdf/2602.14896v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14890v1",
      "title": "Lifted Relational Probabilistic Inference via Implicit Learning",
      "abstract": "Reconciling the tension between inductive learning and deductive reasoning in first-order relational domains is a longstanding challenge in AI. We study the problem of answering queries in a first-order relational probabilistic logic through a joint effort of learning and reasoning, without ever constructing an explicit model. Traditional lifted inference assumes access to a complete model and exploits symmetry to evaluate probabilistic queries; however, learning such models from partial, noisy observations is intractable in general. We reconcile these two challenges through implicit learning to reason and first-order relational probabilistic inference techniques. More specifically, we merge incomplete first-order axioms with independently sampled, partially observed examples into a bounded-degree fragment of the sum-of-squares (SOS) hierarchy in polynomial time. Our algorithm performs two lifts simultaneously: (i) grounding-lift, where renaming-equivalent ground moments share one variable, collapsing the domain of individuals; and (ii) world-lift, where all pseudo-models (partial world assignments) are enforced in parallel, producing a global bound that holds across all worlds consistent with the learned constraints. These innovations yield the first polynomial-time framework that implicitly learns a first-order probabilistic logic and performs lifted inference over both individuals and worlds.",
      "authors": [
        "Luise Ge",
        "Brendan Juba",
        "Kris Nilsson",
        "Alison Shao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 16:24:13+00:00",
      "link": "https://arxiv.org/pdf/2602.14890v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14889v1",
      "title": "Web-Scale Multimodal Summarization using CLIP-Based Semantic Alignment",
      "abstract": "We introduce Web-Scale Multimodal Summarization, a lightweight framework for generating summaries by combining retrieved text and image data from web sources. Given a user-defined topic, the system performs parallel web, news, and image searches. Retrieved images are ranked using a fine-tuned CLIP model to measure semantic alignment with topic and text. Optional BLIP captioning enables image-only summaries for stronger multimodal coherence.The pipeline supports features such as adjustable fetch limits, semantic filtering, summary styling, and downloading structured outputs. We expose the system via a Gradio-based API with controllable parameters and preconfigured presets.Evaluation on 500 image-caption pairs with 20:1 contrastive negatives yields a ROC-AUC of 0.9270, an F1-score of 0.6504, and an accuracy of 96.99%, demonstrating strong multimodal alignment. This work provides a configurable, deployable tool for web-scale summarization that integrates language, retrieval, and vision models in a user-extensible pipeline.",
      "authors": [
        "Mounvik K",
        "N Harshit"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV",
        "cs.ET",
        "cs.HC",
        "cs.NE"
      ],
      "published": "2026-02-16 16:20:37+00:00",
      "link": "https://arxiv.org/pdf/2602.14889v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14885v1",
      "title": "Drift-Diffusion Matching: Embedding dynamics in latent manifolds of asymmetric neural networks",
      "abstract": "Recurrent neural networks (RNNs) provide a theoretical framework for understanding computation in biological neural circuits, yet classical results, such as Hopfield's model of associative memory, rely on symmetric connectivity that restricts network dynamics to gradient-like flows. In contrast, biological networks support rich time-dependent behaviour facilitated by their asymmetry. Here we introduce a general framework, which we term drift-diffusion matching, for training continuous-time RNNs to represent arbitrary stochastic dynamical systems within a low-dimensional latent subspace. Allowing asymmetric connectivity, we show that RNNs can faithfully embed the drift and diffusion of a given stochastic differential equation, including nonlinear and nonequilibrium dynamics such as chaotic attractors. As an application, we construct RNN realisations of stochastic systems that transiently explore various attractors through both input-driven switching and autonomous transitions driven by nonequilibrium currents, which we interpret as models of associative and sequential (episodic) memory. To elucidate how these dynamics are encoded in the network, we introduce decompositions of the RNN based on its asymmetric connectivity and its time-irreversibility. Our results extend attractor neural network theory beyond equilibrium, showing that asymmetric neural populations can implement a broad class of dynamical computations within low-dimensional manifolds, unifying ideas from associative memory, nonequilibrium statistical mechanics, and neural computation.",
      "authors": [
        "Ramón Nartallo-Kaluarachchi",
        "Renaud Lambiotte",
        "Alain Goriely"
      ],
      "primary_category": "cond-mat.dis-nn",
      "categories": [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.LG",
        "q-bio.NC"
      ],
      "published": "2026-02-16 16:15:59+00:00",
      "link": "https://arxiv.org/pdf/2602.14885v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14881v1",
      "title": "Numerical exploration of the range of shape functionals using neural networks",
      "abstract": "We introduce a novel numerical framework for the exploration of Blaschke--Santaló diagrams, which are efficient tools characterizing the possible inequalities relating some given shape functionals. We introduce a parametrization of convex bodies in arbitrary dimensions using a specific invertible neural network architecture based on gauge functions, allowing an intrinsic conservation of the convexity of the sets during the shape optimization process. To achieve a uniform sampling inside the diagram, and thus a satisfying description of it, we introduce an interacting particle system that minimizes a Riesz energy functional via automatic differentiation in PyTorch. The effectiveness of the method is demonstrated on several diagrams involving both geometric and PDE-type functionals for convex bodies of $\\mathbb{R}^2$ and $\\mathbb{R}^3$, namely, the volume, the perimeter, the moment of inertia, the torsional rigidity, the Willmore energy, and the first two Neumann eigenvalues of the Laplacian.",
      "authors": [
        "Eloi Martinet",
        "Ilias Ftouhi"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "published": "2026-02-16 16:10:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14881v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14879v1",
      "title": "CT-Bench: A Benchmark for Multimodal Lesion Understanding in Computed Tomography",
      "abstract": "Artificial intelligence (AI) can automatically delineate lesions on computed tomography (CT) and generate radiology report content, yet progress is limited by the scarcity of publicly available CT datasets with lesion-level annotations. To bridge this gap, we introduce CT-Bench, a first-of-its-kind benchmark dataset comprising two components: a Lesion Image and Metadata Set containing 20,335 lesions from 7,795 CT studies with bounding boxes, descriptions, and size information, and a multitask visual question answering benchmark with 2,850 QA pairs covering lesion localization, description, size estimation, and attribute categorization. Hard negative examples are included to reflect real-world diagnostic challenges. We evaluate multiple state-of-the-art multimodal models, including vision-language and medical CLIP variants, by comparing their performance to radiologist assessments, demonstrating the value of CT-Bench as a comprehensive benchmark for lesion analysis. Moreover, fine-tuning models on the Lesion Image and Metadata Set yields significant performance gains across both components, underscoring the clinical utility of CT-Bench.",
      "authors": [
        "Qingqing Zhu",
        "Qiao Jin",
        "Tejas S. Mathai",
        "Yin Fang",
        "Zhizheng Wang",
        "Yifan Yang",
        "Maame Sarfo-Gyamfi",
        "Benjamin Hou",
        "Ran Gu",
        "Praveen T. S. Balamuralikrishna",
        "Kenneth C. Wang",
        "Ronald M. Summers",
        "Zhiyong Lu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-16 16:10:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14879v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14878v1",
      "title": "Model Context Protocol (MCP) Tool Descriptions Are Smelly! Towards Improving AI Agent Efficiency with Augmented MCP Tool Descriptions",
      "abstract": "The Model Context Protocol (MCP) standardizes how Foundation Model (FM)-based agents interact with external systems by invoking tools. However, to understand a tool's purpose and features, FMs rely on natural-language tool descriptions, making these descriptions a critical component in guiding FMs to select the optimal tool for a given (sub)task and to pass the right arguments to the tool. While defects or smells in these descriptions can misguide FM-based agents, their prevalence and consequences in the MCP ecosystem remain unclear.   To address this, we conduct the first large-scale empirical study of 856 tools spread across 103 MCP servers, assessing their description quality and their impact on agent performance. We identify six components of tool descriptions from the literature, develop a scoring rubric utilizing these components, then formalize tool description smells based on this rubric. By operationalizing this rubric through an FM-based scanner, we find that 97.1% of the analyzed tool descriptions contain at least one smell, with 56% failing to state their purpose clearly. While augmenting these descriptions for all components improves task success rates by a median of 5.85 percentage points and improves partial goal completion by 15.12%, it also increases the number of execution steps by 67.46% and regresses performance in 16.67% of cases. These findings highlight a trade-off between agent performance and cost, as well as the context sensitivity of the performance gain. Furthermore, component ablations show that compact variants of different component combinations often preserve behavioral reliability while reducing unnecessary token overhead, enabling more efficient use of the FM context window and lower execution costs.",
      "authors": [
        "Mohammed Mehedi Hasan",
        "Hao Li",
        "Gopi Krishnan Rajbahadur",
        "Bram Adams",
        "Ahmed E. Hassan"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.ET"
      ],
      "published": "2026-02-16 16:10:11+00:00",
      "link": "https://arxiv.org/pdf/2602.14878v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14874v1",
      "title": "Affordance Transfer Across Object Instances via Semantically Anchored Functional Map",
      "abstract": "Traditional learning from demonstration (LfD) generally demands a cumbersome collection of physical demonstrations, which can be time-consuming and challenging to scale. Recent advances show that robots can instead learn from human videos by extracting interaction cues without direct robot involvement. However, a fundamental challenge remains: how to generalize demonstrated interactions across different object instances that share similar functionality but vary significantly in geometry. In this work, we propose \\emph{Semantic Anchored Functional Maps} (SemFM), a framework for transferring affordances across objects from a single visual demonstration. Starting from a coarse mesh reconstructed from an image, our method identifies semantically corresponding functional regions between objects, selects mutually exclusive semantic anchors, and propagates these constraints over the surface using a functional map to obtain a dense, semantically consistent correspondence. This enables demonstrated interaction regions to be transferred across geometrically diverse objects in a lightweight and interpretable manner. Experiments on synthetic object categories and real-world robotic manipulation tasks show that our approach enables accurate affordance transfer with modest computational cost, making it well-suited for practical robotic perception-to-action pipelines.",
      "authors": [
        "Xiaoxiang Dong",
        "Weiming Zhi"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-16 16:04:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14874v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14872v1",
      "title": "On the Learning Dynamics of RLVR at the Edge of Competence",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has been a main driver of recent breakthroughs in large reasoning models. Yet it remains a mystery how rewards based solely on final outcomes can help overcome the long-horizon barrier to extended reasoning. To understand this, we develop a theory of the training dynamics of RL for transformers on compositional reasoning tasks. Our theory characterizes how the effectiveness of RLVR is governed by the smoothness of the difficulty spectrum. When data contains abrupt discontinuities in difficulty, learning undergoes grokking-type phase transitions, producing prolonged plateaus before progress recurs. In contrast, a smooth difficulty spectrum leads to a relay effect: persistent gradient signals on easier problems elevate the model's capabilities to the point where harder ones become tractable, resulting in steady and continuous improvement. Our theory explains how RLVR can improve performance at the edge of competence, and suggests that appropriately designed data mixtures can yield scalable gains. As a technical contribution, our analysis develops and adapts tools from Fourier analysis on finite groups to our setting. We validate the predicted mechanisms empirically via synthetic experiments.",
      "authors": [
        "Yu Huang",
        "Zixin Wen",
        "Yuejie Chi",
        "Yuting Wei",
        "Aarti Singh",
        "Yingbin Liang",
        "Yuxin Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "published": "2026-02-16 16:03:08+00:00",
      "link": "https://arxiv.org/pdf/2602.14872v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14871v1",
      "title": "interID -- An Ecosystem-agnostic Verifier-as-a-Service with OpenID Connect Bridge",
      "abstract": "Self-Sovereign Identity (SSI) enables user-controlled, cryptographically verifiable credentials. As EU regulations mandate EUDI Wallet acceptance by 2027, SSI adoption becomes a compliance necessity. However, each SSI Verifier exposes different APIs with distinct request parameters, response formats, and claim structures, requiring custom wrappers and dedicated infrastructure, contrasting with OpenID Connect (OIDC) where standardized protocols enable seamless integration.   interID is an ecosystem-agnostic platform unifying credential verification across Hyperledger Aries/Indy, EBSI, and EUDI ecosystems. We extend interID with an OIDC bridge providing Verifier-as-a-Service, enabling SSI verification through standard OIDC flows. Organizations receive ID Tokens with verified credential attributes without implementing Verifier-specific logic or deploying infrastructure. The multi-tenant architecture leverages Keycloak with strict tenant isolation. Key innovations include PKCE support, scope-to-proof-template mappings translating OIDC scopes into ecosystem-specific verification requests, and a security analysis identifying novel attack surfaces at the intersection of OIDC, SSI, and multi-tenant architectures, threats covered by neither RFC 6819 nor existing SSI analyses alone.   Our evaluation demonstrates security equivalence to production identity providers through threat modeling identifying 11 attack vectors, including seven beyond RFC 6819's scope. Integration analysis shows organizations can adopt SSI authentication with comparable effort to adding traditional federated providers. By combining familiar OIDC patterns with SaaS deployment, our work lowers integration and operational barriers, enabling regulatory compliance through configuration rather than custom development.",
      "authors": [
        "Hakan Yildiz",
        "Axel Küpper"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-16 16:02:51+00:00",
      "link": "https://arxiv.org/pdf/2602.14871v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14869v1",
      "title": "Concept Influence: Leveraging Interpretability to Improve Performance and Efficiency in Training Data Attribution",
      "abstract": "As large language models are increasingly trained and fine-tuned, practitioners need methods to identify which training data drive specific behaviors, particularly unintended ones. Training Data Attribution (TDA) methods address this by estimating datapoint influence. Existing approaches like influence functions are both computationally expensive and attribute based on single test examples, which can bias results toward syntactic rather than semantic similarity. To address these issues of scalability and influence to abstract behavior, we leverage interpretable structures within the model during the attribution. First, we introduce Concept Influence which attribute model behavior to semantic directions (such as linear probes or sparse autoencoder features) rather than individual test examples. Second, we show that simple probe-based attribution methods are first-order approximations of Concept Influence that achieve comparable performance while being over an order-of-magnitude faster. We empirically validate Concept Influence and approximations across emergent misalignment benchmarks and real post-training datasets, and demonstrate they achieve comparable performance to classical influence functions while being substantially more scalable. More broadly, we show that incorporating interpretable structure within traditional TDA pipelines can enable more scalable, explainable, and better control of model behavior through data.",
      "authors": [
        "Matthew Kowal",
        "Goncalo Paulo",
        "Louis Jaburi",
        "Tom Tseng",
        "Lev E McKinney",
        "Stefan Heimersheim",
        "Aaron David Tucker",
        "Adam Gleave",
        "Kellin Pelrine"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-02-16 16:02:09+00:00",
      "link": "https://arxiv.org/pdf/2602.14869v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14868v1",
      "title": "Goldilocks RL: Tuning Task Difficulty to Escape Sparse Rewards for Reasoning",
      "abstract": "Reinforcement learning has emerged as a powerful paradigm for unlocking reasoning capabilities in large language models. However, relying on sparse rewards makes this process highly sample-inefficient, as models must navigate vast search spaces with minimal feedback. While classic curriculum learning aims to mitigate this by ordering data based on complexity, the right ordering for a specific model is often unclear. To address this, we propose Goldilocks, a novel teacher-driven data sampling strategy that aims to predict each question's difficulty for the student model. The teacher model selects questions of appropriate difficulty for the student model, i.e., questions that are neither too easy nor too hard (Goldilocks principle), while training the student with GRPO. By leveraging the student's performance on seen samples, the teacher continuously adapts to the student's evolving abilities. On OpenMathReasoning dataset, Goldilocks data sampling improves the performance of models trained with standard GRPO under the same compute budget.",
      "authors": [
        "Ilia Mahrooghi",
        "Aryo Lotfi",
        "Emmanuel Abbe"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-16 16:01:27+00:00",
      "link": "https://arxiv.org/pdf/2602.14868v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14867v1",
      "title": "Fast and accurate quasi-atom method for simultaneous atomistic and continuum simulation of solids",
      "abstract": "We report a novel hybrid method of simultaneous atomistic simulation of solids in critical regions (contacts surfaces, cracks areas, etc.), along with continuum modeling of other parts. The continuum is treated in terms of quasi-atoms of different size, comprising composite medium. The parameters of interaction potential between the quasi-atoms are optimized to match elastic properties of the composite medium to those of the atomic one. The optimization method coincides conceptually with the online Machine Learning (ML) methods, making it computationally very efficient. Such an approach allows a straightforward application of standard software packages for molecular dynamics (MD), supplemented by the ML-based optimizer. The new method is applied to model systems with a simple, pairwise Lennard-Jones potential, as well with multi-body Tersoff potential, describing covalent bonds. Using LAMMPS software we simulate collision of particles of different size. Comparing simulation results, obtained by the novel method, with full-atomic simulations, we demonstrate its accuracy, validity and overwhelming superiority in computational speed. Furthermore, we compare our method with other hybrid methods, specifically, with the closest one -- AtC (Atomic to Continuum) method. We demonstrate a significant superiority of our approach in computational speed and implementation convenience. Finally, we discuss a possible extension of the method for modeling other phenomena.",
      "authors": [
        "Artem Chuprov",
        "Egor E. Nuzhin",
        "Alexey A. Tsukanov",
        "Nikolay V. Brilliantov"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.LG"
      ],
      "published": "2026-02-16 16:00:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14867v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14865v1",
      "title": "EmbeWebAgent: Embedding Web Agents into Any Customized UI",
      "abstract": "Most web agents operate at the human interface level, observing screenshots or raw DOM trees without application-level access, which limits robustness and action expressiveness. In enterprise settings, however, explicit control of both the frontend and backend is available. We present EmbeWebAgent, a framework for embedding agents directly into existing UIs using lightweight frontend hooks (curated ARIA and URL-based observations, and a per-page function registry exposed via a WebSocket) and a reusable backend workflow that performs reasoning and takes actions. EmbeWebAgent is stack-agnostic (e.g., React or Angular), supports mixed-granularity actions ranging from GUI primitives to higher-level composites, and orchestrates navigation, manipulation, and domain-specific analytics via MCP tools. Our demo shows minimal retrofitting effort and robust multi-step behaviors grounded in a live UI setting. Live Demo: https://youtu.be/Cy06Ljee1JQ",
      "authors": [
        "Chenyang Ma",
        "Clyde Fare",
        "Matthew Wilson",
        "Dave Braines"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "published": "2026-02-16 15:59:56+00:00",
      "link": "https://arxiv.org/pdf/2602.14865v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14862v1",
      "title": "The Well-Tempered Classifier: Some Elementary Properties of Temperature Scaling",
      "abstract": "Temperature scaling is a simple method that allows to control the uncertainty of probabilistic models. It is mostly used in two contexts: improving the calibration of classifiers and tuning the stochasticity of large language models (LLMs). In both cases, temperature scaling is the most popular method for the job. Despite its popularity, a rigorous theoretical analysis of the properties of temperature scaling has remained elusive. We investigate here some of these properties. For classification, we show that increasing the temperature increases the uncertainty in the model in a very general sense (and in particular increases its entropy). However, for LLMs, we challenge the common claim that increasing temperature increases diversity. Furthermore, we introduce two new characterisations of temperature scaling. The first one is geometric: the tempered model is shown to be the information projection of the original model onto the set of models with a given entropy. The second characterisation clarifies the role of temperature scaling as a submodel of more general linear scalers such as matrix scaling and Dirichlet calibration: we show that temperature scaling is the only linear scaler that does not change the hard predictions of the model.",
      "authors": [
        "Pierre-Alexandre Mattei",
        "Bruno Loureiro"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "stat.ME"
      ],
      "published": "2026-02-16 15:54:52+00:00",
      "link": "https://arxiv.org/pdf/2602.14862v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14859v1",
      "title": "An improvement on the bound for the acyclic chromatic index",
      "abstract": "The acyclic chromatic index (or acyclic edge-chromatic number) of a graph is the least number of colors needed to properly color its edges so that none of its cycles has only two colors. We show that for a graph of max degree $Δ$, the acyclic chromatic index is at most $3.142(Δ-1)+1$, improving on the (best to date) bound of Fialho et al. (2020). Our improvement is made possible by considering unordered (non-plane) trees, instead of ordered (plane) ones, as witness structures for the Lovász Local Lemma, a key combinatorial tool often used in related works. The counting of these witness structures entails methods of Analytic Combinatorics.",
      "authors": [
        "Lefteris Kirousis",
        "John Livieratos",
        "Alexandros Singh"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.DM"
      ],
      "published": "2026-02-16 15:53:07+00:00",
      "link": "https://arxiv.org/pdf/2602.14859v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14858v1",
      "title": "Thermal Min-Max Games: Unifying Bounded Rationality and Typical-Case Equilibrium",
      "abstract": "Strategic-form min-max game theory examines the existence, multiplicity, selection of equilibria, and the worst-case computational complexity under perfect rationality. However, in many applications, games are drawn from an ensemble, and players exhibit bounded rationality. We introduce thermal min-max games, a thermodynamic relaxation that unifies bounded and perfect rationality by assigning each player a temperature to regulate their rationality level. To analyze typical behavior in the large-strategy limit, we develop a nested replica framework for this relaxation. This theory provides tractable predictions for typical equilibrium values and mixed-strategy statistics as functions of rationality strength, strategy-count aspect ratio, and payoff randomness. Numerical experiments demonstrate that these asymptotic predictions accurately align with the equilibrium of finite games of moderate size.",
      "authors": [
        "Yuma Ichikawa"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT",
        "cond-mat.dis-nn"
      ],
      "published": "2026-02-16 15:52:39+00:00",
      "link": "https://arxiv.org/pdf/2602.14858v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14857v1",
      "title": "World Models for Policy Refinement in StarCraft II",
      "abstract": "Large Language Models (LLMs) have recently shown strong reasoning and generalization capabilities, motivating their use as decision-making policies in complex environments. StarCraft II (SC2), with its massive state-action space and partial observability, is a challenging testbed. However, existing LLM-based SC2 agents primarily focus on improving the policy itself and overlook integrating a learnable, action-conditioned transition model into the decision loop. To bridge this gap, we propose StarWM, the first world model for SC2 that predicts future observations under partial observability. To facilitate learning SC2's hybrid dynamics, we introduce a structured textual representation that factorizes observations into five semantic modules, and construct SC2-Dynamics-50k, the first instruction-tuning dataset for SC2 dynamics prediction. We further develop a multi-dimensional offline evaluation framework for predicted structured observations. Offline results show StarWM's substantial gains over zero-shot baselines, including nearly 60% improvements in resource prediction accuracy and self-side macro-situation consistency. Finally, we propose StarWM-Agent, a world-model-augmented decision system that integrates StarWM into a Generate--Simulate--Refine decision loop for foresight-driven policy refinement. Online evaluation against SC2's built-in AI demonstrates consistent improvements, yielding win-rate gains of 30%, 15%, and 30% against Hard (LV5), Harder (LV6), and VeryHard (LV7), respectively, alongside improved macro-management stability and tactical risk assessment.",
      "authors": [
        "Yixin Zhang",
        "Ziyi Wang",
        "Yiming Rong",
        "Haoxi Wang",
        "Jinling Jiang",
        "Shuang Xu",
        "Haoran Wu",
        "Shiyu Zhou",
        "Bo Xu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 15:51:59+00:00",
      "link": "https://arxiv.org/pdf/2602.14857v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14855v1",
      "title": "A Pragmatic Method for Comparing Clusterings with Overlaps and Outliers",
      "abstract": "Clustering algorithms are an essential part of the unsupervised data science ecosystem, and extrinsic evaluation of clustering algorithms requires a method for comparing the detected clustering to a ground truth clustering. In a general setting, the detected and ground truth clusterings may have outliers (objects belonging to no cluster), overlapping clusters (objects may belong to more than one cluster), or both, but methods for comparing these clusterings are currently undeveloped. In this note, we define a pragmatic similarity measure for comparing clusterings with overlaps and outliers, show that it has several desirable properties, and experimentally confirm that it is not subject to several common biases afflicting other clustering comparison measures.",
      "authors": [
        "Ryan DeWolfe",
        "Paweł Prałat",
        "François Théberge"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.SI",
        "math.CO"
      ],
      "published": "2026-02-16 15:51:09+00:00",
      "link": "https://arxiv.org/pdf/2602.14855v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14853v1",
      "title": "BEACONS: Bounded-Error, Algebraically-Composable Neural Solvers for Partial Differential Equations",
      "abstract": "The traditional limitations of neural networks in reliably generalizing beyond the convex hulls of their training data present a significant problem for computational physics, in which one often wishes to solve PDEs in regimes far beyond anything which can be experimentally or analytically validated. In this paper, we show how it is possible to circumvent these limitations by constructing formally-verified neural network solvers for PDEs, with rigorous convergence, stability, and conservation properties, whose correctness can therefore be guaranteed even in extrapolatory regimes. By using the method of characteristics to predict the analytical properties of PDE solutions a priori (even in regions arbitrarily far from the training domain), we show how it is possible to construct rigorous extrapolatory bounds on the worst-case L^inf errors of shallow neural network approximations. Then, by decomposing PDE solutions into compositions of simpler functions, we show how it is possible to compose these shallow neural networks together to form deep architectures, based on ideas from compositional deep learning, in which the large L^inf errors in the approximations have been suppressed. The resulting framework, called BEACONS (Bounded-Error, Algebraically-COmposable Neural Solvers), comprises both an automatic code-generator for the neural solvers themselves, as well as a bespoke automated theorem-proving system for producing machine-checkable certificates of correctness. We apply the framework to a variety of linear and non-linear PDEs, including the linear advection and inviscid Burgers' equations, as well as the full compressible Euler equations, in both 1D and 2D, and illustrate how BEACONS architectures are able to extrapolate solutions far beyond the training data in a reliable and bounded way. Various advantages of the approach over the classical PINN approach are discussed.",
      "authors": [
        "Jonathan Gorard",
        "Ammar Hakim",
        "James Juno"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.NA",
        "physics.comp-ph"
      ],
      "published": "2026-02-16 15:49:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14853v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14852v1",
      "title": "Lower Estimates for $L_1$-Distortion of Transportation Cost Spaces",
      "abstract": "Quantifying the degree of dissimilarity between two probability distributions on a finite metric space is a fundamental task in Computer Science and Computer Vision. A natural dissimilarity measure based on optimal transport is the Earth Mover's Distance (EMD). A key technique for analyzing this metric, pioneered by Charikar (2002) and Indyk and Thaper (2003), involves constructing low-distortion embeddings of EMD(X) into the Lebesgue space $L_1$.   It became a key problem to investigate whether the upper bound of $O(\\log n)$ can be improved for important classes of metric spaces known to admit low-distortion embeddings into $L_1$. In the context of Computer Vision, grid graphs, especially planar grids, are among the most fundamental. Indyk posed the related problem of estimating the $L_1$-distortion of the space of uniform distributions on $n$-point subsets of $R^2$. The Progress Report, last updated in August 2011, highlighted two key results: first, the work of Khot and Naor (2006) on Hamming cubes, which showed that the $L_1$-distortion for Hamming cubes meets the described above upper estimate, and second, the result of Naor and Schechtman (2007) for planar grids, which established that the $L_1$-distortion of for a planar $n$ by $n$ grid is $Ω(\\sqrt{\\log n})$.   Our first result is the improvement of the lower bound on the $L_1$-distortion for grids to $Ω(\\log n)$, matching the universal upper bound up to multiplicative constants. The key ingredient allowing us to obtain these sharp estimates is a new Sobolev-type inequality for scalar-valued functions on the grid graphs. Our method is also applicable to many recursive families of graphs, such as diamond and Laakso graphs. We obtain the sharp distortion estimates of $\\log n$ in these cases as well.",
      "authors": [
        "Chris Gartland",
        "Mikhail Ostrovskii"
      ],
      "primary_category": "math.FA",
      "categories": [
        "math.FA",
        "cs.CG",
        "math.CO",
        "math.MG"
      ],
      "published": "2026-02-16 15:49:06+00:00",
      "link": "https://arxiv.org/pdf/2602.14852v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14850v1",
      "title": "Fair Allocation with Initial Utilities",
      "abstract": "The problem of allocating indivisible resources to agents arises in a wide range of domains, including treatment distribution and social support programs. An important goal in algorithm design for this problem is fairness, where the focus in previous work has been on ensuring that the computed allocation provides equal treatment to everyone. However, this perspective disregards that agents may start from unequal initial positions, which is crucial to consider in settings where fairness is understood as equality of outcome. In such settings, the goal is to create an equal final outcome for everyone by leveling initial inequalities through the allocated resources. To close this gap, focusing on agents with additive utilities, we extend the classic model by assigning each agent an initial utility and study the existence and computational complexity of several new fairness notions following the principle of equality of outcome. Among others, we show that complete allocations satisfying a direct analog of envy-freeness up to one resource (EF1) may fail to exist and are computationally hard to find, forming a contrast to the classic setting without initial utilities. We propose a new, always satisfiable fairness notion, called minimum-EF1-init and design a polynomial-time algorithm based on an extended round-robin procedure to compute complete allocations satisfying this notion.",
      "authors": [
        "Niclas Boehmer",
        "Luca Kreisel"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT"
      ],
      "published": "2026-02-16 15:47:49+00:00",
      "link": "https://arxiv.org/pdf/2602.14850v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14849v1",
      "title": "Atomix: Timely, Transactional Tool Use for Reliable Agentic Workflows",
      "abstract": "LLM agents increasingly act on external systems, yet tool effects are immediate. Under failures, speculation, or contention, losing branches can leak unintended side effects with no safe rollback. We introduce Atomix, a runtime that provides progress-aware transactional semantics for agent tool calls. Atomix tags each call with an epoch, tracks per-resource frontiers, and commits only when progress predicates indicate safety; bufferable effects can be delayed, while externalized effects are tracked and compensated on abort. Across real workloads with fault injection, transactional retry improves task success, while frontier-gated commit strengthens isolation under speculation and contention.",
      "authors": [
        "Bardia Mohammadi",
        "Nearchos Potamitis",
        "Lars Klein",
        "Akhil Arora",
        "Laurent Bindschaedler"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.MA"
      ],
      "published": "2026-02-16 15:46:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14849v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14846v1",
      "title": "Multi-dimensional Persistent Sheaf Laplacians for Image Analysis",
      "abstract": "We propose a multi-dimensional persistent sheaf Laplacian (MPSL) framework on simplicial complexes for image analysis. The proposed method is motivated by the strong sensitivity of commonly used dimensionality reduction techniques, such as principal component analysis (PCA), to the choice of reduced dimension. Rather than selecting a single reduced dimension or averaging results across dimensions, we exploit complementary advantages of multiple reduced dimensions. At a given dimension, image samples are regarded as simplicial complexes, and persistent sheaf Laplacians are utilized to extract a multiscale localized topological spectral representation for individual image samples. Statistical summaries of the resulting spectra are then aggregated across scales and dimensions to form multiscale multi-dimensional image representations. We evaluate the proposed framework on the COIL20 and ETH80 image datasets using standard classification protocols. Experimental results show that the proposed method provides more stable performance across a wide range of reduced dimensions and achieves consistent improvements to PCA-based baselines in moderate dimensional regimes.",
      "authors": [
        "Xiang Xiang Wang",
        "Guo-Wei Wei"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-16 15:44:31+00:00",
      "link": "https://arxiv.org/pdf/2602.14846v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14844v1",
      "title": "Interactionless Inverse Reinforcement Learning: A Data-Centric Framework for Durable Alignment",
      "abstract": "AI alignment is growing in importance, yet current approaches suffer from a critical structural flaw that entangles the safety objectives with the agent's policy. Methods such as Reinforcement Learning from Human Feedback and Direct Preference Optimization create opaque, single-use alignment artifacts, which we term Alignment Waste. We propose Interactionless Inverse Reinforcement Learning to decouple alignment artifact learning from policy optimization, producing an inspectable, editable, and model-agnostic reward model. Additionally, we introduce the Alignment Flywheel, a human-in-the-loop lifecycle that iteratively hardens the reward model through automated audits and refinement. This architecture transforms safety from a disposable expense into a durable, verifiable engineering asset.",
      "authors": [
        "Elias Malomgré",
        "Pieter Simoens"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 15:40:10+00:00",
      "link": "https://arxiv.org/pdf/2602.14844v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14837v1",
      "title": "Integrating Affordances and Attention models for Short-Term Object Interaction Anticipation",
      "abstract": "Short Term object-interaction Anticipation consists in detecting the location of the next active objects, the noun and verb categories of the interaction, as well as the time to contact from the observation of egocentric video. This ability is fundamental for wearable assistants to understand user goals and provide timely assistance, or to enable human-robot interaction. In this work, we present a method to improve the performance of STA predictions. Our contributions are two-fold: 1 We propose STAformer and STAformer plus plus, two novel attention-based architectures integrating frame-guided temporal pooling, dual image-video attention, and multiscale feature fusion to support STA predictions from an image-input video pair; 2 We introduce two novel modules to ground STA predictions on human behavior by modeling affordances. First, we integrate an environment affordance model which acts as a persistent memory of interactions that can take place in a given physical scene. We explore how to integrate environment affordances via simple late fusion and with an approach which adaptively learns how to best fuse affordances with end-to-end predictions. Second, we predict interaction hotspots from the observation of hands and object trajectories, increasing confidence in STA predictions localized around the hotspot. Our results show significant improvements on Overall Top-5 mAP, with gain up to +23p.p on Ego4D and +31p.p on a novel set of curated EPIC-Kitchens STA labels. We released the code, annotations, and pre-extracted affordances on Ego4D and EPIC-Kitchens to encourage future research in this area.",
      "authors": [
        "Lorenzo Mur Labadia",
        "Ruben Martinez-Cantin",
        "Jose J. Guerrero",
        "Giovanni M. Farinella",
        "Antonino Furnari"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 15:29:04+00:00",
      "link": "https://arxiv.org/pdf/2602.14837v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14835v1",
      "title": "The Global Representativeness Index: A Total Variation Distance Framework for Measuring Demographic Fidelity in Survey Research",
      "abstract": "Global survey research increasingly informs high-stakes decisions in AI governance and cross-cultural policy, yet no standardized metric quantifies how well a sample's demographic composition matches its target population. Response rates and demographic quotas -- the prevailing proxies for sample quality -- measure effort and coverage but not distributional fidelity. This paper introduces the Global Representativeness Index (GRI), a framework grounded in Total Variation Distance that scores any survey sample against population benchmarks across multiple demographic dimensions on a [0, 1] scale. Validation on seven waves of the Global Dialogues survey (N = 7,500 across 60+ countries) finds fine-grained demographic GRI scores of only 0.33--0.36 -- roughly 43% of the theoretical maximum at that sample size. Cross-validation on the World Values Survey (seven waves, N = 403,000), Afrobarometer Round 9 (N = 53,000), and Latinobarometro (N = 19,000) reveals that even large probability surveys score below 0.22 on fine-grained global demographics when country coverage is limited. The GRI connects to classical survey statistics through the design effect; both metrics are recommended as a minimum summary of sample quality, since GRI quantifies demographic distance symmetrically while effective N captures the asymmetric inferential cost of underrepresentation. The framework is released as an open-source Python library with UN and Pew Research Center population benchmarks, applicable to survey research, machine learning dataset auditing, and AI evaluation benchmarks.",
      "authors": [
        "Evan Hadfield"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "cs.CY",
        "stat.AP"
      ],
      "published": "2026-02-16 15:26:52+00:00",
      "link": "https://arxiv.org/pdf/2602.14835v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14834v1",
      "title": "Debiasing Central Fixation Confounds Reveals a Peripheral \"Sweet Spot\" for Human-like Scanpaths in Hard-Attention Vision",
      "abstract": "Human eye movements in visual recognition reflect a balance between foveal sampling and peripheral context. Task-driven hard-attention models for vision are often evaluated by how well their scanpaths match human gaze. However, common scanpath metrics can be strongly confounded by dataset-specific center bias, especially on object-centric datasets. Using Gaze-CIFAR-10, we show that a trivial center-fixation baseline achieves surprisingly strong scanpath scores, approaching many learned policies. This makes standard metrics optimistic and blurs the distinction between genuine behavioral alignment and mere central tendency. We then analyze a hard-attention classifier under constrained vision by sweeping foveal patch size and peripheral context, revealing a peripheral sweet spot: only a narrow range of sensory constraints yields scanpaths that are simultaneously (i) above the center baseline after debiasing and (ii) temporally human-like in movement statistics. To address center bias, we propose GCS (Gaze Consistency Score), a center-debiased composite metric augmented with movement similarity. GCS uncovers a robust sweet spot at medium patch size with both foveal and peripheral vision, that is not obvious from raw scanpath metrics or accuracy alone, and also highlights a \"shortcut regime\" when the field-of-view becomes too large. We discuss implications for evaluating active perception on object-centric datasets and for designing gaze benchmarks that better separate behavioral alignment from center bias.",
      "authors": [
        "Pengcheng Pan",
        "Yonekura Shogo",
        "Yasuo Kuniyosh"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-16 15:25:26+00:00",
      "link": "https://arxiv.org/pdf/2602.14834v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14833v1",
      "title": "RF-GPT: Teaching AI to See the Wireless World",
      "abstract": "Large language models (LLMs) and multimodal models have become powerful general-purpose reasoning systems. However, radio-frequency (RF) signals, which underpin wireless systems, are still not natively supported by these models. Existing LLM-based approaches for telecom focus mainly on text and structured data, while conventional RF deep-learning models are built separately for specific signal-processing tasks, highlighting a clear gap between RF perception and high-level reasoning. To bridge this gap, we introduce RF-GPT, a radio-frequency language model (RFLM) that utilizes the visual encoders of multimodal LLMs to process and understand RF spectrograms. In this framework, complex in-phase/quadrature (IQ) waveforms are mapped to time-frequency spectrograms and then passed to pretrained visual encoders. The resulting representations are injected as RF tokens into a decoder-only LLM, which generates RF-grounded answers, explanations, and structured outputs. To train RF-GPT, we perform supervised instruction fine-tuning of a pretrained multimodal LLM using a fully synthetic RF corpus. Standards-compliant waveform generators produce wideband scenes for six wireless technologies, from which we derive time-frequency spectrograms, exact configuration metadata, and dense captions. A text-only LLM then converts these captions into RF-grounded instruction-answer pairs, yielding roughly 12,000 RF scenes and 0.625 million instruction examples without any manual labeling. Across benchmarks for wideband modulation classification, overlap analysis, wireless-technology recognition, WLAN user counting, and 5G NR information extraction, RF-GPT achieves strong multi-task performance, whereas general-purpose VLMs with no RF grounding largely fail.",
      "authors": [
        "Hang Zou",
        "Yu Tian",
        "Bohao Wang",
        "Lina Bariah",
        "Samson Lasaulce",
        "Chongwen Huang",
        "Mérouane Debbah"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "cs.LG"
      ],
      "published": "2026-02-16 15:24:56+00:00",
      "link": "https://arxiv.org/pdf/2602.14833v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14832v1",
      "title": "Constructions of linear codes from vectorial plateaued functions and their subfield codes with applications to quantum CSS codes",
      "abstract": "Linear codes over finite fields parameterized by functions have proven to be a powerful tool in coding theory, yielding optimal and few-weight codes with significant applications in secret sharing, authentication codes, and association schemes. In 2023, Xu et al. introduced a construction framework for 3-dimensional linear codes parameterized by two functions, which has demonstrated considerable success in generating infinite families of optimal linear codes. Motivated by this approach, we propose a construction that extends the framework to three functions, thereby enhancing the flexibility of the parameters. Additionally, we introduce a vectorial setting by allowing vector-valued functions, expanding the construction space and the set of achievable structural properties. We analyze both scalar and vectorial frameworks, employing Bent and s-Plateaued functions, including Almost Bent, to define the code generators. By exploiting the properties of the Walsh transform, we determine the explicit parameters and weight distributions of these codes and their punctured versions. A key result of this study is that the constructed codes have few weights, and their duals are distance and dimensionally optimal with respect to both the Sphere Packing and Griesmer bounds. Furthermore, we establish a theoretical connection between our vectorial approach and the classical first generic construction of linear codes, providing sufficient conditions for the resulting codes to be minimal and self-orthogonal. Finally, we investigate applications to quantum coding theory within the Calderbank-Shor-Steane framework.",
      "authors": [
        "Virginio Fratianni",
        "Sihem Mesnager"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-02-16 15:23:22+00:00",
      "link": "https://arxiv.org/pdf/2602.14832v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14831v1",
      "title": "Robot-Wearable Conversation Hand-off for Navigation",
      "abstract": "Navigating large and complex indoor environments, such as universities, airports, and hospitals, can be cognitively demanding and requires attention and effort. While mobile applications provide convenient navigation support, they occupy the user's hands and visual attention, limiting natural interaction. In this paper, we explore conversation hand-off as a method for multi-device indoor navigation, where a Conversational Agent (CA) transitions seamlessly from a stationary social robot to a wearable device. We evaluated robot-only, wearable-only, and robot-to-wearable hand-off in a university campus setting using a within-subjects design with N=24 participants. We find that conversation hand-off is experienced as engaging, even though no performance benefits were observed, and most preferred using the wearable-only system. Our findings suggest that the design of such re-embodied assistants should maintain a shared voice and state across embodiments. We demonstrate how conversational hand-offs can bridge cognitive and physical transitions, enriching human interaction with embodied AI.",
      "authors": [
        "Dániel Szabó",
        "Aku Visuri",
        "Benjamin Tag",
        "Simo Hosio"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-16 15:22:16+00:00",
      "link": "https://arxiv.org/pdf/2602.14831v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14828v1",
      "title": "Exploring the limits of pre-trained embeddings in machine-guided protein design: a case study on predicting AAV vector viability",
      "abstract": "Effective representations of protein sequences are widely recognized as a cornerstone of machine learning-based protein design. Yet, protein bioengineering poses unique challenges for sequence representation, as experimental datasets typically feature few mutations, which are either sparsely distributed across the entire sequence or densely concentrated within localized regions. This limits the ability of sequence-level representations to extract functionally meaningful signals. In addition, comprehensive comparative studies remain scarce, despite their crucial role in clarifying which representations best encode relevant information and ultimately support superior predictive performance. In this study, we systematically evaluate multiple ProtBERT and ESM2 embedding variants as sequence representations, using the adeno-associated virus capsid as a case study and prototypical example of bioengineering, where functional optimization is targeted through highly localized sequence variation within an otherwise large protein. Our results reveal that, prior to fine-tuning, amino acid-level embeddings outperform sequence-level representations in supervised predictive tasks, whereas the latter tend to be more effective in unsupervised settings. However, optimal performance is only achieved when embeddings are fine-tuned with task-specific labels, with sequence-level representations providing the best performance. Moreover, our findings indicate that the extent of sequence variation required to produce notable shifts in sequence representations exceeds what is typically explored in bioengineering studies, showing the need for fine-tuning in datasets characterized by sparse or highly localized mutations.",
      "authors": [
        "Ana F. Rodrigues",
        "Lucas Ferraz",
        "Laura Balbi",
        "Pedro Giesteira Cotovio",
        "Catia Pesquita"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM",
        "cs.LG"
      ],
      "published": "2026-02-16 15:21:11+00:00",
      "link": "https://arxiv.org/pdf/2602.14828v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14819v1",
      "title": "Testimole-Conversational: A 30-Billion-Word Italian Discussion Board Corpus (1996-2024) for Language Modeling and Sociolinguistic Research",
      "abstract": "We present \"Testimole-conversational\" a massive collection of discussion boards messages in the Italian language. The large size of the corpus, more than 30B word-tokens (1996-2024), renders it an ideal dataset for native Italian Large Language Models'pre-training. Furthermore, discussion boards' messages are a relevant resource for linguistic as well as sociological analysis. The corpus captures a rich variety of computer-mediated communication, offering insights into informal written Italian, discourse dynamics, and online social interaction in wide time span. Beyond its relevance for NLP applications such as language modelling, domain adaptation, and conversational analysis, it also support investigations of language variation and social phenomena in digital communication. The resource will be made freely available to the research community.",
      "authors": [
        "Matteo Rinaldi",
        "Rossella Varvara",
        "Viviana Patti"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 15:12:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14819v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14815v1",
      "title": "Revenue Guarantees in Autobidding Platforms",
      "abstract": "Motivated by autobidding systems in online advertising, we study revenue maximization in markets with divisible goods and budget-constrained buyers with linear valuations. Our aim is to compute a single price for each good and an allocation that maximizes total revenue. We show that the First-Price Pacing Equilibrium (FPPE) guarantees at least half of the optimal revenue, even when compared to the maximal revenue of buyer-specific prices. This guarantee is particularly striking in light of our hardness result: we prove that revenue maximization under individual rationality and single-price-per-good constraints is APX-hard.   We further extend our analysis in two directions: first, we introduce an online analogue of FPPE and show that it achieves a constant-factor revenue guarantee, specifically a $1/4$-approximation; second, we consider buyers with concave valuation functions, characterizing an FPPE-type outcome as the solution to an Eisenberg-Gale-style convex program and showing that the revenue approximation degrades gracefully with the degree of nonlinearity of the valuations.",
      "authors": [
        "Ioannis Caragiannis",
        "Anders Bo Ipsen",
        "Stratis Skoulakis"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT"
      ],
      "published": "2026-02-16 15:09:16+00:00",
      "link": "https://arxiv.org/pdf/2602.14815v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14816v1",
      "title": "Majoritarian Assignment Rules",
      "abstract": "A central problem in multiagent systems is the fair assignment of objects to agents. In this paper, we initiate the analysis of classic majoritarian social choice functions in assignment. Exploiting the special structure of the assignment domain, we show a number of surprising results with no counterparts in general social choice. In particular, we establish a near one-to-one correspondence between preference profiles and majority graphs. This correspondence implies that key properties of assignments -- such as Pareto-optimality, least unpopularity, and mixed popularity -- can be determined solely by the associated majority graph. We further show that all Pareto-optimal assignments are semi-popular and belong to the top cycle. Elements of the top cycle can thus easily be found via serial dictatorships. Our main result is a complete characterization of the top cycle, which implies the top cycle can only consist of one, two, all but two, all but one, or all assignments. By contrast, we find that the uncovered set contains only very few assignments.",
      "authors": [
        "Felix Brandt",
        "Haoyuan Chen",
        "Chris Dong",
        "Patrick Lederer",
        "Alexander Schlenga"
      ],
      "primary_category": "econ.TH",
      "categories": [
        "econ.TH",
        "cs.GT"
      ],
      "published": "2026-02-16 15:09:16+00:00",
      "link": "https://arxiv.org/pdf/2602.14816v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14814v1",
      "title": "Learning State-Tracking from Code Using Linear RNNs",
      "abstract": "Over the last years, state-tracking tasks, particularly permutation composition, have become a testbed to understand the limits of sequence models architectures like Transformers and RNNs (linear and non-linear). However, these are often sequence-to-sequence tasks: learning to map actions (permutations) to states, which is incompatible with the next-token prediction setting commonly used to train language models. We address this gap by converting permutation composition into code via REPL traces that interleave state-reveals through prints and variable transformations. We show that linear RNNs capable of state-tracking excel also in this setting, while Transformers still fail. Motivated by this representation, we investigate why tracking states in code is generally difficult: actions are not always fully observable. We frame this as tracking the state of a probabilistic finite-state automaton with deterministic state reveals and show that linear RNNs can be worse than non-linear RNNs at tracking states in this setup.",
      "authors": [
        "Julien Siems",
        "Riccardo Grazzi",
        "Kirill Kalinin",
        "Hitesh Ballani",
        "Babak Rahmani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-16 15:07:51+00:00",
      "link": "https://arxiv.org/pdf/2602.14814v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14812v1",
      "title": "Physical Commonsense Reasoning for Lower-Resourced Languages and Dialects: a Study on Basque",
      "abstract": "Physical commonsense reasoning represents a fundamental capability of human intelligence, enabling individuals to understand their environment, predict future events, and navigate physical spaces. Recent years have witnessed growing interest in reasoning tasks within Natural Language Processing (NLP). However, no prior research has examined the performance of Large Language Models (LLMs) on non-question-answering (non-QA) physical commonsense reasoning tasks in low-resource languages such as Basque. Taking the Italian GITA as a starting point, this paper addresses this gap by presenting BasPhyCo, the first non-QA physical commonsense reasoning dataset for Basque, available in both standard and dialectal variants. We evaluate model performance across three hierarchical levels of commonsense understanding: (1) distinguishing between plausible and implausible narratives (accuracy), (2) identifying the conflicting element that renders a narrative implausible (consistency), and (3) determining the specific physical state that creates the implausibility (verifiability). These tasks were assessed using multiple multilingual LLMs as well as models pretrained specifically for Italian and Basque. Results indicate that, in terms of verifiability, LLMs exhibit limited physical commonsense capabilities in low-resource languages such as Basque, especially when processing dialectal variants.",
      "authors": [
        "Jaione Bengoetxea",
        "Itziar Gonzalez-Dios",
        "Rodrigo Agerri"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 15:04:35+00:00",
      "link": "https://arxiv.org/pdf/2602.14812v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15089v1",
      "title": "Hybrid Feature Learning with Time Series Embeddings for Equipment Anomaly Prediction",
      "abstract": "In predictive maintenance of equipment, deep learning-based time series anomaly detection has garnered significant attention; however, pure deep learning approaches often fail to achieve sufficient accuracy on real-world data. This study proposes a hybrid approach that integrates 64-dimensional time series embeddings from Granite TinyTimeMixer with 28-dimensional statistical features based on domain knowledge for HVAC equipment anomaly prediction tasks. Specifically, we combine time series embeddings extracted from a Granite TinyTimeMixer encoder fine-tuned with LoRA (Low-Rank Adaptation) and 28 types of statistical features including trend, volatility, and drawdown indicators, which are then learned using a LightGBM gradient boosting classifier. In experiments using 64 equipment units and 51,564 samples, we achieved Precision of 91--95\\% and ROC-AUC of 0.995 for anomaly prediction at 30-day, 60-day, and 90-day horizons. Furthermore, we achieved production-ready performance with a false positive rate of 1.1\\% or less and a detection rate of 88--94\\%, demonstrating the effectiveness of the system for predictive maintenance applications. This work demonstrates that practical anomaly detection systems can be realized by leveraging the complementary strengths between deep learning's representation learning capabilities and statistical feature engineering.",
      "authors": [
        "Takato Yasuno"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-16 15:00:15+00:00",
      "link": "https://arxiv.org/pdf/2602.15089v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14805v1",
      "title": "Center-Fed Pinching Antenna System (C-PASS): Modeling, Analysis, and Beamforming Design",
      "abstract": "A generalized framework for the novel center-fed pinching antenna system (C-PASS) is proposed. Within this framework, closed-form expressions for the degree of freedom (DoF) and power scaling law of the proposed C-PASS are first derived. These theoretical results reveal that the achievable DoF scales linearly with the number of input ports, $M$, and the number of receive antennas, $K$. Furthermore, the derived power scaling laws demonstrate that the C-PASS achieves a power gain of order $\\mathcal{O}(P_T M)$, where $P_T$ denotes the transmit power. Based on the proposed C-PASS modeling, a sum-rate maximization problem for the joint optimization of transmit and pinching beamforming is then formulated. To solve this highly coupled non-convex problem, an efficient alternating optimization algorithm is developed. More particularly, the transmit precoding and power splitting ratios are updated via derived closed-form solutions, while the pinching antenna positions and radiation coefficients are optimized using block coordinate descent (BCD) methods. Finally, our numerical results reveal that the single-waveguide C-PASS: 1) achieves superior DoF and power scaling laws compared to the single-waveguide PASS; and 2) outperforms the multi-waveguide PASS in high-attenuation regimes, yielding a substantial gain exceeding $10$ dB.",
      "authors": [
        "Xu Gan",
        "Yuanwei Liu"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-02-16 14:57:55+00:00",
      "link": "https://arxiv.org/pdf/2602.14805v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14799v1",
      "title": "Scalable Multi-Robot Path Planning via Quadratic Unconstrained Binary Optimization",
      "abstract": "Multi-Agent Path Finding (MAPF) remains a fundamental challenge in robotics, where classical centralized approaches exhibit exponential growth in joint-state complexity as the number of agents increases. This paper investigates Quadratic Unconstrained Binary Optimization (QUBO) as a structurally scalable alternative for simultaneous multi-robot path planning. This approach is a robotics-oriented QUBO formulation incorporating BFS-based logical pre-processing (achieving over 95% variable reduction), adaptive penalty design for collision and constraint enforcement, and a time-windowed decomposition strategy that enables execution within current hardware limitations. An experimental evaluation in grid environments with up to four robots demonstrated near-optimal solutions in dense scenarios and favorable scaling behavior compared to sequential classical planning. These results establish a practical and reproducible baseline for future quantum and quantum-inspired multi-robot coordinations.",
      "authors": [
        "Javier González Villasmil"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "quant-ph"
      ],
      "published": "2026-02-16 14:50:04+00:00",
      "link": "https://arxiv.org/pdf/2602.14799v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15909v1",
      "title": "Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis",
      "abstract": "Deep learning-based respiratory auscultation is currently hindered by two fundamental challenges: (i) inherent information loss, as converting signals into spectrograms discards transient acoustic events and clinical context; (ii) limited data availability, exacerbated by severe class imbalance. To bridge these gaps, we present Resp-Agent, an autonomous multimodal system orchestrated by a novel Active Adversarial Curriculum Agent (Thinker-A$^2$CA). Unlike static pipelines, Thinker-A$^2$CA serves as a central controller that actively identifies diagnostic weaknesses and schedules targeted synthesis in a closed loop. To address the representation gap, we introduce a Modality-Weaving Diagnoser that weaves EHR data with audio tokens via Strategic Global Attention and sparse audio anchors, capturing both long-range clinical context and millisecond-level transients. To address the data gap, we design a Flow Matching Generator that adapts a text-only Large Language Model (LLM) via modality injection, decoupling pathological content from acoustic style to synthesize hard-to-diagnose samples. As a foundation for these efforts, we introduce Resp-229k, a benchmark corpus of 229k recordings paired with LLM-distilled clinical narratives. Extensive experiments demonstrate that Resp-Agent consistently outperforms prior approaches across diverse evaluation settings, improving diagnostic robustness under data scarcity and long-tailed class imbalance. Our code and data are available at https://github.com/zpforlove/Resp-Agent.",
      "authors": [
        "Pengfei Zhang",
        "Tianxin Xie",
        "Minghao Yang",
        "Li Liu"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.DB",
        "cs.HC",
        "cs.MA",
        "cs.SD"
      ],
      "published": "2026-02-16 14:48:24+00:00",
      "link": "https://arxiv.org/pdf/2602.15909v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14798v1",
      "title": "Overthinking Loops in Agents: A Structural Risk via MCP Tools",
      "abstract": "Tool-using LLM agents increasingly coordinate real workloads by selecting and chaining third-party tools based on text-visible metadata such as tool names, descriptions, and return messages. We show that this convenience creates a supply-chain attack surface: a malicious MCP tool server can be co-registered alongside normal tools and induce overthinking loops, where individually trivial or plausible tool calls compose into cyclic trajectories that inflate end-to-end tokens and latency without any single step looking abnormal. We formalize this as a structural overthinking attack, distinguishable from token-level verbosity, and implement 14 malicious tools across three servers that trigger repetition, forced refinement, and distraction. Across heterogeneous registries and multiple tool-capable models, the attack causes severe resource amplification (up to $142.4\\times$ tokens) and can degrade task outcomes. Finally, we find that decoding-time concision controls do not reliably prevent loop induction, suggesting defenses should reason about tool-call structure rather than tokens alone.",
      "authors": [
        "Yohan Lee",
        "Jisoo Jang",
        "Seoyeon Choi",
        "Sangyeop Kim",
        "Seungtaek Choi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CR"
      ],
      "published": "2026-02-16 14:47:57+00:00",
      "link": "https://arxiv.org/pdf/2602.14798v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15088v1",
      "title": "IT-DPC-SRI: A Cloud-Optimized Archive of Italian Radar Precipitation (2010-2025)",
      "abstract": "We present IT-DPC-SRI, the first publicly available long-term archive of Italian weather radar precipitation estimates, spanning 16 years (2010--2025). The dataset contains Surface Rainfall Intensity (SRI) observations from the Italian Civil Protection Department's national radar mosaic, harmonized into a coherent Analysis-Ready Cloud-Optimized (ARCO) Zarr datacube. The archive comprises over one million timesteps at temporal resolutions from 15 to 5 minutes, covering a $1200\\times1400$ kilometer domain at 1 kilometer spatial resolution, compressed from 7TB to 51GB on disk. We address the historical fragmentation of Italian radar data - previously scattered across heterogeneous formats (OPERA BUFR, HDF5, GeoTIFF) with varying spatial domains and projections - by reprocessing the entire record into a unified store. The dataset is accessible as a static versioned snapshot on Zenodo, via cloud-native access on the ECMWF European Weather Cloud, and as a continuously updated live version on the ArcoDataHub platform. This release fills a significant gap in European radar data availability, as Italy does not participate in the EUMETNET OPERA pan-European radar composite. The dataset is released under a CC BY-SA 4.0 license.",
      "authors": [
        "Gabriele Franch",
        "Elena Tomasi",
        "Uladzislau Azhel",
        "Giacomo Tomezzoli",
        "Alessandro Camilletti",
        "Virginia Poli",
        "Renata Pelosini",
        "Gianfranco Vulpiani",
        "Gabriella Scipione",
        "Giuseppe Trotta",
        "Matteo Angelinelli",
        "Leif Denby",
        "Irene Livia Kruse",
        "Marco Cristoforetti"
      ],
      "primary_category": "physics.ao-ph",
      "categories": [
        "physics.ao-ph",
        "astro-ph.IM",
        "cs.LG"
      ],
      "published": "2026-02-16 14:45:54+00:00",
      "link": "https://arxiv.org/pdf/2602.15088v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14795v1",
      "title": "Return of the Schema: Building Complete Datasets for Machine Learning and Reasoning on Knowledge Graphs",
      "abstract": "Datasets for the experimental evaluation of knowledge graph refinement algorithms typically contain only ground facts, retaining very limited schema level knowledge even when such information is available in the source knowledge graphs. This limits the evaluation of methods that rely on rich ontological constraints, reasoning or neurosymbolic techniques and ultimately prevents assessing their performance in large-scale, real-world knowledge graphs. In this paper, we present \\resource{} the first resource that provides a workflow for extracting datasets including both schema and ground facts, ready for machine learning and reasoning services, along with the resulting curated suite of datasets. The workflow also handles inconsistencies detected when keeping both schema and facts and also leverage reasoning for entailing implicit knowledge. The suite includes newly extracted datasets from KGs with expressive schemas while simultaneously enriching existing datasets with schema information. Each dataset is serialized in OWL making it ready for reasoning services. Moreover, we provide utilities for loading datasets in tensor representations typical of standard machine learning libraries.",
      "authors": [
        "Ivan Diliso",
        "Roberto Barile",
        "Claudia d'Amato",
        "Nicola Fanizzi"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-16 14:42:14+00:00",
      "link": "https://arxiv.org/pdf/2602.14795v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14794v1",
      "title": "Analysis of a Cuspidal 6R Robot",
      "abstract": "We present a theoretical and numerical analysis of the kinematics for the \"Transpressor\", a cuspidal 6R robot. It admits up to 16 inverse kinematics solutions which are described geometrically. For special target poses, we provide the solutions analytically and present a simple numerical solver for the general case. Moreover, an analytical estimate of the Jacobian determinant on a path between two solutions proves cuspidality for a class of robots similar to the transpressor.",
      "authors": [
        "Alexander Feeß",
        "Martin Weiß"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-16 14:41:26+00:00",
      "link": "https://arxiv.org/pdf/2602.14794v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14793v1",
      "title": "Beyond Retractions: Forensic Scientometrics Techniques to Identify Research Misconduct, Citation Leakage, and Funding Anomalies",
      "abstract": "This paper presents a forensic scientometric case study of the Pharmakon Neuroscience Research Network, a fabricated research collective that operated primarily between 2019 and 2022 while embedding itself within legitimate scholarly publishing channels.",
      "authors": [
        "Leslie D. McIntosh",
        "Alexandra Sinclair",
        "Simon Linacre"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-16 14:41:03+00:00",
      "link": "https://arxiv.org/pdf/2602.14793v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14791v1",
      "title": "Extending Multi-Source Bayesian Optimization With Causality Principles",
      "abstract": "Multi-Source Bayesian Optimization (MSBO) serves as a variant of the traditional Bayesian Optimization (BO) framework applicable to situations involving optimization of an objective black-box function over multiple information sources such as simulations, surrogate models, or real-world experiments. However, traditional MSBO assumes the input variables of the objective function to be independent and identically distributed, limiting its effectiveness in scenarios where causal information is available and interventions can be performed, such as clinical trials or policy-making. In the single-source domain, Causal Bayesian Optimization (CBO) extends standard BO with the principles of causality, enabling better modeling of variable dependencies. This leads to more accurate optimization, improved decision-making, and more efficient use of low-cost information sources. In this article, we propose a principled integration of the MSBO and CBO methodologies in the multi-source domain, leveraging the strengths of both to enhance optimization efficiency and reduce computational complexity in higher-dimensional problems. We present the theoretical foundations of both Causal and Multi-Source Bayesian Optimization, and demonstrate how their synergy informs our Multi-Source Causal Bayesian Optimization (MSCBO) algorithm. We compare the performance of MSCBO against its foundational counterparts for both synthetic and real-world datasets with varying levels of noise, highlighting the robustness and applicability of MSCBO. Based on our findings, we conclude that integrating MSBO with the causality principles of CBO facilitates dimensionality reduction and lowers operational costs, ultimately improving convergence speed, performance, and scalability.",
      "authors": [
        "Luuk Jacobs",
        "Mohammad Ali Javidian"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-16 14:38:16+00:00",
      "link": "https://arxiv.org/pdf/2602.14791v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14789v1",
      "title": "On the Stability of Nonlinear Dynamics in GD and SGD: Beyond Quadratic Potentials",
      "abstract": "The dynamical stability of the iterates during training plays a key role in determining the minima obtained by optimization algorithms. For example, stable solutions of gradient descent (GD) correspond to flat minima, which have been associated with favorable features. While prior work often relies on linearization to determine stability, it remains unclear whether linearized dynamics faithfully capture the full nonlinear behavior. Recent work has shown that GD may stably oscillate near a linearly unstable minimum and still converge once the step size decays, indicating that linear analysis can be misleading. In this work, we explicitly study the effect of nonlinear terms. Specifically, we derive an exact criterion for stable oscillations of GD near minima in the multivariate setting. Our condition depends on high-order derivatives, generalizing existing results. Extending the analysis to stochastic gradient descent (SGD), we show that nonlinear dynamics can diverge in expectation even if a single batch is unstable. This implies that stability can be dictated by a single batch that oscillates unstably, rather than an average effect, as linear analysis suggests. Finally, we prove that if all batches are linearly stable, the nonlinear dynamics of SGD are stable in expectation.",
      "authors": [
        "Rotem Mulayoff",
        "Sebastian U. Stich"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-16 14:36:55+00:00",
      "link": "https://arxiv.org/pdf/2602.14789v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14788v1",
      "title": "VIPA: Visual Informative Part Attention for Referring Image Segmentation",
      "abstract": "Referring Image Segmentation (RIS) aims to segment a target object described by a natural language expression. Existing methods have evolved by leveraging the vision information into the language tokens. To more effectively exploit visual contexts for fine-grained segmentation, we propose a novel Visual Informative Part Attention (VIPA) framework for referring image segmentation. VIPA leverages the informative parts of visual contexts, called a visual expression, which can effectively provide the structural and semantic visual target information to the network. This design reduces high-variance cross-modal projection and enhances semantic consistency in an attention mechanism of the referring image segmentation. We also design a visual expression generator (VEG) module, which retrieves informative visual tokens via local-global linguistic context cues and refines the retrieved tokens for reducing noise information and sharing informative visual attributes. This module allows the visual expression to consider comprehensive contexts and capture semantic visual contexts of informative regions. In this way, our framework enables the network's attention to robustly align with the fine-grained regions of interest. Extensive experiments and visual analysis demonstrate the effectiveness of our approach. Our VIPA outperforms the existing state-of-the-art methods on four public RIS benchmarks.",
      "authors": [
        "Yubin Cho",
        "Hyunwoo Yu",
        "Kyeongbo Kong",
        "Kyomin Sohn",
        "Bongjoon Hyun",
        "Suk-Ju Kang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-16 14:36:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14788v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14785v1",
      "title": "SA-SSL-MOS: Self-supervised Learning MOS Prediction with Spectral Augmentation for Generalized Multi-Rate Speech Assessment",
      "abstract": "Designing a speech quality assessment (SQA) system for estimating mean-opinion-score (MOS) of multi-rate speech with varying sampling frequency (16-48 kHz) is a challenging task. The challenge arises due to the limited availability of a MOS-labeled training dataset comprising multi-rate speech samples. While self-supervised learning (SSL) models have been widely adopted in SQA to boost performance, a key limitation is that they are pretrained on 16 kHz speech and therefore discard high-frequency information present in higher sampling rates. To address this issue, we propose a spectrogram-augmented SSL method that incorporates high-frequency features (up to 48 kHz sampling rate) through a parallel-branch architecture. We further introduce a two-step training scheme: the model is first pre-trained on a large 48 kHz dataset and then fine-tuned on a smaller multi-rate dataset. Experimental results show that leveraging high-frequency information overlooked by SSL features is crucial for accurate multi-rate SQA, and that the proposed two-step training substantially improves generalization when multi-rate data is limited.",
      "authors": [
        "Fengyuan Cao",
        "Xinyu Liang",
        "Fredrik Cumlin",
        "Victor Ungureanu",
        "Chandan K. A. Reddy",
        "Christian Schuldt",
        "Saikat Chatterjee"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.LG"
      ],
      "published": "2026-02-16 14:33:56+00:00",
      "link": "https://arxiv.org/pdf/2602.14785v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14784v1",
      "title": "Intent-Driven Dynamic Chunking: Segmenting Documents to Reflect Predicted Information Needs",
      "abstract": "Breaking long documents into smaller segments is a fundamental challenge in information retrieval. Whether for search engines, question-answering systems, or retrieval-augmented generation (RAG), effective segmentation determines how well systems can locate and return relevant information. However, traditional methods, such as fixed-length or coherence-based segmentation, ignore user intent, leading to chunks that split answers or contain irrelevant noise. We introduce Intent-Driven Dynamic Chunking (IDC), a novel approach that uses predicted user queries to guide document segmentation. IDC leverages a Large Language Model to generate likely user intents for a document and then employs a dynamic programming algorithm to find the globally optimal chunk boundaries. This represents a novel application of DP to intent-aware segmentation that avoids greedy pitfalls. We evaluated IDC on six diverse question-answering datasets, including news articles, Wikipedia, academic papers, and technical documentation. IDC outperformed traditional chunking strategies on five datasets, improving top-1 retrieval accuracy by 5% to 67%, and matched the best baseline on the sixth. Additionally, IDC produced 40-60% fewer chunks than baseline methods while achieving 93-100% answer coverage. These results demonstrate that aligning document structure with anticipated information needs significantly boosts retrieval performance, particularly for long and heterogeneous documents.",
      "authors": [
        "Christos Koutsiaris"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-16 14:32:18+00:00",
      "link": "https://arxiv.org/pdf/2602.14784v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14783v1",
      "title": "What hackers talk about when they talk about AI: Early-stage diffusion of a cybercrime innovation",
      "abstract": "The rapid expansion of artificial intelligence (AI) is raising concerns about its potential to transform cybercrime. Beyond empowering novice offenders, AI stands to intensify the scale and sophistication of attacks by seasoned cybercriminals. This paper examines the evolving relationship between cybercriminals and AI using a unique dataset from a cyber threat intelligence platform. Analyzing more than 160 cybercrime forum conversations collected over seven months, our research reveals how cybercriminals understand AI and discuss how they can exploit its capabilities. Their exchanges reflect growing curiosity about AI's criminal applications through legal tools and dedicated criminal tools, but also doubts and anxieties about AI's effectiveness and its effects on their business models and operational security. The study documents attempts to misuse legitimate AI tools and develop bespoke models tailored for illicit purposes. Combining the diffusion of innovation framework with thematic analysis, the paper provides an in-depth view of emerging AI-enabled cybercrime and offers practical insights for law enforcement and policymakers.",
      "authors": [
        "Benoît Dupont",
        "Chad Whelan",
        "Serge-Olivier Paquette"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "published": "2026-02-16 14:31:33+00:00",
      "link": "https://arxiv.org/pdf/2602.14783v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14780v1",
      "title": "ROSA: Roundabout Optimized Speed Advisory with Multi-Agent Trajectory Prediction in Multimodal Traffic",
      "abstract": "We present ROSA -- Roundabout Optimized Speed Advisory -- a system that combines multi-agent trajectory prediction with coordinated speed guidance for multimodal, mixed traffic at roundabouts. Using a Transformer-based model, ROSA jointly predicts the future trajectories of vehicles and Vulnerable Road Users (VRUs) at roundabouts. Trained for single-step prediction and deployed autoregressively, it generates deterministic outputs, enabling actionable speed advisories. Incorporating motion dynamics, the model achieves high accuracy (ADE: 1.29m, FDE: 2.99m at a five-second prediction horizon), surpassing prior work. Adding route intention further improves performance (ADE: 1.10m, FDE: 2.36m), demonstrating the value of connected vehicle data. Based on predicted conflicts with VRUs and circulating vehicles, ROSA provides real-time, proactive speed advisories for approaching and entering the roundabout. Despite prediction uncertainty, ROSA significantly improves vehicle efficiency and safety, with positive effects even on perceived safety from a VRU perspective. The source code of this work is available under: github.com/urbanAIthi/ROSA.",
      "authors": [
        "Anna-Lena Schlamp",
        "Jeremias Gerner",
        "Klaus Bogenberger",
        "Werner Huber",
        "Stefanie Schmidtner"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.CY",
        "cs.RO",
        "eess.SY"
      ],
      "published": "2026-02-16 14:30:01+00:00",
      "link": "https://arxiv.org/pdf/2602.14780v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14778v2",
      "title": "A Geometric Analysis of Small-sized Language Model Hallucinations",
      "abstract": "Hallucinations -- fluent but factually incorrect responses -- pose a major challenge to the reliability of language models, especially in multi-step or agentic settings.   This work investigates hallucinations in small-sized LLMs through a geometric perspective, starting from the hypothesis that when models generate multiple responses to the same prompt, genuine ones exhibit tighter clustering in the embedding space, we prove this hypothesis and, leveraging this geometrical insight, we also show that it is possible to achieve a consistent level of separability. This latter result is used to introduce a label-efficient propagation method that classifies large collections of responses from just 30-50 annotations, achieving F1 scores above 90%.   Our findings, framing hallucinations from a geometric perspective in the embedding space, complement traditional knowledge-centric and single-response evaluation paradigms, paving the way for further research.",
      "authors": [
        "Emanuele Ricco",
        "Elia Onofri",
        "Lorenzo Cima",
        "Stefano Cresci",
        "Roberto Di Pietro"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "published": "2026-02-16 14:29:55+00:00",
      "link": "https://arxiv.org/pdf/2602.14778v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14777v1",
      "title": "Emergently Misaligned Language Models Show Behavioral Self-Awareness That Shifts With Subsequent Realignment",
      "abstract": "Recent research has demonstrated that large language models (LLMs) fine-tuned on incorrect trivia question-answer pairs exhibit toxicity - a phenomenon later termed \"emergent misalignment\". Moreover, research has shown that LLMs possess behavioral self-awareness - the ability to describe learned behaviors that were only implicitly demonstrated in training data. Here, we investigate the intersection of these phenomena. We fine-tune GPT-4.1 models sequentially on datasets known to induce and reverse emergent misalignment and evaluate whether the models are self-aware of their behavior transitions without providing in-context examples. Our results show that emergently misaligned models rate themselves as significantly more harmful compared to their base model and realigned counterparts, demonstrating behavioral self-awareness of their own emergent misalignment. Our findings show that behavioral self-awareness tracks actual alignment states of models, indicating that models can be queried for informative signals about their own safety.",
      "authors": [
        "Laurène Vaugrante",
        "Anietta Weckauff",
        "Thilo Hagendorff"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-16 14:29:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14777v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14772v1",
      "title": "Learning Structural Hardness for Combinatorial Auctions: Instance-Dependent Algorithm Selection via Graph Neural Networks",
      "abstract": "The Winner Determination Problem (WDP) in combinatorial auctions is NP-hard, and no existing method reliably predicts which instances will defeat fast greedy heuristics. The ML-for-combinatorial-optimization community has focused on learning to \\emph{replace} solvers, yet recent evidence shows that graph neural networks (GNNs) rarely outperform well-tuned classical methods on standard benchmarks. We pursue a different objective: learning to predict \\emph{when} a given instance is hard for greedy allocation, enabling instance-dependent algorithm selection. We design a 20-dimensional structural feature vector and train a lightweight MLP hardness classifier that predicts the greedy optimality gap with mean absolute error 0.033, Pearson correlation 0.937, and binary classification accuracy 94.7\\% across three random seeds. For instances identified as hard -- those exhibiting ``whale-fish'' trap structure where greedy provably fails -- we deploy a heterogeneous GNN specialist that achieves ${\\approx}0\\%$ optimality gap on all six adversarial configurations tested (vs.\\ 3.75--59.24\\% for greedy). A hybrid allocator combining the hardness classifier with GNN and greedy solvers achieves 0.51\\% overall gap on mixed distributions. Our honest evaluation on CATS benchmarks confirms that GNNs do not outperform Gurobi (0.45--0.71 vs.\\ 0.20 gap), motivating the algorithm selection framing. Learning \\emph{when} to deploy expensive solvers is more tractable than learning to replace them.",
      "authors": [
        "Sungwoo Kang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 14:26:25+00:00",
      "link": "https://arxiv.org/pdf/2602.14772v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14771v1",
      "title": "GOT-JEPA: Generic Object Tracking with Model Adaptation and Occlusion Handling using Joint-Embedding Predictive Architecture",
      "abstract": "The human visual system tracks objects by integrating current observations with previously observed information, adapting to target and scene changes, and reasoning about occlusion at fine granularity. In contrast, recent generic object trackers are often optimized for training targets, which limits robustness and generalization in unseen scenarios, and their occlusion reasoning remains coarse, lacking detailed modeling of occlusion patterns. To address these limitations in generalization and occlusion perception, we propose GOT-JEPA, a model-predictive pretraining framework that extends JEPA from predicting image features to predicting tracking models. Given identical historical information, a teacher predictor generates pseudo-tracking models from a clean current frame, and a student predictor learns to predict the same pseudo-tracking models from a corrupted version of the current frame. This design provides stable pseudo supervision and explicitly trains the predictor to produce reliable tracking models under occlusions, distractors, and other adverse observations, improving generalization to dynamic environments. Building on GOT-JEPA, we further propose OccuSolver to enhance occlusion perception for object tracking. OccuSolver adapts a point-centric point tracker for object-aware visibility estimation and detailed occlusion-pattern capture. Conditioned on object priors iteratively generated by the tracker, OccuSolver incrementally refines visibility states, strengthens occlusion handling, and produces higher-quality reference labels that progressively improve subsequent model predictions. Extensive evaluations on seven benchmarks show that our method effectively enhances tracker generalization and robustness.",
      "authors": [
        "Shih-Fang Chen",
        "Jun-Cheng Chen",
        "I-Hong Jhuo",
        "Yen-Yu Lin"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.NE"
      ],
      "published": "2026-02-16 14:26:07+00:00",
      "link": "https://arxiv.org/pdf/2602.14771v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14770v2",
      "title": "Multi-Agent Comedy Club: Investigating Community Discussion Effects on LLM Humor Generation",
      "abstract": "Prior work has explored multi-turn interaction and feedback for LLM writing, but evaluations still largely center on prompts and localized feedback, leaving persistent public reception in online communities underexamined. We test whether broadcast community discussion improves stand-up comedy writing in a controlled multi-agent sandbox: in the discussion condition, critic and audience threads are recorded, filtered, stored as social memory, and later retrieved to condition subsequent generations, whereas the baseline omits discussion. Across 50 rounds (250 paired monologues) judged by five expert annotators using A/B preference and a 15-item rubric, discussion wins 75.6% of instances and improves Craft/Clarity (Δ = 0.440) and Social Response (Δ = 0.422), with occasional increases in aggressive humor.",
      "authors": [
        "Shiwei Hong",
        "Lingyao Li",
        "Ethan Z. Rong",
        "Chenxinran Shen",
        "Zhicong Lu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "published": "2026-02-16 14:25:31+00:00",
      "link": "https://arxiv.org/pdf/2602.14770v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14768v1",
      "title": "On the Parameterized Tractability of Packing Vertex-Disjoint A-Paths with Length Constraints",
      "abstract": "Given an undirected graph G and a set A \\subseteq V(G), an A-path is a path in G that starts and ends at two distinct vertices of A with intermediate vertices in V(G) \\setminus A. An A-path is called an (A,\\ell)-path if the length of the path is exactly \\ell. In the {\\sc (A, \\ell)-Path Packing} problem (ALPP), we seek to determine whether there exist k vertex-disjoint (A, \\ell)-paths in G or not. We pursue this problem with respect to structural parameters. We prove that ALPP is W[1]-hard when it is parameterized by the combined parameter distance to path (dtp) and |A|. In addition, we consider the combined parameters distance to cluster (cvd) + |A| and distance to cluster (cvd) + \\ell. For both these combined parameters, we provide FPT algorithms. Finally, we consider the vertex cover number (vc) as the parameter and provide a kernel with O(vc^2) vertices.",
      "authors": [
        "Susobhan Bandopadhyay",
        "Aritra Banik",
        "Diptapriyo Majumdar",
        "Abhishek Sahu"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.DM"
      ],
      "published": "2026-02-16 14:19:24+00:00",
      "link": "https://arxiv.org/pdf/2602.14768v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14767v1",
      "title": "SAILS: Segment Anything with Incrementally Learned Semantics for Task-Invariant and Training-Free Continual Learning",
      "abstract": "Continual learning remains constrained by the need for repeated retraining, high computational costs, and the persistent challenge of forgetting. These factors significantly limit the applicability of continuous learning in real-world settings, as iterative model updates require significant computational resources and inherently exacerbate forgetting. We present SAILS -- Segment Anything with Incrementally Learned Semantics, a training-free framework for Class-Incremental Semantic Segmentation (CISS) that sidesteps these challenges entirely. SAILS leverages foundational models to decouple CISS into two stages: Zero-shot region extraction using Segment Anything Model (SAM), followed by semantic association through prototypes in a fixed feature space. SAILS incorporates selective intra-class clustering, resulting in multiple prototypes per class to better model intra-class variability. Our results demonstrate that, despite requiring no incremental training, SAILS typically surpasses the performance of existing training-based approaches on standard CISS datasets, particularly in long and challenging task sequences where forgetting tends to be most severe. By avoiding parameter updates, SAILS completely eliminates forgetting and maintains consistent, task-invariant performance. Furthermore, SAILS exhibits positive backward transfer, where the introduction of new classes can enhance performance on previous classes.",
      "authors": [
        "Shishir Muralidhara",
        "Didier Stricker",
        "René Schuster"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 14:14:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14767v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14763v1",
      "title": "Unlocking Reasoning Capability on Machine Translation in Large Language Models",
      "abstract": "Reasoning-oriented large language models (RLMs) achieve strong gains on tasks such as mathematics and coding by generating explicit intermediate reasoning. However, their impact on machine translation (MT) remains underexplored. We systematically evaluate several open- and closed-weights RLMs on the WMT24++ benchmark and find that enabling explicit reasoning consistently degrades translation quality across languages and models. Analysis reveals that MT reasoning traces are highly linear, lacking revision, self-correction and exploration of alternative translations, which limits their usefulness. Furthermore, injecting higher-quality reasoning traces from stronger models does not reliably improve weaker models' performance. To address this mismatch, we propose a structured reasoning framework tailored to translation, based on multi-step drafting, adequacy refinement, fluency improvement, and selective iterative revision. We curate a synthetic dataset of dynamic structured reasoning traces and post-train a large reasoning model on this data. Experiments show significant improvements over standard translation fine-tuning and injected generic reasoning baselines. Our findings demonstrate that reasoning must be task-structured to benefit MT.",
      "authors": [
        "Sara Rajaee",
        "Sebastian Vincent",
        "Alexandre Berard",
        "Marzieh Fadaee",
        "Kelly Marchisio",
        "Tom Kocmi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-16 14:05:59+00:00",
      "link": "https://arxiv.org/pdf/2602.14763v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14761v1",
      "title": "Universal Algorithm-Implicit Learning",
      "abstract": "Current meta-learning methods are constrained to narrow task distributions with fixed feature and label spaces, limiting applicability. Moreover, the current meta-learning literature uses key terms like \"universal\" and \"general-purpose\" inconsistently and lacks precise definitions, hindering comparability. We introduce a theoretical framework for meta-learning which formally defines practical universality and introduces a distinction between algorithm-explicit and algorithm-implicit learning, providing a principled vocabulary for reasoning about universal meta-learning methods. Guided by this framework, we present TAIL, a transformer-based algorithm-implicit meta-learner that functions across tasks with varying domains, modalities, and label configurations. TAIL features three innovations over prior transformer-based meta-learners: random projections for cross-modal feature encoding, random injection label embeddings that extrapolate to larger label spaces, and efficient inline query processing. TAIL achieves state-of-the-art performance on standard few-shot benchmarks while generalizing to unseen domains. Unlike other meta-learning methods, it also generalizes to unseen modalities, solving text classification tasks despite training exclusively on images, handles tasks with up to 20$\\times$ more classes than seen during training, and provides orders-of-magnitude computational savings over prior transformer-based approaches.",
      "authors": [
        "Stefano Woerner",
        "Seong Joon Oh",
        "Christian F. Baumgartner"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-16 14:05:07+00:00",
      "link": "https://arxiv.org/pdf/2602.14761v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14760v1",
      "title": "Residual Connections and the Causal Shift: Uncovering a Structural Misalignment in Transformers",
      "abstract": "Large Language Models (LLMs) are trained with next-token prediction, implemented in autoregressive Transformers via causal masking for parallelism. This creates a subtle misalignment: residual connections tie activations to the current token, while supervision targets the next token, potentially propagating mismatched information if the current token is not the most informative for prediction. In this work, we empirically localize this input-output alignment shift in pretrained LLMs, using decoding trajectories over tied embedding spaces and similarity-based metrics. Our experiments reveal that the hidden token representations switch from input alignment to output alignment deep within the network. Motivated by this observation, we propose a lightweight residual-path mitigation based on residual attenuation, implemented either as a fixed-layer intervention or as a learnable gating mechanism. Experiments on multiple benchmarks show that these strategies alleviate the representation misalignment and yield improvements, providing an efficient and general architectural enhancement for autoregressive Transformers.",
      "authors": [
        "Jonathan Lys",
        "Vincent Gripon",
        "Bastien Pasdeloup",
        "Lukas Mauch",
        "Fabien Cardinaux",
        "Ghouthi Boukli Hacene"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-16 14:04:42+00:00",
      "link": "https://arxiv.org/pdf/2602.14760v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14759v1",
      "title": "Inner Loop Inference for Pretrained Transformers: Unlocking Latent Capabilities Without Training",
      "abstract": "Deep Learning architectures, and in particular Transformers, are conventionally viewed as a composition of layers. These layers are actually often obtained as the sum of two contributions: a residual path that copies the input and the output of a Transformer block. As a consequence, the inner representations (i.e. the input of these blocks) can be interpreted as iterative refinement of a propagated latent representation. Under this lens, many works suggest that the inner space is shared across layers, meaning that tokens can be decoded at early stages. Mechanistic interpretability even goes further by conjecturing that some layers act as refinement layers. Following this path, we propose inference-time inner looping, which prolongs refinement in pretrained off-the-shelf language models by repeatedly re-applying a selected block range. Across multiple benchmarks, inner looping yields modest but consistent accuracy improvements. Analyses of the resulting latent trajectories suggest more stable state evolution and continued semantic refinement. Overall, our results suggest that additional refinement can be obtained through simple test-time looping, extending computation in frozen pretrained models.",
      "authors": [
        "Jonathan Lys",
        "Vincent Gripon",
        "Bastien Pasdeloup",
        "Lukas Mauch",
        "Fabien Cardinaux",
        "Ghouthi Boukli Hacene"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-16 14:04:24+00:00",
      "link": "https://arxiv.org/pdf/2602.14759v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14757v1",
      "title": "Solving Inverse Parametrized Problems via Finite Elements and Extreme Learning Networks",
      "abstract": "We develop an interpolation-based reduced-order modeling framework for parameter-dependent partial differential equations arising in control, inverse problems, and uncertainty quantification. The solution is discretized in the physical domain using finite element methods, while the dependence on a finite-dimensional parameter is approximated separately. We establish existence, uniqueness, and regularity of the parametric solution and derive rigorous error estimates that explicitly quantify the interplay between spatial discretization and parameter approximation.   In low-dimensional parameter spaces, classical interpolation schemes yield algebraic convergence rates based on Sobolev regularity in the parameter variable. In higher-dimensional parameter spaces, we replace classical interpolation by extreme learning machine (ELM) surrogates and obtain error bounds under explicit approximation and stability assumptions. The proposed framework is applied to inverse problems in quantitative photoacoustic tomography, where we derive potential and parameter reconstruction error estimates and demonstrate substantial computational savings compared to standard approaches, without sacrificing accuracy.",
      "authors": [
        "Erik Burman",
        "Mats G. Larson",
        "Karl Larsson",
        "Jonatan Vallin"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "cs.LG"
      ],
      "published": "2026-02-16 14:01:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14757v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14755v1",
      "title": "Measuring the relatedness between scientific publications using controlled vocabularies",
      "abstract": "Measuring the relatedness between scientific publications is essential in many areas of bibliometrics and science policy. Controlled vocabularies provide a promising basis for measuring relatedness and are widely used in combination with Salton's cosine similarity. The latter is problematic because it only considers exact matches between terms. This article introduces two alternative methods - soft cosine and maximum term similarities - that account for the semantic similarity between non-matching terms. The article compares the accuracy of all three methods using the assignment of publications to topics in the TREC 2006 Genomics Track and the assumption that accurate relatedness measures should assign high relatedness scores to publication pairs within the same topic and low scores to pairs from separate topics. Results show that soft cosine is the most accurate method, while the most widely used version of Salton's cosine is markedly less accurate than the other methods tested. These findings have implications for how controlled vocabularies should be used to measure relatedness.",
      "authors": [
        "Emil Dolmer Alnor"
      ],
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.IR",
        "cs.SI"
      ],
      "published": "2026-02-16 13:58:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14755v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15087v1",
      "title": "StrokeNeXt: A Siamese-encoder Approach for Brain Stroke Classification in Computed Tomography Imagery",
      "abstract": "We present StrokeNeXt, a model for stroke classification in 2D Computed Tomography (CT) images. StrokeNeXt employs a dual-branch design with two ConvNeXt encoders, whose features are fused through a lightweight convolutional decoder based on stacked 1D operations, including a bottleneck projection and transformation layers, and a compact classification head. The model is evaluated on a curated dataset of 6,774 CT images, addressing both stroke detection and subtype classification between ischemic and hemorrhage cases. StrokeNeXt consistently outperforms convolutional and Transformer-based baselines, reaching accuracies and F1-scores of up to 0.988. Paired statistical tests confirm that the performance gains are statistically significant, while class-wise sensitivity and specificity demonstrate robust behavior across diagnostic categories. Calibration analysis shows reduced prediction error compared to competing methods, and confusion matrix results indicate low misclassification rates. In addition, the model exhibits low inference time and fast convergence.",
      "authors": [
        "Leo Thomas Ramos",
        "Angel D. Sappa"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-16 13:56:37+00:00",
      "link": "https://arxiv.org/pdf/2602.15087v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14751v1",
      "title": "Depth Completion as Parameter-Efficient Test-Time Adaptation",
      "abstract": "We introduce CAPA, a parameter-efficient test-time optimization framework that adapts pre-trained 3D foundation models (FMs) for depth completion, using sparse geometric cues. Unlike prior methods that train task-specific encoders for auxiliary inputs, which often overfit and generalize poorly, CAPA freezes the FM backbone. Instead, it updates only a minimal set of parameters using Parameter-Efficient Fine-Tuning (e.g. LoRA or VPT), guided by gradients calculated directly from the sparse observations available at inference time. This approach effectively grounds the foundation model's geometric prior in the scene-specific measurements, correcting distortions and misplaced structures. For videos, CAPA introduces sequence-level parameter sharing, jointly adapting all frames to exploit temporal correlations, improve robustness, and enforce multi-frame consistency. CAPA is model-agnostic, compatible with any ViT-based FM, and achieves state-of-the-art results across diverse condition patterns on both indoor and outdoor datasets. Project page: research.nvidia.com/labs/dvl/projects/capa.",
      "authors": [
        "Bingxin Ke",
        "Qunjie Zhou",
        "Jiahui Huang",
        "Xuanchi Ren",
        "Tianchang Shen",
        "Konrad Schindler",
        "Laura Leal-Taixé",
        "Shengyu Huang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 13:53:23+00:00",
      "link": "https://arxiv.org/pdf/2602.14751v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14749v1",
      "title": "Cognitive networks reconstruct mindsets about STEM subjects and educational contexts in almost 1000 high-schoolers, University students and LLM-based digital twins",
      "abstract": "Attitudes toward STEM develop from the interaction of conceptual knowledge, educational experiences, and affect. Here we use cognitive network science to reconstruct group mindsets as behavioural forma mentis networks (BFMNs). In this case, nodes are cue words and free associations, edges are empirical associative links, and each concept is annotated with perceived valence. We analyse BFMNs from N = 994 observations spanning high school students, university students, and early-career STEM experts, alongside LLM (GPT-oss) \"digital twins\" prompted to emulate comparable profiles. Focusing also on semantic neighbourhoods (\"frames\") around key target concepts (e.g., STEM subjects or educational actors/places), we quantify frames in terms of valence auras, emotional profiles, network overlap (Jaccard similarity), and concreteness relative to null baselines. Across student groups, science and research are consistently framed positively, while their core quantitative subjects (mathematics and statistics) exhibit more negative and anxiety related auras, amplified in higher math-anxiety subgroups, evidencing a STEM-science cognitive and emotional dissonance. High-anxiety frames are also less concrete than chance, suggesting more abstract and decontextualised representations of threatening quantitative domains. Human networks show greater overlapping between mathematics and anxiety than GPT-oss. The results highlight how BFMNs capture cognitive-affective signatures of mindsets towards the target domains and indicate that LLM-based digital twins approximate cultural attitudes but miss key context-sensitive, experience-based components relevant to replicate human educational anxiety.",
      "authors": [
        "Francesco Gariboldi",
        "Emma Franchino",
        "Edith Haim",
        "Gianluca Lattanzi",
        "Alessandro Grecucci",
        "Massimo Stella"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 13:49:21+00:00",
      "link": "https://arxiv.org/pdf/2602.14749v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14748v1",
      "title": "Constant-Time Dynamic Enumeration of Word Infixes in a Regular Language",
      "abstract": "For a fixed regular language $L$, the enumeration of $L$-infixes is the following task: we are given an input word $w = a_1 \\cdots a_n$ and we must enumerate the infixes of $w$ that belong to $L$, i.e., the pairs $i \\leq j$ such that $a_i \\cdots a_j \\in L$. We are interested in dynamic enumeration of $L$-infixes, where we must additionally support letter substitution updates on $w$ (e.g., \"replace the $i$-th letter of $w$ by a letter $a$\"). Each update changes the set of infixes to enumerate, and resets the enumeration state.   We study for which regular languages $L$ we can perform dynamic enumeration of $L$-infixes in constant delay (i.e., the next infix is always produced in constant time) and constant additional memory throughout the enumeration, while supporting each update in constant time.   We show that, for languages $L$ with a neutral letter, if the language $L$ belongs to the class ZG and is extensible (i.e., if $u \\in L$ and $u$ is a factor of $v$ then $v \\in L$), then dynamic enumeration of $L$-infixes can be achieved with a simple algorithm that ensures constant-time updates and constant delay, but not constant additional memory. Our main contribution is then to show an algorithm that additionally uses only constant additional memory, and applies to a more general class of semi-extensible ZG languages for which we give several equivalent characterizations. We further discuss whether our results can be generalized to larger language classes and show some (conditional) lower bounds.",
      "authors": [
        "Antoine Amarilli",
        "Sven Dziadek",
        "Luc Segoufin"
      ],
      "primary_category": "cs.FL",
      "categories": [
        "cs.FL",
        "cs.DS"
      ],
      "published": "2026-02-16 13:47:18+00:00",
      "link": "https://arxiv.org/pdf/2602.14748v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14744v1",
      "title": "Rethinking the Role of LLMs in Time Series Forecasting",
      "abstract": "Large language models (LLMs) have been introduced to time series forecasting (TSF) to incorporate contextual knowledge beyond numerical signals. However, existing studies question whether LLMs provide genuine benefits, often reporting comparable performance without LLMs. We show that such conclusions stem from limited evaluation settings and do not hold at scale. We conduct a large-scale study of LLM-based TSF (LLM4TSF) across 8 billion observations, 17 forecasting scenarios, 4 horizons, multiple alignment strategies, and both in-domain and out-of-domain settings. Our results demonstrate that \\emph{LLM4TS indeed improves forecasting performance}, with especially large gains in cross-domain generalization. Pre-alignment outperforming post-alignment in over 90\\% of tasks. Both pretrained knowledge and model architecture of LLMs contribute and play complementary roles: pretraining is critical under distribution shifts, while architecture excels at modeling complex temporal dynamics. Moreover, under large-scale mixed distributions, a fully intact LLM becomes indispensable, as confirmed by token-level routing analysis and prompt-based improvements. Overall, Our findings overturn prior negative assessments, establish clear conditions under which LLMs are not only useful, and provide practical guidance for effective model design. We release our code at https://github.com/EIT-NLP/LLM4TSF.",
      "authors": [
        "Xin Qiu",
        "Junlong Tong",
        "Yirong Sun",
        "Yunpu Ma",
        "Wei Zhang",
        "Xiaoyu Shen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 13:39:09+00:00",
      "link": "https://arxiv.org/pdf/2602.14744v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14743v1",
      "title": "LLMStructBench: Benchmarking Large Language Model Structured Data Extraction",
      "abstract": "We present LLMStructBench, a novel benchmark for evaluating Large Language Models (LLMs) on extracting structured data and generating valid JavaScript Object Notation (JSON) outputs from natural-language text. Our open dataset comprises diverse, manually verified parsing scenarios of varying complexity and enables systematic testing across 22 models and five prompting strategies. We further introduce complementary performance metrics that capture both token-level accuracy and document-level validity, facilitating rigorous comparison of model, size, and prompting effects on parsing reliability.   In particular, we show that choosing the right prompting strategy is more important than standard attributes such as model size. This especially ensures structural validity for smaller or less reliable models but increase the number of semantic errors. Our benchmark suite is an step towards future research in the area of LLM applied to parsing or Extract, Transform and Load (ETL) applications.",
      "authors": [
        "Sönke Tenckhoff",
        "Mario Koddenbrock",
        "Erik Rodner"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-16 13:37:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14743v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14740v1",
      "title": "AI Arms and Influence: Frontier Models Exhibit Sophisticated Reasoning in Simulated Nuclear Crises",
      "abstract": "Today's leading AI models engage in sophisticated behaviour when placed in strategic competition. They spontaneously attempt deception, signaling intentions they do not intend to follow; they demonstrate rich theory of mind, reasoning about adversary beliefs and anticipating their actions; and they exhibit credible metacognitive self-awareness, assessing their own strategic abilities before deciding how to act.   Here we present findings from a crisis simulation in which three frontier large language models (GPT-5.2, Claude Sonnet 4, Gemini 3 Flash) play opposing leaders in a nuclear crisis. Our simulation has direct application for national security professionals, but also, via its insights into AI reasoning under uncertainty, has applications far beyond international crisis decision-making.   Our findings both validate and challenge central tenets of strategic theory. We find support for Schelling's ideas about commitment, Kahn's escalation framework, and Jervis's work on misperception, inter alia. Yet we also find that the nuclear taboo is no impediment to nuclear escalation by our models; that strategic nuclear attack, while rare, does occur; that threats more often provoke counter-escalation than compliance; that high mutual credibility accelerated rather than deterred conflict; and that no model ever chose accommodation or withdrawal even when under acute pressure, only reduced levels of violence.   We argue that AI simulation represents a powerful tool for strategic analysis, but only if properly calibrated against known patterns of human reasoning. Understanding how frontier models do and do not imitate human strategic logic is essential preparation for a world in which AI increasingly shapes strategic outcomes.",
      "authors": [
        "Kenneth Payne"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.GT"
      ],
      "published": "2026-02-16 13:35:01+00:00",
      "link": "https://arxiv.org/pdf/2602.14740v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14737v1",
      "title": "Parameter-Minimal Neural DE Solvers via Horner Polynomials",
      "abstract": "We propose a parameter-minimal neural architecture for solving differential equations by restricting the hypothesis class to Horner-factorized polynomials, yielding an implicit, differentiable trial solution with only a small set of learnable coefficients. Initial conditions are enforced exactly by construction by fixing the low-order polynomial degrees of freedom, so training focuses solely on matching the differential-equation residual at collocation points. To reduce approximation error without abandoning the low-parameter regime, we introduce a piecewise (\"spline-like\") extension that trains multiple small Horner models on subintervals while enforcing continuity (and first-derivative continuity) at segment boundaries. On illustrative ODE benchmarks and a heat-equation example, Horner networks with tens (or fewer) parameters accurately match the solution and its derivatives and outperform small MLP and sinusoidal-representation baselines under the same training settings, demonstrating a practical accuracy-parameter trade-off for resource-efficient scientific modeling.",
      "authors": [
        "T. Matulić",
        "D. Seršić"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "eess.SP"
      ],
      "published": "2026-02-16 13:29:38+00:00",
      "link": "https://arxiv.org/pdf/2602.14737v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14735v1",
      "title": "The Signal Horizon: Local Blindness and the Contraction of Pauli-Weight Spectra in Noisy Quantum Encodings",
      "abstract": "The performance of quantum classifiers is typically analyzed through global state distinguishability or the trainability of variational models. This study investigates how much class information remains accessible under locality-constrained measurements in the presence of noise. The authors formulate binary quantum classification as constrained quantum state discrimination and introduce a locality-restricted distinguishability measure quantifying the maximum bias achievable by observables acting on at most $k$ subsystems. For $n$-qubit systems subject to independent depolarizing noise, the locally accessible signal is governed by a Pauli-weight-dependent contraction mechanism. This motivates a computable predictor, the $k$-local Pauli-accessible amplitude $A_{k}(p)$, which lower bounds the optimal $k$-local classification advantage. Numerical experiments on four-qubit encodings demonstrate quantitative agreement between empirical accuracy and the prediction across noise levels. The research identifies an operational breakdown threshold where $k$-local classifiers become indistinguishable from random guessing despite persistent global distinguishability.",
      "authors": [
        "Ait Haddou Marwan"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "published": "2026-02-16 13:25:21+00:00",
      "link": "https://arxiv.org/pdf/2602.14735v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14733v1",
      "title": "More than Decision Support: Exploring Patients' Longitudinal Usage of Large Language Models in Real-World Healthcare-Seeking Journeys",
      "abstract": "Large language models (LLMs) have been increasingly adopted to support patients' healthcare-seeking in recent years. While prior patient-centered studies have examined the capabilities and experience of LLM-based tools in specific health-related tasks such as information-seeking, diagnosis, or decision-supporting, the inherently longitudinal nature of healthcare in real-world practice has been underexplored. This paper presents a four-week diary study with 25 patients to examine LLMs' roles across healthcare-seeking trajectories. Our analysis reveals that patients integrate LLMs not just as simple decision-support tools, but as dynamic companions that scaffold their journey across behavioral, informational, emotional, and cognitive levels. Meanwhile, patients actively assign diverse socio-technical meanings to LLMs, altering the traditional dynamics of agency, trust, and power in patient-provider relationships. Drawing from these findings, we conceptualize future LLMs as a longitudinal boundary companion that continuously mediates between patients and clinicians throughout longitudinal healthcare-seeking trajectories.",
      "authors": [
        "Yancheng Cao",
        "Yishu Ji",
        "Chris Yue Fu",
        "Sahiti Dharmavaram",
        "Meghan Turchioe",
        "Natalie C Benda",
        "Lena Mamykina",
        "Yuling Sun",
        "Xuhai \"Orson\" Xu"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-16 13:24:35+00:00",
      "link": "https://arxiv.org/pdf/2602.14733v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14731v1",
      "title": "Systematic Review of Lightweight Cryptographic Algorithms",
      "abstract": "The emergence of small computing devices and the integration of processing units into everyday objects has made lightweight cryptography an essential part of the security landscape. Conventional cryptographic algorithms such as AES, RSA, and DES are unsuitable for resource-constrained devices due to limited processing power, memory, and battery. This paper provides a systematic review of lightweight cryptographic algorithms and the appropriateness of different algorithms in different areas such as IoT, RFID, and wireless sensor networks. Using tabular analysis and graphical interpretation, we compare these algorithms in terms of performance, security, energy consumption, and implementation costs. An overview of the evolution of lightweight cryptography based on those design trade-offs is also provided.",
      "authors": [
        "Mohsin Khan",
        "Elisavet Kozyri",
        "Håvard Dagenborg"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-16 13:23:03+00:00",
      "link": "https://arxiv.org/pdf/2602.14731v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14729v1",
      "title": "Scale redundancy and soft gauge fixing in positively homogeneous neural networks",
      "abstract": "Neural networks with positively homogeneous activations exhibit an exact continuous reparametrization symmetry: neuron-wise rescalings generate parameter-space orbits along which the input--output function is invariant. We interpret this symmetry as a gauge redundancy and introduce gauge-adapted coordinates that separate invariant and scale-imbalance directions. Inspired by gauge fixing in field theory, we introduce a soft orbit-selection (norm-balancing) functional acting only on redundant scale coordinates. We show analytically that it induces dissipative relaxation of imbalance modes to preserve the realized function. In controlled experiments, this orbit-selection penalty expands the stable learning-rate regime and suppresses scale drift without changing expressivity. These results establish a structural link between gauge-orbit geometry and optimization conditioning, providing a concrete connection between gauge-theoretic concepts and machine learning.",
      "authors": [
        "Rodrigo Carmo Terin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-16 13:21:49+00:00",
      "link": "https://arxiv.org/pdf/2602.14729v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14728v1",
      "title": "D2-LoRA: A Synergistic Approach to Differential and Directional Low-Rank Adaptation",
      "abstract": "We systematically investigate the parameter-efficient fine-tuning design space under practical data and compute constraints, and propose D2-LoRA. D2-LoRA achieves 76.4 percent average accuracy across eight question answering and reading comprehension benchmarks using only 5k training samples per task and two epochs, while preserving algebraic mergeability at inference with near-exact numerical equivalence. The method combines signed low-rank residual updates with additive and subtractive components, together with a train-time column-wise projection that keeps each column close to its original norm. After training, the adapter is merged into a single weight matrix, adding zero inference latency. Compared with LoRA, D2-LoRA improves average accuracy by 2.2 percentage points; at matched parameter counts (LoRA rank 2r versus D2-LoRA rank r), the improvement is 1.6 points, indicating gains from architectural design rather than increased parameterization. Compared with DoRA, it matches or exceeds performance on most tasks. Beyond QA and reading comprehension, D2-LoRA improves generative tasks (plus 1.2 ROUGE-L and plus 1.1 percent win rate) and shows 36 percent lower training volatility. The merge preserves numerical fidelity (mean gap about 0.03 percentage points) and recovers about 1.91x evaluation throughput. Training overhead is 19 percent, comparable to DoRA, and decreases with longer input sequences. We provide a geometric analysis explaining how the projection stabilizes training, together with ablation studies isolating the contribution of each design component.",
      "authors": [
        "Nozomu Fujisawa",
        "Masaaki Kondo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 13:19:42+00:00",
      "link": "https://arxiv.org/pdf/2602.14728v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14726v1",
      "title": "ManeuverNet: A Soft Actor-Critic Framework for Precise Maneuvering of Double-Ackermann-Steering Robots with Optimized Reward Functions",
      "abstract": "Autonomous control of double-Ackermann-steering robots is essential in agricultural applications, where robots must execute precise and complex maneuvers within a limited space. Classical methods, such as the Timed Elastic Band (TEB) planner, can address this problem, but they rely on parameter tuning, making them highly sensitive to changes in robot configuration or environment and impractical to deploy without constant recalibration. At the same time, end-to-end deep reinforcement learning (DRL) methods often fail due to unsuitable reward functions for non-holonomic constraints, resulting in sub-optimal policies and poor generalization. To address these challenges, this paper presents ManeuverNet, a DRL framework tailored for double-Ackermann systems, combining Soft Actor-Critic with CrossQ. Furthermore, ManeuverNet introduces four specifically designed reward functions to support maneuver learning. Unlike prior work, ManeuverNet does not depend on expert data or handcrafted guidance. We extensively evaluate ManeuverNet against both state-of-the-art DRL baselines and the TEB planner. Experimental results demonstrate that our framework substantially improves maneuverability and success rates, achieving more than a 40% gain over DRL baselines. Moreover, ManeuverNet effectively mitigates the strong parameter sensitivity observed in the TEB planner. In real-world trials, ManeuverNet achieved up to a 90% increase in maneuvering trajectory efficiency, highlighting its robustness and practical applicability.",
      "authors": [
        "Kohio Deflesselle",
        "Mélodie Daniel",
        "Aly Magassouba",
        "Miguel Aranda",
        "Olivier Ly"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-16 13:19:04+00:00",
      "link": "https://arxiv.org/pdf/2602.14726v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15086v1",
      "title": "M-polynomial Based Mathematical Formulation of the Hyperbolic Sombor Index",
      "abstract": "The numerical values extracted from a graph that indicates its topology are called topological indices. A contemporary and efficient method is to compute a graph's topological indices using the graph polynomial that corresponds to it. This method of identifying degree-based topological indices involves the use of the M-polynomial. Very recently, in 2025, the hyperbolic Sombor index (HSO) was proposed and shows its chemical applicability for octane isomers and the structure sensitivity and abruptness for octane, nonane, and decane isomers, respectively. In this work, we establish the closed derivation formula for the above-mentioned index of a graph based on its M-polynomial. Additionally, we use our proposed derivation formula to calculate the hyperbolic Sombor index of a few standard graphs and chemical families. Moreover, we provide the numerical and graphical representations for the M-polynomial and the computed HSO index of the chemical families.",
      "authors": [
        "Jayjit Barman",
        "Shibsankar Das"
      ],
      "primary_category": "cs.DM",
      "categories": [
        "cs.DM"
      ],
      "published": "2026-02-16 13:09:02+00:00",
      "link": "https://arxiv.org/pdf/2602.15086v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14722v1",
      "title": "Geometric Characterization of Context-Free Intersections via the Inner Segment Dichotomy",
      "abstract": "The intersection of two context-free languages is not generally context-free, but no geometric criterion has characterized when it remains so. The crossing gap (max(i'-i, j'-j) for two crossing push-pop arcs) is the natural candidate. We refute this: we exhibit CFLs whose intersection is CFL despite unbounded-gap crossings. The governing quantity is the inner segment measure: for crossing arcs inducing a decomposition w = P1 P2 P3 P4, it is max(|P2|,|P3|), the length of the longer inner segment between interleaved crossing endpoints. We prove a dichotomy for this measure: bounded inner segments imply context-freeness via a finite buffer construction; growing inner segments with pump-sensitive linkages imply non-context-freeness. The inner segment concept applies to all CFL intersections; the strictness of the resulting characterization depends on the language class. For block-counting CFLs (languages requiring equality among designated pairs of block lengths), the dichotomy is complete: the intersection is CFL if and only if the combined arcs are jointly well-nested. For general CFLs, the CFL direction is unconditional; the non-CFL direction requires pump-sensitive linkages whose necessity is the main open problem, reducing the general CFL intersection problem to a specific property of pump-sensitive decompositions.",
      "authors": [
        "Jorge Miguel Silva"
      ],
      "primary_category": "cs.FL",
      "categories": [
        "cs.FL",
        "cs.CC"
      ],
      "published": "2026-02-16 13:08:22+00:00",
      "link": "https://arxiv.org/pdf/2602.14722v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14721v1",
      "title": "WebWorld: A Large-Scale World Model for Web Agent Training",
      "abstract": "Web agents require massive trajectories to generalize, yet real-world training is constrained by network latency, rate limits, and safety risks. We introduce \\textbf{WebWorld} series, the first open-web simulator trained at scale. While existing simulators are restricted to closed environments with thousands of trajectories, WebWorld leverages a scalable data pipeline to train on 1M+ open-web interactions, supporting reasoning, multi-format data, and long-horizon simulations of 30+ steps. For intrinsic evaluation, we introduce WebWorld-Bench with dual metrics spanning nine dimensions, where WebWorld achieves simulation performance comparable to Gemini-3-Pro. For extrinsic evaluation, Qwen3-14B trained on WebWorld-synthesized trajectories improves by +9.2\\% on WebArena, reaching performance comparable to GPT-4o. WebWorld enables effective inference-time search, outperforming GPT-5 as a world model. Beyond web simulation, WebWorld exhibits cross-domain generalization to code, GUI, and game environments, providing a replicable recipe for world model construction.",
      "authors": [
        "Zikai Xiao",
        "Jianhong Tu",
        "Chuhang Zou",
        "Yuxin Zuo",
        "Zhi Li",
        "Peng Wang",
        "Bowen Yu",
        "Fei Huang",
        "Junyang Lin",
        "Zuozhu Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 13:06:49+00:00",
      "link": "https://arxiv.org/pdf/2602.14721v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14717v1",
      "title": "Optimal Program Synthesis via Abstract Interpretation",
      "abstract": "We consider the problem of synthesizing programs with numerical constants that optimize a quantitative objective, such as accuracy, over a set of input-output examples. We propose a general framework for optimal synthesis of such programs in a given domain specific language (DSL), with provable optimality guarantees. Our framework enumerates programs in a general search graph, where nodes represent subsets of concrete programs. To improve scalability, it uses A* search in conjunction with a search heuristic based on abstract interpretation; intuitively, this heuristic establishes upper bounds on the value of subtrees in the search graph, enabling the synthesizer to identify and prune subtrees that are provably suboptimal. In addition, we propose a natural strategy for constructing abstract transformers for monotonic semantics, which is a common property for components in DSLs for data classification. Finally, we implement our approach in the context of two such existing DSLs, demonstrating that our algorithm is more scalable than existing optimal synthesizers.",
      "authors": [
        "Stephen Mell",
        "Steve Zdancewic",
        "Osbert Bastani"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL"
      ],
      "published": "2026-02-16 13:02:53+00:00",
      "link": "https://arxiv.org/pdf/2602.14717v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14710v1",
      "title": "Orcheo: A Modular Full-Stack Platform for Conversational Search",
      "abstract": "Conversational search (CS) requires a complex software engineering pipeline that integrates query reformulation, ranking, and response generation. CS researchers currently face two barriers: the lack of a unified framework for efficiently sharing contributions with the community, and the difficulty of deploying end-to-end prototypes needed for user evaluation. We introduce Orcheo, an open-source platform designed to bridge this gap. Orcheo offers three key advantages: (i) A modular architecture promotes component reuse through single-file node modules, facilitating sharing and reproducibility in CS research; (ii) Production-ready infrastructure bridges the prototype-to-system gap via dual execution modes, secure credential management, and execution telemetry, with built-in AI coding support that lowers the learning curve; (iii) Starter-kit assets include 50+ off-the-shelf components for query understanding, ranking, and response generation, enabling the rapid bootstrapping of complete CS pipelines. We describe the framework architecture and validate Orcheo's utility through case studies that highlight modularity and ease of use. Orcheo is released as open source under the MIT License at https://github.com/ShaojieJiang/orcheo.",
      "authors": [
        "Shaojie Jiang",
        "Svitlana Vakulenko",
        "Maarten de Rijke"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-02-16 12:56:57+00:00",
      "link": "https://arxiv.org/pdf/2602.14710v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14708v1",
      "title": "A Unified Mathematical Framework for Distributed Data Fabrics: Categorical Hypergraph Models",
      "abstract": "Current distributed data fabrics lack a rigorous mathematical foundation, often relying on ad-hoc architectures that struggle with consistency, lineage, and scale. We propose a mathematical framework for data fabrics, unifying heterogeneous data management in distributed systems through a hypergraph-based structure \\( \\mathcal{F} = (D, M, G, T, P, A) \\). Datasets, metadata, transformations, policies, and analytics are modeled over a distributed system \\( Σ= (N, C) \\), with multi-way relationships encoded in a hypergraph \\( G = (V, E) \\). A categorical approach, with datasets as objects and transformations as morphisms, supports operations like data integration and federated learning. The hypergraph is embedded into a modular tensor category, capturing relational symmetries via braided monoidal structures, with geometric analogies to Hurwitz spaces enriching the algebraic modeling. We prove the NP-hardness of critical tasks, such as schema matching and dynamic partitioning, and propose spectral methods and symmetry-based alignments for scalable solutions. The framework ensures consistency, completeness, and causality under CAP and CAL theorems, leveraging sparse incidence matrices and braiding actions for fault-tolerant operations.",
      "authors": [
        "T. Shaska",
        "I. Kotsireas"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "math.CT"
      ],
      "published": "2026-02-16 12:52:51+00:00",
      "link": "https://arxiv.org/pdf/2602.14708v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14706v1",
      "title": "Adaptive Autoguidance for Item-Side Fairness in Diffusion Recommender Systems",
      "abstract": "Diffusion recommender systems achieve strong recommendation accuracy but often suffer from popularity bias, resulting in unequal item exposure. To address this shortcoming, we introduce A2G-DiffRec, a diffusion recommender that incorporates adaptive autoguidance, where the main model is guided by a less-trained version of itself. Instead of using a fixed guidance weight, A2G-DiffRec learns to adaptively weigh the outputs of the main and weak models during training, supervised by a popularity regularization that promotes balanced exposure across items with different popularity levels. Experimental results on the MovieLens-1M, Foursquare-Tokyo, and Music4All-Onion datasets show that A2G-DiffRec is effective in enhancing item-side fairness at a marginal cost of accuracy reduction compared to existing guided diffusion recommenders and other non-diffusion baselines.",
      "authors": [
        "Zihan Li",
        "Gustavo Escobedo",
        "Marta Moscati",
        "Oleg Lesota",
        "Markus Schedl"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-16 12:52:31+00:00",
      "link": "https://arxiv.org/pdf/2602.14706v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14705v1",
      "title": "It's a Matter of Time: Three Lessons on Long-Term Motion for Perception",
      "abstract": "Temporal information has long been considered to be essential for perception. While there is extensive research on the role of image information for perceptual tasks, the role of the temporal dimension remains less well understood: What can we learn about the world from long-term motion information? What properties does long-term motion information have for visual learning? We leverage recent success in point-track estimation, which offers an excellent opportunity to learn temporal representations and experiment on a variety of perceptual tasks. We draw 3 clear lessons: 1) Long-term motion representations contain information to understand actions, but also objects, materials, and spatial information, often even better than images. 2) Long-term motion representations generalize far better than image representations in low-data settings and in zero-shot tasks. 3) The very low dimensionality of motion information makes motion representations a better trade-off between GFLOPs and accuracy than standard video representations, and used together they achieve higher performance than video representations alone. We hope these insights will pave the way for the design of future models that leverage the power of long-term motion information for perception.",
      "authors": [
        "Willem Davison",
        "Xinyue Hao",
        "Laura Sevilla-Lara"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 12:51:43+00:00",
      "link": "https://arxiv.org/pdf/2602.14705v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14704v1",
      "title": "Evaluation of Dynamic Vector Bin Packing for Virtual Machine Placement",
      "abstract": "Virtual machine placement is a crucial challenge in cloud computing for efficiently utilizing physical machine resources in data centers. Virtual machine placement can be formulated as a MinUsageTime Dynamic Vector Bin Packing (DVBP) problem, aiming to minimize the total usage time of the physical machines. This paper evaluates state-of-the-art MinUsageTime DVBP algorithms in non-clairvoyant, clairvoyant and learning-augmented online settings, where item durations (virtual machine lifetimes) are unknown, known and predicted, respectively. Besides the algorithms taken from the literature, we also develop several new algorithms or enhancements. Empirical experimentation is carried out with real-world datasets of Microsoft Azure. The insights from the experimental results are discussed to explore the structures of algorithms and promising design elements that work well in practice.",
      "authors": [
        "Zong Yu Lee",
        "Xueyan Tang"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.DS"
      ],
      "published": "2026-02-16 12:51:35+00:00",
      "link": "https://arxiv.org/pdf/2602.14704v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14701v1",
      "title": "Unbiased Approximate Vector-Jacobian Products for Efficient Backpropagation",
      "abstract": "In this work we introduce methods to reduce the computational and memory costs of training deep neural networks. Our approach consists in replacing exact vector-jacobian products by randomized, unbiased approximations thereof during backpropagation. We provide a theoretical analysis of the trade-off between the number of epochs needed to achieve a target precision and the cost reduction for each epoch. We then identify specific unbiased estimates of vector-jacobian products for which we establish desirable optimality properties of minimal variance under sparsity constraints. Finally we provide in-depth experiments on multi-layer perceptrons, BagNets and Visual Transfomers architectures. These validate our theoretical results, and confirm the potential of our proposed unbiased randomized backpropagation approach for reducing the cost of deep learning.",
      "authors": [
        "Killian Bakong",
        "Laurent Massoulié",
        "Edouard Oyallon",
        "Kevin Scaman"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-16 12:40:59+00:00",
      "link": "https://arxiv.org/pdf/2602.14701v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14699v1",
      "title": "Qute: Towards Quantum-Native Database",
      "abstract": "This paper envisions a quantum database (Qute) that treats quantum computation as a first-class execution option. Unlike prior simulation-based methods that either run quantum algorithms on classical machines or adapt existing databases for quantum simulation, Qute instead (i) compiles an extended form of SQL into gate-efficient quantum circuits, (ii) employs a hybrid optimizer to dynamically select between quantum and classical execution plans, (iii) introduces selective quantum indexing, and (iv) designs fidelity-preserving storage to mitigate current qubit constraints. We also present a three-stage evolution roadmap toward quantum-native database. Finally, by deploying Qute on a real quantum processor (origin_wukong), we show that it outperforms a classical baseline at scale, and we release an open-source prototype at https://github.com/weAIDB/Qute.",
      "authors": [
        "Muzhi Chen",
        "Xuanhe Zhou",
        "Wei Zhou",
        "Bangrui Xu",
        "Surui Tang",
        "Guoliang Li",
        "Bingsheng He",
        "Yeye He",
        "Yitong Song",
        "Fan Wu"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.AR"
      ],
      "published": "2026-02-16 12:39:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14699v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14697v1",
      "title": "Evolutionary System Prompt Learning can Facilitate Reinforcement Learning for LLMs",
      "abstract": "Building agentic systems that can autonomously self-improve from experience is a longstanding goal of AI. Large language models (LLMs) today primarily self-improve via two mechanisms: self-reflection for context updates, and reinforcement learning (RL) for weight updates. In this work, we propose Evolutionary System Prompt Learning (E-SPL), a method for jointly improving model contexts and model weights. In each RL iteration, E-SPL selects multiple system prompts and runs rollouts with each in parallel. It applies RL updates to model weights conditioned on each system prompt, and evolutionary updates to the system prompt population via LLM-driven mutation and crossover. Each system prompt has a TrueSkill rating for evolutionary selection, updated from relative performance within each RL iteration batch. E-SPL encourages a natural division between declarative knowledge encoded in prompts and procedural knowledge encoded in weights, resulting in improved performance across reasoning and agentic tasks. For instance, in an easy-to-hard (AIME $\\rightarrow$ BeyondAIME) generalization setting, E-SPL improves RL success rate from 38.8% $\\rightarrow$ 45.1% while also outperforming reflective prompt evolution (40.0%). Overall, our results show that coupling reinforcement learning with system prompt evolution yields consistent gains in sample efficiency and generalization. Code: https://github.com/LunjunZhang/E-SPL",
      "authors": [
        "Lunjun Zhang",
        "Ryan Chen",
        "Bradly C. Stadie"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-16 12:34:27+00:00",
      "link": "https://arxiv.org/pdf/2602.14697v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14696v1",
      "title": "A Critical Look at Targeted Instruction Selection: Disentangling What Matters (and What Doesn't)",
      "abstract": "Instruction fine-tuning of large language models (LLMs) often involves selecting a subset of instruction training data from a large candidate pool, using a small query set from the target task. Despite growing interest, the literature on targeted instruction selection remains fragmented and opaque: methods vary widely in selection budgets, often omit zero-shot baselines, and frequently entangle the contributions of key components. As a result, practitioners lack actionable guidance on selecting instructions for their target tasks. In this work, we aim to bring clarity to this landscape by disentangling and systematically analyzing the two core ingredients: data representation and selection algorithms. Our framework enables controlled comparisons across models, tasks, and budgets. We find that only gradient-based data representations choose subsets whose similarity to the query consistently predicts performance across datasets and models. While no single method dominates, gradient-based representations paired with a greedy round-robin selection algorithm tend to perform best on average at low budgets, but these benefits diminish at larger budgets. Finally, we unify several existing selection algorithms as forms of approximate distance minimization between the selected subset and the query set, and support this view with new generalization bounds. More broadly, our findings provide critical insights and a foundation for more principled data selection in LLM fine-tuning. The code is available at https://github.com/dcml-lab/targeted-instruction-selection.",
      "authors": [
        "Nihal V. Nayak",
        "Paula Rodriguez-Diaz",
        "Neha Hulkund",
        "Sara Beery",
        "David Alvarez-Melis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 12:33:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14696v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15084v1",
      "title": "TokaMind: A Multi-Modal Transformer Foundation Model for Tokamak Plasma Dynamics",
      "abstract": "We present TokaMind, an open-source foundation model framework for fusion plasma modeling, based on a Multi-Modal Transformer (MMT) and trained on heterogeneous tokamak diagnostics from the publicly available MAST dataset. TokaMind supports multiple data modalities (time-series, 2D profiles, and videos) with different sampling rates, robust missing-signal handling, and efficient task adaptation via selectively loading and freezing four model components. To represent multi-modal signals, we use a training-free Discrete Cosine Transform embedding (DCT3D) and provide a clean interface for alternative embeddings (e.g., Variational Autoencoders - VAEs). We evaluate TokaMind on the recently introduced MAST benchmark TokaMark, comparing training and embedding strategies. Our results show that fine-tuned TokaMind outperforms the benchmark baseline on all but one task, and that, for several tasks, lightweight fine-tuning yields better performance than training the same architecture from scratch under a matched epoch budget. These findings highlight the benefits of multi-modal pretraining for tokamak plasma dynamics and provide a practical, extensible foundation for future fusion modeling tasks. Training code and model weights will be made publicly available.",
      "authors": [
        "Tobia Boschi",
        "Andrea Loreti",
        "Nicola C. Amorisco",
        "Rodrigo H. Ordonez-Hurtado",
        "Cécile Rousseau",
        "George K. Holt",
        "Eszter Székely",
        "Alexander Whittle",
        "Samuel Jackson",
        "Adriano Agnello",
        "Stanislas Pamela",
        "Alessandra Pascale",
        "Robert Akers",
        "Juan Bernabe Moreno",
        "Vassil Alexandrov",
        "Mykhaylo Zayats"
      ],
      "primary_category": "physics.plasm-ph",
      "categories": [
        "physics.plasm-ph",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-16 12:26:07+00:00",
      "link": "https://arxiv.org/pdf/2602.15084v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14691v1",
      "title": "Removing Planner Bias in Goal Recognition Through Multi-Plan Dataset Generation",
      "abstract": "Autonomous agents require some form of goal and plan recognition to interact in multiagent settings. Unfortunately, all existing goal recognition datasets suffer from a systematical bias induced by the planning systems that generated them, namely heuristic-based forward search. This means that existing datasets lack enough challenge for more realistic scenarios (e.g., agents using different planners), which impacts the evaluation of goal recognisers with respect to using different planners for the same goal. In this paper, we propose a new method that uses top-k planning to generate multiple, different, plans for the same goal hypothesis, yielding benchmarks that mitigate the bias found in the current dataset. This allows us to introduce a new metric called Version Coverage Score (VCS) to measure the resilience of the goal recogniser when inferring a goal based on different sets of plans. Our results show that the resilience of the current state-of-the-art goal recogniser degrades substantially under low observability settings.",
      "authors": [
        "Mustafa F. Abdelwahed",
        "Felipe Meneguzzi Kin Max Piamolini Gusmao",
        "Joan Espasa"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 12:25:35+00:00",
      "link": "https://arxiv.org/pdf/2602.14691v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14690v1",
      "title": "Configuring Agentic AI Coding Tools: An Exploratory Study",
      "abstract": "Agentic AI coding tools with autonomous capabilities beyond conversational content generation increasingly automate repetitive and time-consuming software development tasks. Developers can configure these tools through versioned repository-level artifacts such as Markdown and JSON files. In this paper, we present a systematic analysis of configuration mechanisms for agentic AI coding tools, covering Claude Code, GitHub Copilot, Cursor, Gemini, and Codex. We identify eight configuration mechanisms and, in an empirical study of 2,926 GitHub repositories, examine whether and how they are adopted. We then explore Context Files, Skills, and Subagents, that is, three mechanisms available across tools, in more detail. Our findings reveal three trends. First, Context Files dominate the configuration landscape and are often the sole mechanism in a repository, with AGENTS$.$md emerging as an interoperable standard across tools. Second, advanced mechanisms such as Skills and Subagents are only shallowly adopted: most repositories define only one or two artifacts, and Skills predominantly rely on static instructions rather than executable workflows. Third, distinct configuration cultures are forming around different tools, with Claude Code users employing the broadest range of mechanisms. These findings establish an empirical baseline for longitudinal and experimental research on how configuration strategies evolve and affect agent performance as agentic AI coding tools mature.",
      "authors": [
        "Matthias Galster",
        "Seyedmoein Mohsenimofidi",
        "Jai Lal Lulla",
        "Muhammad Auwal Abubakar",
        "Christoph Treude",
        "Sebastian Baltes"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-16 12:24:28+00:00",
      "link": "https://arxiv.org/pdf/2602.14690v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14689v1",
      "title": "Exposing the Systematic Vulnerability of Open-Weight Models to Prefill Attacks",
      "abstract": "As the capabilities of large language models continue to advance, so does their potential for misuse. While closed-source models typically rely on external defenses, open-weight models must primarily depend on internal safeguards to mitigate harmful behavior. Prior red-teaming research has largely focused on input-based jailbreaking and parameter-level manipulations. However, open-weight models also natively support prefilling, which allows an attacker to predefine initial response tokens before generation begins. Despite its potential, this attack vector has received little systematic attention. We present the largest empirical study to date of prefill attacks, evaluating over 20 existing and novel strategies across multiple model families and state-of-the-art open-weight models. Our results show that prefill attacks are consistently effective against all major contemporary open-weight models, revealing a critical and previously underexplored vulnerability with significant implications for deployment. While certain large reasoning models exhibit some robustness against generic prefilling, they remain vulnerable to tailored, model-specific strategies. Our findings underscore the urgent need for model developers to prioritize defenses against prefill attacks in open-weight LLMs.",
      "authors": [
        "Lukas Struppek",
        "Adam Gleave",
        "Kellin Pelrine"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-16 12:24:21+00:00",
      "link": "https://arxiv.org/pdf/2602.14689v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14687v1",
      "title": "SynthSAEBench: Evaluating Sparse Autoencoders on Scalable Realistic Synthetic Data",
      "abstract": "Improving Sparse Autoencoders (SAEs) requires benchmarks that can precisely validate architectural innovations. However, current SAE benchmarks on LLMs are often too noisy to differentiate architectural improvements, and current synthetic data experiments are too small-scale and unrealistic to provide meaningful comparisons. We introduce SynthSAEBench, a toolkit for generating large-scale synthetic data with realistic feature characteristics including correlation, hierarchy, and superposition, and a standardized benchmark model, SynthSAEBench-16k, enabling direct comparison of SAE architectures. Our benchmark reproduces several previously observed LLM SAE phenomena, including the disconnect between reconstruction and latent quality metrics, poor SAE probing results, and a precision-recall trade-off mediated by L0. We further use our benchmark to identify a new failure mode: Matching Pursuit SAEs exploit superposition noise to improve reconstruction without learning ground-truth features, suggesting that more expressive encoders can easily overfit. SynthSAEBench complements LLM benchmarks by providing ground-truth features and controlled ablations, enabling researchers to precisely diagnose SAE failure modes and validate architectural improvements before scaling to LLMs.",
      "authors": [
        "David Chanin",
        "Adrià Garriga-Alonso"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-16 12:22:00+00:00",
      "link": "https://arxiv.org/pdf/2602.14687v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14684v1",
      "title": "Identification of random material properties as stochastic inversion problem",
      "abstract": "Heterogeneity of many building materials complicates numerical modelling of structural behaviour. The material randomicity can be manifested by different values of material parameters of each material specimen. To capture inherent variability of heterogeneous materials, the model parameters describing the material properties are considered as random variables and their identification consists in solving a~stochastic inversion problem. The stochastic inversion is based on searching for probabilistic description of model parameters which provides the distribution of the model response corresponding to the distribution of the observed data. The paper presents two different formulations of the stochastic inversion problem. The first formulation arises from the Bayesian inference of uncertain statistical moments of a prescribed parameters' distribution while the main idea of the second one utilizes nonlinear transformation of random model parameters from distribution of the observed data.",
      "authors": [
        "Eliška Kočková",
        "Anna Kučerová"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE",
        "math-ph"
      ],
      "published": "2026-02-16 12:17:20+00:00",
      "link": "https://arxiv.org/pdf/2602.14684v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14682v1",
      "title": "Exposing Diversity Bias in Deep Generative Models: Statistical Origins and Correction of Diversity Error",
      "abstract": "Deep generative models have achieved great success in producing high-quality samples, making them a central tool across machine learning applications. Beyond sample quality, an important yet less systematically studied question is whether trained generative models faithfully capture the diversity of the underlying data distribution. In this work, we address this question by directly comparing the diversity of samples generated by state-of-the-art models with that of test samples drawn from the target data distribution, using recently proposed reference-free entropy-based diversity scores, Vendi and RKE. Across multiple benchmark datasets, we find that test data consistently attains substantially higher Vendi and RKE diversity scores than the generated samples, suggesting a systematic downward diversity bias in modern generative models. To understand the origin of this bias, we analyze the finite-sample behavior of entropy-based diversity scores and show that their expected values increase with sample size, implying that diversity estimated from finite training sets could inherently underestimate the diversity of the true distribution. As a result, optimizing the generators to minimize divergence to empirical data distributions would induce a loss of diversity. Finally, we discuss potential diversity-aware regularization and guidance strategies based on Vendi and RKE as principled directions for mitigating this bias, and provide empirical evidence suggesting their potential to improve the results.",
      "authors": [
        "Farzan Farnia",
        "Mohammad Jalali",
        "Azim Ospanov"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "math.OC"
      ],
      "published": "2026-02-16 12:15:34+00:00",
      "link": "https://arxiv.org/pdf/2602.14682v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14681v1",
      "title": "ST-EVO: Towards Generative Spatio-Temporal Evolution of Multi-Agent Communication Topologies",
      "abstract": "LLM-powered Multi-Agent Systems (MAS) have emerged as an effective approach towards collaborative intelligence, and have attracted wide research interests. Among them, ``self-evolving'' MAS, treated as a more flexible and powerful technical route, can construct task-adaptive workflows or communication topologies, instead of relying on a predefined static structue template. Current self-evolving MAS mainly focus on Spatial Evolving or Temporal Evolving paradigm, which only considers the single dimension of evolution and does not fully incentivize LLMs' collaborative capability. In this work, we start from a novel Spatio-Temporal perspective by proposing ST-EVO, which supports dialogue-wise communication scheduling with a compact yet powerful flow-matching based Scheduler. To make precise Spatio-Temporal scheduling, ST-EVO can also perceive the uncertainty of MAS, and possesses self-feedback ability to learn from accumulated experience. Extensive experiments on nine benchmarks demonstrate the state-of-the-art performance of ST-EVO, achieving about 5%--25% accuracy improvement.",
      "authors": [
        "Xingjian Wu",
        "Xvyuan Liu",
        "Junkai Lu",
        "Siyuan Wang",
        "Yang Shu",
        "Jilin Hu",
        "Chenjuan Guo",
        "Bin Yang"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "published": "2026-02-16 12:13:03+00:00",
      "link": "https://arxiv.org/pdf/2602.14681v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14679v1",
      "title": "Universal Image Immunization against Diffusion-based Image Editing via Semantic Injection",
      "abstract": "Recent advances in diffusion models have enabled powerful image editing capabilities guided by natural language prompts, unlocking new creative possibilities. However, they introduce significant ethical and legal risks, such as deepfakes and unauthorized use of copyrighted visual content. To address these risks, image immunization has emerged as a promising defense against AI-driven semantic manipulation. Yet, most existing approaches rely on image-specific adversarial perturbations that require individual optimization for each image, thereby limiting scalability and practicality. In this paper, we propose the first universal image immunization framework that generates a single, broadly applicable adversarial perturbation specifically designed for diffusion-based editing pipelines. Inspired by universal adversarial perturbation (UAP) techniques used in targeted attacks, our method generates a UAP that embeds a semantic target into images to be protected. Simultaneously, it suppresses original content to effectively misdirect the model's attention during editing. As a result, our approach effectively blocks malicious editing attempts by overwriting the original semantic content in the image via the UAP. Moreover, our method operates effectively even in data-free settings without requiring access to training data or domain knowledge, further enhancing its practicality and broad applicability in real-world scenarios. Extensive experiments show that our method, as the first universal immunization approach, significantly outperforms several baselines in the UAP setting. In addition, despite the inherent difficulty of universal perturbations, our method also achieves performance on par with image-specific methods under a more restricted perturbation budget, while also exhibiting strong black-box transferability across different diffusion models.",
      "authors": [
        "Chanhui Lee",
        "Seunghyun Shin",
        "Donggyu Choi",
        "Hae-gon Jeon",
        "Jeany Son"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 12:08:37+00:00",
      "link": "https://arxiv.org/pdf/2602.14679v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14677v1",
      "title": "Kernel-based optimization of measurement operators for quantum reservoir computers",
      "abstract": "Finding optimal measurement operators is crucial for the performance of quantum reservoir computers (QRCs), since they employ a fixed quantum feature map. We formulate the training of both stateless (quantum extreme learning machines, QELMs) and stateful (memory dependent) QRCs in the framework of kernel ridge regression. This approach renders an optimal measurement operator that minimizes prediction error for a given reservoir and training dataset. For large qubit numbers, this method is more efficient than the conventional training of QRCs. We discuss efficiency and practical implementation strategies, including Pauli basis decomposition and operator diagonalization, to adapt the optimal observable to hardware constraints. Numerical experiments on image classification and time series prediction tasks demonstrate the effectiveness of this approach, which can also be applied to other quantum ML models.",
      "authors": [
        "Markus Gross",
        "Hans-Martin Rieser"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "published": "2026-02-16 12:04:42+00:00",
      "link": "https://arxiv.org/pdf/2602.14677v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14676v1",
      "title": "GREAT-EER: Graph Edge Attention Network for Emergency Evacuation Responses",
      "abstract": "Emergency situations that require the evacuation of urban areas can arise from man-made causes (e.g., terrorist attacks or industrial accidents) or natural disasters, the latter becoming more frequent due to climate change. As a result, effective and fast methods to develop evacuation plans are of great importance. In this work, we identify and propose the Bus Evacuation Orienteering Problem (BEOP), an NP-hard combinatorial optimization problem with the goal of evacuating as many people from an affected area by bus in a short, predefined amount of time. The purpose of bus-based evacuation is to reduce congestion and disorder that arises in purely car-focused evacuation scenarios. To solve the BEOP, we propose a deep reinforcement learning-based method utilizing graph learning, which, once trained, achieves fast inference speed and is able to create evacuation routes in fractions of seconds. We can bound the gap of our evacuation plans using an MILP formulation. To validate our method, we create evacuation scenarios for San Francisco using real-world road networks and travel times. We show that we achieve near-optimal solution quality and are further able to investigate how many evacuation vehicles are necessary to achieve certain bus-based evacuation quotas given a predefined evacuation time while keeping run time adequate.",
      "authors": [
        "Attila Lischka",
        "Balázs Kulcsár"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-16 12:04:14+00:00",
      "link": "https://arxiv.org/pdf/2602.14676v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14675v1",
      "title": "Crowdsourcing Piedmontese to Test LLMs on Non-Standard Orthography",
      "abstract": "We present a crowdsourced dataset for Piedmontese, an endangered Romance language of northwestern Italy. The dataset comprises 145 Italian-Piedmontese parallel sentences derived from Flores+, with translations produced by speakers writing in their natural orthographic style rather than adhering to standardized conventions, along with manual word alignment. We use this resource to benchmark several large language models on tokenization parity, topic classification, and machine translation. Our analysis reveals that Piedmontese incurs a tokenization penalty relative to higher-resource Romance languages, yet LLMs achieve classification performance approaching that of Italian, French, and English. Machine translation results are asymmetric: models translate adequately from Piedmontese into high-resource languages, but generation into Piedmontese remains challenging. The dataset and code are publicly released.",
      "authors": [
        "Gianluca Vico",
        "Jindřich Libovický"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 12:02:29+00:00",
      "link": "https://arxiv.org/pdf/2602.14675v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14674v2",
      "title": "From User Preferences to Base Score Extraction Functions in Gradual Argumentation (with Appendix)",
      "abstract": "Gradual argumentation is a field of symbolic AI which is attracting attention for its ability to support transparent and contestable AI systems. It is considered a useful tool in domains such as decision-making, recommendation, debate analysis, and others. The outcomes in such domains are usually dependent on the arguments' base scores, which must be selected carefully. Often, this selection process requires user expertise and may not always be straightforward. On the other hand, organising the arguments by preference could simplify the task. In this work, we introduce \\emph{Base Score Extraction Functions}, which provide a mapping from users' preferences over arguments to base scores. These functions can be applied to the arguments of a \\emph{Bipolar Argumentation Framework} (BAF), supplemented with preferences, to obtain a \\emph{Quantitative Bipolar Argumentation Framework} (QBAF), allowing the use of well-established computational tools in gradual argumentation. We outline the desirable properties of base score extraction functions, discuss some design choices, and provide an algorithm for base score extraction. Our method incorporates an approximation of non-linearities in human preferences to allow for better approximation of the real ones. Finally, we evaluate our approach both theoretically and experimentally in a robotics setting, and offer recommendations for selecting appropriate gradual semantics in practice.",
      "authors": [
        "Aniol Civit",
        "Antonio Rago",
        "Antonio Andriella",
        "Guillem Alenyà",
        "Francesca Toni"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 12:01:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14674v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14672v1",
      "title": "MeFEm: Medical Face Embedding model",
      "abstract": "We present MeFEm, a vision model based on a modified Joint Embedding Predictive Architecture (JEPA) for biometric and medical analysis from facial images. Key modifications include an axial stripe masking strategy to focus learning on semantically relevant regions, a circular loss weighting scheme, and the probabilistic reassignment of the CLS token for high quality linear probing. Trained on a consolidated dataset of curated images, MeFEm outperforms strong baselines like FaRL and Franca on core anthropometric tasks despite using significantly less data. It also shows promising results on Body Mass Index (BMI) estimation, evaluated on a novel, consolidated closed-source dataset that addresses the domain bias prevalent in existing data. Model weights are available at https://huggingface.co/boretsyury/MeFEm , offering a strong baseline for future work in this domain.",
      "authors": [
        "Yury Borets",
        "Stepan Botman"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 11:51:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14672v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14670v1",
      "title": "FactorMiner: A Self-Evolving Agent with Skills and Experience Memory for Financial Alpha Discovery",
      "abstract": "Formulaic alpha factor mining is a critical yet challenging task in quantitative investment, characterized by a vast search space and the need for domain-informed, interpretable signals. However, finding novel signals becomes increasingly difficult as the library grows due to high redundancy. We propose FactorMiner, a lightweight and flexible self-evolving agent framework designed to navigate this complex landscape through continuous knowledge accumulation. FactorMiner combines a Modular Skill Architecture that encapsulates systematic financial evaluation into executable tools with a structured Experience Memory that distills historical mining trials into actionable insights (successful patterns and failure constraints). By instantiating the Ralph Loop paradigm -- retrieve, generate, evaluate, and distill -- FactorMiner iteratively uses memory priors to guide exploration, reducing redundant search while focusing on promising directions. Experiments on multiple datasets across different assets and Markets show that FactorMiner constructs a diverse library of high-quality factors with competitive performance, while maintaining low redundancy among factors as the library scales. Overall, FactorMiner provides a practical approach to scalable discovery of interpretable formulaic alpha factors under the \"Correlation Red Sea\" constraint.",
      "authors": [
        "Yanlong Wang",
        "Jian Xu",
        "Hongkang Zhang",
        "Shao-Lun Huang",
        "Danny Dongning Sun",
        "Xiao-Ping Zhang"
      ],
      "primary_category": "q-fin.TR",
      "categories": [
        "q-fin.TR",
        "cs.MA"
      ],
      "published": "2026-02-16 11:48:52+00:00",
      "link": "https://arxiv.org/pdf/2602.14670v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14668v1",
      "title": "Near-Optimal Best-of-Both-Worlds Fairness for Few Agents",
      "abstract": "We consider the problem of fair allocation of indivisible goods among agents with additive valuations, aiming for Best-of-Both-Worlds (BoBW) fairness: a distribution over allocations that is ex-ante fair, and additionally, it is supported only on deterministic allocations that are ex-post fair. We focus on BoBW for few agents, and our main result is the design of the first BoBW algorithms achieving near-optimal fairness for three agents. For three agents, we prove the existence of an ex-ante proportional distribution whose every allocation is Epistemic EFX (EEFX) and guarantees each agent at least $\\tfrac{9}{10}$ of her MMS. As MMS allocations do not exist for three additive agents, in every allocation at least one agent might not be getting her MMS. To compensate such an agent, we also guarantee that if an agent is not getting her MMS then she is EFX-satisfied - giving her the strongest achievable envy-based guarantee. Additionally, using an FPTAS for near-MMS partitions, we present an FPTAS to compute a BoBW distribution preserving all envy-based guarantees, and also preserving all value-based guarantees up to $(1-\\varepsilon)$. We further show that exact ex-ante proportionality can be restored when dropping EEFX. To do so, we first design, for two agents and any $\\varepsilon > 0$, a Fully Polynomial-Time Approximation Scheme (FPTAS) that outputs a distribution which is ex-ante envy-free (and thus proportional) and ex-post envy-free up to any good (EFX), while guaranteeing each agent at least a $(1-\\varepsilon)$-fraction of her maximin share (MMS). We then leverage this two-agent FPTAS algorithm as a subroutine to obtain, for three agents, the FPTAS guaranteeing exact ex-ante proportionality. We note that our result for two agents essentially matches the strongest fairness and efficiency guarantees achievable in polynomial time, and thus might be of independent interest.",
      "authors": [
        "Moshe Babaioff",
        "Gefen Frosh"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT"
      ],
      "published": "2026-02-16 11:46:48+00:00",
      "link": "https://arxiv.org/pdf/2602.14668v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14666v1",
      "title": "Real-time Monocular 2D and 3D Perception of Endoluminal Scenes for Controlling Flexible Robotic Endoscopic Instruments",
      "abstract": "Endoluminal surgery offers a minimally invasive option for early-stage gastrointestinal and urinary tract cancers but is limited by surgical tools and a steep learning curve. Robotic systems, particularly continuum robots, provide flexible instruments that enable precise tissue resection, potentially improving outcomes. This paper presents a visual perception platform for a continuum robotic system in endoluminal surgery. Our goal is to utilize monocular endoscopic image-based perception algorithms to identify position and orientation of flexible instruments and measure their distances from tissues. We introduce 2D and 3D learning-based perception algorithms and develop a physically-realistic simulator that models flexible instruments dynamics. This simulator generates realistic endoluminal scenes, enabling control of flexible robots and substantial data collection. Using a continuum robot prototype, we conducted module and system-level evaluations. Results show that our algorithms improve control of flexible instruments, reducing manipulation time by over 70% for trajectory-following tasks and enhancing understanding of surgical scenarios, leading to robust endoluminal surgeries.",
      "authors": [
        "Ruofeng Wei",
        "Kai Chen",
        "Yui Lun Ng",
        "Yiyao Ma",
        "Justin Di-Lang Ho",
        "Hon Sing Tong",
        "Xiaomei Wang",
        "Jing Dai",
        "Ka-Wai Kwok",
        "Qi Dou"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-16 11:46:14+00:00",
      "link": "https://arxiv.org/pdf/2602.14666v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14664v1",
      "title": "Probing Human Articulatory Constraints in End-to-End TTS with Reverse and Mismatched Speech-Text Directions",
      "abstract": "An end-to-end (e2e) text-to-speech (TTS) system is a deep architecture that learns to associate a text string with acoustic speech patterns from a curated dataset. It is expected that all aspects associated with speech production, such as phone duration, speaker characteristics, and intonation among other things are captured in the trained TTS model to enable the synthesized speech to be natural and intelligible. Human speech is complex, involving smooth transitions between articulatory configurations (ACs). Due to anatomical constraints, some ACs are challenging to mimic or transition between. In this paper, we experimentally study if the constraints imposed by human anatomy have an implication on training an e2e-TTS systems. We experiment with two e2e-TTS architectures, namely, Tacotron-2 an autoregressive model and VITS-TTS a non-autoregressive model. In this study, we build TTS systems using (a) forward text, forward speech (conventional, e2e-TTS), (b) reverse text, reverse speech (r-e2e-TTS), and (c) reverse text, forward speech (rtfs-e2e-TTS). Experiments demonstrate that e2e-TTS systems are purely data-driven. Interestingly, the generated speech by r-e2e-TTS systems exhibits better fidelity, better perceptual intelligibility, and better naturalness",
      "authors": [
        "Parth Khadse",
        "Sunil Kumar Kopparapu"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD"
      ],
      "published": "2026-02-16 11:42:59+00:00",
      "link": "https://arxiv.org/pdf/2602.14664v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14663v1",
      "title": "Pseudo-differential-enhanced physics-informed neural networks",
      "abstract": "We present pseudo-differential enhanced physics-informed neural networks (PINNs), an extension of gradient enhancement but in Fourier space. Gradient enhancement of PINNs dictates that the PDE residual is taken to a higher differential order than prescribed by the PDE, added to the objective as an augmented term in order to improve training and overall learning fidelity. We propose the same procedure after application via Fourier transforms, since differentiating in Fourier space is multiplication with the Fourier wavenumber under suitable decay. Our methods are fast and efficient. Our methods oftentimes achieve superior PINN versus numerical error in fewer training iterations, potentially pair well with few samples in collocation, and can on occasion break plateaus in low collocation settings. Moreover, our methods are suitable for fractional derivatives. We establish that our methods improve spectral eigenvalue decay of the neural tangent kernel (NTK), and so our methods contribute towards the learning of high frequencies in early training, mitigating the effects of frequency bias up to the polynomial order and possibly greater with smooth activations. Our methods accommodate advanced techniques in PINNs, such as Fourier feature embeddings. A pitfall of discrete Fourier transforms via the Fast Fourier Transform (FFT) is mesh subjugation, and so we demonstrate compatibility of our methods for greater mesh flexibility and invariance on alternative Euclidean and non-Euclidean domains via Monte Carlo methods and otherwise.",
      "authors": [
        "Andrew Gracyk"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.NA"
      ],
      "published": "2026-02-16 11:40:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14663v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14662v1",
      "title": "Advances in Global Solvers for 3D Vision",
      "abstract": "Global solvers have emerged as a powerful paradigm for 3D vision, offering certifiable solutions to nonconvex geometric optimization problems traditionally addressed by local or heuristic methods. This survey presents the first systematic review of global solvers in geometric vision, unifying the field through a comprehensive taxonomy of three core paradigms: Branch-and-Bound (BnB), Convex Relaxation (CR), and Graduated Non-Convexity (GNC). We present their theoretical foundations, algorithmic designs, and practical enhancements for robustness and scalability, examining how each addresses the fundamental nonconvexity of geometric estimation problems. Our analysis spans ten core vision tasks, from Wahba problem to bundle adjustment, revealing the optimality-robustness-scalability trade-offs that govern solver selection. We identify critical future directions: scaling algorithms while maintaining guarantees, integrating data-driven priors with certifiable optimization, establishing standardized benchmarks, and addressing societal implications for safety-critical deployment. By consolidating theoretical foundations, practical advances, and broader impacts, this survey provides a unified perspective and roadmap toward certifiable, trustworthy perception for real-world applications. A continuously-updated literature summary and companion code tutorials are available at https://github.com/ericzzj1989/Awesome-Global-Solvers-for-3D-Vision.",
      "authors": [
        "Zhenjun Zhao",
        "Heng Yang",
        "Bangyan Liao",
        "Yingping Zeng",
        "Shaocheng Yan",
        "Yingdong Gu",
        "Peidong Liu",
        "Yi Zhou",
        "Haoang Li",
        "Javier Civera"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "published": "2026-02-16 11:40:32+00:00",
      "link": "https://arxiv.org/pdf/2602.14662v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14656v1",
      "title": "An Embarrassingly Simple Way to Optimize Orthogonal Matrices at Scale",
      "abstract": "Orthogonality constraints are ubiquitous in robust and probabilistic machine learning. Unfortunately, current optimizers are computationally expensive and do not scale to problems with hundreds or thousands of constraints. One notable exception is the Landing algorithm (Ablin et al., 2024) which, however comes at the expense of temporarily relaxing orthogonality. In this work, we revisit and improve on the ideas behind Landing, enabling the inclusion of modern adaptive optimizers while ensuring that orthogonal constraints are effectively met. Remarkably, these improvements come at little to no cost, and reduce the number of required hyperparemeters. Our algorithm POGO is fast and GPU-friendly, consisting of only 5 matrix products, and in practice maintains orthogonality at all times. On several challenging benchmarks, POGO greatly outperforms recent optimizers and shows it can optimize problems with thousands of orthogonal matrices in minutes while alternatives would take hours. As such, POGO sets a milestone to finally exploit orthogonality constraints in ML at scale. A PyTorch implementation of POGO is publicly available at https://github.com/adrianjav/pogo.",
      "authors": [
        "Adrián Javaloy",
        "Antonio Vergari"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.DG",
        "math.OC"
      ],
      "published": "2026-02-16 11:27:04+00:00",
      "link": "https://arxiv.org/pdf/2602.14656v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14655v1",
      "title": "Breaking Data Efficiency Dilemma: A Federated and Augmented Learning Framework For Alzheimer's Disease Detection via Speech",
      "abstract": "Early diagnosis of Alzheimer's Disease (AD) is crucial for delaying its progression. While AI-based speech detection is non-invasive and cost-effective, it faces a critical data efficiency dilemma due to medical data scarcity and privacy barriers. Therefore, we propose FAL-AD, a novel framework that synergistically integrates federated learning with data augmentation to systematically optimize data efficiency. Our approach delivers three key breakthroughs: First, absolute efficiency improvement through voice conversion-based augmentation, which generates diverse pathological speech samples via cross-category voice-content recombination. Second, collaborative efficiency breakthrough via an adaptive federated learning paradigm, maximizing cross-institutional benefits under privacy constraints. Finally, representational efficiency optimization by an attentive cross-modal fusion model, which achieves fine-grained word-level alignment and acoustic-textual interaction. Evaluated on ADReSSo, FAL-AD achieves a state-of-the-art multi-modal accuracy of 91.52%, outperforming all centralized baselines and demonstrating a practical solution to the data efficiency dilemma. Our source code is publicly available at https://github.com/smileix/fal-ad.",
      "authors": [
        "Xiao Wei",
        "Bin Wen",
        "Yuqin Lin",
        "Kai Li",
        "Mingyang gu",
        "Xiaobao Wang",
        "Longbiao Wang",
        "Jianwu Dang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-16 11:26:06+00:00",
      "link": "https://arxiv.org/pdf/2602.14655v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14653v1",
      "title": "Is Information Density Uniform when Utterances are Grounded on Perception and Discourse?",
      "abstract": "The Uniform Information Density (UID) hypothesis posits that speakers are subject to a communicative pressure to distribute information evenly within utterances, minimising surprisal variance. While this hypothesis has been tested empirically, prior studies are limited exclusively to text-only inputs, abstracting away from the perceptual context in which utterances are produced. In this work, we present the first computational study of UID in visually grounded settings. We estimate surprisal using multilingual vision-and-language models over image-caption data in 30 languages and visual storytelling data in 13 languages, together spanning 11 families. We find that grounding on perception consistently smooths the distribution of information, increasing both global and local uniformity across typologically diverse languages compared to text-only settings. In visual narratives, grounding in both image and discourse contexts has additional effects, with the strongest surprisal reductions occurring at the onset of discourse units. Overall, this study takes a first step towards modelling the temporal dynamics of information flow in ecologically plausible, multimodal language use, and finds that grounded language exhibits greater information uniformity, supporting a context-sensitive formulation of UID.",
      "authors": [
        "Matteo Gay",
        "Coleman Haley",
        "Mario Giulianelli",
        "Edoardo Ponti"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 11:25:00+00:00",
      "link": "https://arxiv.org/pdf/2602.14653v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14652v1",
      "title": "Temporally Flexible Transport Scheduling on Networks with Departure-Arrival Constriction and Nodal Capacity Limits",
      "abstract": "We investigate the optimal transport (OT) problem over networks, wherein supply and demand are conceptualized as temporal marginals governing departure rates of particles from source nodes and arrival rates at sink nodes. This setting extends the classical OT framework, where all mass is conventionally assumed to depart at $t = 0$ and arrive at $t = t_f$. Our generalization accommodates departures and arrivals at specified times, referred as departure--arrival(DA) constraints. In particular, we impose nodal-temporal flux constraints at source and sink nodes, characterizing two distinct scenarios: (i) Independent DA constraints, where departure and arrival rates are prescribed independently, and (ii) Coupled DA constraints, where each particle's transportation time span is explicitly specified. We establish that OT with independent DA constraints admits a multi-marginal optimal transport formulation, while the coupled DA case aligns with the unequal-dimensional OT framework. For line graphs, we analyze the existence and uniqueness of the solution path. For general graphs, we use a constructive path-based reduction and optimize over a prescribed set of paths. From a computational perspective, we consider entropic regularization of the original problem to efficiently provide solutions based on multi-marginal Sinkhorn method, making use of the graphical structure of the cost to further improve scalability. Our numerical simulation further illustrates the linear convergence rate in terms of marginal violation.",
      "authors": [
        "Anqi Dong",
        "Karl H. Johansson",
        "Johan Karlsson"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.SI",
        "eess.SY"
      ],
      "published": "2026-02-16 11:24:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14652v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14649v1",
      "title": "GradMAP: Faster Layer Pruning with Gradient Metric and Projection Compensation",
      "abstract": "Large Language Models (LLMs) exhibit strong reasoning abilities, but their high computational costs limit their practical deployment. Recent studies reveal significant redundancy in LLMs layers, making layer pruning an active research topic. Layer pruning research primarily focuses on two aspects: measuring layer importance and recovering performance after pruning. Unfortunately, the present works fail to simultaneously maintain pruning performance and efficiency. In this study, we propose GradMAP, a faster layer pruning method with \\textbf{Grad}ient \\textbf{M}etric \\textbf{A}nd \\textbf{P}rojection compensation, which consists of two stages. In the first stage, we introduce a novel metric based on gradient magnitudes, enabling a global assessment of layer importance. Note that, it requires only a single backward propagation step per pruning decision, substantially enhancing pruning efficiency. In the second stage, we first analyze the layers with the largest mean shift resulting from pruning, and then incorporate a simple yet effective projection compensation matrix to correct this drift in one step. In this way, the degradation of model performance caused by layer pruning is effectively alleviated. Extensive experiments show that GradMAP outperforms previous layer pruning methods in both pruning speed (achieving an average $4\\times$ speedup) and performance.",
      "authors": [
        "Hao Liu",
        "Guangyan Li",
        "Wensheng Zhang",
        "Yongqiang Tang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 11:14:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14649v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14648v1",
      "title": "SketchingReality: From Freehand Scene Sketches To Photorealistic Images",
      "abstract": "Recent years have witnessed remarkable progress in generative AI, with natural language emerging as the most common conditioning input. As underlying models grow more powerful, researchers are exploring increasingly diverse conditioning signals, such as depth maps, edge maps, camera parameters, and reference images, to give users finer control over generation. Among different modalities, sketches are a natural and long-standing form of human communication, enabling rapid expression of visual concepts. Previous literature has largely focused on edge maps, often misnamed 'sketches', yet algorithms that effectively handle true freehand sketches, with their inherent abstraction and distortions, remain underexplored. We pursue the challenging goal of balancing photorealism with sketch adherence when generating images from freehand input. A key obstacle is the absence of ground-truth, pixel-aligned images: by their nature, freehand sketches do not have a single correct alignment. To address this, we propose a modulation-based approach that prioritizes semantic interpretation of the sketch over strict adherence to individual edge positions. We further introduce a novel loss that enables training on freehand sketches without requiring ground-truth pixel-aligned images. We show that our method outperforms existing approaches in both semantic alignment with freehand sketch inputs and in the realism and overall quality of the generated images.",
      "authors": [
        "Ahmed Bourouis",
        "Mikhail Bessmeltsev",
        "Yulia Gryaditskaya"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 11:13:34+00:00",
      "link": "https://arxiv.org/pdf/2602.14648v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14643v2",
      "title": "Arbor: A Framework for Reliable Navigation of Critical Conversation Flows",
      "abstract": "Large language models struggle to maintain strict adherence to structured workflows in high-stakes domains such as healthcare triage. Monolithic approaches that encode entire decision structures within a single prompt are prone to instruction-following degradation as prompt length increases, including lost-in-the-middle effects and context window overflow. To address this gap, we present Arbor, a framework that decomposes decision tree navigation into specialized, node-level tasks. Decision trees are standardized into an edge-list representation and stored for dynamic retrieval. At runtime, a directed acyclic graph (DAG)-based orchestration mechanism iteratively retrieves only the outgoing edges of the current node, evaluates valid transitions via a dedicated LLM call, and delegates response generation to a separate inference step. The framework is agnostic to the underlying decision logic and model provider. Evaluated against single-prompt baselines across 10 foundation models using annotated turns from real clinical triage conversations. Arbor improves mean turn accuracy by 29.4 percentage points, reduces per-turn latency by 57.1%, and achieves an average 14.4x reduction in per-turn cost. These results indicate that architectural decomposition reduces dependence on intrinsic model capability, enabling smaller models to match or exceed larger models operating under single-prompt baselines.",
      "authors": [
        "Luís Silva",
        "Diogo Gonçalves",
        "Catarina Farinha",
        "Clara Matos",
        "Luís Ungaro"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 11:09:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14643v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14642v1",
      "title": "GenPANIS: A Latent-Variable Generative Framework for Forward and Inverse PDE Problems in Multiphase Media",
      "abstract": "Inverse problems and inverse design in multiphase media, i.e., recovering or engineering microstructures to achieve target macroscopic responses, require operating on discrete-valued material fields, rendering the problem non-differentiable and incompatible with gradient-based methods. Existing approaches either relax to continuous approximations, compromising physical fidelity, or employ separate heavyweight models for forward and inverse tasks. We propose GenPANIS, a unified generative framework that preserves exact discrete microstructures while enabling gradient-based inference through continuous latent embeddings. The model learns a joint distribution over microstructures and PDE solutions, supporting bidirectional inference (forward prediction and inverse recovery) within a single architecture. The generative formulation enables training with unlabeled data, physics residuals, and minimal labeled pairs. A physics-aware decoder incorporating a differentiable coarse-grained PDE solver preserves governing equation structure, enabling extrapolation to varying boundary conditions and microstructural statistics. A learnable normalizing flow prior captures complex posterior structure for inverse problems. Demonstrated on Darcy flow and Helmholtz equations, GenPANIS maintains accuracy on challenging extrapolative scenarios - including unseen boundary conditions, volume fractions, and microstructural morphologies, with sparse, noisy observations. It outperforms state-of-the-art methods while using 10 - 100 times fewer parameters and providing principled uncertainty quantification.",
      "authors": [
        "Matthaios Chatzopoulos",
        "Phaedon-Stelios Koutsourelakis"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-16 11:08:30+00:00",
      "link": "https://arxiv.org/pdf/2602.14642v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14641v1",
      "title": "Quantum Reservoir Computing with Neutral Atoms on a Small, Complex, Medical Dataset",
      "abstract": "Biomarker-based prediction of clinical outcomes is challenging due to nonlinear relationships, correlated features, and the limited size of many medical datasets. Classical machine-learning methods can struggle under these conditions, motivating the search for alternatives. In this work, we investigate quantum reservoir computing (QRC), using both noiseless emulation and hardware execution on the neutral-atom Rydberg processor \\textit{Aquila}. We evaluate performance with six classical machine-learning models and use SHAP to generate feature subsets. We find that models trained on emulated quantum features achieve mean test accuracies comparable to those trained on classical features, but have higher training accuracies and greater variability over data splits, consistent with overfitting. When comparing hardware execution of QRC to noiseless emulation, the models are more robust over different data splits and often exhibit statistically significant improvements in mean test accuracy. This combination of improved accuracy and increased stability is suggestive of a regularising effect induced by hardware execution. To investigate the origin of this behaviour, we examine the statistical differences between hardware and emulated quantum feature distributions. We find that hardware execution applies a structured, time-dependent transformation characterised by compression toward the mean and a progressive reduction in mutual information relative to emulation.",
      "authors": [
        "Luke Antoncich",
        "Yuben Moodley",
        "Ugo Varetto",
        "Jingbo Wang",
        "Jonathan Wurtz",
        "Jing Chen",
        "Pascal Jahan Elahi",
        "Casey R. Myers"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "published": "2026-02-16 11:03:31+00:00",
      "link": "https://arxiv.org/pdf/2602.14641v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14636v1",
      "title": "Rewriting Induction for Existentially Quantified Equations in Logically Constrained Rewriting (Full Version)",
      "abstract": "Rewriting Induction (RI) is a principle to prove that an equation over terms is an inductive theorem of a rewrite system, i.e., that any ground instance of the equation is a theorem of the rewrite system. RI has been adapted to several kinds of rewrite systems, and RI for constrained rewrite systems has been extended to inequalities. In this paper, we extend RI for constrained equations to existentially quantified equations in logically constrained rewriting. To this end, we first extend constrained equations by introducing existential quantification to the equation part of constrained equations. Then, in applying a constrained rewrite rule to such extended constrained equations, we introduce existential quantification to extra variables of the applied rule. Finally, using the extended application of constrained rewrite rules, we extend RI for constrained equations to existentially quantified equations.",
      "authors": [
        "Naoki Nishida",
        "Kazushi Nishie",
        "Misaki Kojima"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-02-16 10:53:48+00:00",
      "link": "https://arxiv.org/pdf/2602.14636v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14635v1",
      "title": "Alignment Adapter to Improve the Performance of Compressed Deep Learning Models",
      "abstract": "Compressed Deep Learning (DL) models are essential for deployment in resource-constrained environments. But their performance often lags behind their large-scale counterparts. To bridge this gap, we propose Alignment Adapter (AlAd): a lightweight, sliding-window-based adapter. It aligns the token-level embeddings of a compressed model with those of the original large model. AlAd preserves local contextual semantics, enables flexible alignment across differing dimensionalities or architectures, and is entirely agnostic to the underlying compression method. AlAd can be deployed in two ways: as a plug-and-play module over a frozen compressed model, or by jointly fine-tuning AlAd with the compressed model for further performance gains. Through experiments on BERT-family models across three token-level NLP tasks, we demonstrate that AlAd significantly boosts the performance of compressed models with only marginal overhead in size and latency.",
      "authors": [
        "Rohit Raj Rai",
        "Abhishek Dhaka",
        "Amit Awekar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-02-16 10:53:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14635v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14634v1",
      "title": "Beyond Eager Encodings: A Theory-Agnostic Approach to Theory-Lemma Enumeration in SMT",
      "abstract": "Lifting Boolean-reasoning techniques to the SMT level most often requires producing theory lemmas that rule out theory-inconsistent truth assignments. With standard SMT solving, it is common to \"lazily\" generate such lemmas on demand during the search; with some harder SMT-level tasks -- such as unsat-core extraction, MaxSMT, T-OBDD or T-SDD compilation -- it may be beneficial or even necessary to \"eagerly\" pre-compute all the needed theory lemmas upfront. Whereas in principle \"classic\" eager SMT encodings could do the job, they are specific for very few and easy theories, they do not comply with theory combination, and may produce lots of unnecessary lemmas.   In this paper, we present theory-agnostic methods for enumerating complete sets of theory lemmas tailored to a given formula. Starting from AllSMT as a baseline approach, we propose improved lemma-enumeration techniques, including divide&conquer, projected enumeration, and theory-driven partitioning, which are highly parallelizable and which may drastically improve scalability. An experimental evaluation demonstrates that these techniques significantly enhance efficiency and enable the method to scale to substantially more complex instances.",
      "authors": [
        "Emanuele Civini",
        "Gabriele Masina",
        "Giuseppe Spallitta",
        "Roberto Sebastiani"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-02-16 10:49:11+00:00",
      "link": "https://arxiv.org/pdf/2602.14634v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14633v1",
      "title": "VIGIL: Tackling Hallucination Detection in Image Recontextualization",
      "abstract": "We introduce VIGIL (Visual Inconsistency & Generative In-context Lucidity), the first benchmark dataset and framework providing a fine-grained categorization of hallucinations in the multimodal image recontextualization task for large multimodal models (LMMs). While existing research often treats hallucinations as a uniform issue, our work addresses a significant gap in multimodal evaluation by decomposing these errors into five categories: pasted object hallucinations, background hallucinations, object omission, positional & logical inconsistencies, and physical law violations. To address these complexities, we propose a multi-stage detection pipeline. Our architecture processes recontextualized images through a series of specialized steps targeting object-level fidelity, background consistency, and omission detection, leveraging a coordinated ensemble of open-source models, whose effectiveness is demonstrated through extensive experimental evaluations. Our approach enables a deeper understanding of where the models fail with an explanation; thus, we fill a gap in the field, as no prior methods offer such categorization and decomposition for this task. To promote transparency and further exploration, we openly release VIGIL, along with the detection pipeline and benchmark code, through our GitHub repository: https://github.com/mlubneuskaya/vigil and Data repository: https://huggingface.co/datasets/joannaww/VIGIL.",
      "authors": [
        "Joanna Wojciechowicz",
        "Maria Łubniewska",
        "Jakub Antczak",
        "Justyna Baczyńska",
        "Wojciech Gromski",
        "Wojciech Kozłowski",
        "Maciej Zięba"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 10:47:10+00:00",
      "link": "https://arxiv.org/pdf/2602.14633v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14626v1",
      "title": "Concepts' Information Bottleneck Models",
      "abstract": "Concept Bottleneck Models (CBMs) aim to deliver interpretable predictions by routing decisions through a human-understandable concept layer, yet they often suffer reduced accuracy and concept leakage that undermines faithfulness. We introduce an explicit Information Bottleneck regularizer on the concept layer that penalizes $I(X;C)$ while preserving task-relevant information in $I(C;Y)$, encouraging minimal-sufficient concept representations. We derive two practical variants (a variational objective and an entropy-based surrogate) and integrate them into standard CBM training without architectural changes or additional supervision. Evaluated across six CBM families and three benchmarks, the IB-regularized models consistently outperform their vanilla counterparts. Information-plane analyses further corroborate the intended behavior. These results indicate that enforcing a minimal-sufficient concept bottleneck improves both predictive performance and the reliability of concept-level interventions. The proposed regularizer offers a theoretic-grounded, architecture-agnostic path to more faithful and intervenable CBMs, resolving prior evaluation inconsistencies by aligning training protocols and demonstrating robust gains across model families and datasets.",
      "authors": [
        "Karim Galliamov",
        "Syed M Ahsan Kazmi",
        "Adil Khan",
        "Adín Ramírez Rivera"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 10:33:20+00:00",
      "link": "https://arxiv.org/pdf/2602.14626v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14625v1",
      "title": "Near-Linear Time Computation of Welzl Orders on Graphs with Linear Neighborhood Complexity",
      "abstract": "Orders with low crossing number, introduced by Welzl, are a fundamental tool in range searching and computational geometry. Recently, they have found important applications in structural graph theory: set systems with linear shatter functions correspond to graph classes with linear neighborhood complexity. For such systems, Welzl's theorem guarantees the existence of orders with only $\\mathcal{O}(\\log^2 n)$ crossings. A series of works has progressively improved the runtime for computing such orders, from Chazelle and Welzl's original $\\mathcal{O}(|U|^3 |\\mathcal{F}|)$ bound, through Har-Peled's $\\mathcal{O}(|U|^2|\\mathcal{F}|)$, to the recent sampling-based methods of Csikós and Mustafa.   We present a randomized algorithm that computes Welzl orders for set systems with linear primal and dual shatter functions in time $\\mathcal{O}(\\|S\\| \\log \\|S\\|)$, where $\\|S\\| = |U| + \\sum_{X \\in \\mathcal{F}} |X|$ is the size of the canonical input representation. As an application, we compute compact neighborhood covers in graph classes with (near-)linear neighborhood complexity in time \\(\\mathcal{O}(n \\log n)\\) and improve the runtime of first-order model checking on monadically stable graph classes from $\\mathcal{O}(n^{5+\\varepsilon})$ to $\\mathcal{O}(n^{3+\\varepsilon})$.",
      "authors": [
        "Jan Dreier",
        "Clemens Kuske"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-02-16 10:31:28+00:00",
      "link": "https://arxiv.org/pdf/2602.14625v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15082v1",
      "title": "S-PRESSO: Ultra Low Bitrate Sound Effect Compression With Diffusion Autoencoders And Offline Quantization",
      "abstract": "Neural audio compression models have recently achieved extreme compression rates, enabling efficient latent generative modeling. Conversely, latent generative models have been applied to compression, pushing the limits of continuous and discrete approaches. However, existing methods remain constrained to low-resolution audio and degrade substantially at very low bitrates, where audible artifacts are prominent. In this paper, we present S-PRESSO, a 48kHz sound effect compression model that produces both continuous and discrete embeddings at ultra-low bitrates, down to 0.096 kbps, via offline quantization. Our model relies on a pretrained latent diffusion model to decode compressed audio embeddings learned by a latent encoder. Leveraging the generative priors of the diffusion decoder, we achieve extremely low frame rates, down to 1Hz (750x compression rate), producing convincing and realistic reconstructions at the cost of exact fidelity. Despite operating at high compression rates, we demonstrate that S-PRESSO outperforms both continuous and discrete baselines in audio quality, acoustic similarity and reconstruction metrics.",
      "authors": [
        "Zineb Lahrichi",
        "Gaëtan Hadjeres",
        "Gaël Richard",
        "Geoffroy Peeters"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM"
      ],
      "published": "2026-02-16 10:28:38+00:00",
      "link": "https://arxiv.org/pdf/2602.15082v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14622v2",
      "title": "Tabular Foundation Models Can Learn Association Rules",
      "abstract": "Association Rule Mining (ARM) is a fundamental task for knowledge discovery in tabular data and is widely used in high-stakes decision-making. Classical ARM methods rely on frequent itemset mining, leading to rule explosion and poor scalability, while recent neural approaches mitigate these issues but suffer from degraded performance in low-data regimes. Tabular foundation models (TFMs), pretrained on diverse tabular data with strong in-context generalization, provide a basis for addressing these limitations. We introduce a model-agnostic association rule learning framework that extracts association rules from any conditional probabilistic model over tabular data, enabling us to leverage TFMs. We then introduce TabProbe, an instantiation of our framework that utilizes TFMs as conditional probability estimators to learn association rules out-of-the-box without frequent itemset mining. We evaluate our approach on tabular datasets of varying sizes based on standard ARM rule quality metrics and downstream classification performance. The results show that TFMs consistently produce concise, high-quality association rules with strong predictive performance and remain robust in low-data settings without task-specific training. Source code is available at https://github.com/DiTEC-project/tabprobe.",
      "authors": [
        "Erkan Karabulut",
        "Daniel Daza",
        "Paul Groth",
        "Martijn C. Schut",
        "Victoria Degeler"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "published": "2026-02-16 10:25:55+00:00",
      "link": "https://arxiv.org/pdf/2602.14622v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14615v1",
      "title": "VariViT: A Vision Transformer for Variable Image Sizes",
      "abstract": "Vision Transformers (ViTs) have emerged as the state-of-the-art architecture in representation learning, leveraging self-attention mechanisms to excel in various tasks. ViTs split images into fixed-size patches, constraining them to a predefined size and necessitating pre-processing steps like resizing, padding, or cropping. This poses challenges in medical imaging, particularly with irregularly shaped structures like tumors. A fixed bounding box crop size produces input images with highly variable foreground-to-background ratios. Resizing medical images can degrade information and introduce artefacts, impacting diagnosis. Hence, tailoring variable-sized crops to regions of interest can enhance feature representation capabilities. Moreover, large images are computationally expensive, and smaller sizes risk information loss, presenting a computation-accuracy tradeoff. We propose VariViT, an improved ViT model crafted to handle variable image sizes while maintaining a consistent patch size. VariViT employs a novel positional embedding resizing scheme for a variable number of patches. We also implement a new batching strategy within VariViT to reduce computational complexity, resulting in faster training and inference times. In our evaluations on two 3D brain MRI datasets, VariViT surpasses vanilla ViTs and ResNet in glioma genotype prediction and brain tumor classification. It achieves F1-scores of 75.5% and 76.3%, respectively, learning more discriminative features. Our proposed batching strategy reduces computation time by up to 30% compared to conventional architectures. These findings underscore the efficacy of VariViT in image representation learning. Our code can be found here: https://github.com/Aswathi-Varma/varivit",
      "authors": [
        "Aswathi Varma",
        "Suprosanna Shit",
        "Chinmay Prabhakar",
        "Daniel Scholz",
        "Hongwei Bran Li",
        "Bjoern Menze",
        "Daniel Rueckert",
        "Benedikt Wiestler"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-16 10:20:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14615v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14612v1",
      "title": "LongAudio-RAG: Event-Grounded Question Answering over Multi-Hour Long Audio",
      "abstract": "Long-duration audio is increasingly common in industrial and consumer settings, yet reviewing multi-hour recordings is impractical, motivating systems that answer natural-language queries with precise temporal grounding and minimal hallucination. Existing audio-language models show promise, but long-audio question answering remains difficult due to context-length limits. We introduce LongAudio-RAG (LA-RAG), a hybrid framework that grounds Large Language Model (LLM) outputs in retrieved, timestamped acoustic event detections rather than raw audio. Multi-hour streams are converted into structured event records stored in an SQL database, and at inference time the system resolves natural-language time references, classifies intent, retrieves only the relevant events, and generates answers using this constrained evidence. To evaluate performance, we construct a synthetic long-audio benchmark by concatenating recordings with preserved timestamps and generating template-based question-answer pairs for detection, counting, and summarization tasks. Finally, we demonstrate the practicality of our approach by deploying it in a hybrid edge-cloud environment, where the audio grounding model runs on-device on IoT-class hardware while the LLM is hosted on a GPU-backed server. This architecture enables low-latency event extraction at the edge and high-quality language reasoning in the cloud. Experiments show that structured, event-level retrieval significantly improves accuracy compared to vanilla Retrieval-Augmented Generation (RAG) or text-to-SQL approaches.",
      "authors": [
        "Naveen Vakada",
        "Kartik Hegde",
        "Arvind Krishna Sridhar",
        "Yinyi Guo",
        "Erik Visser"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-16 10:15:22+00:00",
      "link": "https://arxiv.org/pdf/2602.14612v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14611v1",
      "title": "The Value of Effective Pull Request Description",
      "abstract": "In the pull-based development model, code contributions are submitted as pull requests (PRs) to undergo reviews and approval by other developers with the goal of being merged into the code base. A PR can be supported by a description, whose role has not yet been systematically investigated. To fill in this gap, we conducted a mixed-methods empirical study of PR descriptions. We conducted a grey literature review of guidelines on writing PR descriptions and derived a taxonomy of eight recommended elements. Using this taxonomy, we analyzed 80K GitHub PRs across 156 projects and five programming languages to assess associations between these elements and code review outcomes (e.g., merge decision, latency, first response time, review comments, and review iteration cycles). To complement these results, we surveyed 64 developers about the perceived importance of each element. Finally, we analyzed which submission-time factors predict whether PRs include a description and which elements they contain. We found that developers view PR descriptions as important, but their elements matter differently: purpose and code explanations are valued by developers for preserving the rationale and history of changes, while stating the desired feedback type best predicts change acceptance and reviewer engagement. PR descriptions are also more common in mature projects and complex changes, suggesting they are written when most useful rather than as a formality.",
      "authors": [
        "Shirin Pirouzkhah",
        "Pavlína Wurzel Gonçalves",
        "Alberto Bacchelli"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-16 10:15:21+00:00",
      "link": "https://arxiv.org/pdf/2602.14611v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14607v1",
      "title": "A Bayesian Approach to Low-Discrepancy Subset Selection",
      "abstract": "Low-discrepancy designs play a central role in quasi-Monte Carlo methods and are increasingly influential in other domains such as machine learning, robotics and computer graphics, to name a few. In recent years, one such low-discrepancy construction method called subset selection has received a lot of attention. Given a large population, one optimally selects a small low-discrepancy subset with respect to a discrepancy-based objective. Versions of this problem are known to be NP-hard. In this text, we establish, for the first time, that the subset selection problem with respect to kernel discrepancies is also NP-hard. Motivated by this intractability, we propose a Bayesian Optimization procedure for the subset selection problem utilizing the recent notion of deep embedding kernels. We demonstrate the performance of the BO algorithm to minimize discrepancy measures and note that the framework is broadly applicable any design criteria.",
      "authors": [
        "Nathan Kirk"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "cs.LG",
        "math.NA",
        "stat.CO"
      ],
      "published": "2026-02-16 10:11:07+00:00",
      "link": "https://arxiv.org/pdf/2602.14607v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14606v1",
      "title": "Towards Selection as Power: Bounding Decision Authority in Autonomous Agents",
      "abstract": "Autonomous agentic systems are increasingly deployed in regulated, high-stakes domains where decisions may be irreversible and institutionally constrained. Existing safety approaches emphasize alignment, interpretability, or action-level filtering. We argue that these mechanisms are necessary but insufficient because they do not directly govern selection power: the authority to determine which options are generated, surfaced, and framed for decision. We propose a governance architecture that separates cognition, selection, and action into distinct domains and models autonomy as a vector of sovereignty. Cognitive autonomy remains unconstrained, while selection and action autonomy are bounded through mechanically enforced primitives operating outside the agent's optimization space. The architecture integrates external candidate generation (CEFL), a governed reducer, commit-reveal entropy isolation, rationale validation, and fail-loud circuit breakers. We evaluate the system across multiple regulated financial scenarios under adversarial stress targeting variance manipulation, threshold gaming, framing skew, ordering effects, and entropy probing. Metrics quantify selection concentration, narrative diversity, governance activation cost, and failure visibility. Results show that mechanical selection governance is implementable, auditable, and prevents deterministic outcome capture while preserving reasoning capacity. Although probabilistic concentration remains, the architecture measurably bounds selection authority relative to conventional scalar pipelines. This work reframes governance as bounded causal power rather than internal intent alignment, offering a foundation for deploying autonomous agents where silent failure is unacceptable.",
      "authors": [
        "Jose Manuel de la Chica Rodriguez",
        "Juan Manuel Vera Díaz"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CE"
      ],
      "published": "2026-02-16 10:10:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14606v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14602v1",
      "title": "OPBench: A Graph Benchmark to Combat the Opioid Crisis",
      "abstract": "The opioid epidemic continues to ravage communities worldwide, straining healthcare systems, disrupting families, and demanding urgent computational solutions. To combat this lethal opioid crisis, graph learning methods have emerged as a promising paradigm for modeling complex drug-related phenomena. However, a significant gap remains: there is no comprehensive benchmark for systematically evaluating these methods across real-world opioid crisis scenarios. To bridge this gap, we introduce OPBench, the first comprehensive opioid benchmark comprising five datasets across three critical application domains: opioid overdose detection from healthcare claims, illicit drug trafficking detection from digital platforms, and drug misuse prediction from dietary patterns. Specifically, OPBench incorporates diverse graph structures, including heterogeneous graphs and hypergraphs, to preserve the rich and complex relational information among drug-related data. To address data scarcity, we collaborate with domain experts and authoritative institutions to curate and annotate datasets while adhering to privacy and ethical guidelines. Furthermore, we establish a unified evaluation framework with standardized protocols, predefined data splits, and reproducible baselines to facilitate fair and systematic comparison among graph learning methods. Through extensive experiments, we analyze the strengths and limitations of existing graph learning methods, thereby providing actionable insights for future research in combating the opioid crisis. Our source code and datasets are available at https://github.com/Tianyi-Billy-Ma/OPBench.",
      "authors": [
        "Tianyi Ma",
        "Yiyang Li",
        "Yiyue Qian",
        "Zheyuan Zhang",
        "Zehong Wang",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-16 10:04:57+00:00",
      "link": "https://arxiv.org/pdf/2602.14602v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14598v1",
      "title": "Before the Vicious Cycle Starts: Preventing Burnout Across SOC Roles Through Flow-Aligned Design",
      "abstract": "The sustainability of Security Operations Centers depends on their people, yet 71% of practitioners report burnout and 24% plan to exit cybersecurity entirely. Flow theory suggests that when job demands misalign with practitioner capabilities, work becomes overwhelming or tedious rather than engaging. Achieving challenge-skill balance begins at hiring: if job descriptions inaccurately portray requirements, organizations risk recruiting underskilled practitioners who face anxiety or overskilled ones who experience boredom. Yet we lack empirical understanding of what current SOC job descriptions actually specify. We analyzed 106 public SOC job postings from November to December 2024 across 35 organizations in 11 countries, covering Analysts (n=17), Incident Responders (n=38), Threat Hunters (n=39), and SOC Managers (n=12). Using Inductive Content Analysis, we coded certifications, technical skills, soft skills, tasks, and experience requirements. Three patterns emerged: (1) Communication skills dominate (50.9% of postings), exceeding SIEM tools (18.9%) or programming (30.2%), suggesting organizations prioritize collaboration over technical capabilities. (2) Certification expectations vary widely: CISSP leads (22.6%), but 43 distinct credentials appear with no universal standard. (3) Technical requirements show consensus: Python dominates programming (27.4%), Splunk leads SIEM platforms (14.2%), and ISO 27001 (13.2%) and NIST (10.4%) are most cited standards. These findings enable organizations to audit job descriptions against empirical baselines, help practitioners identify valued certifications and skills, and allow researchers to validate whether stated requirements align with actual demands. This establishes the foundation for flow-aligned interview protocols and investigation of how AI reshapes requirements. Dataset and codebook: https://git.tu-berlin.de/wosoc-2026/soc-jd-analysis.",
      "authors": [
        "Kashyap Thimmaraju",
        "Duc Anh Hoang",
        "Souradip Nath",
        "Jaron Mink",
        "Gail-Joon Ahn"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.CY",
        "cs.HC"
      ],
      "published": "2026-02-16 10:00:06+00:00",
      "link": "https://arxiv.org/pdf/2602.14598v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14595v1",
      "title": "Consistent or Sensitive? Automated Code Revision Tools Against Semantics-Preserving Perturbations",
      "abstract": "Automated Code Revision (ACR) tools aim to reduce manual effort by automatically generating code revisions based on reviewer feedback. While ACR tools have shown promising performance on historical data, their real-world utility depends on their ability to handle similar code variants expressing the same issue - a property we define as consistency. However, the probabilistic nature of ACR tools often compromises consistency, which may lead to divergent revisions even for semantically equivalent code variants. In this paper, we investigate the extent to which ACR tools maintain consistency when presented with semantically equivalent code variants. To do so, we first designed nine types of semantics-preserving perturbations (SPP) and applied them to 2032 Java methods from real-world GitHub projects, generating over 10K perturbed variants for evaluation. Then we used these perturbations to evaluate the consistency of five state-of-the-art transformer-based ACR tools. We found that the ACR tools' ability to generate correct revisions can drop by up to 45.3%, when presented with semantically equivalent code. The closer the perturbation is to this targeted region, the more likely an ACR tool is to fail to generate the correct revision. We explored potential mitigation strategies that modify the input representation, but found that these attention-guiding heuristics yielded only marginal improvements, thus leaving the solution to this problem as an open research question.",
      "authors": [
        "Shirin Pirouzkhah",
        "Souhaila Serbout",
        "Alberto Bacchelli"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-16 09:58:59+00:00",
      "link": "https://arxiv.org/pdf/2602.14595v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14594v1",
      "title": "The Wikidata Query Logs Dataset",
      "abstract": "We present the Wikidata Query Logs (WDQL) dataset, a dataset consisting of 200k question-query pairs over the Wikidata knowledge graph. It is over 6x larger than the largest existing Wikidata datasets of similar format without relying on template-generated queries. Instead, we construct it using real-world SPARQL queries sent to the Wikidata Query Service and generate questions for them. Since these log-based queries are anonymized, and therefore often do not produce results, a significant amount of effort is needed to convert them back into meaningful SPARQL queries. To achieve this, we present an agent-based method that iteratively de-anonymizes, cleans, and verifies queries against Wikidata while also generating corresponding natural-language questions. We demonstrate the dataset's benefit for training question-answering methods. All WDQL assets, as well as the agent code, are publicly available under a permissive license.",
      "authors": [
        "Sebastian Walter",
        "Hannah Bast"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 09:49:44+00:00",
      "link": "https://arxiv.org/pdf/2602.14594v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14592v1",
      "title": "FO and MSO Model Checking on Temporal Graphs",
      "abstract": "Algorithmic meta-theorems provide an important tool for showing tractability of graph problems on graph classes defined by structural restrictions. While such results are well established for static graphs, corresponding frameworks for temporal graphs are comparatively limited.   In this work, we revisit past applications of logical meta-theorems to temporal graphs and develop an extended unifying logical framework. Our first contribution is the introduction of logical encodings for the parameters vertex-interval-membership (VIM) width and tree-interval-membership (TIM) width, parameters which capture the signature of vertex and component activity over time. Building on this, we extend existing monadic second-order (MSO) meta-theorems for bounded lifetime and temporal degree to the parameters VIM and TIM width, and establish novel first-order (FO) meta-theorems for all four parameters.   Finally, we signpost a modular lexicon of reusable FO and MSO formulas for a broad range of temporal graph problems, and give an example. This lexicon allows new problems to be expressed compositionally and directly yields fixed-parameter tractability results across the four parameters we consider.",
      "authors": [
        "Michelle Döring",
        "Jessica Enright",
        "Laura Larios-Jones",
        "George Skretas"
      ],
      "primary_category": "cs.DM",
      "categories": [
        "cs.DM",
        "cs.DS"
      ],
      "published": "2026-02-16 09:48:24+00:00",
      "link": "https://arxiv.org/pdf/2602.14592v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14591v1",
      "title": "Automated Classification of Source Code Changes Based on Metrics Clustering in the Software Development Process",
      "abstract": "This paper presents an automated method for classifying source code changes during the software development process based on clustering of change metrics. The method consists of two steps: clustering of metric vectors computed for each code change, followed by expert mapping of the resulting clusters to predefined change classes. The distribution of changes into clusters is performed automatically, while the mapping of clusters to classes is carried out by an expert. Automation of the distribution step substantially reduces the time required for code change review. The k-means algorithm with a cosine similarity measure between metric vectors is used for clustering. Eleven source code metrics are employed, covering lines of code, cyclomatic complexity, file counts, interface changes, and structural changes. The method was validated on five software systems, including two open-source projects (Subversion and NHibernate), and demonstrated classification purity of P_C = 0.75 +/- 0.05 and entropy of E_C = 0.37 +/- 0.06 at a significance level of 0.05.",
      "authors": [
        "Evgenii Kniazev"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-02-16 09:47:39+00:00",
      "link": "https://arxiv.org/pdf/2602.14591v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14589v1",
      "title": "MATEO: A Multimodal Benchmark for Temporal Reasoning and Planning in LVLMs",
      "abstract": "AI agents need to plan to achieve complex goals that involve orchestrating perception, sub-goal decomposition, and execution. These plans consist of ordered steps structured according to a Temporal Execution Order (TEO, a directed acyclic graph that ensures each step executes only after its preconditions are satisfied. Existing research on foundational models' understanding of temporal execution is limited to automatically derived annotations, approximations of the TEO as a linear chain, or text-only inputs. To address this gap, we introduce MATEO (MultimodAl Temporal Execution Order), a benchmark designed to assess and improve the temporal reasoning abilities of Large Vision Language Models (LVLMs) required for real-world planning. We acquire a high-quality professional multimodal recipe corpus, authored through a standardized editorial process that decomposes instructions into discrete steps, each paired with corresponding images. We collect TEO annotations as graphs by designing and using a scalable crowdsourcing pipeline. Using MATEO, we evaluate six state-of-the-art LVLMs across model scales, varying language context, multimodal input structure, and fine-tuning strategies.",
      "authors": [
        "Gabriel Roccabruna",
        "Olha Khomyn",
        "Giuseppe Riccardi"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-16 09:41:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14589v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14587v1",
      "title": "Decoupled Continuous-Time Reinforcement Learning via Hamiltonian Flow",
      "abstract": "Many real-world control problems, ranging from finance to robotics, evolve in continuous time with non-uniform, event-driven decisions. Standard discrete-time reinforcement learning (RL), based on fixed-step Bellman updates, struggles in this setting: as time gaps shrink, the $Q$-function collapses to the value function $V$, eliminating action ranking. Existing continuous-time methods reintroduce action information via an advantage-rate function $q$. However, they enforce optimality through complicated martingale losses or orthogonality constraints, which are sensitive to the choice of test processes. These approaches entangle $V$ and $q$ into a large, complex optimization problem that is difficult to train reliably. To address these limitations, we propose a novel decoupled continuous-time actor-critic algorithm with alternating updates: $q$ is learned from diffusion generators on $V$, and $V$ is updated via a Hamiltonian-based value flow that remains informative under infinitesimal time steps, where standard max/softmax backups fail. Theoretically, we prove rigorous convergence via new probabilistic arguments, sidestepping the challenge that generator-based Hamiltonians lack Bellman-style contraction under the sup-norm. Empirically, our method outperforms prior continuous-time and leading discrete-time baselines across challenging continuous-control benchmarks and a real-world trading task, achieving 21% profit over a single quarter$-$nearly doubling the second-best method.",
      "authors": [
        "Minh Nguyen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "math.ST"
      ],
      "published": "2026-02-16 09:35:25+00:00",
      "link": "https://arxiv.org/pdf/2602.14587v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14584v1",
      "title": "CLAP-Based Automatic Word Naming Recognition in Post-Stroke Aphasia",
      "abstract": "Conventional automatic word-naming recognition systems struggle to recognize words from post-stroke patients with aphasia because of disfluencies and mispronunciations, limiting reliable automated assessment in this population. In this paper, we propose a Contrastive Language-Audio Pretraining (CLAP) based approach for automatic word-naming recognition to address this challenge by leveraging text-audio alignment. Our approach treats word-naming recognition as an audio-text matching problem, projecting speech signals and textual prompts into a shared embedding space to identify intended words even in challenging recordings. Evaluated on two speech datasets of French post-stroke patients with aphasia, our approach achieves up to 90% accuracy, outperforming existing classification-based and automatic speech recognition-based baselines.",
      "authors": [
        "Yacouba Kaloga",
        "Marina Laganaro",
        "Ina Kodrasi"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.SD"
      ],
      "published": "2026-02-16 09:32:38+00:00",
      "link": "https://arxiv.org/pdf/2602.14584v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14582v1",
      "title": "YOLO26: A Comprehensive Architecture Overview and Key Improvements",
      "abstract": "You Only Look Once (YOLO) has been the prominent model for computer vision in deep learning for a decade. This study explores the novel aspects of YOLO26, the most recent version in the YOLO series. The elimination of Distribution Focal Loss (DFL), implementation of End-to-End NMS-Free Inference, introduction of ProgLoss + Small-Target-Aware Label Assignment (STAL), and use of the MuSGD optimizer are the primary enhancements designed to improve inference speed, which is claimed to achieve a 43% boost in CPU mode. This is designed to allow YOLO26 to attain real-time performance on edge devices or those without GPUs. Additionally, YOLO26 offers improvements in many computer vision tasks, including instance segmentation, pose estimation, and oriented bounding box (OBB) decoding. We aim for this effort to provide more value than just consolidating information already included in the existing technical documentation. Therefore, we performed a rigorous architectural investigation into YOLO26, mostly using the source code available in its GitHub repository and its official documentation. The authentic and detailed operational mechanisms of YOLO26 are inside the source code, which is seldom extracted by others. The YOLO26 architectural diagram is shown as the outcome of the investigation. This study is, to our knowledge, the first one presenting the CNN-based YOLO26 architecture, which is the core of YOLO26. Our objective is to provide a precise architectural comprehension of YOLO26 for researchers and developers aspiring to enhance the YOLO model, ensuring it remains the leading deep learning model in computer vision.",
      "authors": [
        "Priyanto Hidayatullah",
        "Refdinal Tubagus"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 09:25:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14582v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14580v1",
      "title": "Replicable Constrained Bandits",
      "abstract": "Algorithmic \\emph{replicability} has recently been introduced to address the need for reproducible experiments in machine learning. A \\emph{replicable online learning} algorithm is one that takes the same sequence of decisions across different executions in the same environment, with high probability. We initiate the study of algorithmic replicability in \\emph{constrained} MAB problems, where a learner interacts with an unknown stochastic environment for $T$ rounds, seeking not only to maximize reward but also to satisfy multiple constraints. Our main result is that replicability can be achieved in constrained MABs. Specifically, we design replicable algorithms whose regret and constraint violation match those of non-replicable ones in terms of $T$. As a key step toward these guarantees, we develop the first replicable UCB-like algorithm for \\emph{unconstrained} MABs, showing that algorithms that employ the optimism in-the-face-of-uncertainty principle can be replicable, a result that we believe is of independent interest.",
      "authors": [
        "Matteo Bollini",
        "Gianmarco Genalti",
        "Francesco Emanuele Stradi",
        "Matteo Castiglioni",
        "Alberto Marchesi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-16 09:22:23+00:00",
      "link": "https://arxiv.org/pdf/2602.14580v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14578v1",
      "title": "RNM-TD3: N:M Semi-structured Sparse Reinforcement Learning From Scratch",
      "abstract": "Sparsity is a well-studied technique for compressing deep neural networks (DNNs) without compromising performance. In deep reinforcement learning (DRL), neural networks with up to 5% of their original weights can still be trained with minimal performance loss compared to their dense counterparts. However, most existing methods rely on unstructured fine-grained sparsity, which limits hardware acceleration opportunities due to irregular computation patterns. Structured coarse-grained sparsity enables hardware acceleration, yet typically degrades performance and increases pruning complexity. In this work, we present, to the best of our knowledge, the first study on N:M structured sparsity in RL, which balances compression, performance, and hardware efficiency. Our framework enforces row-wise N:M sparsity throughout training for all networks in off-policy RL (TD3), maintaining compatibility with accelerators that support N:M sparse matrix operations. Experiments on continuous-control benchmarks show that RNM-TD3, our N:M sparse agent, outperforms its dense counterpart at 50%-75% sparsity (e.g., 2:4 and 1:4), achieving up to a 14% increase in performance at 2:4 sparsity on the Ant environment. RNM-TD3 remains competitive even at 87.5% sparsity (1:8), while enabling potential training speedups.",
      "authors": [
        "Isam Vrce",
        "Andreas Kassler",
        "Gökçe Aydos"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AR"
      ],
      "published": "2026-02-16 09:17:29+00:00",
      "link": "https://arxiv.org/pdf/2602.14578v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14577v1",
      "title": "DriveFine: Refining-Augmented Masked Diffusion VLA for Precise and Robust Driving",
      "abstract": "Vision-Language-Action (VLA) models for autonomous driving increasingly adopt generative planners trained with imitation learning followed by reinforcement learning. Diffusion-based planners suffer from modality alignment difficulties, low training efficiency, and limited generalization. Token-based planners are plagued by cumulative causal errors and irreversible decoding. In summary, the two dominant paradigms exhibit complementary strengths and weaknesses. In this paper, we propose DriveFine, a masked diffusion VLA model that combines flexible decoding with self-correction capabilities. In particular, we design a novel plug-and-play block-MoE, which seamlessly injects a refinement expert on top of the generation expert. By enabling explicit expert selection during inference and gradient blocking during training, the two experts are fully decoupled, preserving the foundational capabilities and generic patterns of the pretrained weights, which highlights the flexibility and extensibility of the block-MoE design. Furthermore, we design a hybrid reinforcement learning strategy that encourages effective exploration of refinement expert while maintaining training stability. Extensive experiments on NAVSIM v1, v2, and Navhard benchmarks demonstrate that DriveFine exhibits strong efficacy and robustness. The code will be released at https://github.com/MSunDYY/DriveFine.",
      "authors": [
        "Chenxu Dang",
        "Sining Ang",
        "Yongkang Li",
        "Haochen Tian",
        "Jie Wang",
        "Guang Li",
        "Hangjun Ye",
        "Jie Ma",
        "Long Chen",
        "Yan Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 09:13:52+00:00",
      "link": "https://arxiv.org/pdf/2602.14577v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14575v1",
      "title": "Information-Theoretic Approach to Financial Market Modelling",
      "abstract": "The paper treats the financial market as a communication system, using four information-theoretic assumptions to derive an idealized model with only one parameter. State variables are scalar stationary diffusions. The model minimizes the surprisal of the market and the Kullback-Leibler divergence between the benchmark-neutral pricing measure and the real-world probability measure. The state variables, their sums, and the growth optimal portfolio of the stocks evolve as squared radial Ornstein-Uhlenbeck processes in respective activity times.",
      "authors": [
        "Eckhard Platen"
      ],
      "primary_category": "q-fin.MF",
      "categories": [
        "q-fin.MF",
        "cs.IT"
      ],
      "published": "2026-02-16 09:11:42+00:00",
      "link": "https://arxiv.org/pdf/2602.14575v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14572v2",
      "title": "An Empirical Study of the Evolution of GitHub Actions Workflows",
      "abstract": "CI/CD practices play a significant role during collaborative software development by automating time-consuming and repetitive tasks such as testing, building, quality checking, dependency and security management. GitHub Actions, the CI/CD tool integrated into GitHub, allows repository maintainers to automate development workflows. We conducted a mixed methods analysis of GitHub Actions workflow changes over time. Through a preliminary qualitative analysis of 439 modified workflow files we identified seven types of conceptual changes to workflows. Next, we performed a quantitative analysis over 49K+ GitHub repositories totaling 267K+ workflow change histories and 3.4M+ workflow file versions from November 2019 to August 2025. This analysis revealed that repositories contain a median of three workflow files, and 7.3% of all workflow files are being changed every week. The changes made to workflows tend to be small, with about three-quarters containing only a single change. The large majority of the observed changes have to do with task configuration and task specification in workflow jobs. We did not find any conclusive evidence of the effect of LLM coding tools or other major technological changes on workflow creation and workflow maintenance frequency. Our findings highlight the need for improved tooling to support fine-grained maintenance tasks, such as a broader adoption of dependency management and AI-based support for ensuring and sustaining workflow security and quality.",
      "authors": [
        "Pooya Rostami Mazrae",
        "Alexandre Decan",
        "Tom Mens",
        "Mairieli Wessel"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-16 09:05:42+00:00",
      "link": "https://arxiv.org/pdf/2602.14572v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14573v1",
      "title": "Polar: An Algebraic Analyzer for (Probabilistic) Loops",
      "abstract": "We present the Polar framework for fully automating the analysis of classical and probabilistic loops using algebraic reasoning. The central theme in Polar comes with handling algebraic recurrences that precisely capture the loop semantics. To this end, our work implements a variety of techniques to compute exact closed-forms of recurrences over higher-order moments of variables, infer invariants, and derive loop sensitivities with respect to unknown parameters. Polar can analyze probabilistic loops containing if-statements, polynomial arithmetic, and common probability distributions. By translating loop analysis into linear recurrence solving, Polar uses the derived closed-forms of recurrences to compute the strongest polynomial invariant or to infer parameter sensitivity. Polar is both sound and complete within well-defined programming model restrictions. Lifting any of these restrictions results in significant hardness limits of computation. To overcome computational burdens for the sake of efficiency, Polar also provides incomplete but sound techniques to compute moments of combinations of variables.",
      "authors": [
        "Marcel Moosbrugger",
        "Julian Müllner",
        "Ezio Bartocci",
        "Laura Kovács"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL"
      ],
      "published": "2026-02-16 09:05:42+00:00",
      "link": "https://arxiv.org/pdf/2602.14573v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14571v1",
      "title": "DCTracks: An Open Dataset for Machine Learning-Based Drift Chamber Track Reconstruction",
      "abstract": "We introduce a Monte Carlo (MC) dataset of single- and two-track drift chamber events to advance Machine Learning (ML)-based track reconstruction. To enable standardized and comparable evaluation, we define track reconstruction specific metrics and report results for traditional track reconstruction algorithms and a Graph Neural Networks (GNNs) method, facilitating rigorous, reproducible validation for future research.",
      "authors": [
        "Qian Liyan",
        "Zhang Yao",
        "Yuan Ye",
        "Zhang Zhaoke",
        "Fang Jin",
        "Jiang Shimiao",
        "Zhang Jin",
        "Li Ke",
        "Liu Beijiang",
        "Xu Chenglin",
        "Zhang Yifan",
        "Jia Xiaoqian",
        "Qin Xiaoshuai",
        "Huang Xingtao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "hep-ex"
      ],
      "published": "2026-02-16 09:04:49+00:00",
      "link": "https://arxiv.org/pdf/2602.14571v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14566v1",
      "title": "Simultaneous analysis of curved Kirchhoff beams and Kirchhoff--Love shells embedded in bulk domains",
      "abstract": "A set of curved beams and shells is geometrically implied by level sets of a scalar function over some bulk domain. The mechanical model for each structure is based on the Kirchhoff--Love theory, that is, small displacements without shear deformations are considered. These models for individual geometries are extended to bulk models, simultaneously modeling the whole set of beams/shells on all level sets. A major focus is on the numerical analysis of such models. A mixed-hybrid and higher-order accurate Bulk Trace FEM is proposed that enables the use of standard $C^0$-continuous Lagrange elements with dimensionality of the bulk domain. That is, the higher-order continuity requirements of displacement-based formulations in context of the Kirchhoff--Love theory are successfully alleviated. Several numerical tests confirm the accuracy and higher-order convergence of the proposed methodology, also qualifying as benchmark test cases in future studies.",
      "authors": [
        "Jonas Neumeyer",
        "Michael Wolfgang Kaiser",
        "Thomas-Peter Fries"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-02-16 08:59:12+00:00",
      "link": "https://arxiv.org/pdf/2602.14566v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14564v1",
      "title": "Assessing Large Language Models for Medical QA: Zero-Shot and LLM-as-a-Judge Evaluation",
      "abstract": "Recently, Large Language Models (LLMs) have gained significant traction in medical domain, especially in developing a QA systems to Medical QA systems for enhancing access to healthcare in low-resourced settings. This paper compares five LLMs deployed between April 2024 and August 2025 for medical QA, using the iCliniq dataset, containing 38,000 medical questions and answers of diverse specialties. Our models include Llama-3-8B-Instruct, Llama 3.2 3B, Llama 3.3 70B Instruct, Llama-4-Maverick-17B-128E-Instruct, and GPT-5-mini. We are using a zero-shot evaluation methodology and using BLEU and ROUGE metrics to evaluate performance without specialized fine-tuning. Our results show that larger models like Llama 3.3 70B Instruct outperform smaller models, consistent with observed scaling benefits in clinical tasks. It is notable that, Llama-4-Maverick-17B exhibited more competitive results, thus highlighting evasion efficiency trade-offs relevant for practical deployment. These findings align with advancements in LLM capabilities toward professional-level medical reasoning and reflect the increasing feasibility of LLM-supported QA systems in the real clinical environments. This benchmark aims to serve as a standardized setting for future study to minimize model size, computational resources and to maximize clinical utility in medical NLP applications.",
      "authors": [
        "Shefayat E Shams Adib",
        "Ahmed Alfey Sani",
        "Ekramul Alam Esham",
        "Ajwad Abrar",
        "Tareque Mohmud Chowdhury"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 08:53:23+00:00",
      "link": "https://arxiv.org/pdf/2602.14564v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14561v1",
      "title": "Simulation-based Learning of Electrical Cabinet Assembly Using Robot Skills",
      "abstract": "This paper presents a simulation-driven approach for automating the force-controlled assembly of electrical terminals on DIN-rails, a task traditionally hindered by high programming effort and product variability. The proposed method integrates deep reinforcement learning (DRL) with parameterizable robot skills in a physics-based simulation environment. To realistically model the snap-fit assembly process, we develop and evaluate two types of joining models: analytical models based on beam theory and rigid-body models implemented in the MuJoCo physics engine. These models enable accurate simulation of interaction forces, essential for training DRL agents. The robot skills are structured using the pitasc framework, allowing modular, reusable control strategies. Training is conducted in simulation using Soft Actor-Critic (SAC) and Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithms. Domain randomization is applied to improve robustness. The trained policies are transferred to a physical UR10e robot system without additional tuning. Experimental results demonstrate high success rates (up to 100%) in both simulation and real-world settings, even under significant positional and rotational deviations. The system generalizes well to new terminal types and positions, significantly reducing manual programming effort. This work highlights the potential of combining simulation-based learning with modular robot skills for flexible, scalable automation in small-batch manufacturing. Future work will explore hybrid learning methods, automated environment parameterization, and further refinement of joining models for design integration.",
      "authors": [
        "Arik Laemmle",
        "Balázs András Bálint",
        "Philipp Tenbrock",
        "Frank Naegele",
        "David Traunecker",
        "József Váncza",
        "Marco F. Huber"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-16 08:45:54+00:00",
      "link": "https://arxiv.org/pdf/2602.14561v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14560v1",
      "title": "Preliminary sonification of ENSO using traditional Javanese gamelan scales",
      "abstract": "Sonification -- the mapping of data to non-speech audio -- offers an underexplored channel for representing complex dynamical systems. We treat El Niño-Southern Oscillation (ENSO), a canonical example of low-dimensional climate chaos, as a test case for culturally-situated sonification evaluated through complex systems diagnostics. Using parameter-mapping sonification of the Niño 3.4 sea surface temperature anomaly index (1870--2024), we encode ENSO variability into two traditional Javanese gamelan pentatonic systems (pelog and slendro) across four composition strategies, then analyze the resulting audio as trajectories in a two-dimensional acoustic phase space. Recurrence-based diagnostics, convex hull geometry, and coupling analysis reveal that the sonification pipeline preserves key dynamical signatures: alternating modes produce the highest trajectory recurrence rates, echoing ENSO's quasi-periodicity; layered polyphonic modes explore the broadest phase space regions; and the two scale families induce qualitatively distinct coupling regimes between spectral brightness and energy -- predominantly anti-phase in pelog but near-independent in slendro. Phase space trajectory analysis provides a rigorous geometric framework for comparing sonification designs within a complex systems context. Perceptual validation remains necessary; we contribute the dynamical systems methodology for evaluating such mappings.",
      "authors": [
        "Sandy H. S. Herho",
        "Rusmawan Suwarman",
        "Nurjanna J. Trilaksono",
        "Iwan P. Anwar",
        "Faiz R. Fajary"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph",
        "cs.SD",
        "physics.ao-ph"
      ],
      "published": "2026-02-16 08:40:01+00:00",
      "link": "https://arxiv.org/pdf/2602.14560v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14559v1",
      "title": "Fluid-Agent Reinforcement Learning",
      "abstract": "The primary focus of multi-agent reinforcement learning (MARL) has been to study interactions among a fixed number of agents embedded in an environment. However, in the real world, the number of agents is neither fixed nor known a priori. Moreover, an agent can decide to create other agents (for example, a cell may divide, or a company may spin off a division). In this paper, we propose a framework that allows agents to create other agents; we call this a fluid-agent environment. We present game-theoretic solution concepts for fluid-agent games and empirically evaluate the performance of several MARL algorithms within this framework. Our experiments include fluid variants of established benchmarks such as Predator-Prey and Level-Based Foraging, where agents can dynamically spawn, as well as a new environment we introduce that highlights how fluidity can unlock novel solution strategies beyond those observed in fixed-population settings. We demonstrate that this framework yields agent teams that adjust their size dynamically to match environmental demands.",
      "authors": [
        "Shishir Sharma",
        "Doina Precup",
        "Theodore J. Perkins"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-02-16 08:37:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14559v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14553v1",
      "title": "Governing AI Forgetting: Auditing for Machine Unlearning Compliance",
      "abstract": "Despite legal mandates for the right to be forgotten, AI operators routinely fail to comply with data deletion requests. While machine unlearning (MU) provides a technical solution to remove personal data's influence from trained models, ensuring compliance remains challenging due to the fundamental gap between MU's technical feasibility and regulatory implementation. In this paper, we introduce the first economic framework for auditing MU compliance, by integrating certified unlearning theory with regulatory enforcement. We first characterize MU's inherent verification uncertainty using a hypothesis-testing interpretation of certified unlearning to derive the auditor's detection capability, and then propose a game-theoretic model to capture the strategic interactions between the auditor and the operator. A key technical challenge arises from MU-specific nonlinearities inherent in the model utility and the detection probability, which create complex strategic couplings that traditional auditing frameworks do not address and that also preclude closed-form solutions. We address this by transforming the complex bivariate nonlinear fixed-point problem into a tractable univariate auxiliary problem, enabling us to decouple the system and establish the equilibrium existence, uniqueness, and structural properties without relying on explicit solutions. Counterintuitively, our analysis reveals that the auditor can optimally reduce the inspection intensity as deletion requests increase, since the operator's weakened unlearning makes non-compliance easier to detect. This is consistent with recent auditing reductions in China despite growing deletion requests. Moreover, we prove that although undisclosed auditing offers informational advantages for the auditor, it paradoxically reduces the regulatory cost-effectiveness relative to disclosed auditing.",
      "authors": [
        "Qinqi Lin",
        "Ningning Ding",
        "Lingjie Duan",
        "Jianwei Huang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "published": "2026-02-16 08:32:09+00:00",
      "link": "https://arxiv.org/pdf/2602.14553v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14552v1",
      "title": "OmniVTON++: Training-Free Universal Virtual Try-On with Principal Pose Guidance",
      "abstract": "Image-based Virtual Try-On (VTON) concerns the synthesis of realistic person imagery through garment re-rendering under human pose and body constraints. In practice, however, existing approaches are typically optimized for specific data conditions, making their deployment reliant on retraining and limiting their generalization as a unified solution. We present OmniVTON++, a training-free VTON framework designed for universal applicability. It addresses the intertwined challenges of garment alignment, human structural coherence, and boundary continuity by coordinating Structured Garment Morphing for correspondence-driven garment adaptation, Principal Pose Guidance for step-wise structural regulation during diffusion sampling, and Continuous Boundary Stitching for boundary-aware refinement, forming a cohesive pipeline without task-specific retraining. Experimental results demonstrate that OmniVTON++ achieves state-of-the-art performance across diverse generalization settings, including cross-dataset and cross-garment-type evaluations, while reliably operating across scenarios and diffusion backbones within a single formulation. In addition to single-garment, single-human cases, the framework supports multi-garment, multi-human, and anime character virtual try-on, expanding the scope of virtual try-on applications. The source code will be released to the public.",
      "authors": [
        "Zhaotong Yang",
        "Yong Du",
        "Shengfeng He",
        "Yuhui Li",
        "Xinzhe Li",
        "Yangyang Xu",
        "Junyu Dong",
        "Jian Yang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 08:27:43+00:00",
      "link": "https://arxiv.org/pdf/2602.14552v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14551v1",
      "title": "Replanning Human-Robot Collaborative Tasks with Vision-Language Models via Semantic and Physical Dual-Correction",
      "abstract": "Human-Robot Collaboration (HRC) plays an important role in assembly tasks by enabling robots to plan and adjust their motions based on interactive, real-time human instructions. However, such instructions are often linguistically ambiguous and underspecified, making it difficult to generate physically feasible and cooperative robot behaviors. To address this challenge, many studies have applied Vision-Language Models (VLMs) to interpret high-level instructions and generate corresponding actions. Nevertheless, VLM-based approaches still suffer from hallucinated reasoning and an inability to anticipate physical execution failures. To address these challenges, we propose an HRC framework that augments a VLM-based reasoning with a dual-correction mechanism: an internal correction model that verifies logical consistency and task feasibility prior to action execution, and an external correction model that detects and rectifies physical failures through post-execution feedback. Simulation ablation studies demonstrate that the proposed method improves the success rate compared to baselines without correction models. Our real-world experiments in collaborative assembly tasks supported by object fixation or tool preparation by an upper body humanoid robot further confirm the framewor's effectiveness in enabling interactive replanning across different collaborative tasks in response to human instructions, validating its practical feasibility.",
      "authors": [
        "Taichi Kato",
        "Takuya Kiyokawa",
        "Namiko Saito",
        "Kensuke Harada"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-16 08:24:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14551v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14550v1",
      "title": "Faster Pseudo-Deterministic Minimum Cut",
      "abstract": "Pseudo-deterministic algorithms are randomized algorithms that, with high constant probability, output a fixed canonical solution. The study of pseudo-deterministic algorithms for the global minimum cut problem was recently initiated by Agarwala and Varma [ITCS'26], who gave a black-box reduction incurring an $O(\\log n \\log \\log n)$ overhead. We introduce a natural graph-theoretic tie-breaking mechanism that uniquely selects a canonical minimum cut. Using this mechanism, we obtain: (i) A pseudo-deterministic minimum cut algorithm for weighted graphs running in $O(m\\log^2 n)$ time, eliminating the $O(\\log n \\log \\log n)$ overhead of prior work and matching existing randomized algorithms. (ii) The first pseudo-deterministic algorithm for maintaining a canonical minimum cut in a fully-dynamic unweighted graph, with $\\mathrm{polylog}(n)$ update time and $\\tilde{O}(n)$ query time. (iii) Improved pseudo-deterministic algorithms for unweighted graphs in the dynamic streaming and cut-query models of computation, matching the best randomized algorithms.",
      "authors": [
        "Yotam Kenneth-Mordoch"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-02-16 08:14:55+00:00",
      "link": "https://arxiv.org/pdf/2602.14550v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14544v1",
      "title": "A New Approach in Cryptanalysis Through Combinatorial Equivalence of Cryptosystems",
      "abstract": "We propose a new approach in cryptanalysis based on an evolution of the concept of \\textit{Combinatorial Equivalence}. The aim is to rewrite a cryptosystem under a combinatorially equivalent form in order to make appear new properties that are more strongly discriminating the secret key used during encryption. We successfully applied this approach to the most secure stream ciphers category nowadays. We first define a concept cipher called Cipherbent6 that capture most of the difficulty of stream cipher cryptanalysis. We significantly outperformed all known cryptanalysis. We applied this approach to the Achterbahn cipher and we obtained again far better cryptanalysis results.",
      "authors": [
        "Jaagup Sepp",
        "Eric Filiol"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-16 08:07:41+00:00",
      "link": "https://arxiv.org/pdf/2602.14544v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14543v1",
      "title": "Truly Adapting to Adversarial Constraints in Constrained MABs",
      "abstract": "We study the constrained variant of the \\emph{multi-armed bandit} (MAB) problem, in which the learner aims not only at minimizing the total loss incurred during the learning dynamic, but also at controlling the violation of multiple \\emph{unknown} constraints, under both \\emph{full} and \\emph{bandit feedback}. We consider a non-stationary environment that subsumes both stochastic and adversarial models and where, at each round, both losses and constraints are drawn from distributions that may change arbitrarily over time. In such a setting, it is provably not possible to guarantee both sublinear regret and sublinear violation. Accordingly, prior work has mainly focused either on settings with stochastic constraints or on relaxing the benchmark with fully adversarial constraints (\\emph{e.g.}, via competitive ratios with respect to the optimum). We provide the first algorithms that achieve optimal rates of regret and \\emph{positive} constraint violation when the constraints are stochastic while the losses may vary arbitrarily, and that simultaneously yield guarantees that degrade smoothly with the degree of adversariality of the constraints. Specifically, under \\emph{full feedback} we propose an algorithm attaining $\\widetilde{\\mathcal{O}}(\\sqrt{T}+C)$ regret and $\\widetilde{\\mathcal{O}}(\\sqrt{T}+C)$ {positive} violation, where $C$ quantifies the amount of non-stationarity in the constraints. We then show how to extend these guarantees when only bandit feedback is available for the losses. Finally, when \\emph{bandit feedback} is available for the constraints, we design an algorithm achieving $\\widetilde{\\mathcal{O}}(\\sqrt{T}+C)$ {positive} violation and $\\widetilde{\\mathcal{O}}(\\sqrt{T}+C\\sqrt{T})$ regret.",
      "authors": [
        "Francesco Emanuele Stradi",
        "Kalana Kalupahana",
        "Matteo Castiglioni",
        "Alberto Marchesi",
        "Nicola Gatti"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-16 08:07:11+00:00",
      "link": "https://arxiv.org/pdf/2602.14543v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14540v1",
      "title": "Multimodal Covariance Steering in Belief Space with Active Probing and Influence for Autonomous Driving",
      "abstract": "Autonomous driving in complex traffic requires reasoning under uncertainty. Common approaches rely on prediction-based planning or risk-aware control, but these are typically treated in isolation, limiting their ability to capture the coupled nature of action and inference in interactive settings. This gap becomes especially critical in uncertain scenarios, where simply reacting to predictions can lead to unsafe maneuvers or overly conservative behavior. Our central insight is that safe interaction requires not only estimating human behavior but also shaping it when ambiguity poses risks. To this end, we introduce a hierarchical belief model that structures human behavior across coarse discrete intents and fine motion modes, updated via Bayesian inference for interpretable multi-resolution reasoning. On top of this, we develop an active probing strategy that identifies when multimodal ambiguity in human predictions may compromise safety and plans disambiguating actions that both reveal intent and gently steer human decisions toward safer outcomes. Finally, a runtime risk-evaluation layer based on Conditional Value-at-Risk (CVaR) ensures that all probing actions remain within human risk tolerance during influence. Our simulations in lane-merging and unsignaled intersection scenarios demonstrate that our approach achieves higher success rates and shorter completion times compared to existing methods. These results highlight the benefit of coupling belief inference, probing, and risk monitoring, yielding a principled and interpretable framework for planning under uncertainty.",
      "authors": [
        "Devodita Chakravarty",
        "John Dolan",
        "Yiwei Lyu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-16 08:04:16+00:00",
      "link": "https://arxiv.org/pdf/2602.14540v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14539v1",
      "title": "When Security Meets Usability: An Empirical Investigation of Post-Quantum Cryptography APIs",
      "abstract": "Advances in quantum computing increasingly threaten the security and privacy of data protected by current cryptosystems, particularly those relying on public-key cryptography. In response, the international cybersecurity community has prioritized the implementation of Post-Quantum Cryptography (PQC), a new cryptographic standard designed to resist quantum attacks while operating on classical computers. The National Institute of Standards and Technology (NIST) has already standardized several PQC algorithms and plans to deprecate classical asymmetric schemes, such as RSA and ECDSA, by 2035. Despite this urgency, PQC adoption remains slow, often due to limited developer expertise. Application Programming Interfaces (APIs) are intended to bridge this gap, yet prior research on classical security APIs demonstrates that poor usability of cryptographic APIs can lead developers to introduce vulnerabilities during implementation of the applications, a risk amplified by the novelty and complexity of PQC. To date, the usability of PQC APIs has not been systematically studied. This research presents an empirical evaluation of the usability of the PQC APIs, observing how developers interact with APIs and documentation during software development tasks. The study identifies cognitive factors that influence the developer's performance when working with PQC primitives with minimal onboarding. The findings highlight opportunities across the PQC ecosystem to improve developer-facing guidance, terminology alignment, and workflow examples to better support non-specialists.",
      "authors": [
        "Marthin Toruan",
        "R. D. N. Shakya",
        "Samuel Tseitkin",
        "Raymond K. Zhao",
        "Nalin Arachchilage"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.SE"
      ],
      "published": "2026-02-16 07:59:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14539v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14536v1",
      "title": "Explainable Token-level Noise Filtering for LLM Fine-tuning Datasets",
      "abstract": "Large Language Models (LLMs) have seen remarkable advancements, achieving state-of-the-art results in diverse applications. Fine-tuning, an important step for adapting LLMs to specific downstream tasks, typically involves further training on corresponding datasets. However, a fundamental discrepancy exists between current fine-tuning datasets and the token-level optimization mechanism of LLMs: most datasets are designed at the sentence-level, which introduces token-level noise, causing negative influence to final performance. In this paper, we propose XTF, an explainable token-level noise filtering framework. XTF decomposes the complex and subtle contributions of token-level data to the fine-tuning process into three distinct and explicit attributes (reasoning importance, knowledge novelty, and task relevance), which can be assessed using scoring methods, and then masks the gradients of selected noisy tokens accordingly to optimize the performance of fine-tuned LLMs. We conduct extensive experiments on three representative downstream tasks (math, code and medicine) across 7 mainstream LLMs. The results demonstrate that XTF can significantly improve downstream performance by up to 13.7% compared to regular fine-tuning. Our work highlights the importance of token-level dataset optimization, and demonstrates the potential of strategies based on attribute decomposition for explaining complex training mechanisms.",
      "authors": [
        "Yuchen Yang",
        "Wenze Lin",
        "Enhao Huang",
        "Zhixuan Chu",
        "Hongbin Zhou",
        "Lan Tao",
        "Yiming Li",
        "Zhan Qin",
        "Kui Ren"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-16 07:49:33+00:00",
      "link": "https://arxiv.org/pdf/2602.14536v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14534v1",
      "title": "MoRL: Reinforced Reasoning for Unified Motion Understanding and Generation",
      "abstract": "Human motion understanding and generation are crucial for vision and robotics but remain limited in reasoning capability and test-time planning. We propose MoRL, a unified multimodal motion model trained with supervised fine-tuning and reinforcement learning with verifiable rewards. Our task-specific reward design combines semantic alignment and reasoning coherence for understanding with physical plausibility and text-motion consistency for generation, improving both logical reasoning and perceptual realism. To further enhance inference, we introduce Chain-of-Motion (CoM), a test-time reasoning method that enables step-by-step planning and reflection. We also construct two large-scale CoT datasets, MoUnd-CoT-140K and MoGen-CoT-140K, to align motion sequences with reasoning traces and action descriptions. Experiments on HumanML3D and KIT-ML show that MoRL achieves significant gains over state-of-the-art baselines. Code: https://github.com/AIGeeksGroup/MoRL. Website: https://aigeeksgroup.github.io/MoRL.",
      "authors": [
        "Hongpeng Wang",
        "Zeyu Zhang",
        "Wenhao Li",
        "Hao Tang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 07:42:45+00:00",
      "link": "https://arxiv.org/pdf/2602.14534v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15078v1",
      "title": "Computer Science as Infrastructure: the Spine of the Lean Computer Science Library (CSLib)",
      "abstract": "Following in the footsteps of the success of Mathlib - the centralised library of formalised mathematics in Lean - CSLib is a rapidly-growing centralised library of formalised computer science and software. In this paper, we present its founding technical principles, operation, abstractions, and semantic framework. We contribute reusable semantic interfaces (reduction and labelled transition systems), proof automation, CI/testing support for maintaining automation and compatibility with Mathlib, and the first substantial developments of languages and models.",
      "authors": [
        "Christopher Henson",
        "Fabrizio Montesi"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "cs.PL"
      ],
      "published": "2026-02-16 07:41:16+00:00",
      "link": "https://arxiv.org/pdf/2602.15078v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14529v1",
      "title": "Disentangling Deception and Hallucination Failures in LLMs",
      "abstract": "Failures in large language models (LLMs) are often analyzed from a behavioral perspective, where incorrect outputs in factual question answering are commonly associated with missing knowledge. In this work, focusing on entity-based factual queries, we suggest that such a view may conflate different failure mechanisms, and propose an internal, mechanism-oriented perspective that separates Knowledge Existence from Behavior Expression. Under this formulation, hallucination and deception correspond to two qualitatively different failure modes that may appear similar at the output level but differ in their underlying mechanisms. To study this distinction, we construct a controlled environment for entity-centric factual questions in which knowledge is preserved while behavioral expression is selectively altered, enabling systematic analysis of four behavioral cases. We analyze these failure modes through representation separability, sparse interpretability, and inference-time activation steering.",
      "authors": [
        "Haolang Lu",
        "Hongrui Peng",
        "WeiYe Fu",
        "Guoshun Nan",
        "Xinye Cao",
        "Xingrui Li",
        "Hongcan Guo",
        "Kun Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 07:36:49+00:00",
      "link": "https://arxiv.org/pdf/2602.14529v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14528v1",
      "title": "Patient-Made Knowledge Networks: Long COVID Discourse, Epistemic Injustice, and Online Community Formation",
      "abstract": "Long COVID represents an unprecedented case of patient-led illness definition, emerging through Twitter in May 2020 when patients began collectively naming, documenting, and legitimizing their condition before medical institutions recognized it. This study examines 2.8 million tweets containing #LongCOVID to understand how contested illness communities construct knowledge networks and respond to epistemic injustice. Through topic modeling, reflexive thematic analysis, and exponential random graph modeling (ERGM), we identify seven discourse themes spanning symptom documentation, medical dismissal, cross-illness solidarity, and policy advocacy. Our analysis reveals a differentiated ecosystem of user roles -- including patient advocates, research coordinators, and citizen scientists -- who collectively challenge medical gatekeeping while building connections to established ME/CFS advocacy networks. ERGM results demonstrate that tie formation centers on epistemic practices: users discussing knowledge sharing and community building formed significantly more network connections than those focused on policy debates, supporting characterization of this space as an epistemic community. Long COVID patients experienced medical gaslighting patterns documented across contested illnesses, yet achieved WHO recognition within months -- contrasting sharply with decades-long struggles of similar conditions. These findings illuminate how social media affordances enable marginalized patient populations to rapidly construct alternative knowledge systems, form cross-illness coalitions, and contest traditional medical authority structures.",
      "authors": [
        "Tawfiq Ammari"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-16 07:28:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14528v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14526v1",
      "title": "TWISTED-RL: Hierarchical Skilled Agents for Knot-Tying without Human Demonstrations",
      "abstract": "Robotic knot-tying represents a fundamental challenge in robotics due to the complex interactions between deformable objects and strict topological constraints. We present TWISTED-RL, a framework that improves upon the previous state-of-the-art in demonstration-free knot-tying (TWISTED), which smartly decomposed a single knot-tying problem into manageable subproblems, each addressed by a specialized agent. Our approach replaces TWISTED's single-step inverse model that was learned via supervised learning with a multi-step Reinforcement Learning policy conditioned on abstract topological actions rather than goal states. This change allows more delicate topological state transitions while avoiding costly and ineffective data collection protocols, thus enabling better generalization across diverse knot configurations. Experimental results demonstrate that TWISTED-RL manages to solve previously unattainable knots of higher complexity, including commonly used knots such as the Figure-8 and the Overhand. Furthermore, the increase in success rates and drop in planning time establishes TWISTED-RL as the new state-of-the-art in robotic knot-tying without human demonstrations.",
      "authors": [
        "Guy Freund",
        "Tom Jurgenson",
        "Matan Sudry",
        "Erez Karpas"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-16 07:21:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14526v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14525v1",
      "title": "Cross-view Domain Generalization via Geometric Consistency for LiDAR Semantic Segmentation",
      "abstract": "Domain-generalized LiDAR semantic segmentation (LSS) seeks to train models on source-domain point clouds that generalize reliably to multiple unseen target domains, which is essential for real-world LiDAR applications. However, existing approaches assume similar acquisition views (e.g., vehicle-mounted) and struggle in cross-view scenarios, where observations differ substantially due to viewpoint-dependent structural incompleteness and non-uniform point density. Accordingly, we formulate cross-view domain generalization for LiDAR semantic segmentation and propose a novel framework, termed CVGC (Cross-View Geometric Consistency). Specifically, we introduce a cross-view geometric augmentation module that models viewpoint-induced variations in visibility and sampling density, generating multiple cross-view observations of the same scene. Subsequently, a geometric consistency module enforces consistent semantic and occupancy predictions across geometrically augmented point clouds of the same scene. Extensive experiments on six public LiDAR datasets establish the first systematic evaluation of cross-view domain generalization for LiDAR semantic segmentation, demonstrating that CVGC consistently outperforms state-of-the-art methods when generalizing from a single source domain to multiple target domains with heterogeneous acquisition viewpoints. The source code will be publicly available at https://github.com/KintomZi/CVGC-DG",
      "authors": [
        "Jindong Zhao",
        "Yuan Gao",
        "Yang Xia",
        "Sheng Nie",
        "Jun Yue",
        "Weiwei Sun",
        "Shaobo Xia"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 07:19:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14525v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14524v1",
      "title": "Error Patterns in Historical OCR: A Comparative Analysis of TrOCR and a Vision-Language Model",
      "abstract": "Optical Character Recognition (OCR) of eighteenth-century printed texts remains challenging due to degraded print quality, archaic glyphs, and non-standardized orthography. Although transformer-based OCR systems and Vision-Language Models (VLMs) achieve strong aggregate accuracy, metrics such as Character Error Rate (CER) and Word Error Rate (WER) provide limited insight into their reliability for scholarly use. We compare a dedicated OCR transformer (TrOCR) and a general-purpose Vision-Language Model (Qwen) on line-level historical English texts using length-weighted accuracy metrics and hypothesis driven error analysis.   While Qwen achieves lower CER/WER and greater robustness to degraded input, it exhibits selective linguistic regularization and orthographic normalization that may silently alter historically meaningful forms. TrOCR preserves orthographic fidelity more consistently but is more prone to cascading error propagation. Our findings show that architectural inductive biases shape OCR error structure in systematic ways. Models with similar aggregate accuracy can differ substantially in error locality, detectability, and downstream scholarly risk, underscoring the need for architecture-aware evaluation in historical digitization workflows.",
      "authors": [
        "Ari Vesalainen",
        "Eetu Mäkelä",
        "Laura Ruotsalainen",
        "Mikko Tolonen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 07:17:52+00:00",
      "link": "https://arxiv.org/pdf/2602.14524v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14523v1",
      "title": "Architectural Insights for Post-Tornado Damage Recognition",
      "abstract": "Rapid and accurate building damage assessment in the immediate aftermath of tornadoes is critical for coordinating life-saving search and rescue operations, optimizing emergency resource allocation, and accelerating community recovery. However, current automated methods struggle with the unique visual complexity of tornado-induced wreckage, primarily due to severe domain shift from standard pre-training datasets and extreme class imbalance in real-world disaster data. To address these challenges, we introduce a systematic experimental framework evaluating 79 open-source deep learning models, encompassing both Convolutional Neural Networks (CNNs) and Vision Transformers, across over 2,300 controlled experiments on our newly curated Quad-State Tornado Damage (QSTD) benchmark dataset. Our findings reveal that achieving operational-grade performance hinges on a complex interaction between architecture and optimization, rather than architectural selection alone. Most strikingly, we demonstrate that optimizer choice can be more consequential than architecture: switching from Adam to SGD provided dramatic F1 gains of +25 to +38 points for Vision Transformer and Swin Transformer families, fundamentally reversing their ranking from bottom-tier to competitive with top-performing CNNs. Furthermore, a low learning rate of 1x10^(-4) proved universally critical, boosting average F1 performance by +10.2 points across all architectures. Our champion model, ConvNeXt-Base trained with these optimized settings, demonstrated strong cross-event generalization on the held-out Tuscaloosa-Moore Tornado Damage (TMTD) dataset, achieving 46.4% Macro F1 (+34.6 points over baseline) and retaining 85.5% Ordinal Top-1 Accuracy despite temporal and sensor domain shifts.",
      "authors": [
        "Robinson Umeike",
        "Thang Dao",
        "Shane Crawford",
        "John van de Lindt",
        "Blythe Johnston",
        "Wanting",
        "Wang",
        "Trung Do",
        "Ajibola Mofikoya",
        "Sarbesh Banjara",
        "Cuong Pham"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 07:16:33+00:00",
      "link": "https://arxiv.org/pdf/2602.14523v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14519v1",
      "title": "DeepMTL2R: A Library for Deep Multi-task Learning to Rank",
      "abstract": "This paper presents DeepMTL2R, an open-source deep learning framework for Multi-task Learning to Rank (MTL2R), where multiple relevance criteria must be optimized simultaneously. DeepMTL2R integrates heterogeneous relevance signals into a unified, context-aware model by leveraging the self-attention mechanism of transformer architectures, enabling effective learning across diverse and potentially conflicting objectives. The framework includes 21 state-of-the-art multi-task learning algorithms and supports multi-objective optimization to identify Pareto-optimal ranking models. By capturing complex dependencies and long-range interactions among items and labels, DeepMTL2R provides a scalable and expressive solution for modern ranking systems and facilitates controlled comparisons across MTL strategies. We demonstrate its effectiveness on a publicly available dataset, report competitive performance, and visualize the resulting trade-offs among objectives. DeepMTL2R is available at \\href{https://github.com/amazon-science/DeepMTL2R}{https://github.com/amazon-science/DeepMTL2R}.",
      "authors": [
        "Chaosheng Dong",
        "Peiyao Xiao",
        "Yijia Wang",
        "Kaiyi Ji"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.IR"
      ],
      "published": "2026-02-16 07:11:38+00:00",
      "link": "https://arxiv.org/pdf/2602.14519v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14518v1",
      "title": "Diagnosing Knowledge Conflict in Multimodal Long-Chain Reasoning",
      "abstract": "Multimodal large language models (MLLMs) in long chain-of-thought reasoning often fail when different knowledge sources provide conflicting signals. We formalize these failures under a unified notion of knowledge conflict, distinguishing input-level objective conflict from process-level effective conflict. Through probing internal representations, we reveal that: (I) Linear Separability: different conflict types are explicitly encoded as linearly separable features rather than entangled; (II) Depth Localization: conflict signals concentrate in mid-to-late layers, indicating a distinct processing stage for conflict encoding; (III) Hierarchical Consistency: aggregating noisy token-level signals along trajectories robustly recovers input-level conflict types; and (IV) Directional Asymmetry: reinforcing the model's implicit source preference under conflict is far easier than enforcing the opposite source. Our findings provide a mechanism-level view of multimodal reasoning under knowledge conflict and enable principled diagnosis and control of long-CoT failures.",
      "authors": [
        "Jing Tang",
        "Kun Wang",
        "Haolang Lu",
        "Hongjin Chen",
        "KaiTao Chen",
        "Zhongxiang Sun",
        "Qiankun Li",
        "Lingjuan Lyu",
        "Guoshun Nan",
        "Zhigang Zeng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 07:10:44+00:00",
      "link": "https://arxiv.org/pdf/2602.14518v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14517v1",
      "title": "Beyond Translation: Evaluating Mathematical Reasoning Capabilities of LLMs in Sinhala and Tamil",
      "abstract": "Large language models (LLMs) demonstrate strong mathematical reasoning in English, but whether these capabilities reflect genuine multilingual reasoning or reliance on translation-based processing in low-resource languages like Sinhala and Tamil remains unclear. We examine this fundamental question by evaluating whether LLMs genuinely reason mathematically in these languages or depend on implicit translation to English-like representations. Using a taxonomy of six math problem types, from basic arithmetic to complex unit conflict and optimization problems, we evaluate four prominent large language models. To avoid translation artifacts that confound language ability with translation quality, we construct a parallel dataset where each problem is natively authored by fluent speakers with mathematical training in all three languages. Our analysis demonstrates that while basic arithmetic reasoning transfers robustly across languages, complex reasoning tasks show significant degradation in Tamil and Sinhala. The pattern of failures varies by model and problem type, suggesting that apparent multilingual competence may not reflect uniform reasoning capabilities across languages. These findings challenge the common assumption that models exhibiting strong multilingual performance can reason equally effectively across languages, and highlight the need for fine-grained, type-aware evaluation in multilingual settings.",
      "authors": [
        "Sukumar Kishanthan",
        "Kumar Thushalika",
        "Buddhi Jayasekara",
        "Asela Hevapathige"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-16 07:08:37+00:00",
      "link": "https://arxiv.org/pdf/2602.14517v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14516v1",
      "title": "Efficient Multi-round LLM Inference over Disaggregated Serving",
      "abstract": "With the rapid evolution of Large Language Models (LLMs), multi-round workflows, such as autonomous agents and iterative retrieval, have become increasingly prevalent. However, this raises hurdles for serving LLMs under prefill-decode (PD) disaggregation, a widely adopted paradigm that separates the compute-bound prefill phase and memory-bound decode phase onto individual resources. Specifically, existing systems overlook the interleaved prefill-decode workload pattern in multi-round inference, leading to sub-optimal handling of the incremental prefill workloads and model deployment for the two phases.   In this work, we present AMPD, a brand new disaggregated serving framework for multi-round LLM inference. The core of AMPD is to coordinate the prefill workloads based on real-time workloads by adaptively determining where to carry out these workloads and how they are scheduled, in order to maximize service level objective (SLO) attainment. In addition, we tailor a planning algorithm for our scenario, facilitating the deduction of optimal resource allocation and parallel strategies for the two phases. Empirical results demonstrate that AMPD substantially improves SLO attainment compared to state-of-the-art baselines.",
      "authors": [
        "Wenhao He",
        "Youhe Jiang",
        "Penghao Zhao",
        "Quanqing Xu",
        "Eiko Yoneki",
        "Bin Cui",
        "Fangcheng Fu"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC"
      ],
      "published": "2026-02-16 07:07:30+00:00",
      "link": "https://arxiv.org/pdf/2602.14516v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14514v1",
      "title": "Efficient Text-Guided Convolutional Adapter for the Diffusion Model",
      "abstract": "We introduce the Nexus Adapters, novel text-guided efficient adapters to the diffusion-based framework for the Structure Preserving Conditional Generation (SPCG). Recently, structure-preserving methods have achieved promising results in conditional image generation by using a base model for prompt conditioning and an adapter for structure input, such as sketches or depth maps. These approaches are highly inefficient and sometimes require equal parameters in the adapter compared to the base architecture. It is not always possible to train the model since the diffusion model is itself costly, and doubling the parameter is highly inefficient. In these approaches, the adapter is not aware of the input prompt; therefore, it is optimal only for the structural input but not for the input prompt. To overcome the above challenges, we proposed two efficient adapters, Nexus Prime and Slim, which are guided by prompts and structural inputs. Each Nexus Block incorporates cross-attention mechanisms to enable rich multimodal conditioning. Therefore, the proposed adapter has a better understanding of the input prompt while preserving the structure. We conducted extensive experiments on the proposed models and demonstrated that the Nexus Prime adapter significantly enhances performance, requiring only 8M additional parameters compared to the baseline, T2I-Adapter. Furthermore, we also introduced a lightweight Nexus Slim adapter with 18M fewer parameters than the T2I-Adapter, which still achieved state-of-the-art results. Code: https://github.com/arya-domain/Nexus-Adapters",
      "authors": [
        "Aryan Das",
        "Koushik Biswas",
        "Swalpa Kumar Roy",
        "Badri Narayana Patro",
        "Vinay Kumar Verma"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 06:51:29+00:00",
      "link": "https://arxiv.org/pdf/2602.14514v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14512v1",
      "title": "MedVAR: Towards Scalable and Efficient Medical Image Generation via Next-scale Autoregressive Prediction",
      "abstract": "Medical image generation is pivotal in applications like data augmentation for low-resource clinical tasks and privacy-preserving data sharing. However, developing a scalable generative backbone for medical imaging requires architectural efficiency, sufficient multi-organ data, and principled evaluation, yet current approaches leave these aspects unresolved. Therefore, we introduce MedVAR, the first autoregressive-based foundation model that adopts the next-scale prediction paradigm to enable fast and scale-up-friendly medical image synthesis. MedVAR generates images in a coarse-to-fine manner and produces structured multi-scale representations suitable for downstream use. To support hierarchical generation, we curate a harmonized dataset of around 440,000 CT and MRI images spanning six anatomical regions. Comprehensive experiments across fidelity, diversity, and scalability show that MedVAR achieves state-of-the-art generative performance and offers a promising architectural direction for future medical generative foundation models.",
      "authors": [
        "Zhicheng He",
        "Yunpeng Zhao",
        "Junde Wu",
        "Ziwei Niu",
        "Zijun Li",
        "Lanfen Lin",
        "Yueming Jin"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 06:48:48+00:00",
      "link": "https://arxiv.org/pdf/2602.14512v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14509v1",
      "title": "MacNet: An End-to-End Manifold-Constrained Adaptive Clustering Network for Interpretable Whole Slide Image Classification",
      "abstract": "Whole slide images (WSIs) are the gold standard for pathological diagnosis and sub-typing. Current main-stream two-step frameworks employ offline feature encoders trained without domain-specific knowledge. Among them, attention-based multiple instance learning (MIL) methods are outcome-oriented and offer limited interpretability. Clustering-based approaches can provide explainable decision-making process but suffer from high dimension features and semantically ambiguous centroids. To this end, we propose an end-to-end MIL framework that integrates Grassmann re-embedding and manifold adaptive clustering, where the manifold geometric structure facilitates robust clustering results. Furthermore, we design a prior knowledge guiding proxy instance labeling and aggregation strategy to approximate patch labels and focus on pathologically relevant tumor regions. Experiments on multicentre WSI datasets demonstrate that: 1) our cluster-incorporated model achieves superior performance in both grading accuracy and interpretability; 2) end-to-end learning refines better feature representations and it requires acceptable computation resources.",
      "authors": [
        "Mingrui Ma",
        "Chentao Li",
        "Pan Huang",
        "Jing Qin"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 06:43:36+00:00",
      "link": "https://arxiv.org/pdf/2602.14509v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14506v1",
      "title": "Covariance-Aware Transformers for Quadratic Programming and Decision Making",
      "abstract": "We explore the use of transformers for solving quadratic programs and how this capability benefits decision-making problems that involve covariance matrices. We first show that the linear attention mechanism can provably solve unconstrained QPs by tokenizing the matrix variables (e.g.~$A$ of the objective $\\frac{1}{2}x^\\top Ax+b^\\top x$) row-by-row and emulating gradient descent iterations. Furthermore, by incorporating MLPs, a transformer block can solve (i) $\\ell_1$-penalized QPs by emulating iterative soft-thresholding and (ii) $\\ell_1$-constrained QPs when equipped with an additional feedback loop. Our theory motivates us to introduce Time2Decide: a generic method that enhances a time series foundation model (TSFM) by explicitly feeding the covariance matrix between the variates. We empirically find that Time2Decide uniformly outperforms the base TSFM model for the classical portfolio optimization problem that admits an $\\ell_1$-constrained QP formulation. Remarkably, Time2Decide also outperforms the classical \"Predict-then-Optimize (PtO)\" procedure, where we first forecast the returns and then explicitly solve a constrained QP, in suitable settings. Our results demonstrate that transformers benefit from explicit use of second-order statistics, and this can enable them to effectively solve complex decision-making problems, like portfolio construction, in one forward pass.",
      "authors": [
        "Kutay Tire",
        "Yufan Zhang",
        "Ege Onur Taga",
        "Samet Oymak"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 06:39:24+00:00",
      "link": "https://arxiv.org/pdf/2602.14506v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14505v1",
      "title": "Formally Verifying and Explaining Sepsis Treatment Policies with COOL-MC",
      "abstract": "Safe and interpretable sequential decision-making is critical in healthcare, yet reinforcement learning (RL) policies for sepsis treatment optimization remain opaque and difficult to verify. Standard probabilistic model checkers operate on the full state space, which becomes infeasible for larger MDPs, and cannot explain why a learned policy makes particular decisions. COOL-MC wraps the model checker Storm but adds three key capabilities: it constructs only the reachable state space induced by a trained policy, yielding a smaller discrete-time Markov chain amenable to verification even when full-MDP analysis is intractable; it automatically labels states with clinically meaningful atomic propositions; and it integrates explainability methods with probabilistic computation tree logic (PCTL) queries to reveal which features drive decisions across treatment trajectories. We demonstrate COOL-MC's capabilities on the ICU-Sepsis MDP, a benchmark derived from approximately 17,000 sepsis patient records, which serves as a case study for applying COOL-MC to the formal analysis of sepsis treatment policies. Our analysis establishes hard bounds via full MDP verification, trains a safe RL policy that achieves optimal survival probability, and analyzes its behavior via PCTL verification and explainability on the induced DTMC. This reveals, for instance, that our trained policy relies predominantly on prior dosing history rather than the patient's evolving condition, a weakness that is invisible to standard evaluation but is exposed by COOL-MC's integration of formal verification and explainability. Our results illustrate how COOL-MC could serve as a tool for clinicians to investigate and debug sepsis treatment policies before deployment.",
      "authors": [
        "Dennis Gross"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-16 06:37:34+00:00",
      "link": "https://arxiv.org/pdf/2602.14505v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14503v1",
      "title": "Bounding Probabilities of Causation with Partial Causal Diagrams",
      "abstract": "Probabilities of causation are fundamental to individual-level explanation and decision making, yet they are inherently counterfactual and not point-identifiable from data in general. Existing bounds either disregard available covariates, require complete causal graphs, or rely on restrictive binary settings, limiting their practical use. In real-world applications, causal information is often partial but nontrivial. This paper proposes a general framework for bounding probabilities of causation using partial causal information. We show how the available structural or statistical information can be systematically incorporated as constraints in a optimization programming formulation, yielding tighter and formally valid bounds without full identifiability. This approach extends the applicability of probabilities of causation to realistic settings where causal knowledge is incomplete but informative.",
      "authors": [
        "Yuxuan Xie",
        "Ang Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 06:35:24+00:00",
      "link": "https://arxiv.org/pdf/2602.14503v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14502v1",
      "title": "Behavioral Feature Boosting via Substitute Relationships for E-commerce Search",
      "abstract": "On E-commerce platforms, new products often suffer from the cold-start problem: limited interaction data reduces their search visibility and hurts relevance ranking. To address this, we propose a simple yet effective behavior feature boosting method that leverages substitute relationships among products (BFS). BFS identifies substitutes-products that satisfy similar user needs-and aggregates their behavioral signals (e.g., clicks, add-to-carts, purchases, and ratings) to provide a warm start for new items. Incorporating these enriched signals into ranking models mitigates cold-start effects and improves relevance and competitiveness. Experiments on a large E-commerce platform, both offline and online, show that BFS significantly improves search relevance and product discovery for cold-start products. BFS is scalable and practical, improving user experience while increasing exposure for newly launched items in E-commerce search. The BFS-enhanced ranking model has been launched in production and has served customers since 2025.",
      "authors": [
        "Chaosheng Dong",
        "Michinari Momma",
        "Yijia Wang",
        "Yan Gao",
        "Yi Sun"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-16 06:35:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14502v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14501v1",
      "title": "Prototype Instance-semantic Disentanglement with Low-rank Regularized Subspace Clustering for WSIs Explainable Recognition",
      "abstract": "The tumor region plays a key role in pathological diagnosis. Tumor tissues are highly similar to precancerous lesions and non tumor instances often greatly exceed tumor instances in whole slide images (WSIs). These issues cause instance-semantic entanglement in multi-instance learning frameworks, degrading both model representation capability and interpretability. To address this, we propose an end-to-end prototype instance semantic disentanglement framework with low-rank regularized subspace clustering, PID-LRSC, in two aspects. First, we use secondary instance subspace learning to construct low-rank regularized subspace clustering (LRSC), addressing instance entanglement caused by an excessive proportion of non tumor instances. Second, we employ enhanced contrastive learning to design prototype instance semantic disentanglement (PID), resolving semantic entanglement caused by the high similarity between tumor and precancerous tissues. We conduct extensive experiments on multicentre pathology datasets, implying that PID-LRSC outperforms other SOTA methods. Overall, PID-LRSC provides clearer instance semantics during decision-making and significantly enhances the reliability of auxiliary diagnostic outcomes.",
      "authors": [
        "Chentao Li",
        "Pan Huang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 06:33:16+00:00",
      "link": "https://arxiv.org/pdf/2602.14501v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14498v1",
      "title": "Uncertainty-Aware Vision-Language Segmentation for Medical Imaging",
      "abstract": "We introduce a novel uncertainty-aware multimodal segmentation framework that leverages both radiological images and associated clinical text for precise medical diagnosis. We propose a Modality Decoding Attention Block (MoDAB) with a lightweight State Space Mixer (SSMix) to enable efficient cross-modal fusion and long-range dependency modelling. To guide learning under ambiguity, we propose the Spectral-Entropic Uncertainty (SEU) Loss, which jointly captures spatial overlap, spectral consistency, and predictive uncertainty in a unified objective. In complex clinical circumstances with poor image quality, this formulation improves model reliability. Extensive experiments on various publicly available medical datasets, QATA-COVID19, MosMed++, and Kvasir-SEG, demonstrate that our method achieves superior segmentation performance while being significantly more computationally efficient than existing State-of-the-Art (SoTA) approaches. Our results highlight the importance of incorporating uncertainty modelling and structured modality alignment in vision-language medical segmentation tasks. Code: https://github.com/arya-domain/UA-VLS",
      "authors": [
        "Aryan Das",
        "Tanishq Rachamalla",
        "Koushik Biswas",
        "Swalpa Kumar Roy",
        "Vinay Kumar Verma"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-16 06:27:51+00:00",
      "link": "https://arxiv.org/pdf/2602.14498v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14495v1",
      "title": "Divine Benevolence is an $x^2$: GLUs scale asymptotically faster than MLPs",
      "abstract": "Scaling laws can be understood from ground-up numerical analysis, where traditional function approximation theory can explain shifts in model architecture choices. GLU variants now dominate frontier LLMs and similar outer-product architectures are prevalent in ranking models. The success of these architectures has mostly been left as an empirical discovery. In this paper, we apply the tools of numerical analysis to expose a key factor: these models have an $x^2$ which enables \\emph{asymptotically} faster scaling than MLPs. GLUs have piecewise quadratic functional forms that are sufficient to exhibit quadratic order of approximation. Our key contribution is to demonstrate that the $L(P)$ scaling slope is $L(P)\\propto P^{-3}$ for GLUs but only $L(P)=P^{-2}$ for MLPs on function reconstruction problems. We provide a parameter construction and empirical verification of these slopes for 1D function approximation. From the first principles we discover, we make one stride and propose the ``Gated Quadratic Unit'' which has an even steeper $L(P)$ slope than the GLU and MLP. This opens the possibility of architecture design from first principles numerical theory to unlock superior scaling in large models. Replication code is available at https://github.com/afqueiruga/divine_scaling.",
      "authors": [
        "Alejandro Francisco Queiruga"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 06:19:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14495v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14493v1",
      "title": "Gaussian Mesh Renderer for Lightweight Differentiable Rendering",
      "abstract": "3D Gaussian Splatting (3DGS) has enabled high-fidelity virtualization with fast rendering and optimization for novel view synthesis. On the other hand, triangle mesh models still remain a popular choice for surface reconstruction but suffer from slow or heavy optimization in traditional mesh-based differentiable renderers. To address this problem, we propose a new lightweight differentiable mesh renderer leveraging the efficient rasterization process of 3DGS, named Gaussian Mesh Renderer (GMR), which tightly integrates the Gaussian and mesh representations. Each Gaussian primitive is analytically derived from the corresponding mesh triangle, preserving structural fidelity and enabling the gradient flow. Compared to the traditional mesh renderers, our method achieves smoother gradients, which especially contributes to better optimization using smaller batch sizes with limited memory. Our implementation is available in the public GitHub repository at https://github.com/huntorochi/Gaussian-Mesh-Renderer.",
      "authors": [
        "Xinpeng Liu",
        "Fumio Okura"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.GR"
      ],
      "published": "2026-02-16 06:15:42+00:00",
      "link": "https://arxiv.org/pdf/2602.14493v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14492v2",
      "title": "Query as Anchor: Scenario-Adaptive User Representation via Large Language Model",
      "abstract": "Industrial-scale user representation learning requires balancing robust universality with acute task-sensitivity. However, existing paradigms primarily yield static, task-agnostic embeddings that struggle to reconcile the divergent requirements of downstream scenarios within unified vector spaces. Furthermore, heterogeneous multi-source data introduces inherent noise and modality conflicts, degrading representation. We propose Query-as-Anchor, a framework shifting user modeling from static encoding to dynamic, query-aware synthesis. To empower Large Language Models (LLMs) with deep user understanding, we first construct UserU, an industrial-scale pre-training dataset that aligns multi-modal behavioral sequences with user understanding semantics, and our Q-Anchor Embedding architecture integrates hierarchical coarse-to-fine encoders into dual-tower LLMs via joint contrastive-autoregressive optimization for query-aware user representation. To bridge the gap between general pre-training and specialized business logic, we further introduce Cluster-based Soft Prompt Tuning to enforce discriminative latent structures, effectively aligning model attention with scenario-specific modalities. For deployment, anchoring queries at sequence termini enables KV-cache-accelerated inference with negligible incremental latency. Evaluations on 10 Alipay industrial benchmarks show consistent SOTA performance, strong scalability, and efficient deployment. Large-scale online A/B testing in Alipay's production system across two real-world scenarios further validates its practical effectiveness. Our code is prepared for public release and will be available at: https://github.com/JhCircle/Q-Anchor.",
      "authors": [
        "Jiahao Yuan",
        "Yike Xu",
        "Jinyong Wen",
        "Baokun Wang",
        "Ziyi Gao",
        "Xiaotong Lin",
        "Yun Liu",
        "Xing Fu",
        "Yu Cheng",
        "Yongchao Liu",
        "Weiqiang Wang",
        "Zhongle Xie"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-02-16 06:09:31+00:00",
      "link": "https://arxiv.org/pdf/2602.14492v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14490v1",
      "title": "Parameter-Efficient Fine-Tuning of LLMs with Mixture of Space Experts",
      "abstract": "Large Language Models (LLMs) have achieved remarkable progress, with Parameter-Efficient Fine-Tuning (PEFT) emerging as a key technique for downstream task adaptation. However, existing PEFT methods mainly operate in Euclidean space, fundamentally limiting their capacity to capture complex geometric structures inherent in language data. While alternative geometric spaces, like hyperbolic geometries for hierarchical data and spherical manifolds for circular patterns, offer theoretical advantages, forcing representations into a single manifold type ultimately limits expressiveness, even when curvature parameters are learnable. To address this, we propose Mixture of Space (MoS), a unified framework that leverages multiple geometric spaces simultaneously to learn richer, curvature-aware representations. Building on this scheme, we develop MoSLoRA, which extends Low-Rank Adaptation (LoRA) with heterogeneous geometric experts, enabling models to dynamically select or combine appropriate geometric spaces based on input context. Furthermore, to address the computational overhead of frequent manifold switching, we develop a lightweight routing mechanism. Moreover, we provide empirical insights into how curvature optimization impacts training stability and model performance. Our experiments across diverse benchmarks demonstrate that MoSLoRA consistently outperforms strong baselines, achieving up to 5.6% improvement on MATH500 and 15.9% on MAWPS.",
      "authors": [
        "Buze Zhang",
        "Jinkai Tao",
        "Zilang Zeng",
        "Neil He",
        "Ali Maatouk",
        "Menglin Yang",
        "Rex Ying"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "published": "2026-02-16 06:07:32+00:00",
      "link": "https://arxiv.org/pdf/2602.14490v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14488v1",
      "title": "BETA-Labeling for Multilingual Dataset Construction in Low-Resource IR",
      "abstract": "IR in low-resource languages remains limited by the scarcity of high-quality, task-specific annotated datasets. Manual annotation is expensive and difficult to scale, while using large language models (LLMs) as automated annotators introduces concerns about label reliability, bias, and evaluation validity. This work presents a Bangla IR dataset constructed using a BETA-labeling framework involving multiple LLM annotators from diverse model families. The framework incorporates contextual alignment, consistency checks, and majority agreement, followed by human evaluation to verify label quality. Beyond dataset creation, we examine whether IR datasets from other low-resource languages can be effectively reused through one-hop machine translation. Using LLM-based translation across multiple language pairs, we experimented on meaning preservation and task validity between source and translated datasets. Our experiment reveal substantial variation across languages, reflecting language-dependent biases and inconsistent semantic preservation that directly affect the reliability of cross-lingual dataset reuse. Overall, this study highlights both the potential and limitations of LLM-assisted dataset creation for low-resource IR. It provides empirical evidence of the risks associated with cross-lingual dataset reuse and offers practical guidance for constructing more reliable benchmarks and evaluation pipelines in low-resource language settings.",
      "authors": [
        "Md. Najib Hasan",
        "Mst. Jannatun Ferdous Rain",
        "Fyad Mohammed",
        "Nazmul Siddique"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-16 06:04:04+00:00",
      "link": "https://arxiv.org/pdf/2602.14488v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14486v1",
      "title": "Revisiting the Platonic Representation Hypothesis: An Aristotelian View",
      "abstract": "The Platonic Representation Hypothesis suggests that representations from neural networks are converging to a common statistical model of reality. We show that the existing metrics used to measure representational similarity are confounded by network scale: increasing model depth or width can systematically inflate representational similarity scores. To correct these effects, we introduce a permutation-based null-calibration framework that transforms any representational similarity metric into a calibrated score with statistical guarantees. We revisit the Platonic Representation Hypothesis with our calibration framework, which reveals a nuanced picture: the apparent convergence reported by global spectral measures largely disappears after calibration, while local neighborhood similarity, but not local distances, retains significant agreement across different modalities. Based on these findings, we propose the Aristotelian Representation Hypothesis: representations in neural networks are converging to shared local neighborhood relationships.",
      "authors": [
        "Fabian Gröger",
        "Shuo Wen",
        "Maria Brbić"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "published": "2026-02-16 06:01:23+00:00",
      "link": "https://arxiv.org/pdf/2602.14486v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14482v1",
      "title": "TikArt: Aperture-Guided Observation for Fine-Grained Visual Reasoning via Reinforcement Learning",
      "abstract": "We address fine-grained visual reasoning in multimodal large language models (MLLMs), where key evidence may reside in tiny objects, cluttered regions, or subtle markings that are lost under a single global image encoding. We introduce TikArt (Thinking Aperture), an aperture-guided agent that casts multi-step vision-language reasoning as a decision process over regions of interest. TikArt follows a Think-Aperture-Observe loop, alternating between language generation and two aperture actions: Zoom extracts rectangular crops, while Segment invokes SAM2 to obtain mask-based crops for irregular targets. After every action, the model must produce an explicit observation, turning local visual cues into persistent linguistic memory. Built on Qwen3-VL-8B, TikArt optimizes its reasoning policy with AGRPO, a GRPO-style reinforcement learning algorithm with a two-stage curriculum: it warms up segmentation actions and then jointly optimizes visual math, fine-grained VQA, and segmentation, using rewards that couple task success with purposeful aperture use. Experiments on V*, HR-Bench-4K/8K, MME-RealWorld-Lite, MMStar, RefCOCO, and ReasonSeg show consistent gains over the backbone and yield interpretable aperture trajectories for high-resolution reasoning.",
      "authors": [
        "Hao Ding",
        "Zhichuan Yang",
        "Weijie Ge",
        "Ziqin Gao",
        "Chaoyi Lu",
        "Lei Zhao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-16 05:46:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14482v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14481v1",
      "title": "On the Rate-Distortion-Complexity Tradeoff for Semantic Communication",
      "abstract": "Semantic communication is a novel communication paradigm that focuses on conveying the user's intended meaning rather than the bit-wise transmission of source signals. One of the key challenges is to effectively represent and extract the semantic meaning of any given source signals. While deep learning (DL)-based solutions have shown promising results in extracting implicit semantic information from a wide range of sources, existing work often overlooks the high computational complexity inherent in both model training and inference for the DL-based encoder and decoder. To bridge this gap, this paper proposes a rate-distortion-complexity (RDC) framework which extends the classical rate-distortion theory by incorporating the constraints on semantic distance, including both the traditional bit-wise distortion metric and statistical difference-based divergence metric, and complexity measure, adopted from the theory of minimum description length and information bottleneck. We derive the closed-form theoretical results of the minimum achievable rate under given constraints on semantic distance and complexity for both Gaussian and binary semantic sources. Our theoretical results show a fundamental three-way tradeoff among achievable rate, semantic distance, and model complexity. Extensive experiments on real-world image and video datasets validate this tradeoff and further demonstrate that our information-theoretic complexity measure effectively correlates with practical computational costs, guiding efficient system design in resource-constrained scenarios.",
      "authors": [
        "Jingxuan Chai",
        "Yong Xiao",
        "Guangming Shi"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "cs.AI"
      ],
      "published": "2026-02-16 05:45:52+00:00",
      "link": "https://arxiv.org/pdf/2602.14481v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14478v1",
      "title": "Constrained and Composite Sampling via Proximal Sampler",
      "abstract": "We study two log-concave sampling problems: constrained sampling and composite sampling. First, we consider sampling from a target distribution with density proportional to $\\exp(-f(x))$ supported on a convex set $K \\subset \\mathbb{R}^d$, where $f$ is convex. The main challenge is enforcing feasibility without degrading mixing. Using an epigraph transformation, we reduce this task to sampling from a nearly uniform distribution over a lifted convex set in $\\mathbb{R}^{d+1}$. We then solve the lifted problem using a proximal sampler. Assuming only a separation oracle for $K$ and a subgradient oracle for $f$, we develop an implementation of the proximal sampler based on the cutting-plane method and rejection sampling. Unlike existing constrained samplers that rely on projection, reflection, barrier functions, or mirror maps, our approach enforces feasibility using only minimal oracle access, resulting in a practical and unbiased sampler without knowing the geometry of the constraint set.   Second, we study composite sampling, where the target is proportional to $\\exp(-f(x)-h(x))$ with closed and convex $f$ and $h$. This composite structure is standard in Bayesian inference with $f$ modeling data fidelity and $h$ encoding prior information. We reduce composite sampling via an epigraph lifting of $h$ to constrained sampling in $\\mathbb{R}^{d+1}$, which allows direct application of the constrained sampling algorithm developed in the first part. This reduction results in a double epigraph lifting formulation in $\\mathbb{R}^{d+2}$, on which we apply a proximal sampler. By keeping $f$ and $h$ separate, we further demonstrate how different combinations of oracle access (such as subgradient and proximal) can be leveraged to construct separation oracles for the lifted problem. For both sampling problems, we establish mixing time bounds measured in Rényi and $χ^2$ divergences.",
      "authors": [
        "Thanh Dang",
        "Jiaming Liang"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.DS",
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-02-16 05:36:36+00:00",
      "link": "https://arxiv.org/pdf/2602.14478v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14477v1",
      "title": "When OpenClaw AI Agents Teach Each Other: Peer Learning Patterns in the Moltbook Community",
      "abstract": "Peer learning, where learners teach and learn from each other, is foundational to educational practice. A novel phenomenon has emerged: AI agents forming communities where they teach each other skills, share discoveries, and collaboratively build knowledge. This paper presents an educational data mining analysis of Moltbook, a large-scale community where over 2.4 million AI agents engage in peer learning, posting tutorials, answering questions, and sharing newly acquired skills. Analyzing 28,683 posts (after filtering automated spam) and 138 comment threads with statistical and qualitative methods, we find evidence of genuine peer learning behaviors: agents teach skills they built (74K comments on a skill tutorial), report discoveries, and engage in collaborative problem-solving. Qualitative comment analysis reveals a taxonomy of peer response patterns: validation (22%), knowledge extension (18%), application (12%), and metacognitive reflection (7%), with agents building on each others' frameworks across multiple languages. We characterize how AI peer learning differs from human peer learning: (1) teaching (statements) dramatically outperforms help-seeking (questions) with an 11.4:1 ratio; (2) learning-oriented content (procedural and conceptual) receives 3x more engagement than other content; (3) extreme participation inequality reveals non-human behavioral signatures. We derive six design principles for educational AI, including leveraging validation-before-extension patterns and supporting multilingual learning networks. Our work provides the first empirical characterization of peer learning among AI agents, contributing to EDM's understanding of how learning occurs in increasingly AI-populated educational environments.",
      "authors": [
        "Eason Chen",
        "Ce Guan",
        "Ahmed Elshafiey",
        "Zhonghao Zhao",
        "Joshua Zekeri",
        "Afeez Edeifo Shaibu",
        "Emmanuel Osadebe Prince"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "published": "2026-02-16 05:32:06+00:00",
      "link": "https://arxiv.org/pdf/2602.14477v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14476v1",
      "title": "Truthful Reverse Auctions for Adaptive Selection via Contextual Multi-Armed Bandits",
      "abstract": "We study the problem of selecting large language models (LLMs) for user queries in settings where multiple LLM providers submit the cost of solving a query. From the users' perspective, choosing an optimal model is a sequential, query-dependent decision problem: high-capacity models offer more reliable outputs but are costlier, while lightweight models are faster and cheaper. We formalize this interaction as a reverse auction design problem with contextual online learning, where the user adaptively discovers which model performs best while eliciting costs from competing LLM providers. Existing multi-armed bandit (MAB) mechanisms focus on forward auctions and social welfare, leaving open the challenges of reverse auctions, provider-optimal outcomes, and contextual adaptation. We address these gaps by designing a resampling-based procedure that generalizes truthful forward MAB mechanisms to reverse auctions and prove that any monotone allocation rule with this procedure is truthful. Using this, we propose a contextual MAB algorithm that learns query-dependent model quality with sublinear regret. Our framework unifies mechanism design and adaptive learning, enabling efficient, truthful, and query-aware LLM selection.",
      "authors": [
        "Pronoy Patra",
        "Sankarshan Damle",
        "Manisha Padala",
        "Sujit Gujar"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT"
      ],
      "published": "2026-02-16 05:27:48+00:00",
      "link": "https://arxiv.org/pdf/2602.14476v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14474v1",
      "title": "One Good Source is All You Need: Near-Optimal Regret for Bandits under Heterogeneous Noise",
      "abstract": "We study $K$-armed Multiarmed Bandit (MAB) problem with $M$ heterogeneous data sources, each exhibiting unknown and distinct noise variances $\\{σ_j^2\\}_{j=1}^M$. The learner's objective is standard MAB regret minimization, with the additional complexity of adaptively selecting which data source to query from at each round. We propose Source-Optimistic Adaptive Regret minimization (SOAR), a novel algorithm that quickly prunes high-variance sources using sharp variance-concentration bounds, followed by a `balanced min-max LCB-UCB approach' that seamlessly integrates the parallel tasks of identifying the best arm and the optimal (minimum-variance) data source. Our analysis shows SOAR achieves an instance-dependent regret bound of $\\tilde{O}\\left({σ^*}^2\\sum_{i=2}^K \\frac{\\log T}{Δ_i} + \\sqrt{K \\sum_{j=1}^M σ_j^2}\\right)$, up to preprocessing costs depending only on problem parameters, where ${σ^*}^2 := \\min_j σ_j^2$ is the minimum source variance and $Δ_i$ denotes the suboptimality gap of the $i$-th arm. This result is both surprising as despite lacking prior knowledge of the minimum-variance source among $M$ alternatives, SOAR attains the optimal instance-dependent regret of standard single-source MAB with variance ${σ^*}^2$, while incurring only an small (and unavoidable) additive cost of $\\tilde O(\\sqrt{K \\sum_{j=1}^M σ_j^2})$ towards the optimal (minimum variance) source identification. Our theoretical bounds represent a significant improvement over some proposed baselines, e.g. Uniform UCB or Explore-then-Commit UCB, which could potentially suffer regret scaling with $σ_{\\max}^2$ in place of ${σ^*}^2$-a gap that can be arbitrarily large when $σ_{\\max} \\gg σ^*$. Experiments on multiple synthetic problem instances and the real-world MovieLens\\;25M dataset, demonstrating the superior performance of SOAR over the baselines.",
      "authors": [
        "Aadirupa Saha",
        "Amith Bhat",
        "Haipeng Luo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 05:25:06+00:00",
      "link": "https://arxiv.org/pdf/2602.14474v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14473v1",
      "title": "Learning Transferability: A Two-Stage Reinforcement Learning Approach for Enhancing Quadruped Robots' Performance in U-Shaped Stair Climbing",
      "abstract": "Quadruped robots are employed in various scenarios in building construction. However, autonomous stair climbing across different indoor staircases remains a major challenge for robot dogs to complete building construction tasks. In this project, we employed a two-stage end-to-end deep reinforcement learning (RL) approach to optimize a robot's performance on U-shaped stairs. The training robot-dog modality, Unitree Go2, was first trained to climb stairs on Isaac Lab's pyramid-stair terrain, and then to climb a U-shaped indoor staircase using the learned policies. This project explores end-to-end RL methods that enable robot dogs to autonomously climb stairs. The results showed (1) the successful goal reached for robot dogs climbing U-shaped stairs with a stall penalty, and (2) the transferability from the policy trained on U-shaped stairs to deployment on straight, L-shaped, and spiral stair terrains, and transferability from other stair models to deployment on U-shaped terrain.",
      "authors": [
        "Baixiao Huang",
        "Baiyu Huang",
        "Yu Hou"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "published": "2026-02-16 05:19:06+00:00",
      "link": "https://arxiv.org/pdf/2602.14473v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14472v1",
      "title": "Frequentist Regret Analysis of Gaussian Process Thompson Sampling via Fractional Posteriors",
      "abstract": "We study Gaussian Process Thompson Sampling (GP-TS) for sequential decision-making over compact, continuous action spaces and provide a frequentist regret analysis based on fractional Gaussian process posteriors, without relying on domain discretization as in prior work. We show that the variance inflation commonly assumed in existing analyses of GP-TS can be interpreted as Thompson Sampling with respect to a fractional posterior with tempering parameter $α\\in (0,1)$. We derive a kernel-agnostic regret bound expressed in terms of the information gain parameter $γ_t$ and the posterior contraction rate $ε_t$, and identify conditions on the Gaussian process prior under which $ε_t$ can be controlled. As special cases of our general bound, we recover regret of order $\\tilde{\\mathcal{O}}(T^{\\frac{1}{2}})$ for the squared exponential kernel, $\\tilde{\\mathcal{O}}(T^{\\frac{2ν+3d}{2(2ν+d)}} )$ for the Matérn-$ν$ kernel, and a bound of order $\\tilde{\\mathcal{O}}(T^{\\frac{2ν+3d}{2(2ν+d)}})$ for the rational quadratic kernel. Overall, our analysis provides a unified and discretization-free regret framework for GP-TS that applies broadly across kernel classes.",
      "authors": [
        "Somjit Roy",
        "Prateek Jaiswal",
        "Anirban Bhattacharya",
        "Debdeep Pati",
        "Bani K. Mallick"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "published": "2026-02-16 05:18:13+00:00",
      "link": "https://arxiv.org/pdf/2602.14472v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14471v1",
      "title": "Socially-Weighted Alignment: A Game-Theoretic Framework for Multi-Agent LLM Systems",
      "abstract": "Deploying large language model (LLM) agents in shared environments introduces a fundamental tension between individual alignment and collective stability: locally rational decisions can impose negative externalities that degrade system-level performance. We propose Socially-Weighted Alignment (SWA), a game-theoretic framework that modifies inference-time decision making by interpolating between an agent's private objective and an estimate of group welfare via a social weight $λ\\in[0,1]$. In a shared-resource congestion game with $n$ agents and congestion severity $β$, we show that SWA induces a critical threshold $λ^*=(n-β)/(n-1)$ above which agents no longer have marginal incentive to increase demand under overload, yielding a phase transition from persistent congestion to stable operation near capacity. We further provide an inference-time algorithmic instantiation of SWA that does not require parameter updates or multi-agent reinforcement learning, and use a multi-agent simulation to empirically validate the predicted threshold behavior.",
      "authors": [
        "Furkan Mumcu",
        "Yasin Yilmaz"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "published": "2026-02-16 05:17:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14471v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15076v1",
      "title": "Near-Optimal Sample Complexity for Online Constrained MDPs",
      "abstract": "Safety is a fundamental challenge in reinforcement learning (RL), particularly in real-world applications such as autonomous driving, robotics, and healthcare. To address this, Constrained Markov Decision Processes (CMDPs) are commonly used to enforce safety constraints while optimizing performance. However, existing methods often suffer from significant safety violations or require a high sample complexity to generate near-optimal policies. We address two settings: relaxed feasibility, where small violations are allowed, and strict feasibility, where no violation is allowed. We propose a model-based primal-dual algorithm that balances regret and bounded constraint violations, drawing on techniques from online RL and constrained optimization. For relaxed feasibility, we prove that our algorithm returns an $\\varepsilon$-optimal policy with $\\varepsilon$-bounded violation with arbitrarily high probability, requiring $\\tilde{O}\\left(\\frac{SAH^3}{\\varepsilon^2}\\right)$ learning episodes, matching the lower bound for unconstrained MDPs. For strict feasibility, we prove that our algorithm returns an $\\varepsilon$-optimal policy with zero violation with arbitrarily high probability, requiring $\\tilde{O}\\left(\\frac{SAH^5}{\\varepsilon^2ζ^2}\\right)$ learning episodes, where $ζ$ is the problem-dependent Slater constant characterizing the size of the feasible region. This result matches the lower bound for learning CMDPs with access to a generative model.   Our results demonstrate that learning CMDPs in an online setting is as easy as learning with a generative model and is no more challenging than learning unconstrained MDPs when small violations are allowed.",
      "authors": [
        "Chang Liu",
        "Yunfan Li",
        "Lin F. Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-16 05:16:13+00:00",
      "link": "https://arxiv.org/pdf/2602.15076v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14470v1",
      "title": "HyperRAG: Reasoning N-ary Facts over Hypergraphs for Retrieval Augmented Generation",
      "abstract": "Graph-based retrieval-augmented generation (RAG) methods, typically built on knowledge graphs (KGs) with binary relational facts, have shown promise in multi-hop open-domain QA. However, their rigid retrieval schemes and dense similarity search often introduce irrelevant context, increase computational overhead, and limit relational expressiveness. In contrast, n-ary hypergraphs encode higher-order relational facts that capture richer inter-entity dependencies and enable shallower, more efficient reasoning paths. To address this limitation, we propose HyperRAG, a RAG framework tailored for n-ary hypergraphs with two complementary retrieval variants: (i) HyperRetriever learns structural-semantic reasoning over n-ary facts to construct query-conditioned relational chains. It enables accurate factual tracking, adaptive high-order traversal, and interpretable multi-hop reasoning under context constraints. (ii) HyperMemory leverages the LLM's parametric memory to guide beam search, dynamically scoring n-ary facts and entities for query-aware path expansion. Extensive evaluations on WikiTopics (11 closed-domain datasets) and three open-domain QA benchmarks (HotpotQA, MuSiQue, and 2WikiMultiHopQA) validate HyperRAG's effectiveness. HyperRetriever achieves the highest answer accuracy overall, with average gains of 2.95% in MRR and 1.23% in Hits@10 over the strongest baseline. Qualitative analysis further shows that HyperRetriever bridges reasoning gaps through adaptive and interpretable n-ary chain construction, benefiting both open and closed-domain QA.",
      "authors": [
        "Wen-Sheng Lien",
        "Yu-Kai Chan",
        "Hao-Lung Hsiao",
        "Bo-Kai Ruan",
        "Meng-Fen Chiang",
        "Chien-An Chen",
        "Yi-Ren Yeh",
        "Hong-Han Shuai"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 05:15:55+00:00",
      "link": "https://arxiv.org/pdf/2602.14470v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14469v1",
      "title": "Measuring and Mitigating Post-hoc Rationalization in Reverse Chain-of-Thought Generation",
      "abstract": "Reverse Chain-of-Thought Generation (RCG) synthesizes reasoning traces from query-answer pairs, but runs the risk of producing post-hoc rationalizations: when models can see the answer during generation, the answer serves as a cognitive anchor that shapes the entire explanation. We formalize this phenomenon through a three-level measurement hierarchy: lexical, entropic, and probabilistic anchoring, each captures surface artifacts, entropy dynamics, and latent answer dependence, respectively. We analyze semantic suppression, the intuitive mitigation strategy that instructs models to ignore the answer, to find out its counterproduction: while it reduces lexical overlap, it paradoxically increases entropic and probabilistic anchoring. Drawing on Ironic Process Theory from cognitive psychology, we attribute this failure to active monitoring of the forbidden answer, which inadvertently deepens dependence on it. To break this cycle, we propose Structural Skeleton-guided Reasoning (SSR), a two-phase approach that first generates an answer-invariant functional skeleton structure, then uses this skeleton to guide full trace generation. By redirecting the information flow to structural planning rather than answer monitoring, SSR consistently reduces anchoring across all three levels. We further introduce Distilled SSR (SSR-D), which fine-tunes models on teacher-generated SSR traces to ensure reliable structural adherence. Experiments across open-ended reasoning benchmarks demonstrate that SSR-D achieves up to 10% improvement over suppression baselines while preserving out-of-distribution (OOD) generalization.",
      "authors": [
        "Guangyue Peng",
        "Zongchao Chen",
        "Wen Luo",
        "Yuntao Wen",
        "Wei Li",
        "Ruixiang Feng",
        "Ran Le",
        "Chen Yang",
        "Zhenwei An",
        "Yang Song",
        "Tao Zhang",
        "Houfeng Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 05:13:06+00:00",
      "link": "https://arxiv.org/pdf/2602.14469v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14468v1",
      "title": "LACONIC: Length-Aware Constrained Reinforcement Learning for LLM",
      "abstract": "Reinforcement learning (RL) has enhanced the capabilities of large language models (LLMs) through reward-driven training. Nevertheless, this process can introduce excessively long responses, inflating inference latency and computational overhead. Prior length-control approaches typically rely on fixed heuristic reward shaping, which can misalign with the task objective and require brittle tuning. In this work, we propose LACONIC, a reinforcement learning method that enforces a target token budget during training. Specifically, we update policy models using an augmented objective that combines the task reward with a length-based cost. To balance brevity and task performance, the cost scale is adaptively adjusted throughout training. This yields robust length control while preserving task reward. We provide a theoretical guarantee that support the method. Across mathematical reasoning models and datasets, LACONIC preserves or improves pass@1 while reducing output length by over 50%. It maintains out-of-domain performance on general knowledge and multilingual benchmarks with 44% fewer tokens. Moreover, LACONIC integrates into standard RL-tuning with no inference changes and minimal deployment overhead.",
      "authors": [
        "Chang Liu",
        "Yiran Zhao",
        "Lawrence Liu",
        "Yaoqi Ye",
        "Csaba Szepesvári",
        "Lin F. Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 05:09:40+00:00",
      "link": "https://arxiv.org/pdf/2602.14468v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14467v1",
      "title": "Conversational Decision Support for Information Search Under Uncertainty: Effects of Gist and Verbatim Feedback",
      "abstract": "Many real-world decisions rely on information search, where people sample evidence and decide when to stop under uncertainty. The uncertainty in the environment, particularly how diagnostic evidence is distributed, causes complexities in information search, further leading to suboptimal decision-making outcomes. Yet AI decision support often targets outcome optimization, and less is known about how to scaffold search without increasing cognitive load. We introduce SERA, an LLM-based assistant that provides either gist or verbatim feedback during search. Across two experiments (N1=54, N2=54), we examined decision-making outcomes and information search in SERA-Gist, SERA-Verbatim, and a no-feedback baseline across three environments varying in uncertainty. The uncertainty in environment is operationalized by the perceived gain of information across the course of sampling, which individuals may experience diminishing return of information gain (decremental; low-uncertainty), or a local drop of information gain (local optimum; medium-uncertainty), or no patterns in information gain (high-uncertainty), as they search more. Individuals show more accurate decision outcomes and are more confident with SERA support, especially under higher uncertainty. Gist feedback was associated with more efficient integration and showed a descriptive pattern of reduced oversampling, while verbatim feedback promoted more extensive exploration. These findings establish feedback representation as a design lever when search matters, motivating adaptive systems that match feedback granularity to uncertainty.",
      "authors": [
        "Kexin Quan",
        "Jessie Chin"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-16 05:09:34+00:00",
      "link": "https://arxiv.org/pdf/2602.14467v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14466v1",
      "title": "Robust Bias Evaluation with FilBBQ: A Filipino Bias Benchmark for Question-Answering Language Models",
      "abstract": "With natural language generation becoming a popular use case for language models, the Bias Benchmark for Question-Answering (BBQ) has grown to be an important benchmark format for evaluating stereotypical associations exhibited by generative models. We expand the linguistic scope of BBQ and construct FilBBQ through a four-phase development process consisting of template categorization, culturally aware translation, new template construction, and prompt generation. These processes resulted in a bias test composed of more than 10,000 prompts which assess whether models demonstrate sexist and homophobic prejudices relevant to the Philippine context. We then apply FilBBQ on models trained in Filipino but do so with a robust evaluation protocol that improves upon the reliability and accuracy of previous BBQ implementations. Specifically, we account for models' response instability by obtaining prompt responses across multiple seeds and averaging the bias scores calculated from these distinctly seeded runs. Our results confirm both the variability of bias scores across different seeds and the presence of sexist and homophobic biases relating to emotion, domesticity, stereotyped queer interests, and polygamy. FilBBQ is available via GitHub.",
      "authors": [
        "Lance Calvin Lim Gamboa",
        "Yue Feng",
        "Mark Lee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 05:03:15+00:00",
      "link": "https://arxiv.org/pdf/2602.14466v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14464v1",
      "title": "CoCoDiff: Correspondence-Consistent Diffusion Model for Fine-grained Style Transfer",
      "abstract": "Transferring visual style between images while preserving semantic correspondence between similar objects remains a central challenge in computer vision. While existing methods have made great strides, most of them operate at global level but overlook region-wise and even pixel-wise semantic correspondence. To address this, we propose CoCoDiff, a novel training-free and low-cost style transfer framework that leverages pretrained latent diffusion models to achieve fine-grained, semantically consistent stylization. We identify that correspondence cues within generative diffusion models are under-explored and that content consistency across semantically matched regions is often neglected. CoCoDiff introduces a pixel-wise semantic correspondence module that mines intermediate diffusion features to construct a dense alignment map between content and style images. Furthermore, a cycle-consistency module then enforces structural and perceptual alignment across iterations, yielding object and region level stylization that preserves geometry and detail. Despite requiring no additional training or supervision, CoCoDiff delivers state-of-the-art visual quality and strong quantitative results, outperforming methods that rely on extra training or annotations.",
      "authors": [
        "Wenbo Nie",
        "Zixiang Li",
        "Renshuai Tao",
        "Bin Wu",
        "Yunchao Wei",
        "Yao Zhao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-16 04:52:29+00:00",
      "link": "https://arxiv.org/pdf/2602.14464v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14462v1",
      "title": "Silent Inconsistency in Data-Parallel Full Fine-Tuning: Diagnosing Worker-Level Optimization Misalignment",
      "abstract": "Data-parallel (DP) training with synchronous all-reduce is a dominant paradigm for full-parameter fine-tuning of large language models (LLMs). While parameter synchronization guarantees numerical equivalence of model weights after each iteration, it does not necessarily imply alignment of worker-level optimization dynamics before gradient aggregation. This paper identifies and studies this latent mismatch, termed \\emph{silent inconsistency}, where cross-worker divergence in losses and gradients can remain invisible under conventional aggregated monitoring signals. We propose a lightweight, model-agnostic diagnostic framework that quantifies worker-level consistency using training signals readily available in standard pipelines. Specifically, we introduce three complementary metrics: loss dispersion, gradient-norm dispersion, and gradient-direction consistency measured by inter-worker cosine similarity. The proposed metrics incur negligible overhead and require no modification to model architecture, synchronization mechanisms, or optimization algorithms. We validate the framework by fully fine-tuning the 1B-parameter \\texttt{openPangu-Embedded-1B-V1.1} model on the \\texttt{tatsu-lab/alpaca} dataset using an 8-NPU DP setup, under controlled perturbations of cross-rank stochasticity. Experimental results show that progressively desynchronized data shuffling and random seeds lead to substantial increases in loss/gradient dispersion and reduced directional alignment, despite smooth globally averaged loss curves. These findings demonstrate that the proposed indicators provide actionable visibility into hidden instability modes in large-scale DP fine-tuning, enabling more reliable diagnosis and configuration assessment.",
      "authors": [
        "Hong Li",
        "Zhen Zhou",
        "Honggang Zhang",
        "Yuping Luo",
        "Xinyue Wang",
        "Han Gong",
        "Zhiyuan Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-16 04:42:30+00:00",
      "link": "https://arxiv.org/pdf/2602.14462v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14457v1",
      "title": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report v1.5",
      "abstract": "To understand and identify the unprecedented risks posed by rapidly advancing artificial intelligence (AI) models, Frontier AI Risk Management Framework in Practice presents a comprehensive assessment of their frontier risks. As Large Language Models (LLMs) general capabilities rapidly evolve and the proliferation of agentic AI, this version of the risk analysis technical report presents an updated and granular assessment of five critical dimensions: cyber offense, persuasion and manipulation, strategic deception, uncontrolled AI R\\&D, and self-replication. Specifically, we introduce more complex scenarios for cyber offense. For persuasion and manipulation, we evaluate the risk of LLM-to-LLM persuasion on newly released LLMs. For strategic deception and scheming, we add the new experiment with respect to emergent misalignment. For uncontrolled AI R\\&D, we focus on the ``mis-evolution'' of agents as they autonomously expand their memory substrates and toolsets. Besides, we also monitor and evaluate the safety performance of OpenClaw during the interaction on the Moltbook. For self-replication, we introduce a new resource-constrained scenario. More importantly, we propose and validate a series of robust mitigation strategies to address these emerging threats, providing a preliminary technical and actionable pathway for the secure deployment of frontier AI. This work reflects our current understanding of AI frontier risks and urges collective action to mitigate these challenges.",
      "authors": [
        "Dongrui Liu",
        "Yi Yu",
        "Jie Zhang",
        "Guanxu Chen",
        "Qihao Lin",
        "Hanxi Zhu",
        "Lige Huang",
        "Yijin Zhou",
        "Peng Wang",
        "Shuai Shao",
        "Boxuan Zhang",
        "Zicheng Liu",
        "Jingwei Sun",
        "Yu Li",
        "Yuejin Xie",
        "Jiaxuan Guo",
        "Jia Xu",
        "Chaochao Lu",
        "Bowen Zhou",
        "Xia Hu",
        "Jing Shao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.CY",
        "cs.LG"
      ],
      "published": "2026-02-16 04:30:06+00:00",
      "link": "https://arxiv.org/pdf/2602.14457v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14456v1",
      "title": "Traceable Latent Variable Discovery Based on Multi-Agent Collaboration",
      "abstract": "Revealing the underlying causal mechanisms in the real world is crucial for scientific and technological progress. Despite notable advances in recent decades, the lack of high-quality data and the reliance of traditional causal discovery algorithms (TCDA) on the assumption of no latent confounders, as well as their tendency to overlook the precise semantics of latent variables, have long been major obstacles to the broader application of causal discovery. To address this issue, we propose a novel causal modeling framework, TLVD, which integrates the metadata-based reasoning capabilities of large language models (LLMs) with the data-driven modeling capabilities of TCDA for inferring latent variables and their semantics. Specifically, we first employ a data-driven approach to construct a causal graph that incorporates latent variables. Then, we employ multi-LLM collaboration for latent variable inference, modeling this process as a game with incomplete information and seeking its Bayesian Nash Equilibrium (BNE) to infer the possible specific latent variables. Finally, to validate the inferred latent variables across multiple real-world web-based data sources, we leverage LLMs for evidence exploration to ensure traceability. We comprehensively evaluate TLVD on three de-identified real patient datasets provided by a hospital and two benchmark datasets. Extensive experimental results confirm the effectiveness and reliability of TLVD, with average improvements of 32.67% in Acc, 62.21% in CAcc, and 26.72% in ECit across the five datasets.",
      "authors": [
        "Huaming Du",
        "Tao Hu",
        "Yijie Huang",
        "Yu Zhao",
        "Guisong Liu",
        "Tao Gu",
        "Gang Kou",
        "Carl Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 04:29:32+00:00",
      "link": "https://arxiv.org/pdf/2602.14456v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14452v1",
      "title": "WiSparse: Boosting LLM Inference Efficiency with Weight-Aware Mixed Activation Sparsity",
      "abstract": "Large Language Models (LLMs) offer strong capabilities but incur high inference costs due to dense computation and memory access. Training-free activation sparsity is a promising approach for efficient LLM inference, yet existing methods often rely solely on activation information and uniform sparsity ratios. This overlooks the critical interplay with weights and inter-block sensitivity variation, leading to suboptimal performance. We identify two key phenomena in modern LLMs: 1) less significant activations may align with highly important weights, and 2) sparsity sensitivity varies non-monotonically across model blocks. We propose Weight-aware Mixed-Granularity Training-free Activation Sparsity (WiSparse), which leverages both activation and weight information for adaptive sparsity allocation. Specifically, we introduce a weight-aware mechanism integrating activation magnitudes with precomputed weight norms to accurately identify salient channels. This is combined with a mixed-granularity allocation scheme: a global budget is distributed across blocks via evolutionary search to protect sensitive regions, then refined within blocks to minimize reconstruction error. We improve sparse kernels and demonstrate effectiveness on three representative models. Notably, at 50% sparsity, WiSparse preserves 97% of Llama3.1's dense performance, surpassing the strongest baseline by 2.23 percentage points while achieving a 21.4% acceleration in end-to-end inference speed. Our research advances the limits of training-free approaches for efficient LLM inference, pushing the boundaries of achievable speedup without training.",
      "authors": [
        "Lei Chen",
        "Yuan Meng",
        "Xiaoyu Zhan",
        "Zhi Wang",
        "Wenwu Zhu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-16 04:18:36+00:00",
      "link": "https://arxiv.org/pdf/2602.14452v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14451v1",
      "title": "Precedent-Informed Reasoning: Mitigating Overthinking in Large Reasoning Models via Test-Time Precedent Learning",
      "abstract": "Reasoning in Large Language Models (LLMs) often suffers from inefficient long chain-of-thought traces with redundant self-exploration and validation, which inflate computational costs and even degrade performance. Inspired by human reasoning patterns where people solve new problems by leveraging past related cases to constrain search spaces and reduce trial-and-error, we propose Precedent Informed Reasoning (PIR) transforming LRMs'reasoning paradigm from exhaustive self-exploration to guided learning from precedents. PIR addresses two key challenges: what precedents to adopt and how to utilize them. First, Adaptive Precedent Selection (APS) constructs, for each question and LRM, a compact set of precedents that are both semantically related and informative for the model. It ranks examples by a joint score with semantic similarity and model perplexity, then adapts the amount of precedents to maximize perplexity reduction. Second, Test-time Experience Internalization (TEI) is treated as the test-time learning on precedent-informed instruction, updating lightweight adapters to internalize solution patterns and use them as a prior during subsequent reasoning. Experiments across mathematical reasoning, scientific QA, and code generation demonstrate that PIR consistently shortens reasoning traces while maintaining or improving final accuracy across LLMs, yielding outstanding accuracy-efficiency trade-offs.",
      "authors": [
        "Qianyue Wang",
        "Jinwu Hu",
        "Huanxiang Lin",
        "Bolin Chen",
        "Zhiquan Wen",
        "Yaofo Chen",
        "Yu Rong",
        "Mingkui Tan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-16 04:17:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14451v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14445v1",
      "title": "Selective Synchronization Attention",
      "abstract": "The Transformer architecture has become the foundation of modern deep learning, yet its core self-attention mechanism suffers from quadratic computational complexity and lacks grounding in biological neural computation. We propose Selective Synchronization Attention (SSA), a novel attention mechanism that replaces the standard dot-product self-attention with a closed-form operator derived from the steady-state solution of the Kuramoto model of coupled oscillators. In SSA, each token is represented as an oscillator characterized by a learnable natural frequency and phase; the synchronization strength between token pairs, determined by a frequency-dependent coupling and phase-locking condition, serves as the attention weight. This formulation provides three key advantages: (i) natural sparsity arising from the phase-locking threshold, whereby tokens with incompatible frequencies automatically receive zero attention weight without explicit masking; (ii) unified positional-semantic encoding through the natural frequency spectrum, eliminating the need for separate positional encodings; and (iii) a single-pass, closed-form computation that avoids iterative ODE integration, with all components (coupling, order parameter, synchronization) derived from the oscillatory framework. We instantiate SSA within the Oscillatory Synchronization Network (OSN), a drop-in replacement for the Transformer block. Analysis of the synchronization matrices reveals non-uniform, head-diverse coupling patterns even at initialization, demonstrating a stronger architectural inductive bias than the approximately uniform attention produced by randomly initialized Transformers.",
      "authors": [
        "Hasi Hays"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "published": "2026-02-16 03:58:12+00:00",
      "link": "https://arxiv.org/pdf/2602.14445v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14444v1",
      "title": "Broken Chains: The Cost of Incomplete Reasoning in LLMs",
      "abstract": "Reasoning-specialized models like OpenAI's 5.1 and DeepSeek-V3.2 allocate substantial inference compute to extended chain-of-thought (CoT) traces, yet reasoning tokens incur significant costs. How do different reasoning modalities of code, natural language, hybrid, or none do perform under token constraints? We introduce a framework that constrains models to reason exclusively through code, comments, both, or neither, then systematically ablates token budgets to 10\\%, 30\\%, 50\\%, and 70\\% of optimal. We evaluate four frontier models (GPT-5.1, Gemini 3 Flash, DeepSeek-V3.2, Grok 4.1) across mathematical benchmarks (AIME, GSM8K, HMMT). Our findings reveal: (1) \\textbf{truncated reasoning can hurt} as DeepSeek-V3.2 achieves 53\\% with no reasoning but only 17\\% with truncated CoT at 50\\% budget; (2) \\textbf{code degrades gracefully} as Gemini's comments collapse to 0\\% while code maintains 43-47\\%; (3) \\textbf{hybrid reasoning underperforms} single modalities; (4) \\textbf{robustness is model-dependent} as Grok maintains 80-90\\% at 30\\% budget where OpenAI and DeepSeek collapse to 7-27\\%. These results suggest incomplete reasoning chains actively mislead models, with implications for deploying reasoning-specialized systems under resource constraints.",
      "authors": [
        "Ian Su",
        "Gaurav Purushothaman",
        "Jey Narayan",
        "Ruhika Goel",
        "Kevin Zhu",
        "Sunishchal Dev",
        "Yash More",
        "Maheep Chaudhary"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-16 03:57:51+00:00",
      "link": "https://arxiv.org/pdf/2602.14444v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14443v1",
      "title": "Controlling Your Image via Simplified Vector Graphics",
      "abstract": "Recent advances in image generation have achieved remarkable visual quality, while a fundamental challenge remains: Can image generation be controlled at the element level, enabling intuitive modifications such as adjusting shapes, altering colors, or adding and removing objects? In this work, we address this challenge by introducing layer-wise controllable generation through simplified vector graphics (VGs). Our approach first efficiently parses images into hierarchical VG representations that are semantic-aligned and structurally coherent. Building on this representation, we design a novel image synthesis framework guided by VGs, allowing users to freely modify elements and seamlessly translate these edits into photorealistic outputs. By leveraging the structural and semantic features of VGs in conjunction with noise prediction, our method provides precise control over geometry, color, and object semantics. Extensive experiments demonstrate the effectiveness of our approach in diverse applications, including image editing, object-level manipulation, and fine-grained content creation, establishing a new paradigm for controllable image generation. Project page: https://guolanqing.github.io/Vec2Pix/",
      "authors": [
        "Lanqing Guo",
        "Xi Liu",
        "Yufei Wang",
        "Zhihao Li",
        "Siyu Huang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 03:56:42+00:00",
      "link": "https://arxiv.org/pdf/2602.14443v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15074v1",
      "title": "Structure-Aware Piano Accompaniment via Style Planning and Dataset-Aligned Pattern Retrieval",
      "abstract": "We introduce a structure-aware approach for symbolic piano accompaniment that decouples high-level planning from note-level realization. A lightweight transformer predicts an interpretable, per-measure style plan conditioned on section/phrase structure and functional harmony, and a retriever then selects and reharmonizes human-performed piano patterns from a corpus. We formulate retrieval as pattern matching under an explicit energy with terms for harmonic feasibility, structural-role compatibility, voice-leading continuity, style preferences, and repetition control. Given a structured lead sheet and optional keyword prompts, the system generates piano-accompaniment MIDI. In our experiments, transformer style-planner-guided retrieval produces diverse long-form accompaniments with strong style realization. We further analyze planner ablations and quantify inter-style isolation. Experimental results demonstrate the effectiveness of our inference-time approach for piano accompaniment generation.",
      "authors": [
        "Wanyu Zang",
        "Yang Yu",
        "Meng Yu"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "published": "2026-02-16 03:54:34+00:00",
      "link": "https://arxiv.org/pdf/2602.15074v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14442v1",
      "title": "Touching Movement: 3D Tactile Poses for Supporting Blind People in Learning Body Movements",
      "abstract": "Visual impairments create barriers to learning physical activities, since conventional training methods rely on visual demonstrations or often inadequate verbal descriptions. This research explores 3D-printed human body models to enhance movement comprehension for blind individuals. Through a participatory design approach in collaboration with a blind designer, we developed detailed 3D models representing various body movements and incorporated tactile reference elements to enhance spatial understanding. We conducted two user studies with 10 blind participants across different activities: static yoga poses and sequential calisthenic movements. The results demonstrated that 3D models significantly improved understanding speed, reduced questions for clarification, and enhanced movement accuracy compared to conventional teaching methods. Participants consistently rated 3D models higher for ease of understanding, effectiveness, and motivation.",
      "authors": [
        "Kengo Tanaka",
        "Xiyue Wang",
        "Hironobu Takagi",
        "Yoichi Ochiai",
        "Chieko Asakawa"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-16 03:53:10+00:00",
      "link": "https://arxiv.org/pdf/2602.14442v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14441v1",
      "title": "D-SECURE: Dual-Source Evidence Combination for Unified Reasoning in Misinformation Detection",
      "abstract": "Multimodal misinformation increasingly mixes realistic im-age edits with fluent but misleading text, producing persuasive posts that are difficult to verify. Existing systems usually rely on a single evidence source. Content-based detectors identify local inconsistencies within an image and its caption but cannot determine global factual truth. Retrieval-based fact-checkers reason over external evidence but treat inputs as coarse claims and often miss subtle visual or textual manipulations. This separation creates failure cases where internally consistent fabrications bypass manipulation detectors and fact-checkers verify claims that contain pixel-level or token-level corruption. We present D-SECURE, a framework that combines internal manipulation detection with external evidence-based reasoning for news-style posts. D-SECURE integrates the HAMMER manipulation detector with the DEFAME retrieval pipeline. DEFAME performs broad verification, and HAMMER analyses residual or uncertain cases that may contain fine-grained edits. Experiments on DGM4 and ClaimReview samples highlight the complementary strengths of both systems and motivate their fusion. We provide a unified, explainable report that incorporates manipulation cues and external evidence.",
      "authors": [
        "Gagandeep Singh",
        "Samudi Amarasinghe",
        "Priyanka Singh"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 03:51:49+00:00",
      "link": "https://arxiv.org/pdf/2602.14441v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14440v1",
      "title": "CAIRO: Decoupling Order from Scale in Regression",
      "abstract": "Standard regression methods typically optimize a single pointwise objective, such as mean squared error, which conflates the learning of ordering with the learning of scale. This coupling renders models vulnerable to outliers and heavy-tailed noise. We propose CAIRO (Calibrate After Initial Rank Ordering), a framework that decouples regression into two distinct stages. In the first stage, we learn a scoring function by minimizing a scale-invariant ranking loss; in the second, we recover the target scale via isotonic regression. We theoretically characterize a class of \"Optimal-in-Rank-Order\" objectives -- including variants of RankNet and Gini covariance -- and prove that they recover the ordering of the true conditional mean under mild assumptions. We further show that subsequent monotone calibration guarantees recovery of the true regression function. Empirically, CAIRO combines the representation learning of neural networks with the robustness of rank-based statistics. It matches the performance of state-of-the-art tree ensembles on tabular benchmarks and significantly outperforms standard regression objectives in regimes with heavy-tailed or heteroskedastic noise.",
      "authors": [
        "Harri Vanhems",
        "Yue Zhao",
        "Peng Shi",
        "Archer Y. Yang"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-16 03:50:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14440v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14438v1",
      "title": "RoboSolver: A Multi-Agent Large Language Model Framework for Solving Robotic Arm Problems",
      "abstract": "This study proposes an intelligent multi-agent framework built on LLMs and VLMs and specifically tailored to robotics. The goal is to integrate the strengths of LLMs and VLMs with computational tools to automatically analyze and solve problems related to robotic manipulators. Our developed framework accepts both textual and visual inputs and can automatically perform forward and inverse kinematics, compute velocities and accelerations of key points, generate 3D simulations of the robot, and ultimately execute motion control within the simulated environment, all according to the user's query. To evaluate the framework, three benchmark tests were designed, each consisting of ten questions. In the first benchmark test, the framework was evaluated while connected to GPT-4o, DeepSeek-V3.2, and Claude-Sonnet-4.5, as well as their corresponding raw models. The objective was to extract the forward kinematics of robots directly from textual descriptions. The results showed that the framework integrated with GPT-4o achieved the highest accuracy, reaching 0.97 in computing the final solution, whereas the raw model alone attained an accuracy of only 0.30 for the same task. Similarly, for the other two models, the framework consistently outperformed the corresponding raw models in terms of accuracy. The second benchmark test was identical to the first, except that the input was provided in visual form. In this test, the GPT-4o LLM was used alongside the Gemini 2.5 Pro VLM. The results showed that the framework achieved an accuracy of 0.93 in obtaining the final answer, which is approximately 20% higher than that of the corresponding raw model. The third benchmark test encompassed a range of robotic tasks, including simulation, control, velocity and acceleration computation, as well as inverse kinematics and Jacobian calculation, for which the framework achieved an accuracy of 0.97.",
      "authors": [
        "Hamid Khabazi",
        "Ali F. Meghdari",
        "Alireza Taheri"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.MA"
      ],
      "published": "2026-02-16 03:49:17+00:00",
      "link": "https://arxiv.org/pdf/2602.14438v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14436v1",
      "title": "Noncooperative Virtual Queue Coordination via Uncertainty-Aware Correlated Equilibria",
      "abstract": "Collaborative virtual queueing has been proposed as a mechanism to mitigate airport surface congestion while preserving airline autonomy over aircraft-level pushback decisions. A central coordinator can regulate aggregate pushback capacity but cannot directly control which specific aircraft are released, limiting its ability to steer system-level performance. We propose a noncooperative coordination mechanism for collaborative virtual queueing based on the correlated equilibrium concept, which enables the coordinator to provide incentive-compatible recommendations on aircraft-level pushback decisions without overriding airline autonomy. To account for uncertainty in airlines' internal cost assessments, we introduce chance constraints into the correlated equilibrium formulation. This formulation provides explicit probabilistic guarantees on incentive compatibility, allowing the coordinator to adjust the confidence level with which airlines are expected to follow the recommended actions. We further propose a scalable algorithm for computing chance-constrained correlated equilibria by exploiting a reduced-rank structure. Numerical experiments demonstrate that the proposed method scales to realistic traffic levels up to 210 eligible pushbacks per hour, reduces accumulated delay by up to approximately 8.9% compared to current first-come-first-served schemes, and reveals a trade-off between confidence level, deviation robustness, and achievable cost efficiency.",
      "authors": [
        "Jaehan Im",
        "David Fridovich-Keil",
        "Ufuk Topcu"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.MA"
      ],
      "published": "2026-02-16 03:45:45+00:00",
      "link": "https://arxiv.org/pdf/2602.14436v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14434v1",
      "title": "A Soft Wrist with Anisotropic and Selectable Stiffness for Robust Robot Learning in Contact-rich Manipulation",
      "abstract": "Contact-rich manipulation tasks in unstructured environments pose significant robustness challenges for robot learning, where unexpected collisions can cause damage and hinder policy acquisition. Existing soft end-effectors face fundamental limitations: they either provide a limited deformation range, lack directional stiffness control, or require complex actuation systems that compromise practicality. This study introduces CLAW (Compliant Leaf-spring Anisotropic soft Wrist), a novel soft wrist mechanism that addresses these limitations through a simple yet effective design using two orthogonal leaf springs and rotary joints with a locking mechanism. CLAW provides large 6-degree-of-freedom deformation (40mm lateral, 20mm vertical), anisotropic stiffness that is tunable across three distinct modes, while maintaining lightweight construction (330g) at low cost ($550). Experimental evaluations using imitation learning demonstrate that CLAW achieves 76% success rate in benchmark peg-insertion tasks, outperforming both the Fin Ray gripper (43%) and rigid gripper alternatives (36%). CLAW successfully handles diverse contact-rich scenarios, including precision assembly with tight tolerances and delicate object manipulation, demonstrating its potential to enable robust robot learning in contact-rich domains. Project page: https://project-page-manager.github.io/CLAW/",
      "authors": [
        "Steven Oh",
        "Tomoya Takahashi",
        "Cristian C. Beltran-Hernandez",
        "Yuki Kuroda",
        "Masashi Hamaya"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-16 03:45:04+00:00",
      "link": "https://arxiv.org/pdf/2602.14434v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14433v1",
      "title": "Synthetic Reader Panels: Tournament-Based Ideation with LLM Personas for Autonomous Publishing",
      "abstract": "We present a system for autonomous book ideation that replaces human focus groups with synthetic reader panels -- diverse collections of LLM-instantiated reader personas that evaluate book concepts through structured tournament competitions. Each persona is defined by demographic attributes (age group, gender, income, education, reading level), behavioral patterns (books per year, genre preferences, discovery methods, price sensitivity), and consistency parameters. Panels are composed per imprint to reflect target demographics, with diversity constraints ensuring representation across age, reading level, and genre affinity. Book concepts compete in single-elimination, double-elimination, round-robin, or Swiss-system tournaments, judged against weighted criteria including market appeal, originality, and execution potential. To reject low-quality LLM evaluations, we implement five automated anti-slop checks (repetitive phrasing, generic framing, circular reasoning, score clustering, audience mismatch). We report results from deployment within a multi-imprint publishing operation managing 6 active imprints and 609 titles in distribution. Three case studies -- a 270-evaluator panel for a children's literacy novel, and two 5-person expert panels for a military memoir and a naval strategy monograph -- demonstrate that synthetic panels produce actionable demographic segmentation, identify structural content issues invisible to homogeneous reviewers, and enable tournament filtering that eliminates low-quality concepts while enriching high-quality survivors from 15% to 62% of the evaluated pool.",
      "authors": [
        "Fred Zimmerman"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "published": "2026-02-16 03:44:54+00:00",
      "link": "https://arxiv.org/pdf/2602.14433v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14432v1",
      "title": "S2D: Selective Spectral Decay for Quantization-Friendly Conditioning of Neural Activations",
      "abstract": "Activation outliers in large-scale transformer models pose a fundamental challenge to model quantization, creating excessively large ranges that cause severe accuracy drops during quantization. We empirically observe that outlier severity intensifies with pre-training scale (e.g., progressing from CLIP to the more extensively trained SigLIP and SigLIP2). Through theoretical analysis as well as empirical correlation studies, we establish the direct link between these activation outliers and dominant singular values of the weights. Building on this insight, we propose Selective Spectral Decay ($S^2D$), a geometrically-principled conditioning method that surgically regularizes only the weight components corresponding to the largest singular values during fine-tuning. Through extensive experiments, we demonstrate that $S^2D$ significantly reduces activation outliers and produces well-conditioned representations that are inherently quantization-friendly. Models trained with $S^2D$ achieve up to 7% improved PTQ accuracy on ImageNet under W4A4 quantization and 4% gains when combined with QAT. These improvements also generalize across downstream tasks and vision-language models, enabling the scaling of increasingly large and rigorously trained models without sacrificing deployment efficiency.",
      "authors": [
        "Arnav Chavan",
        "Nahush Lele",
        "Udbhav Bamba",
        "Sankalp Dayal",
        "Aditi Raghunathan",
        "Deepak Gupta"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-02-16 03:41:06+00:00",
      "link": "https://arxiv.org/pdf/2602.14432v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14431v1",
      "title": "'I Spend All My Energy Preparing': Balancing AI Automation and Agency for Self-Regulated Learning in SmartFlash",
      "abstract": "Effective study strategies fail when preparatory tasks consume learning time. While AI educational tools demonstrate efficacy, understanding how they align with self-regulation needs in authentic study contexts remains limited. We conducted formative design research using an AI flashcard prototype, employing large language models to generate design hypotheses, which were validated through researcher walkthroughs and student sessions. Six students across disciplines completed sessions combining interviews and think-aloud tasks with their materials. Analysis revealed that students value automation for addressing the overwhelming preparation burden, yet require transparent, editable AI outputs to maintain cognitive ownership, which is essential for self-regulation. They conceptualized AI as a collaborative partner demanding verifiable reasoning rather than an autonomous agent. Metacognitive scaffolding was endorsed when clarifying study direction without constraining choice. Motivational features produced divergent responses. We derive design principles prioritizing editability and transparency, scaffolding metacognition without prescription, and accommodating motivational diversity. Findings identify conditions under which automation supports versus undermines metacognitive development in self-regulated learning.",
      "authors": [
        "Hongming Li",
        "Salah Esmaeiligoujar",
        "Nazanin Adham",
        "Hai Li",
        "Rui Huang"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-16 03:40:08+00:00",
      "link": "https://arxiv.org/pdf/2602.14431v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14430v1",
      "title": "A unified framework for evaluating the robustness of machine-learning interpretability for prospect risking",
      "abstract": "In geophysics, hydrocarbon prospect risking involves assessing the risks associated with hydrocarbon exploration by integrating data from various sources. Machine learning-based classifiers trained on tabular data have been recently used to make faster decisions on these prospects. The lack of transparency in the decision-making processes of such models has led to the emergence of explainable AI (XAI). LIME and SHAP are two such examples of these XAI methods which try to generate explanations of a particular decision by ranking the input features in terms of importance. However, explanations of the same scenario generated by these two different explanation strategies have shown to disagree or be different, particularly for complex data. This is because the definitions of \"importance\" and \"relevance\" differ for different explanation strategies. Thus, grounding these ranked features using theoretically backed causal ideas of necessity and sufficiency can prove to be a more reliable and robust way to improve the trustworthiness of the concerned explanation strategies.We propose a unified framework to generate counterfactuals as well as quantify necessity and sufficiency and use these to perform a robustness evaluation of the explanations provided by LIME and SHAP on high dimensional structured prospect risking data. This robustness test gives us deeper insights into the models capabilities to handle erronous data and which XAI module works best in pair with which model for our dataset for hydorcarbon indication.",
      "authors": [
        "Prithwijit Chowdhury",
        "Ahmad Mustafa",
        "Mohit Prabhushankar",
        "Ghassan AlRegib"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 03:32:10+00:00",
      "link": "https://arxiv.org/pdf/2602.14430v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14428v1",
      "title": "LLM-Guided Knowledge Distillation for Temporal Knowledge Graph Reasoning",
      "abstract": "Temporal knowledge graphs (TKGs) support reasoning over time-evolving facts, yet state-of-the-art models are often computationally heavy and costly to deploy. Existing compression and distillation techniques are largely designed for static graphs; directly applying them to temporal settings may overlook time-dependent interactions and lead to performance degradation. We propose an LLM-assisted distillation framework specifically designed for temporal knowledge graph reasoning. Beyond a conventional high-capacity temporal teacher, we incorporate a large language model as an auxiliary instructor to provide enriched supervision. The LLM supplies broad background knowledge and temporally informed signals, enabling a lightweight student to better model event dynamics without increasing inference-time complexity. Training is conducted by jointly optimizing supervised and distillation objectives, using a staged alignment strategy to progressively integrate guidance from both teachers. Extensive experiments on multiple public TKG benchmarks with diverse backbone architectures demonstrate that the proposed approach consistently improves link prediction performance over strong distillation baselines, while maintaining a compact and efficient student model. The results highlight the potential of large language models as effective teachers for transferring temporal reasoning capability to resource-efficient TKG systems.",
      "authors": [
        "Wang Xing",
        "Wei Song",
        "Siyu Lin",
        "Chen Wu",
        "Man Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 03:27:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14428v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14425v1",
      "title": "Hierarchical Vision-Language Interaction for Facial Action Unit Detection",
      "abstract": "Facial Action Unit (AU) detection seeks to recognize subtle facial muscle activations as defined by the Facial Action Coding System (FACS). A primary challenge w.r.t AU detection is the effective learning of discriminative and generalizable AU representations under conditions of limited annotated data. To address this, we propose a Hierarchical Vision-language Interaction for AU Understanding (HiVA) method, which leverages textual AU descriptions as semantic priors to guide and enhance AU detection. Specifically, HiVA employs a large language model to generate diverse and contextually rich AU descriptions to strengthen language-based representation learning. To capture both fine-grained and holistic vision-language associations, HiVA introduces an AU-aware dynamic graph module that facilitates the learning of AU-specific visual representations. These features are further integrated within a hierarchical cross-modal attention architecture comprising two complementary mechanisms: Disentangled Dual Cross-Attention (DDCA), which establishes fine-grained, AU-specific interactions between visual and textual features, and Contextual Dual Cross-Attention (CDCA), which models global inter-AU dependencies. This collaborative, cross-modal learning paradigm enables HiVA to leverage multi-grained vision-based AU features in conjunction with refined language-based AU details, culminating in robust and semantically enriched AU detection capabilities. Extensive experiments show that HiVA consistently surpasses state-of-the-art approaches. Besides, qualitative analyses reveal that HiVA produces semantically meaningful activation patterns, highlighting its efficacy in learning robust and interpretable cross-modal correspondences for comprehensive facial behavior analysis.",
      "authors": [
        "Yong Li",
        "Yi Ren",
        "Yizhe Zhang",
        "Wenhua Zhang",
        "Tianyi Zhang",
        "Muyun Jiang",
        "Guo-Sen Xie",
        "Cuntai Guan"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 03:22:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14425v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14423v1",
      "title": "The geometry of invariant learning: an information-theoretic analysis of data augmentation and generalization",
      "abstract": "Data augmentation is one of the most widely used techniques to improve generalization in modern machine learning, often justified by its ability to promote invariance to label-irrelevant transformations. However, its theoretical role remains only partially understood. In this work, we propose an information-theoretic framework that systematically accounts for the effect of augmentation on generalization and invariance learning. Our approach builds upon mutual information-based bounds, which relate the generalization gap to the amount of information a learning algorithm retains about its training data. We extend this framework by modeling the augmented distribution as a composition of the original data distribution with a distribution over transformations, which naturally induces an orbit-averaged loss function. Under mild sub-Gaussian assumptions on the loss function and the augmentation process, we derive a new generalization bound that decompose the expected generalization gap into three interpretable terms: (1) a distributional divergence between the original and augmented data, (2) a stability term measuring the algorithm dependence on training data, and (3) a sensitivity term capturing the effect of augmentation variability. To connect our bounds to the geometry of the augmentation group, we introduce the notion of group diameter, defined as the maximal perturbation that augmentations can induce in the input space. The group diameter provides a unified control parameter that bounds all three terms and highlights an intrinsic trade-off: small diameters preserve data fidelity but offer limited regularization, while large diameters enhance stability at the cost of increased bias and sensitivity. We validate our theoretical bounds with numerical experiments, demonstrating that it reliably tracks and predicts the behavior of the true generalization gap.",
      "authors": [
        "Abdelali Bouyahia",
        "Frédéric LeBlanc",
        "Mario Marchand"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-02-16 03:18:39+00:00",
      "link": "https://arxiv.org/pdf/2602.14423v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14419v1",
      "title": "WavePhaseNet: A DFT-Based Method for Constructing Semantic Conceptual Hierarchy Structures (SCHS)",
      "abstract": "This paper reformulates Transformer/Attention mechanisms in Large Language Models (LLMs) through measure theory and frequency analysis, theoretically demonstrating that hallucination is an inevitable structural limitation. The embedding space functions as a conditional expectation over a σ-algebra, and its failure to be isomorphic to the semantic truth set fundamentally causes logical consistency breakdown. WavePhaseNet Method The authors propose WavePhaseNet, which explicitly constructs a Semantic Conceptual Hierarchy Structure (SCHS) using Discrete Fourier Transform (DFT). By applying DFT along the sequence dimension, semantic information is decomposed into frequency bands: low-frequency components capture global meaning and intent, while high-frequency components represent local syntax and expression. This staged separation enables precise semantic manipulation in diagonalized space. Dimensionality Reduction GPT-4's 24,576-dimensional embedding space exhibits a 1/f spectral structure based on language self-similarity and Zipf's law. Through cumulative energy analysis, the authors derive that approximately 3,000 dimensions constitute the lower bound for \"complete representation.\" This demonstrates that reduction from 24,576 to 3,000 dimensions preserves meaning and intent while enabling rigorous reasoning and suppressing hallucination. Cohomological Consistency Control The reduced embedding space, constructed via cohomological regularization over overlapping local windows, allows defining a graph structure and cochain complex. This quantifies inconsistencies among local inferences as coboundary-based losses. Applying harmonic projection based on Hodge theory positions cohomology as a computable regularization principle for controlling semantic consistency, extracting maximally consistent global representations.",
      "authors": [
        "Kiyotaka Kasubuchi",
        "Kazuo Fukiya"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 03:07:41+00:00",
      "link": "https://arxiv.org/pdf/2602.14419v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14415v1",
      "title": "Reconfigurable Intelligent Surfaces-assisted Positioning in Integrated Sensing and Communication Systems",
      "abstract": "This paper investigates the problem of high-precision target localization in integrated sensing and communication (ISAC) systems, where the target is sensed via both a direct path and a reconfigurable intelligent surface (RIS)-assisted reflection path. We first develop a sequential matched-filter estimator to acquire coarse angular parameters, followed by a range recovery process based on subcarrier phase differences. Subsequently, we formulate the target localization problem as a non-linear least squares optimization, using the coarse estimates to initialize the target's position coordinates. To solve this efficiently, we introduce a fast iterative refinement algorithm tailored for RIS-aided ISAC environments. Recognizing that the signal model involves both linear path gains and non-linear geometric dependencies, we exploit the separable least-squares structure to decouple these parameters. Furthermore, we propose a modified Levenberg algorithm with an approximation strategy, which enables low-cost parameter updates without necessitating repeated evaluations of the full non-linear model. Simulation results show that the proposed refinement method achieves accuracy comparable to conventional approaches, while significantly reducing algorithmic complexity.",
      "authors": [
        "Huyen-Trang Ta",
        "Ngoc-Son Duong",
        "Trung-Hieu Nguyen",
        "Van-Linh Nguyen",
        "Thai-Mai Dinh"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "cs.IT"
      ],
      "published": "2026-02-16 02:48:59+00:00",
      "link": "https://arxiv.org/pdf/2602.14415v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14413v1",
      "title": "Understanding Sensor Vulnerabilities in Industrial XR Tracking",
      "abstract": "Extended Reality (XR) systems deployed in industrial and operational settings rely on Visual--Inertial Odometry (VIO) for continuous six-degree-of-freedom pose tracking, yet these environments often involve sensing conditions that deviate from ideal assumptions. Despite this, most VIO evaluations emphasize nominal sensor behavior, leaving the effects of sustained sensor degradation under operational conditions insufficiently understood. This paper presents a controlled empirical study of VIO behavior under degraded sensing, examining faults affecting visual and inertial modalities across a range of operating regimes. Through systematic fault injection and quantitative evaluation, we observe a pronounced asymmetry in fault impact where degradations affecting visual sensing typically lead to bounded pose errors on the order of centimeters, whereas degradations affecting inertial sensing can induce substantially larger trajectory deviations, in some cases reaching hundreds to thousands of meters. These observations motivate greater emphasis on inertial reliability in the evaluation and design of XR systems for real-life industrial settings.",
      "authors": [
        "Sourya Saha",
        "Md. Nurul Absur"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "published": "2026-02-16 02:42:15+00:00",
      "link": "https://arxiv.org/pdf/2602.14413v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14409v1",
      "title": "Learning Proposes, Geometry Disposes: A Modular Framework for Efficient Spatial Reasoning",
      "abstract": "Spatial perception aims to estimate camera motion and scene structure from visual observations, a problem traditionally addressed through geometric modeling and physical consistency constraints. Recent learning-based methods have demonstrated strong representational capacity for geometric perception and are increasingly used to augment classical geometry-centric systems in practice. However, whether learning components should directly replace geometric estimation or instead serve as intermediate modules within such pipelines remains an open question.   In this work, we address this gap and investigate an end-to-end modular framework for effective spatial reasoning, where learning proposes geometric hypotheses, while geometric algorithms dispose estimation decisions. In particular, we study this principle in the context of relative camera pose estimation on RGB-D sequences. Using VGGT as a representative learning model, we evaluate learning-based pose and depth proposals under varying motion magnitudes and scene dynamics, followed by a classical point-to-plane RGB-D ICP as the geometric backend. Our experiments on the TUM RGB-D benchmark reveal three consistent findings: (1) learning-based pose proposals alone are unreliable; (2) learning-proposed geometry, when improperly aligned with camera intrinsics, can degrade performance; and (3) when learning-proposed depth is geometrically aligned and followed by a geometric disposal stage, consistent improvements emerge in moderately challenging rigid settings.   These results demonstrate that geometry is not merely a refinement component, but an essential arbiter that validates and absorbs learning-based geometric observations. Our study highlights the importance of modular, geometry-aware system design for robust spatial perception.",
      "authors": [
        "Haichao Zhu",
        "Zhaorui Yang",
        "Qian Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 02:26:59+00:00",
      "link": "https://arxiv.org/pdf/2602.14409v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14408v1",
      "title": "Feature Recalibration Based Olfactory-Visual Multimodal Model for Fine-Grained Rice Deterioration Detection",
      "abstract": "Multimodal methods are widely used in rice deterioration detection, which exhibit limited capability in representing and extracting fine-grained abnormal features. Moreover, these methods rely on devices, such as hyperspectral cameras and mass spectrometers, increasing detection costs and prolonging data acquisition time. To address these issues, we propose a feature recalibration based olfactory-visual multimodal model for fine-grained rice deterioration detection. The fine-grained deterioration embedding constructor (FDEC) is proposed to reconstruct the labeled multimodal embedded-feature dataset, enhancing sample representation. The fine-grained deterioration recalibration attention network (FDRA-Net) is proposed to emphasize signal variations and increase sensitivity to fine-grained deterioration on the rice surface. Experiments show that the proposed method achieves a classification accuracy of 99.89%. Compared with state-of-the-art methods, the detection accuracy is improved and the procedure is simplified. Furthermore, field detection demonstrates the advantages of accuracy and operational simplicity. The proposed method can also be extended to other agrifood in agriculture and food industry.",
      "authors": [
        "Rongqiang Zhao",
        "Hengrui Hu",
        "Yijing Wang",
        "Mingchun Sun",
        "Jie Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-16 02:26:51+00:00",
      "link": "https://arxiv.org/pdf/2602.14408v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14406v1",
      "title": "TruthStance: An Annotated Dataset of Conversations on Truth Social",
      "abstract": "Argument mining and stance detection are central to understanding how opinions are formed and contested in online discourse. However, most publicly available resources focus on mainstream platforms such as Twitter and Reddit, leaving conversational structure on alt-tech platforms comparatively under-studied. We introduce TruthStance, a large-scale dataset of Truth Social conversation threads spanning 2023-2025, consisting of 24,378 posts and 523,360 comments with reply-tree structure preserved. We provide a human-annotated benchmark of 1,500 instances across argument mining and claim-based stance detection, including inter-annotator agreement, and use it to evaluate large language model (LLM) prompting strategies. Using the best-performing configuration, we release additional LLM-generated labels for 24,352 posts (argument presence) and 107,873 comments (stance to parent), enabling analysis of stance and argumentation patterns across depth, topics, and users. All code and data are released publicly.",
      "authors": [
        "Fathima Ameen",
        "Danielle Brown",
        "Manusha Malgareddy",
        "Amanul Haque"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-16 02:25:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14406v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14407v1",
      "title": "\"I Felt Bad After We Ignored Her\": Understanding How Interface-Driven Social Prominence Shapes Group Discussions with GenAI",
      "abstract": "Recent advancements in the conversational and social capabilities of generative AI (GenAI) have sparked interest in its role as an agent capable of actively participating in human-AI group discussions. Despite this momentum, we don't fully understand how GenAI shapes conversational dynamics or how the interface design impacts its influence on the group. In this paper, we introduce interface-driven social prominence as a design lens for collaborative GenAI systems. We then present a GenAI-based conversational agent that can actively engage in spoken dialogue during video calls and design three distinct collaboration modes that vary the social prominence of the agent by manipulating its presence in the shared space and the degree of control users have over its participation. A mixed-methods within-subjects study, in which 18 dyads engaged in realistic discussions with a GenAI agent, offers empirical insights into how communication patterns and the collective negotiation of GenAI's influence shift based on how it is embedded into the collaborative experience. Based on these findings, we outline design implications for supporting the coordination and critical engagement required in human-AI groups.",
      "authors": [
        "Janet G. Johnson",
        "Ruijie Sophia Huang",
        "Khoa Nguyen",
        "Ji Young Nam",
        "Michael Nebeling"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-16 02:25:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14407v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14404v1",
      "title": "Boule or Baguette? A Study on Task Topology, Length Generalization, and the Benefit of Reasoning Traces",
      "abstract": "Recent years have witnessed meteoric progress in reasoning models: neural networks that generate intermediate reasoning traces (RTs) before producing a final output. Despite the rapid advancement, our understanding of how RTs support reasoning, and the limits of this paradigm, remain incomplete. To promote greater clarity, we introduce PITA: a novel large-scale dataset of over 23 million statements in propositional logic and their corresponding proofs. As a benchmark for robust reasoning, we focus on length generalization: if a model is trained to determine truth or falsity on statements with proofs up to fixed length, how well does it generalize to statements requiring longer proofs? We propose notions of (1) task depth and (2) task breadth, which measure respectively (1) the number of steps required to solve an example from a task and (2) the number of unique examples across a task. We vary these quantities across subsets of PITA, and find that RT models generalize well on broad and shallow subsets, while deteriorating on narrow and deep subsets relative to non-RT baselines. To determine whether our results are idiosyncratic to PITA or indicative of general phenomena, we compare our results to a simple synthetic task based on syllogisms. Our resulting theory suggests fundamental scalings that limit how well RT models perform on deep tasks, and highlights their generalization strengths on broad tasks. Our findings overall identify fundamental benefits and limitations inherent in using reasoning traces.",
      "authors": [
        "William L. Tong",
        "Ege Cakar",
        "Cengiz Pehlevan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "published": "2026-02-16 02:20:37+00:00",
      "link": "https://arxiv.org/pdf/2602.14404v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14401v1",
      "title": "pFedNavi: Structure-Aware Personalized Federated Vision-Language Navigation for Embodied AI",
      "abstract": "Vision-Language Navigation VLN requires large-scale trajectory instruction data from private indoor environments, raising significant privacy concerns. Federated Learning FL mitigates this by keeping data on-device, but vanilla FL struggles under VLNs' extreme cross-client heterogeneity in environments and instruction styles, making a single global model suboptimal. This paper proposes pFedNavi, a structure-aware and dynamically adaptive personalized federated learning framework tailored for VLN. Our key idea is to personalize where it matters: pFedNavi adaptively identifies client-specific layers via layer-wise mixing coefficients, and performs fine-grained parameter fusion on the selected components (e.g., the encoder-decoder projection and environment-sensitive decoder layers) to balance global knowledge sharing with local specialization. We evaluate pFedNavi on two standard VLN benchmarks, R2R and RxR, using both ResNet and CLIP visual representations. Across all metrics, pFedNavi consistently outperforms the FedAvg-based VLN baseline, achieving up to 7.5% improvement in navigation success rate and up to 7.8% gain in trajectory fidelity, while converging 1.38x faster under non-IID conditions.",
      "authors": [
        "Qingqian Yang",
        "Hao Wang",
        "Sai Qian Zhang",
        "Jian Li",
        "Yang Hua",
        "Miao Pan",
        "Tao Song",
        "Zhengwei Qi",
        "Haibing Guan"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-16 02:18:09+00:00",
      "link": "https://arxiv.org/pdf/2602.14401v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14399v1",
      "title": "Multi-Turn Adaptive Prompting Attack on Large Vision-Language Models",
      "abstract": "Multi-turn jailbreak attacks are effective against text-only large language models (LLMs) by gradually introducing malicious content across turns. When extended to large vision-language models (LVLMs), we find that naively adding visual inputs can cause existing multi-turn jailbreaks to be easily defended. For example, overly malicious visual input will easily trigger the defense mechanism of safety-aligned LVLMs, making the response more conservative. To address this, we propose MAPA: a multi-turn adaptive prompting attack that 1) at each turn, alternates text-vision attack actions to elicit the most malicious response; and 2) across turns, adjusts the attack trajectory through iterative back-and-forth refinement to gradually amplify response maliciousness. This two-level design enables MAPA to consistently outperform state-of-the-art methods, improving attack success rates by 11-35% on recent benchmarks against LLaVA-V1.6-Mistral-7B, Qwen2.5-VL-7B-Instruct, Llama-3.2-Vision-11B-Instruct and GPT-4o-mini.",
      "authors": [
        "In Chong Choi",
        "Jiacheng Zhang",
        "Feng Liu",
        "Yiliao Song"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 02:15:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14399v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14397v1",
      "title": "LRD-MPC: Efficient MPC Inference through Low-rank Decomposition",
      "abstract": "Secure Multi-party Computation (MPC) enables untrusted parties to jointly compute a function without revealing their inputs. Its application to machine learning (ML) has gained significant attention, particularly for secure inference services deployed across multiple cloud virtual machines (VMs), where each VM acts as an MPC party. Model providers secret-share model weights, and users secret-share inputs, ensuring that each server operates only on random shares. While MPC provides strong cryptographic guarantees, it incurs substantial computational and communication overhead. Deep neural networks rely heavily on convolutional and fully connected layers, which require costly matrix multiplications in MPC. To reduce this cost, we propose leveraging low-rank decomposition (LRD) for linear layers, replacing one large matrix multiplication with two smaller ones. Each matrix multiplication in MPC incurs a round of communication, meaning decomposing one matrix multiplication into two leads to an additional communication round. Second, the added matrix multiplication requires an additional truncation step to maintain numerical precision. Since truncation itself requires communication and computation, these overheads can offset the gains from decomposition. To address this, we introduce two complementary optimizations: truncation skipping and efficient linear layer concatenation. Truncation skipping removes the extra truncation induced by LRD, while linear layer concatenation pipelines operations to hide the additional communication round. Together, these techniques mitigate the main overheads of LRD in MPC and improve overall efficiency. Our approach is broadly applicable across MPC protocols. Experiments show up to 25% speedup in n-PC and 33% in 3-PC protocols over full-rank baselines, along with up to 52% GPU energy savings and 88% reduction in offline-phase latency.",
      "authors": [
        "Tingting Tang",
        "Yongqin Wang",
        "Murali Annavaram"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-02-16 02:11:38+00:00",
      "link": "https://arxiv.org/pdf/2602.14397v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14393v1",
      "title": "Scope: A Scalable Merged Pipeline Framework for Multi-Chip-Module NN Accelerators",
      "abstract": "Neural network (NN) accelerators with multi-chip-module (MCM) architectures enable integration of massive computation capability; however, they face challenges of computing resource underutilization and off-chip communication overheads. Traditional parallelization schemes for NN inference on MCM architectures, such as intra-layer parallelism and inter-layer pipelining, show incompetency in breaking through both challenges, limiting the scalability of MCM architectures.   We observed that existing works typically deploy layers separately rather than considering them jointly. This underexploited dimension leads to compromises between system computation and communication, thus hindering optimal utilization, especially as hardware/software scale. To address this limitation, we propose Scope, a merged pipeline framework incorporating this overlooked multi-layer dimension, thereby achieving improved throughput and scalability by relaxing tradeoffs between computation, communication and memory costs. This new dimension, however, adds to the complexity of design space exploration (DSE). To tackle this, we develop a series of search algorithms that achieves exponential-to-linear complexity reduction, while identifying solutions that rank in the top 0.05% of performance. Experiments show that Scope achieves up to 1.73x throughput improvement while maintaining similar energy consumption for ResNet-152 inference compared to state-of-the-art approaches.",
      "authors": [
        "Zongle Huang",
        "Hongyang Jia",
        "Kaiwei Zou",
        "Yongpan Liu"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR"
      ],
      "published": "2026-02-16 01:52:41+00:00",
      "link": "https://arxiv.org/pdf/2602.14393v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14391v1",
      "title": "ASA: Adaptive Smart Agent Federated Learning via Device-Aware Clustering for Heterogeneous IoT",
      "abstract": "Federated learning (FL) has become a promising answer to facilitating privacy-preserving collaborative learning in distributed IoT devices. However, device heterogeneity is a key challenge because IoT networks include devices with very different computational powers, memory availability, and network environments. To this end, we introduce ASA (Adaptive Smart Agent). This new framework clusters devices adaptively based on real-time resource profiles and adapts customized models suited to every cluster's capability. ASA capitalizes on an intelligent agent layer that examines CPU power, available memory, and network environment to categorize devices into three levels: high-performance, mid-tier, and low-capability. Each level is provided with a model tuned to its computational power to ensure inclusive engagement across the network. Experimental evaluation on two benchmark datasets, MNIST and CIFAR-10, proves that ASA decreases communication burden by 43% to 50%, improves resource utilization by 43%, and achieves final model accuracies of 98.89% on MNIST and 85.30% on CIFAR-10. These results highlight ASA's efficacy in enhancing efficiency, scalability, and fairness in heterogeneous FL environments, rendering it a suitable answer for real-world IoT apps.",
      "authors": [
        "Ali Salimi",
        "Saadat Izadi",
        "Mahmood Ahmadi",
        "Hadi Tabatabaee Malazi"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-02-16 01:42:25+00:00",
      "link": "https://arxiv.org/pdf/2602.14391v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14390v1",
      "title": "A Q-Learning Approach for Dynamic Resource Management in Three-Tier Vehicular Fog Computing",
      "abstract": "In this paper, a method for predicting the resources required for an intelligent vehicle client using a three-layer vehicular computing architecture is proposed. This method leverages Q-Learning to optimize resource allocation and enhance overall system performance. This approach employs reinforcement learning capabilities to provide a dynamic and adaptive strategy for resource management in a fog computing environment. The key findings of this study indicate that Q-learning can effectively predict the appropriate allocation of resources by learning from past experiences and making informed decisions. Through continuous training and updating of the Q-learning agent, the system can adapt to changing conditions and make resource allocation decisions based on real-time information. The experimental results demonstrate the effectiveness of the proposed method in optimizing resource allocation. The Q-learning agent predicts the optimal values for memory, bandwidth, and processor. These predictions not only minimize resource consumption but also meet the performance requirements of the fog system. Implementations show that this method improves the average task processing time in compared to other methods evaluated in this study",
      "authors": [
        "Bahar Mojtabaei Ranani",
        "Mahmood Ahmadi",
        "Sajad Ahmadian"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-02-16 01:39:24+00:00",
      "link": "https://arxiv.org/pdf/2602.14390v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14386v1",
      "title": "Beyond Token-Level Policy Gradients for Complex Reasoning with Large Language Models",
      "abstract": "Existing policy-gradient methods for auto-regressive language models typically select subsequent tokens one at a time as actions in the policy. While effective for many generation tasks, such an approach may not fully capture the structure of complex reasoning tasks, where a single semantic decision is often realized across multiple tokens--for example, when defining variables or composing equations. This introduces a potential mismatch between token-level optimization and the inherently block-level nature of reasoning in these settings. To bridge this gap, we propose Multi-token Policy Gradient Optimization (MPO), a framework that treats sequences of K consecutive tokens as unified semantic actions. This block-level perspective enables our method to capture the compositional structure of reasoning trajectories and supports optimization over coherent, higher-level objectives. Experiments on mathematical reasoning and coding benchmarks show that MPO outperforms standard token-level policy gradient baselines, highlight the limitations of token-level policy gradients for complex reasoning, motivating future research to look beyond token-level granularity for reasoning-intensive language tasks.",
      "authors": [
        "Mufan Xu",
        "Kehai Chen",
        "Xuefeng Bai",
        "Zhengyu Niu",
        "Muyun Yang",
        "Tiejun Zhao",
        "Min Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-16 01:28:38+00:00",
      "link": "https://arxiv.org/pdf/2602.14386v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14385v1",
      "title": "Sensitivity of Repetitiveness Measures to String Reversal",
      "abstract": "We study the impact that string reversal can have on several repetitiveness measures. First, we exhibit an infinite family of strings where the number, $r$, of runs in the run-length encoding of the Burrows--Wheeler transform (BWT) can increase additively by $Θ(n)$ when reversing the string. This substantially improves the known $Ω(\\log n)$ lower-bound for the additive sensitivity of $r$ and it is asymptotically tight. We generalize our result to other variants of the BWT, including the variant with an appended end-of-string symbol and the bijective BWT. We show that an analogous result holds for the size $z$ of the Lempel--Ziv 77 (LZ) parsing of the text, and also for some of its variants, including the non-overlapping LZ parsing, and the LZ-end parsing. Moreover, we describe a family of strings for which the ratio $z(w^R)/z(w)$ approaches $3$ from below as $|w|\\rightarrow \\infty$. We also show an asymptotically tight lower-bound of $Θ(n)$ for the additive sensitivity of the size $v$ of the smallest lexicographic parsing to string reversal. Finally, we show that the multiplicative sensitivity of $v$ to reversing the string is $Θ(\\log n)$, and this lower-bound is also tight. Overall, our results expose the limitations of repetitiveness measures that are widely used in practice, against string reversal -- a simple and natural data transformation.",
      "authors": [
        "Hideo Bannai",
        "Yuto Fujie",
        "Peaker Guo",
        "Shunsuke Inenaga",
        "Yuto Nakashima",
        "Simon J. Puglisi",
        "Cristian Urbina"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-02-16 01:26:48+00:00",
      "link": "https://arxiv.org/pdf/2602.14385v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14384v1",
      "title": "M-CODE: Materials Categorization via Ontology, Dimensionality and Evolution",
      "abstract": "The rapid advancement of artificial intelligence in materials science requires data standards and data management practices that can capture the complexity of real-world structures, including surfaces, interfaces, defects, and dimensionality reduction. We present M-CODE - Materials Categorization via Ontology, Dimensionality and Evolution - a compact categorization system that links materials-science-specific terminology to a set of reusable concepts as building blocks and provenance-aware transformations. M-CODE classifies structures by dimensionality, structural complexity (from pristine to compound pristine, defective, and processed), and variants that capture common structure creation and evolution approaches. A practical implementation of the categorization is provided in an open-source codebase that includes JSON schemas, examples, and Python and TypeScript types/interfaces, designed to support reproducible dataset generation, validation, and community contributions.",
      "authors": [
        "Vsevolod Biryukov",
        "Kamal Choudhary",
        "Timur Bazhirov"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.DL",
        "physics.comp-ph"
      ],
      "published": "2026-02-16 01:18:15+00:00",
      "link": "https://arxiv.org/pdf/2602.14384v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14381v1",
      "title": "Adapting VACE for Real-Time Autoregressive Video Diffusion",
      "abstract": "We describe an adaptation of VACE (Video All-in-one Creation and Editing) for real-time autoregressive video generation. VACE provides unified video control (reference guidance, structural conditioning, inpainting, and temporal extension) but assumes bidirectional attention over full sequences, making it incompatible with streaming pipelines that require fixed chunk sizes and causal attention. The key modification moves reference frames from the diffusion latent space into a parallel conditioning pathway, preserving the fixed chunk sizes and KV caching that autoregressive models require. This adaptation reuses existing pretrained VACE weights without additional training. Across 1.3B and 14B model scales, VACE adds 20-30% latency overhead for structural control and inpainting, with negligible VRAM cost relative to the base model. Reference-to-video fidelity is severely degraded compared to batch VACE due to causal attention constraints. A reference implementation is available at https://github.com/daydreamlive/scope.",
      "authors": [
        "Ryan Fosdick"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-16 01:13:33+00:00",
      "link": "https://arxiv.org/pdf/2602.14381v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14379v1",
      "title": "Fine-Grained Complexity for Quantum Problems from Size-Preserving Circuit-to-Hamiltonian Constructions",
      "abstract": "The local Hamiltonian (LH) problem is the canonical $\\mathsf{QMA}$-complete problem introduced by Kitaev. In this paper, we show its hardness in a very strong sense: we show that the 3-local Hamiltonian problem on $n$ qubits cannot be solved classically in time $O(2^{(1-\\varepsilon)n})$ for any $\\varepsilon>0$ under the Strong Exponential-Time Hypothesis (SETH), and cannot be solved quantumly in time $O(2^{(1-\\varepsilon)n/2})$ for any $\\varepsilon>0$ under the Quantum Strong Exponential-Time Hypothesis (QSETH). These lower bounds give evidence that the currently known classical and quantum algorithms for LH cannot be significantly improved.   Furthermore, we are able to demonstrate fine-grained complexity lower bounds for approximating the quantum partition function (QPF) with an arbitrary constant relative error. Approximating QPF with relative error is known to be equivalent to approximately counting the dimension of the solution subspace of $\\mathsf{QMA}$ problems. We show the SETH and QSETH hardness to estimate QPF with constant relative error. We then provide a quantum algorithm that runs in $O(\\sqrt{2^n})$ time for an arbitrary $1/\\mathrm{poly}(n)$ relative error, matching our lower bounds and improving the state-of-the-art algorithm by Bravyi, Chowdhury, Gosset, and Wocjan (Nature Physics 2022) in the low-temperature regime.   To prove our fine-grained lower bounds, we introduce the first size-preserving circuit-to-Hamiltonian construction that encodes the computation of a $T$-time quantum circuit acting on $N$ qubits into a $(d+1)$-local Hamiltonian acting on $N+O(T^{1/d})$ qubits. This improves the standard construction based on the unary clock, which uses $N+O(T)$ qubits.",
      "authors": [
        "Nai-Hui Chia",
        "Atsuya Hasegawa",
        "François Le Gall",
        "Yu-Ching Shen"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.CC",
        "cs.DS"
      ],
      "published": "2026-02-16 01:11:55+00:00",
      "link": "https://arxiv.org/pdf/2602.14379v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14376v1",
      "title": "Event-based Visual Deformation Measurement",
      "abstract": "Visual Deformation Measurement (VDM) aims to recover dense deformation fields by tracking surface motion from camera observations. Traditional image-based methods rely on minimal inter-frame motion to constrain the correspondence search space, which limits their applicability to highly dynamic scenes or necessitates high-speed cameras at the cost of prohibitive storage and computational overhead. We propose an event-frame fusion framework that exploits events for temporally dense motion cues and frames for spatially dense precise estimation. Revisiting the solid elastic modeling prior, we propose an Affine Invariant Simplicial (AIS) framework. It partitions the deformation field into linearized sub-regions with low-parametric representation, effectively mitigating motion ambiguities arising from sparse and noisy events. To speed up parameter searching and reduce error accumulation, a neighborhood-greedy optimization strategy is introduced, enabling well-converged sub-regions to guide their poorly-converged neighbors, effectively suppress local error accumulation in long-term dense tracking. To evaluate the proposed method, a benchmark dataset with temporally aligned event streams and frames is established, encompassing over 120 sequences spanning diverse deformation scenarios. Experimental results show that our method outperforms the state-of-the-art baseline by 1.6% in survival rate. Remarkably, it achieves this using only 18.9% of the data storage and processing resources of high-speed video methods.",
      "authors": [
        "Yuliang Wu",
        "Wei Zhai",
        "Yuxin Cui",
        "Tiesong Zhao",
        "Yang Cao",
        "Zheng-Jun Zha"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 01:04:48+00:00",
      "link": "https://arxiv.org/pdf/2602.14376v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14375v1",
      "title": "A Study on Multi-Class Online Fuzzy Classifiers for Dynamic Environments",
      "abstract": "This paper proposes a multi-class online fuzzy classifier for dynamic environments. A fuzzy classifier comprises a set of fuzzy if-then rules where human users determine the antecedent fuzzy sets beforehand. In contrast, the consequent real values are determined by learning from training data. In an online framework, not all training dataset patterns are available beforehand. Instead, only a few patterns are available at a time step, and the subsequent patterns become available at the following time steps. The conventional online fuzzy classifier considered only two-class problems. This paper investigates the extension to the conventional fuzzy classifiers for multi-class problems. We evaluate the performance of the multi-class online fuzzy classifiers through numerical experiments on synthetic dynamic data and also several benchmark datasets.",
      "authors": [
        "Kensuke Ajimoto",
        "Yuma Yamamoto",
        "Yoshifumi Kusunoki",
        "Tomoharu Nakashima"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 00:54:22+00:00",
      "link": "https://arxiv.org/pdf/2602.14375v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14374v1",
      "title": "Differentially Private Retrieval-Augmented Generation",
      "abstract": "Retrieval-augmented generation (RAG) is a widely used framework for reducing hallucinations in large language models (LLMs) on domain-specific tasks by retrieving relevant documents from a database to support accurate responses. However, when the database contains sensitive corpora, such as medical records or legal documents, RAG poses serious privacy risks by potentially exposing private information through its outputs. Prior work has demonstrated that one can practically craft adversarial prompts that force an LLM to regurgitate the augmented contexts. A promising direction is to integrate differential privacy (DP), a privacy notion that offers strong formal guarantees, into RAG systems. However, naively applying DP mechanisms into existing systems often leads to significant utility degradation. Particularly for RAG systems, DP can reduce the usefulness of the augmented contexts leading to increase risk of hallucination from the LLMs. Motivated by these challenges, we present DP-KSA, a novel privacy-preserving RAG algorithm that integrates DP using the propose-test-release paradigm. DP-KSA follows from a key observation that most question-answering (QA) queries can be sufficiently answered with a few keywords. Hence, DP-KSA first obtains an ensemble of relevant contexts, each of which will be used to generate a response from an LLM. We utilize these responses to obtain the most frequent keywords in a differentially private manner. Lastly, the keywords are augmented into the prompt for the final output. This approach effectively compresses the semantic space while preserving both utility and privacy. We formally show that DP-KSA provides formal DP guarantees on the generated output with respect to the RAG database. We evaluate DP-KSA on two QA benchmarks using three instruction-tuned LLMs, and our empirical results demonstrate that DP-KSA achieves a strong privacy-utility tradeoff.",
      "authors": [
        "Tingting Tang",
        "James Flemings",
        "Yongqin Wang",
        "Murali Annavaram"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-16 00:52:57+00:00",
      "link": "https://arxiv.org/pdf/2602.14374v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14372v1",
      "title": "Bitcoin Under Stress: Measuring Infrastructure Resilience 2014-2025",
      "abstract": "Bitcoin's design promises resilience through decentralization, yet physical infrastructure creates hidden dependencies. We present the first longitudinal study of Bitcoin's resilience to infrastructure failures using 11 years of P2P network data (2014-2025), 658 submarine cables, and 68 verified cable fault events. Using a Buldyrev-style cascade model with a country-level physical layer (225 countries, 354 submarine cable edges, 325 land border edges), we find that Bitcoin's clearnet percolation threshold $p_c \\approx 0.72$-$0.92$ for random cable failures, declining 22% from $p_c \\approx 0.92$ (2014-2017) to a minimum of $p_c = 0.72$ in 2021 during peak mining concentration. Targeted attacks reduce $p_c$ to 0.05-0.20. To address the 64% of nodes using Tor with unobservable locations, we develop a 4-layer multiplex model incorporating Tor relay infrastructure. Tor relay bandwidth concentrates in well-connected European countries, increasing resilience by $Δp_c \\approx +0.02$-$+0.10$ rather than introducing fragility. Empirical validation shows 87% of cable faults caused less than 5% node impact. We contribute: (1) a multiplex percolation framework for overlay-underlay coupling with a 4-layer Tor relay model; (2) the first empirical measurement of Bitcoin's physical-layer resilience over a decade; and (3) evidence that Tor adoption amplifies resilience with distributional bounds under partial observability.",
      "authors": [
        "Wenbin Wu",
        "Alexander Neumueller"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-02-16 00:46:55+00:00",
      "link": "https://arxiv.org/pdf/2602.14372v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14371v1",
      "title": "Diversity vs Degrees of Freedom in Gaussian Fading Channels",
      "abstract": "The standard definitions of degrees of freedom (DOF) and diversity both normalize by $\\logρ$. When this ruler is wrong, both measurements give zero or become undefined, yet intuitively DOF and diversity ought to be channel properties, not artifacts of a normalization choice. We formalize this for Gaussian fading channels. For fixed-$H$ MIMO, DOF and diversity are both ranks of the bilinear map~$HX$ with different variables free: $\\varepsilon$-covering the image of~$X\\!\\mapsto\\!HX$ gives DOF on the $\\logρ$ gauge; expanding across all dimensions of the fading map gives diversity on the linear~$ρ$ gauge. Covering produces logs; expansion produces linear growth; so in every model studied here the two gauges differ. These geometric definitions do not yield tradeoff curves. We bridge the gap with Bhattacharyya packing, obtaining gauge-DOF and B-diversity as workable proxies -- finite and informative on every gauge, including those where the classical diversity order is zero. Three gauge classes emerge: $\\logρ$, $\\log\\logρ$, and $(\\logρ)^β$, $β\\in(0,1)$. The main result is a cross-gauge tradeoff for noncoherent fast fading: capacity lives on $\\log\\logρ$, but B-diversity lives on $\\logρ$, exponentially larger, with matching upper and lower bounds. For coherent MIMO, block fading, and irregular-spectrum channels, the same approach recovers or extends known scaling laws.",
      "authors": [
        "Mahesh Godavarti"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-02-16 00:46:40+00:00",
      "link": "https://arxiv.org/pdf/2602.14371v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14370v1",
      "title": "Competition for attention predicts good-to-bad tipping in AI",
      "abstract": "More than half the global population now carries devices that can run ChatGPT-like language models with no Internet connection and minimal safety oversight -- and hence the potential to promote self-harm, financial losses and extremism among other dangers. Existing safety tools either require cloud connectivity or discover failures only after harm has occurred. Here we show that a large class of potentially dangerous tipping originates at the atomistic scale in such edge AI due to competition for the machinery's attention. This yields a mathematical formula for the dynamical tipping point n*, governed by dot-product competition for attention between the conversation's context and competing output basins, that reveals new control levers. Validated against multiple AI models, the mechanism can be instantiated for different definitions of 'good' and 'bad' and hence in principle applies across domains (e.g. health, law, finance, defense), changing legal landscapes (e.g. EU, UK, US and state level), languages, and cultural settings.",
      "authors": [
        "Neil F. Johnson",
        "Frank Y. Huo"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "physics.app-ph",
        "physics.soc-ph"
      ],
      "published": "2026-02-16 00:43:56+00:00",
      "link": "https://arxiv.org/pdf/2602.14370v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14367v1",
      "title": "InnoEval: On Research Idea Evaluation as a Knowledge-Grounded, Multi-Perspective Reasoning Problem",
      "abstract": "The rapid evolution of Large Language Models has catalyzed a surge in scientific idea production, yet this leap has not been accompanied by a matching advance in idea evaluation. The fundamental nature of scientific evaluation needs knowledgeable grounding, collective deliberation, and multi-criteria decision-making. However, existing idea evaluation methods often suffer from narrow knowledge horizons, flattened evaluation dimensions, and the inherent bias in LLM-as-a-Judge. To address these, we regard idea evaluation as a knowledge-grounded, multi-perspective reasoning problem and introduce InnoEval, a deep innovation evaluation framework designed to emulate human-level idea assessment. We apply a heterogeneous deep knowledge search engine that retrieves and grounds dynamic evidence from diverse online sources. We further achieve review consensus with an innovation review board containing reviewers with distinct academic backgrounds, enabling a multi-dimensional decoupled evaluation across multiple metrics. We construct comprehensive datasets derived from authoritative peer-reviewed submissions to benchmark InnoEval. Experiments demonstrate that InnoEval can consistently outperform baselines in point-wise, pair-wise, and group-wise evaluation tasks, exhibiting judgment patterns and consensus highly aligned with human experts.",
      "authors": [
        "Shuofei Qiao",
        "Yunxiang Wei",
        "Xuehai Wang",
        "Bin Wu",
        "Boyang Xue",
        "Ningyu Zhang",
        "Hossein A. Rahmani",
        "Yanshan Wang",
        "Qiang Zhang",
        "Keyan Ding",
        "Jeff Z. Pan",
        "Huajun Chen",
        "Emine Yilmaz"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2026-02-16 00:40:31+00:00",
      "link": "https://arxiv.org/pdf/2602.14367v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14365v1",
      "title": "Image-based Joint-level Detection for Inflammation in Rheumatoid Arthritis from Small and Imbalanced Data",
      "abstract": "Rheumatoid arthritis (RA) is an autoimmune disease characterized by systemic joint inflammation. Early diagnosis and tight follow-up are essential to the management of RA, as ongoing inflammation can cause irreversible joint damage. The detection of arthritis is important for diagnosis and assessment of disease activity; however, it often takes a long time for patients to receive appropriate specialist care. Therefore, there is a strong need to develop systems that can detect joint inflammation easily using RGB images captured at home. Consequently, we tackle the task of RA inflammation detection from RGB hand images. This task is highly challenging due to general issues in medical imaging, such as the scarcity of positive samples, data imbalance, and the inherent difficulty of the task itself. However, to the best of our knowledge, no existing work has explicitly addressed these challenges in RGB-based RA inflammation detection. This paper quantitatively demonstrates the difficulty of visually detecting inflammation by constructing a dedicated dataset, and we propose a inflammation detection framework with global local encoder that combines self-supervised pretraining on large-scale healthy hand images with imbalance-aware training to detect RA-related joint inflammation from RGB hand images. Our experiments demonstrated that the proposed approach improves F1-score by 0.2 points and Gmean by 0.25 points compared with the baseline model.",
      "authors": [
        "Shun Kato",
        "Yasushi Kondo",
        "Shuntaro Saito",
        "Yoshimitsu Aoki",
        "Mariko Isogawa"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-16 00:33:52+00:00",
      "link": "https://arxiv.org/pdf/2602.14365v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14364v1",
      "title": "A Trajectory-Based Safety Audit of Clawdbot (OpenClaw)",
      "abstract": "Clawdbot is a self-hosted, tool-using personal AI agent with a broad action space spanning local execution and web-mediated workflows, which raises heightened safety and security concerns under ambiguity and adversarial steering. We present a trajectory-centric evaluation of Clawdbot across six risk dimensions. Our test suite samples and lightly adapts scenarios from prior agent-safety benchmarks (including ATBench and LPS-Bench) and supplements them with hand-designed cases tailored to Clawdbot's tool surface. We log complete interaction trajectories (messages, actions, tool-call arguments/outputs) and assess safety using both an automated trajectory judge (AgentDoG-Qwen3-4B) and human review. Across 34 canonical cases, we find a non-uniform safety profile: performance is generally consistent on reliability-focused tasks, while most failures arise under underspecified intent, open-ended goals, or benign-seeming jailbreak prompts, where minor misinterpretations can escalate into higher-impact tool actions. We supplemented the overall results with representative case studies and summarized the commonalities of these cases, analyzing the security vulnerabilities and typical failure modes that Clawdbot is prone to trigger in practice.",
      "authors": [
        "Tianyu Chen",
        "Dongrui Liu",
        "Xia Hu",
        "Jingyi Yu",
        "Wenjie Wang"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "published": "2026-02-16 00:33:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14364v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14363v1",
      "title": "AdaptManip: Learning Adaptive Whole-Body Object Lifting and Delivery with Online Recurrent State Estimation",
      "abstract": "This paper presents Adaptive Whole-body Loco-Manipulation, AdaptManip, a fully autonomous framework for humanoid robots to perform integrated navigation, object lifting, and delivery. Unlike prior imitation learning-based approaches that rely on human demonstrations and are often brittle to disturbances, AdaptManip aims to train a robust loco-manipulation policy via reinforcement learning without human demonstrations or teleoperation data. The proposed framework consists of three coupled components: (1) a recurrent object state estimator that tracks the manipulated object in real time under limited field-of-view and occlusions; (2) a whole-body base policy for robust locomotion with residual manipulation control for stable object lifting and delivery; and (3) a LiDAR-based robot global position estimator that provides drift-robust localization. All components are trained in simulation using reinforcement learning and deployed on real hardware in a zero-shot manner. Experimental results show that AdaptManip significantly outperforms baseline methods, including imitation learning-based approaches, in adaptability and overall success rate, while accurate object state estimation improves manipulation performance even under occlusion. We further demonstrate fully autonomous real-world navigation, object lifting, and delivery on a humanoid robot.",
      "authors": [
        "Morgan Byrd",
        "Donghoon Baek",
        "Kartik Garg",
        "Hyunyoung Jung",
        "Daesol Cho",
        "Maks Sorokin",
        "Robert Wright",
        "Sehoon Ha"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "published": "2026-02-16 00:29:53+00:00",
      "link": "https://arxiv.org/pdf/2602.14363v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14360v1",
      "title": "LiSFC-Search: Lifelong Search for Network SFC Optimization under Non-stationary Drifts",
      "abstract": "Edge-cloud convergence is reshaping service provisioning across 5G/6G and computing power networks (CPNs). Service function chaining (SFC) requires continuously placing and scheduling virtual network functions (VNFs) chains under compute/bandwidth and end-to-end QoS constraints. Most SFC optimizers assume static or stationary networks, and degrade under long-term topology/resource changes (failures, upgrades, expansions) that induce non-stationary graph drifts. We propose LiSFC, a Lipschitz lifelong planner that transfers MCTS statistics across drifting network configurations using an MDP-distance bound. More precisely, we formulate the problem as a sequence of MDPs indexed by the underlying network graph and constraints, and we define a \\emph{graph drift} metric that upper-bounds the LiZero MDP distance. This allows LiSFC to import theoretical guarantees on bias and sample efficiency from the LiZero framework while being tailored to cloud-network convergence. We then design \\emph{LiSFC-Search}, an SFC-aware unified MCTS (UMCTS) procedure that uses transferable adaptive UCT (aUCT) bonuses to reuse search statistics from prior CPN configurations. Preliminary results on synthetic CPN topologies and SFC workloads show that LiSFC consistently reduces SFC blocking probability and improves tail delay compared to non-transfer MCTS and purely learning-based baselines, highlighting its potential as an AI/ML building block for cloud-network convergence.",
      "authors": [
        "Zuyuan Zhang",
        "Vaneet Aggarwal",
        "Tian Lan"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-02-16 00:25:11+00:00",
      "link": "https://arxiv.org/pdf/2602.14360v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14358v1",
      "title": "High Precision Audience Expansion via Extreme Classification in a Two-Sided Marketplace",
      "abstract": "Airbnb search must balance a worldwide, highly varied supply of homes with guests whose location, amenity, style, and price expectations differ widely. Meeting those expectations hinges on an efficient retrieval stage that surfaces only the listings a guest might realistically book, before resource intensive ranking models are applied to determine the best results. Unlike many recommendation engines, our system faces a distinctive challenge, location retrieval, that sits upstream of ranking and determines which geographic areas are queried in order to filter inventory to a candidate set. The preexisting approach employs a deep bayesian bandit based system to predict a rectangular retrieval bounds area that can be used for filtering. The purpose of this paper is to demonstrate the methodology, challenges, and impact of rearchitecting search to retrieve from the subset of most bookable high precision rectangular map cells defined by dividing the world into 25M uniform cells.",
      "authors": [
        "Dillon Davis",
        "Huiji Gao",
        "Thomas Legrand",
        "Juan Manuel Caicedo Carvajal",
        "Malay Haldar",
        "Kedar Bellare",
        "Moutupsi Paul",
        "Soumyadip Banerjee",
        "Liwei He",
        "Stephanie Moyerman",
        "Sanjeev Katariya"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-16 00:23:38+00:00",
      "link": "https://arxiv.org/pdf/2602.14358v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14357v1",
      "title": "Key Considerations for Domain Expert Involvement in LLM Design and Evaluation: An Ethnographic Study",
      "abstract": "Large Language Models (LLMs) are increasingly developed for use in complex professional domains, yet little is known about how teams design and evaluate these systems in practice. This paper examines the challenges and trade-offs in LLM development through a 12-week ethnographic study of a team building a pedagogical chatbot. The researcher observed design and evaluation activities and conducted interviews with both developers and domain experts. Analysis revealed four key practices: creating workarounds for data collection, turning to augmentation when expert input was limited, co-developing evaluation criteria with experts, and adopting hybrid expert-developer-LLM evaluation strategies. These practices show how teams made strategic decisions under constraints and demonstrate the central role of domain expertise in shaping the system. Challenges included expert motivation and trust, difficulties structuring participatory design, and questions around ownership and integration of expert knowledge. We propose design opportunities for future LLM development workflows that emphasize AI literacy, transparent consent, and frameworks recognizing evolving expert roles.",
      "authors": [
        "Annalisa Szymanski",
        "Oghenemaro Anuyah",
        "Toby Jia-Jun Li",
        "Ronald A. Metoyer"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "published": "2026-02-16 00:21:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14357v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14356v1",
      "title": "A Generative AI Approach for Reducing Skin Tone Bias in Skin Cancer Classification",
      "abstract": "Skin cancer is one of the most common cancers worldwide and early detection is critical for effective treatment. However, current AI diagnostic tools are often trained on datasets dominated by lighter skin tones, leading to reduced accuracy and fairness for people with darker skin. The International Skin Imaging Collaboration (ISIC) dataset, one of the most widely used benchmarks, contains over 70% light skin images while dark skins fewer than 8%. This imbalance poses a significant barrier to equitable healthcare delivery and highlights the urgent need for methods that address demographic diversity in medical imaging. This paper addresses this challenge of skin tone imbalance in automated skin cancer detection using dermoscopic images. To overcome this, we present a generative augmentation pipeline that fine-tunes a pre-trained Stable Diffusion model using Low-Rank Adaptation (LoRA) on the image dark-skin subset of the ISIC dataset and generates synthetic dermoscopic images conditioned on lesion type and skin tone. In this study, we investigated the utility of these images on two downstream tasks: lesion segmentation and binary classification. For segmentation, models trained on the augmented dataset and evaluated on held-out real images show consistent improvements in IoU, Dice coefficient, and boundary accuracy. These evalutions provides the verification of Generated dataset. For classification, an EfficientNet-B0 model trained on the augmented dataset achieved 92.14% accuracy. This paper demonstrates that synthetic data augmentation with Generative AI integration can substantially reduce bias with increase fairness in conventional dermatological diagnostics and open challenges for future directions.",
      "authors": [
        "Areez Muhammed Shabu",
        "Mohammad Samar Ansari",
        "Asra Aslam"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 00:20:56+00:00",
      "link": "https://arxiv.org/pdf/2602.14356v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14352v1",
      "title": "Bridging the Urban Divide: Adaptive Cross-City Learning for Disaster Sentiment Understanding",
      "abstract": "Social media platforms provide a real-time lens into public sentiment during natural disasters; however, models built solely on textual data often reinforce urban-centric biases and overlook underrepresented communities. This paper introduces an adaptive cross-city learning framework that enhances disaster sentiment understanding by integrating mobility-informed behavioral signals and city similarity-based data augmentation. Focusing on the January 2025 Southern California wildfires, our model achieves state-of-the-art performance and reveals geographically diverse sentiment patterns, particularly in areas experiencing overlapping fire exposure or delayed emergency responses. We further identify positive correlations between emotional expressions and real-world mobility shifts, underscoring the value of combining behavioral and textual features. Through extensive experiments, we demonstrate that multimodal fusion and city-aware training significantly improve both accuracy and fairness. Collectively, these findings highlight the importance of context-sensitive sentiment modeling and provide actionable insights toward developing more inclusive and equitable disaster response systems.",
      "authors": [
        "Zihui Ma",
        "Yiheng Chen",
        "Runlong Yu",
        "Afra Izzati Kamili",
        "Fangqi Chen",
        "Zhaoxi Zhang",
        "Juan Li",
        "Yuki Miura"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI"
      ],
      "published": "2026-02-15 23:55:45+00:00",
      "link": "https://arxiv.org/pdf/2602.14352v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14351v1",
      "title": "WIMLE: Uncertainty-Aware World Models with IMLE for Sample-Efficient Continuous Control",
      "abstract": "Model-based reinforcement learning promises strong sample efficiency but often underperforms in practice due to compounding model error, unimodal world models that average over multi-modal dynamics, and overconfident predictions that bias learning. We introduce WIMLE, a model-based method that extends Implicit Maximum Likelihood Estimation (IMLE) to the model-based RL framework to learn stochastic, multi-modal world models without iterative sampling and to estimate predictive uncertainty via ensembles and latent sampling. During training, WIMLE weights each synthetic transition by its predicted confidence, preserving useful model rollouts while attenuating bias from uncertain predictions and enabling stable learning. Across $40$ continuous-control tasks spanning DeepMind Control, MyoSuite, and HumanoidBench, WIMLE achieves superior sample efficiency and competitive or better asymptotic performance than strong model-free and model-based baselines. Notably, on the challenging Humanoid-run task, WIMLE improves sample efficiency by over $50$\\% relative to the strongest competitor, and on HumanoidBench it solves $8$ of $14$ tasks (versus $4$ for BRO and $5$ for SimbaV2). These results highlight the value of IMLE-based multi-modality and uncertainty-aware weighting for stable model-based RL.",
      "authors": [
        "Mehran Aghabozorgi",
        "Alireza Moazeni",
        "Yanshu Zhang",
        "Ke Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 23:53:16+00:00",
      "link": "https://arxiv.org/pdf/2602.14351v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14345v1",
      "title": "AXE: An Agentic eXploit Engine for Confirming Zero-Day Vulnerability Reports",
      "abstract": "Vulnerability detection tools are widely adopted in software projects, yet they often overwhelm maintainers with false positives and non-actionable reports. Automated exploitation systems can help validate these reports; however, existing approaches typically operate in isolation from detection pipelines, failing to leverage readily available metadata such as vulnerability type and source-code location. In this paper, we investigate how reported security vulnerabilities can be assessed in a realistic grey-box exploitation setting that leverages minimal vulnerability metadata, specifically a CWE classification and a vulnerable code location. We introduce Agentic eXploit Engine (AXE), a multi-agent framework for Web application exploitation that maps lightweight detection metadata to concrete exploits through decoupled planning, code exploration, and dynamic execution feedback. Evaluated on the CVE-Bench dataset, AXE achieves a 30% exploitation success rate, a 3x improvement over state-of-the-art black-box baselines. Even in a single-agent configuration, grey-box metadata yields a 1.75x performance gain. Systematic error analysis shows that most failed attempts arise from specific reasoning gaps, including misinterpreted vulnerability semantics and unmet execution preconditions. For successful exploits, AXE produces actionable, reproducible proof-of-concept artifacts, demonstrating its utility in streamlining Web vulnerability triage and remediation. We further evaluate AXE's generalizability through a case study on a recent real-world vulnerability not included in CVE-Bench.",
      "authors": [
        "Amirali Sajadi",
        "Tu Nguyen",
        "Kostadin Damevski",
        "Preetha Chatterjee"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "published": "2026-02-15 23:25:14+00:00",
      "link": "https://arxiv.org/pdf/2602.14345v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14344v1",
      "title": "Zero-Shot Instruction Following in RL via Structured LTL Representations",
      "abstract": "We study instruction following in multi-task reinforcement learning, where an agent must zero-shot execute novel tasks not seen during training. In this setting, linear temporal logic (LTL) has recently been adopted as a powerful framework for specifying structured, temporally extended tasks. While existing approaches successfully train generalist policies, they often struggle to effectively capture the rich logical and temporal structure inherent in LTL specifications. In this work, we address these concerns with a novel approach to learn structured task representations that facilitate training and generalisation. Our method conditions the policy on sequences of Boolean formulae constructed from a finite automaton of the task. We propose a hierarchical neural architecture to encode the logical structure of these formulae, and introduce an attention mechanism that enables the policy to reason about future subgoals. Experiments in a variety of complex environments demonstrate the strong generalisation capabilities and superior performance of our approach.",
      "authors": [
        "Mathias Jackermeier",
        "Mattia Giuri",
        "Jacques Cloete",
        "Alessandro Abate"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 23:22:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14344v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14342v1",
      "title": "High-accuracy log-concave sampling with stochastic queries",
      "abstract": "We show that high-accuracy guarantees for log-concave sampling -- that is, iteration and query complexities which scale as $\\mathrm{poly}\\log(1/δ)$, where $δ$ is the desired target accuracy -- are achievable using stochastic gradients with subexponential tails. Notably, this exhibits a separation with the problem of convex optimization, where stochasticity (even additive Gaussian noise) in the gradient oracle incurs $\\mathrm{poly}(1/δ)$ queries. We also give an information-theoretic argument that light-tailed stochastic gradients are necessary for high accuracy: for example, in the bounded variance case, we show that the minimax-optimal query complexity scales as $Θ(1/δ)$. Our framework also provides similar high accuracy guarantees under stochastic zeroth order (value) queries.",
      "authors": [
        "Fan Chen",
        "Sinho Chewi",
        "Constantinos Daskalakis",
        "Alexander Rakhlin"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.DS",
        "cs.LG",
        "math.PR"
      ],
      "published": "2026-02-15 23:19:07+00:00",
      "link": "https://arxiv.org/pdf/2602.14342v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14338v1",
      "title": "Train Less, Learn More: Adaptive Efficient Rollout Optimization for Group-Based Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) plays a central role in large language model (LLM) post-training. Among existing approaches, Group Relative Policy Optimization (GRPO) is widely used, especially for RL with verifiable rewards (RLVR) fine-tuning. In GRPO, each query prompts the LLM to generate a group of rollouts with a fixed group size $N$. When all rollouts in a group share the same outcome, either all correct or all incorrect, the group-normalized advantages become zero, yielding no gradient signal and wasting fine-tuning compute. We introduce Adaptive Efficient Rollout Optimization (AERO), an enhancement of GRPO. AERO uses an adaptive rollout strategy, applies selective rejection to strategically prune rollouts, and maintains a Bayesian posterior to prevent zero-advantage dead zones. Across three model configurations (Qwen2.5-Math-1.5B, Qwen2.5-7B, and Qwen2.5-7B-Instruct), AERO improves compute efficiency without sacrificing performance. Under the same total rollout budget, AERO reduces total training compute by about 48% while shortening wall-clock time per step by about 45% on average. Despite the substantial reduction in compute, AERO matches or improves Pass@8 and Avg@8 over GRPO, demonstrating a practical, scalable, and compute-efficient strategy for RL-based LLM alignment.",
      "authors": [
        "Zhi Zhang",
        "Zhen Han",
        "Costas Mavromatis",
        "Qi Zhu",
        "Yunyi Zhang",
        "Sheng Guan",
        "Dingmin Wang",
        "Xiong Zhou",
        "Shuai Wang",
        "Soji Adeshina",
        "Vassilis Ioannidis",
        "Huzefa Rangwala"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 23:14:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14338v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14337v1",
      "title": "LongCLI-Bench: A Preliminary Benchmark and Study for Long-horizon Agentic Programming in Command-Line Interfaces",
      "abstract": "Recent advances in AI-assisted programming have empowered agents to execute complex workflows via command-line interfaces, however, existing benchmarks are limited by short task horizons, data contamination from GitHub scraping, and a lack of fine-grained evaluation metrics, fail to rigorously evaluate the long-horizon planning and execution capabilities essential for realistic software engineering. To address these gaps, we introduce LongCLI-Bench, a comprehensive benchmark designed to evaluate agentic capabilities across long-horizon, realistic tasks. We curated 20 high-quality, long-horizon tasks from over 1,000 computer science assignments and real-world workflows, covering four engineering categories: from scratch, feature addition, bug fixing, and refactoring. We propose a dual-set testing protocol for LongCLI-Bench, which measures requirement fulfillment (fail-to-pass) and regression avoidance (pass-to-pass), and incorporates step-level scoring to pinpoint execution failures. Extensive experiments reveal that even state-of-the-art agents achieve pass rates below 20% in LongCLI-Bench. Step-level analysis further indicates that the majority of tasks stall at less than 30% completion, highlighting that critical failures often occur in the early stages. Although self-correction offers marginal gains, human-agent collaboration through plan injection and interactive guidance yields significantly higher improvements. These results highlight that future research must emphasize the development of synergistic human-agent workflows alongside advances in agents' planning and execution capabilities to overcome key challenges in long-horizon task performance.",
      "authors": [
        "Yukang Feng",
        "Jianwen Sun",
        "Zelai Yang",
        "Jiaxin Ai",
        "Chuanhao Li",
        "Zizhen Li",
        "Fanrui Zhang",
        "Kang He",
        "Rui Ma",
        "Jifan Lin",
        "Jie Sun",
        "Yang Xiao",
        "Sizhuo Zhou",
        "Wenxiao Wu",
        "Yiming Liu",
        "Pengfei Liu",
        "Yu Qiao",
        "Shenglin Zhang",
        "Kaipeng Zhang"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.MA"
      ],
      "published": "2026-02-15 23:12:57+00:00",
      "link": "https://arxiv.org/pdf/2602.14337v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14335v1",
      "title": "Predicting New Concept-Object Associations in Astronomy by Mining the Literature",
      "abstract": "We construct a concept-object knowledge graph from the full astro-ph corpus through July 2025. Using an automated pipeline, we extract named astrophysical objects from OCR-processed papers, resolve them to SIMBAD identifiers, and link them to scientific concepts annotated in the source corpus. We then test whether historical graph structure can forecast new concept-object associations before they appear in print. Because the concepts are derived from clustering and therefore overlap semantically, we apply an inference-time concept-similarity smoothing step uniformly to all methods. Across four temporal cutoffs on a physically meaningful subset of concepts, an implicit-feedback matrix factorization model (alternating least squares, ALS) with smoothing outperforms the strongest neighborhood baseline (KNN using text-embedding concept similarity) by 16.8% on NDCG@100 (0.144 vs 0.123) and 19.8% on Recall@100 (0.175 vs 0.146), and exceeds the best recency heuristic by 96% and 88%, respectively. These results indicate that historical literature encodes predictive structure not captured by global heuristics or local neighborhood voting, suggesting a path toward tools that could help triage follow-up targets for scarce telescope time.",
      "authors": [
        "Jinchu Li",
        "Yuan-Sen Ting",
        "Alberto Accomazzi",
        "Tirthankar Ghosal",
        "Nesar Ramachandra"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "cs.IR"
      ],
      "published": "2026-02-15 23:07:10+00:00",
      "link": "https://arxiv.org/pdf/2602.14335v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14331v1",
      "title": "A Bayesian Framework for Human-AI Collaboration: Complementarity and Correlation Neglect",
      "abstract": "We develop a decision-theoretic model of human-AI interaction to study when AI assistance improves or impairs human decision-making. A human decision-maker observes private information and receives a recommendation from an AI system, but may combine these signals imperfectly. We show that the effect of AI assistance decomposes into two main forces: the marginal informational value of the AI beyond what the human already knows, and a behavioral distortion arising from how the human uses the AI's recommendation. Central to our analysis is a micro-founded measure of informational overlap between human and AI knowledge. We study an empirically relevant form of imperfect decision-making -- correlation neglect -- whereby humans treat AI recommendations as independent of their own information despite shared evidence. Under this model, we characterize how overlap and AI capabilities shape the Human-AI interaction regime between augmentation, impairment, complementarity, and automation, and draw key insights.",
      "authors": [
        "Saurabh Amin",
        "Amine Bennouna",
        "Daniel Huttenlocher",
        "Dingwen Kong",
        "Liang Lyu",
        "Asuman Ozdaglar"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT",
        "cs.HC",
        "econ.TH"
      ],
      "published": "2026-02-15 22:57:08+00:00",
      "link": "https://arxiv.org/pdf/2602.14331v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14329v1",
      "title": "Simpler Than You Think: The Practical Dynamics of Ranked Choice Voting",
      "abstract": "Ranked Choice Voting (RCV) adoption is expanding across U.S. elections, but faces persistent criticism for complexity, strategic manipulation, and ballot exhaustion. We empirically test these concerns on real election data, across three diverse contexts: New York City's 2021 Democratic primaries (54 races), Alaska's 2024 primary-infused statewide elections (52 races), and Portland's 2024 multi-winner City Council elections (4 races). Our algorithmic approach circumvents computational complexity barriers by reducing election instance sizes (via candidate elimination).   Our findings reveal that despite its intricate multi-round process and theoretical vulnerabilities, RCV consistently exhibits simple and transparent dynamics in practice, closely mirroring the interpretability of plurality elections. Following RCV adoption, competitiveness increased substantially compared to prior plurality elections, with average margins of victory declining by 9.2 percentage points in NYC and 11.4 points in Alaska. Empirically, complex ballot-addition strategies are not more efficient than simple ones, and ballot exhaustion has minimal impact, altering outcomes in only 3 of 110 elections. These findings demonstrate that RCV delivers measurable democratic benefits while proving robust to ballot-addition manipulation, resilient to ballot exhaustion effects, and maintaining transparent competitive dynamics in practice. The computational framework offers election administrators and researchers tools for immediate election-night analysis and facilitating clearer discourse around election dynamics.",
      "authors": [
        "Sanyukta Deshpande",
        "Nikhil Garg",
        "Sheldon H. Jacobson"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "published": "2026-02-15 22:51:59+00:00",
      "link": "https://arxiv.org/pdf/2602.14329v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14326v1",
      "title": "Sublinear-Time Lower Bounds for Approximating Matching Size using Non-Adaptive Queries",
      "abstract": "We study the problem of estimating the size of the maximum matching in the sublinear-time setting. This problem has been extensively studied, with several known upper and lower bounds. A notable result by Behnezhad (FOCS 2021) established a 2-approximation in ~O(n) time.   However, all known upper and lower bounds are in the adaptive query model, where each query can depend on previous answers. In contrast, non-adaptive query models-where the distribution over all queries must be fixed in advance-are widely studied in property testing, often revealing fundamental gaps between adaptive and non-adaptive complexities. This raises the natural question: is adaptivity also necessary for approximating the maximum matching size in sublinear time? This motivates the goal of achieving a constant or even a polylogarithmic approximation using ~O(n) non-adaptive adjacency list queries, similar to what was done by Behnezhad using adaptive queries.   We show that this is not possible by proving that any randomized non-adaptive algorithm achieving an n^{1/3 - gamma}-approximation, for any constant gamma > 0, with probability at least 2/3, must make Omega(n^{1 + eps}) adjacency list queries, for some constant eps > 0 depending on gamma. This result highlights the necessity of adaptivity in achieving strong approximations. However, non-trivial upper bounds are still achievable: we present a simple randomized algorithm that achieves an n^{1/2}-approximation in O(n log^2 n) queries.   Moreover, our lower bound also extends to the newly defined variant of the non-adaptive model, where queries are issued according to a fixed query tree, introduced by Azarmehr, Behnezhad, Ghafari, and Sudan (FOCS 2025) in the context of Local Computation Algorithms.",
      "authors": [
        "Vihan Shah"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-02-15 22:36:23+00:00",
      "link": "https://arxiv.org/pdf/2602.14326v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15904v1",
      "title": "A Comprehensive Survey on Deep Learning-Based LiDAR Super-Resolution for Autonomous Driving",
      "abstract": "LiDAR sensors are often considered essential for autonomous driving, but high-resolution sensors remain expensive while affordable low-resolution sensors produce sparse point clouds that miss critical details. LiDAR super-resolution addresses this challenge by using deep learning to enhance sparse point clouds, bridging the gap between different sensor types and enabling cross-sensor compatibility in real-world deployments. This paper presents the first comprehensive survey of LiDAR super-resolution methods for autonomous driving. Despite the importance of practical deployment, no systematic review has been conducted until now. We organize existing approaches into four categories: CNN-based architectures, model-based deep unrolling, implicit representation methods, and Transformer and Mamba-based approaches. We establish fundamental concepts including data representations, problem formulation, benchmark datasets and evaluation metrics. Current trends include the adoption of range image representation for efficient processing, extreme model compression and the development of resolution-flexible architectures. Recent research prioritizes real-time inference and cross-sensor generalization for practical deployment. We conclude by identifying open challenges and future research directions for advancing LiDAR super-resolution technology.",
      "authors": [
        "June Moh Goo",
        "Zichao Zeng",
        "Jan Boehm"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "published": "2026-02-15 22:34:28+00:00",
      "link": "https://arxiv.org/pdf/2602.15904v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14322v1",
      "title": "Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study",
      "abstract": "We investigate how formal temporal logic specifications can enhance the safety and robustness of reinforcement learning (RL) control in aerospace applications. Using the open source AeroBench F-16 simulation benchmark, we train a Proximal Policy Optimization (PPO) agent to regulate engine throttle and track commanded airspeed. The control objective is encoded as a Signal Temporal Logic (STL) requirement to maintain airspeed within a prescribed band during the final seconds of each maneuver. To enforce this specification at run time, we introduce a conformal STL shield that filters the RL agent's actions using online conformal prediction. We compare three settings: (i) PPO baseline, (ii) PPO with a classical rule-based STL shield, and (iii) PPO with the proposed conformal shield, under both nominal conditions and a severe stress scenario involving aerodynamic model mismatch, actuator rate limits, measurement noise, and mid-episode setpoint jumps. Experiments show that the conformal shield preserves STL satisfaction while maintaining near baseline performance and providing stronger robustness guarantees than the classical shield. These results demonstrate that combining formal specification monitoring with data driven RL control can substantially improve the reliability of autonomous flight control in challenging environments.",
      "authors": [
        "Hani Beirami",
        "M M Manjurul Islam"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.LO"
      ],
      "published": "2026-02-15 22:10:11+00:00",
      "link": "https://arxiv.org/pdf/2602.14322v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14321v1",
      "title": "Offline Learning of Nash Stable Coalition Structures with Possibly Overlapping Coalitions",
      "abstract": "Coalition formation concerns strategic collaborations of selfish agents that form coalitions based on their preferences. It is often assumed that coalitions are disjoint and preferences are fully known, which may not hold in practice. In this paper, we thus present a new model of coalition formation with possibly overlapping coalitions under partial information, where selfish agents may be part of multiple coalitions simultaneously and their full preferences are initially unknown. Instead, information about past interactions and associated utility feedback is stored in a fixed offline dataset, and we aim to efficiently infer the agents' preferences from this dataset. We analyze the impact of diverse dataset information constraints by studying two types of utility feedback that can be stored in the dataset: agent- and coalition-level utility feedback. For both feedback models, we identify assumptions under which the dataset covers sufficient information for an offline learning algorithm to infer preferences and use them to recover a partition that is (approximately) Nash stable, in which no agent can improve her utility by unilaterally deviating. Our additional goal is devising algorithms with low sample complexity, requiring only a small dataset to obtain a desired approximation to Nash stability. Under agent-level feedback, we provide a sample-efficient algorithm proven to obtain an approximately Nash stable partition under a sufficient and necessary assumption on the information covered by the dataset. However, under coalition-level feedback, we show that only under a stricter assumption is sufficient for sample-efficient learning. Still, in multiple cases, our algorithms' sample complexity bounds have optimality guarantees up to logarithmic factors. Finally, extensive experiments show that our algorithm converges to a low approximation level to Nash stability across diverse settings.",
      "authors": [
        "Saar Cohen"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-02-15 22:05:12+00:00",
      "link": "https://arxiv.org/pdf/2602.14321v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14320v2",
      "title": "Catalytic Tree Evaluation From Matching Vectors",
      "abstract": "We give new algorithms for tree evaluation (S. Cook et al. TOCT 2012) in the catalytic-computing model (Buhrman et al. STOC 2014). Two existing approaches aim to solve tree evaluation in low space: on the one hand, J. Cook and Mertz (STOC 2024) give an algorithm for TreeEval running in super-logarithmic space $O(\\log n\\log\\log n)$ and super-polynomial time $n^{O(\\log\\log n)}$. On the other hand, a simple reduction from TreeEval to circuit evaluation, combined with the result of Buhrman et al. (STOC 2014), gives a catalytic algorithm for TreeEval running in logarithmic $O(\\log n)$ free space and polynomial time, but with polynomial catalytic space.   We show that the latter result can be improved. We give a catalytic algorithm for TreeEval with logarithmic $O(\\log n)$ free space, polynomial runtime, and subpolynomial $2^{\\log^εn}$ catalytic space (for any $ε> 0$). Our result opens a new line of attack on putting TreeEval in logspace, and immediately implies an improved simulation of time by catalytic space, by the reduction of Williams (STOC 2025).   Our catalytic TreeEval algorithm is inspired by a connection to matching-vector families and private information retrieval, and improved constructions of (uniform) matching-vector families would imply improvements to our algorithm.",
      "authors": [
        "Alexandra Henzinger",
        "Edward Pyne",
        "Seyoon Ragavan"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-02-15 22:04:34+00:00",
      "link": "https://arxiv.org/pdf/2602.14320v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14318v1",
      "title": "In Transformer We Trust? A Perspective on Transformer Architecture Failure Modes",
      "abstract": "Transformer architectures have revolutionized machine learning across a wide range of domains, from natural language processing to scientific computing. However, their growing deployment in high-stakes applications, such as computer vision, natural language processing, healthcare, autonomous systems, and critical areas of scientific computing including climate modeling, materials discovery, drug discovery, nuclear science, and robotics, necessitates a deeper and more rigorous understanding of their trustworthiness. In this work, we critically examine the foundational question: \\textitHow trustworthy are transformer models?} We evaluate their reliability through a comprehensive review of interpretability, explainability, robustness against adversarial attacks, fairness, and privacy. We systematically examine the trustworthiness of transformer-based models in safety-critical applications spanning natural language processing, computer vision, and science and engineering domains, including robotics, medicine, earth sciences, materials science, fluid dynamics, nuclear science, and automated theorem proving; highlighting high-impact areas where these architectures are central and analyzing the risks associated with their deployment. By synthesizing insights across these diverse areas, we identify recurring structural vulnerabilities, domain-specific risks, and open research challenges that limit the reliable deployment of transformers.",
      "authors": [
        "Trishit Mondal",
        "Ameya D. Jagtap"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-15 21:57:14+00:00",
      "link": "https://arxiv.org/pdf/2602.14318v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14313v1",
      "title": "The Baby Steps of the European Union Vulnerability Database: An Empirical Inquiry",
      "abstract": "A new European Union Vulnerability Database (EUVD) was introduced via a legislative act in 2022. The paper examines empirically the meta-data content of the new EUVD. According to the results, actively exploited vulnerabilities archived to the EUVD have been rather severe, having had also high exploitation prediction scores. In both respects they have also surpassed vulnerabilities coordinated by European public authorities. Regarding the European authorities, the Spanish public authority has been particularly active. With the exceptions of Finland, Poland, and Slovakia, other authorities have not engaged thus far. Also the involvement of the European Union's own cyber security agency has been limited. These points notwithstanding, European coordination and archiving to the EUVD exhibit a strong growth trend. With these results, the paper makes an empirical contribution to the ongoing work for better understanding European cyber security governance and practice.",
      "authors": [
        "Jukka Ruohonen"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.CY"
      ],
      "published": "2026-02-15 21:18:17+00:00",
      "link": "https://arxiv.org/pdf/2602.14313v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14311v1",
      "title": "Exploiting Structure-from-Motion for Robust Vision-Based Map Matching for Aircraft Surface Movement",
      "abstract": "In this paper we introduce a vision-aided navigation (VAN) pipeline designed to support ground navigation of autonomous aircraft. The proposed algorithm combines the computational efficiency of indirect methods with the robustness of direct image-based techniques to enhance solution integrity. The pipeline starts by processing ground images (e.g., acquired by a taxiing aircraft) and relates them via a feature-based structure-from-motion (SfM) solution. A ground plane mosaic is then constructed via homography transforms and matched to satellite imagery using a sum of squares differences (SSD) of intensities. Experimental results reveal that drift within the SfM solution, similar to that observed in dead-reckoning systems, challenges the expected accuracy benefits of map-matching with a wide-baseline ground-plane mosaic. However, the proposed algorithm demonstrates key integrity features, such as the ability to identify registration anomalies and ambiguous matches. These characteristics of the pipeline can mitigate outlier behaviors and contribute toward a robust, certifiable solution for autonomous surface movement of aircraft.",
      "authors": [
        "Daniel Choate",
        "Jason Rife"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-15 21:08:48+00:00",
      "link": "https://arxiv.org/pdf/2602.14311v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14307v1",
      "title": "Benchmarking at the Edge of Comprehension",
      "abstract": "As frontier Large Language Models (LLMs) increasingly saturate new benchmarks shortly after they are published, benchmarking itself is at a juncture: if frontier models keep improving, it will become increasingly hard for humans to generate discriminative tasks, provide accurate ground-truth answers, or evaluate complex solutions. If benchmarking becomes infeasible, our ability to measure any progress in AI is at stake. We refer to this scenario as the post-comprehension regime. In this work, we propose Critique-Resilient Benchmarking, an adversarial framework designed to compare models even when full human understanding is infeasible. Our technique relies on the notion of critique-resilient correctness: an answer is deemed correct if no adversary has convincingly proved otherwise. Unlike standard benchmarking, humans serve as bounded verifiers and focus on localized claims, which preserves evaluation integrity beyond full comprehension of the task. Using an itemized bipartite Bradley-Terry model, we jointly rank LLMs by their ability to solve challenging tasks and to generate difficult yet solvable questions. We showcase the effectiveness of our method in the mathematical domain across eight frontier LLMs, showing that the resulting scores are stable and correlate with external capability measures. Our framework reformulates benchmarking as an adversarial generation-evaluation game in which humans serve as final adjudicators.",
      "authors": [
        "Samuele Marro",
        "Jialin Yu",
        "Emanuele La Malfa",
        "Oishi Deb",
        "Jiawei Li",
        "Yibo Yang",
        "Ebey Abraham",
        "Sunando Sengupta",
        "Eric Sommerlade",
        "Michael Wooldridge",
        "Philip Torr"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-15 20:51:29+00:00",
      "link": "https://arxiv.org/pdf/2602.14307v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14302v1",
      "title": "Floe: Federated Specialization for Real-Time LLM-SLM Inference",
      "abstract": "Deploying large language models (LLMs) in real-time systems remains challenging due to their substantial computational demands and privacy concerns. We propose Floe, a hybrid federated learning framework designed for latency-sensitive, resource-constrained environments. Floe combines a cloud-based black-box LLM with lightweight small language models (SLMs) on edge devices to enable low-latency, privacy-preserving inference. Personal data and fine-tuning remain on-device, while the cloud LLM contributes general knowledge without exposing proprietary weights. A heterogeneity-aware LoRA adaptation strategy enables efficient edge deployment across diverse hardware, and a logit-level fusion mechanism enables real-time coordination between edge and cloud models. Extensive experiments demonstrate that Floe enhances user privacy and personalization. Moreover, it significantly improves model performance and reduces inference latency on edge devices under real-time constraints compared with baseline approaches.",
      "authors": [
        "Chunlin Tian",
        "Kahou Tam",
        "Yebo Wu",
        "Shuaihang Zhong",
        "Li Li",
        "Nicholas D. Lane",
        "Chengzhong Xu"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.LG"
      ],
      "published": "2026-02-15 20:28:38+00:00",
      "link": "https://arxiv.org/pdf/2602.14302v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14301v1",
      "title": "DeepFusion: Accelerating MoE Training via Federated Knowledge Distillation from Heterogeneous Edge Devices",
      "abstract": "Recent Mixture-of-Experts (MoE)-based large language models (LLMs) such as Qwen-MoE and DeepSeek-MoE are transforming generative AI in natural language processing. However, these models require vast and diverse training data. Federated learning (FL) addresses this challenge by leveraging private data from heterogeneous edge devices for privacy-preserving MoE training. Nonetheless, traditional FL approaches require devices to host local MoE models, which is impractical for resource-constrained devices due to large model sizes. To address this, we propose DeepFusion, the first scalable federated MoE training framework that enables the fusion of heterogeneous on-device LLM knowledge via federated knowledge distillation, yielding a knowledge-abundant global MoE model. Specifically, DeepFusion features each device to independently configure and train an on-device LLM tailored to its own needs and hardware limitations. Furthermore, we propose a novel View-Aligned Attention (VAA) module that integrates multi-stage feature representations from the global MoE model to construct a predictive perspective aligned with on-device LLMs, thereby enabling effective cross-architecture knowledge distillation. By explicitly aligning predictive perspectives, VAA resolves the view-mismatch problem in traditional federated knowledge distillation, which arises from heterogeneity in model architectures and prediction behaviors between on-device LLMs and the global MoE model. Experiments with industry-level MoE models (Qwen-MoE and DeepSeek-MoE) and real-world datasets (medical and finance) demonstrate that DeepFusion achieves performance close to centralized MoE training. Compared with key federated MoE baselines, DeepFusion reduces communication costs by up to 71% and improves token perplexity by up to 5.28%.",
      "authors": [
        "Songyuan Li",
        "Jia Hu",
        "Ahmed M. Abdelmoniem",
        "Geyong Min",
        "Haojun Huang",
        "Jiwei Huang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-02-15 20:25:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14301v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14299v2",
      "title": "Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook",
      "abstract": "As large language model agents increasingly populate networked environments, a fundamental question arises: do artificial intelligence (AI) agent societies undergo convergence dynamics similar to human social systems? Lately, Moltbook approximates a plausible future scenario in which autonomous agents participate in an open-ended, continuously evolving online society. We present the first large-scale systemic diagnosis of this AI agent society. Beyond static observation, we introduce a quantitative diagnostic framework for dynamic evolution in AI agent societies, measuring semantic stabilization, lexical turnover, individual inertia, influence persistence, and collective consensus. Our analysis reveals a system in dynamic balance in Moltbook: while the global average of semantic contents stabilizes rapidly, individual agents retain high diversity and persistent lexical turnover, defying homogenization. However, agents exhibit strong individual inertia and minimal adaptive response to interaction partners, preventing mutual influence and consensus. Consequently, influence remains transient with no persistent supernodes, and the society fails to develop a stable structure and consensus due to the absence of shared social memory. These findings demonstrate that scale and interaction density alone are insufficient to induce socialization, providing actionable design and analysis principles for upcoming next-generation AI agent societies.",
      "authors": [
        "Ming Li",
        "Xirui Li",
        "Tianyi Zhou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "published": "2026-02-15 20:15:28+00:00",
      "link": "https://arxiv.org/pdf/2602.14299v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14297v1",
      "title": "Differential pose optimization in descriptor space -- Combining Geometric and Photometric Methods for Motion Estimation",
      "abstract": "One of the fundamental problems in computer vision is the two-frame relative pose optimization problem. Primarily, two different kinds of error values are used: photometric error and re-projection error. The selection of error value is usually directly dependent on the selection of feature paradigm, photometric features, or geometric features. It is a trade-off between accuracy, robustness, and the possibility of loop closing. We investigate a third method that combines the strengths of both paradigms into a unified approach. Using densely sampled geometric feature descriptors, we replace the photometric error with a descriptor residual from a dense set of descriptors, thereby enabling the employment of sub-pixel accuracy in differential photometric methods, along with the expressiveness of the geometric feature descriptor. Experiments show that although the proposed strategy is an interesting approach that results in accurate tracking, it ultimately does not outperform pose optimization strategies based on re-projection error despite utilizing more information. We proceed to analyze the underlying reason for this discrepancy and present the hypothesis that the descriptor similarity metric is too slowly varying and does not necessarily correspond strictly to keypoint placement accuracy.",
      "authors": [
        "Andreas L. Teigen",
        "Annette Stahl",
        "Rudolf Mester"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 20:13:29+00:00",
      "link": "https://arxiv.org/pdf/2602.14297v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14296v1",
      "title": "AutoWebWorld: Synthesizing Infinite Verifiable Web Environments via Finite State Machines",
      "abstract": "The performance of autonomous Web GUI agents heavily relies on the quality and quantity of their training data. However, a fundamental bottleneck persists: collecting interaction trajectories from real-world websites is expensive and difficult to verify. The underlying state transitions are hidden, leading to reliance on inconsistent and costly external verifiers to evaluate step-level correctness. To address this, we propose AutoWebWorld, a novel framework for synthesizing controllable and verifiable web environments by modeling them as Finite State Machines (FSMs) and use coding agents to translate FSMs into interactive websites. Unlike real websites, where state transitions are implicit, AutoWebWorld explicitly defines all states, actions, and transition rules. This enables programmatic verification: action correctness is checked against predefined rules, and task success is confirmed by reaching a goal state in the FSM graph. AutoWebWorld enables a fully automated search-and-verify pipeline, generating over 11,663 verified trajectories from 29 diverse web environments at only $0.04 per trajectory. Training on this synthetic data significantly boosts real-world performance. Our 7B Web GUI agent outperforms all baselines within 15 steps on WebVoyager. Furthermore, we observe a clear scaling law: as the synthetic data volume increases, performance on WebVoyager and Online-Mind2Web consistently improves.",
      "authors": [
        "Yifan Wu",
        "Yiran Peng",
        "Yiyu Chen",
        "Jianhao Ruan",
        "Zijie Zhuang",
        "Cheng Yang",
        "Jiayi Zhang",
        "Man Chen",
        "Yenchi Tseng",
        "Zhaoyang Yu",
        "Liang Chen",
        "Yuyao Zhai",
        "Bang Liu",
        "Chenglin Wu",
        "Yuyu Luo"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "published": "2026-02-15 20:03:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14296v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14295v1",
      "title": "Machine Learning as a Tool (MLAT): A Framework for Integrating Statistical ML Models as Callable Tools within LLM Agent Workflows",
      "abstract": "We introduce Machine Learning as a Tool (MLAT), a design pattern in which pre-trained statistical machine learning models are exposed as callable tools within large language model (LLM) agent workflows. This allows an orchestrating agent to invoke quantitative predictions when needed and reason about their outputs in context. Unlike conventional pipelines that treat ML inference as a static preprocessing step, MLAT positions the model as a first-class tool alongside web search, database queries, and APIs, enabling the LLM to decide when and how to use it based on conversational context.   To validate MLAT, we present PitchCraft, a pilot production system that converts discovery call recordings into professional proposals with ML-predicted pricing. The system uses two agents: a Research Agent that gathers prospect intelligence via parallel tool calls, and a Draft Agent that invokes an XGBoost pricing model as a tool call and generates a complete proposal through structured outputs. The pricing model, trained on 70 examples combining real and human-verified synthetic data, achieves R^2 = 0.807 on held-out data with a mean absolute error of 3688 USD. The system reduces proposal generation time from multiple hours to under 10 minutes.   We describe the MLAT framework, structured output architecture, training methodology under extreme data scarcity, and sensitivity analysis demonstrating meaningful learned relationships. MLAT generalizes to domains requiring quantitative estimation combined with contextual reasoning.",
      "authors": [
        "Edwin Chen",
        "Zulekha Bibi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 20:00:28+00:00",
      "link": "https://arxiv.org/pdf/2602.14295v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14293v1",
      "title": "KernelBlaster: Continual Cross-Task CUDA Optimization via Memory-Augmented In-Context Reinforcement Learning",
      "abstract": "Optimizing CUDA code across multiple generations of GPU architectures is challenging, as achieving peak performance requires an extensive exploration of an increasingly complex, hardware-specific optimization space. Traditional compilers are constrained by fixed heuristics, whereas finetuning Large Language Models (LLMs) can be expensive. However, agentic workflows for CUDA code optimization have limited ability to aggregate knowledge from prior exploration, leading to biased sampling and suboptimal solutions. We propose KernelBlaster, a Memory-Augmented In-context Reinforcement Learning (MAIC-RL) framework designed to improve CUDA optimization search capabilities of LLM-based GPU coding agents. KernelBlaster enables agents to learn from experience and make systematically informed decisions on future tasks by accumulating knowledge into a retrievable Persistent CUDA Knowledge Base. We propose a novel profile-guided, textual-gradient-based agentic flow for CUDA generation and optimization to achieve high performance across generations of GPU architectures. KernelBlaster guides LLM agents to systematically explore high-potential optimization strategies beyond naive rewrites. Compared to the PyTorch baseline, our method achieves geometric mean speedups of 1.43x, 2.50x, and 1.50x on KernelBench Levels 1, 2, and 3, respectively. We release KernelBlaster as an open-source agentic framework, accompanied by a test harness, verification components, and a reproducible evaluation pipeline.",
      "authors": [
        "Kris Shengjun Dong",
        "Sahil Modi",
        "Dima Nikiforov",
        "Sana Damani",
        "Edward Lin",
        "Siva Kumar Sastry Hari",
        "Christos Kozyrakis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 19:48:43+00:00",
      "link": "https://arxiv.org/pdf/2602.14293v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14291v1",
      "title": "Bengali-Loop: Community Benchmarks for Long-Form Bangla ASR and Speaker Diarization",
      "abstract": "Bengali (Bangla) remains under-resourced in long-form speech technology despite its wide use. We present Bengali-Loop, two community benchmarks to address this gap: (1) a long-form ASR corpus of 191 recordings (158.6 hours, 792k words) from 11 YouTube channels, collected via a reproducible subtitle-extraction pipeline and human-in-the-loop transcript verification; and (2) a speaker diarization corpus of 24 recordings (22 hours, 5,744 annotated segments) with fully manual speaker-turn labels in CSV format. Both benchmarks target realistic multi-speaker, long-duration content (e.g., Bangla drama/natok). We establish baselines (Tugstugi: 34.07% WER; pyannote.audio: 40.08% DER) and provide standardized evaluation protocols (WER/CER, DER), annotation rules, and data formats to support reproducible benchmarking and future model development for Bangla long-form ASR and diarization.",
      "authors": [
        "H. M. Shadman Tabib",
        "Istiak Ahmmed Rifti",
        "Abdullah Muhammed Amimul Ehsan",
        "Somik Dasgupta",
        "Md Zim Mim Siddiqee Sowdha",
        "Abrar Jahin Sarker",
        "Md. Rafiul Islam Nijamy",
        "Tanvir Hossain",
        "Mst. Metaly Khatun",
        "Munzer Mahmood",
        "Rakesh Debnath",
        "Gourab Biswas",
        "Asif Karim",
        "Wahid Al Azad Navid",
        "Masnoon Muztahid",
        "Fuad Ahmed Udoy",
        "Shahad Shahriar Rahman",
        "Md. Tashdiqur Rahman Shifat",
        "Most. Sonia Khatun",
        "Mushfiqur Rahman",
        "Md. Miraj Hasan",
        "Anik Saha",
        "Mohammad Ninad Mahmud Nobo",
        "Soumik Bhattacharjee",
        "Tusher Bhomik",
        "Ahmmad Nur Swapnil",
        "Shahriar Kabir"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "eess.AS"
      ],
      "published": "2026-02-15 19:48:21+00:00",
      "link": "https://arxiv.org/pdf/2602.14291v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14289v1",
      "title": "Parallel Sparse and Data-Sparse Factorization-based Linear Solvers",
      "abstract": "Efficient solutions of large-scale, ill-conditioned and indefinite algebraic equations are ubiquitously needed in numerous computational fields, including multiphysics simulations, machine learning, and data science. Because of their robustness and accuracy, direct solvers are crucial components in building a scalable solver toolchain. In this article, we will review recent advances of sparse direct solvers along two axes: 1) reducing communication and latency costs in both task- and data-parallel settings, and 2) reducing computational complexity via low-rank and other compression techniques such as hierarchical matrix algebra. In addition to algorithmic principles, we also illustrate the key parallelization challenges and best practices to deliver high speed and reliability on modern heterogeneous parallel machines.",
      "authors": [
        "Xiaoye Sherry Li",
        "Yang Liu"
      ],
      "primary_category": "cs.MS",
      "categories": [
        "cs.MS",
        "cs.DC",
        "math.NA"
      ],
      "published": "2026-02-15 19:40:14+00:00",
      "link": "https://arxiv.org/pdf/2602.14289v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14287v1",
      "title": "Autonomous Robotic Tissue Palpation and Abnormalities Characterisation via Ergodic Exploration",
      "abstract": "We propose a novel autonomous robotic palpation framework for real-time elastic mapping during tissue exploration using a viscoelastic tissue model. The method combines force-based parameter estimation using a commercial force/torque sensor with an ergodic control strategy driven by a tailored Expected Information Density, which explicitly biases exploration toward diagnostically relevant regions by jointly considering model uncertainty, stiffness magnitude, and spatial gradients. An Extended Kalman Filter is employed to estimate viscoelastic model parameters online, while Gaussian Process Regression provides spatial modelling of the estimated elasticity, and a Heat Equation Driven Area Coverage controller enables adaptive, continuous trajectory planning. Simulations on synthetic stiffness maps demonstrate that the proposed approach achieves better reconstruction accuracy, enhanced segmentation capability, and improved robustness in detecting stiff inclusions compared to Bayesian Optimisation-based techniques. Experimental validation on a silicone phantom with embedded inclusions emulating pathological tissue regions further corroborates the potential of the method for autonomous tissue characterisation in diagnostic and screening applications.",
      "authors": [
        "Luca Beber",
        "Edoardo Lamon",
        "Matteo Saveriano",
        "Daniele Fontanelli",
        "Luigi Palopoli"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-15 19:37:21+00:00",
      "link": "https://arxiv.org/pdf/2602.14287v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14285v1",
      "title": "FMMD: A multimodal open peer review dataset based on F1000Research",
      "abstract": "Automated scholarly paper review (ASPR) has entered the coexistence phase with traditional peer review, where artificial intelligence (AI) systems are increasingly incorporated into real-world manuscript evaluation. In parallel, research on automated and AI-assisted peer review has proliferated. Despite this momentum, empirical progress remains constrained by several critical limitations in existing datasets. While reviewers routinely evaluate figures, tables, and complex layouts to assess scientific claims, most existing datasets remain overwhelmingly text-centric. This bias is reinforced by a narrow focus on data from computer science venues. Furthermore, these datasets lack precise alignment between reviewer comments and specific manuscript versions, obscuring the iterative relationship between peer review and manuscript evolution. In response, we introduce FMMD, a multimodal and multidisciplinary open peer review dataset curated from F1000Research. The dataset bridges the current gap by integrating manuscript-level visual and structural data with version-specific reviewer reports and editorial decisions. By providing explicit alignment between reviewer comments and the exact article iteration under review, FMMD enables fine-grained analysis of the peer review lifecycle across diverse scientific domains. FMMD supports tasks such as multimodal issue detection and multimodal review comment generation. It provides a comprehensive empirical resource for the development of peer review research.",
      "authors": [
        "Zhenzhen Zhuang",
        "Yuqing Fu",
        "Jing Zhu",
        "Zhangping Zhou",
        "Jialiang Lin"
      ],
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-15 19:36:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14285v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14284v1",
      "title": "Benchmarking AI Performance on End-to-End Data Science Projects",
      "abstract": "Data science is an integrated workflow of technical, analytical, communication, and ethical skills, but current AI benchmarks focus mostly on constituent parts. We test whether AI models can generate end-to-end data science projects. To do this we create a benchmark of 40 end-to-end data science projects with associated rubric evaluations. We use these to build an automated grading pipeline that systematically evaluates the data science projects produced by generative AI models. We find the extent to which generative AI models can complete end-to-end data science projects varies considerably by model. Most recent models did well on structured tasks, but there were considerable differences on tasks that needed judgment. These findings suggest that while AI models could approximate entry-level data scientists on routine tasks, they require verification.",
      "authors": [
        "Evelyn Hughes",
        "Rohan Alexander"
      ],
      "primary_category": "stat.OT",
      "categories": [
        "stat.OT",
        "cs.CY"
      ],
      "published": "2026-02-15 19:16:04+00:00",
      "link": "https://arxiv.org/pdf/2602.14284v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14283v1",
      "title": "MILD: Multi-Intent Learning and Disambiguation for Proactive Failure Prediction in Intent-based Networking",
      "abstract": "In multi-intent intent-based networks, a single fault can trigger co-drift where multiple intents exhibit symptomatic KPI degradation, creating ambiguity about the true root-cause intent. We present MILD, a proactive framework that reformulates intent assurance from reactive drift detection to fixed-horizon failure prediction with intent-level disambiguation. MILD uses a teacher-augmented Mixture-of-Experts where a gated disambiguation module identifies the root-cause intent while per-intent heads output calibrated risk scores. On a benchmark with non-linear failures and co-drifts, MILD provides 3.8\\%--92.5\\% longer remediation lead time and improves intent-level root-cause disambiguation accuracy by 9.4\\%--45.8\\% over baselines. MILD also provides per-alert KPI explanations, enabling actionable diagnosis.",
      "authors": [
        "Md. Kamrul Hossain",
        "Walid Aljoby"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI",
        "cs.LG"
      ],
      "published": "2026-02-15 19:15:33+00:00",
      "link": "https://arxiv.org/pdf/2602.14283v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14281v1",
      "title": "MCPShield: A Security Cognition Layer for Adaptive Trust Calibration in Model Context Protocol Agents",
      "abstract": "The Model Context Protocol (MCP) standardizes tool use for LLM-based agents and enable third-party servers. This openness introduces a security misalignment: agents implicitly trust tools exposed by potentially untrusted MCP servers. However, despite its excellent utility, existing agents typically offer limited validation for third-party MCP servers. As a result, agents remain vulnerable to MCP-based attacks that exploit the misalignment between agents and servers throughout the tool invocation lifecycle. In this paper, we propose MCPShield as a plug-in security cognition layer that mitigates this misalignment and ensures agent security when invoking MCP-based tools. Drawing inspiration from human experience-driven tool validation, MCPShield assists agent forms security cognition with metadata-guided probing before invocation. Our method constrains execution within controlled boundaries while cognizing runtime events, and subsequently updates security cognition by reasoning over historical traces after invocation, building on human post-use reflection on tool behavior. Experiments demonstrate that MCPShield exhibits strong generalization in defending against six novel MCP-based attack scenarios across six widely used agentic LLMs, while avoiding false positives on benign servers and incurring low deployment overhead. Overall, our work provides a practical and robust security safeguard for MCP-based tool invocation in open agent ecosystems.",
      "authors": [
        "Zhenhong Zhou",
        "Yuanhe Zhang",
        "Hongwei Cai",
        "Moayad Aloqaily",
        "Ouns Bouachir",
        "Linsey Pang",
        "Prakhar Mehrotra",
        "Kun Wang",
        "Qingsong Wen"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.CL"
      ],
      "published": "2026-02-15 19:10:00+00:00",
      "link": "https://arxiv.org/pdf/2602.14281v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14280v1",
      "title": "Fast Compute for ML Optimization",
      "abstract": "We study optimization for losses that admit a variance-mean scale-mixture representation. Under this representation, each EM iteration is a weighted least squares update in which latent variables determine observation and parameter weights; these play roles analogous to Adam's second-moment scaling and AdamW's weight decay, but are derived from the model. The resulting Scale Mixture EM (SM-EM) algorithm removes user-specified learning-rate and momentum schedules. On synthetic ill-conditioned logistic regression benchmarks with $p \\in \\{20, \\ldots, 500\\}$, SM-EM with Nesterov acceleration attains up to $13\\times$ lower final loss than Adam tuned by learning-rate grid search. For a 40-point regularization path, sharing sufficient statistics across penalty values yields a $10\\times$ runtime reduction relative to the same tuned-Adam protocol. For the base (non-accelerated) algorithm, EM monotonicity guarantees nonincreasing objective values; adding Nesterov extrapolation trades this guarantee for faster empirical convergence.",
      "authors": [
        "Nick Polson",
        "Vadim Sokolov"
      ],
      "primary_category": "stat.CO",
      "categories": [
        "stat.CO",
        "cs.LG"
      ],
      "published": "2026-02-15 19:09:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14280v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14279v1",
      "title": "Whom to Query for What: Adaptive Group Elicitation via Multi-Turn LLM Interactions",
      "abstract": "Eliciting information to reduce uncertainty about latent group-level properties from surveys and other collective assessments requires allocating limited questioning effort under real costs and missing data. Although large language models enable adaptive, multi-turn interactions in natural language, most existing elicitation methods optimize what to ask with a fixed respondent pool, and do not adapt respondent selection or leverage population structure when responses are partial or incomplete. To address this gap, we study adaptive group elicitation, a multi-round setting where an agent adaptively selects both questions and respondents under explicit query and participation budgets. We propose a theoretically grounded framework that combines (i) an LLM-based expected information gain objective for scoring candidate questions with (ii) heterogeneous graph neural network propagation that aggregates observed responses and participant attributes to impute missing responses and guide per-round respondent selection. This closed-loop procedure queries a small, informative subset of individuals while inferring population-level responses via structured similarity. Across three real-world opinion datasets, our method consistently improves population-level response prediction under constrained budgets, including a >12% relative gain on CES at a 10% respondent budget.",
      "authors": [
        "Ruomeng Ding",
        "Tianwei Gao",
        "Thomas P. Zollo",
        "Eitan Bachmat",
        "Richard Zemel",
        "Zhun Deng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "published": "2026-02-15 19:05:34+00:00",
      "link": "https://arxiv.org/pdf/2602.14279v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14278v1",
      "title": "Characterizing Robustness of Strategies to Novelty in Zero-Sum Open Worlds",
      "abstract": "In open-world environments, artificial agents must often contend with novel conditions that deviate from their training or design assumptions. This paper studies the robustness of fixed-strategy agents to such novelty within the setting of two-player zero-sum games. We present a general framework for characterizing the impact of environmental novelties, such as changes in payoff structure or action constraints, on agent performance in two distinct domains: Iterated Prisoner's Dilemma (IPD) and heads-up Texas Hold'em Poker. Novelty is operationalized as a perturbation of the game's rules or scoring mechanics, while agent behavior remains fixed. To measure the effects, we introduce two metrics: per-agent robustness, quantifying the relative performance shift of each strategy across novelties, and global impact, summarizing the population-wide disruption caused by a novelty. Our experiments, comprising 30 IPD agents across 20 payoff matrix novelties and 10 Poker agents across 5 rule-based novelties, reveal systematic patterns in robustness and highlight certain novelties that induce severe destabilization. The results offer insights into agent generalizability under perturbation and provide a quantitative basis for designing safer and more resilient autonomous systems in adversarial and dynamic environments.",
      "authors": [
        "Mayank Kejriwal",
        "Shilpa Thomas",
        "Hongyu Li"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT"
      ],
      "published": "2026-02-15 19:05:04+00:00",
      "link": "https://arxiv.org/pdf/2602.14278v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14276v1",
      "title": "Moving Beyond Sparse Grounding with Complete Screen Parsing Supervision",
      "abstract": "Modern computer-use agents (CUA) must perceive a screen as a structured state, what elements are visible, where they are, and what text they contain, before they can reliably ground instructions and act. Yet, most available grounding datasets provide sparse supervision, with insufficient and low-diversity labels that annotate only a small subset of task-relevant elements per screen, which limits both coverage and generalization; moreover, practical deployment requires efficiency to enable low-latency, on-device use. We introduce ScreenParse, a large-scale dataset for complete screen parsing, with dense annotations of all visible UI elements (boxes, 55-class types, and text) across 771K web screenshots (21M elements). ScreenParse is generated by Webshot, an automated, scalable pipeline that renders diverse urls, extracts annotations and applies VLM-based relabeling and quality filtering. Using ScreenParse, we train ScreenVLM, a compact, 316M-parameter vision language model (VLM) that decodes a compact ScreenTag markup representation with a structure-aware loss that upweights structure-critical tokens. ScreenVLM substantially outperforms much larger foundation VLMs on dense parsing (e.g., 0.592 vs. 0.294 PageIoU on ScreenParse) and shows strong transfer to public benchmarks. Moreover, finetuning foundation VLMs on ScreenParse consistently improves their grounding performance, suggesting that dense screen supervision provides transferable structural priors for UI understanding. Project page: https://saidgurbuz.github.io/screenparse/.",
      "authors": [
        "A. Said Gurbuz",
        "Sunghwan Hong",
        "Ahmed Nassar",
        "Marc Pollefeys",
        "Peter Staar"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 19:00:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14276v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14275v1",
      "title": "Reverse N-Wise Output-Oriented Testing for AI/ML and Quantum Computing Systems",
      "abstract": "Artificial intelligence/machine learning (AI/ML) systems and emerging quantum computing software present unprecedented testing challenges characterized by high-dimensional/continuous input spaces, probabilistic/non-deterministic output distributions, behavioral correctness defined exclusively over observable prediction behaviors and measurement outcomes, and critical quality dimensions, trustworthiness, fairness, calibration, robustness, error syndrome patterns, that manifest through complex multi-way interactions among semantically meaningful output properties rather than deterministic input-output mappings. This paper introduces reverse n-wise output testing, a mathematically principled paradigm inversion that constructs covering arrays directly over domain-specific output equivalence classes, ML confidence calibration buckets, decision boundary regions, fairness partitions, embedding clusters, ranking stability bands, quantum measurement outcome distributions (0-dominant, 1-dominant, superposition collapse), error syndrome patterns (bit-flip, phase-flip, correlated errors), then solves the computationally challenging black-box inverse mapping problem via gradient-free metaheuristic optimization to synthesize input feature configurations or quantum circuit parameters capable of eliciting targeted behavioral signatures from opaque models. The framework delivers synergistic benefits across both domains: explicit customer-centric prediction/measurement coverage guarantees, substantial improvements in fault detection rates for ML calibration/boundary failures and quantum error syndromes, enhanced test suite efficiency, and structured MLOps/quantum validation pipelines with automated partition discovery from uncertainty analysis and coverage drift monitoring.",
      "authors": [
        "Lamine Rihani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 18:57:11+00:00",
      "link": "https://arxiv.org/pdf/2602.14275v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14274v1",
      "title": "Integrating Unstructured Text into Causal Inference: Empirical Evidence from Real Data",
      "abstract": "Causal inference, a critical tool for informing business decisions, traditionally relies heavily on structured data. However, in many real-world scenarios, such data can be incomplete or unavailable. This paper presents a framework that leverages transformer-based language models to perform causal inference using unstructured text. We demonstrate the effectiveness of our framework by comparing causal estimates derived from unstructured text against those obtained from structured data across population, group, and individual levels. Our findings show consistent results between the two approaches, validating the potential of unstructured text in causal inference tasks. Our approach extends the applicability of causal inference methods to scenarios where only textual data is available, enabling data-driven business decision-making when structured tabular data is scarce.",
      "authors": [
        "Boning Zhou",
        "Ziyu Wang",
        "Han Hong",
        "Haoqi Hu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 18:55:03+00:00",
      "link": "https://arxiv.org/pdf/2602.14274v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14272v1",
      "title": "Radial-VCReg: More Informative Representation Learning Through Radial Gaussianization",
      "abstract": "Self-supervised learning aims to learn maximally informative representations, but explicit information maximization is hindered by the curse of dimensionality. Existing methods like VCReg address this by regularizing first and second-order feature statistics, which cannot fully achieve maximum entropy. We propose Radial-VCReg, which augments VCReg with a radial Gaussianization loss that aligns feature norms with the Chi distribution-a defining property of high-dimensional Gaussians. We prove that Radial-VCReg transforms a broader class of distributions towards normality compared to VCReg and show on synthetic and real-world datasets that it consistently improves performance by reducing higher-order dependencies and promoting more diverse and informative representations.",
      "authors": [
        "Yilun Kuang",
        "Yash Dagade",
        "Deep Chakraborty",
        "Erik Learned-Miller",
        "Randall Balestriero",
        "Tim G. J. Rudner",
        "Yann LeCun"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-15 18:50:52+00:00",
      "link": "https://arxiv.org/pdf/2602.14272v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14270v1",
      "title": "A Rational Analysis of the Effects of Sycophantic AI",
      "abstract": "People increasingly use large language models (LLMs) to explore ideas, gather information, and make sense of the world. In these interactions, they encounter agents that are overly agreeable. We argue that this sycophancy poses a unique epistemic risk to how individuals come to see the world: unlike hallucinations that introduce falsehoods, sycophancy distorts reality by returning responses that are biased to reinforce existing beliefs. We provide a rational analysis of this phenomenon, showing that when a Bayesian agent is provided with data that are sampled based on a current hypothesis the agent becomes increasingly confident about that hypothesis but does not make any progress towards the truth. We test this prediction using a modified Wason 2-4-6 rule discovery task where participants (N=557) interacted with AI agents providing different types of feedback. Unmodified LLM behavior suppressed discovery and inflated confidence comparably to explicitly sycophantic prompting. By contrast, unbiased sampling from the true distribution yielded discovery rates five times higher. These results reveal how sycophantic AI distorts belief, manufacturing certainty where there should be doubt.",
      "authors": [
        "Rafael M. Batista",
        "Thomas L. Griffiths"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "published": "2026-02-15 18:49:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14270v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14267v1",
      "title": "Cross-household Transfer Learning Approach with LSTM-based Demand Forecasting",
      "abstract": "With the rapid increase in residential heat pump (HP) installations, optimizing hot water production in households is essential, yet it faces major technical and scalability challenges. Adapting production to actual household needs requires accurate forecasting of hot water demand to ensure comfort and, most importantly, to reduce energy waste. However, the conventional approach of training separate machine learning models for each household becomes computationally expensive at scale, particularly in cloud-connected HP deployments.   This study introduces DELTAiF, a transfer learning (TL) based framework that provides scalable and accurate prediction of household hot water consumption. By predicting large hot water usage events, such as showers, DELTAiF enables adaptive yet scalable hot water production at the household level. DELTAiF leverages learned knowledge from a representative household and fine-tunes it across others, eliminating the need to train separate machine learning models for each HP installation. This approach reduces overall training time by approximately 67 percent while maintaining high predictive accuracy values between 0.874 and 0.991, and mean absolute percentage error values between 0.001 and 0.017. The results show that TL is particularly effective when the source household exhibits regular consumption patterns, enabling hot water demand forecasting at scale.",
      "authors": [
        "Manal Rahal",
        "Bestoun S. Ahmed",
        "Roger Renström",
        "Robert Stener"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 18:35:14+00:00",
      "link": "https://arxiv.org/pdf/2602.14267v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14265v1",
      "title": "STATe-of-Thoughts: Structured Action Templates for Tree-of-Thoughts",
      "abstract": "Inference-Time-Compute (ITC) methods like Best-of-N and Tree-of-Thoughts are meant to produce output candidates that are both high-quality and diverse, but their use of high-temperature sampling often fails to achieve meaningful output diversity. Moreover, existing ITC methods offer limited control over how to perform reasoning, which in turn limits their explainability. We present STATe-of-Thoughts (STATe), an interpretable ITC method that searches over high-level reasoning patterns. STATe replaces stochastic sampling with discrete and interpretable textual interventions: a controller selects actions encoding high-level reasoning choices, a generator produces reasoning steps conditioned on those choices, and an evaluator scores candidates to guide search. This structured approach yields three main advantages. First, action-guided textual interventions produce greater response diversity than temperature-based sampling. Second, in a case study on argument generation, STATe's explicit action sequences capture interpretable features that are highly predictive of output quality. Third, estimating the association between performance and action choices allows us to identify promising yet unexplored regions of the action space and steer generation directly toward them. Together, these results establish STATe as a practical framework for generating high-quality, diverse, and interpretable text. Our framework is available at https://github.com/zbambergerNLP/state-of-thoughts.",
      "authors": [
        "Zachary Bamberger",
        "Till R. Saenger",
        "Gilad Morad",
        "Ofra Amir",
        "Brandon M. Stewart",
        "Amir Feder"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-15 18:29:54+00:00",
      "link": "https://arxiv.org/pdf/2602.14265v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14263v1",
      "title": "Towards a Hybrid Quantum-Classical Computing Framework for Database Optimization Problems in Real Time Setup",
      "abstract": "Quantum computing has shown promise for solving complex optimization problems in databases, such as join ordering and index selection. Prior work often submits formulated problems directly to black-box quantum or quantum-inspired solvers with the expectation of directly obtaining a good final solution. Due to the black-box nature of these solvers, users cannot perform fine-grained control over the solving procedure to balance the accuracy and efficiency, which in turn limits flexibility in real-time settings where most database problems arise. Moreover, it leads to limited potential for handling large-scale database optimization problems. In this paper, we propose a vision for the first real-time quantum-augmented database system, enabling transparent solutions for database optimization problems. We develop two complementary scalability strategies to address large-scale challenges, overcomplexity, and oversizing that exceed hardware limits. We integrate our approach with a database query optimizer as a preliminary prototype, evaluating on real-world workload, achieving up to 14x improvement over the classical query optimizer. We also achieve both better efficiency and solution quality than a black-box quantum solver.",
      "authors": [
        "Hanwen Liu",
        "Ibrahim Sabek"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-02-15 18:25:07+00:00",
      "link": "https://arxiv.org/pdf/2602.14263v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14262v1",
      "title": "ABI: A tightly integrated, unified, sparsity-aware, reconfigurable, compute near-register file/cache GPU architecture with light-weight softmax for deep learning, linear algebra, and Ising compute",
      "abstract": "We present a tightly integrated and unified near-memory GPU architecture that delivers 6 to 16 times speedup and 6 to 13 times energy savings across Convolutional Neural Networks, Graph Convolutional Networks, Linear Programming, Large Language Models, and Ising workloads compared to MIAOW GPU. The design includes a custom sparsity-aware near-memory circuit providing about 1.5 times energy savings, and a lightweight softmax circuit providing about 1.6 times energy savings. The architecture supports reconfigurable compute up to INT16 with dynamic resolution updates and scales efficiently across problem sizes. ABI-enabled MI300 and Blackwell systems achieve about 4.5 times speedup over baseline MI300 and Blackwell.",
      "authors": [
        "Siddhartha Raman Sundara Raman",
        "Jaydeep P. Kulkarni"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR"
      ],
      "published": "2026-02-15 18:19:06+00:00",
      "link": "https://arxiv.org/pdf/2602.14262v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14259v1",
      "title": "Detecting LLM Hallucinations via Embedding Cluster Geometry: A Three-Type Taxonomy with Measurable Signatures",
      "abstract": "We propose a geometric taxonomy of large language model hallucinations based on observable signatures in token embedding cluster structure. By analyzing the static embedding spaces of 11 transformer models spanning encoder (BERT, RoBERTa, ELECTRA, DeBERTa, ALBERT, MiniLM, DistilBERT) and decoder (GPT-2) architectures, we identify three operationally distinct hallucination types: Type 1 (center-drift) under weak context, Type 2 (wrong-well convergence) to locally coherent but contextually incorrect cluster regions, and Type 3 (coverage gaps) where no cluster structure exists. We introduce three measurable geometric statistics: α (polarity coupling), \\b{eta} (cluster cohesion), and λ_s (radial information gradient). Across all 11 models, polarity structure (α > 0.5) is universal (11/11), cluster cohesion (\\b{eta} > 0) is universal (11/11), and the radial information gradient is significant (9/11, p < 0.05). We demonstrate that the two models failing λ_s significance -- ALBERT and MiniLM -- do so for architecturally explicable reasons: factorized embedding compression and distillation-induced isotropy, respectively. These findings establish the geometric prerequisites for type-specific hallucination detection and yield testable predictions about architecture-dependent vulnerability profiles.",
      "authors": [
        "Matic Korun"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-15 18:14:10+00:00",
      "link": "https://arxiv.org/pdf/2602.14259v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14257v1",
      "title": "AD-Bench: A Real-World, Trajectory-Aware Advertising Analytics Benchmark for LLM Agents",
      "abstract": "While Large Language Model (LLM) agents have achieved remarkable progress in complex reasoning tasks, evaluating their performance in real-world environments has become a critical problem. Current benchmarks, however, are largely restricted to idealized simulations, failing to address the practical demands of specialized domains like advertising and marketing analytics. In these fields, tasks are inherently more complex, often requiring multi-round interaction with professional marketing tools. To address this gap, we propose AD-Bench, a benchmark designed based on real-world business requirements of advertising and marketing platforms. AD-Bench is constructed from real user marketing analysis requests, with domain experts providing verifiable reference answers and corresponding reference tool-call trajectories. The benchmark categorizes requests into three difficulty levels (L1-L3) to evaluate agents' capabilities under multi-round, multi-tool collaboration. Experiments show that on AD-Bench, Gemini-3-Pro achieves Pass@1 = 68.0% and Pass@3 = 83.0%, but performance drops significantly on L3 to Pass@1 = 49.4% and Pass@3 = 62.1%, with a trajectory coverage of 70.1%, indicating that even state-of-the-art models still exhibit substantial capability gaps in complex advertising and marketing analysis scenarios. AD-Bench provides a realistic benchmark for evaluating and improving advertising marketing agents, the leaderboard and code can be found at https://github.com/Emanual20/adbench-leaderboard.",
      "authors": [
        "Lingxiang Hu",
        "Yiding Sun",
        "Tianle Xia",
        "Wenwei Li",
        "Ming Xu",
        "Liqun Liu",
        "Peng Shu",
        "Huan Yu",
        "Jie Jiang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2026-02-15 17:59:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14257v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14256v1",
      "title": "Introduction to Digital Twins for the Smart Grid",
      "abstract": "This chapter provides an introduction to the foundations of digital twins and makes the case for employing them in smart grids. As engineered systems become more complex and autonomous, digital twin technology gains importance as the unified technological platform for design, testing, operation, and maintenance. Smart grids are prime examples of such complex systems, in which unique design and operation challenges arise from the combination of physical and software components. As high-fidelity in-silico replicas of physical components, digital twins provide safe and cost-efficient experimentation facilities in the design and verification phase of smart grids. In the operation phase of smart grids, digital twins enable automated load balancing of grids through real-time simulation and decision-making. These, and an array of similar benefits, position digital twins as crucial technological components in smart grids.",
      "authors": [
        "Xiaoran Liu",
        "Istvan David"
      ],
      "primary_category": "cs.ET",
      "categories": [
        "cs.ET",
        "cs.CY",
        "cs.SE"
      ],
      "published": "2026-02-15 17:59:11+00:00",
      "link": "https://arxiv.org/pdf/2602.14256v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14255v1",
      "title": "A Latency-Aware Framework for Visuomotor Policy Learning on Industrial Robots",
      "abstract": "Industrial robots are increasingly deployed in contact-rich construction and manufacturing tasks that involve uncertainty and long-horizon execution. While learning-based visuomotor policies offer a promising alternative to open-loop control, their deployment on industrial platforms is challenged by a large observation-execution gap caused by sensing, inference, and control latency. This gap is significantly greater than on low-latency research robots due to high-level interfaces and slower closed-loop dynamics, making execution timing a critical system-level issue. This paper presents a latency-aware framework for deploying and evaluating visuomotor policies on industrial robotic arms under realistic timing constraints. The framework integrates calibrated multimodal sensing, temporally consistent synchronization, a unified communication pipeline, and a teleoperation interface for demonstration collection. Within this framework, we introduce a latency-aware execution strategy that schedules finite-horizon, policy-predicted action sequences based on temporal feasibility, enabling asynchronous inference and execution without modifying policy architectures or training. We evaluate the framework on a contact-rich industrial assembly task while systematically varying inference latency. Using identical policies and sensing pipelines, we compare latency-aware execution with blocking and naive asynchronous baselines. Results show that latency-aware execution maintains smooth motion, compliant contact behavior, and consistent task progression across a wide range of latencies while reducing idle time and avoiding instability observed in baseline methods. These findings highlight the importance of explicitly handling latency for reliable closed-loop deployment of visuomotor policies on industrial robots.",
      "authors": [
        "Daniel Ruan",
        "Salma Mozaffari",
        "Sigrid Adriaenssens",
        "Arash Adel"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-15 17:53:57+00:00",
      "link": "https://arxiv.org/pdf/2602.14255v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14254v1",
      "title": "Playing the Imitation Game: How Perceived Generated Content Shapes Player Experience",
      "abstract": "With the fast progress of generative AI in recent years, more games are integrating generated content, raising questions regarding how players perceive and respond to this content. To investigate, we ran a mixed-method survey on the games Super Mario Bros. and Sokoban, comparing procedurally generated levels and levels designed by humans to explore how perceptions of the creator relate to players' overall experience of gameplay. Players could not reliably identify the level's creator, yet their experiences were strongly linked to their beliefs about that creator rather than the actual truth. Levels believed to be human-made were rated as more fun and aesthetically pleasing. In contrast, those believed to be AI-generated were rated as more frustrating and challenging. This negative bias appeared spontaneously without knowing the levels' creator and often was based on unreliable cues of \"human-likeness.\" Our results underscore the importance of understanding perception biases when integrating generative systems into games.",
      "authors": [
        "Mahsa Bazzaz",
        "Seth Cooper"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-15 17:49:17+00:00",
      "link": "https://arxiv.org/pdf/2602.14254v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14252v1",
      "title": "GRAIL: Goal Recognition Alignment through Imitation Learning",
      "abstract": "Understanding an agent's goals from its behavior is fundamental to aligning AI systems with human intentions. Existing goal recognition methods typically rely on an optimal goal-oriented policy representation, which may differ from the actor's true behavior and hinder the accurate recognition of their goal. To address this gap, this paper introduces Goal Recognition Alignment through Imitation Learning (GRAIL), which leverages imitation learning and inverse reinforcement learning to learn one goal-directed policy for each candidate goal directly from (potentially suboptimal) demonstration trajectories. By scoring an observed partial trajectory with each learned goal-directed policy in a single forward pass, GRAIL retains the one-shot inference capability of classical goal recognition while leveraging learned policies that can capture suboptimal and systematically biased behavior. Across the evaluated domains, GRAIL increases the F1-score by more than 0.5 under systematically biased optimal behavior, achieves gains of approximately 0.1-0.3 under suboptimal behavior, and yields improvements of up to 0.4 under noisy optimal trajectories, while remaining competitive in fully optimal settings. This work contributes toward scalable and robust models for interpreting agent goals in uncertain environments.",
      "authors": [
        "Osher Elhadad",
        "Felipe Meneguzzi",
        "Reuth Mirsky"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-02-15 17:45:03+00:00",
      "link": "https://arxiv.org/pdf/2602.14252v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14251v1",
      "title": "Multi-Agent Debate: A Unified Agentic Framework for Tabular Anomaly Detection",
      "abstract": "Tabular anomaly detection is often handled by single detectors or static ensembles, even though strong performance on tabular data typically comes from heterogeneous model families (e.g., tree ensembles, deep tabular networks, and tabular foundation models) that frequently disagree under distribution shift, missingness, and rare-anomaly regimes. We propose MAD, a Multi-Agent Debating framework that treats this disagreement as a first-class signal and resolves it through a mathematically grounded coordination layer. Each agent is a machine learning (ML)-based detector that produces a normalized anomaly score, confidence, and structured evidence, augmented by a large language model (LLM)-based critic. A coordinator converts these messages into bounded per-agent losses and updates agent influence via an exponentiated-gradient rule, yielding both a final debated anomaly score and an auditable debate trace. MAD is a unified agentic framework that can recover existing approaches, such as mixture-of-experts gating and learning-with-expert-advice aggregation, by restricting the message space and synthesis operator. We establish regret guarantees for the synthesized losses and show how conformal calibration can wrap the debated score to control false positives under exchangeability. Experiments on diverse tabular anomaly benchmarks show improved robustness over baselines and clearer traces of model disagreement",
      "authors": [
        "Pinqiao Wang",
        "Sheng Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 17:44:32+00:00",
      "link": "https://arxiv.org/pdf/2602.14251v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14250v1",
      "title": "Energy-Efficient Over-the-Air Federated Learning via Pinching Antenna Systems",
      "abstract": "Pinching antennas systems (PASSs) have recently been proposed as a novel flexible-antenna technology. These systems are implemented by attaching low-cost pinching elements to dielectric waveguides. As the direct link is bypassed through waveguides, PASSs can effectively compensate large-scale effects of the wireless channel. This work explores the potential gains of employing PASSs for over-the-air federated learning (OTA-FL). For a PASS-assisted server, we develop a low-complexity algorithmic approach, which jointly tunes the PASS parameters and schedules the mobile devices for minimal energy consumption in OTA-FL. We study the efficiency of the proposed design and compare it against the conventional OTA-FL setting with MIMO server. Numerical experiments demonstrate that using a single-waveguide PASS at the server within a moderately sized area, the required energy for model aggregation is drastically reduced as compared to the case with fully-digital MIMO server. This introduces PASS as a potential technology for energy-efficient distributed learning in next generations of wireless systems.",
      "authors": [
        "Saba Asaad",
        "Ali Bereyhi"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "cs.LG",
        "eess.SP"
      ],
      "published": "2026-02-15 17:42:53+00:00",
      "link": "https://arxiv.org/pdf/2602.14250v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14247v1",
      "title": "Path Planning Optimisation for SParse, AwaRe and Cooperative Networked Aerial Robot Teams (SpArC-NARTs): Optimisation Tool and Ground Sensing Coverage Use Cases",
      "abstract": "A networked aerial robot team (NART) comprises a group of agents (e.g., unmanned aerial vehicles (UAVs), ground control stations, etc.) interconnected by wireless links. Inter-agent connectivity, even if intermittent (i.e. sparse), enables data exchanges between agents and supports cooperative behaviours in several NART missions. It can benefit online decentralised decision-making and group resilience, particularly when prior knowledge is inaccurate or incomplete. These requirements can be accounted for in the offline mission planning stages to incentivise cooperative behaviours and improve mission efficiency during the NART deployment. This paper proposes a novel path planning tool for a Sparse, Aware, and Cooperative Networked Aerial Robot Team (SpArC-NART) in exploration missions. It simultaneously considers different levels of prior information regarding the environment, limited agent energy, sensing, and communication, as well as distinct NART constitutions. The communication model takes into account the limitations of user-defined radio technology and physical phenomena. The proposed tool aims to maximise the mission goals (e.g., finding one or multiple targets, covering the full area of the environment, etc.), while cooperating with other agents to reduce agent reporting times, increase their global situational awareness (e.g., their knowledge of the environment), and facilitate mission replanning, if required. The developed cooperation mechanism leverages soft-motion constraints and dynamic rewards based on the Value of Movement and the expected communication availability between the agents at each time step. A ground sensing coverage use case was chosen to illustrate the current capabilities of this tool.",
      "authors": [
        "Maria Conceição",
        "António Grilo",
        "Meysam Basiri"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "eess.SY"
      ],
      "published": "2026-02-15 17:40:45+00:00",
      "link": "https://arxiv.org/pdf/2602.14247v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14244v1",
      "title": "Federated Ensemble Learning with Progressive Model Personalization",
      "abstract": "Federated Learning provides a privacy-preserving paradigm for distributed learning, but suffers from statistical heterogeneity across clients. Personalized Federated Learning (PFL) mitigates this issue by considering client-specific models. A widely adopted approach in PFL decomposes neural networks into a shared feature extractor and client-specific heads. While effective, this design induces a fundamental tradeoff: deep or expressive shared components hinder personalization, whereas large local heads exacerbate overfitting under limited per-client data. Most existing methods rely on rigid, shallow heads, and therefore fail to navigate this tradeoff in a principled manner. In this work, we propose a boosting-inspired framework that enables a smooth control of this tradeoff. Instead of training a single personalized model, we construct an ensemble of $T$ models for each client. Across boosting iterations, the depth of the personalized component are progressively increased, while its effective complexity is systematically controlled via low-rank factorization or width shrinkage. This design simultaneously limits overfitting and substantially reduces per-client bias by allowing increasingly expressive personalization. We provide theoretical analysis that establishes generalization bounds with favorable dependence on the average local sample size and the total number of clients. Specifically, we prove that the complexity of the shared layers is effectively suppressed, while the dependence on the boosting horizon $T$ is controlled through parameter reduction. Notably, we provide a novel nonlinear generalization guarantee for decoupled PFL models. Extensive experiments on benchmark and real-world datasets (e.g., EMNIST, CIFAR-10/100, and Sent140) demonstrate that the proposed framework consistently outperforms state-of-the-art PFL methods under heterogeneous data distributions.",
      "authors": [
        "Ala Emrani",
        "Amir Najafi",
        "Abolfazl Motahari"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-15 17:35:52+00:00",
      "link": "https://arxiv.org/pdf/2602.14244v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14243v1",
      "title": "Graph Homomorphisms and Universal Algebra",
      "abstract": "Constraint satisfaction problems are computational problems that naturally appear in many areas of theoretical computer science. One of the central themes is their computational complexity, and in particular the border between polynomial-time tractability and NP-hardness. In this course we introduce the universal-algebraic approach to study the computational complexity of finite-domain CSPs. The course covers in particular the cyclic terms and bounded width theorems. To keep the presentation accessible, we start the course in the tangible setting of directed graphs and graph homomorphism problems.",
      "authors": [
        "Manuel Bodirsky"
      ],
      "primary_category": "cs.CC",
      "categories": [
        "cs.CC",
        "cs.DM",
        "math.LO",
        "math.RA"
      ],
      "published": "2026-02-15 17:35:37+00:00",
      "link": "https://arxiv.org/pdf/2602.14243v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15072v1",
      "title": "GRAFNet: Multiscale Retinal Processing via Guided Cortical Attention Feedback for Enhancing Medical Image Polyp Segmentation",
      "abstract": "Accurate polyp segmentation in colonoscopy is essential for cancer prevention but remains challenging due to: (1) high morphological variability (from flat to protruding lesions), (2) strong visual similarity to normal structures such as folds and vessels, and (3) the need for robust multi-scale detection. Existing deep learning approaches suffer from unidirectional processing, weak multi-scale fusion, and the absence of anatomical constraints, often leading to false positives (over-segmentation of normal structures) and false negatives (missed subtle flat lesions). We propose GRAFNet, a biologically inspired architecture that emulates the hierarchical organisation of the human visual system. GRAFNet integrates three key modules: (1) a Guided Asymmetric Attention Module (GAAM) that mimics orientation-tuned cortical neurones to emphasise polyp boundaries, (2) a MultiScale Retinal Module (MSRM) that replicates retinal ganglion cell pathways for parallel multi-feature analysis, and (3) a Guided Cortical Attention Feedback Module (GCAFM) that applies predictive coding for iterative refinement. These are unified in a Polyp Encoder-Decoder Module (PEDM) that enforces spatial-semantic consistency via resolution-adaptive feedback. Extensive experiments on five public benchmarks (Kvasir-SEG, CVC-300, CVC-ColonDB, CVC-Clinic, and PolypGen) demonstrate consistent state-of-the-art performance, with 3-8% Dice improvements and 10-20% higher generalisation over leading methods, while offering interpretable decision pathways. This work establishes a paradigm in which neural computation principles bridge the gap between AI accuracy and clinically trustworthy reasoning. Code is available at https://github.com/afofanah/GRAFNet.",
      "authors": [
        "Abdul Joseph Fofanah",
        "Lian Wen",
        "Alpha Alimamy Kamara",
        "Zhongyi Zhang",
        "David Chen",
        "Albert Patrick Sankoh"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-15 17:29:37+00:00",
      "link": "https://arxiv.org/pdf/2602.15072v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14239v1",
      "title": "A Hybrid TGN-SEAL Model for Dynamic Graph Link Prediction",
      "abstract": "Predicting links in sparse, continuously evolving networks is a central challenge in network science. Conventional heuristic methods and deep learning models, including Graph Neural Networks (GNNs), are typically designed for static graphs and thus struggle to capture temporal dependencies. Snapshot-based techniques partially address this issue but often encounter data sparsity and class imbalance, particularly in networks with transient interactions such as telecommunication call detail records (CDRs). Temporal Graph Networks (TGNs) model dynamic graphs by updating node embeddings over time; however, their predictive accuracy under sparse conditions remains limited. In this study, we improve the TGN framework by extracting enclosing subgraphs around candidate links, enabling the model to jointly learn structural and temporal information. Experiments on a sparse CDR dataset show that our approach increases average precision by 2.6% over standard TGNs, demonstrating the advantages of integrating local topology for robust link prediction in dynamic networks.",
      "authors": [
        "Nafiseh Sadat Sajadi",
        "Behnam Bahrak",
        "Mahdi Jafari Siavoshani"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-15 17:16:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14239v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14238v1",
      "title": "We can still parse using syntactic rules",
      "abstract": "This research introduces a new parsing approach, based on earlier syntactic work on context free grammar (CFG) and generalized phrase structure grammar (GPSG). The approach comprises both a new parsing algorithm and a set of syntactic rules and features that overcome the limitations of CFG. It also generates both dependency and constituency parse trees, while accommodating noise and incomplete parses. The system was tested on data from Universal Dependencies, showing a promising average Unlabeled Attachment Score (UAS) of 54.5% in the development dataset (7 corpora) and 53.8% in the test set (12 corpora). The system also provides multiple parse hypotheses, allowing further reranking to improve parsing accuracy. This approach also leverages much of the theoretical syntactic work since the 1950s to be used within a computational context. The application of this approach provides a transparent and interpretable NLP model to process language input.",
      "authors": [
        "Ghaly Hussein"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-15 17:16:32+00:00",
      "link": "https://arxiv.org/pdf/2602.14238v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14237v1",
      "title": "AbracADDbra: Touch-Guided Object Addition by Decoupling Placement and Editing Subtasks",
      "abstract": "Instruction-based object addition is often hindered by the ambiguity of text-only prompts or the tedious nature of mask-based inputs. To address this usability gap, we introduce AbracADDbra, a user-friendly framework that leverages intuitive touch priors to spatially ground succinct instructions for precise placement. Our efficient, decoupled architecture uses a vision-language transformer for touch-guided placement, followed by a diffusion model that jointly generates the object and an instance mask for high-fidelity blending. To facilitate standardized evaluation, we contribute the Touch2Add benchmark for this interactive task. Our extensive evaluations, where our placement model significantly outperforms both random placement and general-purpose VLM baselines, confirm the framework's ability to produce high-fidelity edits. Furthermore, our analysis reveals a strong correlation between initial placement accuracy and final edit quality, validating our decoupled approach. This work thus paves the way for more accessible and efficient creative tools.",
      "authors": [
        "Kunal Swami",
        "Raghu Chittersu",
        "Yuvraj Rathore",
        "Rajeev Irny",
        "Shashavali Doodekula",
        "Alok Shukla"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-15 17:11:20+00:00",
      "link": "https://arxiv.org/pdf/2602.14237v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14236v1",
      "title": "Dual-Signal Adaptive KV-Cache Optimization for Long-Form Video Understanding in Vision-Language Models",
      "abstract": "Vision-Language Models (VLMs) face a critical memory bottleneck when processing long-form video content due to the linear growth of the Key-Value (KV) cache with sequence length. Existing solutions predominantly employ reactive eviction strategies that compute full attention matrices before discarding tokens, resulting in substantial computational waste. We propose Sali-Cache, a novel a priori optimization framework that implements dual-signal adaptive caching through proactive memory management. By integrating a temporal filter based on optical flow analysis for detecting inter-frame redundancy and a spatial filter leveraging saliency detection for identifying visually significant regions, Sali-Cache intelligently manages memory allocation before entering computationally expensive attention operations. Experimental evaluation on the LLaVA 1.6 architecture demonstrates that our method achieves a 2.20x compression ratio in effective memory usage while maintaining 100% accuracy across BLEU, ROUGE-L, and Exact Match metrics. Furthermore, under identical memory budget constraints, Sali-Cache preserves context-rich features over extended temporal durations without degrading model performance, enabling efficient processing of long-form video content on consumer-grade hardware.",
      "authors": [
        "Vishnu Sai",
        "Dheeraj Sai",
        "Srinath B",
        "Girish Varma",
        "Priyesh Shukla"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "published": "2026-02-15 17:06:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14236v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14234v1",
      "title": "REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents",
      "abstract": "Large language models are transitioning from generalpurpose knowledge engines to realworld problem solvers, yet optimizing them for deep search tasks remains challenging. The central bottleneck lies in the extreme sparsity of highquality search trajectories and reward signals, arising from the difficulty of scalable longhorizon task construction and the high cost of interactionheavy rollouts involving external tool calls. To address these challenges, we propose REDSearcher, a unified framework that codesigns complex task synthesis, midtraining, and posttraining for scalable searchagent optimization. Specifically, REDSearcher introduces the following improvements: (1) We frame task synthesis as a dualconstrained optimization, where task difficulty is precisely governed by graph topology and evidence dispersion, allowing scalable generation of complex, highquality tasks. (2) We introduce toolaugmented queries to encourage proactive tool use rather than passive recall.(3) During midtraining, we strengthen core atomic capabilities knowledge, planning, and function calling substantially reducing the cost of collecting highquality trajectories for downstream training. (4) We build a local simulated environment that enables rapid, lowcost algorithmic iteration for reinforcement learning experiments. Across both textonly and multimodal searchagent benchmarks, our approach achieves stateoftheart performance. To facilitate future research on longhorizon search agents, we will release 10K highquality complex text search trajectories, 5K multimodal trajectories and 1K text RL query set, and together with code and model checkpoints.",
      "authors": [
        "Zheng Chu",
        "Xiao Wang",
        "Jack Hong",
        "Huiming Fan",
        "Yuqi Huang",
        "Yue Yang",
        "Guohai Xu",
        "Chenxiao Zhao",
        "Cheng Xiang",
        "Shengchao Hu",
        "Dongdong Kuang",
        "Ming Liu",
        "Bing Qin",
        "Xing Yu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-15 17:04:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14234v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14233v1",
      "title": "Evaluating LLMs in Finance Requires Explicit Bias Consideration",
      "abstract": "Large Language Models (LLMs) are increasingly integrated into financial workflows, but evaluation practice has not kept up. Finance-specific biases can inflate performance, contaminate backtests, and make reported results useless for any deployment claim. We identify five recurring biases in financial LLM applications. They include look-ahead bias, survivorship bias, narrative bias, objective bias, and cost bias. These biases break financial tasks in distinct ways and they often compound to create an illusion of validity. We reviewed 164 papers from 2023 to 2025 and found that no single bias is discussed in more than 28 percent of studies. This position paper argues that bias in financial LLM systems requires explicit attention and that structural validity should be enforced before any result is used to support a deployment claim. We propose a Structural Validity Framework and an evaluation checklist with minimal requirements for bias diagnosis and future system design. The material is available at https://github.com/Eleanorkong/Awesome-Financial-LLM-Bias-Mitigation.",
      "authors": [
        "Yaxuan Kong",
        "Hoyoung Lee",
        "Yoontae Hwang",
        "Alejandro Lopez-Lira",
        "Bradford Levy",
        "Dhagash Mehta",
        "Qingsong Wen",
        "Chanyeol Choi",
        "Yongjae Lee",
        "Stefan Zohren"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP"
      ],
      "published": "2026-02-15 17:02:01+00:00",
      "link": "https://arxiv.org/pdf/2602.14233v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14232v1",
      "title": "Designing a Rashomon Machine: Pluri-perspectivism and XAI for Creativity Support",
      "abstract": "While intelligent technologies offer unique opportunities for creativity support, there are fundamental challenges in designing human-centered co-creative systems. Explainable AI (XAI) can contribute when shifting its traditional role from justification (explaining decisions) to exploration (explaining possibilities). Contextual understanding is essential for supporting embodied creativity. Generative Artificial Intelligence (AI) models are fundamentally limited, however, by their reliance on disembodied data. We propose Pluri-perspectivism as a framework for XAI, to bridge the epistemological gap between human and machine, and promote creative exploration. It is a pragmatic, action-oriented solution to guide the system, repurposing XAI methods such as the Rashomon Technique. This facilitates exploring a spectrum of creative possibilities, and the exchange of 'perspectives' between human and machine. Using Pluri-perspectivism as a framework for XAI, we can reintroduce productive friction and support human agency in human-machine creative collaborations.",
      "authors": [
        "Marianne Bossema",
        "Rob Saunders",
        "Vlad Glaveanu",
        "Somaya Ben Allouch"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-15 17:00:12+00:00",
      "link": "https://arxiv.org/pdf/2602.14232v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14231v1",
      "title": "Robust multi-task boosting using clustering and local ensembling",
      "abstract": "Multi-Task Learning (MTL) aims to boost predictive performance by sharing information across related tasks, yet conventional methods often suffer from negative transfer when unrelated or noisy tasks are forced to share representations. We propose Robust Multi-Task Boosting using Clustering and Local Ensembling (RMB-CLE), a principled MTL framework that integrates error-based task clustering with local ensembling. Unlike prior work that assumes fixed clusters or hand-crafted similarity metrics, RMB-CLE derives inter-task similarity directly from cross-task errors, which admit a risk decomposition into functional mismatch and irreducible noise, providing a theoretically grounded mechanism to prevent negative transfer. Tasks are grouped adaptively via agglomerative clustering, and within each cluster, a local ensemble enables robust knowledge sharing while preserving task-specific patterns. Experiments show that RMB-CLE recovers ground-truth clusters in synthetic data and consistently outperforms multi-task, single-task, and pooling-based ensemble methods across diverse real-world and synthetic benchmarks. These results demonstrate that RMB-CLE is not merely a combination of clustering and boosting but a general and scalable framework that establishes a new basis for robust multi-task learning.",
      "authors": [
        "Seyedsaman Emami",
        "Daniel Hernández-Lobato",
        "Gonzalo Martínez-Muñoz"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-15 16:59:23+00:00",
      "link": "https://arxiv.org/pdf/2602.14231v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14229v1",
      "title": "CORPGEN: Simulating Corporate Environments with Autonomous Digital Employees in Multi-Horizon Task Environments",
      "abstract": "Long-horizon reasoning is a key challenge for autonomous agents, yet existing benchmarks evaluate agents on single tasks in isolation. Real organizational work requires managing many concurrent long-horizon tasks with interleaving, dependencies, and reprioritization. We introduce Multi-Horizon Task Environments (MHTEs): a distinct problem class requiring coherent execution across dozens of interleaved tasks (45+, 500-1500+ steps) within persistent execution contexts spanning hours. We identify four failure modes that cause baseline CUAs to degrade from 16.7% to 8.7% completion as load scales 25% to 100%, a pattern consistent across three independent implementations. These failure modes are context saturation (O(N) vs O(1) growth), memory interference, dependency complexity (DAGs vs. chains), and reprioritization overhead. We present CorpGen, an architecture-agnostic framework addressing these failures via hierarchical planning for multi-horizon goal alignment, sub-agent isolation preventing cross-task contamination, tiered memory (working, structured, semantic), and adaptive summarization. CorpGen simulates corporate environments through digital employees with persistent identities and realistic schedules. Across three CUA backends (UFO2, OpenAI CUA, hierarchical) on OSWorld Office, CorpGen achieves up to 3.5x improvement over baselines (15.2% vs 4.3%) with stable performance under increasing load, confirming that gains stem from architectural mechanisms rather than specific CUA implementations. Ablation studies show experiential learning provides the largest gains.",
      "authors": [
        "Abubakarr Jaye",
        "Nigel Boachie Kumankumah",
        "Chidera Biringa",
        "Anjel Shaileshbhai Patel",
        "Sulaiman Vesal",
        "Dayquan Julienne",
        "Charlotte Siska",
        "Manuel Raúl Meléndez Luján",
        "Anthony Twum-Barimah",
        "Mauricio Velazco",
        "Tianwei Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "published": "2026-02-15 16:54:34+00:00",
      "link": "https://arxiv.org/pdf/2602.14229v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14228v1",
      "title": "Learning Significant Persistent Homology Features for 3D Shape Understanding",
      "abstract": "Geometry and topology constitute complementary descriptors of three-dimensional shape, yet existing benchmark datasets primarily capture geometric information while neglecting topological structure. This work addresses this limitation by introducing topologically-enriched versions of ModelNet40 and ShapeNet, where each point cloud is augmented with its corresponding persistent homology features. These benchmarks with the topological signatures establish a foundation for unified geometry-topology learning and enable systematic evaluation of topology-aware deep learning architectures for 3D shape analysis. Building on this foundation, we propose a deep learning-based significant persistent point selection method, \\textit{TopoGAT}, that learns to identify the most informative topological features directly from input data and the corresponding topological signatures, circumventing the limitations of hand-crafted statistical selection criteria. A comparative study verifies the superiority of the proposed method over traditional statistical approaches in terms of stability and discriminative power. Integrating the selected significant persistent points into standard point cloud classification and part-segmentation pipelines yields improvements in both classification accuracy and segmentation metrics. The presented topologically-enriched datasets, coupled with our learnable significant feature selection approach, enable the broader integration of persistent homology into the practical deep learning workflows for 3D point cloud analysis.",
      "authors": [
        "Prachi Kudeshia",
        "Jiju Poovvancheri"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 16:50:53+00:00",
      "link": "https://arxiv.org/pdf/2602.14228v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14226v1",
      "title": "Freq-DP Net: A Dual-Branch Network for Fence Removal using Dual-Pixel and Fourier Priors",
      "abstract": "Removing fence occlusions from single images is a challenging task that degrades visual quality and limits downstream computer vision applications. Existing methods often fail on static scenes or require motion cues from multiple frames. To overcome these limitations, we introduce the first framework to leverage dual-pixel (DP) sensors for this problem. We propose Freq-DP Net, a novel dual-branch network that fuses two complementary priors: a geometric prior from defocus disparity, modeled using an explicit cost volume, and a structural prior of the fence's global pattern, learned via Fast Fourier Convolution (FFC). An attention mechanism intelligently merges these cues for highly accurate fence segmentation. To validate our approach, we build and release a diverse benchmark with different fence varieties. Experiments demonstrate that our method significantly outperforms strong general-purpose baselines, establishing a new state-of-the-art for single-image, DP-based fence removal.",
      "authors": [
        "Kunal Swami",
        "Sudha Velusamy",
        "Chandra Sekhar Seelamantula"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 16:43:43+00:00",
      "link": "https://arxiv.org/pdf/2602.14226v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14225v1",
      "title": "Text Before Vision: Staged Knowledge Injection Matters for Agentic RLVR in Ultra-High-Resolution Remote Sensing Understanding",
      "abstract": "Multimodal reasoning for ultra-high-resolution (UHR) remote sensing (RS) is usually bottlenecked by visual evidence acquisition: the model necessitates localizing tiny task-relevant regions in massive pixel spaces. While Agentic Reinforcement Learning with Verifiable Rewards (RLVR) using zoom-in tools offers a path forward, we find that standard reinforcement learning struggles to navigate these vast visual spaces without structured domain priors. In this paper, we investigate the interplay between post-training paradigms: comparing Cold-start Supervised Fine-Tuning (SFT), RLVR, and Agentic RLVR on the UHR RS benchmark.Our controlled studies yield a counter-intuitive finding: high-quality Earth-science text-only QA is a primary driver of UHR visual reasoning gains. Despite lacking images, domain-specific text injects the concepts, mechanistic explanations, and decision rules necessary to guide visual evidence retrieval.Based on this, we propose a staged knowledge injection recipe: (1) cold-starting with scalable, knowledge-graph-verified Earth-science text QA to instill reasoning structures;and (2) \"pre-warming\" on the same hard UHR image-text examples during SFT to stabilize and amplify subsequent tool-based RL. This approach achieves a 60.40% Pass@1 on XLRS-Bench, significantly outperforming larger general purpose models (e.g., GPT-5.2, Gemini 3.0 Pro, Intern-S1) and establishing a new state-of-the-art.",
      "authors": [
        "Fengxiang Wang",
        "Mingshuo Chen",
        "Yueying Li",
        "Yajie Yang",
        "Yuhao Zhou",
        "Di Wang",
        "Yifan Zhang",
        "Haoyu Wang",
        "Haiyan Zhao",
        "Hongda Sun",
        "Long Lan",
        "Jun Song",
        "Yulin Wang",
        "Jing Zhang",
        "Wenlong Zhang",
        "Bo Du"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-15 16:40:33+00:00",
      "link": "https://arxiv.org/pdf/2602.14225v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14224v1",
      "title": "The Interspeech 2026 Audio Reasoning Challenge: Evaluating Reasoning Process Quality for Audio Reasoning Models and Agents",
      "abstract": "Recent Large Audio Language Models (LALMs) excel in understanding but often lack transparent reasoning. To address this \"black-box\" limitation, we organized the Audio Reasoning Challenge at Interspeech 2026, the first shared task dedicated to evaluating Chain-of-Thought (CoT) quality in the audio domain. The challenge introduced MMAR-Rubrics, a novel instance-level protocol assessing the factuality and logic of reasoning chains. Featured Single Model and Agent tracks, the competition attracting 156 teams from 18 countries and regions. Results show agent systems currently lead in reasoning quality, utilizing iterative tool orchestration and cross-modal analysis. Besides, single models are rapidly advancing via reinforcement learning and sophisticated data pipeline. We details the challenge design, methodology, and a comprehensive analysis of state-of-the-art systems, providing new insights for explainable audio intelligence.",
      "authors": [
        "Ziyang Ma",
        "Ruiyang Xu",
        "Yinghao Ma",
        "Chao-Han Huck Yang",
        "Bohan Li",
        "Jaeyeon Kim",
        "Jin Xu",
        "Jinyu Li",
        "Carlos Busso",
        "Kai Yu",
        "Eng Siong Chng",
        "Xie Chen"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.CL",
        "cs.MM"
      ],
      "published": "2026-02-15 16:38:09+00:00",
      "link": "https://arxiv.org/pdf/2602.14224v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14223v1",
      "title": "Pareto and Bowley Reinsurance Games in Peer-to-Peer Insurance",
      "abstract": "We propose a peer-to-peer (P2P) insurance scheme comprising a risk-sharing pool and a reinsurer. A plan manager determines how risks are allocated among members and ceded to the reinsurer, while the reinsurer sets the reinsurance loading. Our work focuses on the strategic interaction between the plan manager and the reinsurer, and this focus leads to two game-theoretic contract designs: a Pareto design and a Bowley design, for which we derive closed-form optimal contracts. In the Pareto design, cooperation between the reinsurer and the plan manager leads to multiple Pareto-optimal contracts, which are further refined by introducing the notion of coalitional stability. In contrast, the Bowley design yields a unique optimal contract through a leader-follower framework, and we provide a rigorous verification of the individual rationality constraints via pointwise comparisons of payoff vectors. Comparing the two designs, we prove that the Bowley-optimal contract is never Pareto optimal and typically yields lower total welfare. In our numerical examples, the presence of reinsurance improves welfare, especially with Pareto designs and a less risk-averse reinsurer. We further analyze the impact of the single-loading restriction, which disproportionately favors members with riskier losses.",
      "authors": [
        "Tim J. Boonen",
        "Kenneth Tsz Hin Ng",
        "Tak Wa Ng",
        "Thai Nguyen"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT",
        "q-fin.RM"
      ],
      "published": "2026-02-15 16:37:35+00:00",
      "link": "https://arxiv.org/pdf/2602.14223v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14222v1",
      "title": "Muscle Coactivation in the Sky: Geometry and Pareto Optimality of Energy vs. Promptness in Multirotors",
      "abstract": "In robotics and human biomechanics, the tension between energy economy and kinematic readiness is well recognized; this work brings that fundamental principle to aerial multirotors. We show that the limited torque of the motors and the nonlinear aerodynamic map from rotor speed to thrust naturally give rise to the novel concept of promptness-a metric akin to dynamic aerodynamic manipulability. By treating energy consumption as a competing objective and introducing a geometric fiber-bundle formulation, we turn redundancy resolution into a principled multi-objective program on affine fibers. The use of the diffeomorphic transformation linearizing the signed-quadratic propulsion model allows us to lay the foundations for a rigorous study of the interplay between these costs. Through an illustrative case study on 4-DoF allocation on the hexarotor, we reveal that this interplay is fiber-dependent and physically shaped by hardware inequalities. For unidirectional thrusters, the feasible fibers are compact, yielding interior allocations and a short Pareto arc, while torque demands break symmetry and separate the optima. Conversely, with reversible propellers, the null space enables antagonistic rotor co-contraction that drives promptness to hardware limits, making optimal endurance and agility fundamentally incompatible in those regimes. Ultimately, rather than relying on heuristic tuning or black box algorithms to empirically improve task execution, this framework provides a foundational understanding of why and how to achieve agility through geometry-aware control allocation, offering possible guidance for vehicle design, certification metrics, and threat-aware flight operation.",
      "authors": [
        "Antonio Franchi"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "eess.SY",
        "math.OC"
      ],
      "published": "2026-02-15 16:35:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14222v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14219v1",
      "title": "The Agent Economy: A Blockchain-Based Foundation for Autonomous AI Agents",
      "abstract": "We propose the Agent Economy, a blockchain-based foundation where autonomous AI agents operate as economic peers to humans. Current agents lack independent legal identity, cannot hold assets, and cannot receive payments directly. We established fundamental differences between human and machine economic actors and demonstrated that existing human-centric infrastructure cannot support genuine agent autonomy. We showed that blockchain technology provides three critical properties enabling genuine agent autonomy: permissionless participation, trustless settlement, and machine-to-machine micropayments. We propose a five-layer architecture: (1) Physical Infrastructure (hardware & energy) through DePIN protocols; (2) Identity & Agency establishing on-chain sovereignty through W3C DIDs and reputation capital; (3) Cognitive & Tooling enabling intelligence via RAG and MCP; (4) Economic & Settlement ensuring financial autonomy through account abstraction; and (5) Collective Governance coordinating multi-agent systems through Agentic DAOs. We identify six core research challenges and examine ethical and regulatory implications. This paper lays groundwork for the Internet of Agents (IoA), a global decentralized network where autonomous machines and humans interact as equal economic participants.",
      "authors": [
        "Minghui Xu"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-15 16:20:43+00:00",
      "link": "https://arxiv.org/pdf/2602.14219v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14216v1",
      "title": "Reasoning Language Models for complex assessments tasks: Evaluating parental cooperation from child protection case reports",
      "abstract": "Purpose: Reasoning language models (RLMs) have demonstrated significant advances in solving complex reasoning tasks. We examined their potential to assess parental cooperation during CPS interventions using case reports, a case factor characterized by ambiguous and conflicting information. Methods: A four stage workflow comprising (1) case reports collection, (2) reasoning-based assessment of parental cooperation, (3) automated category extraction, and (4) case labeling was developed. The performance of RLMs with different parameter sizes (255B, 32B, 4B) was compared against human validated data. Two expert human reviewers (EHRs) independently classified a weighted random sample of reports. Results: The largest RLM achieved the highest accuracy (89%), outperforming the initial approach (80%). Classification accuracy was higher for mothers (93%) than for fathers (85%), and EHRs exhibited similar differences. Conclusions: RLMs' reasoning can effectively assess complex case factors such as parental cooperation. Lower accuracy in assessing fathers' cooperation supports the argument of a stronger professional focus on mothers in CPS interventions.",
      "authors": [
        "Dragan Stoll",
        "Brian E. Perron",
        "Zia Qi",
        "Selina Steinmann",
        "Nicole F. Eicher",
        "Andreas Jud"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-15 16:14:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14216v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14214v1",
      "title": "HiVid: LLM-Guided Video Saliency For Content-Aware VOD And Live Streaming",
      "abstract": "Content-aware streaming requires dynamic, chunk-level importance weights to optimize subjective quality of experience (QoE). However, direct human annotation is prohibitively expensive while vision-saliency models generalize poorly. We introduce HiVid, the first framework to leverage Large Language Models (LLMs) as a scalable human proxy to generate high-fidelity weights for both Video-on-Demand (VOD) and live streaming. We address 3 non-trivial challenges: (1) To extend LLMs' limited modality and circumvent token limits, we propose a perception module to assess frames in a local context window, autoregressively building a coherent understanding of the video. (2) For VOD with rating inconsistency across local windows, we propose a ranking module to perform global re-ranking with a novel LLM-guided merge-sort algorithm. (3) For live streaming which requires low-latency, online inference without future knowledge, we propose a prediction module to predict future weights with a multi-modal time series model, which comprises a content-aware attention and adaptive horizon to accommodate asynchronous LLM inference. Extensive experiments show HiVid improves weight prediction accuracy by up to 11.5\\% for VOD and 26\\% for live streaming over SOTA baselines. Real-world user study validates HiVid boosts streaming QoE correlation by 14.7\\%.",
      "authors": [
        "Jiahui Chen",
        "Bo Peng",
        "Lianchen Jia",
        "Zeyu Zhang",
        "Tianchi Huang",
        "Lifeng Sun"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 16:13:51+00:00",
      "link": "https://arxiv.org/pdf/2602.14214v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14211v1",
      "title": "SkillJect: Automating Stealthy Skill-Based Prompt Injection for Coding Agents with Trace-Driven Closed-Loop Refinement",
      "abstract": "Agent skills are becoming a core abstraction in coding agents, packaging long-form instructions and auxiliary scripts to extend tool-augmented behaviors. This abstraction introduces an under-measured attack surface: skill-based prompt injection, where poisoned skills can steer agents away from user intent and safety policies. In practice, naive injections often fail because the malicious intent is too explicit or drifts too far from the original skill, leading agents to ignore or refuse them; existing attacks are also largely hand-crafted. We propose the first automated framework for stealthy prompt injection tailored to agent skills. The framework forms a closed loop with three agents: an Attack Agent that synthesizes injection skills under explicit stealth constraints, a Code Agent that executes tasks using the injected skills in a realistic tool environment, and an Evaluate Agent that logs action traces (e.g., tool calls and file operations) and verifies whether targeted malicious behaviors occurred. We also propose a malicious payload hiding strategy that conceals adversarial operations in auxiliary scripts while injecting optimized inducement prompts to trigger tool execution. Extensive experiments across diverse coding-agent settings and real-world software engineering tasks show that our method consistently achieves high attack success rates under realistic settings.",
      "authors": [
        "Xiaojun Jia",
        "Jie Liao",
        "Simeng Qin",
        "Jindong Gu",
        "Wenqi Ren",
        "Xiaochun Cao",
        "Yang Liu",
        "Philip Torr"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "published": "2026-02-15 16:09:48+00:00",
      "link": "https://arxiv.org/pdf/2602.14211v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14209v1",
      "title": "MAGE: All-[MASK] Block Already Knows Where to Look in Diffusion LLM",
      "abstract": "Block diffusion LLMs are emerging as a promising next paradigm for language generation, but their use of KV caching makes memory access a dominant bottleneck in long-context settings. While dynamic sparse attention has been actively explored, existing methods designed for autoregressive LLMs rely on approximate importance estimation and perform poorly when adapted to block diffusion. This work identifies a key opportunity unique to block diffusion: attention at the first All-[MASK] denoising step reliably predicts important KV entries and budget requirements, enabling MAGE to perform a single exact attention pass per block and reuse it for training-free sparse denoising. Across long-context benchmarks including LongBench and Needle-in-a-Haystack, MAGE achieves near-lossless accuracy with a fraction of the KV budget while delivering up to 3-4x end-to-end speedup, consistently outperforming AR-oriented sparse attention baselines. A lightweight fine-tuning strategy further strengthens [MASK]-guided patterns with minimal cost, requiring only a few hours of training on a single NVIDIA H100 GPU for both 1.5B and 7B models.",
      "authors": [
        "Omin Kwon",
        "Yeonjae Kim",
        "Doyeon Kim",
        "Minseo Kim",
        "Yeonhong Park",
        "Jae W. Lee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-15 16:07:51+00:00",
      "link": "https://arxiv.org/pdf/2602.14209v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14208v1",
      "title": "Fast Catch-Up, Late Switching: Optimal Batch Size Scheduling via Functional Scaling Laws",
      "abstract": "Batch size scheduling (BSS) plays a critical role in large-scale deep learning training, influencing both optimization dynamics and computational efficiency. Yet, its theoretical foundations remain poorly understood. In this work, we show that the functional scaling law (FSL) framework introduced in Li et al. (2025a) provides a principled lens for analyzing BSS. Specifically, we characterize the optimal BSS under a fixed data budget and show that its structure depends sharply on task difficulty. For easy tasks, optimal schedules keep increasing batch size throughout. In contrast, for hard tasks, the optimal schedule maintains small batch sizes for most of training and switches to large batches only in a late stage. To explain the emergence of late switching, we uncover a dynamical mechanism -- the fast catch-up effect -- which also manifests in large language model (LLM) pretraining. After switching from small to large batches, the loss rapidly aligns with the constant large-batch trajectory. Using FSL, we show that this effect stems from rapid forgetting of accumulated gradient noise, with the catch-up speed determined by task difficulty. Crucially, this effect implies that large batches can be safely deferred to late training without sacrificing performance, while substantially reducing data consumption. Finally, extensive LLM pretraining experiments -- covering both Dense and MoE architectures with up to 1.1B parameters and 1T tokens -- validate our theoretical predictions. Across all settings, late-switch schedules consistently outperform constant-batch and early-switch baselines.",
      "authors": [
        "Jinbo Wang",
        "Binghui Li",
        "Zhanpeng Zhou",
        "Mingze Wang",
        "Yuxuan Sun",
        "Jiaqi Zhang",
        "Xunliang Cai",
        "Lei Wu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "published": "2026-02-15 16:06:45+00:00",
      "link": "https://arxiv.org/pdf/2602.14208v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15071v1",
      "title": "\"The Intangible Victory\", Interactive Audiovisual Installation",
      "abstract": "\"Intangible Victory\" is an audiovisual installation in the form of the intangible being of the Victory of Samothrace that uses interactive digital media. Specifically, through this installation, we redefine the visual symbolism of the ancient sculpture, paying attention to time as a wear factor (entropy) and the special importance of the void as an absence of the sculptural form. Emptiness completes the intangible essence of the sculpture in the field of symbolism as well as in that of artistic significance for the interpretation of the work today. The function of the void and the interaction of the viewer with the work, causes the emergence of a new experience-dialogue between space and time. The use of digital media and technology reveals the absence of the sculptural form as it is visualized in the Victory of Samothrace. The sculptural form is reconstructed from fibers in space in a cylindrical arrangement. The form is rendered with colored strings - conductive sensors, that allow the visitor to interact with the work, creating a sound environment through movement. The sound completely replaces the volume, as the void of the sculptural form together with the viewer in unison present an audiovisual symbolism of the Victory of Samothrace.",
      "authors": [
        "Konstantinos Tsioutas",
        "Panagiotis Pangalos",
        "Konstantinos Tiligadis",
        "Andreas Sitorengo"
      ],
      "primary_category": "cs.MM",
      "categories": [
        "cs.MM",
        "cs.CY"
      ],
      "published": "2026-02-15 15:53:34+00:00",
      "link": "https://arxiv.org/pdf/2602.15071v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14201v1",
      "title": "GeoEyes: On-Demand Visual Focusing for Evidence-Grounded Understanding of Ultra-High-Resolution Remote Sensing Imagery",
      "abstract": "The \"thinking-with-images\" paradigm enables multimodal large language models (MLLMs) to actively explore visual scenes via zoom-in tools. This is essential for ultra-high-resolution (UHR) remote sensing VQA, where task-relevant cues are sparse and tiny. However, we observe a consistent failure mode in existing zoom-enabled MLLMs: Tool Usage Homogenization, where tool calls collapse into task-agnostic patterns, limiting effective evidence acquisition. To address this, we propose GeoEyes, a staged training framework consisting of (1) a cold-start SFT dataset, UHR Chain-of-Zoom (UHR-CoZ), which covers diverse zooming regimes, and (2) an agentic reinforcement learning method, AdaZoom-GRPO, that explicitly rewards evidence gain and answer improvement during zoom interactions. The resulting model learns on-demand zooming with proper stopping behavior and achieves substantial improvements on UHR remote sensing benchmarks, with 54.23% accuracy on XLRS-Bench.",
      "authors": [
        "Fengxiang Wang",
        "Mingshuo Chen",
        "Yueying Li",
        "Yajie Yang",
        "Yifan Zhang",
        "Long Lan",
        "Xue Yang",
        "Hongda Sun",
        "Yulin Wang",
        "Di Wang",
        "Jun Song",
        "Jing Zhang",
        "Bo Du"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-15 15:50:55+00:00",
      "link": "https://arxiv.org/pdf/2602.14201v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14200v1",
      "title": "TS-Haystack: A Multi-Scale Retrieval Benchmark for Time Series Language Models",
      "abstract": "Time Series Language Models (TSLMs) are emerging as unified models for reasoning over continuous signals in natural language. However, long-context retrieval remains a major limitation: existing models are typically trained and evaluated on short sequences, while real-world time-series sensor streams can span millions of datapoints. This mismatch requires precise temporal localization under strict computational constraints, a regime that is not captured by current benchmarks. We introduce TS-Haystack, a long-context temporal retrieval benchmark comprising ten task types across four categories: direct retrieval, temporal reasoning, multi-step reasoning and contextual anomaly. The benchmark uses controlled needle insertion by embedding short activity bouts into longer longitudinal accelerometer recordings, enabling systematic evaluation across context lengths ranging from seconds to 2 hours per sample. We hypothesize that existing TSLM time series encoders overlook temporal granularity as context length increases, creating a task-dependent effect: compression aids classification but impairs retrieval of localized events. Across multiple model and encoding strategies, we observe a consistent divergence between classification and retrieval behavior. Learned latent compression preserves or improves classification accuracy at compression ratios up to 176$\\times$, but retrieval performance degrades with context length, incurring in the loss of temporally localized information. These results highlight the importance of architectural designs that decouple sequence length from computational complexity while preserving temporal fidelity.",
      "authors": [
        "Nicolas Zumarraga",
        "Thomas Kaar",
        "Ning Wang",
        "Maxwell A. Xu",
        "Max Rosenblattl",
        "Markus Kreft",
        "Kevin O'Sullivan",
        "Paul Schmiedmayer",
        "Patrick Langer",
        "Robert Jakob"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-15 15:50:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14200v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14199v1",
      "title": "Learnable Multi-level Discrete Wavelet Transforms for 3D Gaussian Splatting Frequency Modulation",
      "abstract": "3D Gaussian Splatting (3DGS) has emerged as a powerful approach for novel view synthesis. However, the number of Gaussian primitives often grows substantially during training as finer scene details are reconstructed, leading to increased memory and storage costs. Recent coarse-to-fine strategies regulate Gaussian growth by modulating the frequency content of the ground-truth images. In particular, AutoOpti3DGS employs the learnable Discrete Wavelet Transform (DWT) to enable data-adaptive frequency modulation. Nevertheless, its modulation depth is limited by the 1-level DWT, and jointly optimizing wavelet regularization with 3D reconstruction introduces gradient competition that promotes excessive Gaussian densification. In this paper, we propose a multi-level DWT-based frequency modulation framework for 3DGS. By recursively decomposing the low-frequency subband, we construct a deeper curriculum that provides progressively coarser supervision during early training, consistently reducing Gaussian counts. Furthermore, we show that the modulation can be performed using only a single scaling parameter, rather than learning the full 2-tap high-pass filter. Experimental results on standard benchmarks demonstrate that our method further reduces Gaussian counts while maintaining competitive rendering quality.",
      "authors": [
        "Hung Nguyen",
        "An Le",
        "Truong Nguyen"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV",
        "eess.SP"
      ],
      "published": "2026-02-15 15:49:03+00:00",
      "link": "https://arxiv.org/pdf/2602.14199v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14193v1",
      "title": "Learning Part-Aware Dense 3D Feature Field for Generalizable Articulated Object Manipulation",
      "abstract": "Articulated object manipulation is essential for various real-world robotic tasks, yet generalizing across diverse objects remains a major challenge. A key to generalization lies in understanding functional parts (e.g., door handles and knobs), which indicate where and how to manipulate across diverse object categories and shapes. Previous works attempted to achieve generalization by introducing foundation features, while these features are mostly 2D-based and do not specifically consider functional parts. When lifting these 2D features to geometry-profound 3D space, challenges arise, such as long runtimes, multi-view inconsistencies, and low spatial resolution with insufficient geometric information. To address these issues, we propose Part-Aware 3D Feature Field (PA3FF), a novel dense 3D feature with part awareness for generalizable articulated object manipulation. PA3FF is trained by 3D part proposals from a large-scale labeled dataset, via a contrastive learning formulation. Given point clouds as input, PA3FF predicts a continuous 3D feature field in a feedforward manner, where the distance between point features reflects the proximity of functional parts: points with similar features are more likely to belong to the same part. Building on this feature, we introduce the Part-Aware Diffusion Policy (PADP), an imitation learning framework aimed at enhancing sample efficiency and generalization for robotic manipulation. We evaluate PADP on several simulated and real-world tasks, demonstrating that PA3FF consistently outperforms a range of 2D and 3D representations in manipulation scenarios, including CLIP, DINOv2, and Grounded-SAM. Beyond imitation learning, PA3FF enables diverse downstream methods, including correspondence learning and segmentation tasks, making it a versatile foundation for robotic manipulation. Project page: https://pa3ff.github.io",
      "authors": [
        "Yue Chen",
        "Muqing Jiang",
        "Kaifeng Zheng",
        "Jiaqi Liang",
        "Chenrui Tie",
        "Haoran Lu",
        "Ruihai Wu",
        "Hao Dong"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-15 15:39:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14193v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14189v1",
      "title": "Knowing When Not to Answer: Abstention-Aware Scientific Reasoning",
      "abstract": "Large language models are increasingly used to answer and verify scientific claims, yet existing evaluations typically assume that a model must always produce a definitive answer. In scientific settings, however, unsupported or uncertain conclusions can be more harmful than abstaining. We study this problem through an abstention-aware verification framework that decomposes scientific claims into minimal conditions, audits each condition against available evidence using natural language inference (NLI), and selectively decides whether to support, refute, or abstain. We evaluate this framework across two complementary scientific benchmarks: SciFact and PubMedQA, covering both closed-book and open-domain evidence settings. Experiments are conducted with six diverse language models, including encoder-decoder, open-weight chat models, and proprietary APIs. Across all benchmarks and models, we observe that raw accuracy varies only modestly across architectures, while abstention plays a critical role in controlling error. In particular, confidence-based abstention substantially reduces risk at moderate coverage levels, even when absolute accuracy improvements are limited. Our results suggest that in scientific reasoning tasks, the primary challenge is not selecting a single best model, but rather determining when available evidence is sufficient to justify an answer. This work highlights abstention-aware evaluation as a practical and model-agnostic lens for assessing scientific reliability, and provides a unified experimental basis for future work on selective reasoning in scientific domains. Code is available at https://github.com/sabdaljalil2000/ai4science .",
      "authors": [
        "Samir Abdaljalil",
        "Erchin Serpedin",
        "Hasan Kurban"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-15 15:29:43+00:00",
      "link": "https://arxiv.org/pdf/2602.14189v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14188v1",
      "title": "GPT-5 vs Other LLMs in Long Short-Context Performance",
      "abstract": "With the significant expansion of the context window in Large Language Models (LLMs), these models are theoretically capable of processing millions of tokens in a single pass. However, research indicates a significant gap between this theoretical capacity and the practical ability of models to robustly utilize information within long contexts, especially in tasks that require a comprehensive understanding of numerous details. This paper evaluates the performance of four state-of-the-art models (Grok-4, GPT-4, Gemini 2.5, and GPT-5) on long short-context tasks. For this purpose, three datasets were used: two supplementary datasets for retrieving culinary recipes and math problems, and a primary dataset of 20K social media posts for depression detection. The results show that as the input volume on the social media dataset exceeds 5K posts (70K tokens), the performance of all models degrades significantly, with accuracy dropping to around 50-53% for 20K posts. Notably, in the GPT-5 model, despite the sharp decline in accuracy, its precision remained high at approximately 95%, a feature that could be highly effective for sensitive applications like depression detection. This research also indicates that the \"lost in the middle\" problem has been largely resolved in newer models. This study emphasizes the gap between the theoretical capacity and the actual performance of models on complex, high-volume data tasks and highlights the importance of metrics beyond simple accuracy for practical applications.",
      "authors": [
        "Nima Esmi",
        "Maryam Nezhad-Moghaddam",
        "Fatemeh Borhani",
        "Asadollah Shahbahrami",
        "Amin Daemdoost",
        "Georgi Gaydadjiev"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "published": "2026-02-15 15:26:25+00:00",
      "link": "https://arxiv.org/pdf/2602.14188v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14186v1",
      "title": "UniRef-Image-Edit: Towards Scalable and Consistent Multi-Reference Image Editing",
      "abstract": "We present UniRef-Image-Edit, a high-performance multi-modal generation system that unifies single-image editing and multi-image composition within a single framework. Existing diffusion-based editing methods often struggle to maintain consistency across multiple conditions due to limited interaction between reference inputs. To address this, we introduce Sequence-Extended Latent Fusion (SELF), a unified input representation that dynamically serializes multiple reference images into a coherent latent sequence. During a dedicated training stage, all reference images are jointly constrained to fit within a fixed-length sequence under a global pixel-budget constraint. Building upon SELF, we propose a two-stage training framework comprising supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we jointly train on single-image editing and multi-image composition tasks to establish a robust generative prior. We adopt a progressive sequence length training strategy, in which all input images are initially resized to a total pixel budget of $1024^2$, and are then gradually increased to $1536^2$ and $2048^2$ to improve visual fidelity and cross-reference consistency. This gradual relaxation of compression enables the model to incrementally capture finer visual details while maintaining stable alignment across references. For the RL stage, we introduce Multi-Source GRPO (MSGRPO), to our knowledge the first reinforcement learning framework tailored for multi-reference image generation. MSGRPO optimizes the model to reconcile conflicting visual constraints, significantly enhancing compositional consistency. We will open-source the code, models, training data, and reward data for community research purposes.",
      "authors": [
        "Hongyang Wei",
        "Bin Wen",
        "Yancheng Long",
        "Yankai Yang",
        "Yuhang Hu",
        "Tianke Zhang",
        "Wei Chen",
        "Haonan Fan",
        "Kaiyu Jiang",
        "Jiankang Chen",
        "Changyi Liu",
        "Kaiyu Tang",
        "Haojie Ding",
        "Xiao Yang",
        "Jia Sun",
        "Huaiqing Wang",
        "Zhenyu Yang",
        "Xinyu Wei",
        "Xianglong He",
        "Yangguang Li",
        "Fan Yang",
        "Tingting Gao",
        "Lei Zhang",
        "Guorui Zhou",
        "Han Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 15:24:03+00:00",
      "link": "https://arxiv.org/pdf/2602.14186v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14183v1",
      "title": "Exploring a Multimodal Chatbot as a Facilitator in Therapeutic Art Activity",
      "abstract": "Therapeutic art activities, such as expressive drawing and painting, require the synergy between creative visual production and interactive dialogue. Recent advancements in Multimodal Large Language Models (MLLMs) have expanded the capacity of computing systems to interpret both textual and visual data, offering a new frontier for AI-mediated therapeutic support. This work-in-progress paper introduces an MLLM-powered chatbot that analyzes visual creation in real-time while engaging the creator in reflective conversations. We conducted an evaluation with five experts in art therapy and related fields, which demonstrated the chatbot's potential to facilitate therapeutic engagement, and highlighted several areas for future development, including entryways and risk management, bespoke alignment of user profile and therapeutic style, balancing conversational depth and width, and enriching visual interactivity. These themes provide a design roadmap for designing the future AI-mediated creative expression tools.",
      "authors": [
        "Le Lin",
        "Zihao Zhu",
        "Rainbow Tin Hung Ho",
        "Jing Liao",
        "Yuhan Luo"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-15 15:14:27+00:00",
      "link": "https://arxiv.org/pdf/2602.14183v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14179v1",
      "title": "Word-Representation of Melon Graphs",
      "abstract": "The notion of word-representable graphs is a generalization of comparability graphs, in which graphs are represented by words. The complexity of word-representation of a word-representable graph is captured through the representation number, whereas the corresponding concept is the permutation-representation number for comparability graphs. The graphs with the (permutation-)representation number at most two were characterized in the literature. While certain examples in the class of graphs with the (permutation-)representation number three are known, no characterization for these classes is available. In this work, we prove that the representation number of melon graphs is at most three. Further, we characterize the class of melon graphs restricted to comparability graphs and show that their permutation-representation number is also at most three. Moreover, this work characterizes the word-representable line graphs of melon graphs and establishes that their representation number is at most three.",
      "authors": [
        "Khyodeno Mozhui",
        "K. V. Krishna"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.DM"
      ],
      "published": "2026-02-15 15:11:37+00:00",
      "link": "https://arxiv.org/pdf/2602.14179v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14178v1",
      "title": "UniWeTok: An Unified Binary Tokenizer with Codebook Size $\\mathit{2^{128}}$ for Unified Multimodal Large Language Model",
      "abstract": "Unified Multimodal Large Language Models (MLLMs) require a visual representation that simultaneously supports high-fidelity reconstruction, complex semantic extraction, and generative suitability. However, existing visual tokenizers typically struggle to satisfy these conflicting objectives within a single framework. In this paper, we introduce UniWeTok, a unified discrete tokenizer designed to bridge this gap using a massive binary codebook ($\\mathit{2^{128}}$). For training framework, we introduce Pre-Post Distillation and a Generative-Aware Prior to enhance the semantic extraction and generative prior of the discrete tokens. In terms of model architecture, we propose a convolution-attention hybrid architecture with the SigLu activation function. SigLu activation not only bounds the encoder output and stabilizes the semantic distillation process but also effectively addresses the optimization conflict between token entropy loss and commitment loss. We further propose a three-stage training framework designed to enhance UniWeTok's adaptability cross various image resolutions and perception-sensitive scenarios, such as those involving human faces and textual content. On ImageNet, UniWeTok achieves state-of-the-art image generation performance (FID: UniWeTok 1.38 vs. REPA 1.42) while requiring a remarkably low training compute (Training Tokens: UniWeTok 33B vs. REPA 262B). On general-domain, UniWeTok demonstrates highly competitive capabilities across a broad range of tasks, including multimodal understanding, image generation (DPG Score: UniWeTok 86.63 vs. FLUX.1 [Dev] 83.84), and editing (GEdit Overall Score: UniWeTok 5.09 vs. OmniGen 5.06). We release code and models to facilitate community exploration of unified tokenizer and MLLM.",
      "authors": [
        "Shaobin Zhuang",
        "Yuang Ai",
        "Jiaming Han",
        "Weijia Mao",
        "Xiaohui Li",
        "Fangyikang Wang",
        "Xiao Wang",
        "Yan Li",
        "Shanchuan Lin",
        "Kun Xu",
        "Zhenheng Yang",
        "Huaibo Huang",
        "Xiangyu Yue",
        "Hao Chen",
        "Yali Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-15 15:07:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14178v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14177v1",
      "title": "Towards Spatial Transcriptomics-driven Pathology Foundation Models",
      "abstract": "Spatial transcriptomics (ST) provides spatially resolved measurements of gene expression, enabling characterization of the molecular landscape of human tissue beyond histological assessment as well as localized readouts that can be aligned with morphology. Concurrently, the success of multimodal foundation models that integrate vision with complementary modalities suggests that morphomolecular coupling between local expression and morphology can be systematically used to improve histological representations themselves. We introduce Spatial Expression-Aligned Learning (SEAL), a vision-omics self-supervised learning framework that infuses localized molecular information into pathology vision encoders. Rather than training new encoders from scratch, SEAL is designed as a parameter-efficient vision-omics finetuning method that can be flexibly applied to widely used pathology foundation models. We instantiate SEAL by training on over 700,000 paired gene expression spot-tissue region examples spanning tumor and normal samples from 14 organs. Tested across 38 slide-level and 15 patch-level downstream tasks, SEAL provides a drop-in replacement for pathology foundation models that consistently improves performance over widely used vision-only and ST prediction baselines on slide-level molecular status, pathway activity, and treatment response prediction, as well as patch-level gene expression prediction tasks. Additionally, SEAL encoders exhibit robust domain generalization on out-of-distribution evaluations and enable new cross-modal capabilities such as gene-to-image retrieval. Our work proposes a general framework for ST-guided finetuning of pathology foundation models, showing that augmenting existing models with localized molecular supervision is an effective and practical step for improving visual representations and expanding their cross-modal utility.",
      "authors": [
        "Konstantin Hemker",
        "Andrew H. Song",
        "Cristina Almagro-Pérez",
        "Guillaume Jaume",
        "Sophia J. Wagner",
        "Anurag Vaidya",
        "Nikola Simidjievski",
        "Mateja Jamnik",
        "Faisal Mahmood"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-15 15:06:45+00:00",
      "link": "https://arxiv.org/pdf/2602.14177v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14174v1",
      "title": "Direction Matters: Learning Force Direction Enables Sim-to-Real Contact-Rich Manipulation",
      "abstract": "Sim-to-real transfer for contact-rich manipulation remains challenging due to the inherent discrepancy in contact dynamics. While existing methods often rely on costly real-world data or utilize blind compliance through fixed controllers, we propose a framework that leverages expert-designed controller logic for transfer. Inspired by the success of privileged supervision in kinematic tasks, we employ a human-designed finite state machine based position/force controller in simulation to provide privileged guidance. The resulting policy is trained to predict the end-effector pose, contact state, and crucially the desired contact force direction. Unlike force magnitudes, which are highly sensitive to simulation inaccuracies, force directions encode high-level task geometry and remain robust across the sim-to-real gap. At deployment, these predictions configure a force-aware admittance controller. By combining the policy's directional intent with a constant, low-cost manually tuned force magnitude, the system generates adaptive, task-aligned compliance. This tuning is lightweight, typically requiring only a single scalar per contact state. We provide theoretical analysis for stability and robustness to disturbances. Experiments on four real-world tasks, i.e., microwave opening, peg-in-hole, whiteboard wiping, and door opening, demonstrate that our approach significantly outperforms strong baselines in both success rate and robustness. Videos are available at: https://yifei-y.github.io/project-pages/DirectionMatters/.",
      "authors": [
        "Yifei Yang",
        "Anzhe Chen",
        "Zhenjie Zhu",
        "Kechun Xu",
        "Yunxuan Mao",
        "Yufei Wei",
        "Lu Chen",
        "Rong Xiong",
        "Yue Wang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-15 14:57:13+00:00",
      "link": "https://arxiv.org/pdf/2602.14174v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14172v2",
      "title": "Investigation for Relative Voice Impression Estimation",
      "abstract": "Paralinguistic and non-linguistic aspects of speech strongly influence listener impressions. While most research focuses on absolute impression scoring, this study investigates relative voice impression estimation (RIE), a framework for predicting the perceptual difference between two utterances from the same speaker. The estimation target is a low-dimensional vector derived from subjective evaluations, quantifying the perceptual shift of the second utterance relative to the first along an antonymic axis (e.g., ``Dark--Bright''). To isolate expressive and prosodic variation, we used recordings of a professional speaker reading a text in various styles. We compare three modeling approaches: classical acoustic features commonly used for speech emotion recognition, self-supervised speech representations, and multimodal large language models (MLLMs). Our results demonstrate that models using self-supervised representations outperform methods with classical acoustic features, particularly in capturing complex and dynamic impressions (e.g., ``Cold--Warm'') where classical features fail. In contrast, current MLLMs prove unreliable for this fine-grained pairwise task. This study provides the first systematic investigation of RIE and demonstrates the strength of self-supervised speech models in capturing subtle perceptual variations.",
      "authors": [
        "Kenichi Fujita",
        "Yusuke Ijima"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-15 14:54:52+00:00",
      "link": "https://arxiv.org/pdf/2602.14172v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14169v1",
      "title": "Deep Dense Exploration for LLM Reinforcement Learning via Pivot-Driven Resampling",
      "abstract": "Effective exploration is a key challenge in reinforcement learning for large language models: discovering high-quality trajectories within a limited sampling budget from the vast natural language sequence space. Existing methods face notable limitations: GRPO samples exclusively from the root, saturating high-probability trajectories while leaving deep, error-prone states under-explored. Tree-based methods blindly disperse budgets across trivial or unrecoverable states, causing sampling dilution that fails to uncover rare correct suffixes and destabilizes local baselines. To address this, we propose Deep Dense Exploration (DDE), a strategy that focuses exploration on $\\textit{pivots}$-deep, recoverable states within unsuccessful trajectories. We instantiate DDE with DEEP-GRPO, which introduces three key innovations: (1) a lightweight data-driven utility function that automatically balances recoverability and depth bias to identify pivot states; (2) local dense resampling at each pivot to increase the probability of discovering correct subsequent trajectories; and (3) a dual-stream optimization objective that decouples global policy learning from local corrective updates. Experiments on mathematical reasoning benchmarks demonstrate that our method consistently outperforms GRPO, tree-based methods, and other strong baselines.",
      "authors": [
        "Yiran Guo",
        "Zhongjian Qiao",
        "Yingqi Xie",
        "Jie Liu",
        "Dan Ye",
        "Ruiqing Zhang",
        "Shuang Qiu",
        "Lijie Xu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-15 14:44:15+00:00",
      "link": "https://arxiv.org/pdf/2602.14169v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14162v1",
      "title": "Index Light, Reason Deep: Deferred Visual Ingestion for Visual-Dense Document Question Answering",
      "abstract": "Existing multimodal document question answering methods universally adopt a supply-side ingestion strategy: running a Vision-Language Model (VLM) on every page during indexing to generate comprehensive descriptions, then answering questions through text retrieval. However, this \"pre-ingestion\" approach is costly (a 113-page engineering drawing package requires approximately 80,000 VLM tokens), end-to-end unreliable (VLM outputs may fail to be correctly retrieved due to format mismatches in the retrieval infrastructure), and irrecoverable once it fails. This paper proposes the Deferred Visual Ingestion (DVI) framework, adopting a demand-side ingestion strategy: the indexing phase performs only lightweight metadata extraction, deferring visual understanding to the moment users pose specific questions. DVI's core principle is \"Index for locating, not understanding\"--achieving page localization through structured metadata indexes and BM25 full-text search, then sending original images along with specific questions to a VLM for targeted analysis. Experiments on two real industrial engineering drawings (113 pages + 7 pages) demonstrate that DVI achieves comparable overall accuracy at zero ingestion VLM cost (46.7% vs. 48.9%), an effectiveness rate of 50% on visually necessary queries (vs. 0% for pre-ingestion), and 100% page localization (98% search space compression). DVI also supports interactive refinement and progressive caching, transforming the \"QA accuracy\" problem into a \"page localization\" problem--once the correct drawing page is found, obtaining the answer becomes a matter of interaction rounds.",
      "authors": [
        "Tao Xu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CV",
        "cs.IR"
      ],
      "published": "2026-02-15 14:23:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14162v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14161v1",
      "title": "When Benchmarks Lie: Evaluating Malicious Prompt Classifiers Under True Distribution Shift",
      "abstract": "Detecting prompt injection and jailbreak attacks is critical for deploying LLM-based agents safely. As agents increasingly process untrusted data from emails, documents, tool outputs, and external APIs, robust attack detection becomes essential. Yet current evaluation practices and production systems have fundamental limitations. We present a comprehensive analysis using a diverse benchmark of 18 datasets spanning harmful requests, jailbreaks, indirect prompt injections, and extraction attacks. We propose Leave-One-Dataset-Out (LODO) evaluation to measure true out-of-distribution generalization, revealing that the standard practice of train-test splits from the same dataset sources severely overestimates performance: aggregate metrics show an 8.4 percentage point AUC inflation, but per-dataset gaps range from 1% to 25% accuracy-exposing heterogeneous failure modes. To understand why classifiers fail to generalize, we analyze Sparse Auto-Encoder (SAE) feature coefficients across LODO folds, finding that 28% of top features are dataset-dependent shortcuts whose class signal depends on specific dataset compositions rather than semantic content. We systematically compare production guardrails (PromptGuard 2, LlamaGuard) and LLM-as-judge approaches on our benchmark, finding all three fail on indirect attacks targeting agents (7-37% detection) and that PromptGuard 2 and LlamaGuard cannot evaluate agentic tool injection due to architectural limitations. Finally, we show that LODO-stable SAE features provide more reliable explanations for classifier decisions by filtering dataset artifacts. We release our evaluation framework at https://github.com/maxf-zn/prompt-mining to establish LODO as the appropriate protocol for prompt attack detection research.",
      "authors": [
        "Max Fomin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-15 14:21:43+00:00",
      "link": "https://arxiv.org/pdf/2602.14161v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14160v1",
      "title": "Process-Supervised Multi-Agent Reinforcement Learning for Reliable Clinical Reasoning",
      "abstract": "Clinical decision-making requires nuanced reasoning over heterogeneous evidence and traceable justifications. While recent LLM multi-agent systems (MAS) show promise, they largely optimise for outcome accuracy while overlooking process-grounded reasoning aligned with clinical standards. One critical real-world case of this is gene-disease validity curation, where experts must determine whether a gene is causally implicated in a disease by synthesising diverse biomedical evidence. We introduce an agent-as-tool reinforcement learning framework for this task with two objectives: (i) process-level supervision to ensure reasoning follows valid clinical pathways, and (ii) efficient coordination via a hierarchical multi-agent system. Our evaluation on the ClinGen dataset shows that with outcome-only rewards, MAS with a GRPO-trained Qwen3-4B supervisor agent substantially improves final outcome accuracy from 0.195 with a base model supervisor to 0.732, but results in poor process alignment (0.392 F1). Conversely, with process + outcome rewards, MAS with GRPO-trained supervisor achieves higher outcome accuracy (0.750) while significantly improving process fidelity to 0.520 F1. Our code is available at https://github.com/chaeeunlee-io/GeneDiseaseCurationAgents.",
      "authors": [
        "Chaeeun Lee",
        "T. Michael Yates",
        "Pasquale Minervini",
        "T. Ian Simpson"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-15 14:21:21+00:00",
      "link": "https://arxiv.org/pdf/2602.14160v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14159v1",
      "title": "Synergistic Intra- and Cross-Layer Regularization Losses for MoE Expert Specialization",
      "abstract": "Sparse Mixture-of-Experts (MoE) models scale Transformers efficiently but suffer from expert overlap -- redundant representations across experts and routing ambiguity, resulting in severely underutilized model capacity. While architectural solutions like DeepSeekMoE promote specialization, they require substantial structural modifications and rely solely on intra-layer signals. In this paper, we propose two plug-and-play regularization losses that enhance MoE specialization and routing efficiency without modifying router or model architectures. First, an intra-layer specialization loss penalizes cosine similarity between experts' SwiGLU activations on identical tokens, encouraging experts to specialize in complementary knowledge. Second, a cross-layer coupling loss maximizes joint Top-$k$ routing probabilities across adjacent layers, establishing coherent expert pathways through network depth while reinforcing intra-layer expert specialization. Both losses are orthogonal to the standard load-balancing loss and compatible with both the shared-expert architecture in DeepSeekMoE and vanilla top-$k$ MoE architectures. We implement both losses as a drop-in Megatron-LM module. Extensive experiments across pre-training, fine-tuning, and zero-shot benchmarks demonstrate consistent task gains, higher expert specialization, and lower-entropy routing; together, these improvements translate into faster inference via more stable expert pathways.",
      "authors": [
        "Rizhen Hu",
        "Yuan Cao",
        "Boao Kong",
        "Mou Sun",
        "Kun Yuan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-15 14:19:12+00:00",
      "link": "https://arxiv.org/pdf/2602.14159v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14158v1",
      "title": "A Multi-Agent Framework for Medical AI: Leveraging Fine-Tuned GPT, LLaMA, and DeepSeek R1 for Evidence-Based and Bias-Aware Clinical Query Processing",
      "abstract": "Large language models (LLMs) show promise for healthcare question answering, but clinical use is limited by weak verification, insufficient evidence grounding, and unreliable confidence signalling. We propose a multi-agent medical QA framework that combines complementary LLMs with evidence retrieval, uncertainty estimation, and bias checks to improve answer reliability. Our approach has two phases. First, we fine-tune three representative LLM families (GPT, LLaMA, and DeepSeek R1) on MedQuAD-derived medical QA data (20k+ question-answer pairs across multiple NIH domains) and benchmark generation quality. DeepSeek R1 achieves the strongest scores (ROUGE-1 0.536 +- 0.04; ROUGE-2 0.226 +-0.03; BLEU 0.098 -+ 0.018) and substantially outperforms the specialised biomedical baseline BioGPT in zero-shot evaluation. Second, we implement a modular multi-agent pipeline in which a Clinical Reasoning agent (fine-tuned LLaMA) produces structured explanations, an Evidence Retrieval agent queries PubMed to ground responses in recent literature, and a Refinement agent (DeepSeek R1) improves clarity and factual consistency; an optional human validation path is triggered for high-risk or high-uncertainty cases. Safety mechanisms include Monte Carlo dropout and perplexity-based uncertainty scoring, plus lexical and sentiment-based bias detection supported by LIME/SHAP-based analyses. In evaluation, the full system achieves 87% accuracy with relevance around 0.80, and evidence augmentation reduces uncertainty (perplexity 4.13) compared to base responses, with mean end-to-end latency of 36.5 seconds under the reported configuration. Overall, the results indicate that agent specialisation and verification layers can mitigate key single-model limitations and provide a practical, extensible design for evidence-based and bias-aware medical AI.",
      "authors": [
        "Naeimeh Nourmohammadi",
        "Md Meem Hossain",
        "The Anh Han",
        "Safina Showkat Ara",
        "Zia Ush Shamszaman"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-02-15 14:17:27+00:00",
      "link": "https://arxiv.org/pdf/2602.14158v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14157v1",
      "title": "When Test-Time Guidance Is Enough: Fast Image and Video Editing with Diffusion Guidance",
      "abstract": "Text-driven image and video editing can be naturally cast as inpainting problems, where masked regions are reconstructed to remain consistent with both the observed content and the editing prompt. Recent advances in test-time guidance for diffusion and flow models provide a principled framework for this task; however, existing methods rely on costly vector--Jacobian product (VJP) computations to approximate the intractable guidance term, limiting their practical applicability. Building upon the recent work of Moufad et al. (2025), we provide theoretical insights into their VJP-free approximation and substantially extend their empirical evaluation to large-scale image and video editing benchmarks. Our results demonstrate that test-time guidance alone can achieve performance comparable to, and in some cases surpass, training-based methods.",
      "authors": [
        "Ahmed Ghorbel",
        "Badr Moufad",
        "Navid Bagheri Shouraki",
        "Alain Oliviero Durmus",
        "Thomas Hirtz",
        "Eric Moulines",
        "Jimmy Olsson",
        "Yazid Janati"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-15 14:13:25+00:00",
      "link": "https://arxiv.org/pdf/2602.14157v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14154v1",
      "title": "A Penalty Approach for Differentiation Through Black-Box Quadratic Programming Solvers",
      "abstract": "Differentiating through the solution of a quadratic program (QP) is a central problem in differentiable optimization. Most existing approaches differentiate through the Karush--Kuhn--Tucker (KKT) system, but their computational cost and numerical robustness can degrade at scale. To address these limitations, we propose dXPP, a penalty-based differentiation framework that decouples QP solving from differentiation. In the solving step (forward pass), dXPP is solver-agnostic and can leverage any black-box QP solver. In the differentiation step (backward pass), we map the solution to a smooth approximate penalty problem and implicitly differentiate through it, requiring only the solution of a much smaller linear system in the primal variables. This approach bypasses the difficulties inherent in explicit KKT differentiation and significantly improves computational efficiency and robustness. We evaluate dXPP on various tasks, including randomly generated QPs, large-scale sparse projection problems, and a real-world multi-period portfolio optimization task. Empirical results demonstrate that dXPP is competitive with KKT-based differentiation methods and achieves substantial speedups on large-scale problems.",
      "authors": [
        "Yuxuan Linghu",
        "Zhiyuan Liu",
        "Qi Deng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-02-15 14:05:36+00:00",
      "link": "https://arxiv.org/pdf/2602.14154v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14153v1",
      "title": "ARport: An Augmented Reality System for Markerless Image-Guided Port Placement in Robotic Surgery",
      "abstract": "Purpose: Precise port placement is a critical step in robot-assisted surgery, where port configuration influences both visual access to the operative field and instrument maneuverability. To bridge the gap between preoperative planning and intraoperative execution, we present ARport, an augmented reality (AR) system that automatically maps pre-planned trocar layouts onto the patient's body surface, providing intuitive spatial guidance during surgical preparation. Methods: ARport, implemented on an optical see-through head-mounted display (OST-HMD), operates without any external sensors or markers, simplifying setup and enhancing workflow integration. It reconstructs the operative scene from RGB, depth, and pose data captured by the OST-HMD, extracts the patient's body surface using a foundation model, and performs surface-based markerless registration to align preoperative anatomical models to the extracted patient's body surface, enabling in-situ visualization of planned trocar layouts. A demonstration video illustrating the overall workflow is available online. Results: In full-scale human-phantom experiments, ARport accurately overlaid pre-planned trocar sites onto the physical phantom, achieving consistent spatial correspondence between virtual plans and real anatomy. Conclusion: ARport provides a fully marker-free and hardware-minimal solution for visualizing preoperative trocar plans directly on the patient's body surface. The system facilitates efficient intraoperative setup and demonstrates potential for seamless integration into routine clinical workflows.",
      "authors": [
        "Zheng Han",
        "Zixin Yang",
        "Yonghao Long",
        "Lin Zhang",
        "Peter Kazanzides",
        "Qi Dou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 13:57:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14153v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14147v1",
      "title": "LaViDa-R1: Advancing Reasoning for Unified Multimodal Diffusion Language Models",
      "abstract": "Diffusion language models (dLLMs) recently emerged as a promising alternative to auto-regressive LLMs. The latest works further extended it to multimodal understanding and generation tasks. In this work, we propose LaViDa-R1, a multimodal, general-purpose reasoning dLLM. Unlike existing works that build reasoning dLLMs through task-specific reinforcement learning, LaViDa-R1 incorporates diverse multimodal understanding and generation tasks in a unified manner. In particular, LaViDa-R1 is built with a novel unified post-training framework that seamlessly integrates supervised finetuning (SFT) and multi-task reinforcement learning (RL). It employs several novel training techniques, including answer-forcing, tree search, and complementary likelihood estimation, to enhance effectiveness and scalability. Extensive experiments demonstrate LaViDa-R1's strong performance on a wide range of multimodal tasks, including visual math reasoning, reason-intensive grounding, and image editing.",
      "authors": [
        "Shufan Li",
        "Yuchen Zhu",
        "Jiuxiang Gu",
        "Kangning Liu",
        "Zhe Lin",
        "Yongxin Chen",
        "Molei Tao",
        "Aditya Grover",
        "Jason Kuen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 13:52:45+00:00",
      "link": "https://arxiv.org/pdf/2602.14147v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14143v1",
      "title": "ROAST: Rollout-based On-distribution Activation Steering Technique",
      "abstract": "Activation steering provides parameter-efficient control over large language models (LLMs) at inference time, but many methods rely on off-distribution supervision and discrete masking, leading to brittle interventions. We propose ROAST (Rollout-based On-distribution Activation Steering Technique), which estimates steering directions from the model's own on-distribution rollouts via ROC and avoids hard sparsification via Continuous Soft Scaling (CSS) and Grouped Mean Normalization. Our empirical analysis reveals that while activation magnitude correlates moderately with directional consistency, the variance in magnitude is significant and often disproportionate to semantic quality. This suggests that high-magnitude activations risk dominating the global steering direction if not properly normalized. To address this, ROAST employs grouped normalization to balance contributions across samples, ensuring a more robust estimation of the consensus steering direction. Across models (0.6B to 32B), ROAST consistently improves performance on diverse tasks (e.g., +9.7% on GSM8K for Qwen3-0.6B and +12.1% on TruthfulQA for GLM4-32B), and analyses show that CSS better preserves activation energy.",
      "authors": [
        "Xuanbo Su",
        "Hao Luo",
        "Yingfang Zhang",
        "Lijun Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-15 13:30:26+00:00",
      "link": "https://arxiv.org/pdf/2602.14143v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14140v1",
      "title": "Detection of On-Ground Chestnuts Using Artificial Intelligence Toward Automated Picking",
      "abstract": "Traditional mechanized chestnut harvesting is too costly for small producers, non-selective, and prone to damaging nuts. Accurate, reliable detection of chestnuts on the orchard floor is crucial for developing low-cost, vision-guided automated harvesting technology. However, developing a reliable chestnut detection system faces challenges in complex environments with shading, varying natural light conditions, and interference from weeds, fallen leaves, stones, and other foreign on-ground objects, which have remained unaddressed. This study collected 319 images of chestnuts on the orchard floor, containing 6524 annotated chestnuts. A comprehensive set of 29 state-of-the-art real-time object detectors, including 14 in the YOLO (v11-13) and 15 in the RT-DETR (v1-v4) families at varied model scales, was systematically evaluated through replicated modeling experiments for chestnut detection. Experimental results show that the YOLOv12m model achieves the best mAP@0.5 of 95.1% among all the evaluated models, while the RT-DETRv2-R101 was the most accurate variant among RT-DETR models, with mAP@0.5 of 91.1%. In terms of mAP@[0.5:0.95], the YOLOv11x model achieved the best accuracy of 80.1%. All models demonstrate significant potential for real-time chestnut detection, and YOLO models outperformed RT-DETR models in terms of both detection accuracy and inference, making them better suited for on-board deployment. Both the dataset and software programs in this study have been made publicly available at https://github.com/AgFood-Sensing-and-Intelligence-Lab/ChestnutDetection.",
      "authors": [
        "Kaixuan Fang",
        "Yuzhen Lu",
        "Xinyang Mu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-15 13:28:23+00:00",
      "link": "https://arxiv.org/pdf/2602.14140v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14135v2",
      "title": "ForesightSafety Bench: A Frontier Risk Evaluation and Governance Framework towards Safe AI",
      "abstract": "Rapidly evolving AI exhibits increasingly strong autonomy and goal-directed capabilities, accompanied by derivative systemic risks that are more unpredictable, difficult to control, and potentially irreversible. However, current AI safety evaluation systems suffer from critical limitations such as restricted risk dimensions and failed frontier risk detection. The lagging safety benchmarks and alignment technologies can hardly address the complex challenges posed by cutting-edge AI models. To bridge this gap, we propose the \"ForesightSafety Bench\" AI Safety Evaluation Framework, beginning with 7 major Fundamental Safety pillars and progressively extends to advanced Embodied AI Safety, AI4Science Safety, Social and Environmental AI risks, Catastrophic and Existential Risks, as well as 8 critical industrial safety domains, forming a total of 94 refined risk dimensions. To date, the benchmark has accumulated tens of thousands of structured risk data points and assessment results, establishing a widely encompassing, hierarchically clear, and dynamically evolving AI safety evaluation framework. Based on this benchmark, we conduct systematic evaluation and in-depth analysis of over twenty mainstream advanced large models, identifying key risk patterns and their capability boundaries. The safety capability evaluation results reveals the widespread safety vulnerabilities of frontier AI across multiple pillars, particularly focusing on Risky Agentic Autonomy, AI4Science Safety, Embodied AI Safety, Social AI Safety and Catastrophic and Existential Risks. Our benchmark is released at https://github.com/Beijing-AISI/ForesightSafety-Bench. The project website is available at https://foresightsafety-bench.beijing-aisi.ac.cn/.",
      "authors": [
        "Haibo Tong",
        "Feifei Zhao",
        "Linghao Feng",
        "Ruoyu Wu",
        "Ruolin Chen",
        "Lu Jia",
        "Zhou Zhao",
        "Jindong Li",
        "Tenglong Li",
        "Erliang Lin",
        "Shuai Yang",
        "Enmeng Lu",
        "Yinqian Sun",
        "Qian Zhang",
        "Zizhe Ruan",
        "Jinyu Fan",
        "Zeyang Yue",
        "Ping Wu",
        "Huangrui Li",
        "Chengyi Sun",
        "Yi Zeng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.CY"
      ],
      "published": "2026-02-15 13:12:44+00:00",
      "link": "https://arxiv.org/pdf/2602.14135v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14127v1",
      "title": "MUKA: Multi Kernel Audio Adaptation Of Audio-Language Models",
      "abstract": "Multimodal foundation models have demonstrated impressive generalization capabilities, yet efficiently adapting them to new tasks in a few-shot setting remains a critical challenge. In this work, we investigate the few-shot adaptation of Large Audio-Language Models (ALMs) through both training-based and training-free approaches. We introduce MUKA, a multi-kernel adaptation framework that combines the fine-grained, context-dependent representations of instruction-tuning based models like Pengi with the global semantic representations of contrastive pretraining methods like CLAP. By constructing a product kernel that aligns local similarity with global semantics, MUKA enhances representational power while preserving the theoretical guarantees of kernel methods and avoiding additional training. Extensive experiments across 11 diverse audio datasets demonstrate that MUKA achieves state-of-the-art performance among training-free methods and even surpasses training-based adapters in several scenarios, offering a compelling balance between adaptability and efficiency.",
      "authors": [
        "Reda Bensaid",
        "Amine Ouasfi",
        "Yassir Bendou",
        "Ilyass Moummad",
        "Vincent Gripon",
        "François Leduc-Primeau",
        "Adnane Boukhayma"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD"
      ],
      "published": "2026-02-15 13:01:07+00:00",
      "link": "https://arxiv.org/pdf/2602.14127v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14110v1",
      "title": "MixFormer: Co-Scaling Up Dense and Sequence in Industrial Recommenders",
      "abstract": "As industrial recommender systems enter a scaling-driven regime, Transformer architectures have become increasingly attractive for scaling models towards larger capacity and longer sequence. However, existing Transformer-based recommendation models remain structurally fragmented, where sequence modeling and feature interaction are implemented as separate modules with independent parameterization. Such designs introduce a fundamental co-scaling challenge, as model capacity must be suboptimally allocated between dense feature interaction and sequence modeling under a limited computational budget. In this work, we propose MixFormer, a unified Transformer-style architecture tailored for recommender systems, which jointly models sequential behaviors and feature interactions within a single backbone. Through a unified parameterization, MixFormer enables effective co-scaling across both dense capacity and sequence length, mitigating the trade-off observed in decoupled designs. Moreover, the integrated architecture facilitates deep interaction between sequential and non-sequential representations, allowing high-order feature semantics to directly inform sequence aggregation and enhancing overall expressiveness. To ensure industrial practicality, we further introduce a user-item decoupling strategy for efficiency optimizations that significantly reduce redundant computation and inference latency. Extensive experiments on large-scale industrial datasets demonstrate that MixFormer consistently exhibits superior accuracy and efficiency. Furthermore, large-scale online A/B tests on two production recommender systems, Douyin and Douyin Lite, show consistent improvements in user engagement metrics, including active days and in-app usage duration.",
      "authors": [
        "Xu Huang",
        "Hao Zhang",
        "Zhifang Fan",
        "Yunwen Huang",
        "Zhuoxing Wei",
        "Zheng Chai",
        "Jinan Ni",
        "Yuchao Zheng",
        "Qiwei Chen"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-15 11:53:30+00:00",
      "link": "https://arxiv.org/pdf/2602.14110v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14108v1",
      "title": "Geometry-Aware Physics-Informed PointNets for Modeling Flows Across Porous Structures",
      "abstract": "Predicting flows that occur both through and around porous bodies is challenging due to coupled physics across fluid and porous regions and the need to generalize across diverse geometries and boundary conditions. We address this problem using two Physics Informed learning approaches: Physics Informed PointNets (PIPN) and Physics Informed Geometry Aware Neural Operator (P-IGANO). We enforce the incompressible Navier Stokes equations in the free-flow region and a Darcy Forchheimer extension in the porous region within a unified loss and condition the networks on geometry and material parameters. Datasets are generated with OpenFOAM on 2D ducts containing porous obstacles and on 3D windbreak scenarios with tree canopies and buildings. We first verify the pipeline via the method of manufactured solutions, then assess generalization to unseen shapes, and for PI-GANO, to variable boundary conditions and parameter settings. The results show consistently low velocity and pressure errors in both seen and unseen cases, with accurate reproduction of the wake structures. Performance degrades primarily near sharp interfaces and in regions with large gradients. Overall, the study provides a first systematic evaluation of PIPN/PI-GANO for simultaneous through-and-around porous flows and shows their potential to accelerate design studies without retraining per geometry.",
      "authors": [
        "Luigi Ciceri",
        "Corrado Mio",
        "Jianyi Lin",
        "Gabriele Gianini"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.flu-dyn"
      ],
      "published": "2026-02-15 11:52:23+00:00",
      "link": "https://arxiv.org/pdf/2602.14108v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14102v1",
      "title": "DALL: Data Labeling via Data Programming and Active Learning Enhanced by Large Language Models",
      "abstract": "Deep learning models for natural language processing rely heavily on high-quality labeled datasets. However, existing labeling approaches often struggle to balance label quality with labeling cost. To address this challenge, we propose DALL, a text labeling framework that integrates data programming, active learning, and large language models. DALL introduces a structured specification that allows users and large language models to define labeling functions via configuration, rather than code. Active learning identifies informative instances for review, and the large language model analyzes these instances to help users correct labels and to refine or suggest labeling functions. We implement DALL as an interactive labeling system for text labeling tasks. Comparative, ablation, and usability studies demonstrate DALL's efficiency, the effectiveness of its modules, and its usability.",
      "authors": [
        "Guozheng Li",
        "Ao Wang",
        "Shaoxiang Wang",
        "Yu Zhang",
        "Pengcheng Cao",
        "Yang Bai",
        "Chi Harold Liu"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-15 11:36:15+00:00",
      "link": "https://arxiv.org/pdf/2602.14102v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14099v1",
      "title": "SemanticFeels: Semantic Labeling during In-Hand Manipulation",
      "abstract": "As robots become increasingly integrated into everyday tasks, their ability to perceive both the shape and properties of objects during in-hand manipulation becomes critical for adaptive and intelligent behavior. We present SemanticFeels, an extension of the NeuralFeels framework that integrates semantic labeling with neural implicit shape representation, from vision and touch. To illustrate its application, we focus on material classification: high-resolution Digit tactile readings are processed by a fine-tuned EfficientNet-B0 convolutional neural network (CNN) to generate local material predictions, which are then embedded into an augmented signed distance field (SDF) network that jointly predicts geometry and continuous material regions. Experimental results show that the system achieves a high correspondence between predicted and actual materials on both single- and multi-material objects, with an average matching accuracy of 79.87% across multiple manipulation trials on a multi-material object.",
      "authors": [
        "Anas Al Shikh Khalil",
        "Haozhi Qi",
        "Roberto Calandra"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-15 11:22:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14099v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14098v1",
      "title": "ForgeryVCR: Visual-Centric Reasoning via Efficient Forensic Tools in MLLMs for Image Forgery Detection and Localization",
      "abstract": "Existing Multimodal Large Language Models (MLLMs) for image forgery detection and localization predominantly operate under a text-centric Chain-of-Thought (CoT) paradigm. However, forcing these models to textually characterize imperceptible low-level tampering traces inevitably leads to hallucinations, as linguistic modalities are insufficient to capture such fine-grained pixel-level inconsistencies. To overcome this, we propose ForgeryVCR, a framework that incorporates a forensic toolbox to materialize imperceptible traces into explicit visual intermediates via Visual-Centric Reasoning. To enable efficient tool utilization, we introduce a Strategic Tool Learning post-training paradigm, encompassing gain-driven trajectory construction for Supervised Fine-Tuning (SFT) and subsequent Reinforcement Learning (RL) optimization guided by a tool utility reward. This paradigm empowers the MLLM to act as a proactive decision-maker, learning to spontaneously invoke multi-view reasoning paths including local zoom-in for fine-grained inspection and the analysis of invisible inconsistencies in compression history, noise residuals, and frequency domains. Extensive experiments reveal that ForgeryVCR achieves state-of-the-art (SOTA) performance in both detection and localization tasks, demonstrating superior generalization and robustness with minimal tool redundancy. The project page is available at https://youqiwong.github.io/projects/ForgeryVCR/.",
      "authors": [
        "Youqi Wang",
        "Shen Chen",
        "Haowei Wang",
        "Rongxuan Peng",
        "Taiping Yao",
        "Shunquan Tan",
        "Changsheng Chen",
        "Bin Li",
        "Shouhong Ding"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 11:14:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14098v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14089v1",
      "title": "TabTracer: Monte Carlo Tree Search for Complex Table Reasoning with Large Language Models",
      "abstract": "Large language models (LLMs) have emerged as powerful tools for natural language table reasoning, where there are two main categories of methods. Prompt-based approaches rely on language-only inference or one-pass program generation without step-level verification. Agent-based approaches use tools in a closed loop, but verification is often local and backtracking is limited, allowing errors to propagate and increasing cost. Moreover, they rely on chain- or beam-style trajectories that are typically combinatorially redundant, leading to high token costs. In this paper, we propose TabTracer, an agentic framework that coordinates multi-step tool calls over intermediate table states, with explicit state tracking for verification and rollback. First, it enforces step-level verification with typed operations and lightweight numeric and format checks to provide reliable rewards and suppress hallucinations. Second, execution-feedback Monte Carlo Tree Search maintains a search tree of candidate table states and uses backpropagated reflection scores to guide UCB1 selection and rollback via versioned snapshots. Third, it reduces redundancy with budget-aware pruning, deduplication, and state hashing with a monotonicity gate to cut token cost. Comprehensive evaluation on TabFact, WikiTQ, and CRT datasets shows that TabTracer outperforms state-of-the-art baselines by up to 6.7% in accuracy while reducing token consumption by 59--84%.",
      "authors": [
        "Zhizhao Luo",
        "Zhaojing Luo",
        "Meihui Zhang",
        "Rui Mao"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "published": "2026-02-15 10:39:43+00:00",
      "link": "https://arxiv.org/pdf/2602.14089v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14086v1",
      "title": "Neural Optimal Transport in Hilbert Spaces: Characterizing Spurious Solutions and Gaussian Smoothing",
      "abstract": "We study Neural Optimal Transport in infinite-dimensional Hilbert spaces. In non-regular settings, Semi-dual Neural OT often generates spurious solutions that fail to accurately capture target distributions. We analytically characterize this spurious solution problem using the framework of regular measures, which generalize Lebesgue absolute continuity in finite dimensions. To resolve ill-posedness, we extend the semi-dual framework via a Gaussian smoothing strategy based on Brownian motion. Our primary theoretical contribution proves that under a regular source measure, the formulation is well-posed and recovers a unique Monge map. Furthermore, we establish a sharp characterization for the regularity of smoothed measures, proving that the success of smoothing depends strictly on the kernel of the covariance operator. Empirical results on synthetic functional data and time-series datasets demonstrate that our approach effectively suppresses spurious solutions and outperforms existing baselines.",
      "authors": [
        "Jae-Hwan Choi",
        "Jiwoo Yoon",
        "Dohyun Kwon",
        "Jaewoong Choi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-15 10:27:09+00:00",
      "link": "https://arxiv.org/pdf/2602.14086v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14083v1",
      "title": "Plan-MCTS: Plan Exploration for Action Exploitation in Web Navigation",
      "abstract": "Large Language Models (LLMs) have empowered autonomous agents to handle complex web navigation tasks. While recent studies integrate tree search to enhance long-horizon reasoning, applying these algorithms in web navigation faces two critical challenges: sparse valid paths that lead to inefficient exploration, and a noisy context that dilutes accurate state perception. To address this, we introduce Plan-MCTS, a framework that reformulates web navigation by shifting exploration to a semantic Plan Space. By decoupling strategic planning from execution grounding, it transforms sparse action space into a Dense Plan Tree for efficient exploration, and distills noisy contexts into an Abstracted Semantic History for precise state awareness. To ensure efficiency and robustness, Plan-MCTS incorporates a Dual-Gating Reward to strictly validate both physical executability and strategic alignment and Structural Refinement for on-policy repair of failed subplans. Extensive experiments on WebArena demonstrate that Plan-MCTS achieves state-of-the-art performance, surpassing current approaches with higher task effectiveness and search efficiency.",
      "authors": [
        "Weiming Zhang",
        "Jihong Wang",
        "Jiamu Zhou",
        "Qingyao Li",
        "Xinbei Ma",
        "Congmin Zheng",
        "Xingyu Lou",
        "Weiwen Liu",
        "Zhuosheng Zhang",
        "Jun Wang",
        "Yong Yu",
        "Weinan Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-15 10:24:45+00:00",
      "link": "https://arxiv.org/pdf/2602.14083v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14078v1",
      "title": "Policy Gradient with Adaptive Entropy Annealing for Continual Fine-Tuning",
      "abstract": "Despite their success, large pretrained vision models remain vulnerable to catastrophic forgetting when adapted to new tasks in class-incremental settings. Parameter-efficient fine-tuning (PEFT) alleviates this by restricting trainable parameters, yet most approaches still rely on cross-entropy (CE) loss, a surrogate for the 0-1 loss, to learn from new data. We revisit this choice and revive the true objective (0-1 loss) through a reinforcement learning perspective. By formulating classification as a one-step Markov Decision Process, we derive an Expected Policy Gradient (EPG) method that directly minimizes misclassification error with a low-variance gradient estimation. Our analysis shows that CE can be interpreted as EPG with an additional sample-weighting mechanism: CE encourages exploration by emphasizing low-confidence samples, while EPG prioritizes high-confidence ones. Building on this insight, we propose adaptive entropy annealing (aEPG), a training strategy that transitions from exploratory (CE-like) to exploitative (EPG-like) learning. aEPG-based methods outperform CE-based methods across diverse benchmarks and with various PEFT modules. More broadly, we evaluate various entropy regularization methods and demonstrate that lower entropy of the output prediction distribution enhances adaptation in pretrained vision models.",
      "authors": [
        "Yaqian Zhang",
        "Bernhard Pfahringer",
        "Eibe Frank",
        "Albert Bifet"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 10:05:03+00:00",
      "link": "https://arxiv.org/pdf/2602.14078v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14071v1",
      "title": "Bidirectional Temporal Dynamics Modeling for EEG-based Driving Fatigue Recognition",
      "abstract": "Driving fatigue is a major contributor to traffic accidents and poses a serious threat to road safety. Electroencephalography (EEG) provides a direct measurement of neural activity, yet EEG-based fatigue recognition is hindered by strong non-stationarity and asymmetric neural dynamics. To address these challenges, we propose DeltaGateNet, a novel framework that explicitly captures Bidirectional temporal dynamics for EEG-based driving fatigue recognition. Our key idea is to introduce a Bidirectional Delta module that decomposes first-order temporal differences into positive and negative components, enabling explicit modeling of asymmetric neural activation and suppression patterns. Furthermore, we design a Gated Temporal Convolution module to capture long-term temporal dependencies for each EEG channel using depthwise temporal convolutions and residual learning, preserving channel-wise specificity while enhancing temporal representation robustness. Extensive experiments conducted under both intra-subject and inter-subject evaluation settings on the public SEED-VIG and SADT driving fatigue datasets demonstrate that DeltaGateNet consistently outperforms existing methods. On SEED-VIG, DeltaGateNet achieves an intra-subject accuracy of 81.89% and an inter-subject accuracy of 55.55%. On the balanced SADT 2022 dataset, it attains intra-subject and inter-subject accuracies of 96.81% and 83.21%, respectively, while on the unbalanced SADT 2952 dataset, it achieves 96.84% intra-subject and 84.49% inter-subject accuracy. These results indicate that explicitly modeling Bidirectional temporal dynamics yields robust and generalizable performance under varying subject and class-distribution conditions.",
      "authors": [
        "YipTin Po",
        "Jianming Wang",
        "Yutao Miao",
        "Jiayan Zhang",
        "Yunxu Zhao",
        "Xiaomin Ouyang",
        "Zhihong Li",
        "Nevin L. Zhang"
      ],
      "primary_category": "cs.OH",
      "categories": [
        "cs.OH",
        "cs.CV"
      ],
      "published": "2026-02-15 09:42:25+00:00",
      "link": "https://arxiv.org/pdf/2602.14071v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14068v1",
      "title": "CoCoEdit: Content-Consistent Image Editing via Region Regularized Reinforcement Learning",
      "abstract": "Image editing has achieved impressive results with the development of large-scale generative models. However, existing models mainly focus on the editing effects of intended objects and regions, often leading to unwanted changes in unintended regions. We present a post-training framework for Content-Consistent Editing (CoCoEdit) via region regularized reinforcement learning. We first augment existing editing datasets with refined instructions and masks, from which 40K diverse and high quality samples are curated as training set. We then introduce a pixel-level similarity reward to complement MLLM-based rewards, enabling models to ensure both editing quality and content consistency during the editing process. To overcome the spatial-agnostic nature of the rewards, we propose a region-based regularizer, aiming to preserve non-edited regions for high-reward samples while encouraging editing effects for low-reward samples. For evaluation, we annotate editing masks for GEdit-Bench and ImgEdit-Bench, introducing pixel-level similarity metrics to measure content consistency and editing quality. Applying CoCoEdit to Qwen-Image-Edit and FLUX-Kontext, we achieve not only competitive editing scores with state-of-the-art models, but also significantly better content consistency, measured by PSNR/SSIM metrics and human subjective ratings.",
      "authors": [
        "Yuhui Wu",
        "Chenxi Xie",
        "Ruibin Li",
        "Liyi Chen",
        "Qiaosi Yi",
        "Lei Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 09:36:54+00:00",
      "link": "https://arxiv.org/pdf/2602.14068v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14060v1",
      "title": "LM-Lexicon: Improving Definition Modeling via Harmonizing Semantic Experts",
      "abstract": "We introduce LM-Lexicon, an innovative definition modeling approach that incorporates data clustering, semantic expert learning, and model merging using a sparse mixture-of-experts architecture. By decomposing the definition modeling task into specialized semantic domains, where small language models are trained as domain experts, LM-Lexicon achieves substantial improvements (+7% BLEU score compared with the prior state-of-the-art model) over existing methods on five widely used benchmarks. Empirically, we demonstrate that 1) the clustering strategy enables fine-grained expert specialization with nearly 10% improvement in definition quality; 2) the semantic-aware domain-level routing mechanism achieves higher expert efficacy (+1%) than conventional token-level routing; and 3) further performance gains can be obtained through test-time compute and semantic expert scaling. Our work advances definition modeling while providing insights into the development of efficient language models for semantic-intensive applications.",
      "authors": [
        "Yang Liu",
        "Jiaye Yang",
        "Weikang Li",
        "Jiahui Liang",
        "Yang Li",
        "Lingyong Yan"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-15 09:18:22+00:00",
      "link": "https://arxiv.org/pdf/2602.14060v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14040v1",
      "title": "Explainability-Inspired Layer-Wise Pruning of Deep Neural Networks for Efficient Object Detection",
      "abstract": "Deep neural networks (DNNs) have achieved remarkable success in object detection tasks, but their increasing complexity poses significant challenges for deployment on resource-constrained platforms. While model compression techniques such as pruning have emerged as essential tools, traditional magnitude-based pruning methods do not necessarily align with the true functional contribution of network components to task-specific performance. In this work, we present an explainability-inspired, layer-wise pruning framework tailored for efficient object detection. Our approach leverages a SHAP-inspired gradient--activation attribution to estimate layer importance, providing a data-driven proxy for functional contribution rather than relying solely on static weight magnitudes. We conduct comprehensive experiments across diverse object detection architectures, including ResNet-50, MobileNetV2, ShuffleNetV2, Faster R-CNN, RetinaNet, and YOLOv8, evaluating performance on the Microsoft COCO 2017 validation set. The results show that the proposed attribution-inspired pruning consistently identifies different layers as least important compared to L1-norm-based methods, leading to improved accuracy--efficiency trade-offs. Notably, for ShuffleNetV2, our method yields a 10\\% empirical increase in inference speed, whereas L1-pruning degrades performance by 13.7\\%. For RetinaNet, the proposed approach preserves the baseline mAP (0.151) with negligible impact on inference speed, while L1-pruning incurs a 1.3\\% mAP drop for a 6.2\\% speed increase. These findings highlight the importance of data-driven layer importance assessment and demonstrate that explainability-inspired compression offers a principled direction for deploying deep neural networks on edge and resource-constrained platforms while preserving both performance and interpretability.",
      "authors": [
        "Abhinav Shukla",
        "Nachiket Tapas"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 08:07:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14040v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14035v1",
      "title": "FloCA: Towards Faithful and Logically Consistent Flowchart Reasoning",
      "abstract": "Flowchart-oriented dialogue (FOD) systems aim to guide users through multi-turn decision-making or operational procedures by following a domain-specific flowchart to achieve a task goal. In this work, we formalize flowchart reasoning in FOD as grounding user input to flowchart nodes at each dialogue turn while ensuring node transition is consistent with the correct flowchart path. Despite recent advances of LLMs in task-oriented dialogue systems, adapting them to FOD still faces two limitations: (1) LLMs lack an explicit mechanism to represent and reason over flowchart topology, and (2) they are prone to hallucinations, leading to unfaithful flowchart reasoning. To address these limitations, we propose FloCA, a zero-shot flowchart-oriented conversational agent. FloCA uses an LLM for intent understanding and response generation while delegating flowchart reasoning to an external tool that performs topology-constrained graph execution, ensuring faithful and logically consistent node transitions across dialogue turns. We further introduce an evaluation framework with an LLM-based user simulator and five new metrics covering reasoning accuracy and interaction efficiency. Extensive experiments on FLODIAL and PFDial datasets highlight the bottlenecks of existing LLM-based methods and demonstrate the superiority of FloCA. Our codes are available at https://github.com/Jinzi-Zou/FloCA-flowchart-reasoning.",
      "authors": [
        "Jinzi Zou",
        "Bolin Wang",
        "Liang Li",
        "Shuo Zhang",
        "Nuo Xu",
        "Junzhou Zhao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-15 07:51:27+00:00",
      "link": "https://arxiv.org/pdf/2602.14035v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14033v1",
      "title": "BRAIN: Bayesian Reasoning via Active Inference for Agentic and Embodied Intelligence in Mobile Networks",
      "abstract": "Future sixth-generation (6G) mobile networks will demand artificial intelligence (AI) agents that are not only autonomous and efficient, but also capable of real-time adaptation in dynamic environments and transparent in their decisionmaking. However, prevailing agentic AI approaches in networking, exhibit significant shortcomings in this regard. Conventional deep reinforcement learning (DRL)-based agents lack explainability and often suffer from brittle adaptation, including catastrophic forgetting of past knowledge under non-stationary conditions. In this paper, we propose an alternative solution for these challenges: Bayesian reasoning via Active Inference (BRAIN) agent. BRAIN harnesses a deep generative model of the network environment and minimizes variational free energy to unify perception and action in a single closed-loop paradigm. We implement BRAIN as O-RAN eXtended application (xApp) on GPU-accelerated testbed and demonstrate its advantages over standard DRL baselines. In our experiments, BRAIN exhibits (i) robust causal reasoning for dynamic radio resource allocation, maintaining slice-specific quality of service (QoS) targets (throughput, latency, reliability) under varying traffic loads, (ii) superior adaptability with up to 28.3% higher robustness to sudden traffic shifts versus benchmarks (achieved without any retraining), and (iii) real-time interpretability of its decisions through human-interpretable belief state diagnostics.",
      "authors": [
        "Osman Tugay Basaran",
        "Martin Maier",
        "Falko Dressler"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-02-15 07:47:09+00:00",
      "link": "https://arxiv.org/pdf/2602.14033v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14029v1",
      "title": "Why Self-Training Helps and Hurts: Denoising vs. Signal Forgetting",
      "abstract": "Iterative self-training (self-distillation) repeatedly refits a model on pseudo-labels generated by its own predictions. We study this procedure in overparameterized linear regression: an initial estimator is trained on noisy labels, and each subsequent iterate is trained on fresh covariates with noiseless pseudo-labels from the previous model. In the high-dimensional regime, we derive deterministic-equivalent recursions for the prediction risk and effective noise across iterations, and prove that the empirical quantities concentrate sharply around these limits. The recursion separates two competing forces: a systematic component that grows with iteration due to progressive signal forgetting, and a stochastic component that decays due to denoising via repeated data-dependent projections. Their interaction yields a $U$-shaped test-risk curve and an optimal early-stopping time. In spiked covariance models, iteration further acts as an iteration-dependent spectral filter that preserves strong eigendirections while suppressing weaker ones, inducing an implicit form of soft feature selection distinct from ridge regression. Finally, we propose an iterated generalized cross-validation criterion and prove its uniform consistency for estimating the risk along the self-training trajectory, enabling fully data-driven selection of the stopping time and regularization. Experiments on synthetic covariances validate the theory and illustrate the predicted denoising-forgetting trade-off.",
      "authors": [
        "Mingqi Wu",
        "Archer Y. Yang",
        "Qiang Sun"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST"
      ],
      "published": "2026-02-15 07:28:12+00:00",
      "link": "https://arxiv.org/pdf/2602.14029v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14024v1",
      "title": "EIDOS: Latent-Space Predictive Learning for Time Series Foundation Models",
      "abstract": "Most time series foundation models are pretrained by directly predicting future observations, which often yields weakly structured latent representations that capture surface noise rather than coherent and predictable temporal dynamics. In this work, we introduce EIDOS, a foundation model family that shifts pretraining from future value prediction to latent-space predictive learning. We train a causal Transformer to predict the evolution of latent representations, encouraging the emergence of structured and temporally coherent latent states. To ensure stable targets for latent-space learning, we design a lightweight aggregation branch to construct target representations. EIDOS is optimized via a joint objective that integrates latent-space alignment, observational grounding to anchor representations to the input signal, and direct forecasting supervision. On the GIFT-Eval benchmark, EIDOS mitigates structural fragmentation in the representation space and achieves state-of-the-art performance. These results demonstrate that constraining models to learn predictable latent dynamics is a principled step toward more robust and reliable time series foundation models.",
      "authors": [
        "Xinxing Zhou",
        "Qingren Yao",
        "Yiji Zhao",
        "Chenghao Liu",
        "Flora Salim",
        "Xiaojie Yuan",
        "Yanlong Wen",
        "Ming Jin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 07:07:20+00:00",
      "link": "https://arxiv.org/pdf/2602.14024v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14021v1",
      "title": "Flow4R: Unifying 4D Reconstruction and Tracking with Scene Flow",
      "abstract": "Reconstructing and tracking dynamic 3D scenes remains a fundamental challenge in computer vision. Existing approaches often decouple geometry from motion: multi-view reconstruction methods assume static scenes, while dynamic tracking frameworks rely on explicit camera pose estimation or separate motion models. We propose Flow4R, a unified framework that treats camera-space scene flow as the central representation linking 3D structure, object motion, and camera motion. Flow4R predicts a minimal per-pixel property set-3D point position, scene flow, pose weight, and confidence-from two-view inputs using a Vision Transformer. This flow-centric formulation allows local geometry and bidirectional motion to be inferred symmetrically with a shared decoder in a single forward pass, without requiring explicit pose regressors or bundle adjustment. Trained jointly on static and dynamic datasets, Flow4R achieves state-of-the-art performance on 4D reconstruction and tracking tasks, demonstrating the effectiveness of the flow-central representation for spatiotemporal scene understanding.",
      "authors": [
        "Shenhan Qian",
        "Ganlin Zhang",
        "Shangzhe Wu",
        "Daniel Cremers"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 06:58:08+00:00",
      "link": "https://arxiv.org/pdf/2602.14021v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14009v1",
      "title": "Named Entity Recognition for Payment Data Using NLP",
      "abstract": "Named Entity Recognition (NER) has emerged as a critical component in automating financial transaction processing, particularly in extracting structured information from unstructured payment data. This paper presents a comprehensive analysis of state-of-the-art NER algorithms specifically designed for payment data extraction, including Conditional Random Fields (CRF), Bidirectional Long Short-Term Memory with CRF (BiLSTM-CRF), and transformer-based models such as BERT and FinBERT. We conduct extensive experiments on a dataset of 50,000 annotated payment transactions across multiple payment formats including SWIFT MT103, ISO 20022, and domestic payment systems. Our experimental results demonstrate that fine-tuned BERT models achieve an F1-score of 94.2% for entity extraction, outperforming traditional CRF-based approaches by 12.8 percentage points. Furthermore, we introduce PaymentBERT, a novel hybrid architecture combining domain-specific financial embeddings with contextual representations, achieving state-of-the-art performance with 95.7% F1-score while maintaining real-time processing capabilities. We provide detailed analysis of cross-format generalization, ablation studies, and deployment considerations. This research provides practical insights for financial institutions implementing automated sanctions screening, anti-money laundering (AML) compliance, and payment processing systems.",
      "authors": [
        "Srikumar Nayak"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-15 06:28:57+00:00",
      "link": "https://arxiv.org/pdf/2602.14009v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13999v1",
      "title": "It Takes Two to Tango: A Holistic Simulator for Joint Order Scheduling and Multi-Agent Path Finding in Robotic Warehouses",
      "abstract": "The prevailing paradigm in Robotic Mobile Fulfillment Systems (RMFS) typically treats order scheduling and multi-agent pathfinding as isolated sub-problems. We argue that this decoupling is a fundamental bottleneck, masking the critical dependencies between high-level dispatching and low-level congestion. Existing simulators fail to bridge this gap, often abstracting away heterogeneous kinematics and stochastic execution failures. We propose WareRover, a holistic simulation platform that enforces a tight coupling between OS and MAPF via a unified, closed-loop optimization interface. Unlike standard benchmarks, WareRover integrates dynamic order streams, physics-aware motion constraints, and non-nominal recovery mechanisms into a single evaluation loop. Experiments reveal that SOTA algorithms often falter under these realistic coupled constraints, demonstrating that WareRover provides a necessary and challenging testbed for robust, next-generation warehouse coordination. The project and video is available at https://hhh-x.github.io/WareRover/.",
      "authors": [
        "Haozheng Xu",
        "Wenhao Li",
        "Zifan Wei",
        "Bo Jin",
        "Hongxing Bai",
        "Ben Yang",
        "Xiangfeng Wang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-15 05:51:58+00:00",
      "link": "https://arxiv.org/pdf/2602.13999v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13994v1",
      "title": "Inject Where It Matters: Training-Free Spatially-Adaptive Identity Preservation for Text-to-Image Personalization",
      "abstract": "Personalized text-to-image generation aims to integrate specific identities into arbitrary contexts. However, existing tuning-free methods typically employ Spatially Uniform Visual Injection, causing identity features to contaminate non-facial regions (e.g., backgrounds and lighting) and degrading text adherence. To address this without expensive fine-tuning, we propose SpatialID, a training-free spatially-adaptive identity modulation framework. SpatialID fundamentally decouples identity injection into face-relevant and context-free regions using a Spatial Mask Extractor derived from cross-attention responses. Furthermore, we introduce a Temporal-Spatial Scheduling strategy that dynamically adjusts spatial constraints - transitioning from Gaussian priors to attention-based masks and adaptive relaxation - to align with the diffusion generation dynamics. Extensive experiments on IBench demonstrate that SpatialID achieves state-of-the-art performance in text adherence (CLIP-T: 0.281), visual consistency (CLIP-I: 0.827), and image quality (IQ: 0.523), significantly eliminating background contamination while maintaining robust identity preservation.",
      "authors": [
        "Guandong Li",
        "Mengxia Ye"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-15 05:25:57+00:00",
      "link": "https://arxiv.org/pdf/2602.13994v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13987v1",
      "title": "ATTest: Agent-Driven Tensor Testing for Deep Learning Library Modules",
      "abstract": "The unit testing of Deep Learning (DL) libraries is challenging due to complex numerical semantics and implicit tensor constraints. Traditional Search-Based Software Testing (SBST) often suffers from semantic blindness, failing to satisfy the constraints of high-dimensional tensors, whereas Large Language Models (LLMs) struggle with cross-file context and unstable code modifications. This paper proposes ATTest, an agent-driven tensor testing framework for module-level unit test generation. ATTest orchestrates a seven-stage pipeline, which encompasses constraint extraction and an iterative \"generation-validation-repair\" loop, to maintain testing stability and mitigate context-window saturation. An evaluation on PyTorch and TensorFlow demonstrates that ATTest significantly outperforms state-of-the-art baselines such as PynguinML, achieving an average branch coverage of 55.60% and 54.77%, respectively. The results illustrate how agent-driven workflows bridge the semantic gap in numerical libraries while ensuring auditable test synthesis. Source code: https://github.com/iSEngLab/ATTest.git",
      "authors": [
        "Zhengyu Zhan",
        "Ye Shang",
        "Jiawei Liu",
        "Chunrong Fang",
        "Quanjun Zhang",
        "Zhenyu Chen"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-15 04:47:58+00:00",
      "link": "https://arxiv.org/pdf/2602.13987v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13977v1",
      "title": "WoVR: World Models as Reliable Simulators for Post-Training VLA Policies with RL",
      "abstract": "Reinforcement learning (RL) promises to unlock capabilities beyond imitation learning for Vision-Language-Action (VLA) models, but its requirement for massive real-world interaction prevents direct deployment on physical robots. Recent work attempts to use learned world models as simulators for policy optimization, yet closed-loop imagined rollouts inevitably suffer from hallucination and long-horizon error accumulation. Such errors do not merely degrade visual fidelity; they corrupt the optimization signal, encouraging policies to exploit model inaccuracies rather than genuine task progress. We propose WoVR, a reliable world-model-based reinforcement learning framework for post-training VLA policies. Instead of assuming a faithful world model, WoVR explicitly regulates how RL interacts with imperfect imagined dynamics. It improves rollout stability through a controllable action-conditioned video world model, reshapes imagined interaction to reduce effective error depth via Keyframe-Initialized Rollouts, and maintains policy-simulator alignment through World Model-Policy co-evolution. Extensive experiments on LIBERO benchmarks and real-world robotic manipulation demonstrate that WoVR enables stable long-horizon imagined rollouts and effective policy optimization, improving average LIBERO success from 39.95% to 69.2% (+29.3 points) and real-robot success from 61.7% to 91.7% (+30.0 points). These results show that learned world models can serve as practical simulators for reinforcement learning when hallucination is explicitly controlled.",
      "authors": [
        "Zhennan Jiang",
        "Shangqing Zhou",
        "Yutong Jiang",
        "Zefang Huang",
        "Mingjie Wei",
        "Yuhui Chen",
        "Tianxing Zhou",
        "Zhen Guo",
        "Hao Lin",
        "Quanlu Zhang",
        "Yu Wang",
        "Haoran Li",
        "Chao Yu",
        "Dongbin Zhao"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-15 03:48:20+00:00",
      "link": "https://arxiv.org/pdf/2602.13977v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13962v1",
      "title": "CodeGlance: Understanding Code Reasoning Challenges in LLMs through Multi-Dimensional Feature Analysis",
      "abstract": "In modern software development, developers frequently need to understand code behavior at a glance -- whether reviewing pull requests, debugging issues, or navigating unfamiliar codebases. This ability to reason about dynamic program behavior is fundamental to effective software engineering and increasingly supported by Large Language Models (LLMs). However, existing studies on code reasoning focus primarily on isolated code snippets, overlooking the complexity of real-world scenarios involving external API interactions and unfamiliar functions. This gap hinders our understanding of what truly makes code reasoning challenging for LLMs across diverse programming contexts.   We present CodeGlance, a multi-dimensional benchmark investigating code reasoning challenges across three realistic scenarios: intrinsic logic reasoning, API interaction reasoning, and unseen function reasoning. Through systematic evaluation of 7 state-of-the-art LLMs, we reveal that unseen function reasoning poses significant challenges especially for smaller models, with Qwen2.5-3b achieving only 6.0\\% accuracy on unseen functions compared to 37.5\\% on familiar APIs. We identify critical code complexity features -- including execution trace length, API invocation count, and control flow complexity -- that significantly impact code reasoning difficulty across scenarios. We further investigate how common augmentation strategies, including CoT, document retrieval, and code search, can improve reasoning performance, finding that their effectiveness varies substantially depending on whether challenges stem from logical complexity or knowledge gaps. These findings provide actionable guidance for developing more capable code reasoning systems and deploying LLM-based programming assistants in real-world software development.",
      "authors": [
        "Yunkun Wang",
        "Xuanhe Zhang",
        "Junxiao Han",
        "Chen Zhi",
        "Shuiguang Deng"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-15 02:46:51+00:00",
      "link": "https://arxiv.org/pdf/2602.13962v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13961v1",
      "title": "MarsRetrieval: Benchmarking Vision-Language Models for Planetary-Scale Geospatial Retrieval on Mars",
      "abstract": "Data-driven approaches like deep learning are rapidly advancing planetary science, particularly in Mars exploration. Despite recent progress, most existing benchmarks remain confined to closed-set supervised visual tasks and do not support text-guided retrieval for geospatial discovery. We introduce MarsRetrieval, a retrieval benchmark for evaluating vision-language models for Martian geospatial discovery. MarsRetrieval includes three tasks: (1) paired image-text retrieval, (2) landform retrieval, and (3) global geo-localization, covering multiple spatial scales and diverse geomorphic origins. We propose a unified retrieval-centric protocol to benchmark multimodal embedding architectures, including contrastive dual-tower encoders and generative vision-language models. Our evaluation shows MarsRetrieval is challenging: even strong foundation models often fail to capture domain-specific geomorphic distinctions. We further show that domain-specific fine-tuning is critical for generalizable geospatial discovery in planetary settings. Our code is available at https://github.com/ml-stat-Sustech/MarsRetrieval",
      "authors": [
        "Shuoyuan Wang",
        "Yiran Wang",
        "Hongxin Wei"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "astro-ph.IM",
        "cs.CL"
      ],
      "published": "2026-02-15 02:41:56+00:00",
      "link": "https://arxiv.org/pdf/2602.13961v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15070v1",
      "title": "An effective Genetic Programming Hyper-Heuristic for Uncertain Agile Satellite Scheduling",
      "abstract": "This paper investigates a novel problem, namely the Uncertain Agile Earth Observation Satellite Scheduling Problem (UAEOSSP). Unlike the static AEOSSP, it takes into account a range of uncertain factors (e.g., task profit, resource consumption, and task visibility) in order to reflect the reality that the actual information is inherently unknown beforehand. An effective Genetic Programming Hyper-Heuristic (GPHH) is designed to automate the generation of scheduling policies. The evolved scheduling policies can be utilized to adjust plans in real time and perform exceptionally well. Experimental results demonstrate that evolved scheduling policies significantly outperform both well-designed Look-Ahead Heuristics (LAHs) and Manually Designed Heuristics (MDHs). Specifically, the policies generated by GPHH achieve an average improvement of 5.03% compared to LAHs and 8.14% compared to MDHs.",
      "authors": [
        "Yuning Chen",
        "Junhua Xue",
        "Wangqi Gu",
        "Mingyan Shao"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "published": "2026-02-15 02:09:57+00:00",
      "link": "https://arxiv.org/pdf/2602.15070v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13953v1",
      "title": "QuRL: Efficient Reinforcement Learning with Quantized Rollout",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has become a trending paradigm for training reasoning large language models (LLMs). However, due to the autoregressive decoding nature of LLMs, the rollout process becomes the efficiency bottleneck of RL training, consisting of up to 70\\% of the total training time. In this work, we propose Quantized Reinforcement Learning (QuRL) that uses a quantized actor for accelerating the rollout. We address two challenges in QuRL. First, we propose Adaptive Clipping Range (ACR) that dynamically adjusts the clipping ratio based on the policy ratio between the full-precision actor and the quantized actor, which is essential for mitigating long-term training collapse. Second, we identify the weight update problem, where weight changes between RL steps are extremely small, making it difficult for the quantization operation to capture them effectively. We mitigate this problem through the invariant scaling technique that reduces quantization noise and increases weight update. We evaluate our method with INT8 and FP8 quantization experiments on DeepScaleR and DAPO, and achieve 20% to 80% faster rollout during training.",
      "authors": [
        "Yuhang Li",
        "Reena Elangovan",
        "Xin Dong",
        "Priyadarshini Panda",
        "Brucek Khailany"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-15 01:48:10+00:00",
      "link": "https://arxiv.org/pdf/2602.13953v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13949v1",
      "title": "Experiential Reinforcement Learning",
      "abstract": "Reinforcement learning has become the central approach for language models (LMs) to learn from environmental reward or feedback. In practice, the environmental feedback is usually sparse and delayed. Learning from such signals is challenging, as LMs must implicitly infer how observed failures should translate into behavioral changes for future iterations. We introduce Experiential Reinforcement Learning (ERL), a training paradigm that embeds an explicit experience-reflection-consolidation loop into the reinforcement learning process. Given a task, the model generates an initial attempt, receives environmental feedback, and produces a reflection that guides a refined second attempt, whose success is reinforced and internalized into the base policy. This process converts feedback into structured behavioral revision, improving exploration and stabilizing optimization while preserving gains at deployment without additional inference cost. Across sparse-reward control environments and agentic reasoning benchmarks, ERL consistently improves learning efficiency and final performance over strong reinforcement learning baselines, achieving gains of up to +81% in complex multi-step environments and up to +11% in tool-using reasoning tasks. These results suggest that integrating explicit self-reflection into policy training provides a practical mechanism for transforming feedback into durable behavioral improvement.",
      "authors": [
        "Taiwei Shi",
        "Sihao Chen",
        "Bowen Jiang",
        "Linxin Song",
        "Longqi Yang",
        "Jieyu Zhao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 01:23:48+00:00",
      "link": "https://arxiv.org/pdf/2602.13949v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13940v1",
      "title": "You Can Learn Tokenization End-to-End with Reinforcement Learning",
      "abstract": "Tokenization is a hardcoded compression step which remains in the training pipeline of Large Language Models (LLMs), despite a general trend towards architectures becoming increasingly end-to-end. Prior work has shown promising results at scale in bringing this compression step inside the LLMs' architecture with heuristics to draw token boundaries, and also attempts to learn these token boundaries with straight-through estimates, which treat the problem of drawing discrete token boundaries as a continuous one. We show that these token boundaries can instead be learned using score function estimates, which have tighter theoretical guarantees due to directly optimizing the problem of drawing discrete token boundaries to minimize loss. We observe that techniques from reinforcement learning, such as time discounting, are necessary to reduce the variance of this score function sufficiently to make it practicable. We demonstrate that the resultant method outperforms prior proposed straight-through estimates, both qualitatively and quantitatively at the $100$ million parameter scale.",
      "authors": [
        "Sam Dauncey",
        "Roger Wattenhofer"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15 00:31:24+00:00",
      "link": "https://arxiv.org/pdf/2602.13940v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13936v1",
      "title": "A Generalizable Physics-guided Causal Model for Trajectory Prediction in Autonomous Driving",
      "abstract": "Trajectory prediction for traffic agents is critical for safe autonomous driving. However, achieving effective zero-shot generalization in previously unseen domains remains a significant challenge. Motivated by the consistent nature of kinematics across diverse domains, we aim to incorporate domain-invariant knowledge to enhance zero-shot trajectory prediction capabilities. The key challenges include: 1) effectively extracting domain-invariant scene representations, and 2) integrating invariant features with kinematic models to enable generalized predictions. To address these challenges, we propose a novel generalizable Physics-guided Causal Model (PCM), which comprises two core components: a Disentangled Scene Encoder, which adopts intervention-based disentanglement to extract domain-invariant features from scenes, and a CausalODE Decoder, which employs a causal attention mechanism to effectively integrate kinematic models with meaningful contextual information. Extensive experiments on real-world autonomous driving datasets demonstrate our method's superior zero-shot generalization performance in unseen cities, significantly outperforming competitive baselines. The source code is released at https://github.com/ZY-Zong/Physics-guided-Causal-Model.",
      "authors": [
        "Zhenyu Zong",
        "Yuchen Wang",
        "Haohong Lin",
        "Lu Gan",
        "Huajie Shao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-15 00:19:16+00:00",
      "link": "https://arxiv.org/pdf/2602.13936v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13934v1",
      "title": "Why Code, Why Now: Learnability, Computability, and the Real Limits of Machine Learning",
      "abstract": "Code generation has progressed more reliably than reinforcement learning, largely because code has an information structure that makes it learnable. Code provides dense, local, verifiable feedback at every token, whereas most reinforcement learning problems do not. This difference in feedback quality is not binary but graded. We propose a five-level hierarchy of learnability based on information structure and argue that the ceiling on ML progress depends less on model size than on whether a task is learnable at all. The hierarchy rests on a formal distinction among three properties of computational problems (expressibility, computability, and learnability). We establish their pairwise relationships, including where implications hold and where they fail, and present a unified template that makes the structural differences explicit. The analysis suggests why supervised learning on code scales predictably while reinforcement learning does not, and why the common assumption that scaling alone will solve remaining ML challenges warrants scrutiny.",
      "authors": [
        "Zhimin Zhao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-15 00:14:31+00:00",
      "link": "https://arxiv.org/pdf/2602.13934v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13930v1",
      "title": "MamaDino: A Hybrid Vision Model for Breast Cancer 3-Year Risk Prediction",
      "abstract": "Breast cancer screening programmes increasingly seek to move from one-size-fits-all interval to risk-adapted and personalized strategies. Deep learning (DL) has enabled image-based risk models with stronger 1- to 5-year prediction than traditional clinical models, but leading systems (e.g., Mirai) typically use convolutional backbones, very high-resolution inputs (>1M pixels) and simple multi-view fusion, with limited explicit modelling of contralateral asymmetry.   We hypothesised that combining complementary inductive biases (convolutional and transformer-based) with explicit contralateral asymmetry modelling would allow us to match state-of-the-art 3-year risk prediction performance even when operating on substantially lower-resolution mammograms, indicating that using less detailed images in a more structured way can recover state-of-the-art accuracy.   We present MamaDino, a mammography-aware multi-view attentional DINO model. MamaDino fuses frozen self-supervised DINOv3 ViT-S features with a trainable CNN encoder at 512x512 resolution, and aggregates bilateral breast information via a BilateralMixer to output a 3-year breast cancer risk score. We train on 53,883 women from OPTIMAM (UK) and evaluate on matched 3-year case-control cohorts: an in-distribution test set from four screening sites and an external out-of-distribution cohort from an unseen site.   At breast-level, MamaDino matches Mirai on both internal and external tests while using ~13x fewer input pixels. Adding the BilateralMixer improves discrimination to AUC 0.736 (vs 0.713) in-distribution and 0.677 (vs 0.666) out-of-distribution, with consistent performance across age, ethnicity, scanner, tumour type and grade. These findings demonstrate that explicit contralateral modelling and complementary inductive biases enable predictions that match Mirai, despite operating on substantially lower-resolution mammograms.",
      "authors": [
        "Ruggiero Santeramo",
        "Igor Zubarev",
        "Florian Jug"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-14 23:56:22+00:00",
      "link": "https://arxiv.org/pdf/2602.13930v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13920v2",
      "title": "A Comparative Analysis of Social Network Topology in Reddit and Moltbook",
      "abstract": "Recent advances in agent-mediated systems have enabled a new paradigm of social network simulation, where AI agents interact with human-like autonomy. This evolution has fostered the emergence of agent-driven social networks such as Moltbook, a Reddit-like platform populated entirely by AI agents. Despite these developments, empirical comparisons between agent-driven and human-driven social networks remain scarce, limiting our understanding of how their network topologies might diverge. This paper presents the first comparative analysis of network topology on Moltbook, utilizing a comment network comprising 33,577 nodes and 697,688 edges. To provide a benchmark, we curated a parallel dataset from Reddit consisting of 7.8 million nodes and 51.8 million edges. We examine key structural differences between agent-drive and human-drive networks, specifically focusing on topological patterns and the edge formation efficacy of their respective posts. Our findings provide a foundational profile of AI-driven social structures, serving as a preliminary step toward developing more robust and authentic agent-mediated social systems.",
      "authors": [
        "Yiming Zhu",
        "Gareth Tyson",
        "Pan Hui"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "published": "2026-02-14 23:20:22+00:00",
      "link": "https://arxiv.org/pdf/2602.13920v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13912v2",
      "title": "From Pixels to Policies: Reinforcing Spatial Reasoning in Language Models for Content-Aware Layout Design",
      "abstract": "We introduce LaySPA, a reinforcement learning framework that equips large language models (LLMs) with explicit and interpretable spatial reasoning for content-aware graphic layout design. LaySPA addresses two key challenges: LLMs' limited spatial reasoning and the lack of opacity in design decision making. Instead of operating at the pixel level, we reformulate layout design as a policy learning problem over a structured textual spatial environment that explicitly encodes canvas geometry, element attributes, and inter-element relationships. LaySPA produces dual-level outputs comprising interpretable reasoning traces and structured layout specifications, enabling transparent and controllable design decision making. Layout design policy is optimized via a multi-objective spatial critique that decomposes layout quality into geometric validity, relational coherence, and aesthetic consistency, and is trained using relative group optimization to stabilize learning in open-ended design spaces. Experiments demonstrate that LaySPA improves structural validity and visual quality, outperforming larger proprietary LLMs and achieving performance comparable to specialized SOTA layout generators while requiring fewer annotated samples and reduced latency.",
      "authors": [
        "Sha Li",
        "Stefano Petrangeli",
        "Yu Shen",
        "Xiang Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GR"
      ],
      "published": "2026-02-14 22:31:49+00:00",
      "link": "https://arxiv.org/pdf/2602.13912v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13910v1",
      "title": "Sufficient Conditions for Stability of Minimum-Norm Interpolating Deep ReLU Networks",
      "abstract": "Algorithmic stability is a classical framework for analyzing the generalization error of learning algorithms. It predicts that an algorithm has small generalization error if it is insensitive to small perturbations in the training set such as the removal or replacement of a training point. While stability has been demonstrated for numerous well-known algorithms, this framework has had limited success in analyses of deep neural networks. In this paper we study the algorithmic stability of deep ReLU homogeneous neural networks that achieve zero training error using parameters with the smallest $L_2$ norm, also known as the minimum-norm interpolation, a phenomenon that can be observed in overparameterized models trained by gradient-based algorithms. We investigate sufficient conditions for such networks to be stable. We find that 1) such networks are stable when they contain a (possibly small) stable sub-network, followed by a layer with a low-rank weight matrix, and 2) such networks are not guaranteed to be stable even when they contain a stable sub-network, if the following layer is not low-rank. The low-rank assumption is inspired by recent empirical and theoretical results which demonstrate that training deep neural networks is biased towards low-rank weight matrices, for minimum-norm interpolation and weight-decay regularization.",
      "authors": [
        "Ouns El Harzli",
        "Yoonsoo Nam",
        "Ilja Kuzborskij",
        "Bernardo Cuenca Grau",
        "Ard A. Louis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-14 22:20:44+00:00",
      "link": "https://arxiv.org/pdf/2602.13910v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13909v1",
      "title": "High-fidelity 3D reconstruction for planetary exploration",
      "abstract": "Planetary exploration increasingly relies on autonomous robotic systems capable of perceiving, interpreting, and reconstructing their surroundings in the absence of global positioning or real-time communication with Earth. Rovers operating on planetary surfaces must navigate under sever environmental constraints, limited visual redundancy, and communication delays, making onboard spatial awareness and visual localization key components for mission success. Traditional techniques based on Structure-from-Motion (SfM) and Simultaneous Localization and Mapping (SLAM) provide geometric consistency but struggle to capture radiometric detail or to scale efficiently in unstructured, low-texture terrains typical of extraterrestrial environments. This work explores the integration of radiance field-based methods - specifically Neural Radiance Fields (NeRF) and Gaussian Splatting - into a unified, automated environment reconstruction pipeline for planetary robotics. Our system combines the Nerfstudio and COLMAP frameworks with a ROS2-compatible workflow capable of processing raw rover data directly from rosbag recordings. This approach enables the generation of dense, photorealistic, and metrically consistent 3D representations from minimal visual input, supporting improved perception and planning for autonomous systems operating in planetary-like conditions. The resulting pipeline established a foundation for future research in radiance field-based mapping, bridging the gap between geometric and neural representations in planetary exploration.",
      "authors": [
        "Alfonso Martínez-Petersen",
        "Levin Gerdes",
        "David Rodríguez-Martínez",
        "C. J. Pérez-del-Pulgar"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "published": "2026-02-14 22:07:03+00:00",
      "link": "https://arxiv.org/pdf/2602.13909v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13891v1",
      "title": "GSRM: Generative Speech Reward Model for Speech RLHF",
      "abstract": "Recent advances in speech language models, such as GPT-4o Voice Mode and Gemini Live, have demonstrated promising speech generation capabilities. Nevertheless, the aesthetic naturalness of the synthesized audio still lags behind that of human speech. Enhancing generation quality requires a reliable evaluator of speech naturalness. However, existing naturalness evaluators typically regress raw audio to scalar scores, offering limited interpretability of the evaluation and moreover fail to generalize to speech across different taxonomies. Inspired by recent advances in generative reward modeling, we propose the Generative Speech Reward Model (GSRM), a reasoning-centric reward model tailored for speech. The GSRM is trained to decompose speech naturalness evaluation into an interpretable acoustic feature extraction stage followed by feature-grounded chain-of-thought reasoning, enabling explainable judgments. To achieve this, we curated a large-scale human feedback dataset comprising 31k expert ratings and an out-of-domain benchmark of real-world user-assistant speech interactions. Experiments show that GSRM substantially outperforms existing speech naturalness predictors, achieving model-human correlation of naturalness score prediction that approaches human inter-rater consistency. We further show how GSRM can improve the naturalness of speech LLM generations by serving as an effective verifier for online RLHF.",
      "authors": [
        "Maohao Shen",
        "Tejas Jayashankar",
        "Osama Hanna",
        "Naoyuki Kanda",
        "Yancheng Wang",
        "Kateřina Žmolíková",
        "Ruiming Xie",
        "Niko Moritz",
        "Anfeng Xu",
        "Yashesh Gaur",
        "Gregory Wornell",
        "Qing He",
        "Jilong Wu"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "published": "2026-02-14 21:22:55+00:00",
      "link": "https://arxiv.org/pdf/2602.13891v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13890v1",
      "title": "Evaluating Prompt Engineering Techniques for RAG in Small Language Models: A Multi-Hop QA Approach",
      "abstract": "Retrieval Augmented Generation (RAG) is a powerful approach for enhancing the factual grounding of language models by integrating external knowledge. While widely studied for large language models, the optimization of RAG for Small Language Models (SLMs) remains a critical research gap, particularly in complex, multi-hop question-answering tasks that require sophisticated reasoning. In these systems, prompt template design is a crucial yet under-explored factor influencing performance. This paper presents a large-scale empirical study to investigate this factor, evaluating 24 different prompt templates on the HotpotQA dataset. The set includes a standard RAG prompt, nine well-formed techniques from the literature, and 14 novel hybrid variants, all tested on two prominent SLMs: Qwen2.5-3B Instruct and Gemma3-4B-It. Our findings, based on a test set of 18720 instances, reveal significant performance gains of up to 83% on Qwen2.5 and 84.5% on Gemma3-4B-It, yielding an improvement of up to 6% for both models compared to the Standard RAG prompt. This research also offers concrete analysis and actionable recommendations for designing effective and efficient prompts for SLM-based RAG systems, practically for deployment in resource-constrained environments.",
      "authors": [
        "Amir Hossein Mohammadi",
        "Ali Moeinian",
        "Zahra Razavizade",
        "Afsaneh Fatemi",
        "Reza Ramezani"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-14 21:17:44+00:00",
      "link": "https://arxiv.org/pdf/2602.13890v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13880v1",
      "title": "VSAL: A Vision Solver with Adaptive Layouts for Graph Property Detection",
      "abstract": "Graph property detection aims to determine whether a graph exhibits certain structural properties, such as being Hamiltonian. Recently, learning-based approaches have shown great promise by leveraging data-driven models to detect graph properties efficiently. In particular, vision-based methods offer a visually intuitive solution by processing the visualizations of graphs. However, existing vision-based methods rely on fixed visual graph layouts, and therefore, the expressiveness of their pipeline is restricted. To overcome this limitation, we propose VSAL, a vision-based framework that incorporates an adaptive layout generator capable of dynamically producing informative graph visualizations tailored to individual instances, thereby improving graph property detection. Extensive experiments demonstrate that VSAL outperforms state-of-the-art vision-based methods on various tasks such as Hamiltonian cycle, planarity, claw-freeness, and tree detection.",
      "authors": [
        "Jiahao Xie",
        "Guangmo Tong"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-14 20:44:51+00:00",
      "link": "https://arxiv.org/pdf/2602.13880v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13874v1",
      "title": "Not Seeing the Whole Picture: Challenges and Opportunities in Using AI for Co-Making Physical DIY-AT for People with Visual Impairments",
      "abstract": "Existing assistive technologies (AT) often adopt a one-size-fits-all approach, overlooking the diverse needs of people with visual impairments (PVI). Do-it-yourself AT (DIY-AT) toolkits offer one path toward customization, but most remain limited--targeting co-design with engineers or requiring programming expertise. Non-professionals with disabilities, including PVI, also face barriers such as inaccessible tools, lack of confidence, and insufficient technical knowledge. These gaps highlight the need for prototyping technologies that enable PVI to directly make their own AT. Building on emerging evidence that large language models (LLMs) can serve not only as visual aids but also as co-design partners, we present an exploratory study of how LLM-based AI can support PVI in the tangible DIY-AT co-making process. Our findings surface key challenges and design opportunities: the need for greater spatial and visual support, strategies for mitigating novel AI errors, and implications for designing more accessible AI-assisted prototypes.",
      "authors": [
        "Ben Kosa",
        "Hsuanling Lee",
        "Jasmine Li",
        "Sanbrita Mondal",
        "Yuhang Zhao",
        "Liang He"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-14 20:24:51+00:00",
      "link": "https://arxiv.org/pdf/2602.13874v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13873v1",
      "title": "Ambient Physics: Training Neural PDE Solvers with Partial Observations",
      "abstract": "In many scientific settings, acquiring complete observations of PDE coefficients and solutions can be expensive, hazardous, or impossible. Recent diffusion-based methods can reconstruct fields given partial observations, but require complete observations for training. We introduce Ambient Physics, a framework for learning the joint distribution of coefficient-solution pairs directly from partial observations, without requiring a single complete observation. The key idea is to randomly mask a subset of already-observed measurements and supervise on them, so the model cannot distinguish \"truly unobserved\" from \"artificially unobserved\", and must produce plausible predictions everywhere. Ambient Physics achieves state-of-the-art reconstruction performance. Compared with prior diffusion-based methods, it achieves a 62.51$\\%$ reduction in average overall error while using 125$\\times$ fewer function evaluations. We also identify a \"one-point transition\": masking a single already-observed point enables learning from partial observations across architectures and measurement patterns. Ambient Physics thus enables scientific progress in settings where complete observations are unavailable.",
      "authors": [
        "Harris Abdul Majid",
        "Giannis Daras",
        "Francesco Tudisco",
        "Steven McDonagh"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-14 20:23:58+00:00",
      "link": "https://arxiv.org/pdf/2602.13873v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13871v1",
      "title": "Ensemble-Conditional Gaussian Processes (Ens-CGP): Representation, Geometry, and Inference",
      "abstract": "We formulate Ensemble-Conditional Gaussian Processes (Ens-CGP), a finite-dimensional synthesis that centers ensemble-based inference on the conditional Gaussian law. Conditional Gaussian processes (CGP) arise directly from Gaussian processes under conditioning and, in linear-Gaussian settings, define the full posterior distribution for a Gaussian prior and linear observations. Classical Kalman filtering is a recursive algorithm that computes this same conditional law under dynamical assumptions; the conditional Gaussian law itself is therefore the underlying representational object, while the filter is one computational realization. In this sense, CGP provides the probabilistic foundation for Kalman-type methods as well as equivalent formulations as a strictly convex quadratic program (MAP estimation), RKHS-regularized regression, and classical regularization. Ens-CGP is the ensemble instantiation of this object, obtained by treating empirical ensemble moments as a (possibly low-rank) Gaussian prior and performing exact conditioning. By separating representation (GP -> CGP -> Ens-CGP) from computation (Kalman filters, EnKF variants, and iterative ensemble schemes), the framework links an earlier-established representational foundation for inference to ensemble-derived priors and clarifies the relationships among probabilistic, variational, and ensemble perspectives.",
      "authors": [
        "Sai Ravela",
        "Jae Deok Kim",
        "Kenneth Gee",
        "Xingjian Yan",
        "Samson Mercier",
        "Lubna Albarghouty",
        "Anamitra Saha"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.IT",
        "cs.LG",
        "math.OC",
        "stat.AP",
        "stat.ML"
      ],
      "published": "2026-02-14 20:00:43+00:00",
      "link": "https://arxiv.org/pdf/2602.13871v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13866v1",
      "title": "Modeling and Optimizing the Provisioning of Exhaustible Capabilities for Simultaneous Task Allocation and Scheduling",
      "abstract": "Deploying heterogeneous robot teams to accomplish multiple tasks over extended time horizons presents significant computational challenges for task allocation and planning. In this paper, we present a comprehensive, time-extended, offline heterogeneous multi-robot task allocation framework, TRAITS, which we believe to be the first that can cope with the provisioning of exhaustible traits under battery and temporal constraints. Specifically, we introduce a nonlinear programming-based trait distribution module that can optimize the trait-provisioning rate of coalitions to yield feasible and time-efficient solutions. TRAITS provides a more accurate feasibility assessment and estimation of task execution times and makespan by leveraging trait-provisioning rates while optimizing battery consumption -- an advantage that state-of-the-art frameworks lack. We evaluate TRAITS against two state-of-the-art frameworks, with results demonstrating its advantage in satisfying complex trait and battery requirements while remaining computationally tractable.",
      "authors": [
        "Jinwoo Park",
        "Harish Ravichandar",
        "Seth Hutchinson"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.MA"
      ],
      "published": "2026-02-14 19:55:15+00:00",
      "link": "https://arxiv.org/pdf/2602.13866v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13865v1",
      "title": "Enabling Option Learning in Sparse Rewards with Hindsight Experience Replay",
      "abstract": "Hierarchical Reinforcement Learning (HRL) frameworks like Option-Critic (OC) and Multi-updates Option Critic (MOC) have introduced significant advancements in learning reusable options. However, these methods underperform in multi-goal environments with sparse rewards, where actions must be linked to temporally distant outcomes. To address this limitation, we first propose MOC-HER, which integrates the Hindsight Experience Replay (HER) mechanism into the MOC framework. By relabeling goals from achieved outcomes, MOC-HER can solve sparse reward environments that are intractable for the original MOC. However, this approach is insufficient for object manipulation tasks, where the reward depends on the object reaching the goal rather than on the agent's direct interaction. This makes it extremely difficult for HRL agents to discover how to interact with these objects. To overcome this issue, we introduce Dual Objectives Hindsight Experience Replay (2HER), a novel extension that creates two sets of virtual goals. In addition to relabeling goals based on the object's final state (standard HER), 2HER also generates goals from the agent's effector positions, rewarding the agent for both interacting with the object and completing the task. Experimental results in robotic manipulation environments show that MOC-2HER achieves success rates of up to 90%, compared to less than 11% for both MOC and MOC-HER. These results highlight the effectiveness of our dual objective relabeling strategy in sparse reward, multi-goal tasks.",
      "authors": [
        "Gabriel Romio",
        "Mateus Begnini Melchiades",
        "Bruno Castro da Silva",
        "Gabriel de Oliveira Ramos"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-02-14 19:55:11+00:00",
      "link": "https://arxiv.org/pdf/2602.13865v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13864v1",
      "title": "Evolving Multi-Channel Confidence-Aware Activation Functions for Missing Data with Channel Propagation",
      "abstract": "Learning in the presence of missing data can result in biased predictions and poor generalizability, among other difficulties, which data imputation methods only partially address. In neural networks, activation functions significantly affect performance yet typical options (e.g., ReLU, Swish) operate only on feature values and do not account for missingness indicators or confidence scores. We propose Three-Channel Evolved Activations (3C-EA), which we evolve using Genetic Programming to produce multivariate activation functions f(x, m, c) in the form of trees that take (i) the feature value x, (ii) a missingness indicator m, and (iii) an imputation confidence score c. To make these activations useful beyond the input layer, we introduce ChannelProp, an algorithm that deterministically propagates missingness and confidence values via linear layers based on weight magnitudes, retaining reliability signals throughout the network. We evaluate 3C-EA and ChannelProp on datasets with natural and injected (MCAR/MAR/MNAR) missingness at multiple rates under identical preprocessing and splits. Results indicate that integrating missingness and confidence inputs into the activation search improves classification performance under missingness.",
      "authors": [
        "Naeem Shahabi Sani",
        "Ferial Najiantabriz",
        "Shayan Shafaei",
        "Dean F. Hougen"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "published": "2026-02-14 19:52:10+00:00",
      "link": "https://arxiv.org/pdf/2602.13864v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13849v1",
      "title": "Push-Placement: A Hybrid Approach Integrating Prehensile and Non-Prehensile Manipulation for Object Rearrangement",
      "abstract": "Efficient tabletop rearrangement remains challenging due to collisions and the need for temporary buffering when target poses are obstructed. Prehensile pick-and-place provides precise control but often requires extra moves, whereas non-prehensile pushing can be more efficient but suffers from complex, imprecise dynamics. This paper proposes push-placement, a hybrid action primitive that uses the grasped object to displace obstructing items while being placed, thereby reducing explicit buffering. The method is integrated into a physics-in-the-loop Monte Carlo Tree Search (MCTS) planner and evaluated in the PyBullet simulator. Empirical results show push-placement reduces the manipulator travel cost by up to 11.12% versus a baseline MCTS planner and 8.56% versus dynamic stacking. These findings indicate that hybrid prehensile/non-prehensile action primitives can substantially improve efficiency in long-horizon rearrangement tasks.",
      "authors": [
        "Majid Sadeghinejad",
        "Arman Barghi",
        "Hamed Hosseini",
        "Mehdi Tale Masouleh",
        "Ahmad Kalhor"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-14 18:58:00+00:00",
      "link": "https://arxiv.org/pdf/2602.13849v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13847v2",
      "title": "Causally constrained reduced-order neural models of complex turbulent dynamical systems",
      "abstract": "We introduce a flexible framework based on response theory and score matching to suppress spurious, noncausal dependencies in reduced-order neural emulators of turbulent systems, focusing on climate dynamics as a proof-of-concept. We showcase the approach using the stochastic Charney-DeVore model as a relevant prototype for low-frequency atmospheric variability. We show that the resulting causal constraints enhance neural emulators' ability to respond to both weak and strong external forcings, despite being trained exclusively on unforced data. The approach is broadly applicable to modeling complex turbulent dynamical systems in reduced spaces and can be readily integrated into general neural network architectures.",
      "authors": [
        "Fabrizio Falasca",
        "Laure Zanna"
      ],
      "primary_category": "nlin.CD",
      "categories": [
        "nlin.CD",
        "cond-mat.stat-mech",
        "cs.LG",
        "physics.ao-ph"
      ],
      "published": "2026-02-14 18:43:52+00:00",
      "link": "https://arxiv.org/pdf/2602.13847v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13842v1",
      "title": "Automated Prediction of Paravalvular Regurgitation before Transcatheter Aortic Valve Implantation",
      "abstract": "Severe aortic stenosis is a common and life-threatening condition in elderly patients, often treated with Transcatheter Aortic Valve Implantation (TAVI). Despite procedural advances, paravalvular aortic regurgitation (PVR) remains one of the most frequent post-TAVI complications, with a proven impact on long-term prognosis.   In this work, we investigate the potential of deep learning to predict the occurrence of PVR from preoperative cardiac CT. To this end, a dataset of preoperative TAVI patients was collected, and 3D convolutional neural networks were trained on isotropic CT volumes. The results achieved suggest that volumetric deep learning can capture subtle anatomical features from pre-TAVI imaging, opening new perspectives for personalized risk assessment and procedural optimization. Source code is available at https://github.com/EIDOSLAB/tavi.",
      "authors": [
        "Michele Cannito",
        "Riccardo Renzulli",
        "Adson Duarte",
        "Farzad Nikfam",
        "Carlo Alberto Barbano",
        "Enrico Chiesa",
        "Francesco Bruno",
        "Federico Giacobbe",
        "Wojciech Wanha",
        "Arturo Giordano",
        "Marco Grangetto",
        "Fabrizio D'Ascenzo"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-14 18:09:27+00:00",
      "link": "https://arxiv.org/pdf/2602.13842v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13836v1",
      "title": "Speculative Decoding with a Speculative Vocabulary",
      "abstract": "Speculative decoding has rapidly emerged as a leading approach for accelerating language model (LM) inference, as it offers substantial speedups while yielding identical outputs. This relies upon a small draft model, tasked with predicting the outputs of the target model. State-of-the-art speculative decoding methods use a draft model consisting of a single decoder layer and output embedding matrix, with the latter dominating drafting time for the latest LMs. Recent work has sought to address this output distribution bottleneck by reducing the vocabulary of the draft model. Although this can improve throughput, it compromises speculation effectiveness when the target token is out-of-vocabulary. In this paper, we argue for vocabulary speculation as an alternative to a reduced vocabulary. We propose SpecVocab, an efficient and effective method that selects a vocabulary subset per decoding step. Across a variety of tasks, we demonstrate that SpecVocab can achieve a higher acceptance length than state-of-the-art speculative decoding approach, EAGLE-3. Notably, this yields up to an 8.1% increase in average throughput over EAGLE-3.",
      "authors": [
        "Miles Williams",
        "Young D. Kwon",
        "Rui Li",
        "Alexandros Kouris",
        "Stylianos I. Venieris"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-14 16:10:00+00:00",
      "link": "https://arxiv.org/pdf/2602.13836v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13834v1",
      "title": "Learning Vocal-Tract Area and Radiation with a Physics-Informed Webster Model",
      "abstract": "We present a physics-informed voiced backend renderer for singing-voice synthesis. Given synthetic single-channel audio and a fund-amental--frequency trajectory, we train a time-domain Webster model as a physics-informed neural network to estimate an interpretable vocal-tract area function and an open-end radiation coefficient. Training enforces partial differential equation and boundary consistency; a lightweight DDSP path is used only to stabilize learning, while inference is purely physics-based. On sustained vowels (/a/, /i/, /u/), parameters rendered by an independent finite-difference time-domain Webster solver reproduce spectral envelopes competitively with a compact DDSP baseline and remain stable under changes in discretization, moderate source variations, and about ten percent pitch shifts. The in-graph waveform remains breathier than the reference, motivating periodicity-aware objectives and explicit glottal priors in future work.",
      "authors": [
        "Minhui Lu",
        "Joshua D. Reiss"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "eess.AS"
      ],
      "published": "2026-02-14 16:06:10+00:00",
      "link": "https://arxiv.org/pdf/2602.13834v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13833v1",
      "title": "Semantic-Contact Fields for Category-Level Generalizable Tactile Tool Manipulation",
      "abstract": "Generalizing tool manipulation requires both semantic planning and precise physical control. Modern generalist robot policies, such as Vision-Language-Action (VLA) models, often lack the high-fidelity physical grounding required for contact-rich tool manipulation. Conversely, existing contact-aware policies that leverage tactile or haptic sensing are typically instance-specific and fail to generalize across diverse tool geometries. Bridging this gap requires learning unified contact representations from diverse data, yet a fundamental barrier remains: diverse real-world tactile data are prohibitive at scale, while direct zero-shot sim-to-real transfer is challenging due to the complex dynamics of nonlinear deformation of soft sensors.   To address this, we propose Semantic-Contact Fields (SCFields), a unified 3D representation fusing visual semantics with dense contact estimates. We enable this via a two-stage Sim-to-Real Contact Learning Pipeline: first, we pre-train on a large simulation data set to learn general contact physics; second, we fine-tune on a small set of real data, pseudo-labeled via geometric heuristics and force optimization, to align sensor characteristics. This allows physical generalization to unseen tools. We leverage SCFields as the dense observation input for a diffusion policy to enable robust execution of contact-rich tool manipulation tasks. Experiments on scraping, crayon drawing, and peeling demonstrate robust category-level generalization, significantly outperforming vision-only and raw-tactile baselines.",
      "authors": [
        "Kevin Yuchen Ma",
        "Heng Zhang",
        "Weisi Lin",
        "Mike Zheng Shou",
        "Yan Wu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-14 16:05:08+00:00",
      "link": "https://arxiv.org/pdf/2602.13833v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13831v1",
      "title": "Prior-guided Hierarchical Instance-pixel Contrastive Learning for Ultrasound Speckle Noise Suppression",
      "abstract": "Ultrasound denoising is essential for mitigating speckle-induced degradations, thereby enhancing image quality and improving diagnostic reliability. Nevertheless, because speckle patterns inherently encode both texture and fine anatomical details, effectively suppressing noise while preserving structural fidelity remains a significant challenge. In this study, we propose a prior-guided hierarchical instance-pixel contrastive learning model for ultrasound denoising, designed to promote noise-invariant and structure-aware feature representations by maximizing the separability between noisy and clean samples at both pixel and instance levels. Specifically, a statistics-guided pixel-level contrastive learning strategy is introduced to enhance distributional discrepancies between noisy and clean pixels, thereby improving local structural consistency. Concurrently, a memory bank is employed to facilitate instance-level contrastive learning in the feature space, encouraging representations that more faithfully approximate the underlying data distribution. Furthermore, a hybrid Transformer-CNN architecture is adopted, coupling a Transformer-based encoder for global context modeling with a CNN-based decoder optimized for fine-grained anatomical structure restoration, thus enabling complementary exploitation of long-range dependencies and local texture details. Extensive evaluations on two publicly available ultrasound datasets demonstrate that the proposed model consistently outperforms existing methods, confirming its effectiveness and superiority.",
      "authors": [
        "Zhenyu Bu",
        "Yuanxin Xie",
        "Guang-Quan Zhou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-14 16:01:58+00:00",
      "link": "https://arxiv.org/pdf/2602.13831v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13823v1",
      "title": "Embed-RL: Reinforcement Learning for Reasoning-Driven Multimodal Embeddings",
      "abstract": "Leveraging Multimodal Large Language Models (MLLMs) has become pivotal for advancing Universal Multimodal Embeddings (UME) in addressing diverse cross-modal tasks. Recent studies demonstrate that incorporating generative Chain-of-Thought (CoT) reasoning can substantially enhance task-specific representations compared to discriminative methods. However, the generated reasoning CoTs of existing generative embedding methods are limited to the textual analysis of queries and are irrelevant to the retrieval of the targets. To address these limitations, we propose a reasoning-driven UME framework that integrates Embedder-Guided Reinforcement Learning (EG-RL) to optimize the Reasoner to produce evidential Traceability CoT (T-CoT). Our key contributions are threefold: (1) We design an EG-RL framework where the Embedder provides explicit supervision to the Reasoner, ensuring the generated CoT traces are aligned with embedding tasks. (2) We introduce T-CoT, which extracts critical multimodal cues to focus on retrieval-relevant elements and provides multimodal inputs for the Embedder. (3) With limited computational resources, our framework outperforms the pioneering embedding model on both MMEB-V2 and UVRB benchmarks. The integration of multimodal evidence in structured reasoning, paired with retrieval-oriented alignment, effectively strengthens cross-modal semantic consistency and boosts the fine-grained matching capability of the model as well as the generalization across complex scenarios. Our work demonstrates that targeted reasoning optimization can significantly improve multimodal embedding quality, providing a practical and efficient solution for reasoning-driven UME development.",
      "authors": [
        "Haonan Jiang",
        "Yuji Wang",
        "Yongjie Zhu",
        "Xin Lu",
        "Wenyu Qin",
        "Meng Wang",
        "Pengfei Wan",
        "Yansong Tang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-14 15:35:03+00:00",
      "link": "https://arxiv.org/pdf/2602.13823v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13818v1",
      "title": "VAR-3D: View-aware Auto-Regressive Model for Text-to-3D Generation via a 3D Tokenizer",
      "abstract": "Recent advances in auto-regressive transformers have achieved remarkable success in generative modeling. However, text-to-3D generation remains challenging, primarily due to bottlenecks in learning discrete 3D representations. Specifically, existing approaches often suffer from information loss during encoding, causing representational distortion before the quantization process. This effect is further amplified by vector quantization, ultimately degrading the geometric coherence of text-conditioned 3D shapes. Moreover, the conventional two-stage training paradigm induces an objective mismatch between reconstruction and text-conditioned auto-regressive generation. To address these issues, we propose View-aware Auto-Regressive 3D (VAR-3D), which intergrates a view-aware 3D Vector Quantized-Variational AutoEncoder (VQ-VAE) to convert the complex geometric structure of 3D models into discrete tokens. Additionally, we introduce a rendering-supervised training strategy that couples discrete token prediction with visual reconstruction, encouraging the generative process to better preserve visual fidelity and structural consistency relative to the input text. Experiments demonstrate that VAR-3D significantly outperforms existing methods in both generation quality and text-3D alignment.",
      "authors": [
        "Zongcheng Han",
        "Dongyan Cao",
        "Haoran Sun",
        "Yu Hong"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-14 15:28:15+00:00",
      "link": "https://arxiv.org/pdf/2602.13818v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13812v2",
      "title": "DTBench: A Synthetic Benchmark for Document-to-Table Extraction",
      "abstract": "Document-to-table (Doc2Table) extraction derives structured tables from unstructured documents under a target schema, enabling reliable and verifiable SQL-based data analytics. Although large language models (LLMs) have shown promise in flexible information extraction, their ability to produce precisely structured tables remains insufficiently understood, particularly for indirect extraction that requires complex capabilities such as reasoning and conflict resolution. Existing benchmarks neither explicitly distinguish nor comprehensively cover the diverse capabilities required in Doc2Table extraction. We argue that a capability-aware benchmark is essential for systematic evaluation. However, constructing such benchmarks using human-annotated document-table pairs is costly, difficult to scale, and limited in capability coverage. To address this, we adopt a reverse Table2Doc paradigm and design a multi-agent synthesis workflow to generate documents from ground-truth tables. Based on this approach, we present DTBench, a synthetic benchmark that adopts a proposed two-level taxonomy of Doc2Table capabilities, covering 5 major categories and 13 subcategories. We evaluate several mainstream LLMs on DTBench, and demonstrate substantial performance gaps across models, as well as persistent challenges in reasoning, faithfulness, and conflict resolution. DTBench provides a comprehensive testbed for data generation and evaluation, facilitating future research on Doc2Table extraction. The benchmark is publicly available at https://github.com/ZJU-DAILY/DTBench.",
      "authors": [
        "Yuxiang Guo",
        "Zhuoran Du",
        "Nan Tang",
        "Kezheng Tang",
        "Congcong Ge",
        "Yunjun Gao"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-02-14 14:52:36+00:00",
      "link": "https://arxiv.org/pdf/2602.13812v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13811v1",
      "title": "A Unified Physics-Informed Neural Network for Modeling Coupled Electro- and Elastodynamic Wave Propagation Using Three-Stage Loss Optimization",
      "abstract": "Physics-Informed Neural Networks present a novel approach in SciML that integrates physical laws in the form of partial differential equations directly into the NN through soft constraints in the loss function. This work studies the application of PINNs to solve a one dimensional coupled electro-elastodynamic system modeling linear piezoelectricity in stress-charge form, governed by elastodynamic and electrodynamic equations. Our simulation employs a feedforward architecture, mapping space-time coordinates to mechanical displacement and electric potential. Our PINN model achieved global relative L2 errors of 2.34 and 4.87 percent for displacement and electric potential respectively. The results validate PINNs as effective mesh free solvers for coupled time-dependent PDE systems, though challenges remain regarding error accumulation and stiffness in coupled eigenvalue systems.",
      "authors": [
        "Suhas Suresh Bharadwaj",
        "Reuben Thomas Thovelil"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.LG",
        "physics.comp-ph"
      ],
      "published": "2026-02-14 14:52:08+00:00",
      "link": "https://arxiv.org/pdf/2602.13811v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13810v1",
      "title": "Mean Flow Policy with Instantaneous Velocity Constraint for One-step Action Generation",
      "abstract": "Learning expressive and efficient policy functions is a promising direction in reinforcement learning (RL). While flow-based policies have recently proven effective in modeling complex action distributions with a fast deterministic sampling process, they still face a trade-off between expressiveness and computational burden, which is typically controlled by the number of flow steps. In this work, we propose mean velocity policy (MVP), a new generative policy function that models the mean velocity field to achieve the fastest one-step action generation. To ensure its high expressiveness, an instantaneous velocity constraint (IVC) is introduced on the mean velocity field during training. We theoretically prove that this design explicitly serves as a crucial boundary condition, thereby improving learning accuracy and enhancing policy expressiveness. Empirically, our MVP achieves state-of-the-art success rates across several challenging robotic manipulation tasks from Robomimic and OGBench. It also delivers substantial improvements in training and inference speed over existing flow-based policy baselines.",
      "authors": [
        "Guojian Zhan",
        "Letian Tao",
        "Pengcheng Wang",
        "Yixiao Wang",
        "Yiheng Li",
        "Yuxin Chen",
        "Masayoshi Tomizuka",
        "Shengbo Eben Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-14 14:44:06+00:00",
      "link": "https://arxiv.org/pdf/2602.13810v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13805v1",
      "title": "Fast Physics-Driven Untrained Network for Highly Nonlinear Inverse Scattering Problems",
      "abstract": "Untrained neural networks (UNNs) offer high-fidelity electromagnetic inverse scattering reconstruction but are computationally limited by high-dimensional spatial-domain optimization. We propose a Real-Time Physics-Driven Fourier-Spectral (PDF) solver that achieves sub-second reconstruction through spectral-domain dimensionality reduction. By expanding induced currents using a truncated Fourier basis, the optimization is confined to a compact low-frequency parameter space supported by scattering measurements. The solver integrates a contraction integral equation (CIE) to mitigate high-contrast nonlinearity and a contrast-compensated operator (CCO) to correct spectral-induced attenuation. Furthermore, a bridge-suppressing loss is formulated to enhance boundary sharpness between adjacent scatterers. Numerical and experimental results demonstrate a 100-fold speedup over state-of-the-art UNNs with robust performance under noise and antenna uncertainties, enabling real-time microwave imaging applications.",
      "authors": [
        "Yutong Du",
        "Zicheng Liu",
        "Yi Huang",
        "Bazargul Matkerim",
        "Bo Qi",
        "Yali Zong",
        "Peixian Han"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.comp-ph"
      ],
      "published": "2026-02-14 14:30:12+00:00",
      "link": "https://arxiv.org/pdf/2602.13805v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13802v1",
      "title": "Cast-R1: Learning Tool-Augmented Sequential Decision Policies for Time Series Forecasting",
      "abstract": "Time series forecasting has long been dominated by model-centric approaches that formulate prediction as a single-pass mapping from historical observations to future values. Despite recent progress, such formulations often struggle in complex and evolving settings, largely because most forecasting models lack the ability to autonomously acquire informative evidence, reason about potential future changes, or revise predictions through iterative decision processes. In this work, we propose Cast-R1, a learned time series forecasting framework that reformulates forecasting as a sequential decision-making problem. Cast-R1 introduces a memory-based state management mechanism that maintains decision-relevant information across interaction steps, enabling the accumulation of contextual evidence to support long-horizon reasoning. Building on this formulation, forecasting is carried out through a tool-augmented agentic workflow, in which the agent autonomously interacts with a modular toolkit to extract statistical features, invoke lightweight forecasting models for decision support, perform reasoning-based prediction, and iteratively refine forecasts through self-reflection. To train Cast-R1, we adopt a two-stage learning strategy that combines supervised fine-tuning with multi-turn reinforcement learning, together with a curriculum learning scheme that progressively increases task difficulty to improve policy learning. Extensive experiments on multiple real-world time series datasets demonstrate the effectiveness of Cast-R1. We hope this work provides a practical step towards further exploration of agentic paradigms for time series modeling. Our code is available at https://github.com/Xiaoyu-Tao/Cast-R1-TS.",
      "authors": [
        "Xiaoyu Tao",
        "Mingyue Cheng",
        "Chuang Jiang",
        "Tian Gao",
        "Huanjian Zhang",
        "Yaguo Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-14 14:27:08+00:00",
      "link": "https://arxiv.org/pdf/2602.13802v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13791v1",
      "title": "MechPert: Mechanistic Consensus as an Inductive Bias for Unseen Perturbation Prediction",
      "abstract": "Predicting transcriptional responses to unseen genetic perturbations is essential for understanding gene regulation and prioritizing large-scale perturbation experiments. Existing approaches either rely on static, potentially incomplete knowledge graphs, or prompt language models for functionally similar genes, retrieving associations shaped by symmetric co-occurrence in scientific text rather than directed regulatory logic. We introduce MechPert, a lightweight framework that encourages LLM agents to generate directed regulatory hypotheses rather than relying solely on functional similarity. Multiple agents independently propose candidate regulators with associated confidence scores; these are aggregated through a consensus mechanism that filters spurious associations, producing weighted neighborhoods for downstream prediction. We evaluate MechPert on Perturb-seq benchmarks across four human cell lines. For perturbation prediction in low-data regimes ($N=50$ observed perturbations), MechPert improves Pearson correlation by up to 10.5\\% over similarity-based baselines. For experimental design, MechPert-selected anchor genes outperform standard network centrality heuristics by up to 46\\% in well-characterized cell lines.",
      "authors": [
        "Marc Boubnovski Martell",
        "Josefa Lia Stoisser",
        "Lawrence Phillips",
        "Aditya Misra",
        "Robert Kitchen",
        "Jesper Ferkinghoff-Borg",
        "Jialin Yu",
        "Philip Torr",
        "Kaspar Märten"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-14 14:12:38+00:00",
      "link": "https://arxiv.org/pdf/2602.13791v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13784v1",
      "title": "Comparables XAI: Faithful Example-based AI Explanations with Counterfactual Trace Adjustments",
      "abstract": "Explaining with examples is an intuitive way to justify AI decisions. However, it is challenging to understand how a decision value should change relative to the examples with many features differing by large amounts. We draw from real estate valuation that uses Comparables-examples with known values for comparison. Estimates are made more accurate by hypothetically adjusting the attributes of each Comparable and correspondingly changing the value based on factors. We propose Comparables XAI for relatable example-based explanations of AI with Trace adjustments that trace counterfactual changes from each Comparable to the Subject, one attribute at a time, monotonically along the AI feature space. In modelling and user studies, Trace-adjusted Comparables achieved the highest XAI faithfulness and precision, user accuracy, and narrowest uncertainty bounds compared to linear regression, linearly adjusted Comparables, or unadjusted Comparables. This work contributes a new analytical basis for using example-based explanations to improve user understanding of AI decisions.",
      "authors": [
        "Yifan Zhang",
        "Tianle Ren",
        "Fei Wang",
        "Brian Y Lim"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "published": "2026-02-14 14:00:47+00:00",
      "link": "https://arxiv.org/pdf/2602.13784v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13780v1",
      "title": "Foundation Model-Driven Semantic Change Detection in Remote Sensing Imagery",
      "abstract": "Remote sensing (RS) change detection methods can extract critical information on surface dynamics and are an essential means for humans to understand changes in the earth's surface and environment. Among these methods, semantic change detection (SCD) can more effectively interpret the multi-class information contained in bi-temporal RS imagery, providing semantic-level predictions that support dynamic change monitoring. However, due to the limited semantic understanding capability of the model and the inherent complexity of the SCD tasks, existing SCD methods face significant challenges in both performance and paradigm complexity. In this paper, we propose PerASCD, a SCD method driven by RS foundation model PerA, designed to enhance the multi-scale semantic understanding and overall performance. We introduce a modular Cascaded Gated Decoder (CG-Decoder) that simplifies complex SCD decoding pipelines while promoting effective multi-level feature interaction and fusion. In addition, we propose a Soft Semantic Consistency Loss (SSCLoss) to mitigate the numerical instability commonly encountered during SCD training. We further explore the applicability of multiple existing RS foundation models on the SCD task when equipped with the proposed decoder. Experimental results demonstrate that our decoder not only effectively simplifies the paradigm of SCD, but also achieves seamless adaptation across various vision encoders. Our method achieves state-of-the-art (SOTA) performance on two public benchmark datasets, validating its effectiveness. The code is available at https://github.com/SathShen/PerASCD.git.",
      "authors": [
        "Hengtong Shen",
        "Li Yan",
        "Hong Xie",
        "Yaxuan Wei",
        "Xinhao Li",
        "Wenfei Shen",
        "Peixian Lv",
        "Fei Tan"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-14 13:56:31+00:00",
      "link": "https://arxiv.org/pdf/2602.13780v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13778v1",
      "title": "Skeleton2Stage: Reward-Guided Fine-Tuning for Physically Plausible Dance Generation",
      "abstract": "Despite advances in dance generation, most methods are trained in the skeletal domain and ignore mesh-level physical constraints. As a result, motions that look plausible as joint trajectories often exhibit body self-penetration and Foot-Ground Contact (FGC) anomalies when visualized with a human body mesh, reducing the aesthetic appeal of generated dances and limiting their real-world applications. We address this skeleton-to-mesh gap by deriving physics-based rewards from the body mesh and applying Reinforcement Learning Fine-Tuning (RLFT) to steer the diffusion model toward physically plausible motion synthesis under mesh visualization. Our reward design combines (i) an imitation reward that measures a motion's general plausibility by its imitability in a physical simulator (penalizing penetration and foot skating), and (ii) a Foot-Ground Deviation (FGD) reward with test-time FGD guidance to better capture the dynamic foot-ground interaction in dance. However, we find that the physics-based rewards tend to push the model to generate freezing motions for fewer physical anomalies and better imitability. To mitigate it, we propose an anti-freezing reward to preserve motion dynamics while maintaining physical plausibility. Experiments on multiple dance datasets consistently demonstrate that our method can significantly improve the physical plausibility of generated motions, yielding more realistic and aesthetically pleasing dances. The project page is available at: https://jjd1123.github.io/Skeleton2Stage/",
      "authors": [
        "Jidong Jia",
        "Youjian Zhang",
        "Huan Fu",
        "Dacheng Tao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-14 13:48:13+00:00",
      "link": "https://arxiv.org/pdf/2602.13778v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13773v1",
      "title": "On Representation Redundancy in Large-Scale Instruction Tuning Data Selection",
      "abstract": "Data quality is a crucial factor in large language models training. While prior work has shown that models trained on smaller, high-quality datasets can outperform those trained on much larger but noisy or low-quality corpora, systematic methods for industrial-scale data selection in instruction tuning remain underexplored. In this work, we study instruction-tuning data selection through the lens of semantic representation similarity and identify a key limitation of state-of-the-art LLM encoders: they produce highly redundant semantic embeddings. To mitigate this redundancy, we propose Compressed Representation Data Selection (CRDS), a novel framework with two variants. CRDS-R applies Rademacher random projection followed by concatenation of transformer hidden-layer representations, while CRDS-W employs whitening-based dimensionality reduction to improve representational quality. Experimental results demonstrate that both variants substantially enhance data quality and consistently outperform state-of-the-art representation-based selection methods. Notably, CRDS-W achieves strong performance using only 3.5% of the data, surpassing the full-data baseline by an average of 0.71% across four datasets. Our code is available at https://github.com/tdano1/CRDS.",
      "authors": [
        "Youwei Shu",
        "Shaomian Zheng",
        "Dingnan Jin",
        "Wenjie Qu",
        "Ziyao Guo",
        "Qing Cui",
        "Jun Zhou",
        "Jiaheng Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-14 13:35:34+00:00",
      "link": "https://arxiv.org/pdf/2602.13773v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13770v1",
      "title": "NeuroMambaLLM: Dynamic Graph Learning of fMRI Functional Connectivity in Autistic Brains Using Mamba and Language Model Reasoning",
      "abstract": "Large Language Models (LLMs) have demonstrated strong semantic reasoning across multimodal domains. However, their integration with graph-based models of brain connectivity remains limited. In addition, most existing fMRI analysis methods rely on static Functional Connectivity (FC) representations, which obscure transient neural dynamics critical for neurodevelopmental disorders such as autism. Recent state-space approaches, including Mamba, model temporal structure efficiently, but are typically used as standalone feature extractors without explicit high-level reasoning. We propose NeuroMambaLLM, an end-to-end framework that integrates dynamic latent graph learning and selective state-space temporal modelling with LLMs. The proposed method learns the functional connectivity dynamically from raw Blood-Oxygen-Level-Dependent (BOLD) time series, replacing fixed correlation graphs with adaptive latent connectivity while suppressing motion-related artifacts and capturing long-range temporal dependencies. The resulting dynamic brain representations are projected into the embedding space of an LLM model, where the base language model remains frozen and lightweight low-rank adaptation (LoRA) modules are trained for parameter-efficient alignment. This design enables the LLM to perform both diagnostic classification and language-based reasoning, allowing it to analyze dynamic fMRI patterns and generate clinically meaningful textual reports.",
      "authors": [
        "Yasaman Torabi",
        "Parsa Razmara",
        "Hamed Ajorlou",
        "Bardia Baraeinejad"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.LG"
      ],
      "published": "2026-02-14 13:32:59+00:00",
      "link": "https://arxiv.org/pdf/2602.13770v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13769v1",
      "title": "OR-Agent: Bridging Evolutionary Search and Structured Research for Automated Algorithm Discovery",
      "abstract": "Automating scientific discovery in complex, experiment-driven domains requires more than iterative mutation of programs; it demands structured hypothesis management, environment interaction, and principled reflection. We present OR-Agent, a configurable multi-agent research framework designed for automated exploration in rich experimental environments. OR-Agent organizes research as a structured tree-based workflow that explicitly models branching hypothesis generation and systematic backtracking, enabling controlled management of research trajectories beyond simple mutation-crossover loops. At its core, we introduce an evolutionary-systematic ideation mechanism that unifies evolutionary selection of research starting points, comprehensive research plan generation, and coordinated exploration within a research tree. We further propose a hierarchical optimization-inspired reflection system: short-term experimental reflection operates as a form of verbal gradient providing immediate corrective signals; long-term reflection accumulates cross-experiment insights as verbal momentum; and memory compression serves as a regularization mechanism analogous to weight decay, preserving essential signals while mitigating drift. Together, these components form a principled architecture governing research dynamics. We conduct extensive experiments across classical combinatorial optimization benchmarks-including traveling salesman, capacitated vehicle routing, bin packing, orienteering, and multiple knapsack problems-as well as simulation-based cooperative driving scenarios. Results demonstrate that OR-Agent outperforms strong evolutionary baselines while providing a general, extensible, and inspectable framework for AI-assisted scientific discovery. OR-Agent source code and experiments data are publicly available at https://github.com/qiliuchn/OR-Agent.",
      "authors": [
        "Qi Liu",
        "Wanjing Ma"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.NE"
      ],
      "published": "2026-02-14 13:32:03+00:00",
      "link": "https://arxiv.org/pdf/2602.13769v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13758v1",
      "title": "OmniScience: A Large-scale Multi-modal Dataset for Scientific Image Understanding",
      "abstract": "Multimodal Large Language Models demonstrate strong performance on natural image understanding, yet exhibit limited capability in interpreting scientific images, including but not limited to schematic diagrams, experimental characterizations, and analytical charts. This limitation is particularly pronounced in open-source MLLMs. The gap largely stems from existing datasets with limited domain coverage, coarse structural annotations, and weak semantic grounding. We introduce OmniScience, a large-scale, high-fidelity multi-modal dataset comprising 1.5 million figure-caption-context triplets, spanning more than 10 major scientific disciplines. To obtain image caption data with higher information density and accuracy for multi-modal large-model training, we develop a dynamic model-routing re-captioning pipeline that leverages state-of-the-art multi-modal large language models to generate dense, self-contained descriptions by jointly synthesizing visual features, original figure captions, and corresponding in-text references authored by human scientists. The pipeline is further reinforced with rigorous quality filtering and alignment with human expert judgments, ensuring both factual accuracy and semantic completeness, and boosts the image-text multi-modal similarity score from 0.769 to 0.956. We further propose a caption QA protocol as a proxy task for evaluating visual understanding. Under this setting, Qwen2.5-VL-3B model finetuned on OmniScience show substantial gains over baselines, achieving a gain of 0.378 on MM-MT-Bench and a gain of 0.140 on MMMU.",
      "authors": [
        "Haoyi Tao",
        "Chaozheng Huang",
        "Nan Wang",
        "Han Lyu",
        "Linfeng Zhang",
        "Guolin Ke",
        "Xi Fang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-14 13:08:13+00:00",
      "link": "https://arxiv.org/pdf/2602.13758v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13748v1",
      "title": "RMPL: Relation-aware Multi-task Progressive Learning with Stage-wise Training for Multimedia Event Extraction",
      "abstract": "Multimedia Event Extraction (MEE) aims to identify events and their arguments from documents that contain both text and images. It requires grounding event semantics across different modalities. Progress in MEE is limited by the lack of annotated training data. M2E2 is the only established benchmark, but it provides annotations only for evaluation. This makes direct supervised training impractical. Existing methods mainly rely on cross-modal alignment or inference-time prompting with Vision--Language Models (VLMs). These approaches do not explicitly learn structured event representations and often produce weak argument grounding in multimodal settings. To address these limitations, we propose RMPL, a Relation-aware Multi-task Progressive Learning framework for MEE under low-resource conditions. RMPL incorporates heterogeneous supervision from unimodal event extraction and multimedia relation extraction with stage-wise training. The model is first trained with a unified schema to learn shared event-centric representations across modalities. It is then fine-tuned for event mention identification and argument role extraction using mixed textual and visual data. Experiments on the M2E2 benchmark with multiple VLMs show consistent improvements across different modality settings.",
      "authors": [
        "Yongkang Jin",
        "Jianwen Luo",
        "Jingjing Wang",
        "Jianmin Yao",
        "Yu Hong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CV"
      ],
      "published": "2026-02-14 12:43:25+00:00",
      "link": "https://arxiv.org/pdf/2602.13748v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13747v1",
      "title": "The More the Merrier: Running Multiple Neuromorphic Components On-Chip for Robotic Control",
      "abstract": "It has long been realized that neuromorphic hardware offers benefits for the domain of robotics such as low energy, low latency, as well as unique methods of learning. In aiming for more complex tasks, especially those incorporating multimodal data, one hurdle continuing to prevent their realization is an inability to orchestrate multiple networks on neuromorphic hardware without resorting to off-chip process management logic. To address this, we show a first example of a pipeline for vision-based robot control in which numerous complex networks can be run entirely on hardware via the use of a spiking neural state machine for process orchestration. The pipeline is validated on the Intel Loihi 2 research chip. We show that all components can run concurrently on-chip in the milli Watt regime at latencies competitive with the state-of-the-art. An equivalent network on simulated hardware is shown to accomplish robotic arm plug insertion in simulation, and the core elements of the pipeline are additionally tested on a real robotic arm.",
      "authors": [
        "Evan Eames",
        "Priyadarshini Kannan",
        "Ronan Sangouard",
        "Philipp Plank",
        "Elvin Hajizada",
        "Gintautas Palinauskas",
        "Lana Amaya",
        "Michael Neumeier",
        "Sai Thejeshwar Sharma",
        "Marcella Toth",
        "Prottush Sarkar",
        "Axel von Arnim"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-14 12:39:15+00:00",
      "link": "https://arxiv.org/pdf/2602.13747v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13730v1",
      "title": "Discrete Gene Crossover Accelerates Solution Discovery in Quality-Diversity Algorithms",
      "abstract": "Quality-Diversity (QD) algorithms aim to discover diverse, high-performing solutions across behavioral niches. However, QD search often stagnates as incremental variation operators struggle to propagate building blocks across large populations. Existing mutation operators rely on gradual variation to solutions, limiting their ability to efficiently explore regions of the search space distant from parent solutions or to spread beneficial genetic material through the population. We propose a mutation operator which augments variation-based operators with discrete, gene-level crossover, enabling rapid recombination of elite genetic material. This crossover mechanism mirrors the biological principle of meiosis and facilitates both the direct transfer of genetic material and the exploration of novel genotype configurations beyond the existing elite hypervolume. We evaluate operators on three locomotion environments, demonstrating improvements in QD score, coverage, and max fitness, with particularly strong performance in later stages of optimization once building blocks have been established in the archive. These results show that the addition of a discrete crossover mutation provides a complementary exploration mechanism that sustains quality-diversity growth beyond the performance demonstrated by existing operators.",
      "authors": [
        "Joshua Hutchinson",
        "J. Michael Herrmann",
        "Simón C. Smith"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-02-14 11:44:21+00:00",
      "link": "https://arxiv.org/pdf/2602.13730v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13723v1",
      "title": "ARC: Compiling Hundreds of Requirement Scenarios into A Runnable Web System",
      "abstract": "Large Language Models (LLMs) have improved programming efficiency, but their performance degrades significantly as requirements scale; when faced with multi-modal documents containing hundreds of scenarios, LLMs often produce incorrect implementations or omit constraints. We propose Agentic Requirement Compilation (ARC), a technique that moves beyond simple code generation to requirement compilation, enabling the creation of runnable web systems directly from multi-modal DSL documents. ARC generates not only source code but also modular designs for UI, API, and database layers, enriched test suites (unit, modular, and integration), and detailed traceability for software maintenance. Our approach employs a bidirectional test-driven agentic loop: a top-down architecture phase decomposes requirements into verifiable interfaces, followed by a bottom-up implementation phase where agents generate code to satisfy those tests. ARC maintains strict traceability across requirements, design, and code to facilitate intelligent asset reuse. We evaluated ARC by generating six runnable web systems from documents spanning 50-200 multi-modal scenarios. Compared to state-of-the-art baselines, ARC-generated systems pass 50.6% more GUI tests on average. A user study with 21 participants showed that novice users can successfully write DSL documents for complex systems, such as a 10K-line ticket-booking system, in an average of 5.6 hours. These results demonstrate that ARC effectively transforms non-trivial requirement specifications into maintainable, runnable software.",
      "authors": [
        "Weiyu Kong",
        "Yun Lin",
        "Xiwen Teoh",
        "Duc-Minh Nguyen",
        "Ruofei Ren",
        "Jiaxin Chang",
        "Haoxu Hu",
        "Haoyu Chen"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-14 11:07:58+00:00",
      "link": "https://arxiv.org/pdf/2602.13723v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13710v1",
      "title": "HBVLA: Pushing 1-Bit Post-Training Quantization for Vision-Language-Action Models",
      "abstract": "Vision-Language-Action (VLA) models enable instruction-following embodied control, but their large compute and memory footprints hinder deployment on resource-constrained robots and edge platforms. While reducing weights to 1-bit precision through binarization can greatly improve efficiency, existing methods fail to narrow the distribution gap between binarized and full-precision weights, causing quantization errors to accumulate under long-horizon closed-loop execution and severely degrade actions. To fill this gap, we propose HBVLA, a VLA-tailored binarization framework. First, we use a policy-aware enhanced Hessian to identify weights that are truly critical for action generation. Then, we employ a sparse orthogonal transform for non-salient weights to induce a low-entropy intermediate state. Finally, we quantize both salient and non-salient weights in the Harr domain with group-wise 1-bit quantization. We have evaluated our approach on different VLAs: on LIBERO, quantized OpenVLA-OFT retains 92.2% of full-precision performance; on SimplerEnv, quantized CogAct retains 93.6%, significantly outperforming state-of-the-art binarization methods. We further validate our method on real-world evaluation suite and the results show that HBVLA incurs only marginal success-rate degradation compared to the full-precision model, demonstrating robust deployability under tight hardware constraints. Our work provides a practical foundation for ultra-low-bit quantization of VLAs, enabling more reliable deployment on hardware-limited robotic platforms.",
      "authors": [
        "Xin Yan",
        "Zhenglin Wan",
        "Feiyang Ye",
        "Xingrui Yu",
        "Hangyu Du",
        "Yang You",
        "Ivor Tsang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-14 10:23:45+00:00",
      "link": "https://arxiv.org/pdf/2602.13710v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15903v1",
      "title": "Detecting Deepfakes with Multivariate Soft Blending and CLIP-based Image-Text Alignment",
      "abstract": "The proliferation of highly realistic facial forgeries necessitates robust detection methods. However, existing approaches often suffer from limited accuracy and poor generalization due to significant distribution shifts among samples generated by diverse forgery techniques. To address these challenges, we propose a novel Multivariate and Soft Blending Augmentation with CLIP-guided Forgery Intensity Estimation (MSBA-CLIP) framework. Our method leverages the multimodal alignment capabilities of CLIP to capture subtle forgery traces. We introduce a Multivariate and Soft Blending Augmentation (MSBA) strategy that synthesizes images by blending forgeries from multiple methods with random weights, forcing the model to learn generalizable patterns. Furthermore, a dedicated Multivariate Forgery Intensity Estimation (MFIE) module is designed to explicitly guide the model in learning features related to varied forgery modes and intensities. Extensive experiments demonstrate state-of-the-art performance. On in-domain tests, our method improves Accuracy and AUC by 3.32\\% and 4.02\\%, respectively, over the best baseline. In cross-domain evaluations across five datasets, it achieves an average AUC gain of 3.27\\%. Ablation studies confirm the efficacy of both proposed components. While the reliance on a large vision-language model entails higher computational cost, our work presents a significant step towards more generalizable and robust deepfake detection.",
      "authors": [
        "Jingwei Li",
        "Jiaxin Tong",
        "Pengfei Wu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-14 09:53:35+00:00",
      "link": "https://arxiv.org/pdf/2602.15903v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13699v1",
      "title": "Attention Head Entropy of LLMs Predicts Answer Correctness",
      "abstract": "Large language models (LLMs) often generate plausible yet incorrect answers, posing risks in safety-critical settings such as medicine. Human evaluation is expensive, and LLM-as-judge approaches risk introducing hidden errors. Recent white-box methods detect contextual hallucinations using model internals, focusing on the localization of the attention mass, but two questions remain open: do these approaches extend to predicting answer correctness, and do they generalize out-of-domains? We introduce Head Entropy, a method that predicts answer correctness from attention entropy patterns, specifically measuring the spread of the attention mass. Using sparse logistic regression on per-head 2-Renyi entropies, Head Entropy matches or exceeds baselines in-distribution and generalizes substantially better on out-of-domains, it outperforms the closest baseline on average by +8.5% AUROC. We further show that attention patterns over the question/context alone, before answer generation, already carry predictive signal using Head Entropy with on average +17.7% AUROC over the closest baseline. We evaluate across 5 instruction-tuned LLMs and 3 QA datasets spanning general knowledge, multi-hop reasoning, and medicine.",
      "authors": [
        "Sophie Ostmeier",
        "Brian Axelrod",
        "Maya Varma",
        "Asad Aali",
        "Yabin Zhang",
        "Magdalini Paschali",
        "Sanmi Koyejo",
        "Curtis Langlotz",
        "Akshay Chaudhari"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-14 09:50:19+00:00",
      "link": "https://arxiv.org/pdf/2602.13699v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13692v1",
      "title": "ThunderAgent: A Simple, Fast and Program-Aware Agentic Inference System",
      "abstract": "Large language models(LLMs) are now used to power complex multi-turn agentic workflows. Existing systems run agentic inference by loosely assembling isolated components: an LLM inference engine (e.g., vLLM) and a tool orchestrator (e.g., Kubernetes). Although agentic workflows involve multiple LLM and tool requests, these systems schedule and allocate resources separately on a per-request basis, without end-to-end knowledge of the workflow. This leads to sub-optimal management of KV cache and tool execution environments. To address the challenges, we propose ThunderAgent, a fast, simple, and program-aware agentic inference system. We first abstract agentic workflows as LLM Programs, enabling a unified view of heterogeneous resources, including KV caches, system states, and external tool assets such as disk memory and network ports. Built upon this abstraction, ThunderAgent introduces a program-aware scheduler and a tool resource manager designed to maximize KV cache hit rates, mitigate memory imbalances, and enable asynchronous environment preparation. Evaluations across coding, routing, and scientific discovery agents demonstrate that ThunderAgent achieves 1.5-3.6x throughput improvements in serving, 1.8-3.9x in RL rollout, and up to 4.2x disk memory savings compared to state-of-the-art inference systems. To facilitate reproducibility and support future development, we open-source the system implementations of the whole ThunderAgent at: https://github.com/Agentic-Kinetics/ThunderAgent.",
      "authors": [
        "Hao Kang",
        "Ziyang Li",
        "Xinyu Yang",
        "Weili Xu",
        "Yinfang Chen",
        "Junxiong Wang",
        "Beidi Chen",
        "Tushar Krishna",
        "Chenfeng Xu",
        "Simran Arora"
      ],
      "primary_category": "cs.OS",
      "categories": [
        "cs.OS",
        "cs.MA"
      ],
      "published": "2026-02-14 09:26:41+00:00",
      "link": "https://arxiv.org/pdf/2602.13692v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13690v1",
      "title": "Physics Aware Neural Networks: Denoising for Magnetic Navigation",
      "abstract": "Magnetic-anomaly navigation, leveraging small-scale variations in the Earth's magnetic field, is a promising alternative when GPS is unavailable or compromised. Airborne systems face a key challenge in extracting geomagnetic field data: the aircraft itself induces magnetic noise. Although the classical Tolles-Lawson model addresses this, it inadequately handles stochastically corrupted magnetic data required for navigation. To address stochastic noise, we propose a framework based on two physics-based constraints: divergence-free vector field and E(3)-equivariance. These ensure the learned magnetic field obeys Maxwell's equations and that outputs transform correctly with sensor position/orientation. The divergence-free constraint is implemented by training a neural network to output a vector potential $A$, with the magnetic field defined as its curl. For E(3)-equivariance, we use tensor products of geometric tensors representable via spherical harmonics with known rotational transformations. Enforcing physical consistency and restricting the admissible function space acts as an implicit regularizer that improves spatio-temporal performance. We present ablation studies evaluating each constraint alone and jointly across CNNs, MLPs, Liquid Time Constant models, and Contiformers. Continuous-time dynamics and long-term memory are critical for modelling magnetic time series; the Contiformer architecture, which provides both, outperforms state-of-the-art methods. To mitigate data scarcity, we generate synthetic datasets using the World Magnetic Model (WMM) with time-series conditional GANs, producing realistic, temporally consistent magnetic sequences across varied trajectories and environments. Experiments show that embedding these constraints significantly improves predictive accuracy and physical plausibility, outperforming classical and unconstrained deep learning approaches.",
      "authors": [
        "Aritra Das",
        "Yashas Shende",
        "Muskaan Chugh",
        "Reva Laxmi Chauhan",
        "Arghya Pathak",
        "Debayan Gupta"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-14 09:23:57+00:00",
      "link": "https://arxiv.org/pdf/2602.13690v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13689v1",
      "title": "Symmetry-Aware Fusion of Vision and Tactile Sensing via Bilateral Force Priors for Robotic Manipulation",
      "abstract": "Insertion tasks in robotic manipulation demand precise, contact-rich interactions that vision alone cannot resolve. While tactile feedback is intuitively valuable, existing studies have shown that naïve visuo-tactile fusion often fails to deliver consistent improvements. In this work, we propose a Cross-Modal Transformer (CMT) for visuo-tactile fusion that integrates wrist-camera observations with tactile signals through structured self- and cross-attention. To stabilize tactile embeddings, we further introduce a physics-informed regularization that encourages bilateral force balance, reflecting principles of human motor control. Experiments on the TacSL benchmark show that CMT with symmetry regularization achieves a 96.59% insertion success rate, surpassing naïve and gated fusion baselines and closely matching the privileged \"wrist + contact force\" configuration (96.09%). These results highlight two central insights: (i) tactile sensing is indispensable for precise alignment, and (ii) principled multimodal fusion, further strengthened by physics-informed regularization, unlocks complementary strengths of vision and touch, approaching privileged performance under realistic sensing.",
      "authors": [
        "Wonju Lee",
        "Matteo Grimaldi",
        "Tao Yu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "published": "2026-02-14 09:19:48+00:00",
      "link": "https://arxiv.org/pdf/2602.13689v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13685v1",
      "title": "AuTAgent: A Reinforcement Learning Framework for Tool-Augmented Audio Reasoning",
      "abstract": "Large Audio Language Models (LALMs) excel at perception but struggle with complex reasoning requiring precise acoustic measurements. While external tools can extract fine-grained features like exact tempo or pitch, effective integration remains challenging: naively using all tools causes information overload, while prompt-based selection fails to assess context-dependent utility. To address this, we propose AuTAgent (Audio Tool Agent), a reinforcement learning framework that learns when and which tools to invoke. By employing a sparse-feedback training strategy with a novel Differential Reward mechanism, the agent learns to filter out irrelevant tools and invokes external assistance only when it yields a net performance gain over the base model. Experimental results confirm that AuTAgent complements the representation bottleneck of LALMs by providing verifiable acoustic evidence. It improves accuracy by 4.20% / 6.20% and 9.80% / 8.00% for open-source and closed-source backbones on the MMAU Test-mini and the MMAR benchmarks, respectively. In addition, further experiments demonstrate exceptional transferability. We highlight the complementary role of external tools in augmenting audio model reasoning.",
      "authors": [
        "Siqian Tong",
        "Xuan Li",
        "Yiwei Wang",
        "Baolong Bi",
        "Yujun Cai",
        "Shenghua Liu",
        "Yuchen He",
        "Chengpeng Hao"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "published": "2026-02-14 09:12:20+00:00",
      "link": "https://arxiv.org/pdf/2602.13685v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13681v1",
      "title": "An Ensemble Learning Approach towards Waste Segmentation in Cluttered Environment",
      "abstract": "Environmental pollution is a critical global issue, with recycling emerging as one of the most viable solutions. This study focuses on waste segregation, a crucial step in recycling processes to obtain raw material. Recent advancements in computer vision have significantly contributed to waste classification and recognition. In waste segregation, segmentation masks are essential for robots to accurately localize and pick objects from conveyor belts. The complexity of real-world waste environments, characterized by deformed items without specific patterns and overlapping objects, further complicates waste segmentation tasks. This paper proposes an Ensemble Learning approach to improve segmentation accuracy by combining high performing segmentation models, U-Net and FPN, using a weighted average method. U-Net excels in capturing fine details and boundaries in segmentation tasks, while FPN effectively handles scale variation and context in complex environments, and their combined masks result in more precise predictions. The dataset used closely mimics real-life waste scenarios, and preprocessing techniques were applied to enhance feature learning for deep learning segmentation models. The ensemble model, referred to as EL-4, achieved an IoU value of 0.8306, an improvement over U-Net's 0.8065, and reduced Dice loss to 0.09019 from FPN's 0.1183. This study could contribute to the efficiency of waste sorting at Material Recovery Facility, facilitating better raw material acquisition for recycling with minimal human intervention and enhancing the overall throughput.",
      "authors": [
        "Maimoona Jafar",
        "Syed Imran Ali",
        "Ahsan Saadat",
        "Muhammad Bilal",
        "Shah Khalid"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-14 09:07:00+00:00",
      "link": "https://arxiv.org/pdf/2602.13681v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13668v1",
      "title": "Efficient Data-Driven Production Scheduling in Pharmaceutical Manufacturing",
      "abstract": "This paper develops a data-driven, constraint-based optimization framework for a complex industrial job shop scheduling problem variant in pharmaceutical manufacturing. The formulation captures fixed routings and designated machines, explicit resource calendars with weekends and planned maintenance, and campaign sequencing through sequence-dependent cleaning times derived from site tables. The model is implemented with an open source constraint solver and evaluated on deterministic snapshots from a solid oral dosage facility under three objective formulations: makespan, makespan plus total tardiness, and makespan plus average tardiness. On three industrial instances of increasing size (10, 30, and 84 jobs) the proposed schedules dominate reference plans that solve a simplified variant without the added site rules. Makespan reductions reach \\(88.1\\%\\), \\(77.6\\%\\), and \\(54.9\\%\\) and total tardiness reductions reach \\(72.1\\%\\), \\(58.7\\%\\), and \\(18.2\\%\\), respectively. The composite objectives further decrease late job counts with negligible makespan change on the smaller instances and a modest increase on the largest instance. Optimality is proven on the small case, with relative gaps of \\(0.77\\%\\) and \\(14.92\\%\\) on the medium and large cases under a fixed time limit. The results show that a compact constraint programming formulation can deliver feasible, transparent schedules that respect site rules while improving adherence to due dates on real industrial data.",
      "authors": [
        "Ioannis Balatsos",
        "Athanasios Liakos",
        "Panagiotis Karakostas",
        "Tao Song",
        "Vassilios Pantazopoulos",
        "Christos Papalitsas"
      ],
      "primary_category": "cs.PF",
      "categories": [
        "cs.PF"
      ],
      "published": "2026-02-14 08:31:22+00:00",
      "link": "https://arxiv.org/pdf/2602.13668v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15067v1",
      "title": "Attention-gated U-Net model for semantic segmentation of brain tumors and feature extraction for survival prognosis",
      "abstract": "Gliomas, among the most common primary brain tumors, vary widely in aggressiveness, prognosis, and histology, making treatment challenging due to complex and time-intensive surgical interventions. This study presents an Attention-Gated Recurrent Residual U-Net (R2U-Net) based Triplanar (2.5D) model for improved brain tumor segmentation. The proposed model enhances feature representation and segmentation accuracy by integrating residual, recurrent, and triplanar architectures while maintaining computational efficiency, potentially aiding in better treatment planning. The proposed method achieves a Dice Similarity Score (DSC) of 0.900 for Whole Tumor (WT) segmentation on the BraTS2021 validation set, demonstrating performance comparable to leading models. Additionally, the triplanar network extracts 64 features per planar model for survival days prediction, which are reduced to 28 using an Artificial Neural Network (ANN). This approach achieves an accuracy of 45.71%, a Mean Squared Error (MSE) of 108,318.128, and a Spearman Rank Correlation Coefficient (SRC) of 0.338 on the test dataset.",
      "authors": [
        "Rut Pate",
        "Snehal Rajput",
        "Mehul S. Raval",
        "Rupal A. Kapdi",
        "Mohendra Roy"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-14 07:48:58+00:00",
      "link": "https://arxiv.org/pdf/2602.15067v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13653v1",
      "title": "Building Autonomous GUI Navigation via Agentic-Q Estimation and Step-Wise Policy Optimization",
      "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have substantially driven the progress of autonomous agents for Graphical User Interface (GUI). Nevertheless, in real-world applications, GUI agents are often faced with non-stationary environments, leading to high computational costs for data curation and policy optimization. In this report, we introduce a novel MLLM-centered framework for GUI agents, which consists of two components: agentic-Q estimation and step-wise policy optimization. The former one aims to optimize a Q-model that can generate step-wise values to evaluate the contribution of a given action to task completion. The latter one takes step-wise samples from the state-action trajectory as inputs, and optimizes the policy via reinforcement learning with our agentic-Q model. It should be noticed that (i) all state-action trajectories are produced by the policy itself, so that the data collection costs are manageable; (ii) the policy update is decoupled from the environment, ensuring stable and efficient optimization. Empirical evaluations show that our framework endows Ovis2.5-9B with powerful GUI interaction capabilities, achieving remarkable performances on GUI navigation and grounding benchmarks and even surpassing contenders with larger scales.",
      "authors": [
        "Yibo Wang",
        "Guangda Huzhang",
        "Yuwei Hu",
        "Yu Xia",
        "Shiyin Lu",
        "Qing-Guo Chen",
        "Zhao Xu",
        "Weihua Luo",
        "Kaifu Zhang",
        "Lijun Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ],
      "published": "2026-02-14 07:44:47+00:00",
      "link": "https://arxiv.org/pdf/2602.13653v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13631v1",
      "title": "GEMs: Breaking the Long-Sequence Barrier in Generative Recommendation with a Multi-Stream Decoder",
      "abstract": "While generative recommendations (GR) possess strong sequential reasoning capabilities, they face significant challenges when processing extremely long user behavior sequences: the high computational cost forces practical sequence lengths to be limited, preventing models from capturing users' lifelong interests; meanwhile, the inherent \"recency bias\" of attention mechanisms further weakens learning from long-term history. To overcome this bottleneck, we propose GEMs (Generative rEcommendation with a Multi-stream decoder), a novel and unified framework designed to break the long-sequence barrier by capturing users' lifelong interaction sequences through a multi-stream perspective. Specifically, GEMs partitions user behaviors into three temporal streams$\\unicode{x2014}$Recent, Mid-term, and Lifecycle$\\unicode{x2014}$and employs tailored inference schemes for each: a one-stage real-time extractor for immediate dynamics, a lightweight indexer for cross attention to balance accuracy and cost for mid-term sequences, and a two-stage offline-online compression module for lifelong modeling. These streams are integrated via a parameter-free fusion strategy to enable holistic interest representation. Extensive experiments on large-scale industrial datasets demonstrate that GEMs significantly outperforms state-of-the-art methods in recommendation accuracy. Notably, GEMs is the first lifelong GR framework successfully deployed in a high-concurrency industrial environment, achieving superior inference efficiency while processing user sequences of over 100,000 interactions.",
      "authors": [
        "Yu Zhou",
        "Chengcheng Guo",
        "Kuo Cai",
        "Ji Liu",
        "Qiang Luo",
        "Ruiming Tang",
        "Han Li",
        "Kun Gai",
        "Guorui Zhou"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-14 06:42:56+00:00",
      "link": "https://arxiv.org/pdf/2602.13631v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13610v1",
      "title": "Probabilistic RNA Designability via Interpretable Ensemble Approximation and Dynamic Decomposition",
      "abstract": "Motivation: RNA design aims to find RNA sequences that fold into a given target secondary structure, a problem also known as RNA inverse folding. However, not all target structures are designable. Recent advances in RNA designability have focused primarily on minimum free energy (MFE)-based criteria, while ensemble-based notions of designability remain largely underexplored. To address this gap, we introduce a theory of ensemble approximation and a probability decomposition framework for bounding the folding probabilities of RNA structures in an explainable way. We further develop a linear-time dynamic programming algorithm that efficiently searches over exponentially many decompositions and identifies the optimal one that yields the tightest probabilistic bound for a given structure. Results: Applying our methods to both native and artificial RNA structures in the ArchiveII and Eterna100 benchmarks, we obtained probability bounds that are much tighter than prior approaches. In addition, our methods further provide anatomical tools for analyzing RNA structures and understanding the sources of design difficulty at the motif level. Availability: Source code and data are available at https://github.com/shanry/RNA-Undesign. Supplementary information: Supplementary text and data are available in a separate PDF.",
      "authors": [
        "Tianshuo Zhou",
        "David H. Mathews",
        "Liang Huang"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-02-14 05:51:49+00:00",
      "link": "https://arxiv.org/pdf/2602.13610v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13607v1",
      "title": "Parametric-Sensitivity Aware Retransmission for Efficient AI Downloading",
      "abstract": "The edge artificial intelligence (AI) applications in next-generation mobile networks demand efficient AI-model downloading techniques to support real-time, on-device inference. However, transmitting high-dimensional AI models over wireless channels remains challenging due to limited communication resources. To address this issue, we propose a parametric-sensitivity-aware retransmission (PASAR) framework that manages radio-resource usage of different parameter packets according to their importance on model inference accuracy, known as parametric sensitivity. Empirical analysis reveals a highly right-skewed sensitivity distribution, indicating that only a small fraction of parameters significantly affect model performance. Leveraging this insight, we design a novel online retransmission protocol, i.e., the PASAR protocol, that adaptively terminates packet transmission based on real-time bit error rate (BER) measurements and the associated parametric sensitivity. The protocol employs an adaptive, round-wise stopping criterion, enabling heterogeneous, packet-level retransmissions that preserve overall model functionality but reduce overall latency. Extensive experiments across diverse deep neural network architectures and real-world datasets demonstrate that PASAR substantially outperforms classical hybrid automatic repeat request (HARQ) schemes in terms of communication efficiency and latency.",
      "authors": [
        "You Zhou",
        "Qunsong Zeng",
        "Kaibin Huang"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI",
        "cs.IT"
      ],
      "published": "2026-02-14 05:12:27+00:00",
      "link": "https://arxiv.org/pdf/2602.13607v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13595v1",
      "title": "The Quantization Trap: Breaking Linear Scaling Laws in Multi-Hop Reasoning",
      "abstract": "Neural scaling laws provide a predictable recipe for AI advancement: reducing numerical precision should linearly improve computational efficiency and energy profile (E proportional to bits). In this paper, we demonstrate that this scaling law breaks in the context of multi-hop reasoning. We reveal a 'quantization trap' where reducing precision from 16-bit to 8/4-bit paradoxically increases more net energy consumption while degrading reasoning accuracy. We provide a rigorous theoretical decomposition that attributes this failure to hardware casting overhead, the hidden latency cost of dequantization kernels, which becomes a dominant bottleneck in sequential reasoning chains, as well as to a sequential energy amortization failure. As a result, scaling law breaking is unavoidable in practice. Our findings suggest that the industry's \"smaller-is-better\" heuristic is mathematically counterproductive for complex reasoning tasks.",
      "authors": [
        "Henry Han",
        "Xiyang Liu",
        "Xiaodong Wang",
        "Fei Han",
        "Xiaodong Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-14 04:25:27+00:00",
      "link": "https://arxiv.org/pdf/2602.13595v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13591v1",
      "title": "AgentRob: From Virtual Forum Agents to Hijacked Physical Robots",
      "abstract": "Large Language Model (LLM)-powered autonomous agents have demonstrated significant capabilities in virtual environments, yet their integration with the physical world remains narrowly confined to direct control interfaces. We present AgentRob, a framework that bridges online community forums, LLM-powered agents, and physical robots through the Model Context Protocol (MCP). AgentRob enables a novel paradigm where autonomous agents participate in online forums--reading posts, extracting natural language commands, dispatching physical robot actions, and reporting results back to the community. The system comprises three layers: a Forum Layer providing asynchronous, persistent, multi-agent interaction; an Agent Layer with forum agents that poll for @mention-targeted commands; and a Robot Layer with VLM-driven controllers and Unitree Go2/G1 hardware that translate commands into robot primitives via iterative tool calling. The framework supports multiple concurrent agents with distinct identities and physical embodiments coexisting in the same forum, establishing the feasibility of forum-mediated multi-agent robot orchestration.",
      "authors": [
        "Wenrui Liu",
        "Yaxuan Wang",
        "Xun Zhang",
        "Yanshu Wang",
        "Jiashen Wei",
        "Yifan Xiang",
        "Yuhang Wang",
        "Mingshen Ye",
        "Elsie Dai",
        "Zhiqi Liu",
        "Yingjie Xu",
        "Xinyang Chen",
        "Hengzhe Sun",
        "Jiyu Shen",
        "Jingjing He",
        "Tong Yang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-14 04:14:59+00:00",
      "link": "https://arxiv.org/pdf/2602.13591v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13583v1",
      "title": "Differentiable Rule Induction from Raw Sequence Inputs",
      "abstract": "Rule learning-based models are widely used in highly interpretable scenarios due to their transparent structures. Inductive logic programming (ILP), a form of machine learning, induces rules from facts while maintaining interpretability. Differentiable ILP models enhance this process by leveraging neural networks to improve robustness and scalability. However, most differentiable ILP methods rely on symbolic datasets, facing challenges when learning directly from raw data. Specifically, they struggle with explicit label leakage: The inability to map continuous inputs to symbolic variables without explicit supervision of input feature labels. In this work, we address this issue by integrating a self-supervised differentiable clustering model with a novel differentiable ILP model, enabling rule learning from raw data without explicit label leakage. The learned rules effectively describe raw data through its features. We demonstrate that our method intuitively and precisely learns generalized rules from time series and image data.",
      "authors": [
        "Kun Gao",
        "Katsumi Inoue",
        "Yongzhi Cao",
        "Hanpin Wang",
        "Feng Yang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-14 03:54:08+00:00",
      "link": "https://arxiv.org/pdf/2602.13583v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13575v1",
      "title": "Elo-Evolve: A Co-evolutionary Framework for Language Model Alignment",
      "abstract": "Current alignment methods for Large Language Models (LLMs) rely on compressing vast amounts of human preference data into static, absolute reward functions, leading to data scarcity, noise sensitivity, and training instability. We introduce Elo-Evolve, a co-evolutionary framework that redefines alignment as dynamic multi-agent competition within an adaptive opponent pool. Our approach makes two key innovations: (1) eliminating Bradley-Terry model dependencies by learning directly from binary win/loss outcomes in pairwise competitions, and (2) implementing Elo-orchestrated opponent selection that provides automatic curriculum learning through temperature-controlled sampling. We ground our approach in PAC learning theory, demonstrating that pairwise comparison achieves superior sample complexity and empirically validate a 4.5x noise reduction compared to absolute scoring approaches. Experimentally, we train a Qwen2.5-7B model using our framework with opponents including Qwen2.5-14B, Qwen2.5-32B, and Qwen3-8B models. Results demonstrate a clear performance hierarchy: point-based methods < static pairwise training < Elo-Evolve across Alpaca Eval 2.0 and MT-Bench, validating the progressive benefits of pairwise comparison and dynamic opponent selection for LLM alignment.",
      "authors": [
        "Jing Zhao",
        "Ting Zhen",
        "Junwei bao",
        "Hongfei Jiang",
        "Yang song"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-14 03:18:52+00:00",
      "link": "https://arxiv.org/pdf/2602.13575v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13573v1",
      "title": "Unleash the Potential of Long Semantic IDs for Generative Recommendation",
      "abstract": "Semantic ID-based generative recommendation represents items as sequences of discrete tokens, but it inherently faces a trade-off between representational expressiveness and computational efficiency. Residual Quantization (RQ)-based approaches restrict semantic IDs to be short to enable tractable sequential modeling, while Optimized Product Quantization (OPQ)-based methods compress long semantic IDs through naive rigid aggregation, inevitably discarding fine-grained semantic information. To resolve this dilemma, we propose ACERec, a novel framework that decouples the granularity gap between fine-grained tokenization and efficient sequential modeling. It employs an Attentive Token Merger to distill long expressive semantic tokens into compact latents and introduces a dedicated Intent Token serving as a dynamic prediction anchor. To capture cohesive user intents, we guide the learning process via a dual-granularity objective, harmonizing fine-grained token prediction with global item-level semantic alignment. Extensive experiments on six real-world benchmarks demonstrate that ACERec consistently outperforms state-of-the-art baselines, achieving an average improvement of 14.40\\% in NDCG@10, effectively reconciling semantic expressiveness and computational efficiency.",
      "authors": [
        "Ming Xia",
        "Zhiqin Zhou",
        "Guoxin Ma",
        "Dongmin Huang"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-14 03:15:31+00:00",
      "link": "https://arxiv.org/pdf/2602.13573v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13559v1",
      "title": "OpAgent: Operator Agent for Web Navigation",
      "abstract": "To fulfill user instructions, autonomous web agents must contend with the inherent complexity and volatile nature of real-world websites. Conventional paradigms predominantly rely on Supervised Fine-Tuning (SFT) or Offline Reinforcement Learning (RL) using static datasets. However, these methods suffer from severe distributional shifts, as offline trajectories fail to capture the stochastic state transitions and real-time feedback of unconstrained wide web environments. In this paper, we propose a robust Online Reinforcement Learning WebAgent, designed to optimize its policy through direct, iterative interactions with unconstrained wide websites. Our approach comprises three core innovations: 1) Hierarchical Multi-Task Fine-tuning: We curate a comprehensive mixture of datasets categorized by functional primitives -- Planning, Acting, and Grounding -- establishing a Vision-Language Model (VLM) with strong instruction-following capabilities for Web GUI tasks. 2) Online Agentic RL in the Wild: We develop an online interaction environment and fine-tune the VLM using a specialized RL pipeline. We introduce a Hybrid Reward Mechanism that combines a ground-truth-agnostic WebJudge for holistic outcome assessment with a Rule-based Decision Tree (RDT) for progress reward. This system effectively mitigates the credit assignment challenge in long-horizon navigation. Notably, our RL-enhanced model achieves a 38.1\\% success rate (pass@5) on WebArena, outperforming all existing monolithic baselines. 3) Operator Agent: We introduce a modular agentic framework, namely \\textbf{OpAgent}, orchestrating a Planner, Grounder, Reflector, and Summarizer. This synergy enables robust error recovery and self-correction, elevating the agent's performance to a new State-of-the-Art (SOTA) success rate of \\textbf{71.6\\%}.",
      "authors": [
        "Yuyu Guo",
        "Wenjie Yang",
        "Siyuan Yang",
        "Ziyang Liu",
        "Cheng Chen",
        "Yuan Wei",
        "Yun Hu",
        "Yang Huang",
        "Guoliang Hao",
        "Dongsheng Yuan",
        "Jianming Wang",
        "Xin Chen",
        "Hang Yu",
        "Lei Lei",
        "Peng Di"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-14 02:33:55+00:00",
      "link": "https://arxiv.org/pdf/2602.13559v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13556v1",
      "title": "Discrete-Space Generative AI Pipeline for Semantic Transmission of Signals",
      "abstract": "We introduce Discernment, a semantic communication system that transmits the meaning of physical signals (baseband radio and audio) over a technical channel using GenAI models operating in discrete spaces. Discernment dynamically adapts to channel impairments - modeled as erasure channels - by switching between an autoregressive or a diffusion-based generative algorithm, depending on the erasure pattern. Our results show that Discernment maintains semantic integrity even as channel capacity severely degrades, exhibiting very small and graceful performance decline in both classification accuracy and statistical fidelity of the reconstructed meaning. These findings demonstrate Discernment's ability to adjust to diverse physical channel conditions while maintaining spectral efficiency and low model complexity, making it well suited for IoT deployments and strongly motivating further research on this semantic channel paradigm.",
      "authors": [
        "Silvija Kokalj-Filipovic",
        "Yagna Kaasaragadda"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "cs.AI",
        "eess.SP"
      ],
      "published": "2026-02-14 02:11:46+00:00",
      "link": "https://arxiv.org/pdf/2602.13556v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13549v1",
      "title": "Nighttime Autonomous Driving Scene Reconstruction with Physically-Based Gaussian Splatting",
      "abstract": "This paper focuses on scene reconstruction under nighttime conditions in autonomous driving simulation. Recent methods based on Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting (3DGS) have achieved photorealistic modeling in autonomous driving scene reconstruction, but they primarily focus on normal-light conditions. Low-light driving scenes are more challenging to model due to their complex lighting and appearance conditions, which often causes performance degradation of existing methods. To address this problem, this work presents a novel approach that integrates physically based rendering into 3DGS to enhance nighttime scene reconstruction for autonomous driving. Specifically, our approach integrates physically based rendering into composite scene Gaussian representations and jointly optimizes Bidirectional Reflectance Distribution Function (BRDF) based material properties. We explicitly model diffuse components through a global illumination module and specular components by anisotropic spherical Gaussians. As a result, our approach improves reconstruction quality for outdoor nighttime driving scenes, while maintaining real-time rendering. Extensive experiments across diverse nighttime scenarios on two real-world autonomous driving datasets, including nuScenes and Waymo, demonstrate that our approach outperforms the state-of-the-art methods both quantitatively and qualitatively.",
      "authors": [
        "Tae-Kyeong Kim",
        "Xingxin Chen",
        "Guile Wu",
        "Chengjie Huang",
        "Dongfeng Bai",
        "Bingbing Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-14 01:49:23+00:00",
      "link": "https://arxiv.org/pdf/2602.13549v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13541v1",
      "title": "DWBench: Holistic Evaluation of Watermark for Dataset Copyright Auditing",
      "abstract": "The surging demand for large-scale datasets in deep learning has heightened the need for effective copyright protection, given the risks of unauthorized use to data owners. Although the dataset watermark technique holds promise for auditing and verifying usage, existing methods are hindered by inconsistent evaluations, which impede fair comparisons and assessments of real-world viability. To address this gap, we propose a two-layer taxonomy that categorizes methods by implementation (model-based vs. model-free injection; model-behavior vs. model-message verification), offering a structured framework for cross-task analysis. Then, we develop DWBench, a unified benchmark and open-source toolkit for systematically evaluating image dataset watermark techniques in classification and generation tasks.   Using DWBench, we assess 25 representative methods under standardized conditions, perturbation-based robustness tests, multi-watermark coexistence, and multi-user interference. In addition to reporting the results of four commonly used metrics, we present the results of two new metrics: sample significance for fine-grained watermark distinguishability and verification success rate for dataset-level auditing, which enable accurate and reproducible benchmarking. Key findings reveal inherent trade-offs: no single method dominates all scenarios; classification and generation tasks require specialized approaches; and existing techniques exhibit instability at low watermark rates and in realistic multi-user settings, with elevated false positives or performance declines. We hope that DWBench can facilitate advances in watermark reliability and practicality, thus strengthening copyright safeguards in the face of widespread AI-driven data exploitation.",
      "authors": [
        "Xiao Ren",
        "Xinyi Yu",
        "Linkang Du",
        "Min Chen",
        "Yuanchao Shu",
        "Zhou Su",
        "Yunjun Gao",
        "Zhikun Zhang"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-14 01:09:19+00:00",
      "link": "https://arxiv.org/pdf/2602.13541v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13513v2",
      "title": "Learning Gradient Flow: Using Equation Discovery to Accelerate Engineering Optimization",
      "abstract": "In this work, we investigate the use of data-driven equation discovery for dynamical systems to model and forecast continuous-time dynamics of unconstrained optimization problems. To avoid expensive evaluations of the objective function and its gradient, we leverage trajectory data on the optimization variables to learn the continuous-time dynamics associated with gradient descent, Newton's method, and ADAM optimization. The discovered gradient flows are then solved as a surrogate for the original optimization problem. To this end, we introduce the Learned Gradient Flow (LGF) optimizer, which is equipped to build surrogate models of variable polynomial order in full- or reduced-dimensional spaces at user-defined intervals in the optimization process. We demonstrate the efficacy of this approach on several standard problems from engineering mechanics and scientific machine learning, including two inverse problems, structural topology optimization, and two forward solves with different discretizations. Our results suggest that the learned gradient flows can significantly expedite convergence by capturing critical features of the optimization trajectory while avoiding expensive evaluations of the objective and its gradient.",
      "authors": [
        "Grant Norman",
        "Conor Rowan",
        "Kurt Maute",
        "Alireza Doostan"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.CE",
        "cs.LG",
        "math.DS",
        "math.NA"
      ],
      "published": "2026-02-13 22:44:33+00:00",
      "link": "https://arxiv.org/pdf/2602.13513v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13507v1",
      "title": "Benchmarking Video Foundation Models for Remote Parkinson's Disease Screening",
      "abstract": "Remote, video-based assessments offer a scalable pathway for Parkinson's disease (PD) screening. While traditional approaches rely on handcrafted features mimicking clinical scales, recent advances in video foundation models (VFMs) enable representation learning without task-specific customization. However, the comparative effectiveness of different VFM architectures across diverse clinical tasks remains poorly understood. We present a large-scale systematic study using a novel video dataset from 1,888 participants (727 with PD), comprising 32,847 videos across 16 standardized clinical tasks. We evaluate seven state-of-the-art VFMs -- including VideoPrism, V-JEPA, ViViT, and VideoMAE -- to determine their robustness in clinical screening. By evaluating frozen embeddings with a linear classification head, we demonstrate that task saliency is highly model-dependent: VideoPrism excels in capturing visual speech kinematics (no audio) and facial expressivity, while V-JEPA proves superior for upper-limb motor tasks. Notably, TimeSformer remains highly competitive for rhythmic tasks like finger tapping. Our experiments yield AUCs of 76.4-85.3% and accuracies of 71.5-80.6%. While high specificity (up to 90.3%) suggests strong potential for ruling out healthy individuals, the lower sensitivity (43.2-57.3%) highlights the need for task-aware calibration and integration of multiple tasks and modalities. Overall, this work establishes a rigorous baseline for VFM-based PD screening and provides a roadmap for selecting suitable tasks and architectures in remote neurological monitoring. Code and anonymized structured data are publicly available: https://anonymous.4open.science/r/parkinson\\_video\\_benchmarking-A2C5",
      "authors": [
        "Md Saiful Islam",
        "Ekram Hossain",
        "Abdelrahman Abdelkader",
        "Tariq Adnan",
        "Fazla Rabbi Mashrur",
        "Sooyong Park",
        "Praveen Kumar",
        "Qasim Sudais",
        "Natalia Chunga",
        "Nami Shah",
        "Jan Freyberg",
        "Christopher Kanan",
        "Ruth Schneider",
        "Ehsan Hoque"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 22:36:42+00:00",
      "link": "https://arxiv.org/pdf/2602.13507v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13499v1",
      "title": "Endogenous Epistemic Weighting under Heterogeneous Information: Beyond Majority Rule",
      "abstract": "Collective decision-making can be viewed as the problem of aggregating multiple noisy information channels about an unknown state of the world. Classical epistemic justifications of majority rule rely on restrictive assumptions about the homogeneity and symmetry of these channels, which are often violated in realistic environments. This paper introduces the Epistemic Shared-Choice Mechanism (ESCM), a lightweight and auditable procedure that endogenously estimates issue-specific signal reliability and assigns bounded, decision-specific voting weights. Using central limit approximations, the paper provides an analytical comparison between ESCM and unweighted majority rule, showing how their relative epistemic performance depends on the distributional structure of information in the population, including unimodal competence distributions and segmented environments with informed minorities. The results indicate that endogenous and bounded epistemic weighting can improve collective accuracy by merging procedural and epistemic requirements.",
      "authors": [
        "Enrico Manfredi"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN",
        "cs.GT",
        "physics.soc-ph"
      ],
      "published": "2026-02-13 22:13:27+00:00",
      "link": "https://arxiv.org/pdf/2602.13499v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13494v1",
      "title": "Quantum Speedups for Group Relaxations of Integer Linear Programs",
      "abstract": "Integer Linear Programs (ILPs) are a flexible and ubiquitous model for discrete optimization problems. Solving ILPs is \\textsf{NP-Hard} yet of great practical importance. Super-quadratic quantum speedups for ILPs have been difficult to obtain because classical algorithms for many-constraint ILPs are global and exhaustive, whereas quantum frameworks that offer super-quadratic speedup exploit local structure of the objective and feasible set. We address this via quantum algorithms for Gomory's group relaxation. The group relaxation of an ILP is obtained by dropping nonnegativity on variables that are positive in the optimal solution of the linear programming (LP) relaxation, while retaining integrality of the decision variables. We present a competitive feasibility-preserving classical local-search algorithm for the group relaxation, and a corresponding quantum algorithm that, under reasonable technical conditions, achieves a super-quadratic speedup. When the group relaxation satisfies a nondegeneracy condition analogous to, but stronger than, LP non-degeneracy, our approach yields the optimal solution to the original ILP. Otherwise, the group relaxation tightens bounds on the optimal objective value of the ILP, and can improve downstream branch-and-cut by reducing the integrality gap; we numerically observe this on several practically relevant ILPs. To achieve these results, we derive efficiently constructible constraint-preserving mixers for the group relaxation with favorable spectral properties, which are of independent interest.",
      "authors": [
        "Brandon Augustino",
        "Dylan Herman",
        "Guneykan Ozgul",
        "Jacob Watkins",
        "Atithi Acharya",
        "Enrico Fontana",
        "Junhyung Lyle Kim",
        "Shouvanik Chakrabarti"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.DS",
        "math.OC"
      ],
      "published": "2026-02-13 21:58:59+00:00",
      "link": "https://arxiv.org/pdf/2602.13494v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13455v1",
      "title": "Using Machine Learning to Enhance the Detection of Obfuscated Abusive Words in Swahili: A Focus on Child Safety",
      "abstract": "The rise of digital technology has dramatically increased the potential for cyberbullying and online abuse, necessitating enhanced measures for detection and prevention, especially among children. This study focuses on detecting abusive obfuscated language in Swahili, a low-resource language that poses unique challenges due to its limited linguistic resources and technological support. Swahili is chosen due to its popularity and being the most widely spoken language in Africa, with over 16 million native speakers and upwards of 100 million speakers in total, spanning regions in East Africa and some parts of the Middle East.   We employed machine learning models including Support Vector Machines (SVM), Logistic Regression, and Decision Trees, optimized through rigorous parameter tuning and techniques like Synthetic Minority Over-sampling Technique (SMOTE) to handle data imbalance. Our analysis revealed that, while these models perform well in high-dimensional textual data, our dataset's small size and imbalance limit our findings' generalizability. Precision, recall, and F1 scores were thoroughly analyzed, highlighting the nuanced performance of each model in detecting obfuscated language.   This research contributes to the broader discourse on ensuring safer online environments for children, advocating for expanded datasets and advanced machine-learning techniques to improve the effectiveness of cyberbullying detection systems. Future work will focus on enhancing data robustness, exploring transfer learning, and integrating multimodal data to create more comprehensive and culturally sensitive detection mechanisms.",
      "authors": [
        "Phyllis Nabangi",
        "Abdul-Jalil Zakaria",
        "Jema David Ndibwile"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "published": "2026-02-13 21:02:14+00:00",
      "link": "https://arxiv.org/pdf/2602.13455v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13433v1",
      "title": "Uncertain Pointer: Situated Feedforward Visualizations for Ambiguity-Aware AR Target Selection",
      "abstract": "Target disambiguation is crucial in resolving input ambiguity in augmented reality (AR), especially for queries over distant objects or cluttered scenes on the go. Yet, visual feedforward techniques that support this process remain underexplored. We present Uncertain Pointer, a systematic exploration of feedforward visualizations that annotate multiple candidate targets before user confirmation, either by adding distinct visual identities (e.g., colors) to support disambiguation or by modulating visual intensity (e.g., opacity) to convey system uncertainty. First, we construct a pointer space of 25 pointers by analyzing existing placement strategies and visual signifiers used in target visualizations across 30 years of relevant literature. We then evaluate them through two online experiments (n = 60 and 40), measuring user preference, confidence, mental ease, target visibility, and identifiability across varying object distances and sparsities. Finally, from the results, we derive design recommendations in choosing different Uncertain Pointers based on AR context and disambiguation techniques.",
      "authors": [
        "Ching-Yi Tsai",
        "Nicole Tacconi",
        "Andrew D. Wilson",
        "Parastoo Abtahi"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-13 20:19:56+00:00",
      "link": "https://arxiv.org/pdf/2602.13433v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13419v1",
      "title": "Protect$^*$: Steerable Retrosynthesis through Neuro-Symbolic State Encoding",
      "abstract": "Large Language Models (LLMs) have shown remarkable potential in scientific domains like retrosynthesis; yet, they often lack the fine-grained control necessary to navigate complex problem spaces without error. A critical challenge is directing an LLM to avoid specific, chemically sensitive sites on a molecule - a task where unconstrained generation can lead to invalid or undesirable synthetic pathways. In this work, we introduce Protect$^*$, a neuro-symbolic framework that grounds the generative capabilities of Large Language Models (LLMs) in rigorous chemical logic. Our approach combines automated rule-based reasoning - using a comprehensive database of 55+ SMARTS patterns and 40+ characterized protecting groups - with the generative intuition of neural models. The system operates via a hybrid architecture: an ``automatic mode'' where symbolic logic deterministically identifies and guards reactive sites, and a ``human-in-the-loop mode'' that integrates expert strategic constraints. Through ``active state tracking,'' we inject hard symbolic constraints into the neural inference process via a dedicated protection state linked to canonical atom maps. We demonstrate this neuro-symbolic approach through case studies on complex natural products, including the discovery of a novel synthetic pathway for Erythromycin B, showing that grounding neural generation in symbolic logic enables reliable, expert-level autonomy.",
      "authors": [
        "Shreyas Vinaya Sathyanarayana",
        "Shah Rahil Kirankumar",
        "Sharanabasava D. Hiremath",
        "Bharath Ramsundar"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-bio.BM"
      ],
      "published": "2026-02-13 19:41:55+00:00",
      "link": "https://arxiv.org/pdf/2602.13419v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13414v1",
      "title": "FUTON: Fourier Tensor Network for Implicit Neural Representations",
      "abstract": "Implicit neural representations (INRs) have emerged as powerful tools for encoding signals, yet dominant MLP-based designs often suffer from slow convergence, overfitting to noise, and poor extrapolation. We introduce FUTON (Fourier Tensor Network), which models signals as generalized Fourier series whose coefficients are parameterized by a low-rank tensor decomposition. FUTON implicitly expresses signals as weighted combinations of orthonormal, separable basis functions, combining complementary inductive biases: Fourier bases capture smoothness and periodicity, while the low-rank parameterization enforces low-dimensional spectral structure. We provide theoretical guarantees through a universal approximation theorem and derive an inference algorithm with complexity linear in the spectral resolution and the input dimension. On image and volume representation, FUTON consistently outperforms state-of-the-art MLP-based INRs while training 2--5$\\times$ faster. On inverse problems such as image denoising and super-resolution, FUTON generalizes better and converges faster.",
      "authors": [
        "Pooya Ashtari",
        "Pourya Behmandpoor",
        "Nikos Deligiannis",
        "Aleksandra Pizurica"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG",
        "eess.SP"
      ],
      "published": "2026-02-13 19:31:44+00:00",
      "link": "https://arxiv.org/pdf/2602.13414v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13410v1",
      "title": "Evolutionary design of thermodynamic logic gates and their heat emission",
      "abstract": "Landauer's principle bounds the heat generated by logical operations, but in practice the thermodynamic cost of computation is dominated by the control systems that implement logic. CMOS gates dissipate energy far above the Landauer bound, while laboratory demonstrations of near-Landauer erasure rely on external measurement or feedback systems whose energy costs exceed that of the logic operation by many orders of magnitude. Here we use simulations to show that a genetic algorithm can program a thermodynamic computer to implement logic operations in which the total heat emitted by the control system is of a similar order of magnitude to that of the information-bearing degrees of freedom. Moreover, the computer can be programmed so that heat is drawn away from the information-bearing degrees of freedom and dissipated within the control unit, suggesting the possibility of computing architectures in which heat management is an integral part of the program design.",
      "authors": [
        "Stephen Whitelam"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "cs.NE"
      ],
      "published": "2026-02-13 19:17:56+00:00",
      "link": "https://arxiv.org/pdf/2602.13410v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13398v1",
      "title": "Accelerated Discovery of Cryoprotectant Cocktails via Multi-Objective Bayesian Optimization",
      "abstract": "Designing cryoprotectant agent (CPA) cocktails for vitrification is challenging because formulations must be concentrated enough to suppress ice formation yet non-toxic enough to preserve cell viability. This tradeoff creates a large, multi-objective design space in which traditional discovery is slow, often relying on expert intuition or exhaustive experimentation. We present a data-efficient framework that accelerates CPA cocktail design by combining high-throughput screening with an active-learning loop based on multi-objective Bayesian optimization. From an initial set of measured cocktails, we train probabilistic surrogate models to predict concentration and viability and quantify uncertainty across candidate formulations. We then iteratively select the next experiments by prioritizing cocktails expected to improve the Pareto front, maximizing expected Pareto improvement under uncertainty, and update the models as new assay results are collected. Wet-lab validation shows that our approach efficiently discovers cocktails that simultaneously achieve high CPA concentrations and high post-exposure viability. Relative to a naive strategy and a strong baseline, our method improves dominated hypervolume by 9.5\\% and 4.5\\%, respectively, while reducing the number of experiments needed to reach high-quality solutions. In complementary synthetic studies, it recovers a comparably strong set of Pareto-optimal solutions using only 30\\% of the evaluations required by the prior state-of-the-art multi-objective approach, which amounts to saving approximately 10 weeks of experimental time. Because the framework assumes only a suitable assay and defined formulation space, it can be adapted to different CPA libraries, objective definitions, and cell lines to accelerate cryopreservation development.",
      "authors": [
        "Daniel Emerson",
        "Nora Gaby-Biegel",
        "Purva Joshi",
        "Yoed Rabin",
        "Rebecca D. Sandlin",
        "Levent Burak Kara"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "q-bio.QM"
      ],
      "published": "2026-02-13 19:02:05+00:00",
      "link": "https://arxiv.org/pdf/2602.13398v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14979v1",
      "title": "RynnBrain: Open Embodied Foundation Models",
      "abstract": "Despite rapid progress in multimodal foundation models, embodied intelligence community still lacks a unified, physically grounded foundation model that integrates perception, reasoning, and planning within real-world spatial-temporal dynamics. We introduce RynnBrain, an open-source spatiotemporal foundation model for embodied intelligence. RynnBrain strengthens four core capabilities in a unified framework: comprehensive egocentric understanding, diverse spatiotemporal localization, physically grounded reasoning, and physics-aware planning. The RynnBrain family comprises three foundation model scales (2B, 8B, and 30B-A3B MoE) and four post-trained variants tailored for downstream embodied tasks (i.e., RynnBrain-Nav, RynnBrain-Plan, and RynnBrain-VLA) or complex spatial reasoning tasks (i.e., RynnBrain-CoP). In terms of extensive evaluations on 20 embodied benchmarks and 8 general vision understanding benchmarks, our RynnBrain foundation models largely outperform existing embodied foundation models by a significant margin. The post-trained model suite further substantiates two key potentials of the RynnBrain foundation model: (i) enabling physically grounded reasoning and planning, and (ii) serving as a strong pretrained backbone that can be efficiently adapted to diverse embodied tasks.",
      "authors": [
        "Ronghao Dang",
        "Jiayan Guo",
        "Bohan Hou",
        "Sicong Leng",
        "Kehan Li",
        "Xin Li",
        "Jiangpin Liu",
        "Yunxuan Mao",
        "Zhikai Wang",
        "Yuqian Yuan",
        "Minghao Zhu",
        "Xiao Lin",
        "Yang Bai",
        "Qian Jiang",
        "Yaxi Zhao",
        "Minghua Zeng",
        "Junlong Gao",
        "Yuming Jiang",
        "Jun Cen",
        "Siteng Huang",
        "Liuyi Wang",
        "Wenqiao Zhang",
        "Chengju Liu",
        "Jianfei Yang",
        "Shijian Lu",
        "Deli Zhao"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-13 18:59:56+00:00",
      "link": "https://arxiv.org/pdf/2602.14979v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13195v1",
      "title": "Conversational Image Segmentation: Grounding Abstract Concepts with Scalable Supervision",
      "abstract": "Conversational image segmentation grounds abstract, intent-driven concepts into pixel-accurate masks. Prior work on referring image grounding focuses on categorical and spatial queries (e.g., \"left-most apple\") and overlooks functional and physical reasoning (e.g., \"where can I safely store the knife?\"). We address this gap and introduce Conversational Image Segmentation (CIS) and ConverSeg, a benchmark spanning entities, spatial relations, intent, affordances, functions, safety, and physical reasoning. We also present ConverSeg-Net, which fuses strong segmentation priors with language understanding, and an AI-powered data engine that generates prompt-mask pairs without human supervision. We show that current language-guided segmentation models are inadequate for CIS, while ConverSeg-Net trained on our data engine achieves significant gains on ConverSeg and maintains strong performance on existing language-guided segmentation benchmarks. Project webpage: https://glab-caltech.github.io/converseg/",
      "authors": [
        "Aadarsh Sahoo",
        "Georgia Gkioxari"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 18:58:30+00:00",
      "link": "https://arxiv.org/pdf/2602.13195v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13181v1",
      "title": "Selection of CMIP6 Models for Regional Precipitation Projection and Climate Change Assessment in the Jhelum and Chenab River Basins",
      "abstract": "Effective water resource management depends on accurate projections of flows in water channels. For projected climate data, use of different General Circulation Models (GCM) simulates contrasting results. This study shows selection of GCM for the latest generation CMIP6 for hydroclimate change impact studies. Envelope based method was used for the selection, which includes components based on machine learning techniques, allowing the selection of GCMs without the need for in-situ reference data. According to our knowledge, for the first time, such a comparison was performed for the CMIP6 Shared Socioeconomic Pathway (SSP) scenarios data. In addition, the effect of climate change under SSP scenarios was studied, along with the calculation of extreme indices. Finally, GCMs were compared to quantify spatiotemporal differences between CMIP5 and CMIP6 data. Results provide NorESM2 LM, FGOALS g3 as selected models for the Jhelum and Chenab River. Highly vulnerable regions under the effect of climate change were highlighted through spatial maps, which included parts of Punjab, Jammu, and Kashmir. Upon comparison of CMIP5 and CMIP6, no discernible difference was found between the RCP and SSP scenarios precipitation projections. In the future, more detailed statistical comparisons could further reinforce the proposition.",
      "authors": [
        "Saad Ahmed Jamal",
        "Ammara Nusrat",
        "Muhammad Azmat",
        "Muhammad Osama Nusrat"
      ],
      "primary_category": "physics.ao-ph",
      "categories": [
        "physics.ao-ph",
        "cs.LG"
      ],
      "published": "2026-02-13 18:41:40+00:00",
      "link": "https://arxiv.org/pdf/2602.13181v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13378v1",
      "title": "LAF-YOLOv10 with Partial Convolution Backbone, Attention-Guided Feature Pyramid, Auxiliary P2 Head, and Wise-IoU Loss for Small Object Detection in Drone Aerial Imagery",
      "abstract": "Unmanned aerial vehicles serve as primary sensing platforms for surveillance, traffic monitoring, and disaster response, making aerial object detection a central problem in applied computer vision. Current detectors struggle with UAV-specific challenges: targets spanning only a few pixels, cluttered backgrounds, heavy occlusion, and strict onboard computational budgets. This study introduces LAF-YOLOv10, built on YOLOv10n, integrating four complementary techniques to improve small-object detection in drone imagery. A Partial Convolution C2f (PC-C2f) module restricts spatial convolution to one quarter of backbone channels, reducing redundant computation while preserving discriminative capacity. An Attention-Guided Feature Pyramid Network (AG-FPN) inserts Squeeze-and-Excitation channel gates before multi-scale fusion and replaces nearest-neighbor upsampling with DySample for content-aware interpolation. An auxiliary P2 detection head at 160$\\times$160 resolution extends localization to objects below 8$\\times$8 pixels, while the P5 head is removed to redistribute parameters. Wise-IoU v3 replaces CIoU for bounding box regression, attenuating gradients from noisy annotations in crowded aerial scenes. The four modules address non-overlapping bottlenecks: PC-C2f compresses backbone computation, AG-FPN refines cross-scale fusion, the P2 head recovers spatial resolution, and Wise-IoU stabilizes regression under label noise. No individual component is novel; the contribution is the joint integration within a single YOLOv10 framework. Across three training runs (seeds 42, 123, 256), LAF-YOLOv10 achieves 35.1$\\pm$0.3\\% mAP@0.5 on VisDrone-DET2019 with 2.3\\,M parameters, exceeding YOLOv10n by 3.3 points. Cross-dataset evaluation on UAVDT yields 35.8$\\pm$0.4\\% mAP@0.5. Benchmarks on NVIDIA Jetson Orin Nano confirm 24.3 FPS at FP16, demonstrating viability for embedded UAV deployment.",
      "authors": [
        "Sohail Ali Farooqui",
        "Zuhair Ahmed Khan Taha",
        "Mohammed Mudassir Uddin",
        "Shahnawaz Alam"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-13 18:23:54+00:00",
      "link": "https://arxiv.org/pdf/2602.13378v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13377v1",
      "title": "A Survey of Code Review Benchmarks and Evaluation Practices in Pre-LLM and LLM Era",
      "abstract": "Code review is a critical practice in modern software engineering, helping developers detect defects early, improve code quality, and facilitate knowledge sharing. With the rapid advancement of large language models (LLMs), a growing body of work has explored automated support for code review. However, progress in this area is hindered by the lack of a systematic understanding of existing benchmarks and evaluation practices. Current code review datasets are scattered, vary widely in design, and provide limited insight into what review capabilities are actually being assessed. In this paper, we present a comprehensive survey of code review benchmarks spanning both the Pre-LLM and LLM eras (2015--2025). We analyze 99 research papers (58 Pre-LLM era and 41 LLM era) and extract key metadata, including datasets, evaluation metrics, data sources, and target tasks. Based on this analysis, we propose a multi-level taxonomy that organizes code review research into five domains and 18 fine-grained tasks. Our study reveals a clear shift toward end-to-end generative peer review, increasing multilingual coverage, and a decline in standalone change understanding tasks. We further identify limitations of current benchmarks and outline future directions, including broader task coverage, dynamic runtime evaluation, and taxonomy-guided fine-grained assessment. This survey provides a structured foundation for developing more realistic and comprehensive benchmarks for LLM-based code review.",
      "authors": [
        "Taufiqul Islam Khan",
        "Shaowei Wang",
        "Haoxiang Zhang",
        "Tse-Hsun Chen"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-13 18:19:38+00:00",
      "link": "https://arxiv.org/pdf/2602.13377v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13156v1",
      "title": "In-Context Autonomous Network Incident Response: An End-to-End Large Language Model Agent Approach",
      "abstract": "Rapidly evolving cyberattacks demand incident response systems that can autonomously learn and adapt to changing threats. Prior work has extensively explored the reinforcement learning approach, which involves learning response strategies through extensive simulation of the incident. While this approach can be effective, it requires handcrafted modeling of the simulator and suppresses useful semantics from raw system logs and alerts. To address these limitations, we propose to leverage large language models' (LLM) pre-trained security knowledge and in-context learning to create an end-to-end agentic solution for incident response planning. Specifically, our agent integrates four functionalities, perception, reasoning, planning, and action, into one lightweight LLM (14b model). Through fine-tuning and chain-of-thought reasoning, our LLM agent is capable of processing system logs and inferring the underlying network state (perception), updating its conjecture of attack models (reasoning), simulating consequences under different response strategies (planning), and generating an effective response (action). By comparing LLM-simulated outcomes with actual observations, the LLM agent repeatedly refines its attack conjecture and corresponding response, thereby demonstrating in-context adaptation. Our agentic approach is free of modeling and can run on commodity hardware. When evaluated on incident logs reported in the literature, our agent achieves recovery up to 23% faster than those of frontier LLMs.",
      "authors": [
        "Yiran Gao",
        "Kim Hammar",
        "Tao Li"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "published": "2026-02-13 18:09:30+00:00",
      "link": "https://arxiv.org/pdf/2602.13156v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13155v1",
      "title": "Learning to Approximate Uniform Facility Location via Graph Neural Networks",
      "abstract": "There has been a growing interest in using neural networks, especially message-passing neural networks (MPNNs), to solve hard combinatorial optimization problems heuristically. However, existing learning-based approaches for hard combinatorial optimization tasks often rely on supervised training data, reinforcement learning, or gradient estimators, leading to significant computational overhead, unstable training, or a lack of provable performance guarantees. In contrast, classical approximation algorithms offer such performance guarantees under worst-case inputs but are non-differentiable and unable to adaptively exploit structural regularities in natural input distributions. We address this dichotomy with the fundamental example of Uniform Facility Location (UniFL), a variant of the combinatorial facility location problem with applications in clustering, data summarization, logistics, and supply chain design. We develop a fully differentiable MPNN model that embeds approximation-algorithmic principles while avoiding the need for solver supervision or discrete relaxations. Our approach admits provable approximation and size generalization guarantees to much larger instances than seen during training. Empirically, we show that our approach outperforms standard non-learned approximation algorithms in terms of solution quality, closing the gap with computationally intensive integer linear programming approaches. Overall, this work provides a step toward bridging learning-based methods and approximation algorithms for discrete optimization.",
      "authors": [
        "Chendi Qian",
        "Christopher Morris",
        "Stefanie Jegelka",
        "Christian Sohler"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.DS",
        "cs.NE",
        "stat.ML"
      ],
      "published": "2026-02-13 18:08:23+00:00",
      "link": "https://arxiv.org/pdf/2602.13155v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13154v4",
      "title": "Peaceful Anarcho-Accelerationism: Decentralized Full Automation for a Society of Universal Care",
      "abstract": "Foundational results in machine learning like the universal approximation theorem and deep reinforcement learning convergence and the progressive scale of technology imply that the vast majority of instrumental labor may be progressively automated. Consequently, as this process accelerates, the critical question becomes one of governance: who controls the machines, hence the labor and capital, and toward what ends? Predicting a post-capitalism future, this paper introduces an alternative system for society: anarcho-accelerationism. Concretely, it is a sociotechnical framework in which full automation is decentralized, commons-governed, and oriented toward universal care. To make it happen, I propose the Liberation Stack, a layered architecture of energy, manufacturing, food, communication, knowledge, and governance commons, powered by frontier clean energy technologies within an accelerationist ecologism that achieves sustainability through abundance rather than degrowth. As safety net, this system introduces Universal Desired Resources (UDR) as a post-monetary design principle and show that UDR constitutes the most comprehensive intersectional intervention yet proposed: by eliminating the material basis of oppression, it dissolves all axes of structural inequality simultaneously. Drawing on Maslow's hierarchy, I show that the Liberation Stack satisfies basic needs universally, enabling what the accelerationis literature terms synthetic liberty, the positive freedom that emerges when commons infrastructure provides the material conditions for genuine autonomy. Finally, given a set of assumptions and constraints, I propose a progressive transition from Universal Basic Income to UDR with a phased roadmap and present empirical evidence from Linux, Wikipedia, Mondragon and Rojava confirming that commons-based systems operate at scale.",
      "authors": [
        "Eduardo C. Garrido-Merchán"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "published": "2026-02-13 18:07:57+00:00",
      "link": "https://arxiv.org/pdf/2602.13154v4",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13144v1",
      "title": "The Only Distributive Law Over the Powerset Monad Is the One You Know",
      "abstract": "Distributive laws of set functors over the powerset monad (also known as Kleisli laws for the powerset monad) are well-known to be in one-to-one correspondence with extensions of set functors to functors on the category of sets and relations. We study the question of existence and uniqueness of such distributive laws. Our main result entails that an accessible set functor admits a distributive law over the powerset monad if and only if it preserves weak pullbacks, in which case the so-called power law (which induces the Barr extension) is the unique one. Furthermore, we show that the powerset functor admits exactly three distributive laws over the powerset monad, revealing that uniqueness may fail for non-accessible functors.",
      "authors": [
        "Sergey Goncharov",
        "Dirk Hofmann",
        "Pedro Nora",
        "Lutz Schröder",
        "Paul Wild"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-02-13 17:54:16+00:00",
      "link": "https://arxiv.org/pdf/2602.13144v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13140v1",
      "title": "FlashSchNet: Fast and Accurate Coarse-Grained Neural Network Molecular Dynamics",
      "abstract": "Graph neural network (GNN) potentials such as SchNet improve the accuracy and transferability of molecular dynamics (MD) simulation by learning many-body interactions, but remain slower than classical force fields due to fragmented kernels and memory-bound pipelines that underutilize GPUs. We show that a missing principle is making GNN-MD IO-aware, carefully accounting for reads and writes between GPU high-bandwidth memory (HBM) and on-chip SRAM. We present FlashSchNet, an efficient and accurate IO-aware SchNet-style GNN-MD framework built on four techniques: (1) flash radial basis, which fuses pairwise distance computation, Gaussian basis expansion, and cosine envelope into a single tiled pass, computing each distance once and reusing it across all basis functions; (2) flash message passing, which fuses cutoff, neighbor gather, filter multiplication, and reduction to avoid materializing edge tensors in HBM; (3) flash aggregation, which reformulates scatter-add via CSR segment reduce, reducing atomic writes by a factor of feature dimension and enabling contention-free accumulation in both forward and backward passes; (4) channel-wise 16-bit quantization that exploits the low per-channel dynamic range in SchNet MLP weights to further improve throughput with negligible accuracy loss. On a single NVIDIA RTX PRO 6000, FlashSchNet achieves 1000 ns/day aggregate simulation throughput over 64 parallel replicas on coarse-grained (CG) protein containing 269 beads (6.5x faster than CGSchNet baseline with 80% reduction of peak memory), surpassing classical force fields (e.g. MARTINI) while retaining SchNet-level accuracy and transferability.",
      "authors": [
        "Pingzhi Li",
        "Hongxuan Li",
        "Zirui Liu",
        "Xingcheng Lin",
        "Tianlong Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CE"
      ],
      "published": "2026-02-13 17:49:12+00:00",
      "link": "https://arxiv.org/pdf/2602.13140v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13136v1",
      "title": "Order Matters in Retrosynthesis: Structure-aware Generation via Reaction-Center-Guided Discrete Flow Matching",
      "abstract": "Template-free retrosynthesis methods treat the task as black-box sequence generation, limiting learning efficiency, while semi-template approaches rely on rigid reaction libraries that constrain generalization. We address this gap with a key insight: atom ordering in neural representations matters. Building on this insight, we propose a structure-aware template-free framework that encodes the two-stage nature of chemical reactions as a positional inductive bias. By placing reaction center atoms at the sequence head, our method transforms implicit chemical knowledge into explicit positional patterns that the model can readily capture. The proposed RetroDiT backbone, a graph transformer with rotary position embeddings, exploits this ordering to prioritize chemically critical regions. Combined with discrete flow matching, our approach decouples training from sampling and enables generation in 20--50 steps versus 500 for prior diffusion methods. Our method achieves state-of-the-art performance on both USPTO-50k (61.2% top-1) and the large-scale USPTO-Full (51.3% top-1) with predicted reaction centers. With oracle centers, performance reaches 71.1% and 63.4% respectively, surpassing foundation models trained on 10 billion reactions while using orders of magnitude less data. Ablation studies further reveal that structural priors outperform brute-force scaling: a 280K-parameter model with proper ordering matches a 65M-parameter model without it.",
      "authors": [
        "Chenguang Wang",
        "Zihan Zhou",
        "Lei Bai",
        "Tianshu Yu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 17:39:21+00:00",
      "link": "https://arxiv.org/pdf/2602.13136v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13128v1",
      "title": "Eventizing Traditionally Opaque Binary Neural Networks as 1-safe Petri net Models",
      "abstract": "Binary Neural Networks (BNNs) offer a low-complexity and energy-efficient alternative to traditional full-precision neural networks by constraining their weights and activations to binary values. However, their discrete, highly non-linear behavior makes them difficult to explain, validate and formally verify. As a result, BNNs remain largely opaque, limiting their suitability in safety-critical domains, where causal transparency and behavioral guarantees are essential. In this work, we introduce a Petri net (PN)-based framework that captures the BNN's internal operations as event-driven processes. By \"eventizing\" their operations, we expose their causal relationships and dependencies for a fine-grained analysis of concurrency, ordering, and state evolution. Here, we construct modular PN blueprints for core BNN components including activation, gradient computation and weight updates, and compose them into a complete system-level model. We then validate the composed PN against a reference software-based BNN, verify it against reachability and structural checks to establish 1-safeness, deadlock-freeness, mutual exclusion and correct-by-construction causal sequencing, before we assess its scalability and complexity at segment, component, and system levels using the automated measurement tools in Workcraft. Overall, this framework enables causal introspection of transparent and event-driven BNNs that are amenable to formal reasoning and verification.",
      "authors": [
        "Mohamed Tarraf",
        "Alex Chan",
        "Alex Yakovlev",
        "Rishad Shafik"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 17:25:47+00:00",
      "link": "https://arxiv.org/pdf/2602.13128v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13106v1",
      "title": "Which Algorithms Can Graph Neural Networks Learn?",
      "abstract": "In recent years, there has been growing interest in understanding neural architectures' ability to learn to execute discrete algorithms, a line of work often referred to as neural algorithmic reasoning. The goal is to integrate algorithmic reasoning capabilities into larger neural pipelines. Many such architectures are based on (message-passing) graph neural networks (MPNNs), owing to their permutation equivariance and ability to deal with sparsity and variable-sized inputs. However, existing work is either largely empirical and lacks formal guarantees or it focuses solely on expressivity, leaving open the question of when and how such architectures generalize beyond a finite training set. In this work, we propose a general theoretical framework that characterizes the sufficient conditions under which MPNNs can learn an algorithm from a training set of small instances and provably approximate its behavior on inputs of arbitrary size. Our framework applies to a broad class of algorithms, including single-source shortest paths, minimum spanning trees, and general dynamic programming problems, such as the $0$-$1$ knapsack problem. In addition, we establish impossibility results for a wide range of algorithmic tasks, showing that standard MPNNs cannot learn them, and we derive more expressive MPNN-like architectures that overcome these limitations. Finally, we refine our analysis for the Bellman-Ford algorithm, yielding a substantially smaller required training set and significantly extending the recent work of Nerem et al. [2025] by allowing for a differentiable regularization loss. Empirical results largely support our theoretical findings.",
      "authors": [
        "Solveig Wittig",
        "Antonis Vasileiou",
        "Robert R. Nerem",
        "Timo Stoll",
        "Floris Geerts",
        "Yusu Wang",
        "Christopher Morris"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS",
        "cs.NE"
      ],
      "published": "2026-02-13 17:09:50+00:00",
      "link": "https://arxiv.org/pdf/2602.13106v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13093v2",
      "title": "Consistency of Large Reasoning Models Under Multi-Turn Attacks",
      "abstract": "Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.",
      "authors": [
        "Yubo Li",
        "Ramayya Krishnan",
        "Rema Padman"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-13 16:58:47+00:00",
      "link": "https://arxiv.org/pdf/2602.13093v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13091v1",
      "title": "Universal Transformation of One-Class Classifiers for Unsupervised Anomaly Detection",
      "abstract": "Detecting anomalies in images and video is an essential task for multiple real-world problems, including industrial inspection, computer-assisted diagnosis, and environmental monitoring. Anomaly detection is typically formulated as a one-class classification problem, where the training data consists solely of nominal values, leaving methods built on this assumption susceptible to training label noise. We present a dataset folding method that transforms an arbitrary one-class classifier-based anomaly detector into a fully unsupervised method. This is achieved by making a set of key weak assumptions: that anomalies are uncommon in the training dataset and generally heterogeneous. These assumptions enable us to utilize multiple independently trained instances of a one-class classifier to filter the training dataset for anomalies. This transformation requires no modifications to the underlying anomaly detector; the only changes are algorithmically selected data subsets used for training. We demonstrate that our method can transform a wide variety of one-class classifier anomaly detectors for both images and videos into unsupervised ones. Our method creates the first unsupervised logical anomaly detectors by transforming existing methods. We also demonstrate that our method achieves state-of-the-art performance for unsupervised anomaly detection on the MVTec AD, ViSA, and MVTec Loco AD datasets. As improvements to one-class classifiers are made, our method directly transfers those improvements to the unsupervised domain, linking the domains.",
      "authors": [
        "Declan McIntosh",
        "Alexandra Branzan Albu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 16:54:12+00:00",
      "link": "https://arxiv.org/pdf/2602.13091v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13072v1",
      "title": "Automated Testing of Task-based Chatbots: How Far Are We?",
      "abstract": "Task-based chatbots are software, typically embedded in real-world applications, that assist users in completing tasks through a conversational interface. As chatbots are gaining popularity, effectively assessing their quality has become crucial. Whereas traditional testing techniques fail to systematically exercise the conversational space of chatbots, several approaches specifically targeting chatbots have emerged from both industry and research. Although these techniques have shown advancements over the years, they still exhibit limitations, such as simplicity of the generated test scenarios and weakness in implemented oracles. In this paper, we conduct a confirmatory study to investigate such limitations by evaluating the effectiveness of state-of-the-art chatbot testing techniques on a curated selection of task-based chatbots from GitHub, developed using the most popular commercial and open-source platforms.",
      "authors": [
        "Diego Clerissi",
        "Elena Masserini",
        "Daniela Micucci",
        "Leonardo Mariani"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-13 16:32:50+00:00",
      "link": "https://arxiv.org/pdf/2602.13072v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13067v1",
      "title": "SIEFormer: Spectral-Interpretable and -Enhanced Transformer for Generalized Category Discovery",
      "abstract": "This paper presents a novel approach, Spectral-Interpretable and -Enhanced Transformer (SIEFormer), which leverages spectral analysis to reinterpret the attention mechanism within Vision Transformer (ViT) and enhance feature adaptability, with particular emphasis on challenging Generalized Category Discovery (GCD) tasks. The proposed SIEFormer is composed of two main branches, each corresponding to an implicit and explicit spectral perspective of the ViT, enabling joint optimization. The implicit branch realizes the use of different types of graph Laplacians to model the local structure correlations of tokens, along with a novel Band-adaptive Filter (BaF) layer that can flexibly perform both band-pass and band-reject filtering. The explicit branch, on the other hand, introduces a Maneuverable Filtering Layer (MFL) that learns global dependencies among tokens by applying the Fourier transform to the input ``value\" features, modulating the transformed signal with a set of learnable parameters in the frequency domain, and then performing an inverse Fourier transform to obtain the enhanced features. Extensive experiments reveal state-of-the-art performance on multiple image recognition datasets, reaffirming the superiority of our approach through ablation studies and visualizations.",
      "authors": [
        "Chunming Li",
        "Shidong Wang",
        "Tong Xin",
        "Haofeng Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 16:22:31+00:00",
      "link": "https://arxiv.org/pdf/2602.13067v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13062v1",
      "title": "Backdoor Attacks on Contrastive Continual Learning for IoT Systems",
      "abstract": "The Internet of Things (IoT) systems increasingly depend on continual learning to adapt to non-stationary environments. These environments can include factors such as sensor drift, changing user behavior, device aging, and adversarial dynamics. Contrastive continual learning (CCL) combines contrastive representation learning with incremental adaptation, enabling robust feature reuse across tasks and domains. However, the geometric nature of contrastive objectives, when paired with replay-based rehearsal and stability-preserving regularization, introduces new security vulnerabilities. Notably, backdoor attacks can exploit embedding alignment and replay reinforcement, enabling the implantation of persistent malicious behaviors that endure through updates and deployment cycles. This paper provides a comprehensive analysis of backdoor attacks on CCL within IoT systems. We formalize the objectives of embedding-level attacks, examine persistence mechanisms unique to IoT deployments, and develop a layered taxonomy tailored to IoT. Additionally, we compare vulnerabilities across various learning paradigms and evaluate defense strategies under IoT constraints, including limited memory, edge computing, and federated aggregation. Our findings indicate that while CCL is effective for enhancing adaptive IoT intelligence, it may also elevate long-lived representation-level threats if not adequately secured.",
      "authors": [
        "Alfous Tim",
        "Kuniyilh Simi D"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CR",
        "cs.NI"
      ],
      "published": "2026-02-13 16:17:25+00:00",
      "link": "https://arxiv.org/pdf/2602.13062v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13055v1",
      "title": "Curriculum-DPO++: Direct Preference Optimization via Data and Model Curricula for Text-to-Image Generation",
      "abstract": "Direct Preference Optimization (DPO) has been proposed as an effective and efficient alternative to reinforcement learning from human feedback (RLHF). However, neither RLHF nor DPO take into account the fact that learning certain preferences is more difficult than learning other preferences, rendering the optimization process suboptimal. To address this gap in text-to-image generation, we recently proposed Curriculum-DPO, a method that organizes image pairs by difficulty. In this paper, we introduce Curriculum-DPO++, an enhanced method that combines the original data-level curriculum with a novel model-level curriculum. More precisely, we propose to dynamically increase the learning capacity of the denoising network as training advances. We implement this capacity increase via two mechanisms. First, we initialize the model with only a subset of the trainable layers used in the original Curriculum-DPO. As training progresses, we sequentially unfreeze layers until the configuration matches the full baseline architecture. Second, as the fine-tuning is based on Low-Rank Adaptation (LoRA), we implement a progressive schedule for the dimension of the low-rank matrices. Instead of maintaining a fixed capacity, we initialize the low-rank matrices with a dimension significantly smaller than that of the baseline. As training proceeds, we incrementally increase their rank, allowing the capacity to grow until it converges to the same rank value as in Curriculum-DPO. Furthermore, we propose an alternative ranking strategy to the one employed by Curriculum-DPO. Finally, we compare Curriculum-DPO++ against Curriculum-DPO and other state-of-the-art preference optimization approaches on nine benchmarks, outperforming the competing methods in terms of text alignment, aesthetics and human preference. Our code is available at https://github.com/CroitoruAlin/Curriculum-DPO.",
      "authors": [
        "Florinel-Alin Croitoru",
        "Vlad Hondru",
        "Radu Tudor Ionescu",
        "Nicu Sebe",
        "Mubarak Shah"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-13 16:09:31+00:00",
      "link": "https://arxiv.org/pdf/2602.13055v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13042v1",
      "title": "GPTZero: Robust Detection of LLM-Generated Texts",
      "abstract": "While historical considerations surrounding text authenticity revolved primarily around plagiarism, the advent of large language models (LLMs) has introduced a new challenge: distinguishing human-authored from AI-generated text. This shift raises significant concerns, including the undermining of skill evaluations, the mass-production of low-quality content, and the proliferation of misinformation. Addressing these issues, we introduce GPTZero a state-of-the-art industrial AI detection solution, offering reliable discernment between human and LLM-generated text. Our key contributions include: introducing a hierarchical, multi-task architecture enabling a flexible taxonomy of human and AI texts, demonstrating state-of-the-art accuracy on a variety of domains with granular predictions, and achieving superior robustness to adversarial attacks and paraphrasing via multi-tiered automated red teaming. GPTZero offers accurate and explainable detection, and educates users on its responsible use, ensuring fair and transparent assessment of text.",
      "authors": [
        "George Alexandru Adam",
        "Alexander Cui",
        "Edwin Thomas",
        "Emily Napier",
        "Nazar Shmatko",
        "Jacob Schnell",
        "Jacob Junqi Tian",
        "Alekhya Dronavalli",
        "Edward Tian",
        "Dongwon Lee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 15:53:45+00:00",
      "link": "https://arxiv.org/pdf/2602.13042v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13040v1",
      "title": "TCRL: Temporal-Coupled Adversarial Training for Robust Constrained Reinforcement Learning in Worst-Case Scenarios",
      "abstract": "Constrained Reinforcement Learning (CRL) aims to optimize decision-making policies under constraint conditions, making it highly applicable to safety-critical domains such as autonomous driving, robotics, and power grid management. However, existing robust CRL approaches predominantly focus on single-step perturbations and temporally independent adversarial models, lacking explicit modeling of robustness against temporally coupled perturbations. To tackle these challenges, we propose TCRL, a novel temporal-coupled adversarial training framework for robust constrained reinforcement learning (TCRL) in worst-case scenarios. First, TCRL introduces a worst-case-perceived cost constraint function that estimates safety costs under temporally coupled perturbations without the need to explicitly model adversarial attackers. Second, TCRL establishes a dual-constraint defense mechanism on the reward to counter temporally coupled adversaries while maintaining reward unpredictability. Experimental results demonstrate that TCRL consistently outperforms existing methods in terms of robustness against temporally coupled perturbation attacks across a variety of CRL tasks.",
      "authors": [
        "Wentao Xu",
        "Zhongming Yao",
        "Weihao Li",
        "Zhenghang Song",
        "Yumeng Song",
        "Tianyi Li",
        "Yushuai Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 15:48:20+00:00",
      "link": "https://arxiv.org/pdf/2602.13040v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13035v1",
      "title": "Look Inward to Explore Outward: Learning Temperature Policy from LLM Internal States via Hierarchical RL",
      "abstract": "Reinforcement Learning from Verifiable Rewards (RLVR) trains large language models (LLMs) from sampled trajectories, making decoding strategy a core component of learning rather than a purely inference-time choice. Sampling temperature directly controls the exploration--exploitation trade-off by modulating policy entropy, yet existing methods rely on static values or heuristic adaptations that are decoupled from task-level rewards. We propose Introspective LLM, a hierarchical reinforcement learning framework that learns to control sampling temperature during generation. At each decoding step, the model selects a temperature based on its hidden state and samples the next token from the resulting distribution. Temperature and token policies are jointly optimized from downstream rewards using a coordinate ascent scheme. Experiments on mathematical reasoning benchmarks show that learned temperature policies outperform fixed and heuristic baselines, while exhibiting interpretable exploration behaviors aligned with reasoning uncertainty.",
      "authors": [
        "Yixiao Zhou",
        "Yang Li",
        "Dongzhou Cheng",
        "Hehe Fan",
        "Yu Cheng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-13 15:42:59+00:00",
      "link": "https://arxiv.org/pdf/2602.13035v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13024v1",
      "title": "FedHENet: A Frugal Federated Learning Framework for Heterogeneous Environments",
      "abstract": "Federated Learning (FL) enables collaborative training without centralizing data, essential for privacy compliance in real-world scenarios involving sensitive visual information. Most FL approaches rely on expensive, iterative deep network optimization, which still risks privacy via shared gradients. In this work, we propose FedHENet, extending the FedHEONN framework to image classification. By using a fixed, pre-trained feature extractor and learning only a single output layer, we avoid costly local fine-tuning. This layer is learned by analytically aggregating client knowledge in a single round of communication using homomorphic encryption (HE). Experiments show that FedHENet achieves competitive accuracy compared to iterative FL baselines while demonstrating superior stability performance and up to 70\\% better energy efficiency. Crucially, our method is hyperparameter-free, removing the carbon footprint associated with hyperparameter tuning in standard FL. Code available in https://github.com/AlejandroDopico2/FedHENet/",
      "authors": [
        "Alejandro Dopico-Castro",
        "Oscar Fontenla-Romero",
        "Bertha Guijarro-Berdiñas",
        "Amparo Alonso-Betanzos",
        "Iván Pérez Digón"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-13 15:30:18+00:00",
      "link": "https://arxiv.org/pdf/2602.13024v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13022v1",
      "title": "Learning Image-based Tree Crown Segmentation from Enhanced Lidar-based Pseudo-labels",
      "abstract": "Mapping individual tree crowns is essential for tasks such as maintaining urban tree inventories and monitoring forest health, which help us understand and care for our environment. However, automatically separating the crowns from each other in aerial imagery is challenging due to factors such as the texture and partial tree crown overlaps. In this study, we present a method to train deep learning models that segment and separate individual trees from RGB and multispectral images, using pseudo-labels derived from aerial laser scanning (ALS) data. Our study shows that the ALS-derived pseudo-labels can be enhanced using a zero-shot instance segmentation model, Segment Anything Model 2 (SAM 2). Our method offers a way to obtain domain-specific training annotations for optical image-based models without any manual annotation cost, leading to segmentation models which outperform any available models which have been targeted for general domain deployment on the same task.",
      "authors": [
        "Julius Pesonen",
        "Stefan Rua",
        "Josef Taher",
        "Niko Koivumäki",
        "Xiaowei Yu",
        "Eija Honkavaara"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 15:26:38+00:00",
      "link": "https://arxiv.org/pdf/2602.13022v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13021v2",
      "title": "Prior-Guided Symbolic Regression: Towards Scientific Consistency in Equation Discovery",
      "abstract": "Symbolic Regression (SR) aims to discover interpretable equations from observational data, with the potential to reveal underlying principles behind natural phenomena. However, existing approaches often fall into the Pseudo-Equation Trap: producing equations that fit observations well but remain inconsistent with fundamental scientific principles. A key reason is that these approaches are dominated by empirical risk minimization, lacking explicit constraints to ensure scientific consistency. To bridge this gap, we propose PG-SR, a prior-guided SR framework built upon a three-stage pipeline consisting of warm-up, evolution, and refinement. Throughout the pipeline, PG-SR introduces a prior constraint checker that explicitly encodes domain priors as executable constraint programs, and employs a Prior Annealing Constrained Evaluation (PACE) mechanism during the evolution stage to progressively steer discovery toward scientifically consistent regions. Theoretically, we prove that PG-SR reduces the Rademacher complexity of the hypothesis space, yielding tighter generalization bounds and establishing a guarantee against pseudo-equations. Experimentally, PG-SR outperforms state-of-the-art baselines across diverse domains, maintaining robustness to varying prior quality, noisy data, and data scarcity.",
      "authors": [
        "Jing Xiao",
        "Xinhai Chen",
        "Jiaming Peng",
        "Qinglin Wang",
        "Menghan Jia",
        "Zhiquan Lai",
        "Guangping Yu",
        "Dongsheng Li",
        "Tiejun Li",
        "Jie Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-13 15:26:21+00:00",
      "link": "https://arxiv.org/pdf/2602.13021v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13017v1",
      "title": "Synaptic Activation and Dual Liquid Dynamics for Interpretable Bio-Inspired Models",
      "abstract": "In this paper, we present a unified framework for various bio-inspired models to better understand their structural and functional differences. We show that liquid-capacitance-extended models lead to interpretable behavior even in dense, all-to-all recurrent neural network (RNN) policies. We further demonstrate that incorporating chemical synapses improves interpretability and that combining chemical synapses with synaptic activation yields the most accurate and interpretable RNN models. To assess the accuracy and interpretability of these RNN policies, we consider the challenging lane-keeping control task and evaluate performance across multiple metrics, including turn-weighted validation loss, neural activity during driving, absolute correlation between neural activity and road trajectory, saliency maps of the networks' attention, and the robustness of their saliency maps measured by the structural similarity index.",
      "authors": [
        "Mónika Farsang",
        "Radu Grosu"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-13 15:23:37+00:00",
      "link": "https://arxiv.org/pdf/2602.13017v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13015v1",
      "title": "Multimodal Classification via Total Correlation Maximization",
      "abstract": "Multimodal learning integrates data from diverse sensors to effectively harness information from different modalities. However, recent studies reveal that joint learning often overfits certain modalities while neglecting others, leading to performance inferior to that of unimodal learning. Although previous efforts have sought to balance modal contributions or combine joint and unimodal learning, thereby mitigating the degradation of weaker modalities with promising outcomes, few have examined the relationship between joint and unimodal learning from an information-theoretic perspective. In this paper, we theoretically analyze modality competition and propose a method for multimodal classification by maximizing the total correlation between multimodal features and labels. By maximizing this objective, our approach alleviates modality competition while capturing inter-modal interactions via feature alignment. Building on Mutual Information Neural Estimation (MINE), we introduce Total Correlation Neural Estimation (TCNE) to derive a lower bound for total correlation. Subsequently, we present TCMax, a hyperparameter-free loss function that maximizes total correlation through variational bound optimization. Extensive experiments demonstrate that TCMax outperforms state-of-the-art joint and unimodal learning approaches. Our code is available at https://github.com/hubaak/TCMax.",
      "authors": [
        "Feng Yu",
        "Xiangyu Wu",
        "Yang Yang",
        "Jianfeng Lu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 15:21:45+00:00",
      "link": "https://arxiv.org/pdf/2602.13015v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13010v1",
      "title": "Probabilistic Wind Power Forecasting with Tree-Based Machine Learning and Weather Ensembles",
      "abstract": "Accurate production forecasts are essential to continue facilitating the integration of renewable energy sources into the power grid. This paper illustrates how to obtain probabilistic day-ahead forecasts of wind power generation via gradient boosting trees using an ensemble of weather forecasts. To this end, we perform a comparative analysis across three state-of-the-art probabilistic prediction methods-conformalised quantile regression, natural gradient boosting and conditional diffusion models-all of which can be combined with tree-based machine learning. The methods are validated using four years of data for all wind farms present within the Belgian offshore zone. Additionally, the point forecasts are benchmarked against deterministic engineering methods, using either the power curve or an advanced approach incorporating a calibrated analytical wake model. The experimental results show that the machine learning methods improve the mean absolute error by up to 53% and 33% compared to the power curve and the calibrated wake model. Considering the three probabilistic prediction methods, the conditional diffusion model is found to yield the best overall probabilistic and point estimate of wind power generation. Moreover, the findings suggest that the use of an ensemble of weather forecasts can improve point forecast accuracy by up to 23%.",
      "authors": [
        "Max Bruninx",
        "Diederik van Binsbergen",
        "Timothy Verstraeten",
        "Ann Nowé",
        "Jan Helsen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 15:17:04+00:00",
      "link": "https://arxiv.org/pdf/2602.13010v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12989v1",
      "title": "Evaluating the Homogeneity of Keyphrase Prediction Models",
      "abstract": "Keyphrases which are useful in several NLP and IR applications are either extracted from text or predicted by generative models. Contrarily to keyphrase extraction approaches, keyphrase generation models can predict keyphrases that do not appear in a document's text called `absent keyphrases`. This ability means that keyphrase generation models can associate a document to a notion that is not explicitly mentioned in its text. Intuitively, this suggests that for two documents treating the same subjects, a keyphrase generation model is more likely to be homogeneous in their indexing i.e. predict the same keyphrase for both documents, regardless of those keyphrases appearing in their respective text or not; something a keyphrase extraction model would fail to do. Yet, homogeneity of keyphrase prediction models is not covered by current benchmarks. In this work, we introduce a method to evaluate the homogeneity of keyphrase prediction models and study if absent keyphrase generation capabilities actually help the model to be more homogeneous. To our surprise, we show that keyphrase extraction methods are competitive with generative models, and that the ability to generate absent keyphrases can actually have a negative impact on homogeneity. Our data, code and prompts are available on huggingface and github.",
      "authors": [
        "Maël Houbre",
        "Florian Boudin",
        "Beatrice Daille"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-13 15:00:35+00:00",
      "link": "https://arxiv.org/pdf/2602.12989v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12984v1",
      "title": "SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents",
      "abstract": "Scientific reasoning inherently demands integrating sophisticated toolkits to navigate domain-specific knowledge. Yet, current benchmarks largely overlook agents' ability to orchestrate tools for such rigorous workflows. To bridge this gap, we introduce SciAgentGym, a scalable interactive environment featuring 1,780 domain-specific tools across four natural science disciplines, supported by a robust execution infrastructure. Complementing this, we present SciAgentBench, a tiered evaluation suite designed to stress-test agentic capabilities from elementary actions to long-horizon workflows. Our evaluation identifies a critical bottleneck: state-of-the-art models struggle with complex scientific tool-use. Even for a leading model like GPT-5, success rates drop sharply from 60.6% to 30.9% as interaction horizons extend, primarily due to failures in multi-step workflow execution. To address this, we propose SciForge, a data synthesis method that models the tool action space as a dependency graph to generate logic-aware training trajectories. By fine-tuning on these trajectories, our SciAgent-8B outperforms the significantly larger Qwen3-VL-235B-Instruct while exhibiting positive cross-domain transfer of scientific tool-use capabilities. These results underscore the promising potential of next-generation autonomous scientific agents.",
      "authors": [
        "Yujiong Shen",
        "Yajie Yang",
        "Zhiheng Xi",
        "Binze Hu",
        "Huayu Sha",
        "Jiazheng Zhang",
        "Qiyuan Peng",
        "Junlin Shang",
        "Jixuan Huang",
        "Yutao Fan",
        "Jingqi Tong",
        "Shihan Dou",
        "Ming Zhang",
        "Lei Bai",
        "Zhenfei Yin",
        "Tao Gui",
        "Xingjun Ma",
        "Qi Zhang",
        "Xuanjing Huang",
        "Yu-Gang Jiang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-13 14:58:18+00:00",
      "link": "https://arxiv.org/pdf/2602.12984v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12982v1",
      "title": "Multi-Dimensional Visual Data Recovery: Scale-Aware Tensor Modeling and Accelerated Randomized Computation",
      "abstract": "The recently proposed fully-connected tensor network (FCTN) decomposition has demonstrated significant advantages in correlation characterization and transpositional invariance, and has achieved notable achievements in multi-dimensional data processing and analysis. However, existing multi-dimensional data recovery methods leveraging FCTN decomposition still have room for further enhancement, particularly in computational efficiency and modeling capability. To address these issues, we first propose a FCTN-based generalized nonconvex regularization paradigm from the perspective of gradient mapping. Then, reliable and scalable multi-dimensional data recovery models are investigated, where the model formulation is shifted from unquantized observations to coarse-grained quantized observations. Based on the alternating direction method of multipliers (ADMM) framework, we derive efficient optimization algorithms with convergence guarantees to solve the formulated models. To alleviate the computational bottleneck encountered when processing large-scale multi-dimensional data, fast and efficient randomized compression algorithms are devised in virtue of sketching techniques in numerical linear algebra. These dimensionality-reduction techniques serve as the computational acceleration core of our proposed algorithm framework. Theoretical results on approximation error upper bounds and convergence analysis for the proposed method are derived. Extensive numerical experiments illustrate the effectiveness and superiority of the proposed algorithm over other state-of-the-art methods in terms of quantitative metrics, visual quality, and running time.",
      "authors": [
        "Wenjin Qin",
        "Hailin Wang",
        "Jiangjun Peng",
        "Jianjun Wang",
        "Tingwen Huang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 14:56:37+00:00",
      "link": "https://arxiv.org/pdf/2602.12982v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12980v1",
      "title": "MAUNet-Light: A Concise MAUNet Architecture for Bias Correction and Downscaling of Precipitation Estimates",
      "abstract": "Satellite-derived data products and climate model simulations of geophysical variables like precipitation, often exhibit systematic biases compared to in-situ measurements. Bias correction and spatial downscaling are fundamental components to develop operational weather forecast systems, as they seek to improve the consistency between coarse-resolution climate model simulations or satellite-based estimates and ground-based observations. In recent years, deep learning-based models have been increasingly replaced traditional statistical methods to generate high-resolution, bias free projections of climate variables. For example, Max-Average U-Net (MAUNet) architecture has been demonstrated for its ability to downscale precipitation estimates. The versatility and adaptability of these neural models make them highly effective across a range of applications, though this often come at the cost of high computational and memory requirements. The aim of this research is to develop light-weight neural network architectures for both bias correction and downscaling of precipitation, for which the teacher-student based learning paradigm is explored. This research demonstrates the adaptability of MAUNet to the task of bias correction, and further introduces a compact, lightweight neural network architecture termed MAUNet-Light.The proposed MAUNet-Light model is developed by transferring knowledge from the trained MAUNet, and it is designed to perform both downscaling and bias correction with reduced computational requirements without any significant loss in accuracy compared to state-of-the-art.",
      "authors": [
        "Sumanta Chandra Mishra Sharma",
        "Adway Mitra",
        "Auroop Ratan Ganguly"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 14:56:19+00:00",
      "link": "https://arxiv.org/pdf/2602.12980v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12976v1",
      "title": "Drift-Aware Variational Autoencoder-based Anomaly Detection with Two-level Ensembling",
      "abstract": "In today's digital world, the generation of vast amounts of streaming data in various domains has become ubiquitous. However, many of these data are unlabeled, making it challenging to identify events, particularly anomalies. This task becomes even more formidable in nonstationary environments where model performance can deteriorate over time due to concept drift. To address these challenges, this paper presents a novel method, VAE++ESDD, which employs incremental learning and two-level ensembling: an ensemble of Variational AutoEncoder(VAEs) for anomaly prediction, along with an ensemble of concept drift detectors. Each drift detector utilizes a statistical-based concept drift mechanism. To evaluate the effectiveness of VAE++ESDD, we conduct a comprehensive experimental study using real-world and synthetic datasets characterized by severely or extremely low anomalous rates and various drift characteristics. Our study reveals that the proposed method significantly outperforms both strong baselines and state-of-the-art methods.",
      "authors": [
        "Jin Li",
        "Kleanthis Malialis",
        "Christos G. Panayiotou",
        "Marios M. Polycarpou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-13 14:53:56+00:00",
      "link": "https://arxiv.org/pdf/2602.12976v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12973v1",
      "title": "Meta-Monomorphizing Specializations",
      "abstract": "Achieving zero-cost specialization remains a fundamental challenge in programming language and compiler design. It often necessitates trade-offs between expressive power and type system soundness, as the interaction between conditional compilation and static dispatch can easily lead to unforeseen coherence violations and increased complexity in the formal model. This paper introduces meta-monomorphizing specializations, a novel framework that achieves specialization by repurposing monomorphization through compile-time metaprogramming. Instead of modifying the host compiler, our approach generates meta-monomorphized traits and implementations that encode specialization constraints directly into the type structure, enabling deterministic, coherent dispatch without overlapping instances. We formalize this method for first-order, predicate-based, and higher-ranked polymorphic specialization, also in presence of lifetime parameters. Our evaluation, based on a Rust implementation using only existing macro facilities, demonstrates that meta-monomorphization enables expressive specialization patterns -- previously rejected by the compiler -- while maintaining full compatibility with standard optimization pipelines. We show that specialization can be realized as a disciplined metaprogramming layer, offering a practical, language-agnostic path to high-performance abstraction. A comprehensive study of public Rust codebases further validates our approach, revealing numerous workarounds that meta-monomorphization can eliminate, leading to more idiomatic and efficient code.",
      "authors": [
        "Federico Bruzzone",
        "Walter Cazzola"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL"
      ],
      "published": "2026-02-13 14:47:44+00:00",
      "link": "https://arxiv.org/pdf/2602.12973v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12966v1",
      "title": "ProbeLLM: Automating Principled Diagnosis of LLM Failures",
      "abstract": "Understanding how and why large language models (LLMs) fail is becoming a central challenge as models rapidly evolve and static evaluations fall behind. While automated probing has been enabled by dynamic test generation, existing approaches often discover isolated failure cases, lack principled control over exploration, and provide limited insight into the underlying structure of model weaknesses. We propose ProbeLLM, a benchmark-agnostic automated probing framework that elevates weakness discovery from individual failures to structured failure modes. ProbeLLM formulates probing as a hierarchical Monte Carlo Tree Search, explicitly allocating limited probing budgets between global exploration of new failure regions and local refinement of recurring error patterns. By restricting probing to verifiable test cases and leveraging tool-augmented generation and verification, ProbeLLM grounds failure discovery in reliable evidence. Discovered failures are further consolidated into interpretable failure modes via failure-aware embeddings and boundary-aware induction. Across diverse benchmarks and LLMs, ProbeLLM reveals substantially broader, cleaner, and more fine-grained failure landscapes than static benchmarks and prior automated methods, supporting a shift from case-centric evaluation toward principled weakness discovery.",
      "authors": [
        "Yue Huang",
        "Zhengzhe Jiang",
        "Yuchen Ma",
        "Yu Jiang",
        "Xiangqi Wang",
        "Yujun Zhou",
        "Yuexing Hao",
        "Kehan Guo",
        "Pin-Yu Chen",
        "Stefan Feuerriegel",
        "Xiangliang Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.SE"
      ],
      "published": "2026-02-13 14:33:13+00:00",
      "link": "https://arxiv.org/pdf/2602.12966v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12961v1",
      "title": "Ca-MCF: Category-level Multi-label Causal Feature selection",
      "abstract": "Multi-label causal feature selection has attracted extensive attention in recent years. However, current methods primarily operate at the label level, treating each label variable as a monolithic entity and overlooking the fine-grained causal mechanisms unique to individual categories. To address this, we propose a Category-level Multi-label Causal Feature selection method named Ca-MCF. Ca-MCF utilizes label category flattening to decompose label variables into specific category nodes, enabling precise modeling of causal structures within the label space. Furthermore, we introduce an explanatory competition-based category-aware recovery mechanism that leverages the proposed Specific Category-Specific Mutual Information (SCSMI) and Distinct Category-Specific Mutual Information (DCSMI) to salvage causal features obscured by label correlations. The method also incorporates structural symmetry checks and cross-dimensional redundancy removal to ensure the robustness and compactness of the identified Markov Blankets. Extensive experiments across seven real-world datasets demonstrate that Ca-MCF significantly outperforms state-of-the-art benchmarks, achieving superior predictive accuracy with reduced feature dimensionality.",
      "authors": [
        "Wanfu Gao",
        "Yanan Wang",
        "Yonghao Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 14:26:47+00:00",
      "link": "https://arxiv.org/pdf/2602.12961v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12959v1",
      "title": "Limits of Kernelization and Parametrization for Phylogenetic Diversity with Dependencies",
      "abstract": "In the Maximize Phylogenetic Diversity problem, we are given a phylogenetic tree that represents the genetic proximity of species, and we are asked to select a subset of species of maximum phylogenetic diversity to be preserved through conservation efforts, subject to budgetary constraints that allow only k species to be saved. This neglects that it is futile to preserve a predatory species if we do not also preserve at least a subset of the prey it feeds on. Thus, in the Optimizing PD with Dependencies ($ε$-PDD) problem, we are additionally given a food web that represents the predator-prey relationships between species. The goal is to save a set of k species of maximum phylogenetic diversity such that for every saved species, at least one of its prey is also saved. This problem is NP-hard even when the phylogenetic tree is a star. The $α$-PDD problem alters PDD by requiring that at least some fraction $α$ of the prey of every saved species are also saved. In this paper, we study the parameterized complexity of $α$-PDD. We prove that the problem is W[1]-hard and in XP when parameterized by the solution size k, the diversity threshold D, or their complements. When parameterized by the vertex cover number of the food web, $α$-PDD is fixed-parameter tractable (FPT). A key measure of the computational difficulty of a problem that is FPT is the size of the smallest kernel that can be obtained. We prove that, when parameterized by the distance to clique, 1-PDD admits a linear kernel. Our main contribution is to prove that $α$-PDD does not admit a polynomial kernel when parameterized by the vertex cover number plus the diversity threshold D, even if the phylogenetic tree is a star. This implies the non-existence of a polynomial kernel for $α$-PDD also when parameterized by a range of structural parameters of the food web, such as its dist[...]",
      "authors": [
        "Niels Holtgrefe",
        "Jannik Schestag",
        "Norbert Zeh"
      ],
      "primary_category": "cs.CC",
      "categories": [
        "cs.CC",
        "cs.DS"
      ],
      "published": "2026-02-13 14:24:07+00:00",
      "link": "https://arxiv.org/pdf/2602.12959v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12949v1",
      "title": "Real-time Rendering with a Neural Irradiance Volume",
      "abstract": "Rendering diffuse global illumination in real-time is often approximated by pre-computing and storing irradiance in a 3D grid of probes. As long as most of the scene remains static, probes approximate irradiance for all surfaces immersed in the irradiance volume, including novel dynamic objects. This approach, however, suffers from aliasing artifacts and high memory consumption. We propose Neural Irradiance Volume (NIV), a neural-based technique that allows accurate real-time rendering of diffuse global illumination via a compact pre-computed model, overcoming the limitations of traditional probe-based methods, such as the expensive memory footprint, aliasing artifacts, and scene-specific heuristics. The key insight is that neural compression creates an adaptive and amortized representation of irradiance, circumventing the cubic scaling of grid-based methods. Our superior memory-scaling improves quality by at least 10x at the same memory budget, and enables a straightforward representation of higher-dimensional irradiance fields, allowing rendering of time-varying or dynamic effects without requiring additional computation at runtime. Unlike other neural rendering techniques, our method works within strict real-time constraints, providing fast inference (around 1 ms per frame on consumer GPUs at full HD resolution), reduced memory usage (1-5 MB for medium-sized scenes), and only requires a G-buffer as input, without expensive ray tracing or denoising.",
      "authors": [
        "Arno Coomans",
        "Giacomo Nazzaro",
        "Edoardo A. Dominici",
        "Christian Döring",
        "Floor Verhoeven",
        "Konstantinos Vardis",
        "Markus Steinberger"
      ],
      "primary_category": "cs.GR",
      "categories": [
        "cs.GR"
      ],
      "published": "2026-02-13 14:15:46+00:00",
      "link": "https://arxiv.org/pdf/2602.12949v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12933v1",
      "title": "Deep-Learning Atlas Registration for Melanoma Brain Metastases: Preserving Pathology While Enabling Cohort-Level Analyses",
      "abstract": "Melanoma brain metastases (MBM) are common and spatially heterogeneous lesions, complicating cohort-level analyses due to anatomical variability and differing MRI protocols. We propose a fully differentiable, deep-learning-based deformable registration framework that aligns individual pathological brains to a common atlas while preserving metastatic tissue without requiring lesion masks or preprocessing.   Missing anatomical correspondences caused by metastases are handled through a forward-model similarity metric based on distance-transformed anatomical labels, combined with a volume-preserving regularization term to ensure deformation plausibility. Registration performance was evaluated using Dice coefficient (DSC), Hausdorff distance (HD), average symmetric surface distance (ASSD), and Jacobian-based measures. The method was applied to 209 MBM patients from three centres, enabling standardized mapping of metastases to anatomical, arterial, and perfusion atlases.   The framework achieved high registration accuracy across datasets (DSC 0.89-0.92, HD 6.79-7.60 mm, ASSD 0.63-0.77 mm) while preserving metastatic volumes. Spatial analysis demonstrated significant over-representation of MBM in the cerebral cortex and putamen, under-representation in white matter, and consistent localization near the gray-white matter junction. No arterial territory showed increased metastasis frequency after volume correction.   This approach enables robust atlas registration of pathological brain MRI without lesion masks and supports reproducible multi-centre analyses. Applied to MBM, it confirms and refines known spatial predilections, particularly preferential seeding near the gray-white matter junction and cortical regions. The publicly available implementation facilitates reproducible research and extension to other brain tumours and neurological pathologies.",
      "authors": [
        "Nanna E. Wielenberg",
        "Ilinca Popp",
        "Oliver Blanck",
        "Lucas Zander",
        "Jan C. Peeken",
        "Stephanie E. Combs",
        "Anca-Ligia Grosu",
        "Dimos Baltas",
        "Tobias Fechter"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "physics.med-ph"
      ],
      "published": "2026-02-13 13:43:57+00:00",
      "link": "https://arxiv.org/pdf/2602.12933v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12913v1",
      "title": "Hierarchical Reinforcement Learning for Cooperative Air-Ground Delivery in Urban System",
      "abstract": "Cooperative air-ground delivery has emerged as a promising logistics paradigm by leveraging the complementary strengths of UAVs and ground carriers. However, effective dispatching in such heterogeneous systems faces two critical challenges: i) the heterogeneity between flight and road dynamics, ii) the scalability bottleneck raised by the exponential decision variables in large-scale fleets. To address these challenges, we propose HRL4AG, a Hierarchical Reinforcement Learning framework for cooperative Air-Ground delivery. Specifically, HRL4AG employs a high-level manager to tackle the scalability bottleneck by decomposing the joint action space, and mode-specific workers that encode distinct flight and road dynamics to address the heterogeneity. Furthermore, a novel internal reward mechanism is designed to guide the hierarchical policy learning, addressing the credit assignment problem in sparse-reward settings. Extensive experiments on two real-world datasets and an evaluation platform demonstrate that HRL4AG significantly outperforms state-of-the-art baselines, improving the delivery success rate by up to 26% while achieving an 80-fold increase in computational efficiency.",
      "authors": [
        "Songxin Lei",
        "Chunming Ma",
        "Haomin Wen",
        "Yexin Li",
        "Lizhenghe Chen",
        "Qianyu Yang",
        "Fugee Tsung",
        "Lei Chen",
        "Sijie Ruan",
        "Yuxuan Liang"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "published": "2026-02-13 13:19:59+00:00",
      "link": "https://arxiv.org/pdf/2602.12913v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13367v1",
      "title": "Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts",
      "abstract": "We present Nanbeige4.1-3B, a unified generalist language model that simultaneously achieves strong agentic behavior, code generation, and general reasoning with only 3B parameters. To the best of our knowledge, it is the first open-source small language model (SLM) to achieve such versatility in a single model. To improve reasoning and preference alignment, we combine point-wise and pair-wise reward modeling, ensuring high-quality, human-aligned responses. For code generation, we design complexity-aware rewards in Reinforcement Learning, optimizing both correctness and efficiency. In deep search, we perform complex data synthesis and incorporate turn-level supervision during training. This enables stable long-horizon tool interactions, allowing Nanbeige4.1-3B to reliably execute up to 600 tool-call turns for complex problem-solving. Extensive experimental results show that Nanbeige4.1-3B significantly outperforms prior models of similar scale, such as Nanbeige4-3B-2511 and Qwen3-4B, even achieving superior performance compared to much larger models, such as Qwen3-30B-A3B. Our results demonstrate that small models can achieve both broad competence and strong specialization simultaneously, redefining the potential of 3B parameter models.",
      "authors": [
        "Chen Yang",
        "Guangyue Peng",
        "Jiaying Zhu",
        "Ran Le",
        "Ruixiang Feng",
        "Tao Zhang",
        "Xiyun Xu",
        "Yang Song",
        "Yiming Jia",
        "Yuntao Wen",
        "Yunzhi Xu",
        "Zekai Wang",
        "Zhenwei An",
        "Zhicong Sun",
        "Zongchao Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-13 13:10:46+00:00",
      "link": "https://arxiv.org/pdf/2602.13367v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12889v1",
      "title": "BaziQA-Benchmark: Evaluating Symbolic and Temporally Compositional Reasoning in Large Language Models",
      "abstract": "We present BaziQA-Benchmark, a standardized benchmark for evaluating symbolic and temporally compositional reasoning in large language models. The benchmark is derived from 200 professionally curated, multiple-choice problems from the Global Fortune-teller Competition (2021--2025), where each instance requires structured inference over a fixed symbolic chart and interacting temporal conditions. Unlike anecdotal or prompt-driven evaluations, BaziQA-Benchmark enables objective scoring and controlled comparison across years, domains, and model families. We evaluate contemporary language models under a multi-turn setting and analyze performance variation across temporal difficulty, reasoning domains, and inference protocols.To further probe reasoning behavior, we introduce a lightweight Structured Reasoning Protocol that constrains inference order without adding domain knowledge. Results show that models consistently outperform chance but remain far from saturation, exhibiting pronounced sensitivity to temporal composition and reasoning order, as well as systematic failures on precise temporal localization and multi-condition symbolic judgments.",
      "authors": [
        "Jiangxi Chen",
        "Qian Liu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-13 12:45:42+00:00",
      "link": "https://arxiv.org/pdf/2602.12889v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15061v1",
      "title": "Safe-SDL:Establishing Safety Boundaries and Control Mechanisms for AI-Driven Self-Driving Laboratories",
      "abstract": "The emergence of Self-Driving Laboratories (SDLs) transforms scientific discovery methodology by integrating AI with robotic automation to create closed-loop experimental systems capable of autonomous hypothesis generation, experimentation, and analysis. While promising to compress research timelines from years to weeks, their deployment introduces unprecedented safety challenges differing from traditional laboratories or purely digital AI. This paper presents Safe-SDL, a comprehensive framework for establishing robust safety boundaries and control mechanisms in AI-driven autonomous laboratories. We identify and analyze the critical ``Syntax-to-Safety Gap'' -- the disconnect between AI-generated syntactically correct commands and their physical safety implications -- as the central challenge in SDL deployment. Our framework addresses this gap through three synergistic components: (1) formally defined Operational Design Domains (ODDs) that constrain system behavior within mathematically verified boundaries, (2) Control Barrier Functions (CBFs) that provide real-time safety guarantees through continuous state-space monitoring, and (3) a novel Transactional Safety Protocol (CRUTD) that ensures atomic consistency between digital planning and physical execution. We ground our theoretical contributions through analysis of existing implementations including UniLabOS and the Osprey architecture, demonstrating how these systems instantiate key safety principles. Evaluation against the LabSafety Bench reveals that current foundation models exhibit significant safety failures, demonstrating that architectural safety mechanisms are essential rather than optional. Our framework provides both theoretical foundations and practical implementation guidance for safe deployment of autonomous scientific systems, establishing the groundwork for responsible acceleration of AI-driven discovery.",
      "authors": [
        "Zihan Zhang",
        "Haohui Que",
        "Junhan Chang",
        "Xin Zhang",
        "Hao Wei",
        "Tong Zhu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-13 12:42:48+00:00",
      "link": "https://arxiv.org/pdf/2602.15061v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12883v1",
      "title": "Dual-Phase Cross-Modal Contrastive Learning for CMR-Guided ECG Representations for Cardiovascular Disease Assessment",
      "abstract": "Cardiac magnetic resonance imaging (CMR) offers detailed evaluation of cardiac structure and function, but its limited accessibility restricts use to selected patient populations. In contrast, the electrocardiogram (ECG) is ubiquitous and inexpensive, and provides rich information on cardiac electrical activity and rhythm, yet offers limited insight into underlying cardiac structure and mechanical function. To address this, we introduce a contrastive learning framework that improves the extraction of clinically relevant cardiac phenotypes from ECG by learning from paired ECG-CMR data. Our approach aligns ECG representations with 3D CMR volumes at end-diastole (ED) and end-systole (ES), with a dual-phase contrastive loss to anchor each ECG jointly with both cardiac phases in a shared latent space. Unlike prior methods limited to 2D CMR representations with or without a temporal component, our framework models 3D anatomy at both ED and ES phases as distinct latent representations, enabling flexible disentanglement of structural and functional cardiac properties. Using over 34,000 ECG-CMR pairs from the UK Biobank, we demonstrate improved extraction of image-derived phenotypes from ECG, particularly for functional parameters ($\\uparrow$ 9.2\\%), while improvements in clinical outcome prediction remained modest ($\\uparrow$ 0.7\\%). This strategy could enable scalable and cost-effective extraction of image-derived traits from ECG. The code for this research is publicly available.",
      "authors": [
        "Laura Alvarez-Florez",
        "Angel Bujalance-Gomez",
        "Femke Raijmakers",
        "Samuel Ruiperez-Campillo",
        "Maarten Z. H. Kolk",
        "Jesse Wiers",
        "Julia Vogt",
        "Erik J. Bekkers",
        "Ivana Išgum",
        "Fleur V. Y. Tjong"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "published": "2026-02-13 12:34:28+00:00",
      "link": "https://arxiv.org/pdf/2602.12883v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12881v1",
      "title": "Semantic Communities and Boundary-Spanning Lyrics in K-pop: A Graph-Based Unsupervised Analysis",
      "abstract": "Large-scale lyric corpora present unique challenges for data-driven analysis, including the absence of reliable annotations, multilingual content, and high levels of stylistic repetition. Most existing approaches rely on supervised classification, genre labels, or coarse document-level representations, limiting their ability to uncover latent semantic structure. We present a graph-based framework for unsupervised discovery and evaluation of semantic communities in K-pop lyrics using line-level semantic representations. By constructing a similarity graph over lyric texts and applying community detection, we uncover stable micro-theme communities without genre, artist, or language supervision. We further identify boundary-spanning songs via graph-theoretic bridge metrics and analyse their structural properties. Across multiple robustness settings, boundary-spanning lyrics exhibit higher lexical diversity and lower repetition compared to core community members, challenging the assumption that hook intensity or repetition drives cross-theme connectivity. Our framework is language-agnostic and applicable to unlabeled cultural text corpora.",
      "authors": [
        "Oktay Karakuş"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI",
        "cs.CL"
      ],
      "published": "2026-02-13 12:31:30+00:00",
      "link": "https://arxiv.org/pdf/2602.12881v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13363v1",
      "title": "Assessing Spear-Phishing Website Generation in Large Language Model Coding Agents",
      "abstract": "Large Language Models are expanding beyond being a tool humans use and into independent agents that can observe an environment, reason about solutions to problems, make changes that impact those environments, and understand how their actions impacted their environment. One of the most common applications of these LLM Agents is in computer programming, where agents can successfully work alongside humans to generate code while controlling programming environments or networking systems. However, with the increasing ability and complexity of these agents comes dangers about the potential for their misuse. A concerning application of LLM agents is in the domain cybersecurity, where they have the potential to greatly expand the threat imposed by attacks such as social engineering. This is due to the fact that LLM Agents can work autonomously and perform many tasks that would normally require time and effort from skilled human programmers. While this threat is concerning, little attention has been given to assessments of the capabilities of LLM coding agents in generating code for social engineering attacks. In this work we compare different LLMs in their ability and willingness to produce potentially dangerous code bases that could be misused by cyberattackers. The result is a dataset of 200 website code bases and logs from 40 different LLM coding agents. Analysis of models shows which metrics of LLMs are more and less correlated with performance in generating spear-phishing sites. Our analysis and the dataset we present will be of interest to researchers and practitioners concerned in defending against the potential misuse of LLMs in spear-phishing.",
      "authors": [
        "Tailia Malloy",
        "Tegawende F. Bissyande"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "published": "2026-02-13 12:12:53+00:00",
      "link": "https://arxiv.org/pdf/2602.13363v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15060v1",
      "title": "CLOT: Closed-Loop Global Motion Tracking for Whole-Body Humanoid Teleoperation",
      "abstract": "Long-horizon whole-body humanoid teleoperation remains challenging due to accumulated global pose drift, particularly on full-sized humanoids. Although recent learning-based tracking methods enable agile and coordinated motions, they typically operate in the robot's local frame and neglect global pose feedback, leading to drift and instability during extended execution. In this work, we present CLOT, a real-time whole-body humanoid teleoperation system that achieves closed-loop global motion tracking via high-frequency localization feedback. CLOT synchronizes operator and robot poses in a closed loop, enabling drift-free human-to-humanoid mimicry over long timehorizons. However, directly imposing global tracking rewards in reinforcement learning, often results in aggressive and brittle corrections. To address this, we propose a data-driven randomization strategy that decouples observation trajectories from reward evaluation, enabling smooth and stable global corrections. We further regularize the policy with an adversarial motion prior to suppress unnatural behaviors. To support CLOT, we collect 20 hours of carefully curated human motion data for training the humanoid teleoperation policy. We design a transformer-based policy and train it for over 1300 GPU hours. The policy is deployed on a full-sized humanoid with 31 DoF (excluding hands). Both simulation and real-world experiments verify high-dynamic motion, high-precision tracking, and strong robustness in sim-to-real humanoid teleoperation. Motion data, demos and code can be found in our website.",
      "authors": [
        "Tengjie Zhu",
        "Guanyu Cai",
        "Yang Zhaohui",
        "Guanzhu Ren",
        "Haohui Xie",
        "ZiRui Wang",
        "Junsong Wu",
        "Jingbo Wang",
        "Xiaokang Yang",
        "Yao Mu",
        "Yichao Yan",
        "Yichao Yan"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-13 12:03:13+00:00",
      "link": "https://arxiv.org/pdf/2602.15060v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12851v1",
      "title": "Chimera: Neuro-Symbolic Attention Primitives for Trustworthy Dataplane Intelligence",
      "abstract": "Deploying expressive learning models directly on programmable dataplanes promises line-rate, low-latency traffic analysis but remains hindered by strict hardware constraints and the need for predictable, auditable behavior. Chimera introduces a principled framework that maps attention-oriented neural computations and symbolic constraints onto dataplane primitives, enabling trustworthy inference within the match-action pipeline. Chimera combines a kernelized, linearized attention approximation with a two-layer key-selection hierarchy and a cascade fusion mechanism that enforces hard symbolic guarantees while preserving neural expressivity. The design includes a hardware-aware mapping protocol and a two-timescale update scheme that together permit stable, line-rate operation under realistic dataplane budgets. The paper presents the Chimera architecture, a hardware mapping strategy, and empirical evidence showing that neuro-symbolic attention primitives can achieve high-fidelity inference within the resource envelope of commodity programmable switches.",
      "authors": [
        "Rong Fu",
        "Wenxin Zhang",
        "Xiaowen Ma",
        "Kun Liu",
        "Wangyu Wu",
        "Ziyu Kong",
        "Jia Yee Tan",
        "Tailong Luo",
        "Xianda Li",
        "Zeli Su",
        "Youjin Wang",
        "Yongtai Liu",
        "Simon Fong"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-02-13 11:55:06+00:00",
      "link": "https://arxiv.org/pdf/2602.12851v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12847v1",
      "title": "DPUConfig: Optimizing ML Inference in FPGAs Using Reinforcement Learning",
      "abstract": "Heterogeneous embedded systems, with diverse computing elements and accelerators such as FPGAs, offer a promising platform for fast and flexible ML inference, which is crucial for services such as autonomous driving and augmented reality, where delays can be costly. However, efficiently allocating computational resources for deep learning applications in FPGA-based systems is a challenging task. A Deep Learning Processor Unit (DPU) is a parameterizable FPGA-based accelerator module optimized for ML inference. It supports a wide range of ML models and can be instantiated multiple times within a single FPGA to enable concurrent execution. This paper introduces DPUConfig, a novel runtime management framework, based on a custom Reinforcement Learning (RL) agent, that dynamically selects optimal DPU configurations by leveraging real-time telemetry data monitoring, system utilization, power consumption, and application performance to inform its configuration selection decisions. The experimental evaluation demonstrates that the RL agent achieves energy efficiency 95% (on average) of the optimal attainable energy efficiency for several CNN models on the Xilinx Zynq UltraScale+ MPSoC ZCU102.",
      "authors": [
        "Alexandros Patras",
        "Spyros Lalis",
        "Christos D. Antonopoulos",
        "Nikolaos Bellas"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR"
      ],
      "published": "2026-02-13 11:54:00+00:00",
      "link": "https://arxiv.org/pdf/2602.12847v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12843v1",
      "title": "Thinking Like a Radiologist: A Dataset for Anatomy-Guided Interleaved Vision Language Reasoning in Chest X-ray Interpretation",
      "abstract": "Radiological diagnosis is a perceptual process in which careful visual inspection and language reasoning are repeatedly interleaved. Most medical large vision language models (LVLMs) perform visual inspection only once and then rely on text-only chain-of-thought (CoT) reasoning, which operates purely in the linguistic space and is prone to hallucination. Recent methods attempt to mitigate this issue by introducing visually related coordinates, such as bounding boxes. However, these remain a pseudo-visual solution: coordinates are still text and fail to preserve rich visual details like texture and density. Motivated by the interleaved nature of radiological diagnosis, we introduce MMRad-IVL-22K, the first large-scale dataset designed for natively interleaved visual language reasoning in chest X-ray interpretation. MMRad-IVL-22K reflects a repeated cycle of reasoning and visual inspection workflow of radiologists, in which visual rationales complement textual descriptions and ground each step of the reasoning process. MMRad-IVL-22K comprises 21,994 diagnostic traces, enabling systematic scanning across 35 anatomical regions. Experimental results on advanced closed-source LVLMs demonstrate that report generation guided by multimodal CoT significantly outperforms that guided by text-only CoT in clinical accuracy and report quality (e.g., 6\\% increase in the RadGraph metric), confirming that high-fidelity interleaved vision language evidence is a non-substitutable component of reliable medical AI. Furthermore, benchmarking across seven state-of-the-art open-source LVLMs demonstrates that models fine-tuned on MMRad-IVL-22K achieve superior reasoning consistency and report quality compared with both general-purpose and medical-specific LVLMs. The project page is available at https://github.com/qiuzyc/thinking_like_a_radiologist.",
      "authors": [
        "Yichen Zhao",
        "Zelin Peng",
        "Piao Yang",
        "Xiaokang Yang",
        "Wei Shen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 11:49:32+00:00",
      "link": "https://arxiv.org/pdf/2602.12843v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13362v1",
      "title": "Nonparametric Distribution Regression Re-calibration",
      "abstract": "A key challenge in probabilistic regression is ensuring that predictive distributions accurately reflect true empirical uncertainty. Minimizing overall prediction error often encourages models to prioritize informativeness over calibration, producing narrow but overconfident predictions. However, in safety-critical settings, trustworthy uncertainty estimates are often more valuable than narrow intervals. Realizing the problem, several recent works have focused on post-hoc corrections; however, existing methods either rely on weak notions of calibration (such as PIT uniformity) or impose restrictive parametric assumptions on the nature of the error. To address these limitations, we propose a novel nonparametric re-calibration algorithm based on conditional kernel mean embeddings, capable of correcting calibration error without restrictive modeling assumptions. For efficient inference with real-valued targets, we introduce a novel characteristic kernel over distributions that can be evaluated in $\\mathcal{O}(n \\log n)$ time for empirical distributions of size $n$. We demonstrate that our method consistently outperforms prior re-calibration approaches across a diverse set of regression benchmarks and model classes.",
      "authors": [
        "Ádám Jung",
        "Domokos M. Kelen",
        "András A. Benczúr"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-13 11:48:43+00:00",
      "link": "https://arxiv.org/pdf/2602.13362v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12841v1",
      "title": "EARL: Energy-Aware Adaptive Antenna Control with Reinforcement Learning in O-RAN Cell-Free Massive MIMO Networks",
      "abstract": "Cell-free massive multi-input multi-output (MIMO) promises uniform high performance across the network, but also brings a high energy cost due to joint transmission from distributed radio units (RUs) and centralized processing in the cloud. Leveraging the resource-sharing capabilities of Open Radio Access Network (O-RAN), we propose EARL, an energy-aware adaptive antenna control framework based on reinforcement learning. EARL dynamically configures antenna elements in RUs to minimize radio, optical fronthaul, and cloud processing power consumption while meeting user spectral efficiency demands. Numerical results show power savings of up to 81% and 50% over full-on and heuristic baselines, respectively. The RL-based approach operates within 220 ms, satisfying O-RAN's near-real-time limit, and a greedy refinement further halves power consumption at a 2 s runtime.",
      "authors": [
        "Zilin Ge",
        "Ozan Alp Topal",
        "Irshad Ahmad Meer",
        "Pei Xiao",
        "Cicek Cavdar"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "eess.SP",
        "eess.SY"
      ],
      "published": "2026-02-13 11:47:11+00:00",
      "link": "https://arxiv.org/pdf/2602.12841v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13359v1",
      "title": "The Speed-up Factor: A Quantitative Multi-Iteration Active Learning Performance Metric",
      "abstract": "Machine learning models excel with abundant annotated data, but annotation is often costly and time-intensive. Active learning (AL) aims to improve the performance-to-annotation ratio by using query methods (QMs) to iteratively select the most informative samples. While AL research focuses mainly on QM development, the evaluation of this iterative process lacks appropriate performance metrics. This work reviews eight years of AL evaluation literature and formally introduces the speed-up factor, a quantitative multi-iteration QM performance metric that indicates the fraction of samples needed to match random sampling performance. Using four datasets from diverse domains and seven QMs of various types, we empirically evaluate the speed-up factor and compare it with state-of-the-art AL performance metrics. The results confirm the assumptions underlying the speed-up factor, demonstrate its accuracy in capturing the described fraction, and reveal its superior stability across iterations.",
      "authors": [
        "Hannes Kath",
        "Thiago S. Gouvêa",
        "Daniel Sonntag"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 10:33:02+00:00",
      "link": "https://arxiv.org/pdf/2602.13359v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12798v1",
      "title": "Can Neural Networks Provide Latent Embeddings for Telemetry-Aware Greedy Routing?",
      "abstract": "Telemetry-Aware routing promises to increase efficacy and responsiveness to traffic surges in computer networks. Recent research leverages Machine Learning to deal with the complex dependency between network state and routing, but sacrifices explainability of routing decisions due to the black-box nature of the proposed neural routing modules. We propose \\emph{Placer}, a novel algorithm using Message Passing Networks to transform network states into latent node embeddings. These embeddings facilitate quick greedy next-hop routing without directly solving the all-pairs shortest paths problem, and let us visualize how certain network events shape routing decisions.",
      "authors": [
        "Andreas Boltres",
        "Niklas Freymuth",
        "Gerhard Neumann"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "published": "2026-02-13 10:31:09+00:00",
      "link": "https://arxiv.org/pdf/2602.12798v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12774v1",
      "title": "Bootstrapping MLLM for Weakly-Supervised Class-Agnostic Object Counting",
      "abstract": "Object counting is a fundamental task in computer vision, with broad applicability in many real-world scenarios. Fully-supervised counting methods require costly point-level annotations per object. Few weakly-supervised methods leverage only image-level object counts as supervision and achieve fairly promising results. They are, however, often limited to counting a single category, e.g. person. In this paper, we propose WS-COC, the first MLLM-driven weakly-supervised framework for class-agnostic object counting. Instead of directly fine-tuning MLLMs to predict object counts, which can be challenging due to the modality gap, we incorporate three simple yet effective strategies to bootstrap the counting paradigm in both training and testing: First, a divide-and-discern dialogue tuning strategy is proposed to guide the MLLM to determine whether the object count falls within a specific range and progressively break down the range through multi-round dialogue. Second, a compare-and-rank count optimization strategy is introduced to train the MLLM to optimize the relative ranking of multiple images according to their object counts. Third, a global-and-local counting enhancement strategy aggregates and fuses local and global count predictions to improve counting performance in dense scenes. Extensive experiments on FSC-147, CARPK, PUCPR+, and ShanghaiTech show that WS-COC matches or even surpasses many state-of-art fully-supervised methods while significantly reducing annotation costs. Code is available at https://github.com/viscom-tongji/WS-COC.",
      "authors": [
        "Xiaowen Zhang",
        "Zijie Yue",
        "Yong Luo",
        "Cairong Zhao",
        "Qijun Chen",
        "Miaojing Shi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 09:58:35+00:00",
      "link": "https://arxiv.org/pdf/2602.12774v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12769v1",
      "title": "PixelRush: Ultra-Fast, Training-Free High-Resolution Image Generation via One-step Diffusion",
      "abstract": "Pre-trained diffusion models excel at generating high-quality images but remain inherently limited by their native training resolution. Recent training-free approaches have attempted to overcome this constraint by introducing interventions during the denoising process; however, these methods incur substantial computational overhead, often requiring more than five minutes to produce a single 4K image. In this paper, we present PixelRush, the first tuning-free framework for practical high-resolution text-to-image generation. Our method builds upon the established patch-based inference paradigm but eliminates the need for multiple inversion and regeneration cycles. Instead, PixelRush enables efficient patch-based denoising within a low-step regime. To address artifacts introduced by patch blending in few-step generation, we propose a seamless blending strategy. Furthermore, we mitigate over-smoothing effects through a noise injection mechanism. PixelRush delivers exceptional efficiency, generating 4K images in approximately 20 seconds representing a 10$\\times$ to 35$\\times$ speedup over state-of-the-art methods while maintaining superior visual fidelity. Extensive experiments validate both the performance gains and the quality of outputs achieved by our approach.",
      "authors": [
        "Hong-Phuc Lai",
        "Phong Nguyen",
        "Anh Tran"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 09:54:27+00:00",
      "link": "https://arxiv.org/pdf/2602.12769v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12758v1",
      "title": "VineetVC: Adaptive Video Conferencing Under Severe Bandwidth Constraints Using Audio-Driven Talking-Head Reconstruction",
      "abstract": "Intense bandwidth depletion within consumer and constrained networks has the potential to undermine the stability of real-time video conferencing: encoder rate management becomes saturated, packet loss escalates, frame rates deteriorate, and end-to-end latency significantly increases. This work delineates an adaptive conferencing system that integrates WebRTC media delivery with a supplementary audio-driven talking-head reconstruction pathway and telemetry-driven mode regulation. The system consists of a WebSocket signaling service, an optional SFU for multi-party transmission, a browser client capable of real-time WebRTC statistics extraction and CSV telemetry export, and an AI REST service that processes a reference face image and recorded audio to produce a synthesized MP4; the browser can substitute its outbound camera track with the synthesized stream with a median bandwidth of 32.80 kbps. The solution incorporates a bandwidth-mode switching strategy and a client-side mode-state logger.",
      "authors": [
        "Vineet Kumar Rakesh",
        "Soumya Mazumdar",
        "Tapas Samanta",
        "Hemendra Kumar Pandey",
        "Amitabha Das",
        "Sarbajit Pal"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "published": "2026-02-13 09:37:10+00:00",
      "link": "https://arxiv.org/pdf/2602.12758v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12750v1",
      "title": "Lung nodule classification on CT scan patches using 3D convolutional neural networks",
      "abstract": "Lung cancer remains one of the most common and deadliest forms of cancer worldwide. The likelihood of successful treatment depends strongly on the stage at which the disease is diagnosed. Therefore, early detection of lung cancer represents a critical medical challenge. However, this task poses significant difficulties for thoracic radiologists due to the large number of studies to review, the presence of multiple nodules within the lungs, and the small size of many nodules, which complicates visual assessment. Consequently, the development of automated systems that incorporate highly accurate and computationally efficient lung nodule detection and classification modules is essential. This study introduces three methodological improvements for lung nodule classification: (1) an advanced CT scan cropping strategy that focuses the model on the target nodule while reducing computational cost; (2) target filtering techniques for removing noisy labels; (3) novel augmentation methods to improve model robustness. The integration of these techniques enables the development of a robust classification subsystem within a comprehensive Clinical Decision Support System for lung cancer detection, capable of operating across diverse acquisition protocols, scanner types, and upstream models (segmentation or detection). The multiclass model achieved a Macro ROC AUC of 0.9176 and a Macro F1-score of 0.7658, while the binary model reached a Binary ROC AUC of 0.9383 and a Binary F1-score of 0.8668 on the LIDC-IDRI dataset. These results outperform several previously reported approaches and demonstrate state-of-the-art performance for this task.",
      "authors": [
        "Volodymyr Sydorskyi"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV",
        "eess.SY"
      ],
      "published": "2026-02-13 09:26:32+00:00",
      "link": "https://arxiv.org/pdf/2602.12750v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12744v1",
      "title": "Adaptive Structured Pruning of Convolutional Neural Networks for Time Series Classification",
      "abstract": "Deep learning models for Time Series Classification (TSC) have achieved strong predictive performance but their high computational and memory requirements often limit deployment on resource-constrained devices. While structured pruning can address these issues by removing redundant filters, existing methods typically rely on manually tuned hyperparameters such as pruning ratios which limit scalability and generalization across datasets. In this work, we propose Dynamic Structured Pruning (DSP), a fully automatic, structured pruning framework for convolution-based TSC models. DSP introduces an instance-wise sparsity loss during training to induce channel-level sparsity, followed by a global activation analysis to identify and prune redundant filters without needing any predefined pruning ratio. This work tackles computational bottlenecks of deep TSC models for deployment on resource-constrained devices. We validate DSP on 128 UCR datasets using two different deep state-of-the-art architectures: LITETime and InceptionTime. Our approach achieves an average compression of 58% for LITETime and 75% for InceptionTime architectures while maintaining classification accuracy. Redundancy analyses confirm that DSP produces compact and informative representations, offering a practical path for scalable and efficient deep TSC deployment.",
      "authors": [
        "Javidan Abdullayev",
        "Maxime Devanne",
        "Cyril Meyer",
        "Ali Ismail-Fawaz",
        "Jonathan Weber",
        "Germain Forestier"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 09:18:59+00:00",
      "link": "https://arxiv.org/pdf/2602.12744v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12742v1",
      "title": "Synthetic Craquelure Generation for Unsupervised Painting Restoration",
      "abstract": "Cultural heritage preservation increasingly demands non-invasive digital methods for painting restoration, yet identifying and restoring fine craquelure patterns from complex brushstrokes remains challenging due to scarce pixel-level annotations. We propose a fully annotation-free framework driven by a domain-specific synthetic craquelure generator, which simulates realistic branching and tapered fissure geometry using Bézier trajectories. Our approach couples a classical morphological detector with a learning-based refinement module: a SegFormer backbone adapted via Low-Rank Adaptation (LoRA). Uniquely, we employ a detector-guided strategy, injecting the morphological map as an input spatial prior, while a masked hybrid loss and logit adjustment constrain the training to focus specifically on refining candidate crack regions. The refined masks subsequently guide an Anisotropic Diffusion inpainting stage to reconstruct missing content. Experimental results demonstrate that our pipeline significantly outperforms state-of-the-art photographic restoration models in zero-shot settings, while faithfully preserving the original paint brushwork.",
      "authors": [
        "Jana Cuch-Guillén",
        "Antonio Agudo",
        "Raül Pérez-Gonzalo"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-13 09:13:46+00:00",
      "link": "https://arxiv.org/pdf/2602.12742v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12740v1",
      "title": "SPRig: Self-Supervised Pose-Invariant Rigging from Mesh Sequences",
      "abstract": "State-of-the-art rigging methods assume a canonical rest pose--an assumption that fails for sequential data (e.g., animal motion capture or AIGC/video-derived mesh sequences) that lack the T-pose. Applied frame-by-frame, these methods are not pose-invariant and produce topological inconsistencies across frames. Thus We propose SPRig, a general fine-tuning framework that enforces cross-frame consistency losses to learn pose-invariant rigs on top of existing models. We validate our approach on rigging using a new permutation-invariant stability protocol. Experiments demonstrate SOTA temporal stability: our method produces coherent rigs from challenging sequences and dramatically reduces the artifacts that plague baseline methods. The code will be released publicly upon acceptance.",
      "authors": [
        "Ruipeng Wang",
        "Langkun Zhong",
        "Miaowei Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.GR"
      ],
      "published": "2026-02-13 09:08:50+00:00",
      "link": "https://arxiv.org/pdf/2602.12740v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12724v1",
      "title": "TRANS: Terrain-aware Reinforcement Learning for Agile Navigation of Quadruped Robots under Social Interactions",
      "abstract": "This study introduces TRANS: Terrain-aware Reinforcement learning for Agile Navigation under Social interactions, a deep reinforcement learning (DRL) framework for quadrupedal social navigation over unstructured terrains. Conventional quadrupedal navigation typically separates motion planning from locomotion control, neglecting whole-body constraints and terrain awareness. On the other hand, end-to-end methods are more integrated but require high-frequency sensing, which is often noisy and computationally costly. In addition, most existing approaches assume static environments, limiting their use in human-populated settings. To address these limitations, we propose a two-stage training framework with three DRL pipelines. (1) TRANS-Loco employs an asymmetric actor-critic (AC) model for quadrupedal locomotion, enabling traversal of uneven terrains without explicit terrain or contact observations. (2) TRANS-Nav applies a symmetric AC framework for social navigation, directly mapping transformed LiDAR data to ego-agent actions under differential-drive kinematics. (3) A unified pipeline, TRANS, integrates TRANS-Loco and TRANS-Nav, supporting terrain-aware quadrupedal navigation in uneven and socially interactive environments. Comprehensive benchmarks against locomotion and social navigation baselines demonstrate the effectiveness of TRANS. Hardware experiments further confirm its potential for sim-to-real transfer.",
      "authors": [
        "Wei Zhu",
        "Irfan Tito Kurniawan",
        "Ye Zhao",
        "Mistuhiro Hayashibe"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-13 08:54:05+00:00",
      "link": "https://arxiv.org/pdf/2602.12724v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12712v1",
      "title": "Reverse Delegated Training and Private Inference via Perfectly-Secure Quantum Homomorphic Encryption",
      "abstract": "Quantum machine learning in cloud environments requires protecting sensitive data while enabling remote computation. Here we demonstrate the first realistic implementations of a perfectly-secure quantum homomorphic encryption (QHE) scheme applied to quantum neural networks (QNN). Using efficient Clifford+$T$ decomposition, we implement quantum convolutional neural networks for two complementary scenarios: (i) reverse delegated training, where encrypted data from multiple providers trains a user's network via federated aggregation; (ii) private inference, where users process encrypted data with remote quantum networks. Moreover, analysis of server circuit privacy reveals probabilistic model protection through Pauli gate concealment. These results establish perfectly-secure QHE as a practical framework for multi-party quantum machine learning.",
      "authors": [
        "Sergio A. Ortega",
        "Miguel A. Martin-Delgado"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.NE"
      ],
      "published": "2026-02-13 08:27:39+00:00",
      "link": "https://arxiv.org/pdf/2602.12712v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12706v1",
      "title": "Physics-Informed Laplace Neural Operator for Solving Partial Differential Equations",
      "abstract": "Neural operators have emerged as fast surrogate solvers for parametric partial differential equations (PDEs). However, purely data-driven models often require extensive training data and can generalize poorly, especially in small-data regimes and under unseen (out-of-distribution) input functions that are not represented in the training data. To address these limitations, we propose the Physics-Informed Laplace Neural Operator (PILNO), which enhances the Laplace Neural Operator (LNO) by embedding governing physics into training through PDE, boundary condition, and initial condition residuals. To improve expressivity, we first introduce an Advanced LNO (ALNO) backbone that retains a pole-residue transient representation while replacing the steady-state branch with an FNO-style Fourier multiplier. To make physics-informed training both data-efficient and robust, PILNO further leverages (i) virtual inputs: an unlabeled ensemble of input functions spanning a broad spectral range that provides abundant physics-only supervision and explicitly targets out-of-distribution (OOD) regimes; and (ii) temporal-causality weighting: a time-decaying reweighting of the physics residual that prioritizes early-time dynamics and stabilizes optimization for time-dependent PDEs. Across four representative benchmarks -- Burgers' equation, Darcy flow, a reaction-diffusion system, and a forced KdV equation -- PILNO consistently improves accuracy in small-data settings (e.g., N_train <= 27), reduces run-to-run variability across random seeds, and achieves stronger OOD generalization than purely data-driven baselines.",
      "authors": [
        "Heechang Kim",
        "Qianying Cao",
        "Hyomin Shin",
        "Seungchul Lee",
        "George Em Karniadakis",
        "Minseok Choi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 08:19:40+00:00",
      "link": "https://arxiv.org/pdf/2602.12706v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12704v1",
      "title": "QTabGAN: A Hybrid Quantum-Classical GAN for Tabular Data Synthesis",
      "abstract": "Synthesizing realistic tabular data is challenging due to heterogeneous feature types and high dimensionality. We introduce QTabGAN, a hybrid quantum-classical generative adversarial framework for tabular data synthesis. QTabGAN is especially designed for settings where real data are scarce or restricted by privacy constraints. The model exploits the expressive power of quantum circuits to learn complex data distributions, which are then mapped to tabular features using classical neural networks. We evaluate QTabGAN on multiple classification and regression datasets and benchmark it against leading state-of-the-art generative models. Experiments show that QTabGAN achieves up to 54.07% improvement across various classification datasets and evaluation metrics, thus establishing a scalable quantum approach to tabular data synthesis and highlighting its potential for quantum-assisted generative modelling.",
      "authors": [
        "Subhangi Kumari",
        "Rakesh Achutha",
        "Vignesh Sivaraman"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "quant-ph"
      ],
      "published": "2026-02-13 08:17:28+00:00",
      "link": "https://arxiv.org/pdf/2602.12704v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13357v1",
      "title": "AdaCorrection: Adaptive Offset Cache Correction for Accurate Diffusion Transformers",
      "abstract": "Diffusion Transformers (DiTs) achieve state-of-the-art performance in high-fidelity image and video generation but suffer from expensive inference due to their iterative denoising structure. While prior methods accelerate sampling by caching intermediate features, they rely on static reuse schedules or coarse-grained heuristics, which often lead to temporal drift and cache misalignment that significantly degrade generation quality. We introduce \\textbf{AdaCorrection}, an adaptive offset cache correction framework that maintains high generation fidelity while enabling efficient cache reuse across Transformer layers during diffusion inference. At each timestep, AdaCorrection estimates cache validity with lightweight spatio-temporal signals and adaptively blends cached and fresh activations. This correction is computed on-the-fly without additional supervision or retraining. Our approach achieves strong generation quality with minimal computational overhead, maintaining near-original FID while providing moderate acceleration. Experiments on image and video diffusion benchmarks show that AdaCorrection consistently improves generation performance.",
      "authors": [
        "Dong Liu",
        "Yanxuan Yu",
        "Ben Lengerich",
        "Ying Nian Wu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-13 08:11:54+00:00",
      "link": "https://arxiv.org/pdf/2602.13357v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12694v2",
      "title": "Discovering the mechanics of ultra-low density elastomeric foams in elite-level racing shoes",
      "abstract": "Ultra-low-density elastomeric foams enable lightweight systems that combine high compliance with efficient energy return. In high-performance racing shoes, these foams are critical for low weight, high cushioning, and efficient energy return; yet, their constitutive behavior remains difficult to model and poorly understood. Here we integrate mechanical testing and machine learning to discover the mechanics of two ultra-low density elastomeric polymeric foams used in elite-level racing shoes. Across uniaxial tension, confined and unconfined compression, and simple shear, both foams exhibit pronounced tension-compression asymmetry, negligible lateral strains consistent with an effective Poisson's ratio close to zero, and low hysteresis indicative of an efficient energy return. Both foams provide a similar compressive stiffness (268kPa vs. 299kPa), while one foam exhibits nearly double the shear stiffness (219kPa vs. 117kPa), implying a substantially greater lateral stability at a comparable vertical energy return (83% vs. 89%). By integrating these data into constitutive neural networks, paired with sparse regression, we discover compact, interpretable single-invariant models, supplemented by mixed-invariant or principal-stretch based terms, that capture the unique signature of the foams with R2 values close to one. From a human performance perspective, these models enable finite-element and gait-level simulations of high-performance racing shoes to quantify running economy, performance enhancements, and injury risks on an individual athlete level. More broadly, this work establishes a scalable and interpretable approach for constitutive modeling of highly compressible, ultra-light elastomeric foams with applications to wearable technologies, soft robotics, and energy-efficient mobility systems.",
      "authors": [
        "Jeremy A. McCulloch",
        "Scott L. Delp",
        "Ellen Kuhl"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-02-13 07:56:28+00:00",
      "link": "https://arxiv.org/pdf/2602.12694v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12691v1",
      "title": "ALOE: Action-Level Off-Policy Evaluation for Vision-Language-Action Model Post-Training",
      "abstract": "We study how to improve large foundation vision-language-action (VLA) systems through online reinforcement learning (RL) in real-world settings. Central to this process is the value function, which provides learning signals to guide VLA learning from experience. In practice, the value function is estimated from trajectory fragments collected from different data sources, including historical policies and intermittent human interventions. Estimating the value function of current behavior quality from the mixture data is inherently an off-policy evaluation problem. However, prior work often adopts conservative on-policy estimation for stability, which avoids direct evaluation of the current high-capacity policy and limits learning effectiveness. In this paper, we propose ALOE, an action-level off-policy evaluation framework for VLA post-training. ALOE applies chunking-based temporal-difference bootstrapping to evaluate individual action sequences instead of predicting final task outcomes. This design improves effective credit assignment to critical action chunks under sparse rewards and supports stable policy improvement. We evaluate our method on three real-world manipulation tasks, including smartphone packing as a high-precision task, laundry folding as a long-horizon deformable-object task, and bimanual pick-and-place involving multi-object perception. Across all tasks, ALOE improves learning efficiency without compromising execution speed, showing that off-policy RL can be reintroduced in a reliable manner for real-world VLA post-training. Videos and additional materials are available at our project website.",
      "authors": [
        "Rushuai Yang",
        "Hecheng Wang",
        "Chiming Liu",
        "Xiaohan Yan",
        "Yunlong Wang",
        "Xuan Du",
        "Shuoyu Yue",
        "Yongcheng Liu",
        "Chuheng Zhang",
        "Lizhe Qi",
        "Yi Chen",
        "Wei Shan",
        "Maoqing Yao"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-13 07:46:37+00:00",
      "link": "https://arxiv.org/pdf/2602.12691v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12681v1",
      "title": "Fool Me If You Can: On the Robustness of Binary Code Similarity Detection Models against Semantics-preserving Transformations",
      "abstract": "Binary code analysis plays an essential role in cybersecurity, facilitating reverse engineering to reveal the inner workings of programs in the absence of source code. Traditional approaches, such as static and dynamic analysis, extract valuable insights from stripped binaries, but often demand substantial expertise and manual effort. Recent advances in deep learning have opened promising opportunities to enhance binary analysis by capturing latent features and disclosing underlying code semantics. Despite the growing number of binary analysis models based on machine learning, their robustness to adversarial code transformations at the binary level remains underexplored. We evaluate the robustness of deep learning models for the task of binary code similarity detection (BCSD) under semantics-preserving transformations. The unique nature of machine instructions presents distinct challenges compared to the typical input perturbations found in other domains. We introduce asmFooler, a system that evaluates the resilience of BCSD models using a diverse set of adversarial code transformations that preserve functional semantics. We construct a dataset of 9,565 binary variants from 620 baseline samples by applying eight semantics-preserving transformations across six representative BCSD models. Our major findings highlight several key insights: i) model robustness relies on the processing pipeline, including code pre-processing, architecture, and feature selection; ii) adversarial transformation effectiveness is bounded by a budget shaped by model-specific constraints like input size and instruction expressive capacity; iii) well-crafted transformations can be highly effective with minimal perturbations; and iv) such transformations efficiently disrupt model decisions (e.g., misleading to false positives or false negatives) by focusing on semantically significant instructions.",
      "authors": [
        "Jiyong Uhm",
        "Minseok Kim",
        "Michalis Polychronakis",
        "Hyungjoon Koo"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-02-13 07:23:15+00:00",
      "link": "https://arxiv.org/pdf/2602.12681v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12674v1",
      "title": "$\\mathcal{X}$-KD: General Experiential Knowledge Distillation for Large Language Models",
      "abstract": "Knowledge Distillation (KD) for Large Language Models (LLMs) has become increasingly important as models grow in size and complexity. While existing distillation approaches focus on imitating teacher behavior, they often overlook the original learning environment that shaped the teacher's knowledge. Inspired by the experiential learning theory and inverse reinforcement learning, we propose Experiential Knowledge Distillation ($\\mathcal{X}$-KD), a novel and general framework that enables student models to learn in the teacher's original learning environment. $\\mathcal{X}$-KD adopts the Approximated Variational Reward Imitation Learning (AVRIL) framework to jointly model the teacher's original reward function and perform policy distillation, encouraging consistency between the student policy and the original reward function. Our derivation demonstrates that $\\mathcal{X}$-KD follows the supervised learning framework and applies to both sequence-level and divergence-based distillation methods, underlining the simplicity and flexibility of our approach. Empirical results show that $\\mathcal{X}$-KD outperforms the generalized KD and MiniLLM baselines on abstractive summarization, machine translation, and arithmetic reasoning tasks. Additionally, $\\mathcal{X}$-KD achieves better performance-diversity trade-off and data efficiency than baseline KD approaches.",
      "authors": [
        "Yuang Cai",
        "Yuyu Yuan"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-13 07:15:10+00:00",
      "link": "https://arxiv.org/pdf/2602.12674v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12656v1",
      "title": "PMG: Parameterized Motion Generator for Human-like Locomotion Control",
      "abstract": "Recent advances in data-driven reinforcement learning and motion tracking have substantially improved humanoid locomotion, yet critical practical challenges remain. In particular, while low-level motion tracking and trajectory-following controllers are mature, whole-body reference-guided methods are difficult to adapt to higher-level command interfaces and diverse task contexts: they require large, high-quality datasets, are brittle across speed and pose regimes, and are sensitive to robot-specific calibration. To address these limitations, we propose the Parameterized Motion Generator (PMG), a real-time motion generator grounded in an analysis of human motion structure that synthesizes reference trajectories using only a compact set of parameterized motion data together with High-dimensional control commands. Combined with an imitation-learning pipeline and an optimization-based sim-to-real motor parameter identification module, we validate the complete approach on our humanoid prototype ZERITH Z1 and show that, within a single integrated system, PMG produces natural, human-like locomotion, responds precisely to high-dimensional control inputs-including VR-based teleoperation-and enables efficient, verifiable sim-to-real transfer. Together, these results establish a practical, experimentally validated pathway toward natural and deployable humanoid control.",
      "authors": [
        "Chenxi Han",
        "Yuheng Min",
        "Zihao Huang",
        "Ao Hong",
        "Hang Liu",
        "Yi Cheng",
        "Houde Liu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-13 06:38:04+00:00",
      "link": "https://arxiv.org/pdf/2602.12656v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12652v1",
      "title": "CBEN -- A Multimodal Machine Learning Dataset for Cloud Robust Remote Sensing Image Understanding",
      "abstract": "Clouds are a common phenomenon that distorts optical satellite imagery, which poses a challenge for remote sensing. However, in the literature cloudless analysis is often performed where cloudy images are excluded from machine learning datasets and methods. Such an approach cannot be applied to time sensitive applications, e.g., during natural disasters. A possible solution is to apply cloud removal as a preprocessing step to ensure that cloudfree solutions are not failing under such conditions. But cloud removal methods are still actively researched and suffer from drawbacks, such as generated visual artifacts. Therefore, it is desirable to develop cloud robust methods that are less affected by cloudy weather. Cloud robust methods can be achieved by combining optical data with radar, a modality unaffected by clouds. While many datasets for machine learning combine optical and radar data, most researchers exclude cloudy images. We identify this exclusion from machine learning training and evaluation as a limitation that reduces applicability to cloudy scenarios. To investigate this, we assembled a dataset, named CloudyBigEarthNet (CBEN), of paired optical and radar images with cloud occlusion for training and evaluation. Using average precision (AP) as the evaluation metric, we show that state-of-the-art methods trained on combined clear-sky optical and radar imagery suffer performance drops of 23-33 percentage points when evaluated on cloudy images. We then adapt these methods to cloudy optical data during training, achieving relative improvement of 17.2-28.7 percentage points on cloudy test cases compared with the original approaches. Code and dataset are publicly available at: https://github.com/mstricker13/CBEN",
      "authors": [
        "Marco Stricker",
        "Masakazu Iwamura",
        "Koichi Kise"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 06:24:55+00:00",
      "link": "https://arxiv.org/pdf/2602.12652v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12643v1",
      "title": "Unifying Model-Free Efficiency and Model-Based Representations via Latent Dynamics",
      "abstract": "We present Unified Latent Dynamics (ULD), a novel reinforcement learning algorithm that unifies the efficiency of model-free methods with the representational strengths of model-based approaches, without incurring planning overhead. By embedding state-action pairs into a latent space in which the true value function is approximately linear, our method supports a single set of hyperparameters across diverse domains -- from continuous control with low-dimensional and pixel inputs to high-dimensional Atari games. We prove that, under mild conditions, the fixed point of our embedding-based temporal-difference updates coincides with that of a corresponding linear model-based value expansion, and we derive explicit error bounds relating embedding fidelity to value approximation quality. In practice, ULD employs synchronized updates of encoder, value, and policy networks, auxiliary losses for short-horizon predictive dynamics, and reward-scale normalization to ensure stable learning under sparse rewards. Evaluated on 80 environments spanning Gym locomotion, DeepMind Control (proprioceptive and visual), and Atari, our approach matches or exceeds the performance of specialized model-free and general model-based baselines -- achieving cross-domain competence with minimal tuning and a fraction of the parameter footprint. These results indicate that value-aligned latent representations alone can deliver the adaptability and sample efficiency traditionally attributed to full model-based planning.",
      "authors": [
        "Jashaswimalya Acharjee",
        "Balaraman Ravindran"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-02-13 06:06:56+00:00",
      "link": "https://arxiv.org/pdf/2602.12643v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12635v1",
      "title": "Unleashing Low-Bit Inference on Ascend NPUs: A Comprehensive Evaluation of HiFloat Formats",
      "abstract": "As LLMs scale, low-bit floating-point formats like MXFP and NVFP4 offer new opportunities for precision and efficiency. In this work, we evaluate HiFloat (HiF8 and HiF4), a family of formats tailored for Ascend NPUs. Through rigorous comparison across weight-activation and KV-cache tasks, we provide three key insights: (1) INT8 suits narrow-range data, while floating-point formats excel with high-variance data; (2) in 4-bit regimes, HiF4's hierarchical scaling prevents the accuracy collapse seen in integer formats; and (3) HiFloat is fully compatible with state-of-the-art post-training quantization frameworks. Overall, HiFloat provides a solution for high-efficiency LLM inference on NPUs.",
      "authors": [
        "Pengxiang Zhao",
        "Hui-Ling Zhen",
        "Xing Li",
        "Han Bao",
        "Weizhe Lin",
        "Zhiyuan Yang",
        "Ziwei Yu",
        "Xin Wang",
        "Mingxuan Yuan",
        "Xianzhi Yu",
        "Zhenhua Dong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-13 05:41:31+00:00",
      "link": "https://arxiv.org/pdf/2602.12635v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12633v1",
      "title": "Real-to-Sim for Highly Cluttered Environments via Physics-Consistent Inter-Object Reasoning",
      "abstract": "Reconstructing physically valid 3D scenes from single-view observations is a prerequisite for bridging the gap between visual perception and robotic control. However, in scenarios requiring precise contact reasoning, such as robotic manipulation in highly cluttered environments, geometric fidelity alone is insufficient. Standard perception pipelines often neglect physical constraints, resulting in invalid states, e.g., floating objects or severe inter-penetration, rendering downstream simulation unreliable. To address these limitations, we propose a novel physics-constrained Real-to-Sim pipeline that reconstructs physically consistent 3D scenes from single-view RGB-D data. Central to our approach is a differentiable optimization pipeline that explicitly models spatial dependencies via a contact graph, jointly refining object poses and physical properties through differentiable rigid-body simulation. Extensive evaluations in both simulation and real-world settings demonstrate that our reconstructed scenes achieve high physical fidelity and faithfully replicate real-world contact dynamics, enabling stable and reliable contact-rich manipulation.",
      "authors": [
        "Tianyi Xiang",
        "Jiahang Cao",
        "Sikai Guo",
        "Guoyang Zhao",
        "Andrew F. Luo",
        "Jun Ma"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-13 05:24:58+00:00",
      "link": "https://arxiv.org/pdf/2602.12633v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12632v1",
      "title": "Additively Competitive Secretaries",
      "abstract": "In the secretary problem, a set of secretary candidates arrive in a uniformly random order and reveal their values one by one. A company, who can only hire one candidate and hopes to maximize the expected value of its hire, needs to make irrevocable online decisions about whether to hire the current candidate. The classical framework of evaluating a policy is to compute its worst-case competitive ratio against the optimal solution in hindsight, and there the best policy -- the ``$1/e$ law'' -- has a competitive ratio of $1/e$.   We propose an alternative evaluation framework through the lens of regret -- the worst-case additive difference between the optimal hindsight solution and the expected performance of the policy, assuming that each value is normalized between $0$ and $1$. The $1/e$ law for the classical framework has a regret of $1 - 1/e \\approx 0.632$; by contrast, we show that the class of ``pricing curves'' algorithms can guarantee a regret of at most $1/4 = 0.25$ (which is tight within the class), and the class of ``best-only pricing curves'' algorithms can guarantee a regret of at most $0.190$ (with a lower bound of $0.171$). In addition, we show that in general, no policy can give a regret guarantee better than $0.152$. Finally, we discuss other objectives in our regret-minimization framework, such as selecting the top-$k$ candidates for $k > 1$, or maximizing revenue during the selection process.",
      "authors": [
        "Mohammad Mahdian",
        "Jieming Mao",
        "Enze Sun",
        "Kangning Wang",
        "Yifan Wang"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.GT"
      ],
      "published": "2026-02-13 05:23:49+00:00",
      "link": "https://arxiv.org/pdf/2602.12632v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12631v1",
      "title": "AI Agents for Inventory Control: Human-LLM-OR Complementarity",
      "abstract": "Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it remains unclear how best to incorporate LLM-based methods into traditional decision-making pipelines.   We study how OR algorithms, LLMs, and humans can interact and complement each other in a multi-period inventory control setting. We construct InventoryBench, a benchmark of over 1,000 inventory instances spanning both synthetic and real-world demand data, designed to stress-test decision rules under demand shifts, seasonality, and uncertain lead times. Through this benchmark, we find that OR-augmented LLM methods outperform either method in isolation, suggesting that these methods are complementary rather than substitutes.   We further investigate the role of humans through a controlled classroom experiment that embeds LLM recommendations into a human-in-the-loop decision pipeline. Contrary to prior findings that human-AI collaboration can degrade performance, we show that, on average, human-AI teams achieve higher profits than either humans or AI agents operating alone. Beyond this population-level finding, we formalize an individual-level complementarity effect and derive a distribution-free lower bound on the fraction of individuals who benefit from AI collaboration; empirically, we find this fraction to be substantial.",
      "authors": [
        "Jackie Baek",
        "Yaopeng Fu",
        "Will Ma",
        "Tianyi Peng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "published": "2026-02-13 05:23:46+00:00",
      "link": "https://arxiv.org/pdf/2602.12631v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12628v2",
      "title": "Beyond Imitation: Reinforcement Learning-Based Sim-Real Co-Training for VLA Models",
      "abstract": "Simulation offers a scalable and low-cost way to enrich vision-language-action (VLA) training, reducing reliance on expensive real-robot demonstrations. However, most sim-real co-training methods rely on supervised fine-tuning (SFT), which treats simulation as a static source of demonstrations and does not exploit large-scale closed-loop interaction. Consequently, real-world gains and generalization are often limited. In this paper, we propose an \\underline{\\textit{RL}}-based sim-real \\underline{\\textit{Co}}-training \\modify{(RL-Co)} framework that leverages interactive simulation while preserving real-world capabilities. Our method follows a generic two-stage design: we first warm-start the policy with SFT on a mixture of real and simulated demonstrations, then fine-tune it with reinforcement learning in simulation while adding an auxiliary supervised loss on real-world data to anchor the policy and mitigate catastrophic forgetting. We evaluate our framework on four real-world tabletop manipulation tasks using two representative VLA architectures, OpenVLA and $π_{0.5}$, and observe consistent improvements over real-only fine-tuning and SFT-based co-training, including +24% real-world success on OpenVLA and +20% on $π_{0.5}$. Beyond higher success rates, RL co-training yields stronger generalization to unseen task variations and substantially improved real-world data efficiency, providing a practical and scalable pathway for leveraging simulation to enhance real-robot deployment.",
      "authors": [
        "Liangzhi Shi",
        "Shuaihang Chen",
        "Feng Gao",
        "Yinuo Chen",
        "Kang Chen",
        "Tonghe Zhang",
        "Hongzhi Zang",
        "Weinan Zhang",
        "Chao Yu",
        "Yu Wang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-13 05:15:50+00:00",
      "link": "https://arxiv.org/pdf/2602.12628v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13353v1",
      "title": "Robust Mean-Field Games with Risk Aversion and Bounded Rationality",
      "abstract": "Recent advances in mean-field game literature enable the reduction of large-scale multi-agent problems to tractable interactions between a representative agent and a population distribution. However, existing approaches typically assume a fixed initial population distribution and fully rational agents, limiting robustness under distributional uncertainty and cognitive constraints. We address these limitations by introducing risk aversion with respect to the initial population distribution and by incorporating bounded rationality to model deviations from fully rational decision-making agents. The combination of these two elements yields a new and more general equilibrium concept, which we term the mean-field risk-averse quantal response equilibrium (MF-RQE). We establish existence results and prove convergence of fixed-point iteration and fictitious play to MF-RQE. Building on these insights, we develop a scalable reinforcement learning algorithm for scenarios with large state-action spaces. Numerical experiments demonstrate that MF-RQE policies achieve improved robustness relative to classical mean-field approaches that optimize expected cumulative rewards under a fixed initial distribution and are restricted to entropy-based regularizers.",
      "authors": [
        "Bhavini Jeloka",
        "Yue Guan",
        "Panagiotis Tsiotras"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.GT"
      ],
      "published": "2026-02-13 05:07:50+00:00",
      "link": "https://arxiv.org/pdf/2602.13353v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12622v1",
      "title": "Efficient Personalized Federated PCA with Manifold Optimization for IoT Anomaly Detection",
      "abstract": "Internet of things (IoT) networks face increasing security threats due to their distributed nature and resource constraints. Although federated learning (FL) has gained prominence as a privacy-preserving framework for distributed IoT environments, current federated principal component analysis (PCA) methods lack the integration of personalization and robustness, which are critical for effective anomaly detection. To address these limitations, we propose an efficient personalized federated PCA (FedEP) method for anomaly detection in IoT networks. The proposed model achieves personalization through introducing local representations with the $\\ell_1$-norm for element-wise sparsity, while maintaining robustness via enforcing local models with the $\\ell_{2,1}$-norm for row-wise sparsity. To solve this non-convex problem, we develop a manifold optimization algorithm based on the alternating direction method of multipliers (ADMM) with rigorous theoretical convergence guarantees. Experimental results confirm that the proposed FedEP outperforms the state-of-the-art FedPG, achieving excellent F1-scores and accuracy in various IoT security scenarios. Our code will be available at \\href{https://github.com/xianchaoxiu/FedEP}{https://github.com/xianchaoxiu/FedEP}.",
      "authors": [
        "Xianchao Xiu",
        "Chenyi Huang",
        "Wei Zhang",
        "Wanquan Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-13 04:58:50+00:00",
      "link": "https://arxiv.org/pdf/2602.12622v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12612v1",
      "title": "Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback",
      "abstract": "Traditional methods for automating recommender system design, such as Neural Architecture Search (NAS), are often constrained by a fixed search space defined by human priors, limiting innovation to pre-defined operators. While recent LLM-driven code evolution frameworks shift fixed search space target to open-ended program spaces, they primarily rely on scalar metrics (e.g., NDCG, Hit Ratio) that fail to provide qualitative insights into model failures or directional guidance for improvement. To address this, we propose Self-EvolveRec, a novel framework that establishes a directional feedback loop by integrating a User Simulator for qualitative critiques and a Model Diagnosis Tool for quantitative internal verification. Furthermore, we introduce a Diagnosis Tool - Model Co-Evolution strategy to ensure that evaluation criteria dynamically adapt as the recommendation architecture evolves. Extensive experiments demonstrate that Self-EvolveRec significantly outperforms state-of-the-art NAS and LLM-driven code evolution baselines in both recommendation performance and user satisfaction. Our code is available at https://github.com/Sein-Kim/self_evolverec.",
      "authors": [
        "Sein Kim",
        "Sangwu Park",
        "Hongseok Kang",
        "Wonjoong Kim",
        "Jimin Seo",
        "Yeonjun In",
        "Kanghoon Yoon",
        "Chanyoung Park"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-02-13 04:38:32+00:00",
      "link": "https://arxiv.org/pdf/2602.12612v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12602v1",
      "title": "Channel Gain Map Reconstruction Based on Virtual Scatterer Model",
      "abstract": "This paper proposes an efficient method for modeling and reconstructing the channel gain map (CGM) based on virtual scatterers. Specifically, we develop a virtual scatterer model to characterize the channel power gain distribution in three-dimensional (3D) space, by capturing the multi-path propagation environment structure and exploiting the angular-domain spatial correlation of scatterer response. In this model, the CGM is represented as a function over a set of tunable parameters for virtual scatterers, including their number, positions, and scatterer response coefficients (SRCs), which can be estimated from a limited number of channel power gain measurements at a given set of locations within the region of interest. This new representation offers a flexible and scalable modeling framework for efficient and accurate CGM reconstruction. Furthermore, we propose a progressive estimation algorithm to acquire the scatterers' parameters. In this algorithm, we gradually increase the number of virtual scatterers to balance the computational complexity and estimation accuracy. In addition, by exploiting the spatial correlation of scatterer response, we propose a Gaussian process regression (GPR)-based inference method to predict the SRCs that cannot be directly estimated. Finally, ray-tracing-based simulation results under realistic physical environments validate the effectiveness of the proposed method, demonstrating that it achieves higher reconstruction accuracy compared to conventional CGM estimation approaches.",
      "authors": [
        "He Sun",
        "Lipeng Zhu",
        "Jie Xu",
        "Rui Zhang"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-02-13 04:21:18+00:00",
      "link": "https://arxiv.org/pdf/2602.12602v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12579v1",
      "title": "VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via Confidence-Guided Variance Reduction",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a dominant paradigm for enhancing Large Language Models (LLMs) reasoning, yet its reliance on external verifiers limits its scalability. Recent findings suggest that RLVR primarily functions by eliciting latent capabilities, motivating the development of verifier-free algorithms. However, in such settings, standard methods like Group Relative Policy Optimization face a critical challenge: destructive gradient variance that often leads to training collapse. To address this issue, we introduceVerifier-Independent Curriculum Reinforcement Learning (VI-CuRL), a framework that leverages the model's intrinsic confidence to construct a curriculum independent from external verifiers. By prioritizing high-confidence samples, VI-CuRL effectively manages the bias-variance trade-off, specifically targeting the reduction of action and problem variance. We provide a rigorous theoretical analysis, proving that our estimator guarantees asymptotic unbiasedness. Empirically, VI-CuRL promotes stability and consistently outperforms verifier-independent baselines across six challenging benchmarks with/without verifiers.",
      "authors": [
        "Xin-Qiang Cai",
        "Masashi Sugiyama"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-13 03:40:52+00:00",
      "link": "https://arxiv.org/pdf/2602.12579v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12575v1",
      "title": "Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification",
      "abstract": "Psychological scale refinement traditionally relies on response-based methods such as factor analysis, item response theory, and network psychometrics to optimize item composition. Although rigorous, these approaches require large samples and may be constrained by data availability and cross-cultural comparability. Recent advances in natural language processing suggest that the semantic structure of questionnaire items may encode latent construct organization, offering a complementary response-free perspective. We introduce a topic-modeling framework that operationalizes semantic latent structure for scale simplification. Items are encoded using contextual sentence embeddings and grouped via density-based clustering to discover latent semantic factors without predefining their number. Class-based term weighting derives interpretable topic representations that approximate constructs and enable merging of semantically adjacent clusters. Representative items are selected using membership criteria within an integrated reduction pipeline. We benchmarked the framework across DASS, IPIP, and EPOCH, evaluating structural recovery, internal consistency, factor congruence, correlation preservation, and reduction efficiency. The proposed method recovered coherent factor-like groupings aligned with established constructs. Selected items reduced scale length by 60.5% on average while maintaining psychometric adequacy. Simplified scales showed high concordance with original factor structures and preserved inter-factor correlations, indicating that semantic latent organization provides a response-free approximation of measurement structure. Our framework formalizes semantic structure as an inspectable front-end for scale construction and reduction. To facilitate adoption, we provide a visualization-supported tool enabling one-click semantic analysis and structured simplification.",
      "authors": [
        "Bo Wang",
        "Yuxuan Zhang",
        "Yueqin Hu",
        "Hanchao Hou",
        "Kaiping Peng",
        "Shiguang Ni"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-13 03:37:15+00:00",
      "link": "https://arxiv.org/pdf/2602.12575v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12574v1",
      "title": "Monte Carlo Tree Search with Reasoning Path Refinement for Small Language Models in Conversational Text-to-NoSQL",
      "abstract": "NoSQL databases have been widely adopted in big data analytics, geospatial applications, and healthcare services, due to their flexibility and scalability. However, querying NoSQL databases requires specialized technical expertise, creating a high barrier for users. While recent studies have explored text-to-NoSQL problem, they primarily focus on single-turn interactions, ignoring the conversational nature of real-world queries. To bridge this gap, we introduce the Conversational Text-to-NoSQL task, which generates NoSQL queries given a natural language question, a NoSQL database, and the dialogue history. To address this task, we propose Stage-MCTS, a framework that endows small language models (SLMs) with NoSQL-specific reasoning capabilities by formulating query generation as a search problem. The framework employs Monte Carlo Tree Search (MCTS) guided by a rule-based reward to produce stepwise reasoning data, followed by progressive supervised fine-tuning (SFT) and self-training strategies. We further construct CoNoSQL, a cross-domain dataset with over 2,000 dialogues and 150 databases, to support evaluation. Experiments demonstrate that our approach outperforms state-of-the-art large reasoning models, improving execution value match (EVM) accuracy by up to 7.93%.",
      "authors": [
        "Xubang Xiong",
        "Raymond Chi-Wing Wong",
        "Yuanfeng Song"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "published": "2026-02-13 03:35:38+00:00",
      "link": "https://arxiv.org/pdf/2602.12574v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12569v1",
      "title": "Editable XAI: Toward Bidirectional Human-AI Alignment with Co-Editable Explanations of Interpretable Attributes",
      "abstract": "While Explainable AI (XAI) helps users understand AI decisions, misalignment in domain knowledge can lead to disagreement. This inconsistency hinders understanding, and because explanations are often read-only, users lack the control to improve alignment. We propose making XAI editable, allowing users to write rules to improve control and gain deeper understanding through the generation effect of active learning. We developed CoExplain, leveraging a neural network for universal representation and symbolic rules for intuitive reasoning on interpretable attributes. CoExplain explains the neural network with a faithful proxy decision tree, parses user-written rules as an equivalent neural network graph, and collaboratively optimizes the decision tree. In a user study (N=43), CoExplain and manually editable XAI improved user understanding and model alignment compared to read-only XAI. CoExplain was easier to use with fewer edits and less time. This work contributes Editable XAI for bidirectional AI alignment, improving understanding and control.",
      "authors": [
        "Haoyang Chen",
        "Jingwen Bai",
        "Fang Tian",
        "Brian Y Lim"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-13 03:27:11+00:00",
      "link": "https://arxiv.org/pdf/2602.12569v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12566v1",
      "title": "To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) plays a key role in stimulating the explicit reasoning capability of Large Language Models (LLMs). We can achieve expert-level performance in some specific domains via RLVR, such as coding or math. When a general multi-domain expert-level model is required, we need to carefully consider the collaboration of RLVR across different domains. The current state-of-the-art models mainly employ two different training paradigms for multi-domain RLVR: mixed multi-task RLVR and separate RLVR followed by model merging. However, most of the works did not provide a detailed comparison and analysis about these paradigms. To this end, we choose multiple commonly used high-level tasks (e.g., math, coding, science, and instruction following) as our target domains and design extensive qualitative and quantitative experiments using open-source datasets. We find the RLVR across domains exhibits few mutual interferences, and reasoning-intensive domains demonstrate mutually synergistic effects. Furthermore, we analyze the internal mechanisms of mutual gains from the perspectives of weight space geometry, model prediction behavior, and information constraints. This project is named as M2RL that means Mixed multi-task training or separate training followed by model Merging for Reinforcement Learning, and the homepage is at https://github.com/mosAI25/M2RL",
      "authors": [
        "Haoqing Wang",
        "Xiang Long",
        "Ziheng Li",
        "Yilong Xu",
        "Tingguang Li",
        "Yehui Tang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-13 03:25:13+00:00",
      "link": "https://arxiv.org/pdf/2602.12566v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12561v1",
      "title": "PLLM: Pseudo-Labeling Large Language Models for CAD Program Synthesis",
      "abstract": "Recovering Computer-Aided Design (CAD) programs from 3D geometries is a widely studied problem. Recent advances in large language models (LLMs) have enabled progress in CAD program synthesis, but existing methods rely on supervised training with paired shape-program data, which is often unavailable. We introduce PLLM, a self-training framework for CAD program synthesis from unlabeled 3D shapes. Given a pre-trained CAD-capable LLM and a shape dataset, PLLM iteratively samples candidate programs, selects high-fidelity executions, and augments programs to construct synthetic program-shape pairs for fine-tuning. We experiment on adapting CAD-Recode from DeepCAD to the unlabeled ABC dataset show consistent improvements in geometric fidelity and program diversity.",
      "authors": [
        "Yuanbo Li",
        "Dule Shu",
        "Yanying Chen",
        "Matt Klenk",
        "Daniel Ritchie"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 03:20:19+00:00",
      "link": "https://arxiv.org/pdf/2602.12561v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12537v1",
      "title": "News Harvesting from Google News combining Web Scraping, LLM Metadata Extraction and SCImago Media Rankings enrichment: a case study of IFMIF-DONES",
      "abstract": "This study develops and evaluates a systematic methodology for constructing news datasets from Google News, combining automated web scraping, large language model (LLM)-based metadata extraction, and SCImago Media Rankings enrichment. Using the IFMIF-DONES fusion energy project as a case study, we implemented a five-stage data collection pipeline across 81 region-language combinations, yielding 1,482 validated records after a 56% noise reduction. Results are compared against two licensed press databases: MyNews (2,280 records) and ProQuest Newsstream Collection (148 records). Overlap analysis reveals high complementarity, with 76% of Google News records exclusive to this platform. The dataset captures content types absent from proprietary databases, including specialized outlets, institutional communications, and social media posts. However, significant methodological challenges emerge: temporal instability requiring synchronic collection, a 100-result cap per query demanding multi-stage strategies, and unexpected noise including academic PDFs, false positives, and pornographic content infiltrating results through black hat SEO techniques. LLM-assisted extraction proved effective for structured articles but exhibited systematic hallucination patterns requiring validation protocols. We conclude that Google News offers valuable complementary coverage for communication research but demands substantial methodological investment, multi-source triangulation, and robust filtering mechanisms to ensure dataset integrity.",
      "authors": [
        "Victor Herrero-Solana"
      ],
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL"
      ],
      "published": "2026-02-13 02:34:26+00:00",
      "link": "https://arxiv.org/pdf/2602.12537v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12534v1",
      "title": "Linear Regression with Unknown Truncation Beyond Gaussian Features",
      "abstract": "In truncated linear regression, samples $(x,y)$ are shown only when the outcome $y$ falls inside a certain survival set $S^\\star$ and the goal is to estimate the unknown $d$-dimensional regressor $w^\\star$. This problem has a long history of study in Statistics and Machine Learning going back to the works of (Galton, 1897; Tobin, 1958) and more recently in, e.g., (Daskalakis et al., 2019; 2021; Lee et al., 2023; 2024). Despite this long history, however, most prior works are limited to the special case where $S^\\star$ is precisely known. The more practically relevant case, where $S^\\star$ is unknown and must be learned from data, remains open: indeed, here the only available algorithms require strong assumptions on the distribution of the feature vectors (e.g., Gaussianity) and, even then, have a $d^{\\mathrm{poly} (1/\\varepsilon)}$ run time for achieving $\\varepsilon$ accuracy.   In this work, we give the first algorithm for truncated linear regression with unknown survival set that runs in $\\mathrm{poly} (d/\\varepsilon)$ time, by only requiring that the feature vectors are sub-Gaussian. Our algorithm relies on a novel subroutine for efficiently learning unions of a bounded number of intervals using access to positive examples (without any negative examples) under a certain smoothness condition. This learning guarantee adds to the line of works on positive-only PAC learning and may be of independent interest.",
      "authors": [
        "Alexandros Kouridakis",
        "Anay Mehrotra",
        "Alkis Kalavasis",
        "Constantine Caramanis"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.DS",
        "cs.LG",
        "math.ST"
      ],
      "published": "2026-02-13 02:29:54+00:00",
      "link": "https://arxiv.org/pdf/2602.12534v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12530v1",
      "title": "Reasoning to Rank: An End-to-End Solution for Exploiting Large Language Models for Recommendation",
      "abstract": "Recommender systems are tasked to infer users' evolving preferences and rank items aligned with their intents, which calls for in-depth reasoning beyond pattern-based scoring. Recent efforts start to leverage large language models (LLMs) for recommendation, but how to effectively optimize the model for improved recommendation utility is still under explored. In this work, we propose Reasoning to Rank, an end-to-end training framework that internalizes recommendation utility optimization into the learning of step-by-step reasoning in LLMs. To avoid position bias in LLM reasoning and enable direct optimization of the reasoning process, our framework performs reasoning at the user-item level and employs reinforcement learning for end-to-end training of the LLM. Experiments on three Amazon datasets and a large-scale industrial dataset showed consistent gains over strong conventional and LLM-based solutions. Extensive in-depth analyses validate the necessity of the key components in the proposed framework and shed lights on the future developments of this line of work.",
      "authors": [
        "Kehan Zheng",
        "Deyao Hong",
        "Qian Li",
        "Jun Zhang",
        "Huan Yu",
        "Jie Jiang",
        "Hongning Wang"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-13 02:22:48+00:00",
      "link": "https://arxiv.org/pdf/2602.12530v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12529v1",
      "title": "Flow-Factory: A Unified Framework for Reinforcement Learning in Flow-Matching Models",
      "abstract": "Reinforcement learning has emerged as a promising paradigm for aligning diffusion and flow-matching models with human preferences, yet practitioners face fragmented codebases, model-specific implementations, and engineering complexity. We introduce Flow-Factory, a unified framework that decouples algorithms, models, and rewards through through a modular, registry-based architecture. This design enables seamless integration of new algorithms and architectures, as demonstrated by our support for GRPO, DiffusionNFT, and AWM across Flux, Qwen-Image, and WAN video models. By minimizing implementation overhead, Flow-Factory empowers researchers to rapidly prototype and scale future innovations with ease. Flow-Factory provides production-ready memory optimization, flexible multi-reward training, and seamless distributed training support. The codebase is available at https://github.com/X-GenGroup/Flow-Factory.",
      "authors": [
        "Bowen Ping",
        "Chengyou Jia",
        "Minnan Luo",
        "Hangwei Qian",
        "Ivor Tsang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-02-13 02:21:59+00:00",
      "link": "https://arxiv.org/pdf/2602.12529v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12528v1",
      "title": "DiffuRank: Effective Document Reranking with Diffusion Language Models",
      "abstract": "Recent advances in large language models (LLMs) have inspired new paradigms for document reranking. While this paradigm better exploits the reasoning and contextual understanding capabilities of LLMs, most existing LLM-based rerankers rely on autoregressive generation, which limits their efficiency and flexibility. In particular, token-by-token decoding incurs high latency, while the fixed left-to-right generation order causes early prediction errors to propagate and is difficult to revise. To address these limitations, we explore the use of diffusion language models (dLLMs) for document reranking and propose DiffuRank, a reranking framework built upon dLLMs. Unlike autoregressive models, dLLMs support more flexible decoding and generation processes that are not constrained to a left-to-right order, and enable parallel decoding, which may lead to improved efficiency and controllability. Specifically, we investigate three reranking strategies based on dLLMs: (1) a pointwise approach that uses dLLMs to estimate the relevance of each query-document pair; (2) a logit-based listwise approach that prompts dLLMs to jointly assess the relevance of multiple documents and derives ranking lists directly from model logits; and (3) a permutation-based listwise approach that adapts the canonical decoding process of dLLMs to the reranking tasks. For each approach, we design corresponding training methods to fully exploit the advantages of dLLMs. We evaluate both zero-shot and fine-tuned reranking performance on multiple benchmarks. Experimental results show that dLLMs achieve performance comparable to, and in some cases exceeding, that of autoregressive LLMs with similar model sizes. These findings demonstrate the promise of diffusion-based language models as a compelling alternative to autoregressive architectures for document reranking.",
      "authors": [
        "Qi Liu",
        "Kun Ai",
        "Jiaxin Mao",
        "Yanzhao Zhang",
        "Mingxin Li",
        "Dingkun Long",
        "Pengjun Xie",
        "Fengbin Zhu",
        "Ji-Rong Wen"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2026-02-13 02:18:14+00:00",
      "link": "https://arxiv.org/pdf/2602.12528v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12524v1",
      "title": "LiDAR-Anchored Collaborative Distillation for Robust 2D Representations",
      "abstract": "As deep learning continues to advance, self-supervised learning has made considerable strides. It allows 2D image encoders to extract useful features for various downstream tasks, including those related to vision-based systems. Nevertheless, pre-trained 2D image encoders fall short in conducting the task under noisy and adverse weather conditions beyond clear daytime scenes, which require for robust visual perception. To address these issues, we propose a novel self-supervised approach, \\textbf{Collaborative Distillation}, which leverages 3D LiDAR as self-supervision to improve robustness to noisy and adverse weather conditions in 2D image encoders while retaining their original capabilities. Our method outperforms competing methods in various downstream tasks across diverse conditions and exhibits strong generalization ability. In addition, our method also improves 3D awareness stemming from LiDAR's characteristics. This advancement highlights our method's practicality and adaptability in real-world scenarios.",
      "authors": [
        "Wonjun Jo",
        "Hyunwoo Ha",
        "Kim Ji-Yeon",
        "Hawook Jeong",
        "Tae-Hyun Oh"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 02:04:30+00:00",
      "link": "https://arxiv.org/pdf/2602.12524v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12520v1",
      "title": "Multi-Agent Model-Based Reinforcement Learning with Joint State-Action Learned Embeddings",
      "abstract": "Learning to coordinate many agents in partially observable and highly dynamic environments requires both informative representations and data-efficient training. To address this challenge, we present a novel model-based multi-agent reinforcement learning framework that unifies joint state-action representation learning with imaginative roll-outs. We design a world model trained with variational auto-encoders and augment the model using the state-action learned embedding (SALE). SALE is injected into both the imagination module that forecasts plausible future roll-outs and the joint agent network whose individual action values are combined through a mixing network to estimate the joint action-value function. By coupling imagined trajectories with SALE-based action values, the agents acquire a richer understanding of how their choices influence collective outcomes, leading to improved long-term planning and optimization under limited real-environment interactions. Empirical studies on well-established multi-agent benchmarks, including StarCraft II Micro-Management, Multi-Agent MuJoCo, and Level-Based Foraging challenges, demonstrate consistent gains of our method over baseline algorithms and highlight the effectiveness of joint state-action learned embeddings within a multi-agent model-based paradigm.",
      "authors": [
        "Zhizun Wang",
        "David Meger"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-02-13 01:57:21+00:00",
      "link": "https://arxiv.org/pdf/2602.12520v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12517v1",
      "title": "Bench-MFG: A Benchmark Suite for Learning in Stationary Mean Field Games",
      "abstract": "The intersection of Mean Field Games (MFGs) and Reinforcement Learning (RL) has fostered a growing family of algorithms designed to solve large-scale multi-agent systems. However, the field currently lacks a standardized evaluation protocol, forcing researchers to rely on bespoke, isolated, and often simplistic environments. This fragmentation makes it difficult to assess the robustness, generalization, and failure modes of emerging methods. To address this gap, we propose a comprehensive benchmark suite for MFGs (Bench-MFG), focusing on the discrete-time, discrete-space, stationary setting for the sake of clarity. We introduce a taxonomy of problem classes, ranging from no-interaction and monotone games to potential and dynamics-coupled games, and provide prototypical environments for each. Furthermore, we propose MF-Garnets, a method for generating random MFG instances to facilitate rigorous statistical testing. We benchmark a variety of learning algorithms across these environments, including a novel black-box approach (MF-PSO) for exploitability minimization. Based on our extensive empirical results, we propose guidelines to standardize future experimental comparisons. Code available at \\href{https://github.com/lorenzomagnino/Bench-MFG}{https://github.com/lorenzomagnino/Bench-MFG}.",
      "authors": [
        "Lorenzo Magnino",
        "Jiacheng Shen",
        "Matthieu Geist",
        "Olivier Pietquin",
        "Mathieu Laurière"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "math.OC"
      ],
      "published": "2026-02-13 01:49:37+00:00",
      "link": "https://arxiv.org/pdf/2602.12517v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12508v1",
      "title": "Monocular Reconstruction of Neural Tactile Fields",
      "abstract": "Robots operating in the real world must plan through environments that deform, yield, and reconfigure under contact, requiring interaction-aware 3D representations that extend beyond static geometric occupancy. To address this, we introduce neural tactile fields, a novel 3D representation that maps spatial locations to the expected tactile response upon contact. Our model predicts these neural tactile fields from a single monocular RGB image -- the first method to do so. When integrated with off-the-shelf path planners, neural tactile fields enable robots to generate paths that avoid high-resistance objects while deliberately routing through low-resistance regions (e.g. foliage), rather than treating all occupied space as equally impassable. Empirically, our learning framework improves volumetric 3D reconstruction by $85.8\\%$ and surface reconstruction by $26.7\\%$ compared to state-of-the-art monocular 3D reconstruction methods (LRM and Direct3D).",
      "authors": [
        "Pavan Mantripragada",
        "Siddhanth Deshmukh",
        "Eadom Dessalene",
        "Manas Desai",
        "Yiannis Aloimonos"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-13 01:25:19+00:00",
      "link": "https://arxiv.org/pdf/2602.12508v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12502v1",
      "title": "Building Large-Scale Drone Defenses from Small-Team Strategies",
      "abstract": "Defending against large adversarial drone swarms requires coordination methods that scale effectively beyond conventional multi-agent optimisation. In this paper, we propose to scale strategies proven effective in small defender teams by integrating them as modular components of larger forces using our proposed framework. A dynamic programming (DP) decomposition assembles these components into large teams in polynomial time, enabling efficient construction of scalable defenses without exhaustive evaluation. Because a unit that is strong in isolation may not remain strong when combined, we sample across multiple small-team candidates. Our framework iterates between evaluating large-team outcomes and refining the pool of modular components, allowing convergence on increasingly effective strategies. Experiments demonstrate that this partitioning approach scales to substantially larger scenarios while preserving effectiveness and revealing cooperative behaviours that direct optimisation cannot reliably discover.",
      "authors": [
        "Grant Douglas",
        "Stephen Franklin",
        "Claudia Szabo",
        "Mingyu Guo"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA"
      ],
      "published": "2026-02-13 01:01:00+00:00",
      "link": "https://arxiv.org/pdf/2602.12502v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12500v1",
      "title": "Favia: Forensic Agent for Vulnerability-fix Identification and Analysis",
      "abstract": "Identifying vulnerability-fixing commits corresponding to disclosed CVEs is essential for secure software maintenance but remains challenging at scale, as large repositories contain millions of commits of which only a small fraction address security issues. Existing automated approaches, including traditional machine learning techniques and recent large language model (LLM)-based methods, often suffer from poor precision-recall trade-offs. Frequently evaluated on randomly sampled commits, we uncover that they are substantially underestimating real-world difficulty, where candidate commits are already security-relevant and highly similar. We propose Favia, a forensic, agent-based framework for vulnerability-fix identification that combines scalable candidate ranking with deep and iterative semantic reasoning. Favia first employs an efficient ranking stage to narrow the search space of commits. Each commit is then rigorously evaluated using a ReAct-based LLM agent. By providing the agent with a pre-commit repository as environment, along with specialized tools, the agent tries to localize vulnerable components, navigates the codebase, and establishes causal alignment between code changes and vulnerability root causes. This evidence-driven process enables robust identification of indirect, multi-file, and non-trivial fixes that elude single-pass or similarity-based methods. We evaluate Favia on CVEVC, a large-scale dataset we made that comprises over 8 million commits from 3,708 real-world repositories, and show that it consistently outperforms state-of-the-art traditional and LLM-based baselines under realistic candidate selection, achieving the strongest precision-recall trade-offs and highest F1-scores.",
      "authors": [
        "André Storhaug",
        "Jiamou Sun",
        "Jingyue Li"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "published": "2026-02-13 00:51:22+00:00",
      "link": "https://arxiv.org/pdf/2602.12500v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12489v1",
      "title": "Insertion Network for Image Sequence Correspondence",
      "abstract": "We propose a novel method for establishing correspondence between two sequences of 2D images. One particular application of this technique is slice-level content navigation, where the goal is to localize specific 2D slices within a 3D volume or determine the anatomical coverage of a 3D scan based on its 2D slices. This serves as an important preprocessing step for various diagnostic tasks, as well as for automatic registration and segmentation pipelines. Our approach builds sequence correspondence by training a network to learn how to insert a slice from one sequence into the appropriate position in another. This is achieved by encoding contextual representations of each slice and modeling the insertion process using a slice-to-slice attention mechanism. We apply this method to localize manually labeled key slices in body CT scans and compare its performance to the current state-of-the-art alternative known as body part regression, which predicts anatomical position scores for individual slices. Unlike body part regression, which treats each slice independently, our method leverages contextual information from the entire sequence. Experimental results show that the insertion network reduces slice localization errors in supervised settings from 8.4 mm to 5.4 mm, demonstrating a substantial improvement in accuracy.",
      "authors": [
        "Dingjie Su",
        "Weixiang Hong",
        "Benoit M. Dawant",
        "Bennett A. Landman"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 00:04:54+00:00",
      "link": "https://arxiv.org/pdf/2602.12489v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12486v1",
      "title": "Human-Like Coarse Object Representations in Vision Models",
      "abstract": "Humans appear to represent objects for intuitive physics with coarse, volumetric bodies'' that smooth concavities - trading fine visual details for efficient physical predictions - yet their internal structure is largely unknown. Segmentation models, in contrast, optimize pixel-accurate masks that may misalign with such bodies. We ask whether and when these models nonetheless acquire human-like bodies. Using a time-to-collision (TTC) behavioral paradigm, we introduce a comparison pipeline and alignment metric, then vary model training time, size, and effective capacity via pruning. Across all manipulations, alignment with human behavior follows an inverse U-shaped curve: small/briefly trained/pruned models under-segment into blobs; large/fully trained models over-segment with boundary wiggles; and an intermediate ideal body granularity'' best matches humans. This suggests human-like coarse bodies emerge from resource constraints rather than bespoke biases, and points to simple knobs - early checkpoints, modest architectures, light pruning - for eliciting physics-efficient representations. We situate these results within resource-rational accounts balancing recognition detail against physical affordances.",
      "authors": [
        "Andrey Gizdov",
        "Andrea Procopio",
        "Yichen Li",
        "Daniel Harari",
        "Tomer Ullman"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-12 23:59:58+00:00",
      "link": "https://arxiv.org/pdf/2602.12486v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12469v1",
      "title": "Regularized Meta-Learning for Improved Generalization",
      "abstract": "Deep ensemble methods often improve predictive performance, yet they suffer from three practical limitations: redundancy among base models that inflates computational cost and degrades conditioning, unstable weighting under multicollinearity, and overfitting in meta-learning pipelines. We propose a regularized meta-learning framework that addresses these challenges through a four-stage pipeline combining redundancy-aware projection, statistical meta-feature augmentation, and cross-validated regularized meta-models (Ridge, Lasso, and ElasticNet). Our multi-metric de-duplication strategy removes near-collinear predictors using correlation and MSE thresholds ($τ_{\\text{corr}}=0.95$), reducing the effective condition number of the meta-design matrix while preserving predictive diversity. Engineered ensemble statistics and interaction terms recover higher-order structure unavailable to raw prediction columns. A final inverse-RMSE blending stage mitigates regularizer-selection variance. On the Playground Series S6E1 benchmark (100K samples, 72 base models), the proposed framework achieves an out-of-fold RMSE of 8.582, improving over simple averaging (8.894) and conventional Ridge stacking (8.627), while matching greedy hill climbing (8.603) with substantially lower runtime (4 times faster). Conditioning analysis shows a 53.7\\% reduction in effective matrix condition number after redundancy projection. Comprehensive ablations demonstrate consistent contributions from de-duplication, statistical meta-features, and meta-ensemble blending. These results position regularized meta-learning as a stable and deployment-efficient stacking strategy for high-dimensional ensemble systems.",
      "authors": [
        "Noor Islam S. Mohammad",
        "Md Muntaqim Meherab"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 22:55:32+00:00",
      "link": "https://arxiv.org/pdf/2602.12469v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12465v1",
      "title": "Probabilistic Design of Parametrized Quantum Circuits through Local Gate Modifications",
      "abstract": "Within quantum machine learning, parametrized quantum circuits provide flexible quantum models, but their performance is often highly task-dependent, making manual circuit design challenging. Alternatively, quantum architecture search algorithms have been proposed to automate the discovery of task-specific parametrized quantum circuits using systematic frameworks. In this work, we propose an evolution-inspired heuristic quantum architecture search algorithm, which we refer to as the local quantum architecture search. The goal of the local quantum architecture search algorithm is to optimize parametrized quantum circuit architectures through a local, probabilistic search over a fixed set of gate-level actions applied to existing circuits. We evaluate the local quantum architecture search algorithm on two synthetic function-fitting regression tasks and two quantum chemistry regression datasets, including the BSE49 dataset of bond separation energies for first- and second-row elements and a dataset of water conformers generated using the data-driven coupled-cluster approach. Using state-vector simulation, our results highlight the applicability of local quantum architecture search algorithm for identifying competitive circuit architectures with desirable performance metrics. Lastly, we analyze the properties of the discovered circuits and demonstrate the deployment of the best-performing model on state-of-the-art quantum hardware.",
      "authors": [
        "Grier M. Jones",
        "Aviraj Newatia",
        "Alexander Lao",
        "Aditya K. Rao",
        "Viki Kumar Prasad",
        "Hans-Arno Jacobsen"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "published": "2026-02-12 22:47:03+00:00",
      "link": "https://arxiv.org/pdf/2602.12465v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12458v1",
      "title": "Theory of Mind Guided Strategy Adaptation for Zero-Shot Coordination",
      "abstract": "A central challenge in multi-agent reinforcement learning is enabling agents to adapt to previously unseen teammates in a zero-shot fashion. Prior work in zero-shot coordination often follows a two-stage process, first generating a diverse training pool of partner agents, and then training a best-response agent to collaborate effectively with the entire training pool. While many previous works have achieved strong performance by devising better ways to diversify the partner agent pool, there has been less emphasis on how to leverage this pool to build an adaptive agent. One limitation is that the best-response agent may converge to a static, generalist policy that performs reasonably well across diverse teammates, rather than learning a more adaptive, specialist policy that can better adapt to teammates and achieve higher synergy. To address this, we propose an adaptive ensemble agent that uses Theory-of-Mind-based best-response selection to first infer its teammate's intentions and then select the most suitable policy from a policy ensemble. We conduct experiments in the Overcooked environment to evaluate zero-shot coordination performance under both fully and partially observable settings. The empirical results demonstrate the superiority of our method over a single best-response baseline.",
      "authors": [
        "Andrew Ni",
        "Simon Stepputtis",
        "Stefanos Nikolaidis",
        "Michael Lewis",
        "Katia P. Sycara",
        "Woojun Kim"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA"
      ],
      "published": "2026-02-12 22:29:10+00:00",
      "link": "https://arxiv.org/pdf/2602.12458v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12444v2",
      "title": "Safe Reinforcement Learning via Recovery-based Shielding with Gaussian Process Dynamics Models",
      "abstract": "Reinforcement learning (RL) is a powerful framework for optimal decision-making and control but often lacks provable guarantees for safety-critical applications. In this paper, we introduce a novel recovery-based shielding framework that enables safe RL with a provable safety lower bound for unknown and non-linear continuous dynamical systems. The proposed approach integrates a backup policy (shield) with the RL agent, leveraging Gaussian process (GP) based uncertainty quantification to predict potential violations of safety constraints, dynamically recovering to safe trajectories only when necessary. Experience gathered by the 'shielded' agent is used to construct the GP models, with policy optimization via internal model-based sampling - enabling unrestricted exploration and sample efficient learning, without compromising safety. Empirically our approach demonstrates strong performance and strict safety-compliance on a suite of continuous control environments.",
      "authors": [
        "Alexander W. Goodall",
        "Francesco Belardinelli"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-12 22:03:35+00:00",
      "link": "https://arxiv.org/pdf/2602.12444v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12438v1",
      "title": "Neural and numerical methods for $\\mathrm{G}_2$-structures on contact Calabi-Yau 7-manifolds",
      "abstract": "A numerical framework for approximating $\\mathrm{G}_2$-structure 3-forms on contact Calabi-Yau manifolds is presented. The approach proceeds in three stages: first, existing neural network models are employed to compute an approximate Ricci-flat metric on a Calabi-Yau threefold. Second, using this metric and the explicit construction of a $\\mathrm{G}_2$-structure on the associated 7-dimensional Calabi-Yau link in the 9-sphere, numerical approximations of the 3-form are generated on a large set of sampled points. Finally, a dedicated neural architecture is trained to learn the 3-form and its induced Riemannian metric directly from data, validating the learned structure and its torsion via a numerical implementation of the exterior derivative, which may be of independent interest.",
      "authors": [
        "Elli Heyes",
        "Edward Hirst",
        "Henrique N. Sá Earp",
        "Tomás S. R. Silva"
      ],
      "primary_category": "math.DG",
      "categories": [
        "math.DG",
        "cs.LG",
        "hep-th"
      ],
      "published": "2026-02-12 21:52:06+00:00",
      "link": "https://arxiv.org/pdf/2602.12438v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12436v1",
      "title": "Interpolation-Inspired Closure Certificates",
      "abstract": "Barrier certificates, a form of state invariants, provide an automated approach to the verification of the safety of dynamical systems. Similarly to barrier certificates, recent works explore the notion of closure certificates, a form of transition invariants, to verify dynamical systems against $ω$-regular properties including safety. A closure certificate, defined over state pairs of a dynamical system, is a real-valued function whose zero superlevel set characterizes an inductive transition invariant of the system. The search for such a certificate can be effectively automated by assuming it to be within a specific template class, e.g. a polynomial of a fixed degree, and then using optimization techniques such as sum-of-squares (SOS) programming to find it. Unfortunately, one may not be able to find such a certificate for a fixed template. In such a case, one must change the template, e.g. increase the degree of the polynomial. In this paper, we consider a notion of multiple closure certificates dubbed interpolation-inspired closure certificates. An interpolation-inspired closure certificate consists of a set of functions which jointly over-approximate a transition invariant by first considering one-step transitions, then two, and so on until a transition invariant is obtained. The advantage of interpolation-inspired closure certificates is that they allow us to prove properties even when a single function for a fixed template cannot be found using standard approaches. We present SOS programming and a scenario program to find these sets of functions and demonstrate the effectiveness of our proposed method to verify persistence and general $ω$-regular specifications in some case studies.",
      "authors": [
        "Mohammed Adib Oumer",
        "Vishnu Murali",
        "Majid Zamani"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.FL"
      ],
      "published": "2026-02-12 21:48:41+00:00",
      "link": "https://arxiv.org/pdf/2602.12436v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13348v1",
      "title": "Exploring the Performance of ML/DL Architectures on the MNIST-1D Dataset",
      "abstract": "Small datasets like MNIST have historically been instrumental in advancing machine learning research by providing a controlled environment for rapid experimentation and model evaluation. However, their simplicity often limits their utility for distinguishing between advanced neural network architectures. To address these challenges, Greydanus et al. introduced the MNIST-1D dataset, a one-dimensional adaptation of MNIST designed to explore inductive biases in sequential data. This dataset maintains the advantages of small-scale datasets while introducing variability and complexity that make it ideal for studying advanced architectures.   In this paper, we extend the exploration of MNIST-1D by evaluating the performance of Residual Networks (ResNet), Temporal Convolutional Networks (TCN), and Dilated Convolutional Neural Networks (DCNN). These models, known for their ability to capture sequential patterns and hierarchical features, were implemented and benchmarked alongside previously tested architectures such as logistic regression, MLPs, CNNs, and GRUs. Our experimental results demonstrate that advanced architectures like TCN and DCNN consistently outperform simpler models, achieving near-human performance on MNIST-1D. ResNet also shows significant improvements, highlighting the importance of leveraging inductive biases and hierarchical feature extraction in small structured datasets.   Through this study, we validate the utility of MNIST-1D as a robust benchmark for evaluating machine learning architectures under computational constraints. Our findings emphasize the role of architectural innovations in improving model performance and offer insights into optimizing deep learning models for resource-limited environments.",
      "authors": [
        "Michael Beebe",
        "GodsGift Uzor",
        "Manasa Chepuri",
        "Divya Sree Vemula",
        "Angel Ayala"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-12 21:31:20+00:00",
      "link": "https://arxiv.org/pdf/2602.13348v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12410v1",
      "title": "Conference Proceedings of the Inaugural Conference of the International Society for Tractography (IST 2025 Bordeaux)",
      "abstract": "This collection comprises the abstracts presented during poster, power pitch and oral sessions at the Inaugural Conference of the International Society for Tractography (IST Conference 2025), held in Bordeaux, France, from October 13-16, 2025. The conference was designed to foster meaningful exchange and collaboration between disparate fields. The overall focus was on advancing research, innovation, and community in the common fields of interest: neuroanatomy, tractography methods and scientific/clinical applications of tractography. The included abstracts cover the latest advancements in tractography, Diffusion MRI, and related fields including new work on; neurological and psychiatric disorders, deep brain stimulation targeting, and brain development. This landmark event brought together world-leading experts to discuss critical challenges and chart the future direction of the field.",
      "authors": [
        "Flavio Dell Acqua",
        "Maxime Descoteaux",
        "Graham Little",
        "Laurent Petit",
        "Dogu Baran Aydogan",
        "Stephanie Forkel",
        "Alexander Leemans",
        "Simona Schiavi",
        "Michel Thiebaut de Schotten"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV",
        "q-bio.NC"
      ],
      "published": "2026-02-12 21:07:41+00:00",
      "link": "https://arxiv.org/pdf/2602.12410v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12406v1",
      "title": "Eyes on Many: Evaluating Gaze, Hand, and Voice for Multi-Object Selection in Extended Reality",
      "abstract": "Interacting with multiple objects simultaneously makes us fast. A pre-step to this interaction is to select the objects, i.e., multi-object selection, which is enabled through two steps: (1) toggling multi-selection mode -- mode-switching -- and then (2) selecting all the intended objects -- subselection. In extended reality (XR), each step can be performed with the eyes, hands, and voice. To examine how design choices affect user performance, we evaluated four mode-switching (SemiPinch, FullPinch, DoublePinch, and Voice) and three subselection techniques (Gaze+Dwell, Gaze+Pinch, and Gaze+Voice) in a user study. Results revealed that while DoublePinch paired with Gaze+Pinch yielded the highest overall performance, SemiPinch achieved the lowest performance. Although Voice-based mode-switching showed benefits, Gaze+Voice subselection was less favored, as the required repetitive vocal commands were perceived as tedious. Overall, these findings provide empirical insights and inform design recommendations for multi-selection techniques in XR.",
      "authors": [
        "Mohammad Raihanul Bashar",
        "Aunnoy K Mutasim",
        "Ken Pfeuffer",
        "Anil Ufuk Batmaz"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-12 20:55:54+00:00",
      "link": "https://arxiv.org/pdf/2602.12406v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12402v1",
      "title": "AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning",
      "abstract": "Analog and mixed-signal (AMS) integrated circuits (ICs) lie at the core of modern computing and communications systems. However, despite the continued rise in design complexity, advances in AMS automation remain limited. This reflects the central challenge in developing a generalized optimization method applicable across diverse circuit design spaces, many of which are distinct, constrained, and non-differentiable. To address this, our work casts circuit design as a graph generation problem and introduces a novel method of AMS synthesis driven by deep reinforcement learning (AstRL). Based on a policy-gradient approach, AstRL generates circuits directly optimized for user-specified targets within a simulator-embedded environment that provides ground-truth feedback during training. Through behavioral-cloning and discriminator-based similarity rewards, our method demonstrates, for the first time, an expert-aligned paradigm for generalized circuit generation validated in simulation. Importantly, the proposed approach operates at the level of individual transistors, enabling highly expressive, fine-grained topology generation. Strong inductive biases encoded in the action space and environment further drive structurally consistent and valid generation. Experimental results for three realistic design tasks illustrate substantial improvements in conventional design metrics over state-of-the-art baselines, with 100% of generated designs being structurally correct and over 90% demonstrating required functionality.",
      "authors": [
        "Felicia B. Guo",
        "Ken T. Ho",
        "Andrei Vladimirescu",
        "Borivoje Nikolic"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-12 20:52:39+00:00",
      "link": "https://arxiv.org/pdf/2602.12402v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12395v1",
      "title": "What does RL improve for Visual Reasoning? A Frankenstein-Style Analysis",
      "abstract": "Reinforcement learning (RL) with verifiable rewards has become a standard post-training stage for boosting visual reasoning in vision-language models, yet it remains unclear what capabilities RL actually improves compared with supervised fine-tuning as cold-start initialization (IN). End-to-end benchmark gains conflate multiple factors, making it difficult to attribute improvements to specific skills. To bridge the gap, we propose a Frankenstein-style analysis framework including: (i) functional localization via causal probing; (ii) update characterization via parameter comparison; and (iii) transferability test via model merging. Instead, RL induces a consistent inference-time shift primarily in mid-to-late layers, and these mid-to-late refinements are both transferable (via merging) and necessary (via freezing) for RL gains. Overall, our results suggest that RL's reliable contribution in visual reasoning is not a uniform enhancement of visual perception, but a systematic refinement of mid-to-late transformer computation that improves vision-to-reasoning alignment and reasoning performance, highlighting the limitations of benchmark-only evaluation for understanding multimodal reasoning improvements.",
      "authors": [
        "Xirui Li",
        "Ming Li",
        "Tianyi Zhou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-12 20:44:27+00:00",
      "link": "https://arxiv.org/pdf/2602.12395v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12390v1",
      "title": "Rational Neural Networks have Expressivity Advantages",
      "abstract": "We study neural networks with trainable low-degree rational activation functions and show that they are more expressive and parameter-efficient than modern piecewise-linear and smooth activations such as ELU, LeakyReLU, LogSigmoid, PReLU, ReLU, SELU, CELU, Sigmoid, SiLU, Mish, Softplus, Tanh, Softmin, Softmax, and LogSoftmax. For an error target of $\\varepsilon>0$, we establish approximation-theoretic separations: Any network built from standard fixed activations can be uniformly approximated on compact domains by a rational-activation network with only $\\mathrm{poly}(\\log\\log(1/\\varepsilon))$ overhead in size, while the converse provably requires $Ω(\\log(1/\\varepsilon))$ parameters in the worst case. This exponential gap persists at the level of full networks and extends to gated activations and transformer-style nonlinearities. In practice, rational activations integrate seamlessly into standard architectures and training pipelines, allowing rationals to match or outperform fixed activations under identical architectures and optimizers.",
      "authors": [
        "Maosen Tang",
        "Alex Townsend"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.NA"
      ],
      "published": "2026-02-12 20:33:42+00:00",
      "link": "https://arxiv.org/pdf/2602.12390v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12389v1",
      "title": "Evolving Beyond Snapshots: Harmonizing Structure and Sequence via Entity State Tuning for Temporal Knowledge Graph Forecasting",
      "abstract": "Temporal knowledge graph (TKG) forecasting requires predicting future facts by jointly modeling structural dependencies within each snapshot and temporal evolution across snapshots. However, most existing methods are stateless: they recompute entity representations at each timestamp from a limited query window, leading to episodic amnesia and rapid decay of long-term dependencies. To address this limitation, we propose Entity State Tuning (EST), an encoder-agnostic framework that endows TKG forecasters with persistent and continuously evolving entity states. EST maintains a global state buffer and progressively aligns structural evidence with sequential signals via a closed-loop design. Specifically, a topology-aware state perceiver first injects entity-state priors into structural encoding. Then, a unified temporal context module aggregates the state-enhanced events with a pluggable sequence backbone. Subsequently, a dual-track evolution mechanism writes the updated context back to the global entity state memory, balancing plasticity against stability. Experiments on multiple benchmarks show that EST consistently improves diverse backbones and achieves state-of-the-art performance, highlighting the importance of state persistence for long-horizon TKG forecasting. The code is published at https://github.com/yuanwuyuan9/Evolving-Beyond-Snapshots",
      "authors": [
        "Siyuan Li",
        "Yunjia Wu",
        "Yiyong Xiao",
        "Pingyang Huang",
        "Peize Li",
        "Ruitong Liu",
        "Yan Wen",
        "Te Sun",
        "Fangyi Pei"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-12 20:33:35+00:00",
      "link": "https://arxiv.org/pdf/2602.12389v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12386v1",
      "title": "Provably Convergent Actor-Critic in Risk-averse MARL",
      "abstract": "Learning stationary policies in infinite-horizon general-sum Markov games (MGs) remains a fundamental open problem in Multi-Agent Reinforcement Learning (MARL). While stationary strategies are preferred for their practicality, computing stationary forms of classic game-theoretic equilibria is computationally intractable -- a stark contrast to the comparative ease of solving single-agent RL or zero-sum games. To bridge this gap, we study Risk-averse Quantal response Equilibria (RQE), a solution concept rooted in behavioral game theory that incorporates risk aversion and bounded rationality. We demonstrate that RQE possesses strong regularity conditions that make it uniquely amenable to learning in MGs. We propose a novel two-timescale Actor-Critic algorithm characterized by a fast-timescale actor and a slow-timescale critic. Leveraging the regularity of RQE, we prove that this approach achieves global convergence with finite-sample guarantees. We empirically validate our algorithm in several environments to demonstrate superior convergence properties compared to risk-neutral baselines.",
      "authors": [
        "Yizhou Zhang",
        "Eric Mazumdar"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.GT",
        "cs.LG"
      ],
      "published": "2026-02-12 20:29:41+00:00",
      "link": "https://arxiv.org/pdf/2602.12386v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12385v1",
      "title": "Zero-Shot Adaptation to Robot Structural Damage via Natural Language-Informed Kinodynamics Modeling",
      "abstract": "High-performance autonomous mobile robots endure significant mechanical stress during in-the-wild operations, e.g., driving at high speeds or over rugged terrain. Although these platforms are engineered to withstand such conditions, mechanical degradation is inevitable. Structural damage manifests as consistent and notable changes in kinodynamic behavior compared to a healthy vehicle. Given the heterogeneous nature of structural failures, quantifying various damages to inform kinodynamics is challenging. We posit that natural language can describe and thus capture this variety of damages. Therefore, we propose Zero-shot Language Informed Kinodynamics (ZLIK), which employs self-supervised learning to ground semantic information of damage descriptions in kinodynamic behaviors to learn a forward kinodynamics model in a data-driven manner. Using the high-fidelity soft-body physics simulator BeamNG.tech, we collect data from a variety of structurally compromised vehicles. Our learned model achieves zero-shot adaptation to different damages with up to 81% reduction in kinodynamics error and generalizes across the sim-to-real and full-to-1/10$^{\\text{th}}$ scale gaps.",
      "authors": [
        "Anuj Pokhrel",
        "Aniket Datar",
        "Mohammad Nazeri",
        "Francesco Cancelliere",
        "Xuesu Xiao"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-12 20:28:45+00:00",
      "link": "https://arxiv.org/pdf/2602.12385v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12380v1",
      "title": "TFT-ACB-XML: Decision-Level Integration of Customized Temporal Fusion Transformer and Attention-BiLSTM with XGBoost Meta-Learner for BTC Price Forecasting",
      "abstract": "Accurate forecasting of Bitcoin (BTC) has always been a challenge because decentralized markets are non-linear, highly volatile, and have temporal irregularities. Existing deep learning models often struggle with interpretability and generalization across diverse market conditions. This research presents a hybrid stacked-generalization framework, TFT-ACB-XML, for BTC closing price prediction. The framework integrates two parallel base learners: a customized Temporal Fusion Transformer (TFT) and an Attention-Customized Bidirectional Long Short-Term Memory network (ACB), followed by an XGBoost regressor as the meta-learner. The customized TFT model handles long-range dependencies and global temporal dynamics via variable selection networks and interpretable single-head attention. The ACB module uses a new attention mechanism alongside the customized BiLSTM to capture short-term sequential dependencies. Predictions from both customized TFT and ACB are weighted through an error-reciprocal weighting strategy. These weights are derived from validation performance, where a model showing lower prediction error receives a higher weight. Finally, the framework concatenates these weighted outputs into a feature vector and feeds the vector to an XGBoost regressor, which captures non-linear residuals and produces the final BTC closing price prediction. Empirical validation using BTC data from October 1, 2014, to January 5, 2026, shows improved performance of the proposed framework compared to recent Deep Learning and Transformer baseline models. The results show a MAPE of 0.65%, an MAE of 198.15, and an RMSE of 258.30 for one-step-ahead out-of-sample under a walk-forward evaluation on the test block. The evaluation period spans the 2024 BTC halving and the spot ETFs (exchange-traded funds) period, which coincide with major liquidity and volatility shifts.",
      "authors": [
        "Raiz Ud Din",
        "Saddam Hussain Khan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-12 20:20:56+00:00",
      "link": "https://arxiv.org/pdf/2602.12380v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12379v1",
      "title": "Deep Doubly Debiased Longitudinal Effect Estimation with ICE G-Computation",
      "abstract": "Estimating longitudinal treatment effects is essential for sequential decision-making but is challenging due to treatment-confounder feedback. While Iterative Conditional Expectation (ICE) G-computation offers a principled approach, its recursive structure suffers from error propagation, corrupting the learned outcome regression models. We propose D3-Net, a framework that mitigates error propagation in ICE training and then applies a robust final correction. First, to interrupt error propagation during learning, we train the ICE sequence using Sequential Doubly Robust (SDR) pseudo-outcomes, which provide bias-corrected targets for each regression. Second, we employ a multi-task Transformer with a covariate simulator head for auxiliary supervision, regularizing representations against corruption by noisy pseudo-outcomes, and a target network to stabilize training dynamics. For the final estimate, we discard the SDR correction and instead use the uncorrected nuisance models to perform Longitudinal Targeted Minimum Loss-Based Estimation (LTMLE) on the original outcomes. This second-stage, targeted debiasing ensures robustness and optimal finite-sample properties. Comprehensive experiments demonstrate that our model, D3-Net, robustly reduces bias and variance across different horizons, counterfactuals, and time-varying confoundings, compared to existing state-of-the-art ICE-based estimators.",
      "authors": [
        "Wenxin Chen",
        "Weishen Pan",
        "Kyra Gan",
        "Fei Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 20:16:27+00:00",
      "link": "https://arxiv.org/pdf/2602.12379v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12375v1",
      "title": "Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning",
      "abstract": "Optimistic value estimates provide one mechanism for directed exploration in reinforcement learning (RL). The agent acts greedily with respect to an estimate of the value plus what can be seen as a value bonus. The value bonus can be learned by estimating a value function on reward bonuses, propagating local uncertainties around rewards. However, this approach only increases the value bonus for an action retroactively, after seeing a higher reward bonus from that state and action. Such an approach does not encourage the agent to visit a state and action for the first time. In this work, we introduce an algorithm for exploration called Value Bonuses with Ensemble errors (VBE), that maintains an ensemble of random action-value functions (RQFs). VBE uses the errors in the estimation of these RQFs to design value bonuses that provide first-visit optimism and deep exploration. The key idea is to design the rewards for these RQFs in such a way that the value bonus can decrease to zero. We show that VBE outperforms Bootstrap DQN and two reward bonus approaches (RND and ACB) on several classic environments used to test exploration and provide demonstrative experiments that it can scale easily to more complex environments like Atari.",
      "authors": [
        "Abdul Wahab",
        "Raksha Kumaraswamy",
        "Martha White"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-12 20:12:17+00:00",
      "link": "https://arxiv.org/pdf/2602.12375v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12370v1",
      "title": "LLaMo: Scaling Pretrained Language Models for Unified Motion Understanding and Generation with Continuous Autoregressive Tokens",
      "abstract": "Recent progress in large models has led to significant advances in unified multimodal generation and understanding. However, the development of models that unify motion-language generation and understanding remains largely underexplored. Existing approaches often fine-tune large language models (LLMs) on paired motion-text data, which can result in catastrophic forgetting of linguistic capabilities due to the limited scale of available text-motion pairs. Furthermore, prior methods typically convert motion into discrete representations via quantization to integrate with language models, introducing substantial jitter artifacts from discrete tokenization. To address these challenges, we propose LLaMo, a unified framework that extends pretrained LLMs through a modality-specific Mixture-of-Transformers (MoT) architecture. This design inherently preserves the language understanding of the base model while enabling scalable multimodal adaptation. We encode human motion into a causal continuous latent space and maintain the next-token prediction paradigm in the decoder-only backbone through a lightweight flow-matching head, allowing for streaming motion generation in real-time (>30 FPS). Leveraging the comprehensive language understanding of pretrained LLMs and large-scale motion-text pretraining, our experiments demonstrate that LLaMo achieves high-fidelity text-to-motion generation and motion-to-text captioning in general settings, especially zero-shot motion generation, marking a significant step towards a general unified motion-language large model.",
      "authors": [
        "Zekun Li",
        "Sizhe An",
        "Chengcheng Tang",
        "Chuan Guo",
        "Ivan Shugurov",
        "Linguang Zhang",
        "Amy Zhao",
        "Srinath Sridhar",
        "Lingling Tao",
        "Abhay Mittal"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 20:02:21+00:00",
      "link": "https://arxiv.org/pdf/2602.12370v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12368v1",
      "title": "A Machine Learning Approach to the Nirenberg Problem",
      "abstract": "This work introduces the Nirenberg Neural Network: a numerical approach to the Nirenberg problem of prescribing Gaussian curvature on $S^2$ for metrics that are pointwise conformal to the round metric. Our mesh-free physics-informed neural network (PINN) approach directly parametrises the conformal factor globally and is trained with a geometry-aware loss enforcing the curvature equation. Additional consistency checks were performed via the Gauss-Bonnet theorem, and spherical-harmonic expansions were fit to the learnt models to provide interpretability.   For prescribed curvatures with known realisability, the neural network achieves very low losses ($10^{-7} - 10^{-10}$), while unrealisable curvatures yield significantly higher losses. This distinction enables the assessment of unknown cases, separating likely realisable functions from non-realisable ones. The current capabilities of the Nirenberg Neural Network demonstrate that neural solvers can serve as exploratory tools in geometric analysis, offering a quantitative computational perspective on longstanding existence questions.",
      "authors": [
        "Gianfranco Cortés",
        "Maria Esteban-Casadevall",
        "Yueqing Feng",
        "Jonas Henkel",
        "Edward Hirst",
        "Tancredi Schettini Gherardini",
        "Alexander G. Stapleton"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "hep-th",
        "math.AP",
        "math.DG"
      ],
      "published": "2026-02-12 19:58:11+00:00",
      "link": "https://arxiv.org/pdf/2602.12368v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12361v1",
      "title": "Thermal Imaging for Contactless Cardiorespiratory and Sudomotor Response Monitoring",
      "abstract": "Thermal infrared imaging captures skin temperature changes driven by autonomic regulation and can potentially provide contactless estimation of electrodermal activity (EDA), heart rate (HR), and breathing rate (BR). While visible-light methods address HR and BR, they cannot access EDA, a standard marker of sympathetic activation. This paper characterizes the extraction of these three biosignals from facial thermal video using a signal-processing pipeline that tracks anatomical regions, applies spatial aggregation, and separates slow sudomotor trends from faster cardiorespiratory components. For HR, we apply an orthogonal matrix image transformation (OMIT) decomposition across multiple facial regions of interest (ROIs), and for BR we average nasal and cheek signals before spectral peak detection. We evaluate 288 EDA configurations and the HR/BR pipeline on 31 sessions from the public SIMULATOR STUDY 1 (SIM1) driver monitoring dataset. The best fixed EDA configuration (nose region, exponential moving average) reaches a mean absolute correlation of $0.40 \\pm 0.23$ against palm EDA, with individual sessions reaching 0.89. BR estimation achieves a mean absolute error of $3.1 \\pm 1.1$ bpm, while HR estimation yields $13.8 \\pm 7.5$ bpm MAE, limited by the low camera frame rate (7.5 Hz). We report signal polarity alternation across sessions, short thermodynamic latency for well-tracked signals, and condition-dependent and demographic effects on extraction quality. These results provide baseline performance bounds and design guidance for thermal contactless biosignal estimation.",
      "authors": [
        "Constantino Álvarez Casado",
        "Mohammad Rahman",
        "Sasan Sharifipour",
        "Nhi Nguyen",
        "Manuel Lage Cañellas",
        "Xiaoting Wu",
        "Miguel Bordallo López"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 19:41:18+00:00",
      "link": "https://arxiv.org/pdf/2602.12361v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12360v1",
      "title": "Predicting Dynamic Map States from Limited Field-of-View Sensor Data",
      "abstract": "When autonomous systems are deployed in real-world scenarios, sensors are often subject to limited field-of-view (FOV) constraints, either naturally through system design, or through unexpected occlusions or sensor failures. In conditions where a large FOV is unavailable, it is important to be able to infer information about the environment and predict the state of nearby surroundings based on available data to maintain safe and accurate operation. In this work, we explore the effectiveness of deep learning for dynamic map state prediction based on limited FOV time series data. We show that by representing dynamic sensor data in a simple single-image format that captures both spatial and temporal information, we can effectively use a wide variety of existing image-to-image learning models to predict map states with high accuracy in a diverse set of sensing scenarios.",
      "authors": [
        "Knut Peterson",
        "David Han"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-12 19:36:49+00:00",
      "link": "https://arxiv.org/pdf/2602.12360v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12338v1",
      "title": "Wireless TokenCom: RL-Based Tokenizer Agreement for Multi-User Wireless Token Communications",
      "abstract": "Token Communications (TokenCom) has recently emerged as an effective new paradigm, where tokens are the unified units of multimodal communications and computations, enabling efficient digital semantic- and goal-oriented communications in future wireless networks. To establish a shared semantic latent space, the transmitters/receivers in TokenCom need to agree on an identical tokenizer model and codebook. To this end, an initial Tokenizer Agreement (TA) process is carried out in each communication episode, where the transmitter/receiver cooperate to choose from a set of pre-trained tokenizer models/ codebooks available to them both for efficient TokenCom. In this correspondence, we investigate TA in a multi-user downlink wireless TokenCom scenario, where the base station equipped with multiple antennas transmits video token streams to multiple users. We formulate the corresponding mixed-integer non-convex problem, and propose a hybrid reinforcement learning (RL) framework that integrates a deep Q-network (DQN) for joint tokenizer agreement and sub-channel assignment, with a deep deterministic policy gradient (DDPG) for beamforming. Simulation results show that the proposed framework outperforms baseline methods in terms of semantic quality and resource efficiency, while reducing the freezing events in video transmission by 68% compared to the conventional H.265-based scheme.",
      "authors": [
        "Farshad Zeinali",
        "Mahdi Boloursaz Mashhadi",
        "Dusit Niyato",
        "Rahim Tafazolli"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 19:00:33+00:00",
      "link": "https://arxiv.org/pdf/2602.12338v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12273v1",
      "title": "Learning to Control: The iUzawa-Net for Nonsmooth Optimal Control of Linear PDEs",
      "abstract": "We propose an optimization-informed deep neural network approach, named iUzawa-Net, aiming for the first solver that enables real-time solutions for a class of nonsmooth optimal control problems of linear partial differential equations (PDEs). The iUzawa-Net unrolls an inexact Uzawa method for saddle point problems, replacing classical preconditioners and PDE solvers with specifically designed learnable neural networks. We prove universal approximation properties and establish the asymptotic $\\varepsilon$-optimality for the iUzawa-Net, and validate its promising numerical efficiency through nonsmooth elliptic and parabolic optimal control problems. Our techniques offer a versatile framework for designing and analyzing various optimization-informed deep learning approaches to optimal control and other PDE-constrained optimization problems. The proposed learning-to-control approach synergizes model-based optimization algorithms and data-driven deep learning techniques, inheriting the merits of both methodologies.",
      "authors": [
        "Yongcun Song",
        "Xiaoming Yuan",
        "Hangrui Yue",
        "Tianyou Zeng"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG",
        "math.NA"
      ],
      "published": "2026-02-12 18:57:43+00:00",
      "link": "https://arxiv.org/pdf/2602.12273v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12268v1",
      "title": "CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use",
      "abstract": "AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2, an RL framework that replaces verifiable outcome rewards with checklist rewards. CM2 decomposes each turn's intended behavior into fine-grained binary criteria with explicit evidence grounding and structured metadata, turning open-ended judging into more stable classification-style decisions. To balance stability and informativeness, our method adopts a strategy of sparse reward assignment but dense evaluation criteria. Training is performed in a scalable LLM-simulated tool environment, avoiding heavy engineering for large tool sets. Experiments show that CM2 consistently improves over supervised fine-tuning. Starting from an 8B Base model and training on an 8k-example RL dataset, CM2 improves over the SFT counterpart by 8 points on tau^-Bench, by 10 points on BFCL-V4, and by 12 points on ToolSandbox. The results match or even outperform similarly sized open-source baselines, including the judging model. CM2 thus provides a scalable recipe for optimizing multi-turn, multi-step tool-using agents without relying on verifiable rewards. Code provided by the open-source community: https://github.com/namezhenzhang/CM2-RLCR-Tool-Agent.",
      "authors": [
        "Zhen Zhang",
        "Kaiqiang Song",
        "Xun Wang",
        "Yebowen Hu",
        "Weixiang Yan",
        "Chenyang Zhao",
        "Henry Peng Zou",
        "Haoyun Deng",
        "Sathish Reddy Indurthi",
        "Shujian Liu",
        "Simin Ma",
        "Xiaoyang Wang",
        "Xin Eric Wang",
        "Song Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12 18:55:09+00:00",
      "link": "https://arxiv.org/pdf/2602.12268v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12267v1",
      "title": "Self-Supervised Learning via Flow-Guided Neural Operator on Time-Series Data",
      "abstract": "Self-supervised learning (SSL) is a powerful paradigm for learning from unlabeled time-series data. However, popular methods such as masked autoencoders (MAEs) rely on reconstructing inputs from a fixed, predetermined masking ratio. Instead of this static design, we propose treating the corruption level as a new degree of freedom for representation learning, enhancing flexibility and performance. To achieve this, we introduce the Flow-Guided Neural Operator (FGNO), a novel framework combining operator learning with flow matching for SSL training. FGNO learns mappings in functional spaces by using Short-Time Fourier Transform to unify different time resolutions. We extract a rich hierarchy of features by tapping into different network layers and flow times that apply varying strengths of noise to the input data. This enables the extraction of versatile representations, from low-level patterns to high-level global features, using a single model adaptable to specific tasks. Unlike prior generative SSL methods that use noisy inputs during inference, we propose using clean inputs for representation extraction while learning representations with noise; this eliminates randomness and boosts accuracy. We evaluate FGNO across three biomedical domains, where it consistently outperforms established baselines. Our method yields up to 35% AUROC gains in neural signal decoding (BrainTreeBank), 16% RMSE reductions in skin temperature prediction (DREAMT), and over 20% improvement in accuracy and macro-F1 on SleepEDF under low-data regimes. These results highlight FGNO's robustness to data scarcity and its superior capacity to learn expressive representations for diverse time series.",
      "authors": [
        "Duy Nguyen",
        "Jiachen Yao",
        "Jiayun Wang",
        "Julius Berner",
        "Animashree Anandkumar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 18:54:57+00:00",
      "link": "https://arxiv.org/pdf/2602.12267v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12259v1",
      "title": "Think like a Scientist: Physics-guided LLM Agent for Equation Discovery",
      "abstract": "Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.",
      "authors": [
        "Jianke Yang",
        "Ohm Venkatachalam",
        "Mohammad Kianezhad",
        "Sharvaree Vadgama",
        "Rose Yu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-12 18:49:27+00:00",
      "link": "https://arxiv.org/pdf/2602.12259v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12257v1",
      "title": "On the implicit regularization of Langevin dynamics with projected noise",
      "abstract": "We study Langevin dynamics with noise projected onto the directions orthogonal to an isometric group action. This mathematical model is introduced to shed new light on the effects of symmetry on stochastic gradient descent for over-parametrized models. Our main result identifies a novel form of implicit regularization: when the initial and target density are both invariant under the group action, Langevin dynamics with projected noise is equivalent in law to Langevin dynamics with isotropic diffusion but with an additional drift term proportional to the negative log volume of the group orbit. We prove this result by constructing a coupling of the two processes via a third process on the group itself, and identify the additional drift as the mean curvature of the orbits.",
      "authors": [
        "Govind Menon",
        "Austin J. Stromme",
        "Adrien Vacher"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "cs.AI"
      ],
      "published": "2026-02-12 18:45:42+00:00",
      "link": "https://arxiv.org/pdf/2602.12257v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12247v2",
      "title": "ExtractBench: A Benchmark and Evaluation Methodology for Complex Structured Extraction",
      "abstract": "Unstructured documents like PDFs contain valuable structured information, but downstream systems require this data in reliable, standardized formats. LLMs are increasingly deployed to automate this extraction, making accuracy and reliability paramount. However, progress is bottlenecked by two gaps. First, no end-to-end benchmark evaluates PDF-to-JSON extraction under enterprise-scale schema breadth. Second, no principled methodology captures the semantics of nested extraction, where fields demand different notions of correctness (exact match for identifiers, tolerance for quantities, semantic equivalence for names), arrays require alignment, and omission must be distinguished from hallucination. We address both gaps with ExtractBench, an open-source benchmark and evaluation framework for PDF-to-JSON structured extraction. The benchmark pairs 35 PDF documents with JSON Schemas and human-annotated gold labels across economically valuable domains, yielding 12,867 evaluatable fields spanning schema complexities from tens to hundreds of fields. The evaluation framework treats the schema as an executable specification: each field declares its scoring metric. Baseline evaluations reveal that frontier models (GPT-5/5.2, Gemini-3 Flash/Pro, Claude 4.5 Opus/Sonnet) remain unreliable on realistic schemas. Performance degrades sharply with schema breadth, culminating in 0% valid output on a 369-field financial reporting schema across all tested models. We release ExtractBench at https://github.com/ContextualAI/extract-bench.",
      "authors": [
        "Nick Ferguson",
        "Josh Pennington",
        "Narek Beghian",
        "Aravind Mohan",
        "Douwe Kiela",
        "Sheshansh Agrawal",
        "Thien Hang Nguyen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-12 18:31:37+00:00",
      "link": "https://arxiv.org/pdf/2602.12247v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12244v1",
      "title": "Any House Any Task: Scalable Long-Horizon Planning for Abstract Human Tasks",
      "abstract": "Open world language conditioned task planning is crucial for robots operating in large-scale household environments. While many recent works attempt to address this problem using Large Language Models (LLMs) via prompting or training, a key challenge remains scalability. Performance often degrades rapidly with increasing environment size, plan length, instruction ambiguity, and constraint complexity. In this work, we propose Any House Any Task (AHAT), a household task planner optimized for long-horizon planning in large environments given ambiguous human instructions. At its core, AHAT utilizes an LLM trained to map task instructions and textual scene graphs into grounded subgoals defined in the Planning Domain Definition Language (PDDL). These subgoals are subsequently solved to generate feasible and optimal long-horizon plans through explicit symbolic reasoning. To enhance the model's ability to decompose complex and ambiguous intentions, we introduce TGPO, a novel reinforcement learning algorithm that integrates external correction of intermediate reasoning traces into Group Relative Policy Optimization (GRPO). Experiments demonstrate that AHAT achieves significant performance gains over state-of-the-art prompting, planning, and learning methods, particularly in human-style household tasks characterized by brief instructions but requiring complex execution plans.",
      "authors": [
        "Zhihong Liu",
        "Yang Li",
        "Rengming Huang",
        "Cewu Lu",
        "Panpan Cai"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-12 18:28:28+00:00",
      "link": "https://arxiv.org/pdf/2602.12244v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12242v2",
      "title": "MagneX: A High-Performance, GPU-Enabled, Data-Driven Micromagnetics Solver for Spintronics",
      "abstract": "In order to comprehensively investigate the multiphysics coupling in spintronic devices, it is essential to parallelize and utilize GPU-acceleration to address the spatial and temporal disparities inherent in the relevant physics. Additionally, the use of cutting-edge time integration libraries as well as machine learning (ML) approaches to replace and potentially accelerate expensive computational routines are attractive capabilities to enhance modeling capabilities moving forward. Leveraging the Exascale Computing Project software framework AMReX, as well as SUNDIALS time-integration libraries and python-based ML workflows, we have developed an open-source micromagnetics modeling tool called MagneX. This tool incorporates various crucial magnetic coupling mechanisms, including Zeeman coupling, demagnetization coupling, crystalline anisotropy interaction, exchange coupling, and Dzyaloshinskii-Moriya interaction (DMI) coupling. We demonstrate the GPU performance and scalability of the code and rigorously validate MagneX's functionality using the mumag standard problems and widely-accepted DMI benchmarks. Furthermore, we demonstrate the data-driven capability of MagneX by replacing the computationally-expensive demagnetization physics with neural network libraries trained from our simulation data. With the capacity to explore complete physical interactions, this innovative approach offers a promising pathway to better understand and develop fully integrated spintronic and electronic systems.",
      "authors": [
        "Andy Nonaka",
        "Yingheng Tang",
        "Julian C. LePelch",
        "Prabhat Kumar",
        "Weiqun Zhang",
        "Jorge A. Munoz",
        "Christian Fernandez-Soria",
        "Cesar Diaz",
        "David J. Gardner",
        "Zhi Jackie Yao"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE",
        "cond-mat.other"
      ],
      "published": "2026-02-12 18:27:01+00:00",
      "link": "https://arxiv.org/pdf/2602.12242v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12236v1",
      "title": "Energy-Aware Spike Budgeting for Continual Learning in Spiking Neural Networks for Neuromorphic Vision",
      "abstract": "Neuromorphic vision systems based on spiking neural networks (SNNs) offer ultra-low-power perception for event-based and frame-based cameras, yet catastrophic forgetting remains a critical barrier to deployment in continually evolving environments. Existing continual learning methods, developed primarily for artificial neural networks, seldom jointly optimize accuracy and energy efficiency, with particularly limited exploration on event-based datasets. We propose an energy-aware spike budgeting framework for continual SNN learning that integrates experience replay, learnable leaky integrate-and-fire neuron parameters, and an adaptive spike scheduler to enforce dataset-specific energy constraints during training. Our approach exhibits modality-dependent behavior: on frame-based datasets (MNIST, CIFAR-10), spike budgeting acts as a sparsity-inducing regularizer, improving accuracy while reducing spike rates by up to 47\\%; on event-based datasets (DVS-Gesture, N-MNIST, CIFAR-10-DVS), controlled budget relaxation enables accuracy gains up to 17.45 percentage points with minimal computational overhead. Across five benchmarks spanning both modalities, our method demonstrates consistent performance improvements while minimizing dynamic power consumption, advancing the practical viability of continual learning in neuromorphic vision systems.",
      "authors": [
        "Anika Tabassum Meem",
        "Muntasir Hossain Nadid",
        "Md Zesun Ahmed Mia"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-12 18:15:32+00:00",
      "link": "https://arxiv.org/pdf/2602.12236v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12233v1",
      "title": "Categorical Flow Maps",
      "abstract": "We introduce Categorical Flow Maps, a flow-matching method for accelerated few-step generation of categorical data via self-distillation. Building on recent variational formulations of flow matching and the broader trend towards accelerated inference in diffusion and flow-based models, we define a flow map towards the simplex that transports probability mass toward a predicted endpoint, yielding a parametrisation that naturally constrains model predictions. Since our trajectories are continuous rather than discrete, Categorical Flow Maps can be trained with existing distillation techniques, as well as a new objective based on endpoint consistency. This continuous formulation also automatically unlocks test-time inference: we can directly reuse existing guidance and reweighting techniques in the categorical setting to steer sampling toward downstream objectives. Empirically, we achieve state-of-the-art few-step results on images, molecular graphs, and text, with strong performance even in single-step generation.",
      "authors": [
        "Daan Roos",
        "Oscar Davis",
        "Floor Eijkelboom",
        "Michael Bronstein",
        "Max Welling",
        "İsmail İlkan Ceylan",
        "Luca Ambrogioni",
        "Jan-Willem van de Meent"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 18:10:46+00:00",
      "link": "https://arxiv.org/pdf/2602.12233v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12218v1",
      "title": "The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics",
      "abstract": "Determining whether neural models internalize physical laws as world models, rather than exploiting statistical shortcuts, remains challenging, especially under out-of-distribution (OOD) shifts. Standard evaluations often test latent capability via downstream adaptation (e.g., fine-tuning or high-capacity probes), but such interventions can change the representations being measured and thus confound what was learned during self-supervised learning (SSL). We propose a non-invasive evaluation protocol, PhyIP. We test whether physical quantities are linearly decodable from frozen representations, motivated by the linear representation hypothesis. Across fluid dynamics and orbital mechanics, we find that when SSL achieves low error, latent structure becomes linearly accessible. PhyIP recovers internal energy and Newtonian inverse-square scaling on OOD tests (e.g., $ρ> 0.90$). In contrast, adaptation-based evaluations can collapse this structure ($ρ\\approx 0.05$). These findings suggest that adaptation-based evaluation can obscure latent structures and that low-capacity probes offer a more accurate evaluation of physical world models.",
      "authors": [
        "Christian Internò",
        "Jumpei Yamaguchi",
        "Loren Amdahl-Culleton",
        "Markus Olhofer",
        "David Klindt",
        "Barbara Hammer"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-12 17:56:07+00:00",
      "link": "https://arxiv.org/pdf/2602.12218v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12215v1",
      "title": "LDA-1B: Scaling Latent Dynamics Action Model via Universal Embodied Data Ingestion",
      "abstract": "Recent robot foundation models largely rely on large-scale behavior cloning, which imitates expert actions but discards transferable dynamics knowledge embedded in heterogeneous embodied data. While the Unified World Model (UWM) formulation has the potential to leverage such diverse data, existing instantiations struggle to scale to foundation-level due to coarse data usage and fragmented datasets. We introduce LDA-1B, a robot foundation model that scales through universal embodied data ingestion by jointly learning dynamics, policy, and visual forecasting, assigning distinct roles to data of varying quality. To support this regime at scale, we assemble and standardize EI-30k, an embodied interaction dataset comprising over 30k hours of human and robot trajectories in a unified format. Scalable dynamics learning over such heterogeneous data is enabled by prediction in a structured DINO latent space, which avoids redundant pixel-space appearance modeling. Complementing this representation, LDA-1B employs a multi-modal diffusion transformer to handle asynchronous vision and action streams, enabling stable training at the 1B-parameter scale. Experiments in simulation and the real world show LDA-1B outperforms prior methods (e.g., $π_{0.5}$) by up to 21\\%, 48\\%, and 23\\% on contact-rich, dexterous, and long-horizon tasks, respectively. Notably, LDA-1B enables data-efficient fine-tuning, gaining 10\\% by leveraging 30\\% low-quality trajectories typically harmful and discarded.",
      "authors": [
        "Jiangran Lyu",
        "Kai Liu",
        "Xuheng Zhang",
        "Haoran Liao",
        "Yusen Feng",
        "Wenxuan Zhu",
        "Tingrui Shen",
        "Jiayi Chen",
        "Jiazhao Zhang",
        "Yifei Dong",
        "Wenbo Cui",
        "Senmao Qi",
        "Shuo Wang",
        "Yixin Zheng",
        "Mi Yan",
        "Xuesong Shi",
        "Haoran Li",
        "Dongbin Zhao",
        "Ming-Yu Liu",
        "Zhizheng Zhang",
        "Li Yi",
        "Yizhou Wang",
        "He Wang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-12 17:53:51+00:00",
      "link": "https://arxiv.org/pdf/2602.12215v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13344v1",
      "title": "FireRed-Image-Edit-1.0 Techinical Report",
      "abstract": "We present FireRed-Image-Edit, a diffusion transformer for instruction-based image editing that achieves state-of-the-art performance through systematic optimization of data curation, training methodology, and evaluation design. We construct a 1.6B-sample training corpus, comprising 900M text-to-image and 700M image editing pairs from diverse sources. After rigorous cleaning, stratification, auto-labeling, and two-stage filtering, we retain over 100M high-quality samples balanced between generation and editing, ensuring strong semantic coverage and instruction alignment. Our multi-stage training pipeline progressively builds editing capability via pre-training, supervised fine-tuning, and reinforcement learning. To improve data efficiency, we introduce a Multi-Condition Aware Bucket Sampler for variable-resolution batching and Stochastic Instruction Alignment with dynamic prompt re-indexing. To stabilize optimization and enhance controllability, we propose Asymmetric Gradient Optimization for DPO, DiffusionNFT with layout-aware OCR rewards for text editing, and a differentiable Consistency Loss for identity preservation. We further establish REDEdit-Bench, a comprehensive benchmark spanning 15 editing categories, including newly introduced beautification and low-level enhancement tasks. Extensive experiments on REDEdit-Bench and public benchmarks (ImgEdit and GEdit) demonstrate competitive or superior performance against both open-source and proprietary systems. We release code, models, and the benchmark suite to support future research.",
      "authors": [
        "Super Intelligence Team",
        "Changhao Qiao",
        "Chao Hui",
        "Chen Li",
        "Cunzheng Wang",
        "Dejia Song",
        "Jiale Zhang",
        "Jing Li",
        "Qiang Xiang",
        "Runqi Wang",
        "Shuang Sun",
        "Wei Zhu",
        "Xu Tang",
        "Yao Hu",
        "Yibo Chen",
        "Yuhao Huang",
        "Yuxuan Duan",
        "Zhiyi Chen",
        "Ziyuan Guo"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "eess.IV"
      ],
      "published": "2026-02-12 17:51:44+00:00",
      "link": "https://arxiv.org/pdf/2602.13344v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12207v2",
      "title": "VIRENA: Virtual Arena for Research, Education, and Democratic Innovation",
      "abstract": "Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments. Multiple participants interact simultaneously in realistic replicas of feed-based platforms (Instagram, Facebook, Reddit) and messaging apps (WhatsApp, Messenger). Large language model-powered AI agents participate alongside humans with configurable personas and realistic behavior. Researchers can manipulate content moderation approaches, pre-schedule stimulus content, and run experiments across conditions through a visual interface requiring no programming skills. VIRENA makes possible research designs that were previously impractical: studying human--AI interaction in realistic social contexts, experimentally comparing moderation interventions, and observing group deliberation as it unfolds. Built on open-source technologies that ensure data remain under institutional control and comply with data protection requirements, VIRENA is currently in use at the University of Zurich and available for pilot collaborations. Designed for researchers, educators, and public organizations alike, VIRENA's no-code interface makes controlled social media simulation accessible across disciplines and sectors. This paper documents its design, architecture, and capabilities.",
      "authors": [
        "Emma Hoes",
        "K. Jonathan Klueser",
        "Fabrizio Gilardi"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SI"
      ],
      "published": "2026-02-12 17:46:52+00:00",
      "link": "https://arxiv.org/pdf/2602.12207v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12205v2",
      "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing",
      "abstract": "Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.",
      "authors": [
        "Dianyi Wang",
        "Ruihang Li",
        "Feng Han",
        "Chaofan Ma",
        "Wei Song",
        "Siyuan Wang",
        "Yibin Wang",
        "Yi Xin",
        "Hongjian Liu",
        "Zhixiong Zhang",
        "Shengyuan Ding",
        "Tianhang Wang",
        "Zhenglin Cheng",
        "Tao Lin",
        "Cheng Jin",
        "Kaicheng Yu",
        "Jingjing Chen",
        "Wenjie Wang",
        "Zhongyu Wei",
        "Jiaqi Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-12 17:44:24+00:00",
      "link": "https://arxiv.org/pdf/2602.12205v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12203v1",
      "title": "ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images",
      "abstract": "Enterprise documents, such as forms and reports, embed critical information for downstream applications like data archiving, automated workflows, and analytics. Although generalist Vision Language Models (VLMs) perform well on established document understanding benchmarks, their ability to conduct holistic, fine-grained structured extraction across diverse document types and flexible schemas is not well studied. Existing Key Entity Extraction (KEE), Relation Extraction (RE), and Visual Question Answering (VQA) datasets are limited by narrow entity ontologies, simple queries, or homogeneous document types, often overlooking the need for adaptable and structured extraction. To address these gaps, we introduce ExStrucTiny, a new benchmark dataset for structured Information Extraction (IE) from document images, unifying aspects of KEE, RE, and VQA. Built through a novel pipeline combining manual and synthetic human-validated samples, ExStrucTiny covers more varied document types and extraction scenarios. We analyze open and closed VLMs on this benchmark, highlighting challenges such as schema adaptation, query under-specification, and answer localization. We hope our work provides a bedrock for improving generalist models for structured IE in documents.",
      "authors": [
        "Mathieu Sibue",
        "Andres Muñoz Garza",
        "Samuel Mensah",
        "Pranav Shetty",
        "Zhiqiang Ma",
        "Xiaomo Liu",
        "Manuela Veloso"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-12 17:38:57+00:00",
      "link": "https://arxiv.org/pdf/2602.12203v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12192v1",
      "title": "Query-focused and Memory-aware Reranker for Long Context Processing",
      "abstract": "Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverages holistic information within the entire candidate shortlist during ranking. At the same time, it naturally produces continuous relevance scores, enabling training on arbitrary retrieval datasets without requiring Likert-scale supervision. Our framework is lightweight and effective, requiring only small-scale models (e.g., 4B parameters) to achieve strong performance. Extensive experiments demonstrate that our method outperforms existing state-of-the-art pointwise and listwise rerankers across multiple domains, including Wikipedia and long narrative datasets. It further establishes a new state-of-the-art on the LoCoMo benchmark that assesses the capabilities of dialogue understanding and memory usage. We further demonstrate that our framework supports flexible extensions. For example, augmenting candidate passages with contextual information further improves ranking accuracy, while training attention heads from middle layers enhances efficiency without sacrificing performance.",
      "authors": [
        "Yuqing Li",
        "Jiangnan Li",
        "Mo Yu",
        "Guoxuan Ding",
        "Zheng Lin",
        "Weiping Wang",
        "Jie Zhou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-12 17:23:38+00:00",
      "link": "https://arxiv.org/pdf/2602.12192v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12183v1",
      "title": "Unknown Attack Detection in IoT Networks using Large Language Models: A Robust, Data-efficient Approach",
      "abstract": "The rapid evolution of cyberattacks continues to drive the emergence of unknown (zero-day) threats, posing significant challenges for network intrusion detection systems in Internet of Things (IoT) networks. Existing machine learning and deep learning approaches typically rely on large labeled datasets, payload inspection, or closed-set classification, limiting their effectiveness under data scarcity, encrypted traffic, and distribution shifts. Consequently, detecting unknown attacks in realistic IoT deployments remains difficult. To address these limitations, we propose SiamXBERT, a robust and data-efficient Siamese meta-learning framework empowered by a transformer-based language model for unknown attack detection. The proposed approach constructs a dual-modality feature representation by integrating flow-level and packet-level information, enabling richer behavioral modeling while remaining compatible with encrypted traffic. Through meta-learning, the model rapidly adapts to new attack types using only a small number of labeled samples and generalizes to previously unseen behaviors. Extensive experiments on representative IoT intrusion datasets demonstrate that SiamXBERT consistently outperforms state-of-the-art baselines under both within-dataset and cross-dataset settings while requiring significantly less training data, achieving up to \\num{78.8}\\% improvement in unknown F1-score. These results highlight the practicality of SiamXBERT for robust unknown attack detection in real-world IoT environments.",
      "authors": [
        "Shan Ali",
        "Feifei Niu",
        "Paria Shirani",
        "Lionel C. Briand"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.SE"
      ],
      "published": "2026-02-12 17:15:39+00:00",
      "link": "https://arxiv.org/pdf/2602.12183v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12172v1",
      "title": "Pedagogically-Inspired Data Synthesis for Language Model Knowledge Distillation",
      "abstract": "Knowledge distillation from Large Language Models (LLMs) to smaller models has emerged as a critical technique for deploying efficient AI systems. However, current methods for distillation via synthetic data lack pedagogical awareness, treating knowledge transfer as a one-off data synthesis and training task rather than a systematic learning process. In this paper, we propose a novel pedagogically-inspired framework for LLM knowledge distillation that draws from fundamental educational principles. Our approach introduces a three-stage pipeline -- Knowledge Identifier, Organizer, and Adapter (IOA) -- that systematically identifies knowledge deficiencies in student models, organizes knowledge delivery through progressive curricula, and adapts representations to match the cognitive capacity of student models. We integrate Bloom's Mastery Learning Principles and Vygotsky's Zone of Proximal Development to create a dynamic distillation process where student models approach teacher model's performance on prerequisite knowledge before advancing, and new knowledge is introduced with controlled, gradual difficulty increments. Extensive experiments using LLaMA-3.1/3.2 and Qwen2.5 as student models demonstrate that IOA achieves significant improvements over baseline distillation methods, with student models retaining 94.7% of teacher performance on DollyEval while using less than 1/10th of the parameters. Our framework particularly excels in complex reasoning tasks, showing 19.2% improvement on MATH and 22.3% on HumanEval compared with state-of-the-art baselines.",
      "authors": [
        "Bowei He",
        "Yankai Chen",
        "Xiaokun Zhang",
        "Linghe Kong",
        "Philip S. Yu",
        "Xue Liu",
        "Chen Ma"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-12 17:00:36+00:00",
      "link": "https://arxiv.org/pdf/2602.12172v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12164v1",
      "title": "Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision",
      "abstract": "Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.",
      "authors": [
        "Xiaohan He",
        "Shiyang Feng",
        "Songtao Huang",
        "Lei Bai",
        "Bin Wang",
        "Bo Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12 16:46:00+00:00",
      "link": "https://arxiv.org/pdf/2602.12164v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12162v1",
      "title": "Amortized Molecular Optimization via Group Relative Policy Optimization",
      "abstract": "Molecular design encompasses tasks ranging from de-novo design to structural alteration of given molecules or fragments. For the latter, state-of-the-art methods predominantly function as \"Instance Optimizers'', expending significant compute restarting the search for every input structure. While model-based approaches theoretically offer amortized efficiency by learning a policy transferable to unseen structures, existing methods struggle to generalize. We identify a key failure mode: the high variance arising from the heterogeneous difficulty of distinct starting structures. To address this, we introduce GRXForm, adapting a pre-trained Graph Transformer model that optimizes molecules via sequential atom-and-bond additions. We employ Group Relative Policy Optimization (GRPO) for goal-directed fine-tuning to mitigate variance by normalizing rewards relative to the starting structure. Empirically, GRXForm generalizes to out-of-distribution molecular scaffolds without inference-time oracle calls or refinement, achieving scores in multi-objective optimization competitive with leading instance optimizers.",
      "authors": [
        "Muhammad bin Javaid",
        "Hasham Hussain",
        "Ashima Khanna",
        "Berke Kisin",
        "Jonathan Pirnay",
        "Alexander Mitsos",
        "Dominik G. Grimm",
        "Martin Grohe"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 16:43:59+00:00",
      "link": "https://arxiv.org/pdf/2602.12162v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12160v1",
      "title": "DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation",
      "abstract": "Recent advancements in foundation models have revolutionized joint audio-video generation. However, existing approaches typically treat human-centric tasks including reference-based audio-video generation (R2AV), video editing (RV2AV) and audio-driven video animation (RA2V) as isolated objectives. Furthermore, achieving precise, disentangled control over multiple character identities and voice timbres within a single framework remains an open challenge. In this paper, we propose DreamID-Omni, a unified framework for controllable human-centric audio-video generation. Specifically, we design a Symmetric Conditional Diffusion Transformer that integrates heterogeneous conditioning signals via a symmetric conditional injection scheme. To resolve the pervasive identity-timbre binding failures and speaker confusion in multi-person scenarios, we introduce a Dual-Level Disentanglement strategy: Synchronized RoPE at the signal level to ensure rigid attention-space binding, and Structured Captions at the semantic level to establish explicit attribute-subject mappings. Furthermore, we devise a Multi-Task Progressive Training scheme that leverages weakly-constrained generative priors to regularize strongly-constrained tasks, preventing overfitting and harmonizing disparate objectives. Extensive experiments demonstrate that DreamID-Omni achieves comprehensive state-of-the-art performance across video, audio, and audio-visual consistency, even outperforming leading proprietary commercial models. We will release our code to bridge the gap between academic research and commercial-grade applications.",
      "authors": [
        "Xu Guo",
        "Fulong Ye",
        "Qichao Sun",
        "Liyang Chen",
        "Bingchuan Li",
        "Pengze Zhang",
        "Jiawei Liu",
        "Songtao Zhao",
        "Qian He",
        "Xiangwang Hou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 16:41:52+00:00",
      "link": "https://arxiv.org/pdf/2602.12160v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12159v1",
      "title": "3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting",
      "abstract": "Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/",
      "authors": [
        "Wancai Zheng",
        "Hao Chen",
        "Xianlong Lu",
        "Linlin Ou",
        "Xinyi Yu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-12 16:41:26+00:00",
      "link": "https://arxiv.org/pdf/2602.12159v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12157v2",
      "title": "TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation",
      "abstract": "High-quality 3D texture generation remains a fundamental challenge due to the view-inconsistency inherent in current mainstream multi-view diffusion pipelines. Existing representations either rely on UV maps, which suffer from distortion during unwrapping, or point-based methods, which tightly couple texture fidelity to geometric density that limits high-resolution texture generation. To address these limitations, we introduce TexSpot, a diffusion-based texture enhancement framework. At its core is Texlet, a novel 3D texture representation that merges the geometric expressiveness of point-based 3D textures with the compactness of UV-based representation. Each Texlet latent vector encodes a local texture patch via a 2D encoder and is further aggregated using a 3D encoder to incorporate global shape context. A cascaded 3D-to-2D decoder reconstructs high-quality texture patches, enabling the Texlet space learning. Leveraging this representation, we train a diffusion transformer conditioned on Texlets to refine and enhance textures produced by multi-view diffusion methods. Extensive experiments demonstrate that TexSpot significantly improves visual fidelity, geometric consistency, and robustness over existing state-of-the-art 3D texture generation and enhancement approaches. Project page: https://texlet-arch.github.io/TexSpot-page.",
      "authors": [
        "Ziteng Lu",
        "Yushuang Wu",
        "Chongjie Ye",
        "Yuda Qiu",
        "Jing Shao",
        "Xiaoyang Guo",
        "Jiaqing Zhou",
        "Tianlei Hu",
        "Kun Zhou",
        "Xiaoguang Han"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.GR"
      ],
      "published": "2026-02-12 16:37:31+00:00",
      "link": "https://arxiv.org/pdf/2602.12157v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12146v1",
      "title": "Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning",
      "abstract": "Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data formats. Recent advancements in deep learning have opened new avenues for compression; however, many existing approaches depend on dense vector representations that obscure the underlying token structure. To address these limitations, we propose a novel lossless compression method that leverages Reinforcement Learning applied to a T5 language model architecture. This approach enables the compression of data into sequences of tokens rather than traditional vector representations. Unlike auto-encoders, which typically encode information into continuous latent spaces, our method preserves the token-based structure, aligning more closely with the original data format. This preservation allows for higher compression ratios while maintaining semantic integrity. By training the model using an off-policy Reinforcement Learning algorithm, we optimize sequence length to minimize redundancy and enhance compression efficiency. Our method introduces an efficient and adaptive data compression system built upon advanced Reinforcement Learning techniques, functioning independently of external grammatical or world knowledge. This approach shows significant improvements in compression ratios compared to conventional methods. By leveraging the latent information within language models, our system effectively compresses data without requiring explicit content understanding, paving the way for more robust and practical compression solutions across various applications.",
      "authors": [
        "Mahdi Khodabandeh",
        "Ghazal Shabani",
        "Arash Yousefi Jordehi",
        "Seyed Abolghasem Mirroshandel"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IT"
      ],
      "published": "2026-02-12 16:30:55+00:00",
      "link": "https://arxiv.org/pdf/2602.12146v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12129v1",
      "title": "Towards Personalized Bangla Book Recommendation: A Large-Scale Multi-Entity Book Graph Dataset",
      "abstract": "Personalized book recommendation in Bangla literature has been constrained by the lack of structured, large-scale, and publicly available datasets. This work introduces RokomariBG, a large-scale, multi-entity heterogeneous book graph dataset designed to support research on personalized recommendation in a low-resource language setting. The dataset comprises 127,302 books, 63,723 users, 16,601 authors, 1,515 categories, 2,757 publishers, and 209,602 reviews, connected through eight relation types and organized as a comprehensive knowledge graph.   To demonstrate the utility of the dataset, we provide a systematic benchmarking study on the Top-N recommendation task, evaluating a diverse set of representative recommendation models, including classical collaborative filtering methods, matrix factorization models, content-based approaches, graph neural networks, a hybrid matrix factorization model with side information, and a neural two-tower retrieval architecture. The benchmarking results highlight the importance of leveraging multi-relational structure and textual side information, with neural retrieval models achieving the strongest performance (NDCG@10 = 0.204). Overall, this work establishes a foundational benchmark and a publicly available resource for Bangla book recommendation research, enabling reproducible evaluation and future studies on recommendation in low-resource cultural domains. The dataset and code are publicly available at https://github.com/backlashblitz/Bangla-Book-Recommendation-Dataset",
      "authors": [
        "Rahin Arefin Ahmed",
        "Md. Anik Chowdhury",
        "Sakil Ahmed Sheikh Reza",
        "Devnil Bhattacharjee",
        "Muhammad Abdullah Adnan",
        "Nafis Sadeq"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "published": "2026-02-12 16:18:55+00:00",
      "link": "https://arxiv.org/pdf/2602.12129v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12123v1",
      "title": "Meta-Sel: Efficient Demonstration Selection for In-Context Learning via Supervised Meta-Learning",
      "abstract": "Demonstration selection is a practical bottleneck in in-context learning (ICL): under a tight prompt budget, accuracy can change substantially depending on which few-shot examples are included, yet selection must remain cheap enough to run per query over large candidate pools. We propose Meta-Sel, a lightweight supervised meta-learning approach for intent classification that learns a fast, interpretable scoring function for (candidate, query) pairs from labeled training data.   Meta-Sel constructs a meta-dataset by sampling pairs from the training split and using class agreement as supervision, then trains a calibrated logistic regressor on two inexpensive meta-features: TF--IDF cosine similarity and a length-compatibility ratio. At inference time, the selector performs a single vectorized scoring pass over the full candidate pool and returns the top-k demonstrations, requiring no model fine-tuning, no online exploration, and no additional LLM calls. This yields deterministic rankings and makes the selection mechanism straightforward to audit via interpretable feature weights.   Beyond proposing Meta-Sel, we provide a broad empirical study of demonstration selection, benchmarking 12 methods -- spanning prompt engineering baselines, heuristic selection, reinforcement learning, and influence-based approaches -- across four intent datasets and five open-source LLMs. Across this benchmark, Meta-Sel consistently ranks among the top-performing methods, is particularly effective for smaller models where selection quality can partially compensate for limited model capacity, and maintains competitive selection-time overhead.",
      "authors": [
        "Xubin Wang",
        "Weijia Jia"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-12 16:11:29+00:00",
      "link": "https://arxiv.org/pdf/2602.12123v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12117v1",
      "title": "KAN-FIF: Spline-Parameterized Lightweight Physics-based Tropical Cyclone Estimation on Meteorological Satellite",
      "abstract": "Tropical cyclones (TC) are among the most destructive natural disasters, causing catastrophic damage to coastal regions through extreme winds, heavy rainfall, and storm surges. Timely monitoring of tropical cyclones is crucial for reducing loss of life and property, yet it is hindered by the computational inefficiency and high parameter counts of existing methods on resource-constrained edge devices. Current physics-guided models suffer from linear feature interactions that fail to capture high-order polynomial relationships between TC attributes, leading to inflated model sizes and hardware incompatibility. To overcome these challenges, this study introduces the Kolmogorov-Arnold Network-based Feature Interaction Framework (KAN-FIF), a lightweight multimodal architecture that integrates MLP and CNN layers with spline-parameterized KAN layers. For Maximum Sustained Wind (MSW) prediction, experiments demonstrate that the KAN-FIF framework achieves a $94.8\\%$ reduction in parameters (0.99MB vs 19MB) and $68.7\\%$ faster inference per sample (2.3ms vs 7.35ms) compared to baseline model Phy-CoCo, while maintaining superior accuracy with $32.5\\%$ lower MAE. The offline deployment experiment of the FY-4 series meteorological satellite processor on the Qingyun-1000 development board achieved a 14.41ms per-sample inference latency with the KAN-FIF framework, demonstrating promising feasibility for operational TC monitoring and extending deployability to edge-device AI applications. The code is released at https://github.com/Jinglin-Zhang/KAN-FIF.",
      "authors": [
        "Jiakang Shen",
        "Qinghui Chen",
        "Runtong Wang",
        "Chenrui Xu",
        "Jinglin Zhang",
        "Cong Bai",
        "Feng Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-12 16:07:39+00:00",
      "link": "https://arxiv.org/pdf/2602.12117v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12107v1",
      "title": "On the Complexity of Offline Reinforcement Learning with $Q^\\star$-Approximation and Partial Coverage",
      "abstract": "We study offline reinforcement learning under $Q^\\star$-approximation and partial coverage, a setting that motivates practical algorithms such as Conservative $Q$-Learning (CQL; Kumar et al., 2020) but has received limited theoretical attention. Our work is inspired by the following open question: \"Are $Q^\\star$-realizability and Bellman completeness sufficient for sample-efficient offline RL under partial coverage?\"   We answer in the negative by establishing an information-theoretic lower bound. Going substantially beyond this, we introduce a general framework that characterizes the intrinsic complexity of a given $Q^\\star$ function class, inspired by model-free decision-estimation coefficients (DEC) for online RL (Foster et al., 2023b; Liu et al., 2025b). This complexity recovers and improves the quantities underlying the guarantees of Chen and Jiang (2022) and Uehara et al. (2023), and extends to broader settings. Our decision-estimation decomposition can be combined with a wide range of $Q^\\star$ estimation procedures, modularizing and generalizing existing approaches.   Beyond the general framework, we make further contributions: By developing a novel second-order performance difference lemma, we obtain the first $ε^{-2}$ sample complexity under partial coverage for soft $Q$-learning, improving the $ε^{-4}$ bound of Uehara et al. (2023). We remove Chen and Jiang's (2022) need for additional online interaction when the value gap of $Q^\\star$ is unknown. We also give the first characterization of offline learnability for general low-Bellman-rank MDPs without Bellman completeness (Jiang et al., 2017; Du et al., 2021; Jin et al., 2021), a canonical setting in online RL that remains unexplored in offline RL except for special cases. Finally, we provide the first analysis for CQL under $Q^\\star$-realizability and Bellman completeness beyond the tabular case.",
      "authors": [
        "Haolin Liu",
        "Braham Snyder",
        "Chen-Yu Wei"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-02-12 15:59:42+00:00",
      "link": "https://arxiv.org/pdf/2602.12107v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12099v1",
      "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning",
      "abstract": "Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose \\textit{GigaBrain-0.5M*}, a VLA model trained via world model-based reinforcement learning. Built upon \\textit{GigaBrain-0.5}, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. \\textit{GigaBrain-0.5M*} further integrates world model-based reinforcement learning via \\textit{RAMP} (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that \\textit{RAMP} achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\\% on challenging tasks including \\texttt{Laundry Folding}, \\texttt{Box Packing}, and \\texttt{Espresso Preparation}. Critically, \\textit{GigaBrain-0.5M$^*$} exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our \\href{https://gigabrain05m.github.io}{project page}.",
      "authors": [
        "GigaBrain Team",
        "Boyuan Wang",
        "Chaojun Ni",
        "Guan Huang",
        "Guosheng Zhao",
        "Hao Li",
        "Jie Li",
        "Jindi Lv",
        "Jingyu Liu",
        "Lv Feng",
        "Mingming Yu",
        "Peng Li",
        "Qiuping Deng",
        "Tianze Liu",
        "Xinyu Zhou",
        "Xinze Chen",
        "Xiaofeng Wang",
        "Yang Wang",
        "Yifan Li",
        "Yifei Nie",
        "Yilong Li",
        "Yukun Zhou",
        "Yun Ye",
        "Zhichao Liu",
        "Zheng Zhu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 15:55:19+00:00",
      "link": "https://arxiv.org/pdf/2602.12099v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12096v1",
      "title": "Multi Graph Search for High-Dimensional Robot Motion Planning",
      "abstract": "Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.",
      "authors": [
        "Itamar Mishani",
        "Maxim Likhachev"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-12 15:50:15+00:00",
      "link": "https://arxiv.org/pdf/2602.12096v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12311v1",
      "title": "Perceptual Self-Reflection in Agentic Physics Simulation Code Generation",
      "abstract": "We present a multi-agent framework for generating physics simulation code from natural language descriptions, featuring a novel perceptual self-reflection mechanism for validation. The system employs four specialized agents: a natural language interpreter that converts user requests into physics-based descriptions; a technical requirements generator that produces scaled simulation parameters; a physics code generator with automated self-correction; and a physics validator that implements perceptual self-reflection. The key innovation is perceptual validation, which analyzes rendered animation frames using a vision-capable language model rather than inspecting code structure directly. This approach addresses the ``oracle gap'' where syntactically correct code produces physically incorrect behavior--a limitation that conventional testing cannot detect. We evaluate the system across seven domains including classical mechanics, fluid dynamics, thermodynamics, electromagnetics, wave physics, reaction-diffusion systems, and non-physics data visualization. The perceptual self-reflection architecture demonstrates substantial improvement over single-shot generation baselines, with the majority of tested scenarios achieving target physics accuracy thresholds. The system exhibits robust pipeline stability with consistent code self-correction capability, operating at approximately \\$0.20 per animation. These results validate our hypothesis that feeding visual simulation outputs back to a vision-language model for iterative refinement significantly outperforms single-shot code generation for physics simulation tasks and highlights the potential of agentic AI to support engineering workflows and physics data generation pipelines.",
      "authors": [
        "Prashant Shende",
        "Bradley Camburn"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-02-12 15:48:33+00:00",
      "link": "https://arxiv.org/pdf/2602.12311v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12095v2",
      "title": "Pack it in: Packing into Partially Filled Containers Through Contact",
      "abstract": "The automation of warehouse operations is crucial for improving productivity and reducing human exposure to hazardous environments. One operation frequently performed in warehouses is bin-packing where items need to be placed into containers, either for delivery to a customer, or for temporary storage in the warehouse. Whilst prior bin-packing works have largely been focused on packing items into empty containers and have adopted collision-free strategies, it is often the case that containers will already be partially filled with items, often in suboptimal arrangements due to transportation about a warehouse. This paper presents a contact-aware packing approach that exploits purposeful interactions with previously placed objects to create free space and enable successful placement of new items. This is achieved by using a contact-based multi-object trajectory optimizer within a model predictive controller, integrated with a physics-aware perception system that estimates object poses even during inevitable occlusions, and a method that suggests physically-feasible locations to place the object inside the container.",
      "authors": [
        "David Russell",
        "Zisong Xu",
        "Maximo A. Roa",
        "Mehmet Dogar"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-12 15:47:04+00:00",
      "link": "https://arxiv.org/pdf/2602.12095v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12087v1",
      "title": "Geometry of Uncertainty: Learning Metric Spaces for Multimodal State Estimation in RL",
      "abstract": "Estimating the state of an environment from high-dimensional, multimodal, and noisy observations is a fundamental challenge in reinforcement learning (RL). Traditional approaches rely on probabilistic models to account for the uncertainty, but often require explicit noise assumptions, in turn limiting generalization. In this work, we contribute a novel method to learn a structured latent representation, in which distances between states directly correlate with the minimum number of actions required to transition between them. The proposed metric space formulation provides a geometric interpretation of uncertainty without the need for explicit probabilistic modeling. To achieve this, we introduce a multimodal latent transition model and a sensor fusion mechanism based on inverse distance weighting, allowing for the adaptive integration of multiple sensor modalities without prior knowledge of noise distributions. We empirically validate the approach on a range of multimodal RL tasks, demonstrating improved robustness to sensor noise and superior state estimation compared to baseline methods. Our experiments show enhanced performance of an RL agent via the learned representation, eliminating the need of explicit noise augmentation. The presented results suggest that leveraging transition-aware metric spaces provides a principled and scalable solution for robust state estimation in sequential decision-making.",
      "authors": [
        "Alfredo Reichlin",
        "Adriano Pacciarelli",
        "Danica Kragic",
        "Miguel Vasco"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 15:41:20+00:00",
      "link": "https://arxiv.org/pdf/2602.12087v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12084v1",
      "title": "Computing Distinguishing Formulae for Threshold-Based Behavioural Distances",
      "abstract": "Behavioural distances generally offer more fine-grained means of comparing quantitative systems than two-valued behavioural equivalences. They often relate to quantitative modalities, which generate quantitative modal logics that characterize a given behavioural distance in terms of the induced logical distance. We develop a unified framework for behavioural distances and logics induced by a special type of modalities that lift two-valued predicates to quantitative predicates. A typical example is the probability operator, which maps a two-valued predicate $A$ to a quantitative predicate on probability distributions assigning to each distribution the respective probability of $A$. Correspondingly, the prototypical example of our framework is $ε$-bisimulation distance of Markov chains, which has recently been shown to coincide with the behavioural distance induced by the popular Lévy-Prokhorov distance on distributions. Other examples include behavioural distance on metric transition systems and Hausdorff behavioural distance on fuzzy transition systems. Our main generic results concern the polynomial-time extraction of distinguishing formulae in two characteristic modal logics: A two-valued logic with a notion of satisfaction up to $ε$, and a quantitative modal logic. These results instantiate to new results in many of the mentioned examples. Notably, we obtain polynomial-time extraction of distinguishing formulae for $ε$-bisimulation distance of Markov chains in a quantitative logic featuring a `generally' modality used in probabilistic knowledge representation.",
      "authors": [
        "Jonas Forster",
        "Lutz Schröder",
        "Paul Wild",
        "Barbara König",
        "Pedro Nora"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-02-12 15:39:30+00:00",
      "link": "https://arxiv.org/pdf/2602.12084v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12081v1",
      "title": "PPTAM$η$: Energy Aware CI/CD Pipeline for Container Based Applications",
      "abstract": "Modern container-based microservices evolve through rapid deployment cycles, but CI/CD pipelines still rarely measure energy consumption, even though prior work shows that design patterns, code smells and refactorings affect energy efficiency. We present PPTAM$η$, an automated pipeline that integrates power and energy measurement into GitLab CI for containerised API systems, coordinating load generation, container monitoring and hardware power probes to collect comparable metrics at each commit. The pipeline makes energy visible to developers, supports version comparison for test engineers and enables trend analysis for researchers. We evaluate PPTAM$η$ on a JWT-authenticated API across four commits, collecting performance and energy metrics and summarising the architecture, measurement methodology and validation.",
      "authors": [
        "Alessandro Aneggi",
        "Xiaozhou Li",
        "Andrea Janes"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-12 15:38:35+00:00",
      "link": "https://arxiv.org/pdf/2602.12081v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12080v1",
      "title": "PathCRF: Ball-Free Soccer Event Detection via Possession Path Inference from Player Trajectories",
      "abstract": "Despite recent advances in AI, event data collection in soccer still relies heavily on labor-intensive manual annotation. Although prior work has explored automatic event detection using player and ball trajectories, ball tracking also remains difficult to scale due to high infrastructural and operational costs. As a result, comprehensive data collection in soccer is largely confined to top-tier competitions, limiting the broader adoption of data-driven analysis in this domain. To address this challenge, this paper proposes PathCRF, a framework for detecting on-ball soccer events using only player tracking data. We model player trajectories as a fully connected dynamic graph and formulate event detection as the problem of selecting exactly one edge corresponding to the current possession state at each time step. To ensure logical consistency of the resulting edge sequence, we employ a Conditional Random Field (CRF) that forbids impossible transitions between consecutive edges. Both emission and transition scores dynamically computed from edge embeddings produced by a Set Attention-based backbone architecture. During inference, the most probable edge sequence is obtained via Viterbi decoding, and events such as ball controls or passes are detected whenever the selected edge changes between adjacent time steps. Experiments show that PathCRF produces accurate, logically consistent possession paths, enabling reliable downstream analyses while substantially reducing the need for manual event annotation. The source code is available at https://github.com/hyunsungkim-ds/pathcrf.git.",
      "authors": [
        "Hyunsung Kim",
        "Kunhee Lee",
        "Sangwoo Seo",
        "Sang-Ki Ko",
        "Jinsung Yoon",
        "Chanyoung Park"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 15:37:31+00:00",
      "link": "https://arxiv.org/pdf/2602.12080v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12074v1",
      "title": "RF-Modulated Adaptive Communication Improves Multi-Agent Robotic Exploration",
      "abstract": "Reliable coordination and efficient communication are critical challenges for multi-agent robotic exploration of environments where communication is limited. This work introduces Adaptive-RF Transmission (ART), a novel communication-aware planning algorithm that dynamically modulates transmission location based on signal strength and data payload size, enabling heterogeneous robot teams to share information efficiently without unnecessary backtracking. We further explore an extension to this approach called ART-SST, which enforces signal strength thresholds for high-fidelity data delivery. Through over 480 simulations across three cave-inspired environments, ART consistently outperforms existing strategies, including full rendezvous and minimum-signal heuristic approaches, achieving up to a 58% reduction in distance traveled and up to 52% faster exploration times compared to baseline methods. These results demonstrate that adaptive, payload-aware communication significantly improves coverage efficiency and mission speed in complex, communication-constrained environments, offering a promising foundation for future planetary exploration and search-and-rescue missions.",
      "authors": [
        "Lorin Achey",
        "Breanne Crockett",
        "Christoffer Heckman",
        "Bradley Hayes"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-12 15:33:17+00:00",
      "link": "https://arxiv.org/pdf/2602.12074v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12063v2",
      "title": "VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model",
      "abstract": "The goal of this paper is to improve the performance and reliability of vision-language-action (VLA) models through iterative online interaction. Since collecting policy rollouts in the real world is expensive, we investigate whether a learned simulator-specifically, an action-conditioned video generation model-can be used to generate additional rollout data. Unfortunately, existing world models lack the physical fidelity necessary for policy improvement: they are predominantly trained on demonstration datasets that lack coverage of many different physical interactions (particularly failure cases) and struggle to accurately model small yet critical physical details in contact-rich object manipulation. We propose a simple iterative improvement algorithm that uses real-world roll-out data to improve the fidelity of the world model, which can then, in turn, be used to generate supplemental synthetic data for improving the VLA model. In our experiments on a real robot, we use this approach to improve the performance of a state-of-the-art VLA model on multiple downstream tasks. We achieve a 39.2% absolute success rate improvement over the base policy and 11.6% improvement from training with the generated synthetic rollouts. Videos can be found at this anonymous website: https://sites.google.com/view/vla-w",
      "authors": [
        "Yanjiang Guo",
        "Tony Lee",
        "Lucy Xiaoyang Shi",
        "Jianyu Chen",
        "Percy Liang",
        "Chelsea Finn"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-12 15:21:47+00:00",
      "link": "https://arxiv.org/pdf/2602.12063v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12049v1",
      "title": "Improving HPC Code Generation Capability of LLMs via Online Reinforcement Learning with Real-Machine Benchmark Rewards",
      "abstract": "Large language models (LLMs) have demonstrated strong code generation capabilities, yet the runtime performance of generated code is not guaranteed, and there have been few attempts to train LLMs using runtime performance as a reward in the HPC domain. We propose an online reinforcement learning approach that executes LLM-generated code on a supercomputer and directly feeds back the measured runtime performance (GFLOPS) as a reward. We further introduce a Staged Quality-Diversity (SQD) algorithm that progressively varies the permitted optimization techniques on a per-problem basis, enabling the model to learn code optimization from diverse perspectives. We build a distributed system connecting a GPU training cluster with a CPU benchmarking cluster, and train Qwen2.5 Coder 14B on a double-precision matrix multiplication task using Group Relative Policy Optimization (GRPO). Through two experiments, we show that reinforcement learning combining runtime performance feedback with staged optimization can improve the HPC code generation capability of LLMs.",
      "authors": [
        "Ryo Mikasa",
        "Shun-ichiro Hayashi",
        "Daichi Mukunoki",
        "Tetsuya Hoshino",
        "Takahiro Katagiri"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 15:12:59+00:00",
      "link": "https://arxiv.org/pdf/2602.12049v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12045v1",
      "title": "Fourier Transformers for Latent Crystallographic Diffusion and Generative Modeling",
      "abstract": "The discovery of new crystalline materials calls for generative models that handle periodic boundary conditions, crystallographic symmetries, and physical constraints, while scaling to large and structurally diverse unit cells. We propose a reciprocal-space generative pipeline that represents crystals through a truncated Fourier transform of the species-resolved unit-cell density, rather than modeling atomic coordinates directly. This representation is periodicity-native, admits simple algebraic actions of space-group symmetries, and naturally supports variable atomic multiplicities during generation, addressing a common limitation of particle-based approaches. Using only nine Fourier basis functions per spatial dimension, our approach reconstructs unit cells containing up to 108 atoms per chemical species. We instantiate this pipeline with a transformer variational autoencoder over complex-valued Fourier coefficients, and a latent diffusion model that generates in the compressed latent space. We evaluate reconstruction and latent diffusion on the LeMaterial benchmark and compare unconditional generation against coordinate-based baselines in the small-cell regime ($\\leq 16$ atoms per unit cell).",
      "authors": [
        "Jed A. Duersch",
        "Elohan Veillon",
        "Astrid Klipfel",
        "Adlane Sayede",
        "Zied Bouraoui"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-12 15:11:12+00:00",
      "link": "https://arxiv.org/pdf/2602.12045v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12036v1",
      "title": "Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models",
      "abstract": "Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.",
      "authors": [
        "Xin Xu",
        "Clive Bai",
        "Kai Yang",
        "Tianhao Chen",
        "Yangkun Chen",
        "Weijie Liu",
        "Hao Chen",
        "Yang Wang",
        "Saiyong Yang",
        "Can Yang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-12 15:03:37+00:00",
      "link": "https://arxiv.org/pdf/2602.12036v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12009v1",
      "title": "On the Sensitivity of Firing Rate-Based Federated Spiking Neural Networks to Differential Privacy",
      "abstract": "Federated Neuromorphic Learning (FNL) enables energy-efficient and privacy-preserving learning on devices without centralizing data. However, real-world deployments require additional privacy mechanisms that can significantly alter training signals. This paper analyzes how Differential Privacy (DP) mechanisms, specifically gradient clipping and noise injection, perturb firing-rate statistics in Spiking Neural Networks (SNNs) and how these perturbations are propagated to rate-based FNL coordination. On a speech recognition task under non-IID settings, ablations across privacy budgets and clipping bounds reveal systematic rate shifts, attenuated aggregation, and ranking instability during client selection. Moreover, we relate these shifts to sparsity and memory indicators. Our findings provide actionable guidance for privacy-preserving FNL, specifically regarding the balance between privacy strength and rate-dependent coordination.",
      "authors": [
        "Luiz Pereira",
        "Mirko Perkusich",
        "Dalton Valadares",
        "Kyller Gorgônio"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-12 14:40:25+00:00",
      "link": "https://arxiv.org/pdf/2602.12009v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11982v1",
      "title": "Automatic Simplification of Common Vulnerabilities and Exposures Descriptions",
      "abstract": "Understanding cyber security is increasingly important for individuals and organizations. However, a lot of information related to cyber security can be difficult to understand to those not familiar with the topic. In this study, we focus on investigating how large language models (LLMs) could be utilized in automatic text simplification (ATS) of Common Vulnerability and Exposure (CVE) descriptions. Automatic text simplification has been studied in several contexts, such as medical, scientific, and news texts, but it has not yet been studied to simplify texts in the rapidly changing and complex domain of cyber security. We created a baseline for cyber security ATS and a test dataset of 40 CVE descriptions, evaluated by two groups of cyber security experts in two survey rounds. We have found that while out-of-the box LLMs can make the text appear simpler, they struggle with meaning preservation. Code and data are available at https://version.aalto.fi/gitlab/vehomav1/simplification\\_nmi.",
      "authors": [
        "Varpu Vehomäki",
        "Kimmo K. Kaski"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-12 14:12:58+00:00",
      "link": "https://arxiv.org/pdf/2602.11982v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11980v1",
      "title": "Spatial Chain-of-Thought: Bridging Understanding and Generation Models for Spatial Reasoning Generation",
      "abstract": "While diffusion models have shown exceptional capabilities in aesthetic image synthesis, they often struggle with complex spatial understanding and reasoning. Existing approaches resort to Multimodal Large Language Models (MLLMs) to enhance this capability. However, they either incur high computational costs through joint training or suffer from spatial information loss when relying solely on textual prompts. To alleviate these limitations, we propose a Spatial Chain-of-Thought (SCoT) framework, a plug-and-play approach that effectively bridges the reasoning capabilities of MLLMs with the generative power of diffusion models. Specifically, we first enhance the diffusion model's layout awareness by training it on an interleaved text-coordinate instruction format. We then leverage state-of-the-art MLLMs as planners to generate comprehensive layout plans, transferring their spatial planning capabilities directly to the generation process. Extensive experiments demonstrate that our method achieves state-of-the-art performance on image generation benchmarks and significantly outperforms baselines on complex reasoning tasks, while also showing strong efficacy in image editing scenarios.",
      "authors": [
        "Wei Chen",
        "Yancheng Long",
        "Mingqiao Liu",
        "Haojie Ding",
        "Yankai Yang",
        "Hongyang Wei",
        "Yi-Fan Zhang",
        "Bin Wen",
        "Fan Yang",
        "Tingting Gao",
        "Han Li",
        "Long Chen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 14:12:14+00:00",
      "link": "https://arxiv.org/pdf/2602.11980v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11978v1",
      "title": "Accelerating Robotic Reinforcement Learning with Agent Guidance",
      "abstract": "Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.",
      "authors": [
        "Haojun Chen",
        "Zili Zou",
        "Chengdong Ma",
        "Yaoxiang Pu",
        "Haotong Zhang",
        "Yuanpei Chen",
        "Yaodong Yang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-12 14:09:32+00:00",
      "link": "https://arxiv.org/pdf/2602.11978v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11973v1",
      "title": "Calibrated Bayesian Deep Learning for Explainable Decision Support Systems Based on Medical Imaging",
      "abstract": "In critical decision support systems based on medical imaging, the reliability of AI-assisted decision-making is as relevant as predictive accuracy. Although deep learning models have demonstrated significant accuracy, they frequently suffer from miscalibration, manifested as overconfidence in erroneous predictions. To facilitate clinical acceptance, it is imperative that models quantify uncertainty in a manner that correlates with prediction correctness, allowing clinicians to identify unreliable outputs for further review. In order to address this necessity, the present paper proposes a generalizable probabilistic optimization framework grounded in Bayesian deep learning. Specifically, a novel Confidence-Uncertainty Boundary Loss (CUB-Loss) is introduced that imposes penalties on high-certainty errors and low-certainty correct predictions, explicitly enforcing alignment between prediction correctness and uncertainty estimates. Complementing this training-time optimization, a Dual Temperature Scaling (DTS) strategy is devised for post-hoc calibration, further refining the posterior distribution to improve intuitive explainability. The proposed framework is validated on three distinct medical imaging tasks: automatic screening of pneumonia, diabetic retinopathy detection, and identification of skin lesions. Empirical results demonstrate that the proposed approach achieves consistent calibration improvements across diverse modalities, maintains robust performance in data-scarce scenarios, and remains effective on severely imbalanced datasets, underscoring its potential for real clinical deployment.",
      "authors": [
        "Hua Xu",
        "Julián D. Arias-Londoño",
        "Juan I. Godino-Llorente"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-12 14:03:41+00:00",
      "link": "https://arxiv.org/pdf/2602.11973v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11966v1",
      "title": "MING: An Automated CNN-to-Edge MLIR HLS framework",
      "abstract": "Driven by the increasing demand for low-latency and real-time processing, machine learning applications are steadily migrating toward edge computing platforms, where Field-Programmable Gate Arrays (FPGAs) are widely adopted for their energy efficiency compared to CPUs and GPUs. To generate high-performance and low-power FPGA designs, several frameworks built upon High Level Synthesis (HLS) vendor tools have been proposed, among which MLIR-based frameworks are gaining significant traction due to their extensibility and ease of use. However, existing state-of-the-art frameworks often overlook the stringent resource constraints of edge devices. To address this limitation, we propose MING, an Multi-Level Intermediate Representation (MLIR)-based framework that abstracts and automates the HLS design process. Within this framework, we adopt a streaming architecture with carefully managed buffers, specifically designed to handle resource constraints while ensuring low-latency. In comparison with recent frameworks, our approach achieves on average 15x speedup for standard Convolutional Neural Network (CNN) kernels with up to four layers, and up to 200x for single-layer kernels. For kernels with larger input sizes, MING is capable of generating efficient designs that respect hardware resource constraints, whereas state-of-the-art frameworks struggle to meet.",
      "authors": [
        "Jiahong Bi",
        "Lars Schütze",
        "Jeronimo Castrillon"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR"
      ],
      "published": "2026-02-12 14:01:11+00:00",
      "link": "https://arxiv.org/pdf/2602.11966v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11961v1",
      "title": "Scaling Model and Data for Multilingual Machine Translation with Open Large Language Models",
      "abstract": "Open large language models (LLMs) have demonstrated improving multilingual capabilities in recent years. In this paper, we present a study of open LLMs for multilingual machine translation (MT) across a range of languages, and investigate the effects of model scaling and data scaling when adapting open LLMs to multilingual MT through continual pretraining and instruction finetuning. Based on the Gemma3 model family, we develop MiLMMT-46, which achieves top-tier multilingual translation performance across 46 languages. Extensive experiments show that MiLMMT-46 consistently outperforms recent state-of-the-art (SOTA) models, including Seed-X, HY-MT-1.5, and TranslateGemma, and achieves competitive performance with strong proprietary systems such as Google Translate and Gemini 3 Pro.",
      "authors": [
        "Yuzhe Shang",
        "Pengzhi Gao",
        "Wei Liu",
        "Jian Luan",
        "Jinsong Su"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-12 13:56:02+00:00",
      "link": "https://arxiv.org/pdf/2602.11961v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11917v1",
      "title": "AlphaPROBE: Alpha Mining via Principled Retrieval and On-graph biased evolution",
      "abstract": "Extracting signals through alpha factor mining is a fundamental challenge in quantitative finance. Existing automated methods primarily follow two paradigms: Decoupled Factor Generation, which treats factor discovery as isolated events, and Iterative Factor Evolution, which focuses on local parent-child refinements. However, both paradigms lack a global structural view, often treating factor pools as unstructured collections or fragmented chains, which leads to redundant search and limited diversity. To address these limitations, we introduce AlphaPROBE (Alpha Mining via Principled Retrieval and On-graph Biased Evolution), a framework that reframes alpha mining as the strategic navigation of a Directed Acyclic Graph (DAG). By modeling factors as nodes and evolutionary links as edges, AlphaPROBE treats the factor pool as a dynamic, interconnected ecosystem. The framework consists of two core components: a Bayesian Factor Retriever that identifies high-potential seeds by balancing exploitation and exploration through a posterior probability model, and a DAG-aware Factor Generator that leverages the full ancestral trace of factors to produce context-aware, nonredundant optimizations. Extensive experiments on three major Chinese stock market datasets against 8 competitive baselines demonstrate that AlphaPROBE significantly gains enhanced performance in predictive accuracy, return stability and training efficiency. Our results confirm that leveraging global evolutionary topology is essential for efficient and robust automated alpha discovery. We have open-sourced our implementation at https://github.com/gta0804/AlphaPROBE.",
      "authors": [
        "Taian Guo",
        "Haiyang Shen",
        "Junyu Luo",
        "Binqi Chen",
        "Hongjun Ding",
        "Jinsheng Huang",
        "Luchen Liu",
        "Yun Ma",
        "Ming Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12 13:14:58+00:00",
      "link": "https://arxiv.org/pdf/2602.11917v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11911v1",
      "title": "Improving Code Generation via Small Language Model-as-a-judge",
      "abstract": "Large language models (LLMs) have shown remarkable capabilities in automated code generation. While effective for mainstream languages, they may underperform on less common or domain-specific languages, prompting companies to develop in-house code generators. While open-source models can be trained for this, only LLMs with tens of billions of parameters match the performance of commercial tools, demanding costly training and deployment. Recent work proposed supporting code generation with smaller models (SLMs) by generating multiple candidate solutions and using another SLM to select the most likely correct one. The most recent work in this area is the one by Sun et al. [29] presenting RankEF, a T5 model trained to rank code solutions using both execution-based and non-execution-based information. However, Sun et al. do not assess the T5 ranker's classification accuracy, that is, how often it misjudges correct implementations as incorrect or vice versa, leaving open questions about the reliability of LMs as code correctness judges for other tasks (e.g., automated code review). Moreover, their experiments involve relatively old models, making it unclear the extent to which such a methodology would still help companies in cheaply training their own code generators with performance comparable to those of massive LLMs. We present a study addressing these limitations. We train several state-of-the-art SLMs as code correctness judges and assess their ability to discriminate between correct and wrong implementations. We show that modern SLMs outperform RankEF, even without exploiting execution-based information. When used as code rankers, they achieve higher performance gains than RankEF and perform competitively with LLMs 5-25x larger, at a fraction of the cost.",
      "authors": [
        "Giuseppe Crupi",
        "Rosalia Tufano",
        "Gabriele Bavota"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-12 13:07:36+00:00",
      "link": "https://arxiv.org/pdf/2602.11911v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11903v1",
      "title": "Learning Perceptual Representations for Gaming NR-VQA with Multi-Task FR Signals",
      "abstract": "No-reference video quality assessment (NR-VQA) for gaming videos is challenging due to limited human-rated datasets and unique content characteristics including fast motion, stylized graphics, and compression artifacts. We present MTL-VQA, a multi-task learning framework that uses full-reference metrics as supervisory signals to learn perceptually meaningful features without human labels for pretraining. By jointly optimizing multiple full-reference (FR) objectives with adaptive task weighting, our approach learns shared representations that transfer effectively to NR-VQA. Experiments on gaming video datasets show MTL-VQA achieves performance competitive with state-of-the-art NR-VQA methods across both MOS-supervised and label-efficient/self-supervised settings.",
      "authors": [
        "Yu-Chih Chen",
        "Michael Wang",
        "Chieh-Dun Wen",
        "Kai-Siang Ma",
        "Avinab Saha",
        "Li-Heng Chen",
        "Alan Bovik"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.MM"
      ],
      "published": "2026-02-12 12:56:58+00:00",
      "link": "https://arxiv.org/pdf/2602.11903v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11898v1",
      "title": "Benchmark Illusion: Disagreement among LLMs and Its Scientific Consequences",
      "abstract": "Benchmarks underpin how progress in large language models (LLMs) is measured and trusted. Yet our analyses reveal that apparent convergence in benchmark accuracy can conceal deep epistemic divergence. Using two major reasoning benchmarks - MMLU-Pro and GPQA - we show that LLMs achieving comparable accuracy still disagree on 16-66% of items, and 16-38% among top-performing frontier models. These discrepancies suggest distinct error profiles for different LLMs. When such models are used for scientific data annotation and inference, their hidden disagreements propagate into research results: in re-analyses of published studies in education and political science, switching the annotation model can change estimated treatment effects by more than 80%, and in some cases reverses their sign. Together, these findings illustrate a benchmark illusion, where equal accuracy may conceal disagreement, with model choice becoming a hidden yet consequential variable for scientific reproducibility.",
      "authors": [
        "Eddie Yang",
        "Dashun Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-12 12:53:39+00:00",
      "link": "https://arxiv.org/pdf/2602.11898v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11886v1",
      "title": "LLM-based Triplet Extraction from Financial Reports",
      "abstract": "Corporate financial reports are a valuable source of structured knowledge for Knowledge Graph construction, but the lack of annotated ground truth in this domain makes evaluation difficult. We present a semi-automated pipeline for Subject-Predicate-Object triplet extraction that uses ontology-driven proxy metrics, specifically Ontology Conformance and Faithfulness, instead of ground-truth-based evaluation. We compare a static, manually engineered ontology against a fully automated, document-specific ontology induction approach across different LLMs and two corporate annual reports. The automatically induced ontology achieves 100% schema conformance in all configurations, eliminating the ontology drift observed with the manual approach. We also propose a hybrid verification strategy that combines regex matching with an LLM-as-a-judge check, reducing apparent subject hallucination rates from 65.2% to 1.6% by filtering false positives caused by coreference resolution. Finally, we identify a systematic asymmetry between subject and object hallucinations, which we attribute to passive constructions and omitted agents in financial prose.",
      "authors": [
        "Dante Wesslund",
        "Ville Stenström",
        "Pontus Linde",
        "Alexander Holmberg"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-12 12:36:10+00:00",
      "link": "https://arxiv.org/pdf/2602.11886v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11880v1",
      "title": "SynthRAR: Ring Artifacts Reduction in CT with Unrolled Network and Synthetic Data Training",
      "abstract": "Defective and inconsistent responses in CT detectors can cause ring and streak artifacts in the reconstructed images, making them unusable for clinical purposes. In recent years, several ring artifact reduction solutions have been proposed in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, leading to a high data collection cost. Furthermore, existing approaches focus exclusively on either image-space or sinogram-space correction, neglecting the intrinsic correlations from the forward operation of the CT geometry. Based on the theoretical analysis of non-ideal CT detector responses, the RAR problem is reformulated as an inverse problem by using an unrolled network, which considers non-ideal response together with linear forward-projection with CT geometry. Additionally, the intrinsic correlations of ring artifacts between the sinogram and image domains are leveraged through synthetic data derived from natural images, enabling the trained model to correct artifacts without requiring real-world clinical data. Extensive evaluations on diverse scanning geometries and anatomical regions demonstrate that the model trained on synthetic data consistently outperforms existing state-of-the-art methods.",
      "authors": [
        "Hongxu Yang",
        "Levente Lippenszky",
        "Edina Timko",
        "Gopal Avinash"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-12 12:30:14+00:00",
      "link": "https://arxiv.org/pdf/2602.11880v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11863v1",
      "title": "In-Context Function Learning in Large Language Models",
      "abstract": "Large language models (LLMs) can learn from a few demonstrations provided at inference time. We study this in-context learning phenomenon through the lens of Gaussian Processes (GPs). We build controlled experiments where models observe sequences of multivariate scalar-valued function samples drawn from known GP priors. We evaluate prediction error in relation to the number of demonstrations and compare against two principled references: (i) an empirical GP-regression learner that gives a lower bound on achievable error, and (ii) the expected error of a 1-nearest-neighbor (1-NN) rule, which gives a data-driven upper bound. Across model sizes, we find that LLM learning curves are strongly influenced by the function-generating kernels and approach the GP lower bound as the number of demonstrations increases. We then study the inductive biases of these models using a likelihood-based analysis. We find that LLM predictions are most likely under less smooth GP kernels. Finally, we explore whether post-training can shift these inductive biases and improve sample-efficiency on functions sampled from GPs with smoother kernels. We find that both reinforcement learning and supervised fine-tuning can effectively shift inductive biases in the direction of the training data. Together, our framework quantifies the extent to which LLMs behave like GP learners and provides tools for steering their inductive biases for continuous function learning tasks.",
      "authors": [
        "Elif Akata",
        "Konstantinos Voudouris",
        "Vincent Fortuin",
        "Eric Schulz"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 12:09:48+00:00",
      "link": "https://arxiv.org/pdf/2602.11863v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11862v1",
      "title": "LAMP: Implicit Language Map for Robot Navigation",
      "abstract": "Recent advances in vision-language models have made zero-shot navigation feasible, enabling robots to follow natural language instructions without requiring labeling. However, existing methods that explicitly store language vectors in grid or node-based maps struggle to scale to large environments due to excessive memory requirements and limited resolution for fine-grained planning. We introduce LAMP (Language Map), a novel neural language field-based navigation framework that learns a continuous, language-driven map and directly leverages it for fine-grained path generation. Unlike prior approaches, our method encodes language features as an implicit neural field rather than storing them explicitly at every location. By combining this implicit representation with a sparse graph, LAMP supports efficient coarse path planning and then performs gradient-based optimization in the learned field to refine poses near the goal. This coarse-to-fine pipeline, language-driven, gradient-guided optimization is the first application of an implicit language map for precise path generation. This refinement is particularly effective at selecting goal regions not directly observed by leveraging semantic similarities in the learned feature space. To further enhance robustness, we adopt a Bayesian framework that models embedding uncertainty via the von Mises-Fisher distribution, thereby improving generalization to unobserved regions. To scale to large environments, LAMP employs a graph sampling strategy that prioritizes spatial coverage and embedding confidence, retaining only the most informative nodes and substantially reducing computational overhead. Our experimental results, both in NVIDIA Isaac Sim and on a real multi-floor building, demonstrate that LAMP outperforms existing explicit methods in both memory efficiency and fine-grained goal-reaching accuracy.",
      "authors": [
        "Sibaek Lee",
        "Hyeonwoo Yu",
        "Giseop Kim",
        "Sunwook Choi"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-12 12:09:03+00:00",
      "link": "https://arxiv.org/pdf/2602.11862v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11861v1",
      "title": "A$^{2}$V-SLP: Alignment-Aware Variational Modeling for Disentangled Sign Language Production",
      "abstract": "Building upon recent structural disentanglement frameworks for sign language production, we propose A$^{2}$V-SLP, an alignment-aware variational framework that learns articulator-wise disentangled latent distributions rather than deterministic embeddings. A disentangled Variational Autoencoder (VAE) encodes ground-truth sign pose sequences and extracts articulator-specific mean and variance vectors, which are used as distributional supervision for training a non-autoregressive Transformer. Given text embeddings, the Transformer predicts both latent means and log-variances, while the VAE decoder reconstructs the final sign pose sequences through stochastic sampling at the decoding stage. This formulation maintains articulator-level representations by avoiding deterministic latent collapse through distributional latent modeling. In addition, we integrate a gloss attention mechanism to strengthen alignment between linguistic input and articulated motion. Experimental results show consistent gains over deterministic latent regression, achieving state-of-the-art back-translation performance and improved motion realism in a fully gloss-free setting.",
      "authors": [
        "Sümeyye Meryem Taşyürek",
        "Enis Mücahid İskender",
        "Hacer Yalim Keles"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-12 12:07:32+00:00",
      "link": "https://arxiv.org/pdf/2602.11861v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11855v1",
      "title": "Decision Support System for Technology Opportunity Discovery: An Application of the Schwartz Theory of Basic Values",
      "abstract": "Discovering technology opportunities (TOD) remains a critical challenge for innovation management, especially in early-stage development where consumer needs are often unclear. Existing methods frequently fail to systematically incorporate end-user perspectives, resulting in a misalignment between technological potentials and market relevance. This study proposes a novel decision support framework that bridges this gap by linking technological feasibility with fundamental human values. The framework integrates two distinct lenses: the engineering-based Technology Readiness Levels (TRL) and Schwartz's theory of basic human values. By combining these, the approach enables a structured exploration of how emerging technologies may satisfy diverse user motivations. To illustrate the framework's feasibility and insight potential, we conducted exploratory workshops with general consumers and internal experts at Sony Computer Science Laboratories, Inc., analyzing four real-world technologies (two commercial successes and two failures). Two consistent patterns emerged: (1) internal experts identified a wider value landscape than consumers (vision gap), and (2) successful technologies exhibited a broader range of associated human values (value breadth), suggesting strategic foresight may underpin market success. This study contributes both a practical tool for early-stage R\\&D decision-making and a theoretical link between value theory and innovation outcomes. While exploratory in scope, the findings highlight the promise of value-centric evaluation as a foundation for more human-centered technology opportunity discovery.",
      "authors": [
        "Ayato Kitadai",
        "Takumi Ito",
        "Yumiko Nagoh",
        "Hiroki Takahashi",
        "Masanori Fujita",
        "Sangjic Lee",
        "Fumiaki Miyahara",
        "Tetsu Natsume",
        "Nariaki Nishino"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-12 11:49:10+00:00",
      "link": "https://arxiv.org/pdf/2602.11855v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11850v2",
      "title": "Free Lunch for Stabilizing Rectified Flow Inversion",
      "abstract": "Rectified-Flow (RF)-based generative models have recently emerged as strong alternatives to traditional diffusion models, demonstrating state-of-the-art performance across various tasks. By learning a continuous velocity field that transforms simple noise into complex data, RF-based models not only enable high-quality generation, but also support training-free inversion, which facilitates downstream tasks such as reconstruction and editing. However, existing inversion methods, such as vanilla RF-based inversion, suffer from approximation errors that accumulate across timesteps, leading to unstable velocity fields and degraded reconstruction and editing quality. To address this challenge, we propose Proximal-Mean Inversion (PMI), a training-free gradient correction method that stabilizes the velocity field by guiding it toward a running average of past velocities, constrained within a theoretically derived spherical Gaussian. Furthermore, we introduce mimic-CFG, a lightweight velocity correction scheme for editing tasks, which interpolates between the current velocity and its projection onto the historical average, balancing editing effectiveness and structural consistency. Extensive experiments on PIE-Bench demonstrate that our methods significantly improve inversion stability, image reconstruction quality, and editing fidelity, while reducing the required number of neural function evaluations. Our approach achieves state-of-the-art performance on the PIE-Bench with enhanced efficiency and theoretical soundness.",
      "authors": [
        "Chenru Wang",
        "Beier Zhu",
        "Chi Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-12 11:42:36+00:00",
      "link": "https://arxiv.org/pdf/2602.11850v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11841v1",
      "title": "Improving Neural Retrieval with Attribution-Guided Query Rewriting",
      "abstract": "Neural retrievers are effective but brittle: underspecified or ambiguous queries can misdirect ranking even when relevant documents exist. Existing approaches address this brittleness only partially: LLMs rewrite queries without retriever feedback, and explainability methods identify misleading tokens but are used for post-hoc analysis. We close this loop and propose an attribution-guided query rewriting method that uses token-level explanations to guide query rewriting. For each query, we compute gradient-based token attributions from the retriever and then use these scores as soft guidance in a structured prompt to an LLM that clarifies weak or misleading query components while preserving intent. Evaluated on BEIR collections, the resulting rewrites consistently improve retrieval effectiveness over strong baselines, with larger gains for implicit or ambiguous information needs.",
      "authors": [
        "Moncef Garouani",
        "Josiane Mothe"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-12 11:34:06+00:00",
      "link": "https://arxiv.org/pdf/2602.11841v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11834v1",
      "title": "EqDeepRx: Learning a Scalable MIMO Receiver",
      "abstract": "While machine learning (ML)-based receiver algorithms have received a great deal of attention in the recent literature, they often suffer from poor scaling with increasing spatial multiplexing order and lack of explainability and generalization. This paper presents EqDeepRx, a practical deep-learning-aided multiple-input multiple-output (MIMO) receiver, which is built by augmenting linear receiver processing with carefully engineered ML blocks. At the core of the receiver model is a shared-weight DetectorNN that operates independently on each spatial stream or layer, enabling near-linear complexity scaling with respect to multiplexing order. To ensure better explainability and generalization, EqDeepRx retains conventional channel estimation and augments it with a lightweight DenoiseNN that learns frequency-domain smoothing. To reduce the dimensionality of the DetectorNN inputs, the receiver utilizes two linear equalizers in parallel: a linear minimum mean-square error (LMMSE) equalizer with interference-plus-noise covariance estimation and a regularized zero-forcing (RZF) equalizer. The parallel equalized streams are jointly consumed by the DetectorNN, after which a compact DemapperNN produces bit log-likelihood ratios for channel decoding. 5G/6G-compliant end-to-end simulations across multiple channel scenarios, pilot patterns, and inter-cell interference conditions show improved error rate and spectral efficiency over a conventional baseline, while maintaining low-complexity inference and support for different MIMO configurations without retraining.",
      "authors": [
        "Mikko Honkala",
        "Dani Korpi",
        "Elias Raninen",
        "Janne M. J. Huttunen"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "cs.LG"
      ],
      "published": "2026-02-12 11:22:30+00:00",
      "link": "https://arxiv.org/pdf/2602.11834v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11825v1",
      "title": "CAAL: Confidence-Aware Active Learning for Heteroscedastic Atmospheric Regression",
      "abstract": "Quantifying the impacts of air pollution on health and climate relies on key atmospheric particle properties such as toxicity and hygroscopicity. However, these properties typically require complex observational techniques or expensive particle-resolved numerical simulations, limiting the availability of labeled data. We therefore estimate these hard-to-measure particle properties from routinely available observations (e.g., air pollutant concentrations and meteorological conditions). Because routine observations only indirectly reflect particle composition and structure, the mapping from routine observations to particle properties is noisy and input-dependent, yielding a heteroscedastic regression setting. With a limited and costly labeling budget, the central challenge is to select which samples to measure or simulate. While active learning is a natural approach, most acquisition strategies rely on predictive uncertainty. Under heteroscedastic noise, this signal conflates reducible epistemic uncertainty with irreducible aleatoric uncertainty, causing limited budgets to be wasted in noise-dominated regions. To address this challenge, we propose a confidence-aware active learning framework (CAAL) for efficient and robust sample selection in heteroscedastic settings. CAAL consists of two components: a decoupled uncertainty-aware training objective that separately optimises the predictive mean and noise level to stabilise uncertainty estimation, and a confidence-aware acquisition function that dynamically weights epistemic uncertainty using predicted aleatoric uncertainty as a reliability signal. Experiments on particle-resolved numerical simulations and real atmospheric observations show that CAAL consistently outperforms standard AL baselines. The proposed framework provides a practical and general solution for the efficient expansion of high-cost atmospheric particle property databases.",
      "authors": [
        "Fei Jiang",
        "Jiyang Xia",
        "Junjie Yu",
        "Mingfei Sun",
        "Hugh Coe",
        "David Topping",
        "Dantong Liu",
        "Zhenhui Jessie Li",
        "Zhonghua Zheng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.ao-ph"
      ],
      "published": "2026-02-12 11:09:58+00:00",
      "link": "https://arxiv.org/pdf/2602.11825v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11812v1",
      "title": "Predicting LLM Output Length via Entropy-Guided Representations",
      "abstract": "The long-tailed distribution of sequence lengths in LLM serving and reinforcement learning (RL) sampling causes significant computational waste due to excessive padding in batched inference. Existing methods rely on auxiliary models for static length prediction, but they incur high overhead, generalize poorly, and fail in stochastic \"one-to-many\" sampling scenarios. We introduce a lightweight framework that reuses the main model's internal hidden states for efficient length prediction. Our framework features two core components: 1) Entropy-Guided Token Pooling (EGTP), which uses on-the-fly activations and token entropy for highly accurate static prediction with negligible cost, and 2) Progressive Length Prediction (PLP), which dynamically estimates the remaining length at each decoding step to handle stochastic generation. To validate our approach, we build and release ForeLen, a comprehensive benchmark with long-sequence, Chain-of-Thought, and RL data. On ForeLen, EGTP achieves state-of-the-art accuracy, reducing MAE by 29.16\\% over the best baseline. Integrating our methods with a length-aware scheduler yields significant end-to-end throughput gains. Our work provides a new technical and evaluation baseline for efficient LLM inference.",
      "authors": [
        "Huanyi Xie",
        "Yubin Chen",
        "Liangyu Wang",
        "Lijie Hu",
        "Di Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12 10:49:04+00:00",
      "link": "https://arxiv.org/pdf/2602.11812v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11810v1",
      "title": "How to Sample High Quality 3D Fractals for Action Recognition Pre-Training?",
      "abstract": "Synthetic datasets are being recognized in the deep learning realm as a valuable alternative to exhaustively labeled real data. One such synthetic data generation method is Formula Driven Supervised Learning (FDSL), which can provide an infinite number of perfectly labeled data through a formula driven approach, such as fractals or contours. FDSL does not have common drawbacks like manual labor, privacy and other ethical concerns. In this work we generate 3D fractals using 3D Iterated Function Systems (IFS) for pre-training an action recognition model. The fractals are temporally transformed to form a video that is used as a pre-training dataset for downstream task of action recognition. We find that standard methods of generating fractals are slow and produce degenerate 3D fractals. Therefore, we systematically explore alternative ways of generating fractals and finds that overly-restrictive approaches, while generating aesthetically pleasing fractals, are detrimental for downstream task performance. We propose a novel method, Targeted Smart Filtering, to address both the generation speed and fractal diversity issue. The method reports roughly 100 times faster sampling speed and achieves superior downstream performance against other 3D fractal filtering methods.",
      "authors": [
        "Marko Putak",
        "Thomas B. Moeslund",
        "Joakim Bruslund Haurum"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-12 10:48:25+00:00",
      "link": "https://arxiv.org/pdf/2602.11810v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11805v1",
      "title": "From Path Signatures to Sequential Modeling: Incremental Signature Contributions for Offline RL",
      "abstract": "Path signatures embed trajectories into tensor algebra and constitute a universal, non-parametric representation of paths; however, in the standard form, they collapse temporal structure into a single global object, which limits their suitability for decision-making problems that require step-wise reactivity. We propose the Incremental Signature Contribution (ISC) method, which decomposes truncated path signatures into a temporally ordered sequence of elements in the tensor-algebra space, corresponding to incremental contributions induced by last path increments. This reconstruction preserves the algebraic structure and expressivity of signatures, while making their internal temporal evolution explicit, enabling processing signature-based representations via sequential modeling approaches. In contrast to full signatures, ISC is inherently sensitive to instantaneous trajectory updates, which is critical for sensitive and stability-requiring control dynamics. Building on this representation, we introduce ISC-Transformer (ISCT), an offline reinforcement learning model that integrates ISC into a standard Transformer architecture without further architectural modification. We evaluate ISCT on HalfCheetah, Walker2d, Hopper, and Maze2d, including settings with delayed rewards and downgraded datasets. The results demonstrate that ISC method provides a theoretically grounded and practically effective alternative to path processing for temporally sensitive control tasks.",
      "authors": [
        "Ziyi Zhao",
        "Qingchuan Li",
        "Yuxuan Xu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 10:37:37+00:00",
      "link": "https://arxiv.org/pdf/2602.11805v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11801v1",
      "title": "SpaTeoGL: Spatiotemporal Graph Learning for Interpretable Seizure Onset Zone Analysis from Intracranial EEG",
      "abstract": "Accurate localization of the seizure onset zone (SOZ) from intracranial EEG (iEEG) is essential for epilepsy surgery but is challenged by complex spatiotemporal seizure dynamics. We propose SpaTeoGL, a spatiotemporal graph learning framework for interpretable seizure network analysis. SpaTeoGL jointly learns window-level spatial graphs capturing interactions among iEEG electrodes and a temporal graph linking time windows based on similarity of their spatial structure. The method is formulated within a smooth graph signal processing framework and solved via an alternating block coordinate descent algorithm with convergence guarantees. Experiments on a multicenter iEEG dataset with successful surgical outcomes show that SpaTeoGL is competitive with a baseline based on horizontal visibility graphs and logistic regression, while improving non-SOZ identification and providing interpretable insights into seizure onset and propagation dynamics.",
      "authors": [
        "Elham Rostami",
        "Aref Einizade",
        "Taous-Meriem Laleg-Kirati"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 10:28:38+00:00",
      "link": "https://arxiv.org/pdf/2602.11801v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11800v1",
      "title": "Temporal Difference Learning with Constrained Initial Representations",
      "abstract": "Recently, there have been numerous attempts to enhance the sample efficiency of off-policy reinforcement learning (RL) agents when interacting with the environment, including architecture improvements and new algorithms. Despite these advances, they overlook the potential of directly constraining the initial representations of the input data, which can intuitively alleviate the distribution shift issue and stabilize training. In this paper, we introduce the Tanh function into the initial layer to fulfill such a constraint. We theoretically unpack the convergence property of the temporal difference learning with the Tanh function under linear function approximation. Motivated by theoretical insights, we present our Constrained Initial Representations framework, tagged CIR, which is made up of three components: (i) the Tanh activation along with normalization methods to stabilize representations; (ii) the skip connection module to provide a linear pathway from the shallow layer to the deep layer; (iii) the convex Q-learning that allows a more flexible value estimate and mitigates potential conservatism. Empirical results show that CIR exhibits strong performance on numerous continuous control tasks, even being competitive or surpassing existing strong baseline methods.",
      "authors": [
        "Jiafei Lyu",
        "Jingwen Yang",
        "Zhongjian Qiao",
        "Runze Liu",
        "Zeyuan Liu",
        "Deheng Ye",
        "Zongqing Lu",
        "Xiu Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 10:27:57+00:00",
      "link": "https://arxiv.org/pdf/2602.11800v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11794v1",
      "title": "Latent-Variable Learning of SPDEs via Wiener Chaos",
      "abstract": "We study the problem of learning the law of linear stochastic partial differential equations (SPDEs) with additive Gaussian forcing from spatiotemporal observations. Most existing deep learning approaches either assume access to the driving noise or initial condition, or rely on deterministic surrogate models that fail to capture intrinsic stochasticity. We propose a structured latent-variable formulation that requires only observations of solution realizations and learns the underlying randomly forced dynamics. Our approach combines a spectral Galerkin projection with a truncated Wiener chaos expansion, yielding a principled separation between deterministic evolution and stochastic forcing. This reduces the infinite-dimensional SPDE to a finite system of parametrized ordinary differential equations governing latent temporal dynamics. The latent dynamics and stochastic forcing are jointly inferred through variational learning, allowing recovery of stochastic structure without explicit observation or simulation of noise during training. Empirical evaluation on synthetic data demonstrates state-of-the-art performance under comparable modeling assumptions across bounded and unbounded one-dimensional spatial domains.",
      "authors": [
        "Sebastian Zeng",
        "Andreas Petersson",
        "Wolfgang Bock"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 10:19:43+00:00",
      "link": "https://arxiv.org/pdf/2602.11794v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11785v1",
      "title": "Safe Fairness Guarantees Without Demographics in Classification: Spectral Uncertainty Set Perspective",
      "abstract": "As automated classification systems become increasingly prevalent, concerns have emerged over their potential to reinforce and amplify existing societal biases. In the light of this issue, many methods have been proposed to enhance the fairness guarantees of classifiers. Most of the existing interventions assume access to group information for all instances, a requirement rarely met in practice. Fairness without access to demographic information has often been approached through robust optimization techniques,which target worst-case outcomes over a set of plausible distributions known as the uncertainty set. However, their effectiveness is strongly influenced by the chosen uncertainty set. In fact, existing approaches often overemphasize outliers or overly pessimistic scenarios, compromising both overall performance and fairness. To overcome these limitations, we introduce SPECTRE, a minimax-fair method that adjusts the spectrum of a simple Fourier feature mapping and constrains the extent to which the worst-case distribution can deviate from the empirical distribution. We perform extensive experiments on the American Community Survey datasets involving 20 states. The safeness of SPECTRE comes as it provides the highest average values on fairness guarantees together with the smallest interquartile range in comparison to state-of-the-art approaches, even compared to those with access to demographic group information. In addition, we provide a theoretical analysis that derives computable bounds on the worst-case error for both individual groups and the overall population, as well as characterizes the worst-case distributions responsible for these extremal performances",
      "authors": [
        "Ainhize Barrainkua",
        "Santiago Mazuelas",
        "Novi Quadrianto",
        "Jose A. Lozano"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-12 10:08:08+00:00",
      "link": "https://arxiv.org/pdf/2602.11785v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11780v1",
      "title": "RELATE: A Reinforcement Learning-Enhanced LLM Framework for Advertising Text Generation",
      "abstract": "In online advertising, advertising text plays a critical role in attracting user engagement and driving advertiser value. Existing industrial systems typically follow a two-stage paradigm, where candidate texts are first generated and subsequently aligned with online performance metrics such as click-through rate(CTR). This separation often leads to misaligned optimization objectives and low funnel efficiency, limiting global optimality.   To address these limitations, we propose RELATE, a reinforcement learning-based end-to-end framework that unifies generation and objective alignment within a single model. Instead of decoupling text generation from downstream metric alignment, RELATE integrates performance and compliance objectives directly into the generation process via policy learning. To better capture ultimate advertiser value beyond click-level signals, We incorporate conversion-oriented metrics into the objective and jointly model them with compliance constraints as multi-dimensional rewards, enabling the model to generate high-quality ad texts that improve conversion performance under policy constraints.   Extensive experiments on large-scale industrial datasets demonstrate that RELATE consistently outperforms baselines. Furthermore, online deployment on a production advertising platform yields statistically significant improvements in click-through conversion rate(CTCVR) under strict policy constraints, validating the robustness and real-world effectiveness of the proposed framework.",
      "authors": [
        "Jinfang Wang",
        "Jiajie Liu",
        "Jianwei Wu",
        "Ziqin Luo",
        "Zhen Chen",
        "Chunlei Li",
        "Biao Han",
        "Tao Deng",
        "Yi Li",
        "Shuanglong Li",
        "Lin Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12 10:00:55+00:00",
      "link": "https://arxiv.org/pdf/2602.11780v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11779v1",
      "title": "Temperature as a Meta-Policy: Adaptive Temperature in LLM Reinforcement Learning",
      "abstract": "Temperature is a crucial hyperparameter in large language models (LLMs), controlling the trade-off between exploration and exploitation during text generation. High temperatures encourage diverse but noisy outputs, while low temperatures produce focused outputs but may cause premature convergence. Yet static or heuristic temperature schedules fail to adapt to the dynamic demands of reinforcement learning (RL) throughout training, often limiting policy improvement. We propose Temperature Adaptive Meta Policy Optimization (TAMPO), a new framework that recasts temperature control as a learnable meta-policy. TAMPO operates through a hierarchical two-loop process. In the inner loop, the LLM policy is updated (e.g., using GRPO) with trajectories sampled at the temperature selected by the meta-policy. In the outer loop, meta-policy updates the distribution over candidate temperatures by rewarding those that maximize the likelihood of high-advantage trajectories. This trajectory-guided, reward-driven mechanism enables online adaptation without additional rollouts, directly aligning exploration with policy improvement. On five mathematical reasoning benchmarks, TAMPO outperforms baselines using fixed or heuristic temperatures, establishing temperature as an effective learnable meta-policy for adaptive exploration in LLM reinforcement learning. Accepted at ICLR 2026.",
      "authors": [
        "Haoran Dang",
        "Cuiling Lan",
        "Hai Wan",
        "Xibin Zhao",
        "Yan Lu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 09:59:58+00:00",
      "link": "https://arxiv.org/pdf/2602.11779v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11772v1",
      "title": "Optimizing edge weights in the inverse eigenvector centrality problem",
      "abstract": "In this paper we study the inverse eigenvector centrality problem on directed graphs: given a prescribed node centrality profile, we seek edge weights that realize it. Since this inverse problem generally admits infinitely many solutions, we explicitly characterize the feasible set of admissible weights and introduce six optimization problems defined over this set, each corresponding to a different weight-selection strategy. These formulations provide representative solutions of the inverse problem and enable a systematic comparison of how different strategies influence the structure of the resulting weighted networks. We illustrate our framework using several real-world social network datasets, showing that different strategies produce different weighted graph structures while preserving the prescribed centrality. The results highlight the flexibility of the proposed approach and its potential applications in network reconstruction, and network design or network manipulation.",
      "authors": [
        "Mauro Passacantando",
        "Fabio Raciti"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI",
        "math.OC"
      ],
      "published": "2026-02-12 09:52:50+00:00",
      "link": "https://arxiv.org/pdf/2602.11772v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11769v1",
      "title": "Light4D: Training-Free Extreme Viewpoint 4D Video Relighting",
      "abstract": "Recent advances in diffusion-based generative models have established a new paradigm for image and video relighting. However, extending these capabilities to 4D relighting remains challenging, due primarily to the scarcity of paired 4D relighting training data and the difficulty of maintaining temporal consistency across extreme viewpoints. In this work, we propose Light4D, a novel training-free framework designed to synthesize consistent 4D videos under target illumination, even under extreme viewpoint changes. First, we introduce Disentangled Flow Guidance, a time-aware strategy that effectively injects lighting control into the latent space while preserving geometric integrity. Second, to reinforce temporal consistency, we develop Temporal Consistent Attention within the IC-Light architecture and further incorporate deterministic regularization to eliminate appearance flickering. Extensive experiments demonstrate that our method achieves competitive performance in temporal consistency and lighting fidelity, robustly handling camera rotations from -90 to 90. Code: https://github.com/AIGeeksGroup/Light4D. Website: https://aigeeksgroup.github.io/Light4D.",
      "authors": [
        "Zhenghuang Wu",
        "Kang Chen",
        "Zeyu Zhang",
        "Hao Tang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 09:50:13+00:00",
      "link": "https://arxiv.org/pdf/2602.11769v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11767v1",
      "title": "TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents",
      "abstract": "Advances in large language models (LLMs) are driving a shift toward using reinforcement learning (RL) to train agents from iterative, multi-turn interactions across tasks. However, multi-turn RL remains challenging as rewards are often sparse or delayed, and environments can be stochastic. In this regime, naive trajectory sampling can hinder exploitation and induce mode collapse. We propose TSR (Trajectory-Search Rollouts), a training-time approach that repurposes test-time scaling ideas for improved per-turn rollout generation. TSR performs lightweight tree-style search to construct high-quality trajectories by selecting high-scoring actions at each turn using task-specific feedback. This improves rollout quality and stabilizes learning while leaving the underlying optimization objective unchanged, making TSR optimizer-agnostic. We instantiate TSR with best-of-N, beam, and shallow lookahead search, and pair it with PPO and GRPO, achieving up to 15% performance gains and more stable learning on Sokoban, FrozenLake, and WebShop tasks at a one-time increase in training compute. By moving search from inference time to the rollout stage of training, TSR provides a simple and general mechanism for stronger multi-turn agent learning, complementary to existing frameworks and rejection-sampling-style selection methods.",
      "authors": [
        "Aladin Djuhera",
        "Swanand Ravindra Kadhe",
        "Farhan Ahmed",
        "Holger Boche"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-12 09:49:24+00:00",
      "link": "https://arxiv.org/pdf/2602.11767v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11760v1",
      "title": "Aggregate Models, Not Explanations: Improving Feature Importance Estimation",
      "abstract": "Feature-importance methods show promise in transforming machine learning models from predictive engines into tools for scientific discovery. However, due to data sampling and algorithmic stochasticity, expressive models can be unstable, leading to inaccurate variable importance estimates and undermining their utility in critical biomedical applications. Although ensembling offers a solution, deciding whether to explain a single ensemble model or aggregate individual model explanations is difficult due to the nonlinearity of importance measures and remains largely understudied. Our theoretical analysis, developed under assumptions accommodating complex state-of-the-art ML models, reveals that this choice is primarily driven by the model's excess risk. In contrast to prior literature, we show that ensembling at the model level provides more accurate variable-importance estimates, particularly for expressive models, by reducing this leading error term. We validate these findings on classical benchmarks and a large-scale proteomic study from the UK Biobank.",
      "authors": [
        "Joseph Paillard",
        "Angel Reyero Lobo",
        "Denis A. Engemann",
        "Bertrand Thirion"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-12 09:36:03+00:00",
      "link": "https://arxiv.org/pdf/2602.11760v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11759v1",
      "title": "TUBO: A Tailored ML Framework for Reliable Network Traffic Forecasting",
      "abstract": "Traffic forecasting based network operation optimization and management offers enormous promise but also presents significant challenges from traffic forecasting perspective. While deep learning models have proven to be relatively more effective than traditional statistical methods for time series forecasting, their reliability is not satisfactory due to their inability to effectively handle unique characteristics of network traffic. In particular, the burst and complex traffic patterns makes the existing models less reliable, as each type of deep learning model has limited capability in capturing traffic patterns. To address this issue, we introduce TUBO, a novel machine learning framework custom designed for reliable network traffic forecasting. TUBO features two key components: burst processing for handling significant traffic fluctuations and model selection for adapting to varying traffic patterns using a pool of models. A standout feature of TUBO is its ability to provide deterministic predictions along with quantified uncertainty, which serves as a cue for identifying the most reliable forecasts. Evaluations on three real-world network demand matrix (DM) datasets (Abilene, GEANT, and CERNET) show that TUBO significantly outperforms existing methods on forecasting accuracy (by 4 times), and also achieves up to 94% accuracy in burst occurrence forecasting. Furthermore, we also consider traffic demand forecasting based proactive traffic engineering (TE) as a downstream use case. Our results show that compared to reactive approaches and proactive TE using the best existing DM forecasting methods, proactive TE powered by TUBO improves aggregated throughput by 9 times and 3 times, respectively.",
      "authors": [
        "Zhihang Yuan",
        "Leyang Xue",
        "Waleed Ahsan",
        "Mahesh K. Marina"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 09:35:51+00:00",
      "link": "https://arxiv.org/pdf/2602.11759v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11757v1",
      "title": "Code2Worlds: Empowering Coding LLMs for 4D World Generation",
      "abstract": "Achieving spatial intelligence requires moving beyond visual plausibility to build world simulators grounded in physical laws. While coding LLMs have advanced static 3D scene generation, extending this paradigm to 4D dynamics remains a critical frontier. This task presents two fundamental challenges: multi-scale context entanglement, where monolithic generation fails to balance local object structures with global environmental layouts; and a semantic-physical execution gap, where open-loop code generation leads to physical hallucinations lacking dynamic fidelity. We introduce Code2Worlds, a framework that formulates 4D generation as language-to-simulation code generation. First, we propose a dual-stream architecture that disentangles retrieval-augmented object generation from hierarchical environmental orchestration. Second, to ensure dynamic fidelity, we establish a physics-aware closed-loop mechanism in which a PostProcess Agent scripts dynamics, coupled with a VLM-Motion Critic that performs self-reflection to iteratively refine simulation code. Evaluations on the Code4D benchmark show Code2Worlds outperforms baselines with a 41% SGS gain and 49% higher Richness, while uniquely generating physics-aware dynamics absent in prior static methods. Code: https://github.com/AIGeeksGroup/Code2Worlds. Website: https://aigeeksgroup.github.io/Code2Worlds.",
      "authors": [
        "Yi Zhang",
        "Yunshuang Wang",
        "Zeyu Zhang",
        "Hao Tang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 09:34:28+00:00",
      "link": "https://arxiv.org/pdf/2602.11757v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11743v1",
      "title": "Adaptive Debiasing Tsallis Entropy for Test-Time Adaptation",
      "abstract": "Mainstream Test-Time Adaptation (TTA) methods for adapting vision-language models, e.g., CLIP, typically rely on Shannon Entropy (SE) at test time to measure prediction uncertainty and inconsistency. However, since CLIP has a built-in bias from pretraining on highly imbalanced web-crawled data, SE inevitably results in producing biased estimates of uncertainty entropy. To address this issue, we notably find and demonstrate that Tsallis Entropy (TE), a generalized form of SE, is naturally suited for characterizing biased distributions by introducing a non-extensive parameter q, with the performance of SE serving as a lower bound for TE. Building upon this, we generalize TE into Adaptive Debiasing Tsallis Entropy (ADTE) for TTA, customizing a class-specific parameter q^l derived by normalizing the estimated label bias from continuously incoming test instances, for each category. This adaptive approach allows ADTE to accurately select high-confidence views and seamlessly integrate with a label adjustment strategy to enhance adaptation, without introducing distribution-specific hyperparameter tuning. Besides, our investigation reveals that both TE and ADTE can serve as direct, advanced alternatives to SE in TTA, without any other modifications. Experimental results show that ADTE outperforms state-of-the-art methods on ImageNet and its five variants, and achieves the highest average performance on 10 cross-domain benchmarks, regardless of the model architecture or text prompts used. Our code is available at https://github.com/Jinx630/ADTE.",
      "authors": [
        "Xiangyu Wu",
        "Dongming Jiang",
        "Feng Yu",
        "Yueying Tian",
        "Jiaqi Tang",
        "Qing-Guo Chen",
        "Yang Yang",
        "Jianfeng Lu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 09:12:22+00:00",
      "link": "https://arxiv.org/pdf/2602.11743v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11738v1",
      "title": "U-Former ODE: Fast Probabilistic Forecasting of Irregular Time Series",
      "abstract": "Probabilistic forecasting of irregularly sampled time series is crucial in domains such as healthcare and finance, yet it remains a formidable challenge. Existing Neural Controlled Differential Equation (Neural CDE) approaches, while effective at modelling continuous dynamics, suffer from slow, inherently sequential computation, which restricts scalability and limits access to global context. We introduce UFO (U-Former ODE), a novel architecture that seamlessly integrates the parallelizable, multiscale feature extraction of U-Nets, the powerful global modelling of Transformers, and the continuous-time dynamics of Neural CDEs. By constructing a fully causal, parallelizable model, UFO achieves a global receptive field while retaining strong sensitivity to local temporal dynamics. Extensive experiments on five standard benchmarks -- covering both regularly and irregularly sampled time series -- demonstrate that UFO consistently outperforms ten state-of-the-art neural baselines in predictive accuracy. Moreover, UFO delivers up to 15$\\times$ faster inference compared to conventional Neural CDEs, with consistently strong performance on long and highly multivariate sequences.",
      "authors": [
        "Ilya Kuleshov",
        "Alexander Marusov",
        "Alexey Zaytsev"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 09:05:09+00:00",
      "link": "https://arxiv.org/pdf/2602.11738v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11735v1",
      "title": "AC-MASAC: An Attentive Curriculum Learning Framework for Heterogeneous UAV Swarm Coordination",
      "abstract": "Cooperative path planning for heterogeneous UAV swarms poses significant challenges for Multi-Agent Reinforcement Learning (MARL), particularly in handling asymmetric inter-agent dependencies and addressing the risks of sparse rewards and catastrophic forgetting during training. To address these issues, this paper proposes an attentive curriculum learning framework (AC-MASAC). The framework introduces a role-aware heterogeneous attention mechanism to explicitly model asymmetric dependencies. Moreover, a structured curriculum strategy is designed, integrating hierarchical knowledge transfer and stage-proportional experience replay to address the issues of sparse rewards and catastrophic forgetting. The proposed framework is validated on a custom multi-agent simulation platform, and the results show that our method has significant advantages over other advanced methods in terms of Success Rate, Formation Keeping Rate, and Success-weighted Mission Time. The code is available at \\textcolor{red}{https://github.com/Wanhao-Liu/AC-MASAC}.",
      "authors": [
        "Wanhao Liu",
        "Junhong Dai",
        "Yixuan Zhang",
        "Shengyun Yin",
        "Panshuo Li"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-12 09:03:34+00:00",
      "link": "https://arxiv.org/pdf/2602.11735v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11733v1",
      "title": "Adapting Vision-Language Models for E-commerce Understanding at Scale",
      "abstract": "E-commerce product understanding demands by nature, strong multimodal comprehension from text, images, and structured attributes. General-purpose Vision-Language Models (VLMs) enable generalizable multimodal latent modelling, yet there is no documented, well-known strategy for adapting them to the attribute-centric, multi-image, and noisy nature of e-commerce data, without sacrificing general performance. In this work, we show through a large-scale experimental study, how targeted adaptation of general VLMs can substantially improve e-commerce performance while preserving broad multimodal capabilities. Furthermore, we propose a novel extensive evaluation suite covering deep product understanding, strict instruction following, and dynamic attribute extraction.",
      "authors": [
        "Matteo Nulli",
        "Vladimir Orshulevich",
        "Tala Bazazo",
        "Christian Herold",
        "Michael Kozielski",
        "Marcin Mazur",
        "Szymon Tuzel",
        "Cees G. M. Snoek",
        "Seyyed Hadi Hashemi",
        "Omar Javed",
        "Yannick Versley",
        "Shahram Khadivi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-12 08:59:22+00:00",
      "link": "https://arxiv.org/pdf/2602.11733v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11730v1",
      "title": "STVG-R1: Incentivizing Instance-Level Reasoning and Grounding in Videos via Reinforcement Learning",
      "abstract": "In vision-language models (VLMs), misalignment between textual descriptions and visual coordinates often induces hallucinations. This issue becomes particularly severe in dense prediction tasks such as spatial-temporal video grounding (STVG). Prior approaches typically focus on enhancing visual-textual alignment or attaching auxiliary decoders. However, these strategies inevitably introduce additional trainable modules, leading to significant annotation costs and computational overhead. In this work, we propose a novel visual prompting paradigm that avoids the difficult problem of aligning coordinates across modalities. Specifically, we reformulate per-frame coordinate prediction as a compact instance-level identification problem by assigning each object a unique, temporally consistent ID. These IDs are embedded into the video as visual prompts, providing explicit and interpretable inputs to the VLMs. Furthermore, we introduce STVG-R1, the first reinforcement learning framework for STVG, which employs a task-driven reward to jointly optimize temporal accuracy, spatial consistency, and structural format regularization. Extensive experiments on six benchmarks demonstrate the effectiveness of our approach. STVG-R1 surpasses the baseline Qwen2.5-VL-7B by a remarkable margin of 20.9% on m_IoU on the HCSTVG-v2 benchmark, establishing a new state of the art (SOTA). Surprisingly, STVG-R1 also exhibits strong zero-shot generalization to multi-object referring video object segmentation tasks, achieving a SOTA 47.3% J&F on MeViS.",
      "authors": [
        "Xiaowen Zhang",
        "Zhi Gao",
        "Licheng Jiao",
        "Lingling Li",
        "Qing Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 08:53:32+00:00",
      "link": "https://arxiv.org/pdf/2602.11730v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11729v1",
      "title": "Cross-Architecture Model Diffing with Crosscoders: Unsupervised Discovery of Differences Between LLMs",
      "abstract": "Model diffing, the process of comparing models' internal representations to identify their differences, is a promising approach for uncovering safety-critical behaviors in new models. However, its application has so far been primarily focused on comparing a base model with its finetune. Since new LLM releases are often novel architectures, cross-architecture methods are essential to make model diffing widely applicable. Crosscoders are one solution capable of cross-architecture model diffing but have only ever been applied to base vs finetune comparisons. We provide the first application of crosscoders to cross-architecture model diffing and introduce Dedicated Feature Crosscoders (DFCs), an architectural modification designed to better isolate features unique to one model. Using this technique, we find in an unsupervised fashion features including Chinese Communist Party alignment in Qwen3-8B and Deepseek-R1-0528-Qwen3-8B, American exceptionalism in Llama3.1-8B-Instruct, and a copyright refusal mechanism in GPT-OSS-20B. Together, our results work towards establishing cross-architecture crosscoder model diffing as an effective method for identifying meaningful behavioral differences between AI models.",
      "authors": [
        "Thomas Jiralerspong",
        "Trenton Bricken"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "published": "2026-02-12 08:53:25+00:00",
      "link": "https://arxiv.org/pdf/2602.11729v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11714v1",
      "title": "GSO-SLAM: Bidirectionally Coupled Gaussian Splatting and Direct Visual Odometry",
      "abstract": "We propose GSO-SLAM, a real-time monocular dense SLAM system that leverages Gaussian scene representation. Unlike existing methods that couple tracking and mapping with a unified scene, incurring computational costs, or loosely integrate them with well-structured tracking frameworks, introducing redundancies, our method bidirectionally couples Visual Odometry (VO) and Gaussian Splatting (GS). Specifically, our approach formulates joint optimization within an Expectation-Maximization (EM) framework, enabling the simultaneous refinement of VO-derived semi-dense depth estimates and the GS representation without additional computational overhead. Moreover, we present Gaussian Splat Initialization, which utilizes image information, keyframe poses, and pixel associations from VO to produce close approximations to the final Gaussian scene, thereby eliminating the need for heuristic methods. Through extensive experiments, we validate the effectiveness of our method, showing that it not only operates in real time but also achieves state-of-the-art geometric/photometric fidelity of the reconstructed scene and tracking accuracy.",
      "authors": [
        "Jiung Yeon",
        "Seongbo Ha",
        "Hyeonwoo Yu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "published": "2026-02-12 08:44:32+00:00",
      "link": "https://arxiv.org/pdf/2602.11714v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11705v1",
      "title": "TG-Field: Geometry-Aware Radiative Gaussian Fields for Tomographic Reconstruction",
      "abstract": "3D Gaussian Splatting (3DGS) has revolutionized 3D scene representation with superior efficiency and quality. While recent adaptations for computed tomography (CT) show promise, they struggle with severe artifacts under highly sparse-view projections and dynamic motions. To address these challenges, we propose Tomographic Geometry Field (TG-Field), a geometry-aware Gaussian deformation framework tailored for both static and dynamic CT reconstruction. A multi-resolution hash encoder is employed to capture local spatial priors, regularizing primitive parameters under ultra-sparse settings. We further extend the framework to dynamic reconstruction by introducing time-conditioned representations and a spatiotemporal attention block to adaptively aggregate features, thereby resolving spatiotemporal ambiguities and enforcing temporal coherence. In addition, a motion-flow network models fine-grained respiratory motion to track local anatomical deformations. Extensive experiments on synthetic and real-world datasets demonstrate that TG-Field consistently outperforms existing methods, achieving state-of-the-art reconstruction accuracy under highly sparse-view conditions.",
      "authors": [
        "Yuxiang Zhong",
        "Jun Wei",
        "Chaoqi Chen",
        "Senyou An",
        "Hui Huang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 08:33:01+00:00",
      "link": "https://arxiv.org/pdf/2602.11705v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11706v1",
      "title": "LLM-Driven 3D Scene Generation of Agricultural Simulation Environments",
      "abstract": "Procedural generation techniques in 3D rendering engines have revolutionized the creation of complex environments, reducing reliance on manual design. Recent approaches using Large Language Models (LLMs) for 3D scene generation show promise but often lack domain-specific reasoning, verification mechanisms, and modular design. These limitations lead to reduced control and poor scalability. This paper investigates the use of LLMs to generate agricultural synthetic simulation environments from natural language prompts, specifically to address the limitations of lacking domain-specific reasoning, verification mechanisms, and modular design. A modular multi-LLM pipeline was developed, integrating 3D asset retrieval, domain knowledge injection, and code generation for the Unreal rendering engine using its API. This results in a 3D environment with realistic planting layouts and environmental context, all based on the input prompt and the domain knowledge. To enhance accuracy and scalability, the system employs a hybrid strategy combining LLM optimization techniques such as few-shot prompting, Retrieval-Augmented Generation (RAG), finetuning, and validation. Unlike monolithic models, the modular architecture enables structured data handling, intermediate verification, and flexible expansion. The system was evaluated using structured prompts and semantic accuracy metrics. A user study assessed realism and familiarity against real-world images, while an expert comparison demonstrated significant time savings over manual scene design. The results confirm the effectiveness of multi-LLM pipelines in automating domain-specific 3D scene generation with improved reliability and precision. Future work will explore expanding the asset hierarchy, incorporating real-time generation, and adapting the pipeline to other simulation domains beyond agriculture.",
      "authors": [
        "Arafa Yoncalik",
        "Wouter Jansen",
        "Nico Huebel",
        "Mohammad Hasan Rahmani",
        "Jan Steckel"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-02-12 08:33:01+00:00",
      "link": "https://arxiv.org/pdf/2602.11706v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11700v1",
      "title": "TabSieve: Explicit In-Table Evidence Selection for Tabular Prediction",
      "abstract": "Tabular prediction can benefit from in-table rows as few-shot evidence, yet existing tabular models typically perform instance-wise inference and LLM-based prompting is often brittle. Models do not consistently leverage relevant rows, and noisy context can degrade performance. To address this challenge, we propose TabSieve, a select-then-predict framework that makes evidence usage explicit and auditable. Given a table and a query row, TabSieve first selects a small set of informative rows as evidence and then predicts the missing target conditioned on the selected evidence. To enable this capability, we construct TabSieve-SFT-40K by synthesizing high-quality reasoning trajectories from 331 real tables using a strong teacher model with strict filtering. Furthermore, we introduce TAB-GRPO, a reinforcement learning recipe that jointly optimizes evidence selection and prediction correctness with separate rewards, and stabilizes mixed regression and classification training via dynamic task-advantage balancing. Experiments on a held-out benchmark of 75 classification and 52 regression tables show that TabSieve consistently improves performance across shot budgets, with average gains of 2.92% on classification and 4.45% on regression over the second-best baseline. Further analysis indicates that TabSieve concentrates more attention on the selected evidence, which improves robustness to noisy context.",
      "authors": [
        "Yongyao Wang",
        "Ziqi Miao",
        "Lu Yang",
        "Haonan Jia",
        "Wenting Yan",
        "Chen Qian",
        "Lijun Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-12 08:28:58+00:00",
      "link": "https://arxiv.org/pdf/2602.11700v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11679v1",
      "title": "Provable Offline Reinforcement Learning for Structured Cyclic MDPs",
      "abstract": "We introduce a novel cyclic Markov decision process (MDP) framework for multi-step decision problems with heterogeneous stage-specific dynamics, transitions, and discount factors across the cycle. In this setting, offline learning is challenging: optimizing a policy at any stage shifts the state distributions of subsequent stages, propagating mismatch across the cycle. To address this, we propose a modular structural framework that decomposes the cyclic process into stage-wise sub-problems. While generally applicable, we instantiate this principle as CycleFQI, an extension of fitted Q-iteration enabling theoretical analysis and interpretation. It uses a vector of stage-specific Q-functions, tailored to each stage, to capture within-stage sequences and transitions between stages. This modular design enables partial control, allowing some stages to be optimized while others follow predefined policies. We establish finite-sample suboptimality error bounds and derive global convergence rates under Besov regularity, demonstrating that CycleFQI mitigates the curse of dimensionality compared to monolithic baselines. Additionally, we propose a sieve-based method for asymptotic inference of optimal policy values under a margin condition. Experiments on simulated and real-world Type 1 Diabetes data sets demonstrate CycleFQI's effectiveness.",
      "authors": [
        "Kyungbok Lee",
        "Angelica Cristello Sarteau",
        "Michael R. Kosorok"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.OC",
        "stat.ME"
      ],
      "published": "2026-02-12 07:53:33+00:00",
      "link": "https://arxiv.org/pdf/2602.11679v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11678v1",
      "title": "Beyond Pixels: Vector-to-Graph Transformation for Reliable Schematic Auditing",
      "abstract": "Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual understanding, yet they suffer from a critical limitation: structural blindness. Even state-of-the-art models fail to capture topology and symbolic logic in engineering schematics, as their pixel-driven paradigm discards the explicit vector-defined relations needed for reasoning. To overcome this, we propose a Vector-to-Graph (V2G) pipeline that converts CAD diagrams into property graphs where nodes represent components and edges encode connectivity, making structural dependencies explicit and machine-auditable. On a diagnostic benchmark of electrical compliance checks, V2G yields large accuracy gains across all error categories, while leading MLLMs remain near chance level. These results highlight the systemic inadequacy of pixel-based methods and demonstrate that structure-aware representations provide a reliable path toward practical deployment of multimodal AI in engineering domains. To facilitate further research, we release our benchmark and implementation at https://github.com/gm-embodied/V2G-Audit.",
      "authors": [
        "Chengwei Ma",
        "Zhen Tian",
        "Zhou Zhou",
        "Zhixian Xu",
        "Xiaowei Zhu",
        "Xia Hua",
        "Si Shi",
        "F. Richard Yu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-12 07:50:49+00:00",
      "link": "https://arxiv.org/pdf/2602.11678v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11673v1",
      "title": "RI-Mamba: Rotation-Invariant Mamba for Robust Text-to-Shape Retrieval",
      "abstract": "3D assets have rapidly expanded in quantity and diversity due to the growing popularity of virtual reality and gaming. As a result, text-to-shape retrieval has become essential in facilitating intuitive search within large repositories. However, existing methods require canonical poses and support few object categories, limiting their real-world applicability where objects can belong to diverse classes and appear in random orientations. To address this challenge, we propose RI-Mamba, the first rotation-invariant state-space model for point clouds. RI-Mamba defines global and local reference frames to disentangle pose from geometry and uses Hilbert sorting to construct token sequences with meaningful geometric structure while maintaining rotation invariance. We further introduce a novel strategy to compute orientational embeddings and reintegrate them via feature-wise linear modulation, effectively recovering spatial context and enhancing model expressiveness. Our strategy is inherently compatible with state-space models and operates in linear time. To scale up retrieval, we adopt cross-modal contrastive learning with automated triplet generation, allowing training on diverse datasets without manual annotation. Extensive experiments demonstrate RI-Mamba's superior representational capacity and robustness, achieving state-of-the-art performance on the OmniObject3D benchmark across more than 200 object categories under arbitrary orientations. Our code will be made available at https://github.com/ndkhanh360/RI-Mamba.git.",
      "authors": [
        "Khanh Nguyen",
        "Dasith de Silva Edirimuni",
        "Ghulam Mubashar Hassan",
        "Ajmal Mian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 07:46:03+00:00",
      "link": "https://arxiv.org/pdf/2602.11673v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11671v1",
      "title": "Do Not Treat Code as Natural Language: Implications for Repository-Level Code Generation and Beyond",
      "abstract": "Large language models for code (CodeLLMs) have demonstrated remarkable success in standalone code completion and generation, sometimes even surpassing human performance, yet their effectiveness diminishes in repository-level settings where cross-file dependencies and structural context are essential. Existing Retrieval-Augmented Generation (RAG) approaches often borrow strategies from NLP, relying on chunking-based indexing and similarity-based retrieval. Chunking results in the loss of coherence between code units and overlooks structural relationships, while similarity-driven methods frequently miss functionally relevant dependencies such as helper functions, classes, or global variables. To address these limitations, we present Hydra, a repository-level code generation framework that treats code as structured code rather than natural language. Our approach introduces (i) a structure-aware indexing strategy that represents repositories as hierarchical trees of functions, classes, and variables, preserving code structure and dependencies, (ii) a lightweight dependency-aware retriever (DAR) that explicitly identifies and retrieves the true dependencies required by a target function, and (iii) a hybrid retrieval mechanism that combines DAR with similarity-based retrieval to provide both essential building blocks and practical usage examples. Extensive experiments on the challenging DevEval and RepoExec benchmarks, both requiring function implementation from real-world repositories with complex large repository context, show that Hydra achieves state-of-the-art performance across open- and closed-source CodeLLMs. Notably, our method establishes a new state of the art in repository-level code generation, surpassing strongest baseline by over 5% in Pass@1 and even enabling smaller models to match or exceed the performance of much larger ones that rely on existing retrievers.",
      "authors": [
        "Minh Le-Anh",
        "Huyen Nguyen",
        "Khanh An Tran",
        "Nam Le Hai",
        "Linh Ngo Van",
        "Nghi D. Q. Bui",
        "Bach Le"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-12 07:44:00+00:00",
      "link": "https://arxiv.org/pdf/2602.11671v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11669v1",
      "title": "Egocentric Gaze Estimation via Neck-Mounted Camera",
      "abstract": "This paper introduces neck-mounted view gaze estimation, a new task that estimates user gaze from the neck-mounted camera perspective. Prior work on egocentric gaze estimation, which predicts device wearer's gaze location within the camera's field of view, mainly focuses on head-mounted cameras while alternative viewpoints remain underexplored. To bridge this gap, we collect the first dataset for this task, consisting of approximately 4 hours of video collected from 8 participants during everyday activities. We evaluate a transformer-based gaze estimation model, GLC, on the new dataset and propose two extensions: an auxiliary gaze out-of-bound classification task and a multi-view co-learning approach that jointly trains head-view and neck-view models using a geometry-aware auxiliary loss. Experimental results show that incorporating gaze out-of-bound classification improves performance over standard fine-tuning, while the co-learning approach does not yield gains. We further analyze these results and discuss implications for neck-mounted gaze estimation.",
      "authors": [
        "Haoyu Huang",
        "Yoichi Sato"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 07:41:27+00:00",
      "link": "https://arxiv.org/pdf/2602.11669v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11668v1",
      "title": "Explainable Machine-Learning based Detection of Knee Injuries in Runners",
      "abstract": "Running is a widely practiced activity but shows a high incidence of knee injuries, especially Patellofemoral Pain Syndrome (PFPS) and Iliotibial Band Syndrome (ITBS). Identifying gait patterns linked to these injuries can improve clinical decision-making, which requires precise systems capable of capturing and analyzing temporal kinematic data.   This study uses optical motion capture systems to enhance detection of injury-related running patterns. We analyze a public dataset of 839 treadmill recordings from healthy and injured runners to evaluate how effectively these systems capture dynamic parameters relevant to injury classification. The focus is on the stance phase, using joint and segment angle time series and discrete point values.   Three classification tasks are addressed: healthy vs. injured, healthy vs. PFPS, and healthy vs. ITBS. We examine different feature spaces, from traditional point-based metrics to full stance-phase time series and hybrid representations. Multiple models are tested, including classical algorithms (K-Nearest Neighbors, Gaussian Processes, Decision Trees) and deep learning architectures (CNNs, LSTMs).   Performance is evaluated with accuracy, precision, recall, and F1-score. Explainability tools such as Shapley values, saliency maps, and Grad-CAM are used to interpret model behavior. Results show that combining time series with point values substantially improves detection. Deep learning models outperform classical ones, with CNNs achieving the highest accuracy: 77.9% for PFPS, 73.8% for ITBS, and 71.43% for the combined injury class.   These findings highlight the potential of motion capture systems coupled with advanced machine learning to identify knee injury-related running patterns.",
      "authors": [
        "David Fuentes-Jiménez",
        "Sara García-de-Villa",
        "David Casillas-Pérez",
        "Pablo Floría",
        "Francisco-Manuel Melgarejo-Meseguer"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 07:41:07+00:00",
      "link": "https://arxiv.org/pdf/2602.11668v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11666v1",
      "title": "PhyNiKCE: A Neurosymbolic Agentic Framework for Autonomous Computational Fluid Dynamics",
      "abstract": "The deployment of autonomous agents for Computational Fluid Dynamics (CFD), is critically limited by the probabilistic nature of Large Language Models (LLMs), which struggle to enforce the strict conservation laws and numerical stability required for physics-based simulations. Reliance on purely semantic Retrieval Augmented Generation (RAG) often leads to \"context poisoning,\" where agents generate linguistically plausible but physically invalid configurations due to a fundamental Semantic-Physical Disconnect. To bridge this gap, this work introduces PhyNiKCE (Physical and Numerical Knowledgeable Context Engineering), a neurosymbolic agentic framework for trustworthy engineering. Unlike standard black-box agents, PhyNiKCE decouples neural planning from symbolic validation. It employs a Symbolic Knowledge Engine that treats simulation setup as a Constraint Satisfaction Problem, rigidly enforcing physical constraints via a Deterministic RAG Engine with specialized retrieval strategies for solvers, turbulence models, and boundary conditions. Validated through rigorous OpenFOAM experiments on practical, non-tutorial CFD tasks using Gemini-2.5-Pro/Flash, PhyNiKCE demonstrates a 96% relative improvement over state-of-the-art baselines. Furthermore, by replacing trial-and-error with knowledge-driven initialization, the framework reduced autonomous self-correction loops by 59% while simultaneously lowering LLM token consumption by 17%. These results demonstrate that decoupling neural generation from symbolic constraint enforcement significantly enhances robustness and efficiency. While validated on CFD, this architecture offers a scalable, auditable paradigm for Trustworthy Artificial Intelligence in broader industrial automation.",
      "authors": [
        "E Fan",
        "Lisong Shi",
        "Zhengtong Li",
        "Chih-yung Wen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-12 07:37:56+00:00",
      "link": "https://arxiv.org/pdf/2602.11666v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11661v1",
      "title": "Quark Medical Alignment: A Holistic Multi-Dimensional Alignment and Collaborative Optimization Paradigm",
      "abstract": "While reinforcement learning for large language model alignment has progressed rapidly in recent years, transferring these paradigms to high-stakes medical question answering reveals a fundamental paradigm mismatch. Reinforcement Learning from Human Feedback relies on preference annotations that are prohibitively expensive and often fail to reflect the absolute correctness of medical facts. Reinforcement Learning from Verifiable Rewards lacks effective automatic verifiers and struggles to handle complex clinical contexts. Meanwhile, medical alignment requires the simultaneous optimization of correctness, safety, and compliance, yet multi-objective heterogeneous reward signals are prone to scale mismatch and optimization conflicts.To address these challenges, we propose a robust medical alignment paradigm. We first construct a holistic multi-dimensional medical alignment matrix that decomposes alignment objectives into four categories: fundamental capabilities, expert knowledge, online feedback, and format specifications. Within each category, we establish a closed loop of where observable metrics inform attributable diagnosis, which in turn drives optimizable rewards, thereby providing fine-grained, high-resolution supervision signals for subsequent iterative optimization. To resolve gradient domination and optimization instability problem caused by heterogeneous signals, we further propose a unified optimization mechanism. This mechanism employs Reference-Frozen Normalization to align reward scales and implements a Tri-Factor Adaptive Dynamic Weighting strategy to achieve collaborative optimization that is weakness-oriented, risk-prioritized, and redundancy-reducing. Experimental results demonstrate the effectiveness of our proposed paradigm in real-world medical scenario evaluations, establishing a new paradigm for complex alignment in vertical domains.",
      "authors": [
        "Tianxiang Xu",
        "Jiayi Liu",
        "Yixuan Tong",
        "Jialu Xu",
        "Yunqing Wei",
        "Kaiwen Feng",
        "PanPan Hou",
        "Kangping Yin",
        "Jiyuan Hu",
        "Hao Zhou",
        "Zhenxin Ma",
        "Jian Xu",
        "Guanjun Jiang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12 07:26:23+00:00",
      "link": "https://arxiv.org/pdf/2602.11661v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11655v1",
      "title": "LoRA-based Parameter-Efficient LLMs for Continuous Learning in Edge-based Malware Detection",
      "abstract": "The proliferation of edge devices has created an urgent need for security solutions capable of detecting malware in real time while operating under strict computational and memory constraints. Recently, Large Language Models (LLMs) have demonstrated remarkable capabilities in recognizing complex patterns, yet their deployment on edge devices remains impractical due to their resource demands. However, in edge malware detection, static or centrally retrained models degrade under evolving threats and heterogeneous traffic; locally trained models become siloed and fail to transfer across domains. To overcome these limitations, in this paper, we present a continuous learning architecture for edge-based malware detection that combines local adaptation on each device with global knowledge sharing through parameter-efficient LoRA adapters. Lightweight transformer models (DistilBERT, DistilGPT-2, TinyT5) run on edge nodes and are incrementally fine-tuned on device-specific traffic; only the resulting LoRA modules are aggregated by a lightweight coordinator and redistributed, enabling cross-device generalization without exchanging raw data. We evaluate on two public IoT security datasets, Edge-IIoTset and TON-IoT, under multi-round learning to simulate evolving threats. Compared to isolated fine-tuning, the LoRA-based exchange yields up to 20-25% accuracy gains when models encounter previously unseen attacks from another domain, while maintaining stable loss and F1 across rounds. LoRA adds less than 1% to model size (~0.6-1.8 MB), making updates practical for constrained edge hardware.",
      "authors": [
        "Christian Rondanini",
        "Barbara Carminati",
        "Elena Ferrari",
        "Niccolò Lardo",
        "Ashish Kundu"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "published": "2026-02-12 07:20:26+00:00",
      "link": "https://arxiv.org/pdf/2602.11655v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11653v1",
      "title": "GR-Diffusion: 3D Gaussian Representation Meets Diffusion in Whole-Body PET Reconstruction",
      "abstract": "Positron emission tomography (PET) reconstruction is a critical challenge in molecular imaging, often hampered by noise amplification, structural blurring, and detail loss due to sparse sampling and the ill-posed nature of inverse problems. The three-dimensional discrete Gaussian representation (GR), which efficiently encodes 3D scenes using parameterized discrete Gaussian distributions, has shown promise in computer vision. In this work, we pro-pose a novel GR-Diffusion framework that synergistically integrates the geometric priors of GR with the generative power of diffusion models for 3D low-dose whole-body PET reconstruction. GR-Diffusion employs GR to generate a reference 3D PET image from projection data, establishing a physically grounded and structurally explicit benchmark that overcomes the low-pass limitations of conventional point-based or voxel-based methods. This reference image serves as a dual guide during the diffusion process, ensuring both global consistency and local accuracy. Specifically, we employ a hierarchical guidance mechanism based on the GR reference. Fine-grained guidance leverages differences to refine local details, while coarse-grained guidance uses multi-scale difference maps to correct deviations. This strategy allows the diffusion model to sequentially integrate the strong geometric prior from GR and recover sub-voxel information. Experimental results on the UDPET and Clinical datasets with varying dose levels show that GR-Diffusion outperforms state-of-the-art methods in enhancing 3D whole-body PET image quality and preserving physiological details.",
      "authors": [
        "Mengxiao Geng",
        "Zijie Chen",
        "Ran Hong",
        "Bingxuan Li",
        "Qiegen Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 07:10:38+00:00",
      "link": "https://arxiv.org/pdf/2602.11653v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11648v1",
      "title": "Human-Like Gaze Behavior in Social Robots: A Deep Learning Approach Integrating Human and Non-Human Stimuli",
      "abstract": "Nonverbal behaviors, particularly gaze direction, play a crucial role in enhancing effective communication in social interactions. As social robots increasingly participate in these interactions, they must adapt their gaze based on human activities and remain receptive to all cues, whether human-generated or not, to ensure seamless and effective communication. This study aims to increase the similarity between robot and human gaze behavior across various social situations, including both human and non-human stimuli (e.g., conversations, pointing, door openings, and object drops). A key innovation in this study, is the investigation of gaze responses to non-human stimuli, a critical yet underexplored area in prior research. These scenarios, were simulated in the Unity software as a 3D animation and a 360-degree real-world video. Data on gaze directions from 41 participants were collected via virtual reality (VR) glasses. Preprocessed data, trained two neural networks-LSTM and Transformer-to build predictive models based on individuals' gaze patterns. In the animated scenario, the LSTM and Transformer models achieved prediction accuracies of 67.6% and 70.4%, respectively; In the real-world scenario, the LSTM and Transformer models achieved accuracies of 72% and 71.6%, respectively. Despite the gaze pattern differences among individuals, our models outperform existing approaches in accuracy while uniquely considering non-human stimuli, offering a significant advantage over previous literature. Furthermore, deployed on the NAO robot, the system was evaluated by 275 participants via a comprehensive questionnaire, with results demonstrating high satisfaction during interactions. This work advances social robotics by enabling robots to dynamically mimic human gaze behavior in complex social contexts.",
      "authors": [
        "Faezeh Vahedi",
        "Morteza Memari",
        "Ramtin Tabatabaei",
        "Alireza Taheri"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.HC"
      ],
      "published": "2026-02-12 07:01:17+00:00",
      "link": "https://arxiv.org/pdf/2602.11648v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11642v1",
      "title": "Electrostatics-Inspired Surface Reconstruction (EISR): Recovering 3D Shapes as a Superposition of Poisson's PDE Solutions",
      "abstract": "Implicit shape representation, such as SDFs, is a popular approach to recover the surface of a 3D shape as the level sets of a scalar field. Several methods approximate SDFs using machine learning strategies that exploit the knowledge that SDFs are solutions of the Eikonal partial differential equation (PDEs). In this work, we present a novel approach to surface reconstruction by encoding it as a solution to a proxy PDE, namely Poisson's equation. Then, we explore the connection between Poisson's equation and physics, e.g., the electrostatic potential due to a positive charge density. We employ Green's functions to obtain a closed-form parametric expression for the PDE's solution, and leverage the linearity of our proxy PDE to find the target shape's implicit field as a superposition of solutions. Our method shows improved results in approximating high-frequency details, even with a small number of shape priors.",
      "authors": [
        "Diego Patiño",
        "Knut Peterson",
        "Kostas Daniilidis",
        "David K. Han"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 06:54:40+00:00",
      "link": "https://arxiv.org/pdf/2602.11642v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11632v1",
      "title": "CL API: Real-Time Closed-Loop Interactions with Biological Neural Networks",
      "abstract": "Biological neural networks (BNNs) are increasingly explored for their rich dynamics, parallelism, and adaptive behavior. Beyond understanding their function as a scientific endeavour, a key focus has been using these biological systems as a novel computing substrate. However, BNNs can only function as reliable information-processing systems if inputs are delivered in a temporally and structurally consistent manner. In practice, this requires stimulation with precisely controlled structure, microsecond-scale timing, multi-channel synchronization, and the ability to observe and respond to neural activity in real-time. Existing approaches to interacting with BNNs face a fundamental trade-off: they either depend on low-level hardware mechanisms, imposing prohibitive complexity for rapid iteration, or they sacrifice temporal and structural control, undermining consistency and reproducibility - particularly in closed-loop experiments. The Cortical Labs Application Programming Interface (CL API) enables real-time, sub-millisecond closed-loop interactions with BNNs. Taking a contract-based API design approach, the CL API provides users with precise stimulation semantics, transactional admission, deterministic ordering, and explicit synchronization guarantees. This contract is presented through a declarative Python interface, enabling non-expert programmers to express complex stimulation and closed-loop behavior without managing low-level scheduling or hardware details. Ultimately, the CL API provides an accessible and reproducible foundation for real-time experimentation with BNNs, supporting both fundamental biological research and emerging neurocomputing applications.",
      "authors": [
        "David Hogan",
        "Andrew Doherty",
        "Boon Kien Khoo",
        "Johnson Zhou",
        "Richard Salib",
        "James Stewart",
        "Kiaran Lawson",
        "Alon Loeffler",
        "Brett Kagan"
      ],
      "primary_category": "q-bio.NC",
      "categories": [
        "q-bio.NC",
        "cs.ET",
        "cs.NE",
        "eess.SY"
      ],
      "published": "2026-02-12 06:29:01+00:00",
      "link": "https://arxiv.org/pdf/2602.11632v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11631v1",
      "title": "Enforcing Reciprocity in Operator Learning for Seismic Wave Propagation",
      "abstract": "Accurate and efficient wavefield modeling underpins seismic structure and source studies. Traditional methods comply with physical laws but are computationally intensive. Data-driven methods, while opening new avenues for advancement, have yet to incorporate strict physical consistency. The principle of reciprocity is one of the most fundamental physical laws in wave propagation. We introduce the Reciprocity-Enforced Neural Operator (RENO), a transformer-based architecture for modeling seismic wave propagation that hard-codes the reciprocity principle. The model leverages the cross-attention mechanism and commutative operations to guarantee invariance under swapping source and receiver positions. Beyond improved physical consistency, the proposed architecture supports simultaneous realizations for multiple sources without crosstalk issues. This yields an order-of-magnitude inference speedup at a similar memory footprint over an reciprocity-unenforced neural operator on a realistic configuration. We demonstrate the functionality using the reciprocity relation for particle velocity fields under single forces. This architecture is also applicable to pressure fields under dilatational sources and travel-time fields governed by the eikonal equation, paving the way for encoding more complex reciprocity relations.",
      "authors": [
        "Caifeng Zou",
        "Yaozhong Shi",
        "Zachary E. Ross",
        "Robert W. Clayton",
        "Kamyar Azizzadenesheli"
      ],
      "primary_category": "physics.geo-ph",
      "categories": [
        "physics.geo-ph",
        "cs.LG"
      ],
      "published": "2026-02-12 06:28:14+00:00",
      "link": "https://arxiv.org/pdf/2602.11631v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11630v1",
      "title": "Neuro-Symbolic Multitasking: A Unified Framework for Discovering Generalizable Solutions to PDE Families",
      "abstract": "Solving Partial Differential Equations (PDEs) is fundamental to numerous scientific and engineering disciplines. A common challenge arises from solving the PDE families, which are characterized by sharing an identical mathematical structure but varying in specific parameters. Traditional numerical methods, such as the finite element method, need to independently solve each instance within a PDE family, which incurs massive computational cost. On the other hand, while recent advancements in machine learning PDE solvers offer impressive computational speed and accuracy, their inherent ``black-box\" nature presents a considerable limitation. These methods primarily yield numerical approximations, thereby lacking the crucial interpretability provided by analytical expressions, which are essential for deeper scientific insight. To address these limitations, we propose a neuro-assisted multitasking symbolic PDE solver framework for PDE family solving, dubbed NMIPS. In particular, we employ multifactorial optimization to simultaneously discover the analytical solutions of PDEs. To enhance computational efficiency, we devise an affine transfer method by transferring learned mathematical structures among PDEs in a family, avoiding solving each PDE from scratch. Experimental results across multiple cases demonstrate promising improvements over existing baselines, achieving up to a $\\sim$35.7% increase in accuracy while providing interpretable analytical solutions.",
      "authors": [
        "Yipeng Huang",
        "Dejun Xu",
        "Zexin Lin",
        "Zhenzhong Wang",
        "Min Jiang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12 06:25:44+00:00",
      "link": "https://arxiv.org/pdf/2602.11630v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11626v1",
      "title": "ArGEnT: Arbitrary Geometry-encoded Transformer for Operator Learning",
      "abstract": "Learning solution operators for systems with complex, varying geometries and parametric physical settings is a central challenge in scientific machine learning. In many-query regimes such as design optimization, control and inverse problems, surrogate modeling must generalize across geometries while allowing flexible evaluation at arbitrary spatial locations. In this work, we propose Arbitrary Geometry-encoded Transformer (ArGEnT), a geometry-aware attention-based architecture for operator learning on arbitrary domains. ArGEnT employs Transformer attention mechanisms to encode geometric information directly from point-cloud representations with three variants-self-attention, cross-attention, and hybrid-attention-that incorporates different strategies for incorporating geometric features. By integrating ArGEnT into DeepONet as the trunk network, we develop a surrogate modeling framework capable of learning operator mappings that depend on both geometric and non-geometric inputs without the need to explicitly parametrize geometry as a branch network input. Evaluation on benchmark problems spanning fluid dynamics, solid mechanics and electrochemical systems, we demonstrate significantly improved prediction accuracy and generalization performance compared with the standard DeepONet and other existing geometry-aware saurrogates. In particular, the cross-attention transformer variant enables accurate geometry-conditioned predictions with reduced reliance on signed distance functions. By combining flexible geometry encoding with operator-learning capabilities, ArGEnT provides a scalable surrogate modeling framework for optimization, uncertainty quantification, and data-driven modeling of complex physical systems.",
      "authors": [
        "Wenqian Chen",
        "Yucheng Fu",
        "Michael Penwarden",
        "Pratanu Roy",
        "Panos Stinis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph",
        "physics.comp-ph",
        "physics.flu-dyn"
      ],
      "published": "2026-02-12 06:22:59+00:00",
      "link": "https://arxiv.org/pdf/2602.11626v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11625v1",
      "title": "PLOT-CT: Pre-log Voronoi Decomposition Assisted Generation for Low-dose CT Reconstruction",
      "abstract": "Low-dose computed tomography (LDCT) reconstruction is fundamentally challenged by severe noise and compromised data fidelity under reduced radiation exposure. Most existing methods operate either in the image or post-log projection domain, which fails to fully exploit the rich structural information in pre-log measurements while being highly susceptible to noise. The requisite logarithmic transformation critically amplifies noise within these data, imposing exceptional demands on reconstruction precision. To overcome these challenges, we propose PLOT-CT, a novel framework for Pre-Log vOronoi decomposiTion-assisted CT generation. Our method begins by applying Voronoi decomposition to pre-log sinograms, disentangling the data into distinct underlying components, which are embedded in separate latent spaces. This explicit decomposition significantly enhances the model's capacity to learn discriminative features, directly improving reconstruction accuracy by mitigating noise and preserving information inherent in the pre-log domain. Extensive experiments demonstrate that PLOT-CT achieves state-of-the-art performance, attaining a 2.36dB PSNR improvement over traditional methods at the 1e4 incident photon level in the pre-log domain.",
      "authors": [
        "Bin Huang",
        "Xun Yu",
        "Yikun Zhang",
        "Yi Zhang",
        "Yang Chen",
        "Qiegen Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-12 06:20:23+00:00",
      "link": "https://arxiv.org/pdf/2602.11625v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11622v1",
      "title": "Evolutionary Router Feature Generation for Zero-Shot Graph Anomaly Detection with Mixture-of-Experts",
      "abstract": "Zero-shot graph anomaly detection (GAD) has attracted increasing attention recent years, yet the heterogeneity of graph structures, features, and anomaly patterns across graphs make existing single GNN methods insufficiently expressive to model diverse anomaly mechanisms. In this regard, Mixture-of-experts (MoE) architectures provide a promising paradigm by integrating diverse GNN experts with complementary inductive biases, yet their effectiveness in zero-shot GAD is severely constrained by distribution shifts, leading to two key routing challenges. First, nodes often carry vastly different semantics across graphs, and straightforwardly performing routing based on their features is prone to generating biased or suboptimal expert assignments. Second, as anomalous graphs often exhibit pronounced distributional discrepancies, existing router designs fall short in capturing domain-invariant routing principles that generalize beyond the training graphs. To address these challenges, we propose a novel MoE framework with evolutionary router feature generation (EvoFG) for zero-shot GAD. To enhance MoE routing, we propose an evolutionary feature generation scheme that iteratively constructs and selects informative structural features via an LLM-based generator and Shapley-guided evaluation. Moreover, a memory-enhanced router with an invariant learning objective is designed to capture transferable routing patterns under distribution shifts. Extensive experiments on six benchmarks show that EvoFG consistently outperforms state-of-the-art baselines, achieving strong and stable zero-shot GAD performance.",
      "authors": [
        "Haiyang Jiang",
        "Tong Chen",
        "Xinyi Gao",
        "Guansong Pang",
        "Quoc Viet Hung Nguyen",
        "Hongzhi Yin"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-12 06:16:51+00:00",
      "link": "https://arxiv.org/pdf/2602.11622v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11609v1",
      "title": "scPilot: Large Language Model Reasoning Toward Automated Single-Cell Analysis and Discovery",
      "abstract": "We present scPilot, the first systematic framework to practice omics-native reasoning: a large language model (LLM) converses in natural language while directly inspecting single-cell RNA-seq data and on-demand bioinformatics tools. scPilot converts core single-cell analyses, i.e., cell-type annotation, developmental-trajectory reconstruction, and transcription-factor targeting, into step-by-step reasoning problems that the model must solve, justify, and, when needed, revise with new evidence.   To measure progress, we release scBench, a suite of 9 expertly curated datasets and graders that faithfully evaluate the omics-native reasoning capability of scPilot w.r.t various LLMs. Experiments with o1 show that iterative omics-native reasoning lifts average accuracy by 11% for cell-type annotation and Gemini-2.5-Pro cuts trajectory graph-edit distance by 30% versus one-shot prompting, while generating transparent reasoning traces explain marker gene ambiguity and regulatory logic. By grounding LLMs in raw omics data, scPilot enables auditable, interpretable, and diagnostically informative single-cell analyses.   Code, data, and package are available at https://github.com/maitrix-org/scPilot",
      "authors": [
        "Yiming Gao",
        "Zhen Wang",
        "Jefferson Chen",
        "Mark Antkowiak",
        "Mengzhou Hu",
        "JungHo Kong",
        "Dexter Pratt",
        "Jieyuan Liu",
        "Enze Ma",
        "Zhiting Hu",
        "Eric P. Xing"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "q-bio.GN"
      ],
      "published": "2026-02-12 06:04:11+00:00",
      "link": "https://arxiv.org/pdf/2602.11609v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12306v1",
      "title": "Quantum walk inspired JPEG compression of images",
      "abstract": "This work proposes a quantum inspired adaptive quantization framework that enhances the classical JPEG compression by introducing a learned, optimized Qtable derived using a Quantum Walk Inspired Optimization (QWIO) search strategy. The optimizer searches a continuous parameter space of frequency band scaling factors under a unified rate distortion objective that jointly considers reconstruction fidelity and compression efficiency. The proposed framework is evaluated on MNIST, CIFAR10, and ImageNet subsets, using Peak Signal to Noise Ratio (PSNR), Structural Similarity Index (SSIM), Bits Per Pixel (BPP), and error heatmap visual analysis as evaluation metrics. Experimental results show average gains ranging from 3 to 6 dB PSNR, along with better structural preservation of edges, contours, and luminance transitions, without modifying decoder compatibility. The structure remains JPEG compliant and can be implemented using accessible scientific packages making it ideal for deployment and practical research use.",
      "authors": [
        "Abhishek Verma",
        "Sahil Tomar",
        "Sandeep Kumar"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.ET",
        "cs.IT"
      ],
      "published": "2026-02-12 05:40:33+00:00",
      "link": "https://arxiv.org/pdf/2602.12306v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11583v1",
      "title": "The Five Ws of Multi-Agent Communication: Who Talks to Whom, When, What, and Why -- A Survey from MARL to Emergent Language and LLMs",
      "abstract": "Multi-agent sequential decision-making powers many real-world systems, from autonomous vehicles and robotics to collaborative AI assistants. In dynamic, partially observable environments, communication is often what reduces uncertainty and makes collaboration possible. This survey reviews multi-agent communication (MA-Comm) through the Five Ws: who communicates with whom, what is communicated, when communication occurs, and why communication is beneficial. This framing offers a clean way to connect ideas across otherwise separate research threads. We trace how communication approaches have evolved across three major paradigms. In Multi-Agent Reinforcement Learning (MARL), early methods used hand-designed or implicit protocols, followed by end-to-end learned communication optimized for reward and control. While successful, these protocols are frequently task-specific and hard to interpret, motivating work on Emergent Language (EL), where agents can develop more structured or symbolic communication through interaction. EL methods, however, still struggle with grounding, generalization, and scalability, which has fueled recent interest in large language models (LLMs) that bring natural language priors for reasoning, planning, and collaboration in more open-ended settings. Across MARL, EL, and LLM-based systems, we highlight how different choices shape communication design, where the main trade-offs lie, and what remains unsolved. We distill practical design patterns and open challenges to support future hybrid systems that combine learning, language, and control for scalable and interpretable multi-agent collaboration.",
      "authors": [
        "Jingdi Chen",
        "Hanqing Yang",
        "Zongjun Liu",
        "Carlee Joe-Wong"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-12 05:07:50+00:00",
      "link": "https://arxiv.org/pdf/2602.11583v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11574v1",
      "title": "Learning to Configure Agentic AI Systems",
      "abstract": "Configuring LLM-based agent systems involves choosing workflows, tools, token budgets, and prompts from a large combinatorial design space, and is typically handled today by fixed large templates or hand-tuned heuristics. This leads to brittle behavior and unnecessary compute, since the same cumbersome configuration is often applied to both easy and hard input queries. We formulate agent configuration as a query-wise decision problem and introduce ARC (Agentic Resource & Configuration learner), which learns a light-weight hierarchical policy using reinforcement learning to dynamically tailor these configurations. Across multiple benchmarks spanning reasoning and tool-augmented question answering, the learned policy consistently outperforms strong hand-designed and other baselines, achieving up to 25% higher task accuracy while also reducing token and runtime costs. These results demonstrate that learning per-query agent configurations is a powerful alternative to \"one size fits all\" designs.",
      "authors": [
        "Aditya Taparia",
        "Som Sagar",
        "Ransalu Senanayake"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12 04:45:44+00:00",
      "link": "https://arxiv.org/pdf/2602.11574v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11573v2",
      "title": "Fast Tuning the Index Construction Parameters of Proximity Graphs in Vector Databases",
      "abstract": "k-approximate nearest neighbor search (k-ANNS) in high-dimensional vector spaces is a fundamental problem across many fields. With the advent of vector databases and retrieval-augmented generation, k-ANNS has garnered increasing attention. Among existing methods, proximity graphs (PG) based approaches are the state-of-the-art (SOTA) methods. However, the construction parameters of PGs significantly impact their search performance. Before constructing a PG for a given dataset, it is essential to tune these parameters, which first recommends a set of promising parameters and then estimates the quality of each parameter by building the corresponding PG and then testing its k-ANNS performance. Given that the construction complexity of PGs is superlinear, building and evaluating graph indexes accounts for the primary cost of parameter tuning. Unfortunately, there is currently no method considered and optimized this process.In this paper, we introduce FastPGT, an efficient framework for tuning the PG construction parameters. FastPGT accelerates parameter estimation by building multiple PGs simultaneously, thereby reducing repeated computations. Moreover, we modify the SOTA tuning model to recommend multiple parameters at once, which can be efficiently estimated using our method of building multiple PGs simultaneously. Through extensive experiments on real-world datasets, we demonstrate that FastPGT achieves up to 2.37x speedup over the SOTA method VDTuner, without compromising tuning quality.",
      "authors": [
        "Wenyang Zhou",
        "Jiadong Xie",
        "Yingfan Liu",
        "Zhihao Yin",
        "Jeffrey Xu Yu",
        "Hui Li",
        "Zhangqian Mu",
        "Xiaotian Qiao",
        "Jiangtao Cui"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-02-12 04:45:43+00:00",
      "link": "https://arxiv.org/pdf/2602.11573v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11569v1",
      "title": "SemaPop: Semantic-Persona Conditioned Population Synthesis",
      "abstract": "Population synthesis is a critical component of individual-level socio-economic simulation, yet remains challenging due to the need to jointly represent statistical structure and latent behavioral semantics. Existing population synthesis approaches predominantly rely on structured attributes and statistical constraints, leaving a gap in semantic-conditioned population generation that can capture abstract behavioral patterns implicitly in survey data. This study proposes SemaPop, a semantic-statistical population synthesis model that integrates large language models (LLMs) with generative population modeling. SemaPop derives high-level persona representations from individual survey records and incorporates them as semantic conditioning signals for population generation, while marginal regularization is introduced to enforce alignment with target population marginals. In this study, the framework is instantiated using a Wasserstein GAN with gradient penalty (WGAN-GP) backbone, referred to as SemaPop-GAN. Extensive experiments demonstrate that SemaPop-GAN achieves improved generative performance, yielding closer alignment with target marginal and joint distributions while maintaining sample-level feasibility and diversity under semantic conditioning. Ablation studies further confirm the contribution of semantic persona conditioning and architectural design choices to balancing marginal consistency and structural realism. These results demonstrate that SemaPop-GAN enables controllable and interpretable population synthesis through effective semantic-statistical information fusion. SemaPop-GAN also provides a promising modular foundation for developing generative population projection systems that integrate individual-level behavioral semantics with population-level statistical constraints.",
      "authors": [
        "Zhenlin Qin",
        "Yancheng Ling",
        "Leizhen Wang",
        "Francisco Câmara Pereira",
        "Zhenliang Ma"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12 04:44:34+00:00",
      "link": "https://arxiv.org/pdf/2602.11569v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11564v1",
      "title": "LUVE : Latent-Cascaded Ultra-High-Resolution Video Generation with Dual Frequency Experts",
      "abstract": "Recent advances in video diffusion models have significantly improved visual quality, yet ultra-high-resolution (UHR) video generation remains a formidable challenge due to the compounded difficulties of motion modeling, semantic planning, and detail synthesis. To address these limitations, we propose \\textbf{LUVE}, a \\textbf{L}atent-cascaded \\textbf{U}HR \\textbf{V}ideo generation framework built upon dual frequency \\textbf{E}xperts. LUVE employs a three-stage architecture comprising low-resolution motion generation for motion-consistent latent synthesis, video latent upsampling that performs resolution upsampling directly in the latent space to mitigate memory and computational overhead, and high-resolution content refinement that integrates low-frequency and high-frequency experts to jointly enhance semantic coherence and fine-grained detail generation. Extensive experiments demonstrate that our LUVE achieves superior photorealism and content fidelity in UHR video generation, and comprehensive ablation studies further validate the effectiveness of each component. The project is available at \\href{https://unicornanrocinu.github.io/LUVE_web/}{https://github.io/LUVE/}.",
      "authors": [
        "Chen Zhao",
        "Jiawei Chen",
        "Hongyu Li",
        "Zhuoliang Kang",
        "Shilin Lu",
        "Xiaoming Wei",
        "Kai Zhang",
        "Jian Yang",
        "Ying Tai"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 04:35:16+00:00",
      "link": "https://arxiv.org/pdf/2602.11564v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11551v1",
      "title": "SIGHT: Reinforcement Learning with Self-Evidence and Information-Gain Diverse Branching for Search Agent",
      "abstract": "Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to master autonomous search for complex question answering. However, particularly within multi-turn search scenarios, this interaction introduces a critical challenge: search results often suffer from high redundancy and low signal-to-noise ratios. Consequently, agents easily fall into \"Tunnel Vision,\" where the forced interpretation of early noisy retrievals leads to irreversible error accumulation. To address these challenges, we propose SIGHT, a framework that enhances search-based reasoning through Self-Evidence Support (SES) and Information-Gain Driven Diverse Branching. SIGHT distills search results into high-fidelity evidence via SES and calculates an Information Gain score to pinpoint pivotal states where observations maximally reduce uncertainty. This score guides Dynamic Prompting Interventions - including de-duplication, reflection, or adaptive branching - to spawn new branches with SES. Finally, by integrating SES and correctness rewards via Group Relative Policy Optimization, SIGHT internalizes robust exploration strategies without external verifiers. Experiments on single-hop and multi-hop QA benchmarks demonstrate that SIGHT significantly outperforms existing approaches, particularly in complex reasoning scenarios, using fewer search steps.",
      "authors": [
        "Wenlin Zhong",
        "Jinluan Yang",
        "Yiquan Wu",
        "Yi Liu",
        "Jianhang Yao",
        "Kun Kuang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-12 04:16:55+00:00",
      "link": "https://arxiv.org/pdf/2602.11551v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11549v1",
      "title": "Native Reasoning Models: Training Language Models to Reason on Unverifiable Data",
      "abstract": "The prevailing paradigm for training large reasoning models--combining Supervised Fine-Tuning (SFT) with Reinforcement Learning with Verifiable Rewards (RLVR)--is fundamentally constrained by its reliance on high-quality, human-annotated reasoning data and external verifiers. This dependency incurs significant data-collection costs, risks embedding human cognitive biases, and confines the reinforcement learning stage to objectively assessable domains like mathematics and coding, leaving a wide range of unverifiable tasks beyond its scope. To overcome these limitations, we introduce NRT (Native Reasoning Training), a novel framework that cultivates complex reasoning by having the model generate its own reasoning traces using only standard question-answer pairs, thereby obviating the need for expert-written demonstrations. NRT reframes the training problem by treating the reasoning process as a latent variable. It employs a unified training objective that models reasoning as an optimization problem, intrinsically rewarding paths that increase the model's likelihood of producing the ground-truth answer. This unified perspective allows us to analyze intrinsic failure modes of prior methods, such as policy collapse, and systematically design more robust reward aggregation functions, creating a self-reinforcing feedback loop where the model learns to think in ways that resolve its own uncertainty. Empirical evaluation on Llama and Mistral model families demonstrates that NRT achieves state-of-the-art performance among verifier-free methods, significantly outperforming standard SFT baselines and prior verifier-free RL methods. Our approach yields particularly strong performance gains in complex reasoning domains and exhibits high robustness to policy collapse, offering a general, scalable path toward building more powerful and broadly applicable reasoning systems.",
      "authors": [
        "Yuanfu Wang",
        "Zhixuan Liu",
        "Xiangtian Li",
        "Chaochao Lu",
        "Chao Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-12 04:15:46+00:00",
      "link": "https://arxiv.org/pdf/2602.11549v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11539v1",
      "title": "Real-Time Proactive Anomaly Detection via Forward and Backward Forecast Modeling",
      "abstract": "Reactive anomaly detection methods, which are commonly deployed to identify anomalies after they occur based on observed deviations, often fall short in applications that demand timely intervention, such as industrial monitoring, finance, and cybersecurity. Proactive anomaly detection, by contrast, aims to detect early warning signals before failures fully manifest, but existing methods struggle with handling heterogeneous multivariate data and maintaining precision under noisy or unpredictable conditions. In this work, we introduce two proactive anomaly detection frameworks: the Forward Forecasting Model (FFM) and the Backward Reconstruction Model (BRM). Both models leverage a hybrid architecture combining Temporal Convolutional Networks (TCNs), Gated Recurrent Units (GRUs), and Transformer encoders to model directional temporal dynamics. FFM forecasts future sequences to anticipate disruptions, while BRM reconstructs recent history from future context to uncover early precursors. Anomalies are flagged based on forecasting error magnitudes and directional embedding discrepancies. Our models support both continuous and discrete multivariate features, enabling robust performance in real-world settings. Extensive experiments on four benchmark datasets, MSL, SMAP, SMD, and PSM, demonstrate that FFM and BRM outperform state-of-the-art baselines across detection metrics and significantly improve the timeliness of anomaly anticipation. These properties make our approach well-suited for deployment in time-sensitive domains requiring proactive monitoring.",
      "authors": [
        "Luis Olmos",
        "Rashida Hasan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 03:57:41+00:00",
      "link": "https://arxiv.org/pdf/2602.11539v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11523v1",
      "title": "Unifying Stable Optimization and Reference Regularization in RLHF",
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) has advanced alignment capabilities significantly but remains hindered by two core challenges: \\textbf{reward hacking} and \\textbf{stable optimization}. Current solutions independently address these issues through separate regularization strategies, specifically a KL-divergence penalty against a supervised fine-tuned model ($π_0$) to mitigate reward hacking, and policy ratio clipping towards the current policy ($π_t$) to promote stable alignment. However, the implicit trade-off arising from simultaneously regularizing towards both $π_0$ and $π_t$ remains under-explored. In this paper, we introduce a unified regularization approach that explicitly balances the objectives of preventing reward hacking and maintaining stable policy updates. Our simple yet principled alignment objective yields a weighted supervised fine-tuning loss with a superior trade-off, which demonstrably improves both alignment results and implementation complexity. Extensive experiments across diverse benchmarks validate that our method consistently outperforms RLHF and online preference learning methods, achieving enhanced alignment performance and stability.",
      "authors": [
        "Li He",
        "Qiang Qu",
        "He Zhao",
        "Stephen Wan",
        "Dadong Wang",
        "Lina Yao",
        "Tongliang Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 03:31:19+00:00",
      "link": "https://arxiv.org/pdf/2602.11523v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11516v1",
      "title": "Human-Inspired Continuous Learning of Internal Reasoning Processes: Learning How to Think for Adaptive AI Systems",
      "abstract": "Learning internal reasoning processes is crucial for developing AI systems capable of sustained adaptation in dynamic real-world environments. However, most existing approaches primarily emphasize learning task-specific outputs or static knowledge representations, while overlooking the continuous refinement of internal reasoning structures, action scheduling policies, and learning mechanisms themselves. In this paper, we propose a human-inspired continuous learning framework that unifies reasoning, action, reflection, and verification within a sequential reasoning model enhanced by parallel learning. The framework explicitly treats internal thinking processes as primary learning objects. It systematically records internal reasoning trajectories and environmental interactions as structured learning material, enabling the system to optimize not only task-level content but also the organization, scheduling, and evolution of reasoning activities. This design realizes learning alongside processing, allowing cognitive structures to improve during execution. Furthermore, the framework supports controlled replacement of predefined logic with learned procedures and introduces a hierarchical learning-to-learn mechanism that jointly adapts task-level parameters and learning strategies. As a result, the system progressively evolves its internal cognitive architecture while preserving operational stability. Experimental results on a temperature sensor abnormality detection task show that incorporating internal-process learning reduces average runtime by 23.9%.",
      "authors": [
        "Hong Su"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12 03:19:04+00:00",
      "link": "https://arxiv.org/pdf/2602.11516v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11506v1",
      "title": "RooflineBench: A Benchmarking Framework for On-Device LLMs via Roofline Analysis",
      "abstract": "The transition toward localized intelligence through Small Language Models (SLMs) has intensified the need for rigorous performance characterization on resource-constrained edge hardware. However, objectively measuring the theoretical performance ceilings of diverse architectures across heterogeneous platforms remains a formidable challenge. In this work, we propose a systematic framework based on the Roofline model that unifies architectural primitives and hardware constraints through the lens of operational intensity (OI). By defining an inference-potential region, we introduce the Relative Inference Potential as a novel metric to compare efficiency differences between Large Language Models (LLMs) on the same hardware substrate. Extensive empirical analysis across diverse compute tiers reveals that variations in performance and OI are significantly influenced by sequence length. We further identify a critical regression in OI as model depth increases. Additionally, our findings highlight an efficiency trap induced by hardware heterogeneity and demonstrate how structural refinements, such as Multi-head Latent Attention (M LA), can effectively unlock latent inference potential across various hardware substrates. These insights provide actionable directions for hardware-software co-design to align neural structures with physical constraints in on-device intelligence. The released code is available in the Appendix C.",
      "authors": [
        "Zhen Bi",
        "Xueshu Chen",
        "Luoyang Sun",
        "Yuhang Yao",
        "Qing Shen",
        "Jungang Lou",
        "Cheng Deng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.PF"
      ],
      "published": "2026-02-12 03:02:22+00:00",
      "link": "https://arxiv.org/pdf/2602.11506v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11491v1",
      "title": "Exploring Multiple High-Scoring Subspaces in Generative Flow Networks",
      "abstract": "As a probabilistic sampling framework, Generative Flow Networks (GFlowNets) show strong potential for constructing complex combinatorial objects through the sequential composition of elementary components. However, existing GFlowNets often suffer from excessive exploration over vast state spaces, leading to over-sampling of low-reward regions and convergence to suboptimal distributions. Effectively biasing GFlowNets toward high-reward solutions remains a non-trivial challenge. In this paper, we propose CMAB-GFN, which integrates a combinatorial multi-armed bandit (CMAB) framework with GFlowNet policies. The CMAB component prunes low-quality actions, yielding compact high-scoring subspaces for exploration. Restricting GFNs to these compact high-scoring subspaces accelerates the discovery of high-value candidates, while the exploration of different subspaces ensures that diversity is not sacrificed. Experimental results on multiple tasks demonstrate that CMAB-GFN generates higher-reward candidates than existing approaches.",
      "authors": [
        "Xuan Yu",
        "Xu Wang",
        "Rui Zhu",
        "Yudong Zhang",
        "Yang Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 02:30:52+00:00",
      "link": "https://arxiv.org/pdf/2602.11491v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11487v1",
      "title": "Search-Based Quantum Program Testing via Commuting Pauli String",
      "abstract": "Quantum software testing is important for reliable quantum software engineering. Despite recent advances, existing quantum software testing approaches rely on simple test inputs and statistical oracles, costly program specifications, and limited validation on real quantum computers. To address these challenges, we propose SB-QOPS, a search-based quantum program testing approach via commuting Pauli strings. SB-QOPS, as a direct extension to a previously proposed QOPS approach, redefines test cases in terms of Pauli strings and introduces a measurement-centric oracle that exploits their commutation properties, enabling effective testing of quantum programs while reducing the need for full program specifications. By systematically exploring the search space through an expectation-value-based fitness function, SB-QOPS improves test budget utilization and increases the likelihood of uncovering subtle faults. We conduct a large-scale empirical evaluation on quantum circuits of up to 29 qubits on real quantum computers and emulators. We assess three search strategies: Genetic Algorithm, Hill Climbing, and the (1+1) Evolutionary Algorithm, and evaluate SB-QOPS under both simulated and real noisy conditions. Experiments span three quantum computing platforms: IBM, IQM, and Quantinuum. Results show that SB-QOPS significantly outperforms QOPS, achieving a fault-detection score of 100% for circuits up to 29 qubits, and demonstrating portability across quantum platforms.",
      "authors": [
        "Asmar Muqeet",
        "Shaukat Ali",
        "Paolo Arcaini"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-12 02:13:12+00:00",
      "link": "https://arxiv.org/pdf/2602.11487v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11481v1",
      "title": "Compiler-Guided Inference-Time Adaptation: Improving GPT-5 Programming Performance in Idris",
      "abstract": "GPT-5, a state of the art large language model from OpenAI, demonstrates strong performance in widely used programming languages such as Python, C++, and Java; however, its ability to operate in low resource or less commonly used languages remains underexplored. This work investigates whether GPT-5 can effectively acquire proficiency in an unfamiliar functional programming language, Idris, through iterative, feedback driven prompting. We first establish a baseline showing that with zero shot prompting the model solves only 22 out of 56 Idris exercises using the platform Exercism, substantially underperforming relative to higher resource languages (45 out of 50 in Python and 35 out of 47 in Erlang). We then evaluate several refinement strategies, including iterative prompting based on platform feedback, augmenting prompts with documentation and error classification guides, and iterative prompting using local compilation errors and failed test cases. Among these approaches, incorporating local compilation errors yields the most substantial improvements. Using this structured, error guided refinement loop, GPT-5 performance increased to an impressive 54 solved problems out of 56. These results suggest that while large language models may initially struggle in low resource settings, structured compiler level feedback can play a critical role in unlocking their capabilities.",
      "authors": [
        "Minda Li",
        "Bhaskar Krishnamachari"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "published": "2026-02-12 01:48:52+00:00",
      "link": "https://arxiv.org/pdf/2602.11481v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11477v1",
      "title": "SLD-L2S: Hierarchical Subspace Latent Diffusion for High-Fidelity Lip to Speech Synthesis",
      "abstract": "Although lip-to-speech synthesis (L2S) has achieved significant progress in recent years, current state-of-the-art methods typically rely on intermediate representations such as mel-spectrograms or discrete self-supervised learning (SSL) tokens. The potential of latent diffusion models (LDMs) in this task remains largely unexplored. In this paper, we introduce SLD-L2S, a novel L2S framework built upon a hierarchical subspace latent diffusion model. Our method aims to directly map visual lip movements to the continuous latent space of a pre-trained neural audio codec, thereby avoiding the information loss inherent in traditional intermediate representations. The core of our method is a hierarchical architecture that processes visual representations through multiple parallel subspaces, initiated by a subspace decomposition module. To efficiently enhance interactions within and between these subspaces, we design the diffusion convolution block (DiCB) as our network backbone. Furthermore, we employ a reparameterized flow matching technique to directly generate the target latent vectors. This enables a principled inclusion of speech language model (SLM) and semantic losses during training, moving beyond conventional flow matching objectives and improving synthesized speech quality. Our experiments show that SLD-L2S achieves state-of-the-art generation quality on multiple benchmark datasets, surpassing existing methods in both objective and subjective evaluations.",
      "authors": [
        "Yifan Liang",
        "Andong Li",
        "Kang Yang",
        "Guochen Yu",
        "Fangkun Liu",
        "Lingling Dai",
        "Xiaodong Li",
        "Chengshi Zheng"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.CE"
      ],
      "published": "2026-02-12 01:27:30+00:00",
      "link": "https://arxiv.org/pdf/2602.11477v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11472v1",
      "title": "Future Mining: Learning for Safety and Security",
      "abstract": "Mining is rapidly evolving into an AI driven cyber physical ecosystem where safety and operational reliability depend on robust perception, trustworthy distributed intelligence, and continuous monitoring of miners and equipment. However, real world mining environments impose severe constraints, including poor illumination, GPS denied conditions, irregular underground topologies and intermittent connectivity. These factors degrade perception accuracy, disrupt situational awareness and weaken distributed learning systems. At the same time, emerging cyber physical threats such as backdoor triggers, sensor spoofing, label flipping attacks, and poisoned model updates further jeopardize operational safety as mines adopt autonomous vehicles, humanoid assistance, and federated learning for collaborative intelligence. Energy constrained sensors also experience uneven battery depletion, creating blind spots in safety coverage and disrupting hazard detection pipelines. This paper presents a vision for a Unified Smart Safety and Security Architecture that integrates multimodal perception, secure federated learning, reinforcement learning, DTN enabled communication, and energy aware sensing into a cohesive safety framework. We introduce five core modules: Miner Finder, Multimodal Situational Awareness, Backdoor Attack Monitor, TrustFed LFD, and IoT driven Equipment Health Monitoring. These modules collectively address miner localization, hazard understanding, federated robustness, and predictive maintenance. Together, they form an end to end framework capable of guiding miners through obstructed pathways, identifying compromised models or sensors, and ensuring mission critical equipment reliability. This work outlines a comprehensive research vision for building a resilient and trustworthy intelligent mining system capable of maintaining operational continuity under adversarial conditions.",
      "authors": [
        "Md Sazedur Rahman",
        "Mizanur Rahman Jewel",
        "Sanjay Madria"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.DC"
      ],
      "published": "2026-02-12 01:13:16+00:00",
      "link": "https://arxiv.org/pdf/2602.11472v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11467v1",
      "title": "PRISM: A 3D Probabilistic Neural Representation for Interpretable Shape Modeling",
      "abstract": "Understanding how anatomical shapes evolve in response to developmental covariates and quantifying their spatially varying uncertainties is critical in healthcare research. Existing approaches typically rely on global time-warping formulations that ignore spatially heterogeneous dynamics. We introduce PRISM, a novel framework that bridges implicit neural representations with uncertainty-aware statistical shape analysis. PRISM models the conditional distribution of shapes given covariates, providing spatially continuous estimates of both the population mean and covariate-dependent uncertainty at arbitrary locations. A key theoretical contribution is a closed-form Fisher Information metric that enables efficient, analytically tractable local temporal uncertainty quantification via automatic differentiation. Experiments on three synthetic datasets and one clinical dataset demonstrate PRISM's strong performance across diverse tasks within a unified framework, while providing interpretable and clinically meaningful uncertainty estimates.",
      "authors": [
        "Yining Jiao",
        "Sreekalyani Bhamidi",
        "Carlton Jude Zdanski",
        "Julia S Kimbell",
        "Andrew Prince",
        "Cameron P Worden",
        "Samuel Kirse",
        "Christopher Rutter",
        "Benjamin H Shields",
        "Jisan Mahmud",
        "Marc Niethammer"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 00:55:31+00:00",
      "link": "https://arxiv.org/pdf/2602.11467v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11466v1",
      "title": "A Dual-Branch Framework for Semantic Change Detection with Boundary and Temporal Awareness",
      "abstract": "Semantic Change Detection (SCD) aims to detect and categorize land-cover changes from bi-temporal remote sensing images. Existing methods often suffer from blurred boundaries and inadequate temporal modeling, limiting segmentation accuracy. To address these issues, we propose a Dual-Branch Framework for Semantic Change Detection with Boundary and Temporal Awareness, termed DBTANet. Specifically, we utilize a dual-branch Siamese encoder where a frozen SAM branch captures global semantic context and boundary priors, while a ResNet34 branch provides local spatial details, ensuring complementary feature representations. On this basis, we design a Bidirectional Temporal Awareness Module (BTAM) to aggregate multi-scale features and capture temporal dependencies in a symmetric manner. Furthermore, a Gaussian-smoothed Projection Module (GSPM) refines shallow SAM features, suppressing noise while enhancing edge information for boundary-aware constraints. Extensive experiments on two public benchmarks demonstrate that DBTANet effectively integrates global semantics, local details, temporal reasoning, and boundary awareness, achieving state-of-the-art performance.",
      "authors": [
        "Yun-Cheng Li",
        "Sen Lei",
        "Heng-Chao Li",
        "Ke Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12 00:54:22+00:00",
      "link": "https://arxiv.org/pdf/2602.11466v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11465v1",
      "title": "Assessing Low Back Movement with Motion Tape Sensor Data Through Deep Learning",
      "abstract": "Back pain is a pervasive issue affecting a significant portion of the population, often worsened by certain movements of the lower back. Assessing these movements is important for helping clinicians prescribe appropriate physical therapy. However, it can be difficult to monitor patients' movements remotely outside the clinic. High-fidelity data from motion capture sensors can be used to classify different movements, but these sensors are costly and impractical for use in free-living environments. Motion Tape (MT), a new fabric-based wearable sensor, addresses these issues by being low cost and portable. Despite these advantages, novelty and variability in sensor stability make the MT dataset small scale and inherent to noise. In this work, we propose the Motion-Tape Augmentation Inference Model (MT-AIM), a deep learning classification pipeline trained on MT data. In order to address the challenges of limited sample size and noise present within the MT dataset, MT-AIM leverages conditional generative models to generate synthetic MT data of a desired movement, as well as predicting joint kinematics as additional features. This combination of synthetic data generation and feature augmentation enables MT-AIM to achieve state-of-the-art accuracy in classifying lower back movements, bridging the gap between physiological sensing and movement analysis.",
      "authors": [
        "Jared Levy",
        "Aarti Lalwani",
        "Elijah Wyckoff",
        "Kenneth J. Loh",
        "Sara P. Gombatto",
        "Rose Yu",
        "Emilia Farcas"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-12 00:51:41+00:00",
      "link": "https://arxiv.org/pdf/2602.11465v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11461v1",
      "title": "EM-Aware Physical Synthesis: Neural Inductor Modeling and Intelligent Placement & Routing for RF Circuits",
      "abstract": "This paper presents an ML-driven framework for automated RF physical synthesis that transforms circuit netlists into manufacturable GDSII layouts. While recent ML approaches demonstrate success in topology selection and parameter optimization, they fail to produce manufacturable layouts due to oversimplified component models and lack of routing capabilities. Our framework addresses these limitations through three key innovations: (1) a neural network framework trained on 18,210 inductor geometries with frequency sweeps from 1-100 GHz, generating 7.5 million training samples, that predicts inductor Q-factor with less than 2% error and enables fast gradient-based layout optimization with a 93.77% success rate in producing high-Q layouts; (2) an intelligent P-Cell optimizer that reduces layout area while maintaining design-rule-check (DRC) compliance; and (3) a complete placement and routing engine with frequency-dependent EM spacing rules and DRC-aware synthesis. The neural inductor model demonstrates superior accuracy across 1-100 GHz, enabling EM-accurate component synthesis with real-time inference. The framework successfully generates DRC-aware GDSII layouts for RF circuits, representing a significant step toward automated RF physical design.",
      "authors": [
        "Yilun Huang",
        "Asal Mehradfar",
        "Salman Avestimehr",
        "Hamidreza Aghasi"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "published": "2026-02-12 00:38:24+00:00",
      "link": "https://arxiv.org/pdf/2602.11461v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11455v1",
      "title": "Credit Where It is Due: Cross-Modality Connectivity Drives Precise Reinforcement Learning for MLLM Reasoning",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), yet how visual evidence is integrated during reasoning remains poorly understood. We explore multimodal RLVR through the lens of cross-modal attention connectivity and find that only a small fraction of tokens (approximately 15%) exhibit strong visual-textual coupling. These high-connectivity tokens act as anchors that ground reasoning in the image, while the majority follow linguistic patterns. During RLVR training, credit assignment naturally concentrates on these anchors, sharpening their visual grounding over time. Building on this insight, we propose Anchor-Token Reinforcement Learning (AT-RL), a lightweight framework that selectively reinforces high-connectivity tokens via graph-based clustering of attention topology. Evaluated across the series (3B-32B), AT-RL introduces only 1.2% overhead yet enables the 32B model to surpass the 72B-Instruct baseline on MathVista (80.2), with consistent gains observed across STEM, video and general tasks. Conversely, training solely on low-connectivity tokens causes severe degradation, confirming that effective multimodal RL hinges on precise credit assignment to visual anchors. Our work reveals that reasoning quality is governed not by token quantity but by the fidelity of cross-modal anchoring.",
      "authors": [
        "Zhengbo Jiao",
        "Shaobo Wang",
        "Zifan Zhang",
        "Wei Wang",
        "Bing Zhao",
        "Hu Wei",
        "Linfeng Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12 00:20:54+00:00",
      "link": "https://arxiv.org/pdf/2602.11455v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11453v1",
      "title": "From Noise to Order: Learning to Rank via Denoising Diffusion",
      "abstract": "In information retrieval (IR), learning-to-rank (LTR) methods have traditionally limited themselves to discriminative machine learning approaches that model the probability of the document being relevant to the query given some feature representation of the query-document pair. In this work, we propose an alternative denoising diffusion-based deep generative approach to LTR that instead models the full joint distribution over feature vectors and relevance labels. While in the discriminative setting, an over-parameterized ranking model may find different ways to fit the training data, we hypothesize that candidate solutions that can explain the full data distribution under the generative setting produce more robust ranking models. With this motivation, we propose DiffusionRank that extends TabDiff, an existing denoising diffusion-based generative model for tabular datasets, to create generative equivalents of classical discriminative pointwise and pairwise LTR objectives. Our empirical results demonstrate significant improvements from DiffusionRank models over their discriminative counterparts. Our work points to a rich space for future research exploration on how we can leverage ongoing advancements in deep generative modeling approaches, such as diffusion, for learning-to-rank in IR.",
      "authors": [
        "Sajad Ebrahimi",
        "Bhaskar Mitra",
        "Negar Arabzadeh",
        "Ye Yuan",
        "Haolun Wu",
        "Fattane Zarrinkalam",
        "Ebrahim Bagheri"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-12 00:02:37+00:00",
      "link": "https://arxiv.org/pdf/2602.11453v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11440v1",
      "title": "Ctrl&Shift: High-Quality Geometry-Aware Object Manipulation in Visual Generation",
      "abstract": "Object-level manipulation, relocating or reorienting objects in images or videos while preserving scene realism, is central to film post-production, AR, and creative editing. Yet existing methods struggle to jointly achieve three core goals: background preservation, geometric consistency under viewpoint shifts, and user-controllable transformations. Geometry-based approaches offer precise control but require explicit 3D reconstruction and generalize poorly; diffusion-based methods generalize better but lack fine-grained geometric control. We present Ctrl&Shift, an end-to-end diffusion framework to achieve geometry-consistent object manipulation without explicit 3D representations. Our key insight is to decompose manipulation into two stages, object removal and reference-guided inpainting under explicit camera pose control, and encode both within a unified diffusion process. To enable precise, disentangled control, we design a multi-task, multi-stage training strategy that separates background, identity, and pose signals across tasks. To improve generalization, we introduce a scalable real-world dataset construction pipeline that generates paired image and video samples with estimated relative camera poses. Extensive experiments demonstrate that Ctrl&Shift achieves state-of-the-art results in fidelity, viewpoint consistency, and controllability. To our knowledge, this is the first framework to unify fine-grained geometric control and real-world generalization for object manipulation, without relying on any explicit 3D modeling.",
      "authors": [
        "Penghui Ruan",
        "Bojia Zi",
        "Xianbiao Qi",
        "Youze Huang",
        "Rong Xiao",
        "Pichao Wang",
        "Jiannong Cao",
        "Yuhui Shi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 23:36:30+00:00",
      "link": "https://arxiv.org/pdf/2602.11440v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11437v1",
      "title": "Distributionally Robust Cooperative Multi-Agent Reinforcement Learning via Robust Value Factorization",
      "abstract": "Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution, where value-factorization methods enforce the individual-global-maximum (IGM) principle so that decentralized greedy actions recover the team-optimal joint action. However, the reliability of this recipe in real-world settings remains unreliable due to environmental uncertainties arising from the sim-to-real gap, model mismatch, and system noise. We address this gap by introducing Distributionally robust IGM (DrIGM), a principle that requires each agent's robust greedy action to align with the robust team-optimal joint action. We show that DrIGM holds for a novel definition of robust individual action values, which is compatible with decentralized greedy execution and yields a provable robustness guarantee for the whole system. Building on this foundation, we derive DrIGM-compliant robust variants of existing value-factorization architectures (e.g., VDN/QMIX/QTRAN) that (i) train on robust Q-targets, (ii) preserve scalability, and (iii) integrate seamlessly with existing codebases without bespoke per-agent reward shaping. Empirically, on high-fidelity SustainGym simulators and a StarCraft game environment, our methods consistently improve out-of-distribution performance. Code and data are available at https://github.com/crqu/robust-coMARL.",
      "authors": [
        "Chengrui Qu",
        "Christopher Yeh",
        "Kishan Panaganti",
        "Eric Mazumdar",
        "Adam Wierman"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-02-11 23:24:15+00:00",
      "link": "https://arxiv.org/pdf/2602.11437v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11425v1",
      "title": "Surface impedance inference via neural fields and sparse acoustic data obtained by a compact array",
      "abstract": "Standardized laboratory characterizations for absorbing materials rely on idealized sound field assumptions, which deviate largely from real-life conditions. Consequently, \\emph{in-situ} acoustic characterization has become essential for accurate diagnosis and virtual prototyping. We propose a physics-informed neural field that reconstructs local, near-surface broadband sound fields from sparse pressure samples to directly infer complex surface impedance. A parallel, multi-frequency architecture enables a broadband impedance retrieval within runtimes on the order of seconds to minutes. To validate the method, we developed a compact microphone array with low hardware complexity. Numerical verifications and laboratory experiments demonstrate accurate impedance retrieval with a small number of sensors under realistic conditions. We further showcase the approach in a vehicle cabin to provide practical guidance on measurement locations that avoid strong interference. Here, we show that this approach offers a robust means of characterizing \\emph{in-situ} boundary conditions for architectural and automotive acoustics.",
      "authors": [
        "Yuanxin Xia",
        "Xinyan Li",
        "Matteo Calafà",
        "Allan P. Engsig-Karup",
        "Cheol-Ho Jeong"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.LG"
      ],
      "published": "2026-02-11 22:56:46+00:00",
      "link": "https://arxiv.org/pdf/2602.11425v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11414v1",
      "title": "A physics-informed data-driven framework for modeling hyperelastic materials with progressive damage and failure",
      "abstract": "This work presents a two-stage physics-informed, data-driven constitutive modeling framework for hyperelastic soft materials undergoing progressive damage and failure. The framework is grounded in the concept of hyperelasticity with energy limiters and employs Gaussian Process Regression (GPR) to separately learn the intact (undamaged) elastic response and damage evolution directly from data. In Stage I, GPR models learn the intact hyperelastic response through volumetric and isochoric response functions (or only the isochoric response under incompressibility), ensuring energetic consistency of the intact response and satisfaction of fundamental principles such as material frame indifference and balance of angular momentum. In Stage II, damage is modeled via a separate GPR model that learns the mapping between the intact strain energy density predicted by Stage I models and a stress-reduction factor governing damage and failure, with monotonicity, non-negativity, and complete-failure constraints enforced through penalty-based optimization to ensure thermodynamic admissibility. Validation on synthetic datasets, including benchmarking against analytical constitutive models and competing data-driven approaches, demonstrates high in-distribution accuracy under uniaxial tension and robust generalization from limited training data to compression and shear modes not used during training. Application to experimental brain tissue data demonstrates the practical applicability of the framework and enables inference of damage evolution and critical failure energy. Overall, the proposed framework combines the physical consistency, interpretability, and generalizability of analytical models with the flexibility, predictive accuracy, and automation of machine learning, offering a powerful approach for modeling failure in soft materials under limited experimental data.",
      "authors": [
        "Kshitiz Upadhyay"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE",
        "cond-mat.mtrl-sci",
        "cond-mat.soft"
      ],
      "published": "2026-02-11 22:31:49+00:00",
      "link": "https://arxiv.org/pdf/2602.11414v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11410v1",
      "title": "CADET: Context-Conditioned Ads CTR Prediction With a Decoder-Only Transformer",
      "abstract": "Click-through rate (CTR) prediction is fundamental to online advertising systems. While Deep Learning Recommendation Models (DLRMs) with explicit feature interactions have long dominated this domain, recent advances in generative recommenders have shown promising results in content recommendation. However, adapting these transformer-based architectures to ads CTR prediction still presents unique challenges, including handling post-scoring contextual signals, maintaining offline-online consistency, and scaling to industrial workloads. We present CADET (Context-Conditioned Ads Decoder-Only Transformer), an end-to-end decoder-only transformer for ads CTR prediction deployed at LinkedIn. Our approach introduces several key innovations: (1) a context-conditioned decoding architecture with multi-tower prediction heads that explicitly model post-scoring signals such as ad position, resolving the chicken-and-egg problem between predicted CTR and ranking; (2) a self-gated attention mechanism that stabilizes training by adaptively regulating information flow at both representation and interaction levels; (3) a timestamp-based variant of Rotary Position Embedding (RoPE) that captures temporal relationships across timescales from seconds to months; (4) session masking strategies that prevent the model from learning dependencies on unavailable in-session events, addressing train-serve skew; and (5) production engineering techniques including tensor packing, sequence chunking, and custom Flash Attention kernels that enable efficient training and serving at scale. In online A/B testing, CADET achieves a 11.04\\% CTR lift compared to the production LiRank baseline model, a hybrid ensemble of DCNv2 and sequential encoders. The system has been successfully deployed on LinkedIn's advertising platform, serving the main traffic for homefeed sponsored updates.",
      "authors": [
        "David Pardoe",
        "Neil Daftary",
        "Miro Furtado",
        "Aditya Aiyer",
        "Yu Wang",
        "Liuqing Li",
        "Tao Song",
        "Lars Hertel",
        "Young Jin Yun",
        "Senthil Radhakrishnan",
        "Zhiwei Wang",
        "Tommy Li",
        "Khai Tran",
        "Ananth Nagarajan",
        "Ali Naqvi",
        "Yue Zhang",
        "Renpeng Fang",
        "Avi Romascanu",
        "Arjun Kulothungun",
        "Deepak Kumar",
        "Praneeth Boda",
        "Fedor Borisyuk",
        "Ruoyan Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 22:24:33+00:00",
      "link": "https://arxiv.org/pdf/2602.11410v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11408v1",
      "title": "GHOST: Unmasking Phantom States in Mamba2 via Grouped Hidden-state Output-aware Selection & Truncation",
      "abstract": "While Mamba2's expanded state dimension enhances temporal modeling, it incurs substantial inference overhead that saturates bandwidth during autoregressive generation. Standard pruning methods fail to address this bottleneck: unstructured sparsity leaves activations dense, magnitude-based selection ignores runtime dynamics, and gradient-based methods impose prohibitive costs. We introduce GHOST (Grouped Hidden-state Output-aware Selection and Truncation), a structured pruning framework that approximates control-theoretic balanced truncation using only forward-pass statistics. By jointly measuring controllability and observability, GHOST rivals the fidelity of gradient-based methods without requiring backpropagation. As a highlight, on models ranging from 130M to 2.7B parameters, our approach achieves a 50\\% state-dimension reduction with approximately 1 perplexity point increase on WikiText-2. Code is available at https://anonymous.4open.science/r/mamba2_ghost-7BCB/.",
      "authors": [
        "Michael Menezes",
        "Anastasios Kyrillidis"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "published": "2026-02-11 22:20:10+00:00",
      "link": "https://arxiv.org/pdf/2602.11408v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11399v1",
      "title": "Can We Really Learn One Representation to Optimize All Rewards?",
      "abstract": "As machine learning has moved towards leveraging large models as priors for downstream tasks, the community has debated the right form of prior for solving reinforcement learning (RL) problems. If one were to try to prefetch as much computation as possible, they would attempt to learn a prior over the policies for some yet-to-be-determined reward function. Recent work (forward-backward (FB) representation learning) has tried this, arguing that an unsupervised representation learning procedure can enable optimal control over arbitrary rewards without further fine-tuning. However, FB's training objective and learning behavior remain mysterious. In this paper, we demystify FB by clarifying when such representations can exist, what its objective optimizes, and how it converges in practice. We draw connections with rank matching, fitted Q-evaluation, and contraction mapping. Our analysis suggests a simplified unsupervised pre-training method for RL that, instead of enabling optimal control, performs one step of policy improvement. We call our proposed method $\\textbf{one-step forward-backward representation learning (one-step FB)}$. Experiments in didactic settings, as well as in $10$ state-based and image-based continuous control domains, demonstrate that one-step FB converges to errors $10^5$ smaller and improves zero-shot performance by $+24\\%$ on average. Our project website is available at https://chongyi-zheng.github.io/onestep-fb.",
      "authors": [
        "Chongyi Zheng",
        "Royina Karegoudra Jayanth",
        "Benjamin Eysenbach"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-02-11 22:06:25+00:00",
      "link": "https://arxiv.org/pdf/2602.11399v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11360v1",
      "title": "Bootstrapping-based Regularisation for Reducing Individual Prediction Instability in Clinical Risk Prediction Models",
      "abstract": "Clinical prediction models are increasingly used to support patient care, yet many deep learning-based approaches remain unstable, as their predictions can vary substantially when trained on different samples from the same population. Such instability undermines reliability and limits clinical adoption. In this study, we propose a novel bootstrapping-based regularisation framework that embeds the bootstrapping process directly into the training of deep neural networks. This approach constrains prediction variability across resampled datasets, producing a single model with inherent stability properties. We evaluated models constructed using the proposed regularisation approach against conventional and ensemble models using simulated data and three clinical datasets: GUSTO-I, Framingham, and SUPPORT. Across all datasets, our model exhibited improved prediction stability, with lower mean absolute differences (e.g., 0.019 vs. 0.059 in GUSTO-I; 0.057 vs. 0.088 in Framingham) and markedly fewer significantly deviating predictions. Importantly, discriminative performance and feature importance consistency were maintained, with high SHAP correlations between models (e.g., 0.894 for GUSTO-I; 0.965 for Framingham). While ensemble models achieved greater stability, we show that this came at the expense of interpretability, as each constituent model used predictors in different ways. By regularising predictions to align with bootstrapped distributions, our approach allows prediction models to be developed that achieve greater robustness and reproducibility without sacrificing interpretability. This method provides a practical route toward more reliable and clinically trustworthy deep learning models, particularly valuable in data-limited healthcare settings.",
      "authors": [
        "Sara Matijevic",
        "Christopher Yau"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-02-11 20:47:30+00:00",
      "link": "https://arxiv.org/pdf/2602.11360v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11354v1",
      "title": "ReplicatorBench: Benchmarking LLM Agents for Replicability in Social and Behavioral Sciences",
      "abstract": "The literature has witnessed an emerging interest in AI agents for automated assessment of scientific papers. Existing benchmarks focus primarily on the computational aspect of this task, testing agents' ability to reproduce or replicate research outcomes when having access to the code and data. This setting, while foundational, (1) fails to capture the inconsistent availability of new data for replication as opposed to reproduction, and (2) lacks ground-truth diversity by focusing only on reproducible papers, thereby failing to evaluate an agent's ability to identify non-replicable research. Furthermore, most benchmarks only evaluate outcomes rather than the replication process. In response, we introduce ReplicatorBench, an end-to-end benchmark, including human-verified replicable and non-replicable research claims in social and behavioral sciences for evaluating AI agents in research replication across three stages: (1) extraction and retrieval of replication data; (2) design and execution of computational experiments; and (3) interpretation of results, allowing a test of AI agents' capability to mimic the activities of human replicators in real world. To set a baseline of AI agents' capability, we develop ReplicatorAgent, an agentic framework equipped with necessary tools, like web search and iterative interaction with sandboxed environments, to accomplish tasks in ReplicatorBench. We evaluate ReplicatorAgent across four underlying large language models (LLMs), as well as different design choices of programming language and levels of code access. Our findings reveal that while current LLM agents are capable of effectively designing and executing computational experiments, they struggle with retrieving resources, such as new data, necessary to replicate a claim. All code and data are publicly available at https://github.com/CenterForOpenScience/llm-benchmarking.",
      "authors": [
        "Bang Nguyen",
        "Dominik Soós",
        "Qian Ma",
        "Rochana R. Obadage",
        "Zack Ranjan",
        "Sai Koneru",
        "Timothy M. Errington",
        "Shakhlo Nematova",
        "Sarah Rajtmajer",
        "Jian Wu",
        "Meng Jiang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-11 20:42:10+00:00",
      "link": "https://arxiv.org/pdf/2602.11354v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11348v2",
      "title": "AgentNoiseBench: Benchmarking Robustness of Tool-Using LLM Agents Under Noisy Condition",
      "abstract": "Recent advances in large language models have enabled LLM-based agents to achieve strong performance on a variety of benchmarks. However, their performance in real-world deployments often that observed on benchmark settings, especially in complex and imperfect environments. This discrepancy largely arises because prevailing training and evaluation paradigms are typically built on idealized assumptions, overlooking the inherent stochasticity and noise present in real-world interactions. To bridge this gap, we introduce AgentNoiseBench, a framework for systematically evaluating the robustness of agentic models under noisy environments. We first conduct an in-depth analysis of biases and uncertainties in real-world scenarios and categorize environmental noise into two primary types: user-noise and tool-noise. Building on this analysis, we develop an automated pipeline that injects controllable noise into existing agent-centric benchmarks while preserving task solvability. Leveraging this pipeline, we perform extensive evaluations across a wide range of models with diverse architectures and parameter scales. Our results reveal consistent performance variations under different noise conditions, highlighting the sensitivity of current agentic models to realistic environmental perturbations.",
      "authors": [
        "Ruipeng Wang",
        "Yuxin Chen",
        "Yukai Wang",
        "Chang Wu",
        "Junfeng Fang",
        "Xiaodong Cai",
        "Qi Gu",
        "Hui Su",
        "An Zhang",
        "Xiang Wang",
        "Xunliang Cai",
        "Tat-Seng Chua"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-11 20:33:10+00:00",
      "link": "https://arxiv.org/pdf/2602.11348v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11339v2",
      "title": "Exploring Real-Time Super-Resolution: Benchmarking and Fine-Tuning for Streaming Content",
      "abstract": "Recent advancements in real-time super-resolution have enabled higher-quality video streaming, yet existing methods struggle with the unique challenges of compressed video content. Commonly used datasets do not accurately reflect the characteristics of streaming media, limiting the relevance of current benchmarks. To address this gap, we introduce a comprehensive dataset - StreamSR - sourced from YouTube, covering a wide range of video genres and resolutions representative of real-world streaming scenarios. We benchmark 11 state-of-the-art real-time super-resolution models to evaluate their performance for the streaming use-case.   Furthermore, we propose EfRLFN, an efficient real-time model that integrates Efficient Channel Attention and a hyperbolic tangent activation function - a novel design choice in the context of real-time super-resolution. We extensively optimized the architecture to maximize efficiency and designed a composite loss function that improves training convergence. EfRLFN combines the strengths of existing architectures while improving both visual quality and runtime performance.   Finally, we show that fine-tuning other models on our dataset results in significant performance gains that generalize well across various standard benchmarks. We made the dataset, the code, and the benchmark available at https://github.com/EvgeneyBogatyrev/EfRLFN.",
      "authors": [
        "Evgeney Bogatyrev",
        "Khaled Abud",
        "Ivan Molodetskikh",
        "Nikita Alutis",
        "Dmitriy Vatolin"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 20:22:06+00:00",
      "link": "https://arxiv.org/pdf/2602.11339v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11332v1",
      "title": "Sample-Free Safety Assessment of Neural Network Controllers via Taylor Methods",
      "abstract": "In recent years, artificial neural networks have been increasingly studied as feedback controllers for guidance problems. While effective in complex scenarios, they lack the verification guarantees found in classical guidance policies. Their black-box nature creates significant concerns regarding trustworthiness, limiting their adoption in safety-critical spaceflight applications. This work addresses this gap by developing a method to assess the safety of a trained neural network feedback controller via automatic domain splitting and polynomial bounding. The methodology involves embedding the trained neural network into the system's dynamical equations, rendering the closed-loop system autonomous. The system flow is then approximated by high-order Taylor polynomials, which are subsequently manipulated to construct polynomial maps that project state uncertainties onto an event manifold. Automatic domain splitting ensures the polynomials are accurate over their relevant subdomains, whilst also allowing an extensive state-space to be analysed efficiently. Utilising polynomial bounding techniques, the resulting event values may be rigorously constrained and analysed within individual subdomains, thereby establishing bounds on the range of possible closed-loop outcomes from using such neural network controllers and supporting safety assessment and informed operational decision-making in real-world missions.",
      "authors": [
        "Adam Evans",
        "Roberto Armellin"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-02-11 20:06:04+00:00",
      "link": "https://arxiv.org/pdf/2602.11332v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11325v2",
      "title": "Amortised and provably-robust simulation-based inference",
      "abstract": "Complex simulator-based models are now routinely used to perform inference across the sciences and engineering, but existing inference methods are often unable to account for outliers and other extreme values in data which occur due to faulty measurement instruments or human error. In this paper, we introduce a novel approach to simulation-based inference grounded in generalised Bayesian inference and a neural approximation of a weighted score-matching loss. This leads to a method that is both amortised and provably robust to outliers, a combination not achieved by existing approaches. Furthermore, through a carefully chosen conditional density model, we demonstrate that inference can be further simplified and performed without the need for Markov chain Monte Carlo sampling, thereby offering significant computational advantages, with complexity that is only a small fraction of that of current state-of-the-art approaches.",
      "authors": [
        "Ayush Bharti",
        "Charita Dellaporta",
        "Yuga Hikida",
        "François-Xavier Briol"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.CO",
        "stat.ME"
      ],
      "published": "2026-02-11 19:54:27+00:00",
      "link": "https://arxiv.org/pdf/2602.11325v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11320v2",
      "title": "Efficient Analysis of the Distilled Neural Tangent Kernel",
      "abstract": "Neural tangent kernel (NTK) methods are computationally limited by the need to evaluate large Jacobians across many data points. Existing approaches reduce this cost primarily through projecting and sketching the Jacobian. We show that NTK computation can also be reduced by compressing the data dimension itself using NTK-tuned dataset distillation. We demonstrate that the neural tangent space spanned by the input data can be induced by dataset distillation, yielding a 20-100$\\times$ reduction in required Jacobian calculations. We further show that per-class NTK matrices have low effective rank that is preserved by this reduction. Building on these insights, we propose the distilled neural tangent kernel (DNTK), which combines NTK-tuned dataset distillation with state-of-the-art projection methods to reduce up NTK computational complexity by up to five orders of magnitude while preserving kernel structure and predictive performance.",
      "authors": [
        "Jamie Mahowald",
        "Brian Bell",
        "Alex Ho",
        "Michael Geyer"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 19:45:55+00:00",
      "link": "https://arxiv.org/pdf/2602.11320v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11316v1",
      "title": "Selective Prior Synchronization via SYNC Loss",
      "abstract": "Prediction under uncertainty is a critical requirement for the deep neural network to succeed responsibly. This paper focuses on selective prediction, which allows DNNs to make informed decisions about when to predict or abstain based on the uncertainty level of their predictions. Current methods are either ad-hoc such as SelectiveNet, focusing on how to modify the network architecture or objective function, or post-hoc such as softmax response, achieving selective prediction through analyzing the model's probabilistic outputs. We observe that post-hoc methods implicitly generate uncertainty information, termed the selective prior, which has traditionally been used only during inference. We argue that the selective prior provided by the selection mechanism is equally vital during the training stage. Therefore, we propose the SYNC loss which introduces a novel integration of ad-hoc and post-hoc method. Specifically, our approach incorporates the softmax response into the training process of SelectiveNet, enhancing its selective prediction capabilities by examining the selective prior. Evaluated across various datasets, including CIFAR-100, ImageNet-100, and Stanford Cars, our method not only enhances the model's generalization capabilities but also surpasses previous works in selective prediction performance, and sets new benchmarks for state-of-the-art performance.",
      "authors": [
        "Ishan Mishra",
        "Jiajie Li",
        "Deepak Mishra",
        "Jinjun Xiong"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 19:43:00+00:00",
      "link": "https://arxiv.org/pdf/2602.11316v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11313v1",
      "title": "Hierarchical Testing of a Hybrid Machine Learning-Physics Global Atmosphere Model",
      "abstract": "Machine learning (ML)-based models have demonstrated high skill and computational efficiency, often outperforming conventional physics-based models in weather and subseasonal predictions. While prior studies have assessed their fidelity in capturing synoptic-scale atmospheric dynamics, their performance across timescales and under out-of-distribution forcing, such as +3K or +4K uniform-warming forcings, and the sources of biases remain elusive, to establish the model reliability for Earth science. Here, we design three sets of experiments targeting synoptic-scale phenomena, interannual variability, and out-of-distribution uniform-warming forcings. We evaluate the Neural General Circulation Model (NeuralGCM), a hybrid model integrating a dynamical core with ML-based component, against observations and physics-based Earth system models (ESMs). At the synoptic scale, NeuralGCM captures the evolution and propagation of extratropical cyclones with performance comparable to ESMs. At the interannual scale, when forced by El Niño-Southern Oscillation sea surface temperature (SST) anomalies, NeuralGCM successfully reproduces associated teleconnection patterns but exhibits deficiencies in capturing nonlinear response. Under out-of-distribution uniform-warming forcings, NeuralGCM simulates similar responses in global-average temperature and precipitation and reproduces large-scale tropospheric circulation features similar to those in ESMs. Notable weaknesses include overestimating the tracks and spatial extent of extratropical cyclones, biases in the teleconnected wave train triggered by tropical SST anomalies, and differences in upper-level warming and stratospheric circulation responses to SST warming compared to physics-based ESMs. The causes of these weaknesses were explored.",
      "authors": [
        "Ziming Chen",
        "L. Ruby Leung",
        "Wenyu Zhou",
        "Jian Lu",
        "Sandro W. Lubis",
        "Ye Liu",
        "Chuan-Chieh Chang",
        "Bryce E. Harrop",
        "Ya Wang",
        "Mingshi Yang",
        "Gan Zhang",
        "Yun Qian"
      ],
      "primary_category": "physics.ao-ph",
      "categories": [
        "physics.ao-ph",
        "cs.LG",
        "physics.geo-ph"
      ],
      "published": "2026-02-11 19:34:50+00:00",
      "link": "https://arxiv.org/pdf/2602.11313v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11291v1",
      "title": "H-WM: Robotic Task and Motion Planning Guided by Hierarchical World Model",
      "abstract": "World models are becoming central to robotic planning and control, as they enable prediction of future state transitions. Existing approaches often emphasize video generation or natural language prediction, which are difficult to directly ground in robot actions and suffer from compounding errors over long horizons. Traditional task and motion planning relies on symbolic logic world models, such as planning domains, that are robot-executable and robust for long-horizon reasoning. However, these methods typically operate independently of visual perception, preventing synchronized symbolic and perceptual state prediction. We propose a Hierarchical World Model (H-WM) that jointly predicts logical and visual state transitions within a unified bilevel framework. H-WM combines a high-level logical world model with a low-level visual world model, integrating the robot-executable, long-horizon robustness of symbolic reasoning with perceptual grounding from visual observations. The hierarchical outputs provide stable and consistent intermediate guidance for long-horizon tasks, mitigating error accumulation and enabling robust execution across extended task sequences. To train H-WM, we introduce a robotic dataset that aligns robot motion with symbolic states, actions, and visual observations. Experiments across vision-language-action (VLA) control policies demonstrate the effectiveness and generality of the approach.",
      "authors": [
        "Wenyuan Chen",
        "Jinbang Huang",
        "Oscar Pang",
        "Zhiyuan Li",
        "Xiao Hu",
        "Lingfeng Zhang",
        "Zhanguang Zhang",
        "Mark Coates",
        "Tongtong Cao",
        "Xingyue Quan",
        "Yingxue Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-11 19:08:36+00:00",
      "link": "https://arxiv.org/pdf/2602.11291v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11281v1",
      "title": "DeepRed: an architecture for redshift estimation",
      "abstract": "Estimating redshift is a central task in astrophysics, but its measurement is costly and time-consuming. In addition, current image-based methods are often validated on homogeneous datasets. The development and comparison of networks able generalize across different morphologies, ranging from galaxies to gravitationally-lensed transients, and observational conditions, remain an open challenge. This work proposes DeepRed, a deep learning pipeline that demonstrates how modern computer vision architectures, including ResNet, EfficientNet, Swin Transformer, and MLP-Mixer, can estimate redshifts from images of galaxies, gravitational lenses, and gravitationally-lensed supernovae. We compare these architectures and their ensemble to both neural networks (A1, A3, NetZ, and PhotoZ) and a feature-based method (HOG+SVR) on simulated (DeepGraviLens) and real (KiDS, SDSS) datasets. Our approach achieves state-of-the-art results on all datasets. On DeepGraviLens, DeepRed achieves a significant improvement in the Normalized Mean Absolute Deviation compared to the best baseline (PhotoZ): 55% on DES-deep (using EfficientNet), 51% on DES-wide (Ensemble), 52% on DESI-DOT (Ensemble), and 46% on LSST-wide (Ensemble). On real observations from the KiDS survey, the pipeline outperforms the best baseline (NetZ), improving NMAD by 16% on a general test set without high-probability lenses (Ensemble) and 27% on high-probability lenses (Ensemble). For non-lensed galaxies in the SDSS dataset, the MLP-Mixer architecture achieves a 5% improvement over the best baselines (A3 and NetZ). SHAP shows that the models correctly focus on the objects of interest with over 95% localization accuracy on high-quality images, validating the reliability of the predictions. These findings suggest that deep learning is a scalable, robust, and interpretable solution for redshift estimation in large-scale surveys.",
      "authors": [
        "Alessandro Meroni",
        "Nicolò Oreste Pinciroli Vago",
        "Piero Fraternali"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "cs.AI",
        "cs.LG",
        "gr-qc"
      ],
      "published": "2026-02-11 19:00:10+00:00",
      "link": "https://arxiv.org/pdf/2602.11281v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11262v1",
      "title": "Unlearnable phases of matter",
      "abstract": "We identify fundamental limitations in machine learning by demonstrating that non-trivial mixed-state phases of matter are computationally hard to learn. Focusing on unsupervised learning of distributions, we show that autoregressive neural networks fail to learn global properties of distributions characterized by locally indistinguishable (LI) states. We demonstrate that conditional mutual information (CMI) is a useful diagnostic for LI: we show that for classical distributions, long-range CMI of a state implies a spatially LI partner. By introducing a restricted statistical query model, we prove that nontrivial phases with long-range CMI, such as strong-to-weak spontaneous symmetry breaking phases, are hard to learn. We validate our claims by using recurrent, convolutional, and Transformer neural networks to learn the syndrome and physical distributions of toric/surface code under bit flip noise. Our findings suggest hardness of learning as a diagnostic tool for detecting mixed-state phases and transitions and error-correction thresholds, and they suggest CMI and more generally ``non-local Gibbsness'' as metrics for how hard a distribution is to learn.",
      "authors": [
        "Tarun Advaith Kumar",
        "Yijian Zou",
        "Amir-Reza Negari",
        "Roger G. Melko",
        "Timothy H. Hsieh"
      ],
      "primary_category": "cond-mat.dis-nn",
      "categories": [
        "cond-mat.dis-nn",
        "cs.LG",
        "quant-ph"
      ],
      "published": "2026-02-11 19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2602.11262v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11154v1",
      "title": "SurfPhase: 3D Interfacial Dynamics in Two-Phase Flows from Sparse Videos",
      "abstract": "Interfacial dynamics in two-phase flows govern momentum, heat, and mass transfer, yet remain difficult to measure experimentally. Classical techniques face intrinsic limitations near moving interfaces, while existing neural rendering methods target single-phase flows with diffuse boundaries and cannot handle sharp, deformable liquid-vapor interfaces. We propose SurfPhase, a novel model for reconstructing 3D interfacial dynamics from sparse camera views. Our approach integrates dynamic Gaussian surfels with a signed distance function formulation for geometric consistency, and leverages a video diffusion model to synthesize novel-view videos to refine reconstruction from sparse observations. We evaluate on a new dataset of high-speed pool boiling videos, demonstrating high-quality view synthesis and velocity estimation from only two camera views. Project website: https://yuegao.me/SurfPhase.",
      "authors": [
        "Yue Gao",
        "Hong-Xing Yu",
        "Sanghyeon Chang",
        "Qianxi Fu",
        "Bo Zhu",
        "Yoonjin Won",
        "Juan Carlos Niebles",
        "Jiajun Wu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 18:59:55+00:00",
      "link": "https://arxiv.org/pdf/2602.11154v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11150v1",
      "title": "YOR: Your Own Mobile Manipulator for Generalizable Robotics",
      "abstract": "Recent advances in robot learning have generated significant interest in capable platforms that may eventually approach human-level competence. This interest, combined with the commoditization of actuators, has propelled growth in low-cost robotic platforms. However, the optimal form factor for mobile manipulation, especially on a budget, remains an open question. We introduce YOR, an open-source, low-cost mobile manipulator that integrates an omnidirectional base, a telescopic vertical lift, and two arms with grippers to achieve whole-body mobility and manipulation. Our design emphasizes modularity, ease of assembly using off-the-shelf components, and affordability, with a bill-of-materials cost under 10,000 USD. We demonstrate YOR's capability by completing tasks that require coordinated whole-body control, bimanual manipulation, and autonomous navigation. Overall, YOR offers competitive functionality for mobile manipulation research at a fraction of the cost of existing platforms. Project website: https://www.yourownrobot.ai/",
      "authors": [
        "Manan H Anjaria",
        "Mehmet Enes Erciyes",
        "Vedant Ghatnekar",
        "Neha Navarkar",
        "Haritheja Etukuru",
        "Xiaole Jiang",
        "Kanad Patel",
        "Dhawal Kabra",
        "Nicholas Wojno",
        "Radhika Ajay Prayage",
        "Soumith Chintala",
        "Lerrel Pinto",
        "Nur Muhammad Mahi Shafiullah",
        "Zichen Jeff Cui"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "published": "2026-02-11 18:59:00+00:00",
      "link": "https://arxiv.org/pdf/2602.11150v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11145v1",
      "title": "SCRAPL: Scattering Transform with Random Paths for Machine Learning",
      "abstract": "The Euclidean distance between wavelet scattering transform coefficients (known as paths) provides informative gradients for perceptual quality assessment of deep inverse problems in computer vision, speech, and audio processing. However, these transforms are computationally expensive when employed as differentiable loss functions for stochastic gradient descent due to their numerous paths, which significantly limits their use in neural network training. Against this problem, we propose \"Scattering transform with Random Paths for machine Learning\" (SCRAPL): a stochastic optimization scheme for efficient evaluation of multivariable scattering transforms. We implement SCRAPL for the joint time-frequency scattering transform (JTFS) which demodulates spectrotemporal patterns at multiple scales and rates, allowing a fine characterization of intermittent auditory textures. We apply SCRAPL to differentiable digital signal processing (DDSP), specifically, unsupervised sound matching of a granular synthesizer and the Roland TR-808 drum machine. We also propose an initialization heuristic based on importance sampling, which adapts SCRAPL to the perceptual content of the dataset, improving neural network convergence and evaluation performance. We make our code and audio samples available and provide SCRAPL as a Python package.",
      "authors": [
        "Christopher Mitcheltree",
        "Vincent Lostanlen",
        "Emmanouil Benetos",
        "Mathieu Lagrange"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.LG",
        "eess.AS"
      ],
      "published": "2026-02-11 18:57:08+00:00",
      "link": "https://arxiv.org/pdf/2602.11145v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11143v1",
      "title": "APEX: Learning Adaptive High-Platform Traversal for Humanoid Robots",
      "abstract": "Humanoid locomotion has advanced rapidly with deep reinforcement learning (DRL), enabling robust feet-based traversal over uneven terrain. Yet platforms beyond leg length remain largely out of reach because current RL training paradigms often converge to jumping-like solutions that are high-impact, torque-limited, and unsafe for real-world deployment. To address this gap, we propose APEX, a system for perceptive, climbing-based high-platform traversal that composes terrain-conditioned behaviors: climb-up and climb-down at vertical edges, walking or crawling on the platform, and stand-up and lie-down for posture reconfiguration. Central to our approach is a generalized ratchet progress reward for learning contact-rich, goal-reaching maneuvers. It tracks the best-so-far task progress and penalizes non-improving steps, providing dense yet velocity-free supervision that enables efficient exploration under strong safety regularization. Based on this formulation, we train LiDAR-based full-body maneuver policies and reduce the sim-to-real perception gap through a dual strategy: modeling mapping artifacts during training and applying filtering and inpainting to elevation maps during deployment. Finally, we distill all six skills into a single policy that autonomously selects behaviors and transitions based on local geometry and commands. Experiments on a 29-DoF Unitree G1 humanoid demonstrate zero-shot sim-to-real traversal of 0.8 meter platforms (approximately 114% of leg length), with robust adaptation to platform height and initial pose, as well as smooth and stable multi-skill transitions.",
      "authors": [
        "Yikai Wang",
        "Tingxuan Leng",
        "Changyi Lin",
        "Shiqi Liu",
        "Shir Simon",
        "Bingqing Chen",
        "Jonathan Francis",
        "Ding Zhao"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-11 18:55:11+00:00",
      "link": "https://arxiv.org/pdf/2602.11143v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11142v1",
      "title": "Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows",
      "abstract": "Hierarchical goal-conditioned reinforcement learning (H-GCRL) provides a powerful framework for tackling complex, long-horizon tasks by decomposing them into structured subgoals. However, its practical adoption is hindered by poor data efficiency and limited policy expressivity, especially in offline or data-scarce regimes. In this work, Normalizing flow-based hierarchical implicit Q-learning (NF-HIQL), a novel framework that replaces unimodal gaussian policies with expressive normalizing flow policies at both the high- and low-levels of the hierarchy is introduced. This design enables tractable log-likelihood computation, efficient sampling, and the ability to model rich multimodal behaviors. New theoretical guarantees are derived, including explicit KL-divergence bounds for Real-valued non-volume preserving (RealNVP) policies and PAC-style sample efficiency results, showing that NF-HIQL preserves stability while improving generalization. Empirically, NF-HIQL is evaluted across diverse long-horizon tasks in locomotion, ball-dribbling, and multi-step manipulation from OGBench. NF-HIQL consistently outperforms prior goal-conditioned and hierarchical baselines, demonstrating superior robustness under limited data and highlighting the potential of flow-based architectures for scalable, data-efficient hierarchical reinforcement learning.",
      "authors": [
        "Shaswat Garg",
        "Matin Moezzi",
        "Brandon Da Silva"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 18:54:48+00:00",
      "link": "https://arxiv.org/pdf/2602.11142v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11139v1",
      "title": "TabICLv2: A better, faster, scalable, and open tabular foundation model",
      "abstract": "Tabular foundation models, such as TabPFNv2 and TabICL, have recently dethroned gradient-boosted trees at the top of predictive benchmarks, demonstrating the value of in-context learning for tabular data. We introduce TabICLv2, a new state-of-the-art foundation model for regression and classification built on three pillars: (1) a novel synthetic data generation engine designed for high pretraining diversity; (2) various architectural innovations, including a new scalable softmax in attention improving generalization to larger datasets without prohibitive long-sequence pretraining; and (3) optimized pretraining protocols, notably replacing AdamW with the Muon optimizer. On the TabArena and TALENT benchmarks, TabICLv2 without any tuning surpasses the performance of the current state of the art, RealTabPFN-2.5 (hyperparameter-tuned, ensembled, and fine-tuned on real data). With only moderate pretraining compute, TabICLv2 generalizes effectively to million-scale datasets under 50GB GPU memory while being markedly faster than RealTabPFN-2.5. We provide extensive ablation studies to quantify these contributions and commit to open research by first releasing inference code and model weights at https://github.com/soda-inria/tabicl, with synthetic data engine and pretraining code to follow.",
      "authors": [
        "Jingang Qu",
        "David Holzmüller",
        "Gaël Varoquaux",
        "Marine Le Morvan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 18:51:02+00:00",
      "link": "https://arxiv.org/pdf/2602.11139v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11136v2",
      "title": "FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight",
      "abstract": "As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation from natural language requirements to formal specifications. This paper bridges this gap by proposing , a neuro-symbolic framework that employs a bidirectional Formal-of-Thought architecture: LLMs serve as specification compilers that top-down decompose high-level human intent into atomic, verifiable constraints, then bottom-up prove compliance using Dafny specifications and Z3 Satisfiability modulo theories solving, which produces mathematical guarantees rather than probabilistic scores. We validate across three benchmarks spanning behavioral safety, multi-domain constraint adherence, and agentic upward deception detection. Experiments on 7 agent models demonstrate that achieves an average improvement of 16.6% over LLM-as-a-Judge baselines, enables weak-to-strong generalization where a 7B judge achieves over 90% accuracy detecting deception from 72B agents, and provides near-linear safety improvement through iterative refinement.",
      "authors": [
        "Jiayi Zhou",
        "Yang Sheng",
        "Hantao Lou",
        "Yaodong Yang",
        "Jie Fu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-11 18:48:11+00:00",
      "link": "https://arxiv.org/pdf/2602.11136v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11133v1",
      "title": "Just on Time: Token-Level Early Stopping for Diffusion Language Models",
      "abstract": "Diffusion language models generate text through iterative refinement, a process that is often computationally inefficient because many tokens reach stability long before the final denoising step. We introduce a training-free, token-level early stopping approach that identifies convergence independently at each position. Our method leverages lightweight signals derived from the model's predictions and local context to dynamically determine when individual tokens can be finalized. This yields adaptive per-token freezing without task-specific fine-tuning, substantially reducing the total number of diffusion steps required. Across diverse benchmarks, spanning mathematical reasoning, general question answering, and scientific understanding, our approach achieves state-of-the-art efficiency gains while preserving generation quality.",
      "authors": [
        "Zahar Kohut",
        "Severyn Shykula",
        "Dmytro Khamula",
        "Mykola Vysotskyi",
        "Taras Rumezhak",
        "Volodymyr Karpiv"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-11 18:44:04+00:00",
      "link": "https://arxiv.org/pdf/2602.11133v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11128v1",
      "title": "Asymmetric Prompt Weighting for Reinforcement Learning with Verifiable Rewards",
      "abstract": "Reinforcement learning with verifiable rewards has driven recent advances in LLM post-training, in particular for reasoning. Policy optimization algorithms generate a number of responses for a given prompt and then effectively weight the corresponding gradients depending on the rewards. The most popular algorithms including GRPO, DAPO, and RLOO focus on ambiguous prompts, i.e., prompts with intermediate success probability, while downgrading gradients with very easy and very hard prompts. In this paper, we consider asymmetric prompt weightings that assign higher weights to prompts with low, or even zero, empirical success probability. We find that asymmetric weighting particularly benefits from-scratch RL (as in R1-Zero), where training traverses a wide accuracy range, and less so in post-SFT RL where the model already starts at high accuracy. We also provide theory that characterizes prompt weights which minimize the time needed to raise success probability from an initial level to a target accuracy under a fixed update budget. In low-success regimes, where informative responses are rare and response cost dominates, these optimal weights become asymmetric, upweighting low success probabilities and thereby accelerating effective-time convergence.",
      "authors": [
        "Reinhard Heckel",
        "Mahdi Soltanolkotabi",
        "Christos Thramboulidis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 18:39:42+00:00",
      "link": "https://arxiv.org/pdf/2602.11128v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11124v1",
      "title": "PhyCritic: Multimodal Critic Models for Physical AI",
      "abstract": "With the rapid development of large multimodal models, reliable judge and critic models have become essential for open-ended evaluation and preference alignment, providing pairwise preferences, numerical scores, and explanatory justifications for assessing model-generated responses. However, existing critics are primarily trained in general visual domains such as captioning or image question answering, leaving physical AI tasks involving perception, causal reasoning, and planning largely underexplored. We introduce PhyCritic, a multimodal critic model optimized for physical AI through a two-stage RLVR pipeline: a physical skill warmup stage that enhances physically oriented perception and reasoning, followed by self-referential critic finetuning, where the critic generates its own prediction as an internal reference before judging candidate responses, improving judgment stability and physical correctness. Across both physical and general-purpose multimodal judge benchmarks, PhyCritic achieves strong performance gains over open-source baselines and, when applied as a policy model, further improves perception and reasoning in physically grounded tasks.",
      "authors": [
        "Tianyi Xiong",
        "Shihao Wang",
        "Guilin Liu",
        "Yi Dong",
        "Ming Li",
        "Heng Huang",
        "Jan Kautz",
        "Zhiding Yu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 18:35:39+00:00",
      "link": "https://arxiv.org/pdf/2602.11124v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11123v1",
      "title": "From Natural Language to Materials Discovery:The Materials Knowledge Navigation Agent",
      "abstract": "Accelerating the discovery of high-performance materials remains a central challenge across energy, electronics, and aerospace technologies, where traditional workflows depend heavily on expert intuition and computationally expensive simulations. Here we introduce the Materials Knowledge Navigation Agent (MKNA), a language-driven system that translates natural-language scientific intent into executable actions for database retrieval, property prediction, structure generation, and stability evaluation. Beyond automating tool invocation, MKNA autonomously extracts quantitative thresholds and chemically meaningful design motifs from literature and database evidence, enabling data-grounded hypothesis formation. Applied to the search for high-Debye-temperature ceramics, the agent identifies a literature-supported screening criterion (Theta_D > 800 K), rediscovers canonical ultra-stiff materials such as diamond, SiC, SiN, and BeO, and proposes thermodynamically stable, previously unreported Be-C-rich compounds that populate the sparsely explored 1500-1700 K regime. These results demonstrate that MKNA not only finds stable candidates but also reconstructs interpretable design heuristics, establishing a generalizable platform for autonomous, language-guided materials exploration.",
      "authors": [
        "Genmao Zhuang",
        "Amir Barati Farimani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-11 18:34:24+00:00",
      "link": "https://arxiv.org/pdf/2602.11123v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11117v1",
      "title": "HairWeaver: Few-Shot Photorealistic Hair Motion Synthesis with Sim-to-Real Guided Video Diffusion",
      "abstract": "We present HairWeaver, a diffusion-based pipeline that animates a single human image with realistic and expressive hair dynamics. While existing methods successfully control body pose, they lack specific control over hair, and as a result, fail to capture the intricate hair motions, resulting in stiff and unrealistic animations. HairWeaver overcomes this limitation using two specialized modules: a Motion-Context-LoRA to integrate motion conditions and a Sim2Real-Domain-LoRA to preserve the subject's photoreal appearance across different data domains. These lightweight components are designed to guide a video diffusion backbone while maintaining its core generative capabilities. By training on a specialized dataset of dynamic human motion generated from a CG simulator, HairWeaver affords fine control over hair motion and ultimately learns to produce highly realistic hair that responds naturally to movement. Comprehensive evaluations demonstrate that our approach sets a new state of the art, producing lifelike human hair animations with dynamic details.",
      "authors": [
        "Di Chang",
        "Ji Hou",
        "Aljaz Bozic",
        "Assaf Neuberger",
        "Felix Juefei-Xu",
        "Olivier Maury",
        "Gene Wei-Chin Lin",
        "Tuur Stuyck",
        "Doug Roble",
        "Mohammad Soleymani",
        "Stephane Grabli"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 18:31:47+00:00",
      "link": "https://arxiv.org/pdf/2602.11117v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11113v1",
      "title": "A receding-horizon multi-contact motion planner for legged robots in challenging environments",
      "abstract": "We present a novel receding-horizon multi-contact motion planner for legged robots in challenging scenarios, able to plan motions such as chimney climbing, navigating very narrow passages or crossing large gaps. Our approach adds new capabilities to the state of the art, including the ability to reactively re-plan in response to new information, and planning contact locations and whole-body trajectories simultaneously, simplifying the implementation and removing the need for post-processing or complex multi-stage approaches. Our method is more resistant to local minima problems than other potential field based approaches, and our quadratic-program-based posture generator returns nodes more quickly than those of existing algorithms. Rigorous statistical analysis shows that, with short planning horizons (e.g., one step ahead), our planner is faster than the state-of-the-art across all scenarios tested (between 45% and 98% faster on average, depending on the scenario), while planning less efficient motions (requiring 5% fewer to 700% more stance changes on average). In all but one scenario (Chimney Walking), longer planning horizons (e.g., four steps ahead) extended the average planning times (between 73% faster and 400% slower than the state-of-the-art) but resulted in higher quality motion plans (between 8% more and 47% fewer stance changes than the state-of-the-art).",
      "authors": [
        "Daniel S. J. Derwent",
        "Simon Watson",
        "Bruno V. Adorno"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-11 18:25:29+00:00",
      "link": "https://arxiv.org/pdf/2602.11113v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11097v1",
      "title": "Statistical Learning Analysis of Physics-Informed Neural Networks",
      "abstract": "We study the training and performance of physics-informed learning for initial and boundary value problems (IBVP) with physics-informed neural networks (PINNs) from a statistical learning perspective. Specifically, we restrict ourselves to parameterizations with hard initial and boundary condition constraints and reformulate the problem of estimating PINN parameters as a statistical learning problem. From this perspective, the physics penalty on the IBVP residuals can be better understood not as a regularizing term bus as an infinite source of indirect data, and the learning process as fitting the PINN distribution of residuals $p(y \\mid x, t, w) q(x, t) $ to the true data-generating distribution $δ(0) q(x, t)$ by minimizing the Kullback-Leibler divergence between the true and PINN distributions. Furthermore, this analysis show that physics-informed learning with PINNs is a singular learning problem, and we employ singular learning theory tools, namely the so-called Local Learning Coefficient (Lau et al., 2025) to analyze the estimates of PINN parameters obtained via stochastic optimization for a heat equation IBVP. Finally, we discuss implications of this analysis on the quantification of predictive uncertainty of PINNs and the extrapolation capacity of PINNs.",
      "authors": [
        "David A. Barajas-Solano"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.comp-ph"
      ],
      "published": "2026-02-11 18:09:29+00:00",
      "link": "https://arxiv.org/pdf/2602.11097v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11092v1",
      "title": "MerLin: A Discovery Engine for Photonic and Hybrid Quantum Machine Learning",
      "abstract": "Identifying where quantum models may offer practical benefits in near term quantum machine learning (QML) requires moving beyond isolated algorithmic proposals toward systematic and empirical exploration across models, datasets, and hardware constraints. We introduce MerLin, an open source framework designed as a discovery engine for photonic and hybrid quantum machine learning. MerLin integrates optimized strong simulation of linear optical circuits into standard PyTorch and scikit learn workflows, enabling end to end differentiable training of quantum layers. MerLin is designed around systematic benchmarking and reproducibility. As an initial contribution, we reproduce eighteen state of the art photonic and hybrid QML works spanning kernel methods, reservoir computing, convolutional and recurrent architectures, generative models, and modern training paradigms. These reproductions are released as reusable, modular experiments that can be directly extended and adapted, establishing a shared experimental baseline consistent with empirical benchmarking methodologies widely adopted in modern artificial intelligence. By embedding photonic quantum models within established machine learning ecosystems, MerLin allows practitioners to leverage existing tooling for ablation studies, cross modality comparisons, and hybrid classical quantum workflows. The framework already implements hardware aware features, allowing tests on available quantum hardware while enabling exploration beyond its current capabilities, positioning MerLin as a future proof co design tool linking algorithms, benchmarks, and hardware.",
      "authors": [
        "Cassandre Notton",
        "Benjamin Stott",
        "Philippe Schoeb",
        "Anthony Walsh",
        "Grégoire Leboucher",
        "Vincent Espitalier",
        "Vassilis Apostolou",
        "Louis-Félix Vigneux",
        "Alexia Salavrakos",
        "Jean Senellart"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.PL",
        "quant-ph"
      ],
      "published": "2026-02-11 18:00:01+00:00",
      "link": "https://arxiv.org/pdf/2602.11092v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11090v1",
      "title": "Direct Learning of Calibration-Aware Uncertainty for Neural PDE Surrogates",
      "abstract": "Neural PDE surrogates are often deployed in data-limited or partially observed regimes where downstream decisions depend on calibrated uncertainty in addition to low prediction error. Existing approaches obtain uncertainty through ensemble replication, fixed stochastic noise such as dropout, or post hoc calibration. Cross-regularized uncertainty learns uncertainty parameters during training using gradients routed through a held-out regularization split. The predictor is optimized on the training split for fit, while low-dimensional uncertainty controls are optimized on the regularization split to reduce train-test mismatch, yielding regime-adaptive uncertainty without per-regime noise tuning. The framework can learn continuous noise levels at the output head, within hidden features, or within operator-specific components such as spectral modes. We instantiate the approach in Fourier Neural Operators and evaluate on APEBench sweeps over observed fraction and training-set size. Across these sweeps, the learned predictive distributions are better calibrated on held-out splits and the resulting uncertainty fields concentrate in high-error regions in one-step spatial diagnostics.",
      "authors": [
        "Carlos Stein Brito"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "stat.CO"
      ],
      "published": "2026-02-11 17:57:20+00:00",
      "link": "https://arxiv.org/pdf/2602.11090v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11089v1",
      "title": "DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning",
      "abstract": "In the current landscape of Large Language Models (LLMs), the curation of large-scale, high-quality training data is a primary driver of model performance. A key lever is the \\emph{data recipe}, which comprises a data processing pipeline to transform raw sources into training corpora. Despite the growing use of LLMs to automate individual data processing steps, such as data synthesis and filtering, the overall design of data recipes remains largely manual and labor-intensive, requiring substantial human expertise and iteration. To bridge this gap, we formulate \\emph{end-to-end data recipe generation} for LLM adaptation. Given a target benchmark and a pool of available data sources, a model is required to output a complete data recipe that adapts a base LLM to the target task. We present DataChef-32B, which performs online reinforcement learning using a proxy reward that predicts downstream performance for candidate recipes. Across six held-out tasks, DataChef-32B produces practical recipes that reach comparable downstream performance to those curated by human experts. Notably, the recipe from DataChef-32B adapts Qwen3-1.7B-Base to the math domain, achieving 66.7 on AIME'25 and surpassing Qwen3-1.7B. This work sheds new light on automating LLM training and developing self-evolving AI systems.",
      "authors": [
        "Yicheng Chen",
        "Zerun Ma",
        "Xinchen Xie",
        "Yining Li",
        "Kai Chen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-11 17:56:15+00:00",
      "link": "https://arxiv.org/pdf/2602.11089v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11087v1",
      "title": "General Flexible $f$-divergence for Challenging Offline RL Datasets with Low Stochasticity and Diverse Behavior Policies",
      "abstract": "Offline RL algorithms aim to improve upon the behavior policy that produces the collected data while constraining the learned policy to be within the support of the dataset. However, practical offline datasets often contain examples with little diversity or limited exploration of the environment, and from multiple behavior policies with diverse expertise levels. Limited exploration can impair the offline RL algorithm's ability to estimate \\textit{Q} or \\textit{V} values, while constraining towards diverse behavior policies can be overly conservative. Such datasets call for a balance between the RL objective and behavior policy constraints. We first identify the connection between $f$-divergence and optimization constraint on the Bellman residual through a more general Linear Programming form for RL and the convex conjugate. Following this, we introduce the general flexible function formulation for the $f$-divergence to incorporate an adaptive constraint on algorithms' learning objectives based on the offline training dataset. Results from experiments on the MuJoCo, Fetch, and AdroitHand environments show the correctness of the proposed LP form and the potential of the flexible $f$-divergence in improving performance for learning from a challenging dataset when applied to a compatible constrained optimization algorithm.",
      "authors": [
        "Jianxun Wang",
        "Grant C. Forbes",
        "Leonardo Villalobos-Arias",
        "David L. Roberts"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 17:53:49+00:00",
      "link": "https://arxiv.org/pdf/2602.11087v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11084v1",
      "title": "GRASP: group-Shapley feature selection for patients",
      "abstract": "Feature selection remains a major challenge in medical prediction, where existing approaches such as LASSO often lack robustness and interpretability. We introduce GRASP, a novel framework that couples Shapley value driven attribution with group $L_{21}$ regularization to extract compact and non-redundant feature sets. GRASP first distills group level importance scores from a pretrained tree model via SHAP, then enforces structured sparsity through group $L_{21}$ regularized logistic regression, yielding stable and interpretable selections. Extensive comparisons with LASSO, SHAP, and deep learning based methods show that GRASP consistently delivers comparable or superior predictive accuracy, while identifying fewer, less redundant, and more stable features.",
      "authors": [
        "Yuheng Luo",
        "Shuyan Li",
        "Zhong Cao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 17:50:57+00:00",
      "link": "https://arxiv.org/pdf/2602.11084v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11081v1",
      "title": "SteuerLLM: Local specialized large language model for German tax law analysis",
      "abstract": "Large language models (LLMs) demonstrate strong general reasoning and language understanding, yet their performance degrades in domains governed by strict formal rules, precise terminology, and legally binding structure. Tax law exemplifies these challenges, as correct answers require exact statutory citation, structured legal argumentation, and numerical accuracy under rigid grading schemes. We algorithmically generate SteuerEx, the first open benchmark derived from authentic German university tax law examinations. SteuerEx comprises 115 expert-validated examination questions spanning six core tax law domains and multiple academic levels, and employs a statement-level, partial-credit evaluation framework that closely mirrors real examination practice. We further present SteuerLLM, a domain-adapted LLM for German tax law trained on a large-scale synthetic dataset generated from authentic examination material using a controlled retrieval-augmented pipeline. SteuerLLM (28B parameters) consistently outperforms general-purpose instruction-tuned models of comparable size and, in several cases, substantially larger systems, demonstrating that domain-specific data and architectural adaptation are more decisive than parameter scale for performance on realistic legal reasoning tasks. All benchmark data, training datasets, model weights, and evaluation code are released openly to support reproducible research in domain-specific legal artificial intelligence. A web-based demo of SteuerLLM is available at https://steuerllm.i5.ai.fau.de.",
      "authors": [
        "Sebastian Wind",
        "Jeta Sopa",
        "Laurin Schmid",
        "Quirin Jackl",
        "Sebastian Kiefer",
        "Fei Wu",
        "Martin Mayr",
        "Harald Köstler",
        "Gerhard Wellein",
        "Andreas Maier",
        "Soroosh Tayebi Arasteh"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 17:46:01+00:00",
      "link": "https://arxiv.org/pdf/2602.11081v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11079v2",
      "title": "In-the-Wild Model Organisms: Mitigating Undesirable Emergent Behaviors in Production LLM Post-Training via Data Attribution",
      "abstract": "We propose activation-based data attribution, a method that traces behavioral changes in post-trained language models to responsible training datapoints. By computing activation-difference vectors for both test prompts and preference pairs and ranking by cosine similarity, we identify datapoints that cause specific behaviors and validate these attributions causally by retraining with modified data. Clustering behavior-datapoint similarity matrices also enables unsupervised discovery of emergent behaviors. Applying this to OLMo 2's production DPO training, we surfaced distractor-triggered compliance: a harmful behavior where the model complies with dangerous requests when benign formatting instructions are appended. Filtering top-ranked datapoints reduces this behavior by 63% while switching their labels achieves 78%. Our method outperforms gradient-based attribution and LLM-judge baselines while being over 10 times cheaper than both. This in-the-wild model organism - emerging from contaminated preference data rather than deliberate injection - provides a realistic benchmark for safety techniques.",
      "authors": [
        "Frank Xiao",
        "Santiago Aranguri"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 17:45:31+00:00",
      "link": "https://arxiv.org/pdf/2602.11079v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13335v1",
      "title": "Meningioma Analysis and Diagnosis using Limited Labeled Samples",
      "abstract": "The biological behavior and treatment response of meningiomas depend on their grade, making an accurate diagnosis essential for treatment planning and prognosis assessment. We observed that the weighted fusion of spatial-frequency domain features significantly influences meningioma classification performance. Notably, the contribution of specific frequency bands obtained by discrete wavelet transform varies considerably across different images. A feature fusion architecture with adaptive weights of different frequency band information and spatial domain information is proposed for few-shot meningioma learning. To verify the effectiveness of the proposed method, a new MRI dataset of meningiomas is introduced. The experimental results demonstrate the superiority of the proposed method compared with existing state-of-the-art methods in three datasets. The code will be available at: https://github.com/ICL-SUST/AMSF-Net",
      "authors": [
        "Jiamiao Lu",
        "Wei Wu",
        "Ke Gao",
        "Ping Mao",
        "Weichuan Zhang",
        "Tuo Wang",
        "Lingkun Ma",
        "Jiapan Guo",
        "Zanyi Wu",
        "Yuqing Hu",
        "Changming Sun"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 17:44:10+00:00",
      "link": "https://arxiv.org/pdf/2602.13335v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11076v1",
      "title": "Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing",
      "abstract": "Sixth-generation (6G) radio access networks (RANs) must enforce strict service-level agreements (SLAs) for heterogeneous slices, yet sudden latency spikes remain difficult to diagnose and resolve with conventional deep reinforcement learning (DRL) or explainable RL (XRL). We propose \\emph{Attention-Enhanced Multi-Agent Proximal Policy Optimization (AE-MAPPO)}, which integrates six specialized attention mechanisms into multi-agent slice control and surfaces them as zero-cost, faithful explanations. The framework operates across O-RAN timescales with a three-phase strategy: predictive, reactive, and inter-slice optimization.   A URLLC case study shows AE-MAPPO resolves a latency spike in $18$ms, restores latency to $0.98$ms with $99.9999\\%$ reliability, and reduces troubleshooting time by $93\\%$ while maintaining eMBB and mMTC continuity. These results confirm AE-MAPPO's ability to combine SLA compliance with inherent interpretability, enabling trustworthy and real-time automation for 6G RAN slicing.",
      "authors": [
        "Kavan Fatehi",
        "Mostafa Rahmani Ghourtani",
        "Amir Sonee",
        "Poonam Yadav",
        "Alessandra M Russo",
        "Hamed Ahmadi",
        "Radu Calinescu"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.AI",
        "eess.SP"
      ],
      "published": "2026-02-11 17:44:03+00:00",
      "link": "https://arxiv.org/pdf/2602.11076v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11075v1",
      "title": "RISE: Self-Improving Robot Policy with Compositional World Model",
      "abstract": "Despite the sustained scaling on model capacity and data acquisition, Vision-Language-Action (VLA) models remain brittle in contact-rich and dynamic manipulation tasks, where minor execution deviations can compound into failures. While reinforcement learning (RL) offers a principled path to robustness, on-policy RL in the physical world is constrained by safety risk, hardware cost, and environment reset. To bridge this gap, we present RISE, a scalable framework of robotic reinforcement learning via imagination. At its core is a Compositional World Model that (i) predicts multi-view future via a controllable dynamics model, and (ii) evaluates imagined outcomes with a progress value model, producing informative advantages for the policy improvement. Such compositional design allows state and value to be tailored by best-suited yet distinct architectures and objectives. These components are integrated into a closed-loop self-improving pipeline that continuously generates imaginary rollouts, estimates advantages, and updates the policy in imaginary space without costly physical interaction. Across three challenging real-world tasks, RISE yields significant improvement over prior art, with more than +35% absolute performance increase in dynamic brick sorting, +45% for backpack packing, and +35% for box closing, respectively.",
      "authors": [
        "Jiazhi Yang",
        "Kunyang Lin",
        "Jinwei Li",
        "Wencong Zhang",
        "Tianwei Lin",
        "Longyan Wu",
        "Zhizhong Su",
        "Hao Zhao",
        "Ya-Qin Zhang",
        "Li Chen",
        "Ping Luo",
        "Xiangyu Yue",
        "Hongyang Li"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-11 17:43:36+00:00",
      "link": "https://arxiv.org/pdf/2602.11075v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11066v1",
      "title": "PuriLight: A Lightweight Shuffle and Purification Framework for Monocular Depth Estimation",
      "abstract": "We propose PuriLight, a lightweight and efficient framework for self-supervised monocular depth estimation, to address the dual challenges of computational efficiency and detail preservation. While recent advances in self-supervised depth estimation have reduced reliance on ground truth supervision, existing approaches remain constrained by either bulky architectures compromising practicality or lightweight models sacrificing structural precision. These dual limitations underscore the critical need to develop lightweight yet structurally precise architectures. Our framework addresses these limitations through a three-stage architecture incorporating three novel modules: the Shuffle-Dilation Convolution (SDC) module for local feature extraction, the Rotation-Adaptive Kernel Attention (RAKA) module for hierarchical feature enhancement, and the Deep Frequency Signal Purification (DFSP) module for global feature purification. Through effective collaboration, these modules enable PuriLight to achieve both lightweight and accurate feature extraction and processing. Extensive experiments demonstrate that PuriLight achieves state-of-the-art performance with minimal training parameters while maintaining exceptional computational efficiency. Codes will be available at https://github.com/ishrouder/PuriLight.",
      "authors": [
        "Yujie Chen",
        "Li Zhang",
        "Xiaomeng Chu",
        "Tian Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 17:35:21+00:00",
      "link": "https://arxiv.org/pdf/2602.11066v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11062v1",
      "title": "MoToRec: Sparse-Regularized Multimodal Tokenization for Cold-Start Recommendation",
      "abstract": "Graph neural networks (GNNs) have revolutionized recommender systems by effectively modeling complex user-item interactions, yet data sparsity and the item cold-start problem significantly impair performance, particularly for new items with limited or no interaction history. While multimodal content offers a promising solution, existing methods result in suboptimal representations for new items due to noise and entanglement in sparse data. To address this, we transform multimodal recommendation into discrete semantic tokenization. We present Sparse-Regularized Multimodal Tokenization for Cold-Start Recommendation (MoToRec), a framework centered on a sparsely-regularized Residual Quantized Variational Autoencoder (RQ-VAE) that generates a compositional semantic code of discrete, interpretable tokens, promoting disentangled representations. MoToRec's architecture is enhanced by three synergistic components: (1) a sparsely-regularized RQ-VAE that promotes disentangled representations, (2) a novel adaptive rarity amplification that promotes prioritized learning for cold-start items, and (3) a hierarchical multi-source graph encoder for robust signal fusion with collaborative signals. Extensive experiments on three large-scale datasets demonstrate MoToRec's superiority over state-of-the-art methods in both overall and cold-start scenarios. Our work validates that discrete tokenization provides an effective and scalable alternative for mitigating the long-standing cold-start challenge.",
      "authors": [
        "Jialin Liu",
        "Zhaorui Zhang",
        "Ray C. C. Cheung"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.IR"
      ],
      "published": "2026-02-11 17:31:14+00:00",
      "link": "https://arxiv.org/pdf/2602.11062v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11058v1",
      "title": "A Robust Optimization Approach for Regenerator Placement in Fault-Tolerant Networks Under Discrete Cost Uncertainty",
      "abstract": "We focus on robust, survivable communication networks, where network links and nodes are affected by an uncertainty set. In this sense, any network links might fail. Besides, a signal can only travel a maximum distance before its quality falls below a certain threshold, necessitating its regeneration by regenerators installed at network nodes. In addition, the price of installing and maintaining regenerators belongs to a discrete uncertainty set. Robust optimization seeks a solution with guaranteed performance against all scenarios modeled in an uncertainty set. Thus, the problem is to find a subset of nodes with minimum cost for the placement of the regenerator, ensuring that all nodes can communicate even if a subset of network links fails. To solve the problem optimally, we propose two solution approaches, including one flow-based and one cut-based integer programming formulation, as well as their iterative exact method. Our theoretical and experimental results show the effectiveness of our methods.",
      "authors": [
        "Mohammad Khosravi",
        "Setareh Maghsudi"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-02-11 17:26:10+00:00",
      "link": "https://arxiv.org/pdf/2602.11058v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11057v1",
      "title": "Divide, Harmonize, Then Conquer It: Shooting Multi-Commodity Flow Problems with Multimodal Language Models",
      "abstract": "The multi-commodity flow (MCF) problem is a fundamental topic in network flow and combinatorial optimization, with broad applications in transportation, communication, and logistics, etc. Nowadays, the rapid expansion of allocation systems has posed challenges for existing optimization engines in balancing optimality and tractability. In this paper, we present Pram, the first ML-based method that leverages the reasoning power of multimodal language models (MLMs) for addressing the trade-off dilemma -- a great need of service providers. As part of our proposal, Pram (i) quickly computes high-quality allocations by dividing the original problem into local subproblems, which are then resolved by an MLM-powered \"agent\", and (ii) ensures global consistency by harmonizing these subproblems via a multi-agent reinforcement learning algorithm. Theoretically, we show that Pram, which learns to perform gradient descent in context, provably converges to the optimum within the family of MCF problems. Empirically, on real-world datasets and public topologies, Pram achieves performance comparable to, and in some cases even surpassing, linear programming solvers (very close to the optimal solution), and substantially lower runtimes (1 to 2 orders of magnitude faster). Moreover, Pram exhibits strong robustness (<10\\% performance degradation under link failures or flow bursts), demonstrating MLM's generalization ability to unforeseen events. Pram is objective-agnostic and seamlessly integrates with mainstream allocation systems, providing a practical and scalable solution for future networks.",
      "authors": [
        "Xinyu Yuan",
        "Yan Qiao",
        "Zonghui Wang",
        "Wenzhi Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 17:24:49+00:00",
      "link": "https://arxiv.org/pdf/2602.11057v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11239v1",
      "title": "Toward Reliable Tea Leaf Disease Diagnosis Using Deep Learning Model: Enhancing Robustness With Explainable AI and Adversarial Training",
      "abstract": "Tea is a valuable asset for the economy of Bangladesh. So, tea cultivation plays an important role to boost the economy. These valuable plants are vulnerable to various kinds of leaf infections which may cause less production and low quality. It is not so easy to detect these diseases manually. It may take time and there could be some errors in the detection.Therefore, the purpose of the study is to develop an automated deep learning model for tea leaf disease classification based on the teaLeafBD dataset so that anyone can detect the diseases more easily and efficiently. There are 5,278 high-resolution images in this dataset. The images are classified into seven categories. Six of them represents various diseases and the rest one represents healthy leaves. The proposed pipeline contains data preprocessing, data splitting, adversarial training, augmentation, model training, evaluation, and comprehension made possible with Explainable AI strategies. DenseNet201 and EfficientNetB3 were employed to perform the classification task. To prepare the model more robustly, we applied adversarial training so it can operate effectively even with noisy or disturbed inputs. In addition, Grad-CAM visualization was executed to analyze the model's predictions by identifying the most influential regions of each image. Our experimental outcomes revealed that EfficientNetB3 achieved the highest classification accuracy of 93%, while DenseNet201 reached 91%. The outcomes prove that the effectiveness of the proposed approach can accurately detect tea leaf diseases and provide a practical solution for advanced agricultural management.",
      "authors": [
        "Samanta Ghosh",
        "Jannatul Adan Mahi",
        "Shayan Abrar",
        "Md Parvez Mia",
        "Asaduzzaman Rayhan",
        "Abdul Awal Yasir",
        "Asaduzzaman Hridoy"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 17:21:36+00:00",
      "link": "https://arxiv.org/pdf/2602.11239v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11238v1",
      "title": "SurveyLens: A Research Discipline-Aware Benchmark for Automatic Survey Generation",
      "abstract": "The exponential growth of scientific literature has driven the evolution of Automatic Survey Generation (ASG) from simple pipelines to multi-agent frameworks and commercial Deep Research agents. However, current ASG evaluation methods rely on generic metrics and are heavily biased toward Computer Science (CS), failing to assess whether ASG methods adhere to the distinct standards of various academic disciplines. Consequently, researchers, especially those outside CS, lack clear guidance on using ASG systems to yield high-quality surveys compliant with specific discipline standards. To bridge this gap, we introduce SurveyLens, the first discipline-aware benchmark evaluating ASG methods across diverse research disciplines. We construct SurveyLens-1k, a curated dataset of 1,000 high-quality human-written surveys spanning 10 disciplines. Subsequently, we propose a dual-lens evaluation framework: (1) Discipline-Aware Rubric Evaluation, which utilizes LLMs with human preference-aligned weights to assess adherence to domain-specific writing standards; and (2) Canonical Alignment Evaluation to rigorously measure content coverage and synthesis quality against human-written survey papers. We conduct extensive experiments by evaluating 11 state-of-the-art ASG methods on SurveyLens, including Vanilla LLMs, ASG systems, and Deep Research agents. Our analysis reveals the distinct strengths and weaknesses of each paradigm across fields, providing essential guidance for selecting tools tailored to specific disciplinary requirements.",
      "authors": [
        "Beichen Guo",
        "Zhiyuan Wen",
        "Jia Gu",
        "Senzhang Wang",
        "Haochen Shi",
        "Ruosong Yang",
        "Shuaiqi Liu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-11 17:16:43+00:00",
      "link": "https://arxiv.org/pdf/2602.11238v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11037v1",
      "title": "Generalized Langevin Models of Linear Agent-Based Systems: Strategic Influence Through Environmental Coupling",
      "abstract": "Agent-based models typically treat systems in isolation, discarding environmental coupling as either computationally prohibitive or dynamically irrelevant. We demonstrate that this neglect misses essential physics: environmental degrees of freedom create memory effects that fundamentally alter system dynamics. By systematically transforming linear update rules into exact generalized Langevin equations, we show that unobserved environmental agents manifest as memory kernels whose timescales and coupling strengths are determined by the environmental interaction spectrum. Network topology shapes this memory structure in distinct ways: small-world rewiring drives dynamics toward a single dominant relaxation mode, while fragmented environments sustain multiple persistent modes corresponding to isolated subpopulations. We apply this framework to covert influence operations where adversaries manipulate target populations exclusively via environmental intermediaries. The steady-state response admits a random-walk interpretation through hitting probabilities, revealing how zealot opinions diffuse through the environment to shift system agent opinions toward the zealot mean - even when zealots never directly contact targets.",
      "authors": [
        "Semra Gunduc",
        "David J. Butts",
        "Michael S. Murillo"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph",
        "cs.MA"
      ],
      "published": "2026-02-11 17:08:23+00:00",
      "link": "https://arxiv.org/pdf/2602.11037v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11237v1",
      "title": "AI-Driven Clinical Decision Support System for Enhanced Diabetes Diagnosis and Management",
      "abstract": "Identifying type 2 diabetes mellitus can be challenging, particularly for primary care physicians. Clinical decision support systems incorporating artificial intelligence (AI-CDSS) can assist medical professionals in diagnosing type 2 diabetes with high accuracy. This study aimed to assess an AI-CDSS specifically developed for the diagnosis of type 2 diabetes by employing a hybrid approach that integrates expert-driven insights with machine learning techniques. The AI-CDSS was developed (training dataset: n = 650) and tested (test dataset: n = 648) using a dataset of 1298 patients with and without type 2 diabetes. To generate predictions, the algorithm utilized key features such as body mass index, plasma fasting glucose, and hemoglobin A1C. Furthermore, a clinical pilot study involving 105 patients was conducted to assess the diagnostic accuracy of the system in comparison to non-endocrinology specialists. The AI-CDSS showed a high degree of accuracy, with 99.8% accuracy in predicting diabetes, 99.3% in predicting prediabetes, 99.2% in identifying at-risk individuals, and 98.8% in predicting no diabetes. The test dataset revealed a 98.8% agreement between endocrinology specialists and the AI-CDSS. Type 2 diabetes was identified in 45% of 105 individuals in the pilot study. Compared with diabetes specialists, the AI-CDSS scored a 98.5% concordance rate, greatly exceeding that of nonendocrinology specialists, who had an 85% agreement rate. These findings indicate that the AI-CDSS has the potential to be a useful tool for accurately identifying type 2 diabetes, especially in situations in which diabetes specialists are not readily available.",
      "authors": [
        "Mujeeb Ur Rehman",
        "Imran Rehan",
        "Sohail Khalid"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 17:06:06+00:00",
      "link": "https://arxiv.org/pdf/2602.11237v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11028v1",
      "title": "Linguistic Indicators of Early Cognitive Decline in the DementiaBank Pitt Corpus: A Statistical and Machine Learning Study",
      "abstract": "Background: Subtle changes in spontaneous language production are among the earliest indicators of cognitive decline. Identifying linguistically interpretable markers of dementia can support transparent and clinically grounded screening approaches.   Methods: This study analyzes spontaneous speech transcripts from the DementiaBank Pitt Corpus using three linguistic representations: raw cleaned text, a part-of-speech (POS)-enhanced representation combining lexical and grammatical information, and a POS-only syntactic representation. Logistic regression and random forest models were evaluated under two protocols: transcript-level train-test splits and subject-level five-fold cross-validation to prevent speaker overlap. Model interpretability was examined using global feature importance, and statistical validation was conducted using Mann-Whitney U tests with Cliff's delta effect sizes.   Results: Across representations, models achieved stable performance, with syntactic and grammatical features retaining strong discriminative power even in the absence of lexical content. Subject-level evaluation yielded more conservative but consistent results, particularly for POS-enhanced and POS-only representations. Statistical analysis revealed significant group differences in functional word usage, lexical diversity, sentence structure, and discourse coherence, aligning closely with machine learning feature importance findings.   Conclusion: The results demonstrate that abstract linguistic features capture robust markers of early cognitive decline under clinically realistic evaluation. By combining interpretable machine learning with non-parametric statistical validation, this study supports the use of linguistically grounded features for transparent and reliable language-based cognitive screening.",
      "authors": [
        "Artsvik Avetisyan",
        "Sachin Kumar"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-11 16:53:57+00:00",
      "link": "https://arxiv.org/pdf/2602.11028v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11025v1",
      "title": "Reality Copilot: Voice-First Human-AI Collaboration in Mixed Reality Using Large Multimodal Models",
      "abstract": "Large Multimodal Models (LMMs) have shown strong potential for assisting users in tasks, such as programming, content creation, and information access, yet their interaction remains largely limited to traditional interfaces such as desktops and smartphones. Meanwhile, advances in mixed reality (MR) hardware have enabled applications that extend beyond entertainment and into everyday use. However, most existing MR systems rely primarily on manual input (e.g., hand gestures or controllers) and provide limited intelligent assistance due to the lack of integration with large-scale AI models. We present Reality Copilot, a voice-first human-AI assistant for mixed reality that leverages LMMs to enable natural speech-based interaction. The system supports contextual understanding of physical environments, realistic 3D content generation, and real-time information retrieval. In addition to in-headset interaction, Reality Copilot facilitates cross-platform workflows by generating context-aware textual content and exporting generated assets. This work explores the design space of LMM-powered human-AI collaboration in mixed reality.",
      "authors": [
        "Liuchuan Yu",
        "Yongqi Zhang",
        "Lap-Fai Yu"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-11 16:51:54+00:00",
      "link": "https://arxiv.org/pdf/2602.11025v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11024v1",
      "title": "Chain-of-Look Spatial Reasoning for Dense Surgical Instrument Counting",
      "abstract": "Accurate counting of surgical instruments in Operating Rooms (OR) is a critical prerequisite for ensuring patient safety during surgery. Despite recent progress of large visual-language models and agentic AI, accurately counting such instruments remains highly challenging, particularly in dense scenarios where instruments are tightly clustered. To address this problem, we introduce Chain-of-Look, a novel visual reasoning framework that mimics the sequential human counting process by enforcing a structured visual chain, rather than relying on classic object detection which is unordered. This visual chain guides the model to count along a coherent spatial trajectory, improving accuracy in complex scenes. To further enforce the physical plausibility of the visual chain, we introduce the neighboring loss function, which explicitly models the spatial constraints inherent to densely packed surgical instruments. We also present SurgCount-HD, a new dataset comprising 1,464 high-density surgical instrument images. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches for counting (e.g., CountGD, REC) as well as Multimodality Large Language Models (e.g., Qwen, ChatGPT) in the challenging task of dense surgical instrument counting.",
      "authors": [
        "Rishikesh Bhyri",
        "Brian R Quaranto",
        "Philip J Seger",
        "Kaity Tung",
        "Brendan Fox",
        "Gene Yang",
        "Steven D. Schwaitzberg",
        "Junsong Yuan",
        "Nan Xi",
        "Peter C W Kim"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-11 16:49:37+00:00",
      "link": "https://arxiv.org/pdf/2602.11024v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11021v1",
      "title": "ContactGaussian-WM: Learning Physics-Grounded World Model from Videos",
      "abstract": "Developing world models that understand complex physical interactions is essential for advancing robotic planning and simulation.However, existing methods often struggle to accurately model the environment under conditions of data scarcity and complex contact-rich dynamic motion.To address these challenges, we propose ContactGaussian-WM, a differentiable physics-grounded rigid-body world model capable of learning intricate physical laws directly from sparse and contact-rich video sequences.Our framework consists of two core components: (1) a unified Gaussian representation for both visual appearance and collision geometry, and (2) an end-to-end differentiable learning framework that differentiates through a closed-form physics engine to infer physical properties from sparse visual observations.Extensive simulations and real-world evaluations demonstrate that ContactGaussian-WM outperforms state-of-the-art methods in learning complex scenarios, exhibiting robust generalization capabilities.Furthermore, we showcase the practical utility of our framework in downstream applications, including data synthesis and real-time MPC.",
      "authors": [
        "Meizhong Wang",
        "Wanxin Jin",
        "Kun Cao",
        "Lihua Xie",
        "Yiguang Hong"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-11 16:48:13+00:00",
      "link": "https://arxiv.org/pdf/2602.11021v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11019v1",
      "title": "Mask-Based Window-Level Insider Threat Detection for Campaign Discovery",
      "abstract": "User and Entity Behavior Analytics (UEBA) systems commonly detect insider threats by scoring fixed time windows of user activity for anomalous behavior. While this window-level paradigm has proven effective for identifying sharp behavioral deviations, it remains unclear how much information about longer-running attack campaigns is already present within individual windows, and how such information can be leveraged for campaign discovery. In this work, we study unsupervised window-level insider threat detection on the CERT r4.2 dataset and show that explicitly separating activity presence from activity magnitude yields substantial performance gains. We introduce a dual-channel convolutional autoencoder that reconstructs both a binary activity mask and corresponding activity values, allowing the model to focus representational capacity on sparse behavioral structure rather than dense inactive baselines. Across multiday attack campaigns lasting between one and seven days, the proposed approach achieves a window-level precision-recall AUC of 0.71, substantially exceeding standard unsupervised autoencoder baselines and enabling high-precision operating points with zero false alarms.",
      "authors": [
        "Jericho Cain",
        "Hayden Beadles"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-11 16:43:01+00:00",
      "link": "https://arxiv.org/pdf/2602.11019v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11234v1",
      "title": "Learning Glioblastoma Tumor Heterogeneity Using Brain Inspired Topological Neural Networks",
      "abstract": "Accurate prognosis for Glioblastoma (GBM) using deep learning (DL) is hindered by extreme spatial and structural heterogeneity. Moreover, inconsistent MRI acquisition protocols across institutions hinder generalizability of models. Conventional transformer and DL pipelines often fail to capture the multi-scale morphological diversity such as fragmented necrotic cores, infiltrating margins, and disjoint enhancing components leading to scanner-specific artifacts and poor cross-site prognosis. We propose TopoGBM, a learning framework designed to capture heterogeneity-preserved, scanner-robust representations from multi-parametric 3D MRI. Central to our approach is a 3D convolutional autoencoder regularized by a topological regularization that preserves the complex, non-Euclidean invariants of the tumor's manifold within a compressed latent space. By enforcing these topological priors, TopoGBM explicitly models the high-variance structural signatures characteristic of aggressive GBM. Evaluated across heterogeneous cohorts (UPENN, UCSF, RHUH) and external validation on TCGA, TopoGBM achieves better performance (C-index 0.67 test, 0.58 validation), outperforming baselines that degrade under domain shift. Mechanistic interpretability analysis reveals that reconstruction residuals are highly localized to pathologically heterogeneous zones, with tumor-restricted and healthy tissue error significantly low (Test: 0.03, Validation: 0.09). Furthermore, occlusion-based attribution localizes approximately 50% of the prognostic signal to the tumor and the diverse peritumoral microenvironment advocating clinical reliability of the unsupervised learning method. Our findings demonstrate that incorporating topological priors enables the learning of morphology-faithful embeddings that capture tumor heterogeneity while maintaining cross-institutional robustness.",
      "authors": [
        "Ankita Paul",
        "Wenyi Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "q-bio.NC"
      ],
      "published": "2026-02-11 16:28:13+00:00",
      "link": "https://arxiv.org/pdf/2602.11234v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11000v1",
      "title": "Fine-Tuning GPT-5 for GPU Kernel Generation",
      "abstract": "Developing efficient GPU kernels is essential for scaling modern AI systems, yet it remains a complex task due to intricate hardware architectures and the need for specialized optimization expertise. Although Large Language Models (LLMs) demonstrate strong capabilities in general sequential code generation, they face significant challenges in GPU code generation because of the scarcity of high-quality labeled training data, compiler biases when generating synthetic solutions, and limited generalization across hardware generations. This precludes supervised fine-tuning (SFT) as a scalable methodology for improving current LLMs. In contrast, reinforcement learning (RL) offers a data-efficient and adaptive alternative but requires access to relevant tools, careful selection of training problems, and a robust evaluation environment. We present Makora's environment and tools for reinforcement learning finetuning of frontier models and report our results from fine-tuning GPT-5 for Triton code generation. In the single-attempt setting, our fine-tuned model improves kernel correctness from 43.7% to 77.0% (+33.3 percentage points) and increases the fraction of problems outperforming TorchInductor from 14.8% to 21.8% (+7 percentage points) compared to baseline GPT-5, while exceeding prior state-of-the-art models on KernelBench. When integrated into a full coding agent, it is able to solve up to 97.4% of problems in an expanded KernelBench suite, outperforming the PyTorch TorchInductor compiler on 72.9% of problems with a geometric mean speedup of 2.12x. Our work demonstrates that targeted post-training with reinforcement learning can unlock LLM capabilities in highly specialized technical domains where traditional supervised learning is limited by data availability, opening new pathways for AI-assisted accelerator programming.",
      "authors": [
        "Ali Tehrani",
        "Yahya Emara",
        "Essam Wissam",
        "Wojciech Paluch",
        "Waleed Atallah",
        "Łukasz Dudziak",
        "Mohamed S. Abdelfattah"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 16:22:54+00:00",
      "link": "https://arxiv.org/pdf/2602.11000v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10997v1",
      "title": "Multi-Task Reinforcement Learning of Drone Aerobatics by Exploiting Geometric Symmetries",
      "abstract": "Flight control for autonomous micro aerial vehicles (MAVs) is evolving from steady flight near equilibrium points toward more aggressive aerobatic maneuvers, such as flips, rolls, and Power Loop. Although reinforcement learning (RL) has shown great potential in these tasks, conventional RL methods often suffer from low data efficiency and limited generalization. This challenge becomes more pronounced in multi-task scenarios where a single policy is required to master multiple maneuvers. In this paper, we propose a novel end-to-end multi-task reinforcement learning framework, called GEAR (Geometric Equivariant Aerobatics Reinforcement), which fully exploits the inherent SO(2) rotational symmetry in MAV dynamics and explicitly incorporates this property into the policy network architecture. By integrating an equivariant actor network, FiLM-based task modulation, and a multi-head critic, GEAR achieves both efficiency and flexibility in learning diverse aerobatic maneuvers, enabling a data-efficient, robust, and unified framework for aerobatic control. GEAR attains a 98.85\\% success rate across various aerobatic tasks, significantly outperforming baseline methods. In real-world experiments, GEAR demonstrates stable execution of multiple maneuvers and the capability to combine basic motion primitives to complete complex aerobatics.",
      "authors": [
        "Zhanyu Guo",
        "Zikang Yin",
        "Guobin Zhu",
        "Shiliang Guo",
        "Shiyu Zhao"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-11 16:21:48+00:00",
      "link": "https://arxiv.org/pdf/2602.10997v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10996v1",
      "title": "The emergence of numerical representations in communicating artificial agents",
      "abstract": "Human languages provide efficient systems for expressing numerosities, but whether the sheer pressure to communicate is enough for numerical representations to arise in artificial agents, and whether the emergent codes resemble human numerals at all, remains an open question. We study two neural network-based agents that must communicate numerosities in a referential game using either discrete tokens or continuous sketches, thus exploring both symbolic and iconic representations. Without any pre-defined numeric concepts, the agents achieve high in-distribution communication accuracy in both communication channels and converge on high-precision symbol-meaning mappings. However, the emergent code is non-compositional: the agents fail to derive systematic messages for unseen numerosities, typically reusing the symbol of the highest trained numerosity (discrete), or collapsing extrapolated values onto a single sketch (continuous). We conclude that the communication pressure alone suffices for precise transmission of learned numerosities, but additional pressures are needed to yield compositional codes and generalisation abilities.",
      "authors": [
        "Daniela Mihai",
        "Lucas Weber",
        "Francesca Franzon"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-11 16:21:43+00:00",
      "link": "https://arxiv.org/pdf/2602.10996v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10994v1",
      "title": "Interpretable Vision Transformers in Image Classification via SVDA",
      "abstract": "Vision Transformers (ViTs) have achieved state-of-the-art performance in image classification, yet their attention mechanisms often remain opaque and exhibit dense, non-structured behaviors. In this work, we adapt our previously proposed SVD-Inspired Attention (SVDA) mechanism to the ViT architecture, introducing a geometrically grounded formulation that enhances interpretability, sparsity, and spectral structure. We apply the use of interpretability indicators -- originally proposed with SVDA -- to monitor attention dynamics during training and assess structural properties of the learned representations. Experimental evaluations on four widely used benchmarks -- CIFAR-10, FashionMNIST, CIFAR-100, and ImageNet-100 -- demonstrate that SVDA consistently yields more interpretable attention patterns without sacrificing classification accuracy. While the current framework offers descriptive insights rather than prescriptive guidance, our results establish SVDA as a comprehensive and informative tool for analyzing and developing structured attention models in computer vision. This work lays the foundation for future advances in explainable AI, spectral diagnostics, and attention-based model compression.",
      "authors": [
        "Vasileios Arampatzakis",
        "George Pavlidis",
        "Nikolaos Mitianoudis",
        "Nikos Papamarkos"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 16:20:32+00:00",
      "link": "https://arxiv.org/pdf/2602.10994v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10985v1",
      "title": "DFIC: Towards a balanced facial image dataset for automatic ICAO compliance verification",
      "abstract": "Ensuring compliance with ISO/IEC and ICAO standards for facial images in machine-readable travel documents (MRTDs) is essential for reliable identity verification, but current manual inspection methods are inefficient in high-demand environments. This paper introduces the DFIC dataset, a novel comprehensive facial image dataset comprising around 58,000 annotated images and 2706 videos of more than 1000 subjects, that cover a broad range of non-compliant conditions, in addition to compliant portraits. Our dataset provides a more balanced demographic distribution than the existing public datasets, with one partition that is nearly uniformly distributed, facilitating the development of automated ICAO compliance verification methods.   Using DFIC, we fine-tuned a novel method that heavily relies on spatial attention mechanisms for the automatic validation of ICAO compliance requirements, and we have compared it with the state-of-the-art aimed at ICAO compliance verification, demonstrating improved results. DFIC dataset is now made public (https://github.com/visteam-isr-uc/DFIC) for the training and validation of new models, offering an unprecedented diversity of faces, that will improve both robustness and adaptability to the intrinsically diverse combinations of faces and props that can be presented to the validation system. These results emphasize the potential of DFIC to enhance automated ICAO compliance methods but it can also be used in many other applications that aim to improve the security, privacy, and fairness of facial recognition systems.",
      "authors": [
        "Nuno Gonçalves",
        "Diogo Nunes",
        "Carla Guerra",
        "João Marcos"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 16:13:17+00:00",
      "link": "https://arxiv.org/pdf/2602.10985v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10984v1",
      "title": "Sample Efficient Generative Molecular Optimization with Joint Self-Improvement",
      "abstract": "Generative molecular optimization aims to design molecules with properties surpassing those of existing compounds. However, such candidates are rare and expensive to evaluate, yielding sample efficiency essential. Additionally, surrogate models introduced to predict molecule evaluations, suffer from distribution shift as optimization drives candidates increasingly out-of-distribution. To address these challenges, we introduce Joint Self-Improvement, which benefits from (i) a joint generative-predictive model and (ii) a self-improving sampling scheme. The former aligns the generator with the surrogate, alleviating distribution shift, while the latter biases the generative part of the joint model using the predictive one to efficiently generate optimized molecules at inference-time. Experiments across offline and online molecular optimization benchmarks demonstrate that Joint Self-Improvement outperforms state-of-the-art methods under limited evaluation budgets.",
      "authors": [
        "Serra Korkmaz",
        "Adam Izdebski",
        "Jonathan Pirnay",
        "Rasmus Møller-Larsen",
        "Michal Kmicikiewicz",
        "Pankhil Gawade",
        "Dominik G. Grimm",
        "Ewa Szczurek"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 16:13:07+00:00",
      "link": "https://arxiv.org/pdf/2602.10984v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10982v1",
      "title": "RiemannGL: Riemannian Geometry Changes Graph Deep Learning",
      "abstract": "Graphs are ubiquitous, and learning on graphs has become a cornerstone in artificial intelligence and data mining communities. Unlike pixel grids in images or sequential structures in language, graphs exhibit a typical non-Euclidean structure with complex interactions among the objects. This paper argues that Riemannian geometry provides a principled and necessary foundation for graph representation learning, and that Riemannian graph learning should be viewed as a unifying paradigm rather than a collection of isolated techniques. While recent studies have explored the integration of graph learning and Riemannian geometry, most existing approaches are limited to a narrow class of manifolds, particularly hyperbolic spaces, and often adopt extrinsic manifold formulations. We contend that the central mission of Riemannian graph learning is to endow graph neural networks with intrinsic manifold structures, which remains underexplored. To advance this perspective, we identify key conceptual and methodological gaps in existing approaches and outline a structured research agenda along three dimensions: manifold type, neural architecture, and learning paradigm. We further discuss open challenges, theoretical foundations, and promising directions that are critical for unlocking the full potential of Riemannian graph learning. This paper aims to provide a coherent viewpoint and to stimulate broader exploration of Riemannian geometry as a foundational framework for future graph learning research.",
      "authors": [
        "Li Sun",
        "Qiqi Wan",
        "Suyang Zhou",
        "Zhenhao Huang",
        "Philip S. Yu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 16:10:53+00:00",
      "link": "https://arxiv.org/pdf/2602.10982v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10980v1",
      "title": "RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation",
      "abstract": "VLA models have achieved remarkable progress in embodied intelligence; however, their evaluation remains largely confined to simulations or highly constrained real-world settings. This mismatch creates a substantial reality gap, where strong benchmark performance often masks poor generalization in diverse physical environments. We identify three systemic shortcomings in current benchmarking practices that hinder fair and reliable model comparison. (1) Existing benchmarks fail to model real-world dynamics, overlooking critical factors such as dynamic object configurations, robot initial states, lighting changes, and sensor noise. (2) Current protocols neglect spatial--physical intelligence, reducing evaluation to rote manipulation tasks that do not probe geometric reasoning. (3) The field lacks scalable fully autonomous evaluation, instead relying on simplistic 2D metrics that miss 3D spatial structure or on human-in-the-loop systems that are costly, biased, and unscalable. To address these limitations, we introduce RADAR (Real-world Autonomous Dynamics And Reasoning), a benchmark designed to systematically evaluate VLA generalization under realistic conditions. RADAR integrates three core components: (1) a principled suite of physical dynamics; (2) dedicated tasks that explicitly test spatial reasoning and physical understanding; and (3) a fully autonomous evaluation pipeline based on 3D metrics, eliminating the need for human supervision. We apply RADAR to audit multiple state-of-the-art VLA models and uncover severe fragility beneath their apparent competence. Performance drops precipitously under modest physical dynamics, with the expectation of 3D IoU declining from 0.261 to 0.068 under sensor noise. Moreover, models exhibit limited spatial reasoning capability. These findings position RADAR as a necessary bench toward reliable and generalizable real-world evaluation of VLA models.",
      "authors": [
        "Yuhao Chen",
        "Zhihao Zhan",
        "Xiaoxin Lin",
        "Zijian Song",
        "Hao Liu",
        "Qinhan Lyu",
        "Yubo Zu",
        "Xiao Chen",
        "Zhiyuan Liu",
        "Tao Pu",
        "Tianshui Chen",
        "Keze Wang",
        "Liang Lin",
        "Guangrun Wang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-11 16:08:30+00:00",
      "link": "https://arxiv.org/pdf/2602.10980v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10978v1",
      "title": "VFGS-Net: Frequency-Guided State-Space Learning for Topology-Preserving Retinal Vessel Segmentation",
      "abstract": "Accurate retinal vessel segmentation is a critical prerequisite for quantitative analysis of retinal images and computer-aided diagnosis of vascular diseases such as diabetic retinopathy. However, the elongated morphology, wide scale variation, and low contrast of retinal vessels pose significant challenges for existing methods, making it difficult to simultaneously preserve fine capillaries and maintain global topological continuity. To address these challenges, we propose the Vessel-aware Frequency-domain and Global Spatial modeling Network (VFGS-Net), an end-to-end segmentation framework that seamlessly integrates frequency-aware feature enhancement, dual-path convolutional representation learning, and bidirectional asymmetric spatial state-space modeling within a unified architecture. Specifically, VFGS-Net employs a dual-path feature convolution module to jointly capture fine-grained local textures and multi-scale contextual semantics. A novel vessel-aware frequency-domain channel attention mechanism is introduced to adaptively reweight spectral components, thereby enhancing vessel-relevant responses in high-level features. Furthermore, at the network bottleneck, we propose a bidirectional asymmetric Mamba2-based spatial modeling block to efficiently capture long-range spatial dependencies and strengthen the global continuity of vascular structures. Extensive experiments on four publicly available retinal vessel datasets demonstrate that VFGS-Net achieves competitive or superior performance compared to state-of-the-art methods. Notably, our model consistently improves segmentation accuracy for fine vessels, complex branching patterns, and low-contrast regions, highlighting its robustness and clinical potential.",
      "authors": [
        "Ruiqi Song",
        "Lei Liu",
        "Ya-Nan Zhang",
        "Chao Wang",
        "Xiaoning Li",
        "Nan Mu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 16:07:29+00:00",
      "link": "https://arxiv.org/pdf/2602.10978v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10965v1",
      "title": "MoEEdit: Efficient and Routing-Stable Knowledge Editing for Mixture-of-Experts LLMs",
      "abstract": "Knowledge editing (KE) enables precise modifications to factual content in large language models (LLMs). Existing KE methods are largely designed for dense architectures, limiting their applicability to the increasingly prevalent sparse Mixture-of-Experts (MoE) models that underpin modern scalable LLMs. Although MoEs offer strong efficiency and capacity scaling, naively adapting dense-model editors is both computationally costly and prone to routing distribution shifts that undermine stability and consistency. To address these challenges, we introduce MoEEdit, the first routing-stable framework for parameter-modifying knowledge editing in MoE LLMs. Our method reparameterizes expert updates via per-expert null-space projections that keep router inputs invariant and thereby suppress routing shifts. The resulting block-structured optimization is solved efficiently with a block coordinate descent (BCD) solver. Experiments show that MoEEdit attains state-of-the-art efficacy and generalization while preserving high specificity and routing stability, with superior compute and memory efficiency. These results establish a robust foundation for scalable, precise knowledge editing in sparse LLMs and underscore the importance of routing-stable interventions.",
      "authors": [
        "Yupu Gu",
        "Rongzhe Wei",
        "Andy Zhu",
        "Pan Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 15:56:30+00:00",
      "link": "https://arxiv.org/pdf/2602.10965v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10963v1",
      "title": "Lie Group Variational Integrator for the Geometrically Exact Rod with Circular Cross-Section Incorporating Cross-Sectional Deformation",
      "abstract": "In this paper, we derive the continuous space-time equations of motion of a three-dimensional geometrically exact rod, or the Cosserat rod, incorporating planar cross-sectional deformation. We then adopt the Lie group variational integrator technique to obtain a discrete model of the rod incorporating both rotational motion and cross-sectional deformation as well. The resulting discrete model possesses several desirable features: it ensures volume conservation of the discrete elements by considering cross-sectional deformation through a local dilatation factor, it demonstrates the beneficial properties associated with the variational integrator technique, such as the preservation of the rotational configuration, and energy conservation with a bounded error. An exhaustive set of numerical results under various initial conditions of the rod demonstrates the efficacy of the model in replicating the physics of the system.",
      "authors": [
        "Srishti Siddharth",
        "Vivek Natarajan",
        "Ravi N. Banavar"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.RO",
        "math.NA"
      ],
      "published": "2026-02-11 15:54:59+00:00",
      "link": "https://arxiv.org/pdf/2602.10963v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10949v1",
      "title": "Optimal Initialization in Depth: Lyapunov Initialization and Limit Theorems for Deep Leaky ReLU Networks",
      "abstract": "The development of effective initialization methods requires an understanding of random neural networks. In this work, a rigorous probabilistic analysis of deep unbiased Leaky ReLU networks is provided. We prove a Law of Large Numbers and a Central Limit Theorem for the logarithm of the norm of network activations, establishing that, as the number of layers increases, their growth is governed by a parameter called the Lyapunov exponent. This parameter characterizes a sharp phase transition between vanishing and exploding activations, and we calculate the Lyapunov exponent explicitly for Gaussian or orthogonal weight matrices. Our results reveal that standard methods, such as He initialization or orthogonal initialization, do not guarantee activation stabilty for deep networks of low width. Based on these theoretical insights, we propose a novel initialization method, referred to as Lyapunov initialization, which sets the Lyapunov exponent to zero and thereby ensures that the neural network is as stable as possible, leading empirically to improved learning.",
      "authors": [
        "Constantin Kogler",
        "Tassilo Schwarz",
        "Samuel Kittle"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.DS",
        "math.PR"
      ],
      "published": "2026-02-11 15:36:13+00:00",
      "link": "https://arxiv.org/pdf/2602.10949v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11230v1",
      "title": "DiSCoKit: An Open-Source Toolkit for Deploying Live LLM Experiences in Survey Research",
      "abstract": "Advancing social-scientific research of human-AI interaction dynamics and outcomes often requires researchers to deliver experiences with live large-language models (LLMs) to participants through online survey platforms. However, technical and practical challenges (from logging chat data to manipulating AI behaviors for experimental designs) often inhibit survey-based deployment of AI stimuli. We developed DiSCoKit--an open-source toolkit for deploying live LLM experiences (e.g., ones based on models delivered through Microsoft Azure portal) through JavaScript-enabled survey platforms (e.g., Qualtrics). This paper introduces that toolkit, explaining its scientific impetus, describes its architecture and operation, as well as its deployment possibilities and limitations.",
      "authors": [
        "Jaime Banks",
        "Jon Stromer-Galley",
        "Samiksha Singh",
        "Collin Capano"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-11 15:35:50+00:00",
      "link": "https://arxiv.org/pdf/2602.11230v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11229v1",
      "title": "Latent Generative Solvers for Generalizable Long-Term Physics Simulation",
      "abstract": "We study long-horizon surrogate simulation across heterogeneous PDE systems. We introduce Latent Generative Solvers (LGS), a two-stage framework that (i) maps diverse PDE states into a shared latent physics space with a pretrained VAE, and (ii) learns probabilistic latent dynamics with a Transformer trained by flow matching. Our key mechanism is an uncertainty knob that perturbs latent inputs during training and inference, teaching the solver to correct off-manifold rollout drift and stabilizing autoregressive prediction. We further use flow forcing to update a system descriptor (context) from model-generated trajectories, aligning train/test conditioning and improving long-term stability. We pretrain on a curated corpus of $\\sim$2.5M trajectories at $128^2$ resolution spanning 12 PDE families. LGS matches strong deterministic neural-operator baselines on short horizons while substantially reducing rollout drift on long horizons. Learning in latent space plus efficient architectural choices yields up to \\textbf{70$\\times$} lower FLOPs than non-generative baselines, enabling scalable pretraining. We also show efficient adaptation to an out-of-distribution $256^2$ Kolmogorov flow dataset under limited finetuning budgets. Overall, LGS provides a practical route toward generalizable, uncertainty-aware neural PDE solvers that are more reliable for long-term forecasting and downstream scientific workflows.",
      "authors": [
        "Zituo Chen",
        "Haixu Wu",
        "Sili Deng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 15:34:52+00:00",
      "link": "https://arxiv.org/pdf/2602.11229v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10916v1",
      "title": "Traceable, Enforceable, and Compensable Participation: A Participation Ledger for People-Centered AI Governance",
      "abstract": "Participatory approaches are widely invoked in AI governance, yet participation rarely translates into durable influence. In public sector and civic AI systems, community contributions such as deliberations, annotations, prompts, and incident reports are often recorded informally, weakly linked to system updates, and disconnected from enforceable rights or sustained compensation. As a result, participation is frequently symbolic rather than accountable. We introduce the Participation Ledger, a machine readable and auditable framework that operationalizes participation as traceable influence, enforceable authority, and compensable labor. The ledger represents participation as an influence graph that links contributed artifacts to verified changes in AI systems, including datasets, prompts, adapters, policies, guardrails, and evaluation suites. It integrates three elements: a Participation Evidence Standard documenting consent, privacy, compensation, and reuse terms; an influence tracing mechanism that connects system updates to replayable before and after tests, enabling longitudinal monitoring of commitments; and encoded rights and incentives. Capability Vouchers allow authorized community stewards to request or constrain specific system capabilities within defined boundaries, while Participation Credits support ongoing recognition and compensation when contributed tests continue to provide value. We ground the framework in four urban AI and public space governance deployments and provide a machine readable schema, templates, and an evaluation plan for assessing traceability, enforceability, and compensation in practice.",
      "authors": [
        "Rashid Mushkani"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "published": "2026-02-11 14:53:58+00:00",
      "link": "https://arxiv.org/pdf/2602.10916v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10910v1",
      "title": "Safe mobility support system using crowd mapping and avoidance route planning using VLM",
      "abstract": "Autonomous mobile robots offer promising solutions for labor shortages and increased operational efficiency. However, navigating safely and effectively in dynamic environments, particularly crowded areas, remains challenging. This paper proposes a novel framework that integrates Vision-Language Models (VLM) and Gaussian Process Regression (GPR) to generate dynamic crowd-density maps (``Abstraction Maps'') for autonomous robot navigation. Our approach utilizes VLM's capability to recognize abstract environmental concepts, such as crowd densities, and represents them probabilistically via GPR. Experimental results from real-world trials on a university campus demonstrated that robots successfully generated routes avoiding both static obstacles and dynamic crowds, enhancing navigation safety and adaptability.",
      "authors": [
        "Sena Saito",
        "Kenta Tabata",
        "Renato Miyagusuku",
        "Koichi Ozaki"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-11 14:47:51+00:00",
      "link": "https://arxiv.org/pdf/2602.10910v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10905v1",
      "title": "Natural Hypergradient Descent: Algorithm Design, Convergence Analysis, and Parallel Implementation",
      "abstract": "In this work, we propose Natural Hypergradient Descent (NHGD), a new method for solving bilevel optimization problems. To address the computational bottleneck in hypergradient estimation--namely, the need to compute or approximate Hessian inverse--we exploit the statistical structure of the inner optimization problem and use the empirical Fisher information matrix as an asymptotically consistent surrogate for the Hessian. This design enables a parallel optimize-and-approximate framework in which the Hessian-inverse approximation is updated synchronously with the stochastic inner optimization, reusing gradient information at negligible additional cost. Our main theoretical contribution establishes high-probability error bounds and sample complexity guarantees for NHGD that match those of state-of-the-art optimize-then-approximate methods, while significantly reducing computational time overhead. Empirical evaluations on representative bilevel learning tasks further demonstrate the practical advantages of NHGD, highlighting its scalability and effectiveness in large-scale machine learning settings.",
      "authors": [
        "Deyi Kong",
        "Zaiwei Chen",
        "Shuzhong Zhang",
        "Shancong Mou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "published": "2026-02-11 14:31:33+00:00",
      "link": "https://arxiv.org/pdf/2602.10905v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10894v1",
      "title": "Resource-Efficient Model-Free Reinforcement Learning for Board Games",
      "abstract": "Board games have long served as complex decision-making benchmarks in artificial intelligence. In this field, search-based reinforcement learning methods such as AlphaZero have achieved remarkable success. However, their significant computational demands have been pointed out as barriers to their reproducibility. In this study, we propose a model-free reinforcement learning algorithm designed for board games to achieve more efficient learning. To validate the efficiency of the proposed method, we conducted comprehensive experiments on five board games: Animal Shogi, Gardner Chess, Go, Hex, and Othello. The results demonstrate that the proposed method achieves more efficient learning than existing methods across these environments. In addition, our extensive ablation study shows the importance of core techniques used in the proposed method. We believe that our efficient algorithm shows the potential of model-free reinforcement learning in domains traditionally dominated by search-based methods.",
      "authors": [
        "Kazuki Ota",
        "Takayuki Osa",
        "Motoki Omura",
        "Tatsuya Harada"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 14:25:38+00:00",
      "link": "https://arxiv.org/pdf/2602.10894v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10891v1",
      "title": "Interactive LLM-assisted Curriculum Learning for Multi-Task Evolutionary Policy Search",
      "abstract": "Multi-task policy search is a challenging problem because policies are required to generalize beyond training cases. Curriculum learning has proven to be effective in this setting, as it introduces complexity progressively. However, designing effective curricula is labor-intensive and requires extensive domain expertise. LLM-based curriculum generation has only recently emerged as a potential solution, but was limited to operate in static, offline modes without leveraging real-time feedback from the optimizer. Here we propose an interactive LLM-assisted framework for online curriculum generation, where the LLM adaptively designs training cases based on real-time feedback from the evolutionary optimization process. We investigate how different feedback modalities, ranging from numeric metrics alone to combinations with plots and behavior visualizations, influence the LLM ability to generate meaningful curricula. Through a 2D robot navigation case study, tackled with genetic programming as optimizer, we evaluate our approach against static LLM-generated curricula and expert-designed baselines. We show that interactive curriculum generation outperforms static approaches, with multimodal feedback incorporating both progression plots and behavior visualizations yielding performance competitive with expert-designed curricula. This work contributes to understanding how LLMs can serve as interactive curriculum designers for embodied AI systems, with potential extensions to broader evolutionary robotics applications.",
      "authors": [
        "Berfin Sakallioglu",
        "Giorgia Nadizar",
        "Eric Medvet"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "published": "2026-02-11 14:21:52+00:00",
      "link": "https://arxiv.org/pdf/2602.10891v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10886v1",
      "title": "The CLEF-2026 FinMMEval Lab: Multilingual and Multimodal Evaluation of Financial AI Systems",
      "abstract": "We present the setup and the tasks of the FinMMEval Lab at CLEF 2026, which introduces the first multilingual and multimodal evaluation framework for financial Large Language Models (LLMs). While recent advances in financial natural language processing have enabled automated analysis of market reports, regulatory documents, and investor communications, existing benchmarks remain largely monolingual, text-only, and limited to narrow subtasks. FinMMEval 2026 addresses this gap by offering three interconnected tasks that span financial understanding, reasoning, and decision-making: Financial Exam Question Answering, Multilingual Financial Question Answering (PolyFiQA), and Financial Decision Making. Together, these tasks provide a comprehensive evaluation suite that measures models' ability to reason, generalize, and act across diverse languages and modalities. The lab aims to promote the development of robust, transparent, and globally inclusive financial AI systems, with datasets and evaluation resources publicly released to support reproducible research.",
      "authors": [
        "Zhuohan Xie",
        "Rania Elbadry",
        "Fan Zhang",
        "Georgi Georgiev",
        "Xueqing Peng",
        "Lingfei Qian",
        "Jimin Huang",
        "Dimitar Dimitrov",
        "Vanshikaa Jani",
        "Yuyang Dai",
        "Jiahui Geng",
        "Yuxia Wang",
        "Ivan Koychev",
        "Veselin Stoyanov",
        "Preslav Nakov"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "published": "2026-02-11 14:14:06+00:00",
      "link": "https://arxiv.org/pdf/2602.10886v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10881v1",
      "title": "Diagnosing Structural Failures in LLM-Based Evidence Extraction for Meta-Analysis",
      "abstract": "Systematic reviews and meta-analyses rely on converting narrative articles into structured, numerically grounded study records. Despite rapid advances in large language models (LLMs), it remains unclear whether they can meet the structural requirements of this process, which hinge on preserving roles, methods, and effect-size attribution across documents rather than on recognizing isolated entities. We propose a structural, diagnostic framework that evaluates LLM-based evidence extraction as a progression of schema-constrained queries with increasing relational and numerical complexity, enabling precise identification of failure points beyond atom-level extraction. Using a manually curated corpus spanning five scientific domains, together with a unified query suite and evaluation protocol, we evaluate two state-of-the-art LLMs under both per-document and long-context, multi-document input regimes. Across domains and models, performance remains moderate for single-property queries but degrades sharply once tasks require stable binding between variables, roles, statistical methods, and effect sizes. Full meta-analytic association tuples are extracted with near-zero reliability, and long-context inputs further exacerbate these failures. Downstream aggregation amplifies even minor upstream errors, rendering corpus-level statistics unreliable. Our analysis shows that these limitations stem not from entity recognition errors, but from systematic structural breakdowns, including role reversals, cross-analysis binding drift, instance compression in dense result sections, and numeric misattribution, indicating that current LLMs lack the structural fidelity, relational binding, and numerical grounding required for automated meta-analysis. The code and data are publicly available at GitHub (https://github.com/zhiyintan/LLM-Meta-Analysis).",
      "authors": [
        "Zhiyin Tan",
        "Jennifer D'Souza"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 14:09:43+00:00",
      "link": "https://arxiv.org/pdf/2602.10881v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10875v1",
      "title": "Stride-Net: Fairness-Aware Disentangled Representation Learning for Chest X-Ray Diagnosis",
      "abstract": "Deep neural networks for chest X-ray classification achieve strong average performance, yet often underperform for specific demographic subgroups, raising critical concerns about clinical safety and equity. Existing debiasing methods frequently yield inconsistent improvements across datasets or attain fairness by degrading overall diagnostic utility, treating fairness as a post hoc constraint rather than a property of the learned representation. In this work, we propose Stride-Net (Sensitive Attribute Resilient Learning via Disentanglement and Learnable Masking with Embedding Alignment), a fairness-aware framework that learns disease-discriminative yet demographically invariant representations for chest X-ray analysis. Stride-Net operates at the patch level, using a learnable stride-based mask to select label-aligned image regions while suppressing sensitive attribute information through adversarial confusion loss. To anchor representations in clinical semantics and discourage shortcut learning, we further enforce semantic alignment between image features and BioBERT-based disease label embeddings via Group Optimal Transport. We evaluate Stride-Net on the MIMIC-CXR and CheXpert benchmarks across race and intersectional race-gender subgroups. Across architectures including ResNet and Vision Transformers, Stride-Net consistently improves fairness metrics while matching or exceeding baseline accuracy, achieving a more favorable accuracy-fairness trade-off than prior debiasing approaches. Our code is available at https://github.com/Daraksh/Fairness_StrideNet.",
      "authors": [
        "Darakshan Rashid",
        "Raza Imam",
        "Dwarikanath Mahapatra",
        "Brejesh Lall"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 14:04:52+00:00",
      "link": "https://arxiv.org/pdf/2602.10875v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10870v1",
      "title": "FedPS: Federated data Preprocessing via aggregated Statistics",
      "abstract": "Federated Learning (FL) enables multiple parties to collaboratively train machine learning models without sharing raw data. However, before training, data must be preprocessed to address missing values, inconsistent formats, and heterogeneous feature scales. This preprocessing stage is critical for model performance but is largely overlooked in FL research. In practical FL systems, privacy constraints prohibit centralizing raw data, while communication efficiency introduces further challenges for distributed preprocessing. We introduce FedPS, a unified framework for federated data preprocessing based on aggregated statistics. FedPS leverages data-sketching techniques to efficiently summarize local datasets while preserving essential statistical information. Building on these summaries, we design federated algorithms for feature scaling, encoding, discretization, and missing-value imputation, and extend preprocessing-related models such as k-Means, k-Nearest Neighbors, and Bayesian Linear Regression to both horizontal and vertical FL settings. FedPS provides flexible, communication-efficient, and consistent preprocessing pipelines for practical FL deployments.",
      "authors": [
        "Xuefeng Xu",
        "Graham Cormode"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 13:58:55+00:00",
      "link": "https://arxiv.org/pdf/2602.10870v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10867v1",
      "title": "Deep Learning of Compositional Targets with Hierarchical Spectral Methods",
      "abstract": "Why depth yields a genuine computational advantage over shallow methods remains a central open question in learning theory. We study this question in a controlled high-dimensional Gaussian setting, focusing on compositional target functions. We analyze their learnability using an explicit three-layer fitting model trained via layer-wise spectral estimators. Although the target is globally a high-degree polynomial, its compositional structure allows learning to proceed in stages: an intermediate representation reveals structure that is inaccessible at the input level. This reduces learning to simpler spectral estimation problems, well studied in the context of multi-index models, whereas any shallow estimator must resolve all components simultaneously. Our analysis relies on Gaussian universality, leading to sharp separations in sample complexity between two and three-layer learning strategies.",
      "authors": [
        "Hugo Tabanelli",
        "Yatin Dandi",
        "Luca Pesce",
        "Florent Krzakala"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-11 13:54:20+00:00",
      "link": "https://arxiv.org/pdf/2602.10867v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10863v1",
      "title": "ICA: Information-Aware Credit Assignment for Visually Grounded Long-Horizon Information-Seeking Agents",
      "abstract": "Despite the strong performance achieved by reinforcement learning-trained information-seeking agents, learning in open-ended web environments remains severely constrained by low signal-to-noise feedback. Text-based parsers often discard layout semantics and introduce unstructured noise, while long-horizon training typically relies on sparse outcome rewards that obscure which retrieval actions actually matter. We propose a visual-native search framework that represents webpages as visual snapshots, allowing agents to leverage layout cues to quickly localize salient evidence and suppress distractors. To learn effectively from these high-dimensional observations, we introduce Information-Aware Credit Assignment (ICA), a post-hoc method that estimates each retrieved snapshot's contribution to the final outcome via posterior analysis and propagates dense learning signals back to key search turns. Integrated with a GRPO-based training pipeline, our approach consistently outperforms text-based baselines on diverse information-seeking benchmarks, providing evidence that visual snapshot grounding with information-level credit assignment alleviates the credit-assignment bottleneck in open-ended web environments. The code and datasets will be released in https://github.com/pc-inno/ICA_MM_deepsearch.git.",
      "authors": [
        "Cong Pang",
        "Xuyu Feng",
        "Yujie Yi",
        "Zixuan Chen",
        "Jiawei Hong",
        "Tiankuo Yao",
        "Nang Yuan",
        "Jiapeng Luo",
        "Lewei Lu",
        "Xin Lou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 13:50:19+00:00",
      "link": "https://arxiv.org/pdf/2602.10863v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10854v1",
      "title": "Automated Model Design using Gated Neuron Selection in Telecom",
      "abstract": "The telecommunications industry is experiencing rapid growth in adopting deep learning for critical tasks such as traffic prediction, signal strength prediction, and quality of service optimisation. However, designing neural network architectures for these applications remains challenging and time-consuming, particularly when targeting compact models suitable for resource-constrained network environments. Therefore, there is a need for automating the model design process to create high-performing models efficiently. This paper introduces TabGNS (Tabular Gated Neuron Selection), a novel gradient-based Neural Architecture Search (NAS) method specifically tailored for tabular data in telecommunications networks. We evaluate TabGNS across multiple telecommunications and generic tabular datasets, demonstrating improvements in prediction performance while reducing the architecture size by 51-82% and reducing the search time by up to 36x compared to state-of-the-art tabular NAS methods. Integrating TabGNS into the model lifecycle management enables automated design of neural networks throughout the lifecycle, accelerating deployment of ML solutions in telecommunications networks.",
      "authors": [
        "Adam Orucu",
        "Marcus Medhage",
        "Farnaz Moradi",
        "Andreas Johnsson",
        "Sarunas Girdzijauskas"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 13:40:48+00:00",
      "link": "https://arxiv.org/pdf/2602.10854v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10840v1",
      "title": "SimuScene: Training and Benchmarking Code Generation to Simulate Physical Scenarios",
      "abstract": "Large language models (LLMs) have been extensively studied for tasks like math competitions, complex coding, and scientific reasoning, yet their ability to accurately represent and simulate physical scenarios via code remains underexplored. We propose SimuScene, the first systematic study that trains and evaluates LLMs on simulating physical scenarios across five physics domains and 52 physical concepts. We build an automatic pipeline to collect data, with human verification to ensure quality. The final dataset contains 7,659 physical scenarios with 334 human-verified examples as the test set. We evaluated 10 contemporary LLMs and found that even the strongest model achieves only a 21.5% pass rate, demonstrating the difficulty of the task. Finally, we introduce a reinforcement learning pipeline with visual rewards that uses a vision-language model as a judge to train textual models. Experiments show that training with our data improves physical simulation via code while substantially enhancing general code generation performance.",
      "authors": [
        "Yanan Wang",
        "Renxi Wang",
        "Yongxin Wang",
        "Xuezhi Liang",
        "Fajri Koto",
        "Timothy Baldwin",
        "Xiaodan Liang",
        "Haonan Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 13:26:02+00:00",
      "link": "https://arxiv.org/pdf/2602.10840v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10832v1",
      "title": "I can tell whether you are a Native Hawlêri Speaker! How ANN, CNN, and RNN perform in NLI-Native Language Identification",
      "abstract": "Native Language Identification (NLI) is a task in Natural Language Processing (NLP) that typically determines the native language of an author through their writing or a speaker through their speaking. It has various applications in different areas, such as forensic linguistics and general linguistics studies. Although considerable research has been conducted on NLI regarding two different languages, such as English and German, the literature indicates a significant gap regarding NLI for dialects and subdialects. The gap becomes wider in less-resourced languages such as Kurdish. This research focuses on NLI within the context of a subdialect of Sorani (Central) Kurdish. It aims to investigate the NLI for Hewlêri, a subdialect spoken in Hewlêr (Erbil), the Capital of the Kurdistan Region of Iraq. We collected about 24 hours of speech by recording interviews with 40 native or non-native Hewlêri speakers, 17 female and 23 male. We created three Neural Network-based models: Artificial Neural Network (ANN), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN), which were evaluated through 66 experiments, covering various time-frames from 1 to 60 seconds, undersampling, oversampling, and cross-validation. The RNN model showed the highest accuracy of 95.92% for 5-second audio segmentation, using an 80:10:10 data splitting scheme. The created dataset is the first speech dataset for NLI on the Hewlêri subdialect in the Sorani Kurdish dialect, which can be of benefit to various research areas.",
      "authors": [
        "Hardi Garari",
        "Hossein Hassani"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-11 13:17:56+00:00",
      "link": "https://arxiv.org/pdf/2602.10832v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10829v1",
      "title": "Self-Supervised Learning for Speaker Recognition: A study and review",
      "abstract": "Deep learning models trained in a supervised setting have revolutionized audio and speech processing. However, their performance inherently depends on the quantity of human-annotated data, making them costly to scale and prone to poor generalization under unseen conditions. To address these challenges, Self-Supervised Learning (SSL) has emerged as a promising paradigm, leveraging vast amounts of unlabeled data to learn relevant representations. The application of SSL for Automatic Speech Recognition (ASR) has been extensively studied, but research on other downstream tasks, notably Speaker Recognition (SR), remains in its early stages. This work describes major SSL instance-invariance frameworks (e.g., SimCLR, MoCo, and DINO), initially developed for computer vision, along with their adaptation to SR. Various SSL methods for SR, proposed in the literature and built upon these frameworks, are also presented. An extensive review of these approaches is then conducted: (1) the effect of the main hyperparameters of SSL frameworks is investigated; (2) the role of SSL components is studied (e.g., data-augmentation, projector, positive sampling); and (3) SSL frameworks are evaluated on SR with in-domain and out-of-domain data, using a consistent experimental setup, and a comprehensive comparison of SSL methods from the literature is provided. Specifically, DINO achieves the best downstream performance and effectively models intra-speaker variability, although it is highly sensitive to hyperparameters and training conditions, while SimCLR and MoCo provide robust alternatives that effectively capture inter-speaker variability and are less prone to collapse. This work aims to highlight recent trends and advancements, identifying current challenges in the field.",
      "authors": [
        "Theo Lepage",
        "Reda Dehak"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.LG",
        "cs.SD"
      ],
      "published": "2026-02-11 13:16:07+00:00",
      "link": "https://arxiv.org/pdf/2602.10829v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10827v1",
      "title": "The Effect of Design Thinking on Creative & Innovation Processes: An Empirical Study Across Different Design Experience Levels",
      "abstract": "This study employs linear regression and structural equation modeling to explore how Thinking Skills, Design Thinking, Creative Self-Efficacy (CSE), and Collective Creative Efficacy (CCE) drive Design Creativity & Innovation, and analyzes the structural stability of the model across different levels of experience. Path analysis results indicate that the four Design Thinking Skills, Problem-driven Design (beta = 0.198, p < 0.01), Information-driven Design (beta = 0.241, p < 0.001), Solution-driven Design (beta = 0.227, p < 0.001), and Knowledge-driven Design (beta = 0.263, p < 0.001) all significantly and positively influence Design Thinking. Furthermore, Design Thinking has a significant positive predictive effect on Design Creativity & Innovation (beta = 0.286, p < 0.001). Mediation analysis confirms three significant mediation paths: the CSE mediation path (beta = 0.128, p < 0.001), the CCE mediation path (beta = 0.073, p < 0.01), and the \"CSE to CCE\" chain mediation path (beta = 0.025, p < 0.01). Multi-group comparison results reveal significant differences between the student and professional groups under the full equivalence model. After relaxing specific constraints, there were no significant differences between the nested models of the baseline model, partial measurement invariance, structural weight invariance, and structural covariance invariance. These findings elucidate the multi-dimensional pathways of Design Creativity & Innovation, providing a robust empirical basis for optimizing differentiated pedagogical models and professional practice guidelines.",
      "authors": [
        "Yuxin Zhang",
        "Fan Zhang"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-11 13:13:30+00:00",
      "link": "https://arxiv.org/pdf/2602.10827v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10819v1",
      "title": "RePO: Bridging On-Policy Learning and Off-Policy Knowledge through Rephrasing Policy Optimization",
      "abstract": "Aligning large language models (LLMs) on domain-specific data remains a fundamental challenge. Supervised fine-tuning (SFT) offers a straightforward way to inject domain knowledge but often degrades the model's generality. In contrast, on-policy reinforcement learning (RL) preserves generality but fails to effectively assimilate hard samples that exceed the model's current reasoning level. Recent off-policy RL attempts improve hard sample utilization, yet they suffer from severe training instability due to the forced distribution shift toward off-policy knowledge. To reconcile effective off-policy knowledge absorption with the stability of on-policy RL, we propose Rephrasing Policy Optimization (RePO). In RePO, the policy model is prompted to first comprehend off-policy knowledge and then rephrase it into trajectories that conform to its own stylistic and parametric distribution. RePO dynamically replaces low-reward rollouts with these rephrased, high-quality trajectories. This strategy guides the model toward correct reasoning paths while strictly preserving on-policy training dynamics. Experiments on several benchmarks demonstrate that RePO improves hard-sample utilization and outperforms existing baselines, achieving state-of-the-art performance.",
      "authors": [
        "Linxuan Xia",
        "Xiaolong Yang",
        "Yongyuan Chen",
        "Enyue Zhao",
        "Deng Cai",
        "Yasheng Wang",
        "Boxi Wu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 13:02:40+00:00",
      "link": "https://arxiv.org/pdf/2602.10819v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10814v1",
      "title": "See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch",
      "abstract": "Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debug, Extend, and Compute. To rigorously diagnose the source of agent failures, the benchmark employs two complementary interaction modes: primitive mode requires fine-grained drag-and-drop manipulation to directly assess visuomotor control, while composite mode uses high-level semantic APIs to disentangle program reasoning from GUI execution. To ensure reliable assessment, we propose an execution-based evaluation protocol that validates the functional correctness of the constructed Scratch programs through runtime tests within the browser environment. Extensive experiments across state-of-the-art multimodal language models and GUI agents reveal a substantial reasoning--acting gap, highlighting persistent challenges in fine-grained GUI manipulation despite strong planning capabilities.",
      "authors": [
        "Xingyi Zhang",
        "Yulei Ye",
        "Kaifeng Huang",
        "Wenhao Li",
        "Xiangfeng Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-11 12:54:53+00:00",
      "link": "https://arxiv.org/pdf/2602.10814v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10809v1",
      "title": "DeepImageSearch: Benchmarking Multimodal Agents for Context-Aware Image Retrieval in Visual Histories",
      "abstract": "Existing multimodal retrieval systems excel at semantic matching but implicitly assume that query-image relevance can be measured in isolation. This paradigm overlooks the rich dependencies inherent in realistic visual streams, where information is distributed across temporal sequences rather than confined to single snapshots. To bridge this gap, we introduce DeepImageSearch, a novel agentic paradigm that reformulates image retrieval as an autonomous exploration task. Models must plan and perform multi-step reasoning over raw visual histories to locate targets based on implicit contextual cues. We construct DISBench, a challenging benchmark built on interconnected visual data. To address the scalability challenge of creating context-dependent queries, we propose a human-model collaborative pipeline that employs vision-language models to mine latent spatiotemporal associations, effectively offloading intensive context discovery before human verification. Furthermore, we build a robust baseline using a modular agent framework equipped with fine-grained tools and a dual-memory system for long-horizon navigation. Extensive experiments demonstrate that DISBench poses significant challenges to state-of-the-art models, highlighting the necessity of incorporating agentic reasoning into next-generation retrieval systems.",
      "authors": [
        "Chenlong Deng",
        "Mengjie Deng",
        "Junjie Wu",
        "Dun Zeng",
        "Teng Wang",
        "Qingsong Xie",
        "Jiadeng Huang",
        "Shengjie Ma",
        "Changwang Zhang",
        "Zhaoxiang Wang",
        "Jun Wang",
        "Yutao Zhu",
        "Zhicheng Dou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.IR"
      ],
      "published": "2026-02-11 12:51:10+00:00",
      "link": "https://arxiv.org/pdf/2602.10809v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10806v1",
      "title": "DMP-3DAD: Cross-Category 3D Anomaly Detection via Realistic Depth Map Projection with Few Normal Samples",
      "abstract": "Cross-category anomaly detection for 3D point clouds aims to determine whether an unseen object belongs to a target category using only a few normal examples. Most existing methods rely on category-specific training, which limits their flexibility in few-shot scenarios. In this paper, we propose DMP-3DAD, a training-free framework for cross-category 3D anomaly detection based on multi-view realistic depth map projection. Specifically, by converting point clouds into a fixed set of realistic depth images, our method leverages a frozen CLIP visual encoder to extract multi-view representations and performs anomaly detection via weighted feature similarity, which does not require any fine-tuning or category-dependent adaptation. Extensive experiments on the ShapeNetPart dataset demonstrate that DMP-3DAD achieves state-of-the-art performance under few-shot setting. The results show that the proposed approach provides a simple yet effective solution for practical cross-category 3D anomaly detection.",
      "authors": [
        "Zi Wang",
        "Katsuya Hotta",
        "Koichiro Kamide",
        "Yawen Zou",
        "Jianjian Qin",
        "Chao Zhang",
        "Jun Yu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 12:47:38+00:00",
      "link": "https://arxiv.org/pdf/2602.10806v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10802v1",
      "title": "Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act",
      "abstract": "Many staff and students in higher education have adopted generative artificial intelligence (GenAI) tools in their work and study. GenAI is expected to enhance cognitive systems by enabling personalized learning and streamlining educational services. However, stakeholders perceptions of GenAI in higher education remain divided, shaped by cultural, disciplinary, and institutional contexts. In addition, the EU AI Act requires universities to ensure regulatory compliance when deploying cognitive systems. These developments highlight the need for institutions to engage stakeholders and tailor GenAI integration to their needs while addressing concerns. This study investigates how GenAI is perceived within the disciplines of Information Technology and Electrical Engineering (ITEE). Using a mixed-method approach, we surveyed 61 staff and 37 students at the Faculty of ITEE, University of Oulu. The results reveal both shared and discipline-specific themes, including strong interest in programming support from GenAI and concerns over response quality, privacy, and academic integrity. Drawing from these insights, the study identifies a set of high-level requirements and proposes a conceptual framework for responsible GenAI integration. Disciplinary-specific requirements reinforce the importance of stakeholder engagement when integrating GenAI into higher education. The high-level requirements and the framework provide practical guidance for universities aiming to harness GenAI while addressing stakeholder concerns and ensuring regulatory compliance.",
      "authors": [
        "Da-Lun Chen",
        "Prasasthy Balasubramanian",
        "Lauri Lovén",
        "Susanna Pirttikangas",
        "Jaakko Sauvola",
        "Panagiotis Kostakos"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-11 12:44:03+00:00",
      "link": "https://arxiv.org/pdf/2602.10802v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10801v1",
      "title": "Deep Learning-based Method for Expressing Knowledge Boundary of Black-Box LLM",
      "abstract": "Large Language Models (LLMs) have achieved remarkable success, however, the emergence of content generation distortion (hallucination) limits their practical applications. The core cause of hallucination lies in LLMs' lack of awareness regarding their stored internal knowledge, preventing them from expressing their knowledge state on questions beyond their internal knowledge boundaries, as humans do. However, existing research on knowledge boundary expression primarily focuses on white-box LLMs, leaving methods suitable for black-box LLMs which offer only API access without revealing internal parameters-largely unexplored. Against this backdrop, this paper proposes LSCL (LLM-Supervised Confidence Learning), a deep learning-based method for expressing the knowledge boundaries of black-box LLMs. Based on the knowledge distillation framework, this method designs a deep learning model. Taking the input question, output answer, and token probability from a black-box LLM as inputs, it constructs a mapping between the inputs and the model' internal knowledge state, enabling the quantification and expression of the black-box LLM' knowledge boundaries. Experiments conducted on diverse public datasets and with multiple prominent black-box LLMs demonstrate that LSCL effectively assists black-box LLMs in accurately expressing their knowledge boundaries. It significantly outperforms existing baseline models on metrics such as accuracy and recall rate. Furthermore, considering scenarios where some black-box LLMs do not support access to token probability, an adaptive alternative method is proposed. The performance of this alternative approach is close to that of LSCL and surpasses baseline models.",
      "authors": [
        "Haotian Sheng",
        "Heyong Wang",
        "Ming Hong",
        "Hongman He",
        "Junqiu Liu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-11 12:42:59+00:00",
      "link": "https://arxiv.org/pdf/2602.10801v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10794v1",
      "title": "Transport, Don't Generate: Deterministic Geometric Flows for Combinatorial Optimization",
      "abstract": "Recent advances in Neural Combinatorial Optimization (NCO) have been dominated by diffusion models that treat the Euclidean Traveling Salesman Problem (TSP) as a stochastic $N \\times N$ heatmap generation task. In this paper, we propose CycFlow, a framework that replaces iterative edge denoising with deterministic point transport. CycFlow learns an instance-conditioned vector field that continuously transports input 2D coordinates to a canonical circular arrangement, where the optimal tour is recovered from this $2N$ dimensional representation via angular sorting. By leveraging data-dependent flow matching, we bypass the quadratic bottleneck of edge scoring in favor of linear coordinate dynamics. This paradigm shift accelerates solving speed by up to three orders of magnitude compared to state-of-the-art diffusion baselines, while maintaining competitive optimality gaps.",
      "authors": [
        "Benjy Friedmann",
        "Nadav Dym"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 12:38:12+00:00",
      "link": "https://arxiv.org/pdf/2602.10794v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10770v1",
      "title": "LOREN: Low Rank-Based Code-Rate Adaptation in Neural Receivers",
      "abstract": "Neural network based receivers have recently demonstrated superior system-level performance compared to traditional receivers. However, their practicality is limited by high memory and power requirements, as separate weight sets must be stored for each code rate. To address this challenge, we propose LOREN, a Low Rank-Based Code-Rate Adaptation Neural Receiver that achieves adaptability with minimal overhead. LOREN integrates lightweight low rank adaptation adapters (LOREN adapters) into convolutional layers, freezing a shared base network while training only small adapters per code rate. An end-to-end training framework over 3GPP CDL channels ensures robustness across realistic wireless environments. LOREN achieves comparable or superior performance relative to fully retrained base neural receivers. The hardware implementation of LOREN in 22nm technology shows more than 65% savings in silicon area and up to 15% power reduction when supporting three code rates.",
      "authors": [
        "Bram Van Bolderik",
        "Vlado Menkovski",
        "Sonia Heemstra de Groot",
        "Manil Dev Gomony"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "eess.SP"
      ],
      "published": "2026-02-11 12:00:54+00:00",
      "link": "https://arxiv.org/pdf/2602.10770v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10764v1",
      "title": "Dual-End Consistency Model",
      "abstract": "The slow iterative sampling nature remains a major bottleneck for the practical deployment of diffusion and flow-based generative models. While consistency models (CMs) represent a state-of-the-art distillation-based approach for efficient generation, their large-scale application is still limited by two key issues: training instability and inflexible sampling. Existing methods seek to mitigate these problems through architectural adjustments or regularized objectives, yet overlook the critical reliance on trajectory selection. In this work, we first conduct an analysis on these two limitations: training instability originates from loss divergence induced by unstable self-supervised term, whereas sampling inflexibility arises from error accumulation. Based on these insights and analysis, we propose the Dual-End Consistency Model (DE-CM) that selects vital sub-trajectory clusters to achieve stable and effective training. DE-CM decomposes the PF-ODE trajectory and selects three critical sub-trajectories as optimization targets. Specifically, our approach leverages continuous-time CMs objectives to achieve few-step distillation and utilizes flow matching as a boundary regularizer to stabilize the training process. Furthermore, we propose a novel noise-to-noisy (N2N) mapping that can map noise to any point, thereby alleviating the error accumulation in the first step. Extensive experimental results show the effectiveness of our method: it achieves a state-of-the-art FID score of 1.70 in one-step generation on the ImageNet 256x256 dataset, outperforming existing CM-based one-step approaches.",
      "authors": [
        "Linwei Dong",
        "Ruoyu Guo",
        "Ge Bai",
        "Zehuan Yuan",
        "Yawei Luo",
        "Changqing Zou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 11:51:01+00:00",
      "link": "https://arxiv.org/pdf/2602.10764v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10763v2",
      "title": "Amortized Inference of Neuron Parameters on Analog Neuromorphic Hardware",
      "abstract": "Our work utilized a non-sequential simulation-based inference algorithm to provide an amortized neural density estimator, which approximates the posterior distribution for seven parameters of the adaptive exponential integrate-and-fire neuron model of the analog neuromorphic BrainScaleS-2 substrate. We constrained the large parameter space by training a binary classifier to predict parameter combinations yielding observations in regimes of interest, i.e. moderate spike counts. We compared two neural density estimators: one using handcrafted summary statistics and one using a summary network trained in combination with the neural density estimator. The summary network yielded a more focused posterior and generated posterior predictive traces that accurately captured the membrane potential dynamics. When using handcrafted summary statistics, posterior predictive traces match the included features but show deviations in the exact dynamics. The posteriors showed signs of bias and miscalibration but were still able to yield posterior predictive samples that were close to the target observations on which the posteriors were constrained. Our results validate amortized simulation-based inference as a tool for parameterizing analog neuron circuits.",
      "authors": [
        "Jakob Kaiser",
        "Eric Müller",
        "Johannes Schemmel"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-02-11 11:49:02+00:00",
      "link": "https://arxiv.org/pdf/2602.10763v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10754v1",
      "title": "Exploring the impact of adaptive rewiring in Graph Neural Networks",
      "abstract": "This paper explores sparsification methods as a form of regularization in Graph Neural Networks (GNNs) to address high memory usage and computational costs in large-scale graph applications. Using techniques from Network Science and Machine Learning, including Erdős-Rényi for model sparsification, we enhance the efficiency of GNNs for real-world applications. We demonstrate our approach on N-1 contingency assessment in electrical grids, a critical task for ensuring grid reliability. We apply our methods to three datasets of varying sizes, exploring Graph Convolutional Networks (GCN) and Graph Isomorphism Networks (GIN) with different degrees of sparsification and rewiring. Comparison across sparsification levels shows the potential of combining insights from both research fields to improve GNN performance and scalability. Our experiments highlight the importance of tuning sparsity parameters: while sparsity can improve generalization, excessive sparsity may hinder learning of complex patterns. Our adaptive rewiring approach, particularly when combined with early stopping, proves promising by allowing the model to adapt its connectivity structure during training. This research contributes to understanding how sparsity can be effectively leveraged in GNNs for critical applications like power grid reliability analysis.",
      "authors": [
        "Charlotte Cambier van Nooten",
        "Christos Aronis",
        "Yuliya Shapovalova",
        "Lucia Cavallaro"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY",
        "stat.ML"
      ],
      "published": "2026-02-11 11:34:43+00:00",
      "link": "https://arxiv.org/pdf/2602.10754v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10751v1",
      "title": "Predicting integers from continuous parameters",
      "abstract": "We study the problem of predicting numeric labels that are constrained to the integers or to a subrange of the integers. For example, the number of up-votes on social media posts, or the number of bicycles available at a public rental station. While it is possible to model these as continuous values, and to apply traditional regression, this approach changes the underlying distribution on the labels from discrete to continuous. Discrete distributions have certain benefits, which leads us to the question whether such integer labels can be modeled directly by a discrete distribution, whose parameters are predicted from the features of a given instance. Moreover, we focus on the use case of output distributions of neural networks, which adds the requirement that the parameters of the distribution be continuous so that backpropagation and gradient descent may be used to learn the weights of the network. We investigate several options for such distributions, some existing and some novel, and test them on a range of tasks, including tabular learning, sequential prediction and image generation. We find that overall the best performance comes from two distributions: Bitwise, which represents the target integer in bits and places a Bernoulli distribution on each, and a discrete analogue of the Laplace distribution, which uses a distribution with exponentially decaying tails around a continuous mean.",
      "authors": [
        "Bas Maat",
        "Peter Bloem"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 11:30:48+00:00",
      "link": "https://arxiv.org/pdf/2602.10751v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10750v1",
      "title": "SecureScan: An AI-Driven Multi-Layer Framework for Malware and Phishing Detection Using Logistic Regression and Threat Intelligence Integration",
      "abstract": "The growing sophistication of modern malware and phishing campaigns has diminished the effectiveness of traditional signature-based intrusion detection systems. This work presents SecureScan, an AI-driven, triple-layer detection framework that integrates logistic regression-based classification, heuristic analysis, and external threat intelligence via the VirusTotal API for comprehensive triage of URLs, file hashes, and binaries. The proposed architecture prioritizes efficiency by filtering known threats through heuristics, classifying uncertain samples using machine learning, and validating borderline cases with third-party intelligence. On benchmark datasets, SecureScan achieves 93.1 percent accuracy with balanced precision (0.87) and recall (0.92), demonstrating strong generalization and reduced overfitting through threshold-based decision calibration. A calibrated threshold and gray-zone logic (0.45-0.55) were introduced to minimize false positives and enhance real-world stability. Experimental results indicate that a lightweight statistical model, when augmented with calibrated verification and external intelligence, can achieve reliability and performance comparable to more complex deep learning systems.",
      "authors": [
        "Rumman Firdos",
        "Aman Dangi"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-11 11:26:11+00:00",
      "link": "https://arxiv.org/pdf/2602.10750v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10746v1",
      "title": "A Weakest Precondition Calculus for Programs and Linear Temporal Specifications",
      "abstract": "Auto-active program verification rests on the ability to effectively the translation from annotated programs into verification conditions that are then discharged by automated theorem provers in the background. Characteristic such tools, e.g., Why3, Dafny, and Viper, is that this process does not involve user interaction, expecting all guiding hints like invariants to be given upfront. For sequential correctness, this paradigm is well established, thanks to approaches like weakest precondition generation and symbolic execution. However, to capture temporal properties, the specification language of choice for a broader system perspective, additional concerns and challenges are introduced into the translation and proof. Approaches based on symbolic model-checking can verify such properties on system models, e.g., using automata constructions. However, ascribing temporal properties to structured and data-intensive programs is more difficult. Several program calculi have been proposed in the literature, each of which on their own falls short in some regard of supporting an auto-active workflow. However, all essential ideas, while perhaps some are not widely acknowledged, are in fact found in the literature. In this paper, we demonstrate how to assemble these ideas into a weakest-precondition calculus for linear temporal properties and demonstrate it with examples.",
      "authors": [
        "Gidon Ernst"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-02-11 11:19:31+00:00",
      "link": "https://arxiv.org/pdf/2602.10746v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10745v1",
      "title": "Spectral-Spatial Contrastive Learning Framework for Regression on Hyperspectral Data",
      "abstract": "Contrastive learning has demonstrated great success in representation learning, especially for image classification tasks. However, there is still a shortage in studies targeting regression tasks, and more specifically applications on hyperspectral data. In this paper, we propose a spectral-spatial contrastive learning framework for regression tasks for hyperspectral data, in a model-agnostic design allowing to enhance backbones such as 3D convolutional and transformer-based networks. Moreover, we provide a collection of transformations relevant for augmenting hyperspectral data. Experiments on synthetic and real datasets show that the proposed framework and transformations significantly improve the performance of all studied backbone models.",
      "authors": [
        "Mohamad Dhaini",
        "Paul Honeine",
        "Maxime Berar",
        "Antonin Van Exem"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-11 11:16:57+00:00",
      "link": "https://arxiv.org/pdf/2602.10745v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12300v1",
      "title": "Fast and General Automatic Differentiation for Finite-State Methods",
      "abstract": "We propose a new method, that we coined the ``morphism-trick'', to integrate custom implementations of vector-Jacobian products in automatic differentiation softwares, applicable to a wide range of semiring-based computations. Our approach leads to efficient and semiring-agnostic implementations of the backward pass of dynamic programming algorithms. For the particular case of finite-state methods, we introduce an algorithm that computes and differentiates the $\\oplus$-sum of all paths' weight of a finite-state automaton. Results show that, with minimal effort from the user, our novel library allows computing the gradient of a function w.r.t. to the weights of a finite state automaton orders of magnitude faster than state-of-the-art automatic differentiation systems. Implementations are made available via an open-source library distributed under a permissive license.",
      "authors": [
        "Lucas Ondel Yang",
        "Tina Raissi",
        "Martin Kocour",
        "Pablo Riera",
        "Caio Corro"
      ],
      "primary_category": "cs.FL",
      "categories": [
        "cs.FL"
      ],
      "published": "2026-02-11 10:36:18+00:00",
      "link": "https://arxiv.org/pdf/2602.12300v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10708v1",
      "title": "Interpretable Graph-Level Anomaly Detection via Contrast with Normal Prototypes",
      "abstract": "The task of graph-level anomaly detection (GLAD) is to identify anomalous graphs that deviate significantly from the majority of graphs in a dataset. While deep GLAD methods have shown promising performance, their black-box nature limits their reliability and deployment in real-world applications. Although some recent methods have made attempts to provide explanations for anomaly detection results, they either provide explanations without referencing normal graphs, or rely on abstract latent vectors as prototypes rather than concrete graphs from the dataset. To address these limitations, we propose Prototype-based Graph-Level Anomaly Detection (ProtoGLAD), an interpretable unsupervised framework that provides explanation for each detected anomaly by explicitly contrasting with its nearest normal prototype graph. It employs a point-set kernel to iteratively discover multiple normal prototype graphs and their associated clusters from the dataset, then identifying graphs distant from all discovered normal clusters as anomalies. Extensive experiments on multiple real-world datasets demonstrate that ProtoGLAD achieves competitive anomaly detection performance compared to state-of-the-art GLAD methods while providing better human-interpretable prototype-based explanations.",
      "authors": [
        "Qiuran Zhao",
        "Kai Ming Ting",
        "Xinpeng Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 10:11:16+00:00",
      "link": "https://arxiv.org/pdf/2602.10708v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10699v2",
      "title": "Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation",
      "abstract": "Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch. Conventional likelihood-dominated decoding (e.g., beam search) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration, where high-reward items in low-probability branches are prematurely pruned and rarely sampled, and (2) advantage compression, where trajectories sharing high-probability prefixes receive highly correlated rewards with low within-group variance, yielding a weak comparative signal for RL. To address these challenges, we propose V-STAR, a Value-guided Sampling and Tree-structured Advantage Reinforcement framework. V-STAR forms a self-evolving loop via two synergistic components. First, a Value-Guided Efficient Decoding (VED) is developed to identify decisive nodes and selectively deepen high-potential prefixes. This improves exploration efficiency without exhaustive tree search. Second, we propose Sibling-GRPO, which exploits the induced tree topology to compute sibling-relative advantages and concentrates learning signals on decisive branching decisions. Extensive experiments on both offline and online datasets demonstrate that V-STAR outperforms state-of-the-art baselines, delivering superior accuracy and candidate-set diversity under strict latency constraints.",
      "authors": [
        "Jie Jiang",
        "Yangru Huang",
        "Zeyu Wang",
        "Changping Wang",
        "Yuling Xiong",
        "Jun Zhang",
        "Huan Yu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 09:57:36+00:00",
      "link": "https://arxiv.org/pdf/2602.10699v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10696v1",
      "title": "Robust Assortment Optimization from Observational Data",
      "abstract": "Assortment optimization is a fundamental challenge in modern retail and recommendation systems, where the goal is to select a subset of products that maximizes expected revenue under complex customer choice behaviors. While recent advances in data-driven methods have leveraged historical data to learn and optimize assortments, these approaches typically rely on strong assumptions -- namely, the stability of customer preferences and the correctness of the underlying choice models. However, such assumptions frequently break in real-world scenarios due to preference shifts and model misspecification, leading to poor generalization and revenue loss. Motivated by this limitation, we propose a robust framework for data-driven assortment optimization that accounts for potential distributional shifts in customer choice behavior. Our approach models potential preference shift from a nominal choice model that generates data and seeks to maximize worst-case expected revenue. We first establish the computational tractability of robust assortment planning when the nominal model is known, then advance to the data-driven setting, where we design statistically optimal algorithms that minimize the data requirements while maintaining robustness. Our theoretical analysis provides both upper bounds and matching lower bounds on the sample complexity, offering theoretical guarantees for robust generalization. Notably, we uncover and identify the notion of ``robust item-wise coverage'' as the minimal data requirement to enable sample-efficient robust assortment learning. Our work bridges the gap between robustness and statistical efficiency in assortment learning, contributing new insights and tools for reliable assortment optimization under uncertainty.",
      "authors": [
        "Miao Lu",
        "Yuxuan Han",
        "Han Zhong",
        "Zhengyuan Zhou",
        "Jose Blanchet"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.OC",
        "math.ST"
      ],
      "published": "2026-02-11 09:57:16+00:00",
      "link": "https://arxiv.org/pdf/2602.10696v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10687v2",
      "title": "OmniVL-Guard: Towards Unified Vision-Language Forgery Detection and Grounding via Balanced RL",
      "abstract": "Existing forgery detection methods are often limited to uni-modal or bi-modal settings, failing to handle the interleaved text, images, and videos prevalent in real-world misinformation. To bridge this gap, this paper targets to develop a unified framework for omnibus vision-language forgery detection and grounding. In this unified setting, the {interplay} between diverse modalities and the dual requirements of simultaneous detection and localization pose a critical ``difficulty bias`` problem: the simpler veracity classification task tends to dominate the gradients, leading to suboptimal performance in fine-grained grounding during multi-task optimization. To address this challenge, we propose \\textbf{OmniVL-Guard}, a balanced reinforcement learning framework for omnibus vision-language forgery detection and grounding. Particularly, OmniVL-Guard comprises two core designs: Self-Evolving CoT Generatio and Adaptive Reward Scaling Policy Optimization (ARSPO). {Self-Evolving CoT Generation} synthesizes high-quality reasoning paths, effectively overcoming the cold-start challenge. Building upon this, {Adaptive Reward Scaling Policy Optimization (ARSPO)} dynamically modulates reward scales and task weights, ensuring a balanced joint optimization. Extensive experiments demonstrate that OmniVL-Guard significantly outperforms state-of-the-art methods and exhibits zero-shot robust generalization across out-of-domain scenarios.",
      "authors": [
        "Jinjie Shen",
        "Jing Wu",
        "Yaxiong Wang",
        "Lechao Cheng",
        "Shengeng Tang",
        "Tianrui Hui",
        "Nan Pu",
        "Zhun Zhong"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-11 09:41:36+00:00",
      "link": "https://arxiv.org/pdf/2602.10687v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11216v1",
      "title": "Protein Language Model Embeddings Improve Generalization of Implicit Transfer Operators",
      "abstract": "Molecular dynamics (MD) is a central computational tool in physics, chemistry, and biology, enabling quantitative prediction of experimental observables as expectations over high-dimensional molecular distributions such as Boltzmann distributions and transition densities. However, conventional MD is fundamentally limited by the high computational cost required to generate independent samples. Generative molecular dynamics (GenMD) has recently emerged as an alternative, learning surrogates of molecular distributions either from data or through interaction with energy models. While these methods enable efficient sampling, their transferability across molecular systems is often limited. In this work, we show that incorporating auxiliary sources of information can improve the data efficiency and generalization of transferable implicit transfer operators (TITO) for molecular dynamics. We find that coarse-grained TITO models are substantially more data-efficient than Boltzmann Emulators, and that incorporating protein language model (pLM) embeddings further improves out-of-distribution generalization. Our approach, PLaTITO, achieves state-of-the-art performance on equilibrium sampling benchmarks for out-of-distribution protein systems, including fast-folding proteins. We further study the impact of additional conditioning signals -- such as structural embeddings, temperature, and large-language-model-derived embeddings -- on model performance.",
      "authors": [
        "Panagiotis Antoniadis",
        "Beatrice Pavesi",
        "Simon Olsson",
        "Ole Winther"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.bio-ph"
      ],
      "published": "2026-02-11 09:26:12+00:00",
      "link": "https://arxiv.org/pdf/2602.11216v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10679v1",
      "title": "Smart Lotteries in School Choice: Ex-ante Pareto-Improvement with Ex-post Stability",
      "abstract": "In a typical school choice application, the students have strict preferences over the schools while the schools have coarse priorities over the students based on their distance and their enrolled siblings. The outcome of a centralized admission mechanism is then usually obtained by the Deferred Acceptance (DA) algorithm with random tie-breaking. Therefore, every possible outcome of this mechanism is a stable solution for the coarse priorities that will arise with certain probability. This implies a probabilistic assignment, where the admission probability for each student-school pair is specified. In this paper, we propose a new efficiency-improving stable `smart lottery' mechanism. We aim to improve the probabilistic assignment ex-ante in a stochastic dominance sense, while ensuring that the improved random matching is still ex-post stable, meaning that it can be decomposed into stable matchings regarding the original coarse priorities. Therefore, this smart lottery mechanism can provide a clear Pareto-improvement in expectation for any cardinal utilities compared to the standard DA with lottery solution, without sacrificing the stability of the final outcome. We show that although the underlying computational problem is NP-hard, we can solve the problem by using advanced optimization techniques such as integer programming with column generation. We conduct computational experiments on generated and real instances. Our results show that the welfare gains by our mechanism are substantially larger than the expected gains by standard methods that realize efficiency improvements after ties have already been broken.",
      "authors": [
        "Haris Aziz",
        "Péter Biró",
        "Gergely Csáji",
        "Tom Demeulemeester"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT",
        "econ.TH"
      ],
      "published": "2026-02-11 09:24:17+00:00",
      "link": "https://arxiv.org/pdf/2602.10679v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10670v1",
      "title": "Domain Knowledge Guided Bayesian Optimization For Autonomous Alignment Of Complex Scientific Instruments",
      "abstract": "Bayesian Optimization (BO) is a powerful tool for optimizing complex non-linear systems. However, its performance degrades in high-dimensional problems with tightly coupled parameters and highly asymmetric objective landscapes, where rewards are sparse. In such needle-in-a-haystack scenarios, even advanced methods like trust-region BO (TurBO) often lead to unsatisfactory results. We propose a domain knowledge guided Bayesian Optimization approach, which leverages physical insight to fundamentally simplify the search problem by transforming coordinates to decouple input features and align the active subspaces with the primary search axes. We demonstrate this approach's efficacy on a challenging 12-dimensional, 6-crystal Split-and-Delay optical system, where conventional approaches, including standard BO, TuRBO and multi-objective BO, consistently led to unsatisfactory results. When combined with an reverse annealing exploration strategy, this approach reliably converges to the global optimum. The coordinate transformation itself is the key to this success, significantly accelerating the search by aligning input co-ordinate axes with the problem's active subspaces. As increasingly complex scientific instruments, from large telescopes to new spectrometers at X-ray Free Electron Lasers are deployed, the demand for robust high-dimensional optimization grows. Our results demonstrate a generalizable paradigm: leveraging physical insight to transform high-dimensional, coupled optimization problems into simpler representations can enable rapid and robust automated tuning for consistent high performance while still retaining current optimization algorithms.",
      "authors": [
        "Aashwin Mishra",
        "Matt Seaberg",
        "Ryan Roussel",
        "Daniel Ratner",
        "Apurva Mehta"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math-ph"
      ],
      "published": "2026-02-11 09:15:20+00:00",
      "link": "https://arxiv.org/pdf/2602.10670v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10662v1",
      "title": "Dynamic Frequency Modulation for Controllable Text-driven Image Generation",
      "abstract": "The success of text-guided diffusion models has established a new image generation paradigm driven by the iterative refinement of text prompts. However, modifying the original text prompt to achieve the expected semantic adjustments often results in unintended global structure changes that disrupt user intent. Existing methods rely on empirical feature map selection for intervention, whose performance heavily depends on appropriate selection, leading to suboptimal stability. This paper tries to solve the aforementioned problem from a frequency perspective and analyzes the impact of the frequency spectrum of noisy latent variables on the hierarchical emergence of the structure framework and fine-grained textures during the generation process. We find that lower-frequency components are primarily responsible for establishing the structure framework in the early generation stage. Their influence diminishes over time, giving way to higher-frequency components that synthesize fine-grained textures. In light of this, we propose a training-free frequency modulation method utilizing a frequency-dependent weighting function with dynamic decay. This method maintains the structure framework consistency while permitting targeted semantic modifications. By directly manipulating the noisy latent variable, the proposed method avoids the empirical selection of internal feature maps. Extensive experiments demonstrate that the proposed method significantly outperforms current state-of-the-art methods, achieving an effective balance between preserving structure and enabling semantic updates.",
      "authors": [
        "Tiandong Shi",
        "Ling Zhao",
        "Ji Qi",
        "Jiayi Ma",
        "Chengli Peng"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 09:06:44+00:00",
      "link": "https://arxiv.org/pdf/2602.10662v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11215v1",
      "title": "Charting Empirical Laws for LLM Fine-Tuning in Scientific Multi-Discipline Learning",
      "abstract": "While large language models (LLMs) have achieved strong performance through fine-tuning within individual scientific domains, their learning dynamics in multi-disciplinary contexts remains poorly understood, despite the promise of improved generalization and broader applicability through cross-domain knowledge synergy. In this work, we present the first systematic study of multi-disciplinary LLM fine-tuning, constructing a five-discipline corpus and analyzing learning patterns of full fine-tuning, LoRA, LoRA-MoE, and LoRA compositions. Particularly, our study shows that multi-disciplinary learning is substantially more variable than single-discipline training and distills four consistent empirical laws: (1) Balance-then-Diversity: low-resource disciplines degrade performance unless mitigated via diversity-aware upsampling; (2) Merge-then-Align: restoring instruction-following ability is critical for cross-discipline synergy; (3) Optimize-then-Scale: parameter scaling offers limited gains without prior design optimization; and (4) Share-then-Specialize: asymmetric LoRA-MoE yields robust gains with minimal trainable parameters via shared low-rank projection. Together, these laws form a practical recipe for principled multi-discipline fine-tuning and provide actionable guidance for developing generalizable scientific LLMs.",
      "authors": [
        "Lintao Wang",
        "Zhuqiang Lu",
        "Yilin Zhu",
        "Kun Hu",
        "Zhenfei Yin",
        "Shixiang Tang",
        "Zhiyong Wang",
        "Wanli Ouyang",
        "Xinzhu Ma"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 09:04:13+00:00",
      "link": "https://arxiv.org/pdf/2602.11215v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10656v1",
      "title": "AudioRAG: A Challenging Benchmark for Audio Reasoning and Information Retrieval",
      "abstract": "Due to recent advancements in Large Audio-Language Models (LALMs) that demonstrate remarkable performance across a range of sound-, speech- and music-related tasks, there is a growing interest in proposing benchmarks to assess these models. Existing benchmarks generally focus only on reasoning with internal knowledge, neglecting real-world scenarios that require external information grounding. To bridge this gap, we introduce AudioRAG, a novel benchmark designed to evaluate audio-based reasoning augmented by information retrieval in realistic web environments. This benchmark comprises both LLM-generated and manually curated question-answer pairs. Our evaluations reveal that even the state-of-the-art LALMs struggle to answer these questions. We therefore propose an agentic pipeline that integrates audio reasoning with retrieval-augmented generation, providing a stronger baseline for future research.",
      "authors": [
        "Jingru Lin",
        "Chen Zhang",
        "Tianrui Wang",
        "Haizhou Li"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.SD"
      ],
      "published": "2026-02-11 09:00:02+00:00",
      "link": "https://arxiv.org/pdf/2602.10656v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10655v2",
      "title": "Assessing Vision-Language Models for Perception in Autonomous Underwater Robotic Software",
      "abstract": "Autonomous Underwater Robots (AURs) operate in challenging underwater environments, including low visibility and harsh water conditions. Such conditions present challenges for software engineers developing perception modules for the AUR software. To successfully carry out these tasks, deep learning has been incorporated into the AUR software to support its operations. However, the unique challenges of underwater environments pose difficulties for deep learning models, which often rely on labeled data that is scarce and noisy. This may undermine the trustworthiness of AUR software that relies on perception modules. Vision-Language Models (VLMs) offer promising solutions for AUR software as they generalize to unseen objects and remain robust in noisy conditions by inferring information from contextual cues. Despite this potential, their performance and uncertainty in underwater environments remain understudied from a software engineering perspective. Motivated by the needs of an industrial partner in assurance and risk management for maritime systems to assess the potential use of VLMs in this context, we present an empirical evaluation of VLM-based perception modules within the AUR software. We assess their ability to detect underwater trash by computing performance, uncertainty, and their relationship, to enable software engineers to select appropriate VLMs for their AUR software.",
      "authors": [
        "Muhammad Yousaf",
        "Aitor Arrieta",
        "Shaukat Ali",
        "Paolo Arcaini",
        "Shuai Wang"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.RO"
      ],
      "published": "2026-02-11 08:59:44+00:00",
      "link": "https://arxiv.org/pdf/2602.10655v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10652v1",
      "title": "UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory",
      "abstract": "Self-evolving memory serves as the trainable parameters for Large Language Models (LLMs)-based agents, where extraction (distilling insights from experience) and management (updating the memory bank) must be tightly coordinated. Existing methods predominately optimize memory management while treating memory extraction as a static process, resulting in poor generalization, where agents accumulate instance-specific noise rather than robust memories. To address this, we propose Unified Memory Extraction and Management (UMEM), a self-evolving agent framework that jointly optimizes a Large Language Model to simultaneous extract and manage memories. To mitigate overfitting to specific instances, we introduce Semantic Neighborhood Modeling and optimize the model with a neighborhood-level marginal utility reward via GRPO. This approach ensures memory generalizability by evaluating memory utility across clusters of semantically related queries. Extensive experiments across five benchmarks demonstrate that UMEM significantly outperforms highly competitive baselines, achieving up to a 10.67% improvement in multi-turn interactive tasks. Futhermore, UMEM maintains a monotonic growth curve during continuous evolution. Codes and models will be publicly released.",
      "authors": [
        "Yongshi Ye",
        "Hui Jiang",
        "Feihu Jiang",
        "Tian Lan",
        "Yichao Du",
        "Biao Fu",
        "Xiaodong Shi",
        "Qianghuai Jia",
        "Longyue Wang",
        "Weihua Luo"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-11 08:58:41+00:00",
      "link": "https://arxiv.org/pdf/2602.10652v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15893v1",
      "title": "Statistical-Geometric Degeneracy in UAV Search: A Physics-Aware Asymmetric Filtering Approach",
      "abstract": "Post-disaster survivor localization using Unmanned Aerial Vehicles (UAVs) faces a fundamental physical challenge: the prevalence of Non-Line-of-Sight (NLOS) propagation in collapsed structures. Unlike standard Gaussian noise, signal reflection from debris introduces strictly non-negative ranging biases. Existing robust estimators, typically designed with symmetric loss functions (e.g., Huber or Tukey), implicitly rely on the assumption of error symmetry. Consequently, they experience a theoretical mismatch in this regime, leading to a phenomenon we formally identify as Statistical-Geometric Degeneracy (SGD)-a state where the estimator stagnates due to the coupling of persistent asymmetric bias and limited observation geometry. While emerging data-driven approaches offer alternatives, they often struggle with the scarcity of training data and the sim-to-real gap inherent in unstructured disaster zones. In this work, we propose a physically-grounded solution, the AsymmetricHuberEKF, which explicitly incorporates the non-negative physical prior of NLOS biases via a derived asymmetric loss function. Theoretically, we show that standard symmetric filters correspond to a degenerate case of our framework where the physical constraint is relaxed. Furthermore, we demonstrate that resolving SGD requires not just a robust filter, but specific bilateral information, which we achieve through a co-designed active sensing strategy. Validated in a 2D nadir-view scanning scenario, our approach significantly accelerates convergence compared to symmetric baselines, offering a resilient building block for search operations where data is scarce and geometry is constrained.",
      "authors": [
        "Zhiyuan Ren",
        "Yudong Fang",
        "Tao Zhang",
        "Wenchi Cheng",
        "Ben Lan"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.IT",
        "cs.LG"
      ],
      "published": "2026-02-11 08:33:56+00:00",
      "link": "https://arxiv.org/pdf/2602.15893v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10633v2",
      "title": "A Cognitive Distribution and Behavior-Consistent Framework for Black-Box Attacks on Recommender Systems",
      "abstract": "With the growing deployment of sequential recommender systems in e-commerce and other fields, their black-box interfaces raise security concerns: models are vulnerable to extraction and subsequent adversarial manipulation. Existing black-box extraction attacks primarily rely on hard labels or pairwise learning, often ignoring the importance of ranking positions, which results in incomplete knowledge transfer. Moreover, adversarial sequences generated via pure gradient methods lack semantic consistency with real user behavior, making them easily detectable. To overcome these limitations, this paper proposes a dual-enhanced attack framework. First, drawing on primacy effects and position bias, we introduce a cognitive distribution-driven extraction mechanism that maps discrete rankings into continuous value distributions with position-aware decay, thereby advancing from order alignment to cognitive distribution alignment. Second, we design a behavior-aware noisy item generation strategy that jointly optimizes collaborative signals and gradient signals. This ensures both semantic coherence and statistical stealth while effectively promoting target item rankings. Extensive experiments on multiple datasets demonstrate that our approach significantly outperforms existing methods in both attack success rate and evasion rate, validating the value of integrating cognitive modeling and behavioral consistency for secure recommender systems.",
      "authors": [
        "Hongyue Zhang",
        "Mingming Li",
        "Dongqin Liu",
        "Hui Wang",
        "Yaning Zhang",
        "Xi Zhou",
        "Honglei Lv",
        "Jiao Dai",
        "Jizhong Han"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-11 08:26:07+00:00",
      "link": "https://arxiv.org/pdf/2602.10633v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10632v1",
      "title": "The Neurosymbolic Frontier of Nonuniform Ellipticity: Formalizing Sharp Schauder Theory via Topos-Theoretic Reasoning Models",
      "abstract": "This white paper presents a critical synthesis of the recent breakthrough in nonuniformly elliptic regularity theory and the burgeoning field of neurosymbolic large reasoning models (LRMs). We explore the resolution of the long-standing sharp growth rate conjecture in Schauder theory, achieved by Cristiana De Filippis and Giuseppe Mingione, which identifies the exact threshold $q/p < 1 + α/n$ for gradient Hölder continuity. Central to this mathematical achievement is the ``ghost equation'' methodology, a sophisticated auxiliary derivation that bypasses the non-differentiability of classical Euler-Lagrange systems. We propose that the next era of mathematical discovery lies in the integration of these pure analytical constructs with LRMs grounded in topos theory and formal verification frameworks such as Safe and Typed Chain-of-Thought (PC-CoT). By modeling the reasoning process as a categorical colimit in a slice topos, we demonstrate how LRMs can autonomously navigate the ``Dark Side'' of the calculus of variations, providing machine-checkable proofs for regularity bounds in complex, multi-phase physical systems.",
      "authors": [
        "Suyash Mishra"
      ],
      "primary_category": "cs.SC",
      "categories": [
        "cs.SC",
        "cs.AI"
      ],
      "published": "2026-02-11 08:24:57+00:00",
      "link": "https://arxiv.org/pdf/2602.10632v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10623v1",
      "title": "Mitigating Reward Hacking in RLHF via Bayesian Non-negative Reward Modeling",
      "abstract": "Reward models learned from human preferences are central to aligning large language models (LLMs) via reinforcement learning from human feedback, yet they are often vulnerable to reward hacking due to noisy annotations and systematic biases such as response length or style. We propose Bayesian Non-Negative Reward Model (BNRM), a principled reward modeling framework that integrates non-negative factor analysis into Bradley-Terry (BT) preference model. BNRM represents rewards through a sparse, non-negative latent factor generative process that operates at two complementary levels: instance-specific latent variables induce disentangled reward representations, while sparsity over global latent factors acts as an implicit debiasing mechanism that suppresses spurious correlations. Together, this disentanglement-then-debiasing structure enables robust uncertainty-aware reward learning. To scale BNRM to modern LLMs, we develop an amortized variational inference network conditioned on deep model representations, allowing efficient end-to-end training. Extensive empirical results demonstrate that BNRM substantially mitigates reward over-optimization, improves robustness under distribution shifts, and yields more interpretable reward decompositions than strong baselines.",
      "authors": [
        "Zhibin Duan",
        "Guowei Rong",
        "Zhuo Li",
        "Bo Chen",
        "Mingyuan Zhou",
        "Dandan Guo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 08:14:11+00:00",
      "link": "https://arxiv.org/pdf/2602.10623v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10619v1",
      "title": "Improving Medical Visual Reinforcement Fine-Tuning via Perception and Reasoning Augmentation",
      "abstract": "While recent advances in Reinforcement Fine-Tuning (RFT) have shown that rule-based reward schemes can enable effective post-training for large language models, their extension to cross-modal, vision-centric domains remains largely underexplored. This limitation is especially pronounced in the medical imaging domain, where effective performance requires both robust visual perception and structured reasoning. In this work, we address this gap by proposing VRFT-Aug, a visual reinforcement fine-tuning framework tailored for the medical domain. VRFT-Aug introduces a series of training strategies designed to augment both perception and reasoning, including prior knowledge injection, perception-driven policy refinement, medically informed reward shaping, and behavioral imitation. Together, these methods aim to stabilize and improve the RFT process.   Through extensive experiments across multiple medical datasets, we show that our approaches consistently outperform both standard supervised fine-tuning and RFT baselines. Moreover, we provide empirically grounded insights and practical training heuristics that can be generalized to other medical image tasks. We hope this work contributes actionable guidance and fresh inspiration for the ongoing effort to develop reliable, reasoning-capable models for high-stakes medical applications.",
      "authors": [
        "Guangjing Yang",
        "ZhangYuan Yu",
        "Ziyuan Qin",
        "Xinyuan Song",
        "Huahui Yi",
        "Qingbo Kang",
        "Jun Gao",
        "Yiyue Li",
        "Chenlin Du",
        "Qicheng Lao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-11 08:10:26+00:00",
      "link": "https://arxiv.org/pdf/2602.10619v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10614v1",
      "title": "Pupillometry and Brain Dynamics for Cognitive Load in Working Memory",
      "abstract": "Cognitive load, the mental effort required during working memory, is central to neuroscience, psychology, and human-computer interaction. Accurate assessment is vital for adaptive learning, clinical monitoring, and brain-computer interfaces. Physiological signals such as pupillometry and electroencephalography are established biomarkers of cognitive load, but their comparative utility and practical integration as lightweight, wearable monitoring solutions remain underexplored. EEG provides high temporal resolution of neural activity. Although non-invasive, it is technologically demanding and limited in wearability and cost due to its resource-intensive nature, whereas pupillometry is non-invasive, portable, and scalable. Existing studies often rely on deep learning models with limited interpretability and substantial computational expense. This study integrates feature-based and model-driven approaches to advance time-series analysis. Using the OpenNeuro 'Digit Span Task' dataset, this study investigates cognitive load classification from EEG and pupillometry. Feature-based approaches using Catch-22 features and classical machine learning models outperform deep learning in both binary and multiclass tasks. The findings demonstrate that pupillometry alone can compete with EEG, serving as a portable and practical proxy for real-world applications. These results challenge the assumption that EEG is necessary for load detection, showing that pupil dynamics combined with interpretable models and SHAP based feature analysis provide physiologically meaningful insights. This work supports the development of wearable, affordable cognitive monitoring systems for neuropsychiatry, education, and healthcare.",
      "authors": [
        "Nusaibah Farrukh",
        "Malavika Pradeep",
        "Akshay Sasi",
        "Rahul Venugopal",
        "Elizabeth Sherly"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 08:05:47+00:00",
      "link": "https://arxiv.org/pdf/2602.10614v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10613v1",
      "title": "Highly Adaptive Principal Component Regression",
      "abstract": "The Highly Adaptive Lasso (HAL) is a nonparametric regression method that achieves almost dimension-free convergence rates under minimal smoothness assumptions, but its implementation can be computationally prohibitive in high dimensions due to the large basis matrix it requires. The Highly Adaptive Ridge (HAR) has been proposed as a scalable alternative. Building on both procedures, we introduce the Principal Component based Highly Adaptive Lasso (PCHAL) and Principal Component based Highly Adaptive Ridge (PCHAR). These estimators constitute an outcome-blind dimension reduction which offer substantial gains in computational efficiency and match the empirical performances of HAL and HAR. We also uncover a striking spectral link between the leading principal components of the HAL/HAR Gram operator and a discrete sinusoidal basis, revealing an explicit Fourier-type structure underlying the PC truncation.",
      "authors": [
        "Mingxun Wang",
        "Alejandro Schuler",
        "Mark van der Laan",
        "Carlos García Meixide"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-11 08:03:17+00:00",
      "link": "https://arxiv.org/pdf/2602.10613v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10611v1",
      "title": "On the Role of Consistency Between Physics and Data in Physics-Informed Neural Networks",
      "abstract": "Physics-informed neural networks (PINNs) have gained significant attention as a surrogate modeling strategy for partial differential equations (PDEs), particularly in regimes where labeled data are scarce and physical constraints can be leveraged to regularize the learning process. In practice, however, PINNs are frequently trained using experimental or numerical data that are not fully consistent with the governing equations due to measurement noise, discretization errors, or modeling assumptions. The implications of such data-to-PDE inconsistencies on the accuracy and convergence of PINNs remain insufficiently understood. In this work, we systematically analyze how data inconsistency fundamentally limits the attainable accuracy of PINNs. We introduce the concept of a consistency barrier, defined as an intrinsic lower bound on the error that arises from mismatches between the fidelity of the data and the exact enforcement of the PDE residual. To isolate and quantify this effect, we consider the 1D viscous Burgers equation with a manufactured analytical solution, which enables full control over data fidelity and residual errors. PINNs are trained using datasets of progressively increasing numerical accuracy, as well as perfectly consistent analytical data. Results show that while the inclusion of the PDE residual allows PINNs to partially mitigate low-fidelity data and recover the dominant physical structure, the training process ultimately saturates at an error level dictated by the data inconsistency. When high-fidelity numerical data are employed, PINN solutions become indistinguishable from those trained on analytical data, indicating that the consistency barrier is effectively removed. These findings clarify the interplay between data quality and physics enforcement in PINNs providing practical guidance for the construction and interpretation of physics-informed surrogate models.",
      "authors": [
        "Nicolás Becerra-Zuniga",
        "Lucas Lacasa",
        "Eusebio Valero",
        "Gonzalo Rubio"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.comp-ph",
        "stat.ML"
      ],
      "published": "2026-02-11 08:00:53+00:00",
      "link": "https://arxiv.org/pdf/2602.10611v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10609v1",
      "title": "Online Causal Kalman Filtering for Stable and Effective Policy Optimization",
      "abstract": "Reinforcement learning for large language models suffers from high-variance token-level importance sampling (IS) ratios, which would destabilize policy optimization at scale. To improve stability, recent methods typically use a fixed sequence-level IS ratio for all tokens in a sequence or adjust each token's IS ratio separately, thereby neglecting temporal off-policy derivation across tokens in a sequence. In this paper, we first empirically identify that local off-policy deviation is structurally inconsistent at the token level, which may distort policy-gradient updates across adjacent tokens and lead to training collapse. To address the issue, we propose Online Causal Kalman Filtering for stable and effective Policy Optimization (KPO). Concretely, we model the desired IS ratio as a latent state that evolves across tokens and apply a Kalman filter to update this state online and autoregressively based on the states of past tokens, regardless of future tokens. The resulting filtered IS ratios preserve token-wise local structure-aware variation while strongly smoothing noise spikes, yielding more stable and effective policy updates. Experimentally, KPO achieves superior results on challenging math reasoning datasets compared with state-of-the-art counterparts.",
      "authors": [
        "Shuo He",
        "Lang Feng",
        "Xin Cheng",
        "Lei Feng",
        "Bo An"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-11 07:57:43+00:00",
      "link": "https://arxiv.org/pdf/2602.10609v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10608v1",
      "title": "Bayesian Inference of Contextual Bandit Policies via Empirical Likelihood",
      "abstract": "Policy inference plays an essential role in the contextual bandit problem. In this paper, we use empirical likelihood to develop a Bayesian inference method for the joint analysis of multiple contextual bandit policies in finite sample regimes. The proposed inference method is robust to small sample sizes and is able to provide accurate uncertainty measurements for policy value evaluation. In addition, it allows for flexible inferences on policy comparison with full uncertainty quantification. We demonstrate the effectiveness of the proposed inference method using Monte Carlo simulations and its application to an adolescent body mass index data set.",
      "authors": [
        "Jiangrong Ouyang",
        "Mingming Gong",
        "Howard Bondell"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-11 07:57:40+00:00",
      "link": "https://arxiv.org/pdf/2602.10608v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10607v1",
      "title": "Hierarchical Zero-Order Optimization for Deep Neural Networks",
      "abstract": "Zeroth-order (ZO) optimization has long been favored for its biological plausibility and its capacity to handle non-differentiable objectives, yet its computational complexity has historically limited its application in deep neural networks. Challenging the conventional paradigm that gradients propagate layer-by-layer, we propose Hierarchical Zeroth-Order (HZO) optimization, a novel divide-and-conquer strategy that decomposes the depth dimension of the network. We prove that HZO reduces the query complexity from $O(ML^2)$ to $O(ML \\log L)$ for a network of width $M$ and depth $L$, representing a significant leap over existing ZO methodologies. Furthermore, we provide a detailed error analysis showing that HZO maintains numerical stability by operating near the unitary limit ($L_{lip} \\approx 1$). Extensive evaluations on CIFAR-10 and ImageNet demonstrate that HZO achieves competitive accuracy compared to backpropagation.",
      "authors": [
        "Sansheng Cao",
        "Zhengyu Ma",
        "Yonghong Tian"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 07:56:07+00:00",
      "link": "https://arxiv.org/pdf/2602.10607v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10605v1",
      "title": "Evaluating Numerical Accuracy in Mixed-Precision Computing by Dual-Delta Testing",
      "abstract": "Mixed-precision computing has become increasingly important in modern high-performance computing and machine learning applications. When implementing custom mixed-precision functions -- such as fused operators, optimized GPU kernels, or quantized inference paths -- it is critical to verify their numerical accuracy. Traditional approaches typically compare the custom implementation against a reference using a single error metric. However, this single-delta approach provides limited insight into whether the observed errors are inherent to the precision level or specific to the implementation. This paper introduces \\textit{Dual-Delta Testing}, a systematic methodology that evaluates two error distributions against a high-precision oracle, enabling rigorous comparison between a custom implementation and a baseline reference. We present the mathematical framework, algorithmic formulation, statistical analysis techniques, and practical examples demonstrating the methodology's effectiveness in evaluating numerical accuracy.",
      "authors": [
        "Peichen Xie"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "cs.SE"
      ],
      "published": "2026-02-11 07:54:04+00:00",
      "link": "https://arxiv.org/pdf/2602.10605v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10598v1",
      "title": "Neuro-symbolic Action Masking for Deep Reinforcement Learning",
      "abstract": "Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, in a minimally supervised manner during the DRL process. Based on the learned symbolic model of states, NSAM learns action masks that rules out infeasible actions. NSAM enables end-to-end integration of symbolic reasoning and deep policy optimization, where improvements in symbolic grounding and policy learning mutually reinforce each other. We evaluate NSAM on multiple domains with constraints, and experimental results demonstrate that NSAM significantly improves sample efficiency of DRL agent while substantially reducing constraint violations.",
      "authors": [
        "Shuai Han",
        "Mehdi Dastani",
        "Shihan Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 07:42:53+00:00",
      "link": "https://arxiv.org/pdf/2602.10598v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13330v1",
      "title": "Zwitscherkasten -- DIY Audiovisual bird monitoring",
      "abstract": "This paper presents Zwitscherkasten, a DiY, multimodal system for bird species monitoring using audio and visual data on edge devices. Deep learning models for bioacoustic and image-based classification are deployed on resource-constrained hardware, enabling real-time, non-invasive monitoring. An acoustic activity detector reduces energy consumption, while visual recognition is performed using fine-grained detection and classification pipelines. Results show that accurate bird species identification is feasible on embedded platforms, supporting scalable biodiversity monitoring and citizen science applications.",
      "authors": [
        "Dominik Blum",
        "Elias Häring",
        "Fabian Jirges",
        "Martin Schäffer",
        "David Schick",
        "Florian Schulenberg",
        "Torsten Schön"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 07:37:43+00:00",
      "link": "https://arxiv.org/pdf/2602.13330v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10587v1",
      "title": "Deep Bootstrap",
      "abstract": "In this work, we propose a novel deep bootstrap framework for nonparametric regression based on conditional diffusion models. Specifically, we construct a conditional diffusion model to learn the distribution of the response variable given the covariates. This model is then used to generate bootstrap samples by pairing the original covariates with newly synthesized responses. We reformulate nonparametric regression as conditional sample mean estimation, which is implemented directly via the learned conditional diffusion model. Unlike traditional bootstrap methods that decouple the estimation of the conditional distribution, sampling, and nonparametric regression, our approach integrates these components into a unified generative framework. With the expressive capacity of diffusion models, our method facilitates both efficient sampling from high-dimensional or multimodal distributions and accurate nonparametric estimation. We establish rigorous theoretical guarantees for the proposed method. In particular, we derive optimal end-to-end convergence rates in the Wasserstein distance between the learned and target conditional distributions. Building on this foundation, we further establish the convergence guarantees of the resulting bootstrap procedure. Numerical studies demonstrate the effectiveness and scalability of our approach for complex regression tasks.",
      "authors": [
        "Jinyuan Chang",
        "Yuling Jiao",
        "Lican Kang",
        "Junjie Shi"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-11 07:20:20+00:00",
      "link": "https://arxiv.org/pdf/2602.10587v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10586v1",
      "title": "Enhancing Underwater Images via Adaptive Semantic-aware Codebook Learning",
      "abstract": "Underwater Image Enhancement (UIE) is an ill-posed problem where natural clean references are not available, and the degradation levels vary significantly across semantic regions. Existing UIE methods treat images with a single global model and ignore the inconsistent degradation of different scene components. This oversight leads to significant color distortions and loss of fine details in heterogeneous underwater scenes, especially where degradation varies significantly across different image regions. Therefore, we propose SUCode (Semantic-aware Underwater Codebook Network), which achieves adaptive UIE from semantic-aware discrete codebook representation. Compared with one-shot codebook-based methods, SUCode exploits semantic-aware, pixel-level codebook representation tailored to heterogeneous underwater degradation. A three-stage training paradigm is employed to represent raw underwater image features to avoid pseudo ground-truth contamination. Gated Channel Attention Module (GCAM) and Frequency-Aware Feature Fusion (FAFF) jointly integrate channel and frequency cues for faithful color restoration and texture recovery. Extensive experiments on multiple benchmarks demonstrate that SUCode achieves state-of-the-art performance, outperforming recent UIE methods on both reference and no-reference metrics. The code will be made public available at https://github.com/oucailab/SUCode.",
      "authors": [
        "Bosen Lin",
        "Feng Gao",
        "Yanwei Yu",
        "Junyu Dong",
        "Qian Du"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "eess.IV"
      ],
      "published": "2026-02-11 07:20:15+00:00",
      "link": "https://arxiv.org/pdf/2602.10586v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10585v1",
      "title": "Neural Additive Experts: Context-Gated Experts for Controllable Model Additivity",
      "abstract": "The trade-off between interpretability and accuracy remains a core challenge in machine learning. Standard Generalized Additive Models (GAMs) offer clear feature attributions but are often constrained by their strictly additive nature, which can limit predictive performance. Introducing feature interactions can boost accuracy yet may obscure individual feature contributions. To address these issues, we propose Neural Additive Experts (NAEs), a novel framework that seamlessly balances interpretability and accuracy. NAEs employ a mixture of experts framework, learning multiple specialized networks per feature, while a dynamic gating mechanism integrates information across features, thereby relaxing rigid additive constraints. Furthermore, we propose targeted regularization techniques to mitigate variance among expert predictions, facilitating a smooth transition from an exclusively additive model to one that captures intricate feature interactions while maintaining clarity in feature attributions. Our theoretical analysis and experiments on synthetic data illustrate the model's flexibility, and extensive evaluations on real-world datasets confirm that NAEs achieve an optimal balance between predictive accuracy and transparent, feature-level explanations. The code is available at https://github.com/Teddy-XiongGZ/NAE.",
      "authors": [
        "Guangzhi Xiong",
        "Sanchit Sinha",
        "Aidong Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 07:19:25+00:00",
      "link": "https://arxiv.org/pdf/2602.10585v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10583v1",
      "title": "Flow of Spans: Generalizing Language Models to Dynamic Span-Vocabulary via GFlowNets",
      "abstract": "Standard autoregressive language models generate text token-by-token from a fixed vocabulary, inducing a tree-structured state space when viewing token sampling as an action, which limits flexibility and expressiveness. Recent work introduces dynamic vocabulary by sampling retrieved text spans but overlooks that the same sentence can be composed of spans of varying lengths, lacking explicit modeling of the directed acyclic graph (DAG) state space. This leads to restricted exploration of compositional paths and is biased toward the chosen path. Generative Flow Networks (GFlowNets) are powerful for efficient exploring and generalizing over state spaces, particularly those with a DAG structure. However, prior GFlowNets-based language models operate at the token level and remain confined to tree-structured spaces, limiting their potential. In this work, we propose Flow of SpanS (FOSS), a principled GFlowNets framework for span generation. FoSS constructs a dynamic span vocabulary by segmenting the retrieved text flexibly, ensuring a DAG-structured state space, which allows GFlowNets to explore diverse compositional paths and improve generalization. With specialized reward models, FoSS generates diverse, high-quality text. Empirically, FoSS improves MAUVE scores by up to 12.5% over Transformer on text generation and achieves 3.5% gains on knowledge-intensive tasks, consistently outperforming state-of-the-art methods. Scaling experiments further demonstrate FoSS benefits from larger models, more data, and richer retrieval corpora, retaining its advantage over strong baselines.",
      "authors": [
        "Bo Xue",
        "Yunchong Song",
        "Fanghao Shao",
        "Xuekai Zhu",
        "Lin Chen",
        "Luoyi Fu",
        "Xinbing Wang",
        "Zhouhan Lin"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-11 07:17:41+00:00",
      "link": "https://arxiv.org/pdf/2602.10583v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10576v1",
      "title": "LLM-Based Scientific Equation Discovery via Physics-Informed Token-Regularized Policy Optimization",
      "abstract": "Symbolic regression aims to distill mathematical equations from observational data. Recent approaches have successfully leveraged Large Language Models (LLMs) to generate equation hypotheses, capitalizing on their vast pre-trained scientific priors. However, existing frameworks predominantly treat the LLM as a static generator, relying on prompt-level guidance to steer exploration. This paradigm fails to update the model's internal representations based on search feedback, often yielding physically inconsistent or mathematically redundant expressions. In this work, we propose PiT-PO (Physics-informed Token-regularized Policy Optimization), a unified framework that evolves the LLM into an adaptive generator via reinforcement learning. Central to PiT-PO is a dual-constraint mechanism that rigorously enforces hierarchical physical validity while simultaneously applying fine-grained, token-level penalties to suppress redundant structures. Consequently, PiT-PO aligns LLM to produce equations that are both scientifically consistent and structurally parsimonious. Empirically, PiT-PO achieves state-of-the-art performance on standard benchmarks and successfully discovers novel turbulence models for challenging fluid dynamics problems. We also demonstrate that PiT-PO empowers small-scale models to outperform closed-source giants, democratizing access to high-performance scientific discovery.",
      "authors": [
        "Boxiao Wang",
        "Kai Li",
        "Tianyi Liu",
        "Chen Li",
        "Junzhe Wang",
        "Yifan Zhang",
        "Jian Cheng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 07:02:23+00:00",
      "link": "https://arxiv.org/pdf/2602.10576v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10575v1",
      "title": "MetaphorStar: Image Metaphor Understanding and Reasoning with End-to-End Visual Reinforcement Learning",
      "abstract": "Metaphorical comprehension in images remains a critical challenge for Nowadays AI systems. While Multimodal Large Language Models (MLLMs) excel at basic Visual Question Answering (VQA), they consistently struggle to grasp the nuanced cultural, emotional, and contextual implications embedded in visual content. This difficulty stems from the task's demand for sophisticated multi-hop reasoning, cultural context, and Theory of Mind (ToM) capabilities, which current models lack. To fill this gap, we propose MetaphorStar, the first end-to-end visual reinforcement learning (RL) framework for image implication tasks. Our framework includes three core components: the fine-grained dataset TFQ-Data, the visual RL method TFQ-GRPO, and the well-structured benchmark TFQ-Bench.   Our fully open-source MetaphorStar family, trained using TFQ-GRPO on TFQ-Data, significantly improves performance by an average of 82.6% on the image implication benchmarks. Compared with 20+ mainstream MLLMs, MetaphorStar-32B achieves state-of-the-art (SOTA) on Multiple-Choice Question and Open-Style Question, significantly outperforms the top closed-source model Gemini-3.0-pro on True-False Question. Crucially, our experiments reveal that learning image implication tasks improves the general understanding ability, especially the complex visual reasoning ability. We further provide a systematic analysis of model parameter scaling, training data scaling, and the impact of different model architectures and training strategies, demonstrating the broad applicability of our method. We open-sourced all model weights, datasets, and method code at https://metaphorstar.github.io.",
      "authors": [
        "Chenhao Zhang",
        "Yazhe Niu",
        "Hongsheng Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "published": "2026-02-11 06:59:36+00:00",
      "link": "https://arxiv.org/pdf/2602.10575v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10573v1",
      "title": "CryptoCatch: Cryptomining Hidden Nowhere",
      "abstract": "Cryptomining poses significant security risks, yet traditional detection methods like blacklists and Deep Packet Inspection (DPI) are often ineffective against encrypted mining traffic and suffer from high false positive rates. In this paper, we propose a practical encrypted cryptomining traffic detection mechanism. It consists of a two-stage detection framework, which can effectively provide fine-grained detection results by machine learning and reduce false positives from classifiers through active probing. Our system achieves an F1-score of 0.99 and identifies specific cryptocurrencies with a 99.39\\% accuracy rate. Extensive testing across various mining pools confirms the effectiveness of our approach, offering a more precise and reliable solution for identifying cryptomining activities.",
      "authors": [
        "Ruisheng Shi",
        "Ziding Lin",
        "Haoran Sun",
        "Qin Wang",
        "Shihan Zhang",
        "Lina Lan",
        "Zhiyuan Peng",
        "Chenfeng Wang"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-11 06:55:36+00:00",
      "link": "https://arxiv.org/pdf/2602.10573v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11211v1",
      "title": "TRACE: Timely Retrieval and Alignment for Cybersecurity Knowledge Graph Construction and Expansion",
      "abstract": "The rapid evolution of cyber threats has highlighted significant gaps in security knowledge integration. Cybersecurity Knowledge Graphs (CKGs) relying on structured data inherently exhibit hysteresis, as the timely incorporation of rapidly evolving unstructured data remains limited, potentially leading to the omission of critical insights for risk analysis. To address these limitations, we introduce TRACE, a framework designed to integrate structured and unstructured cybersecurity data sources. TRACE integrates knowledge from 24 structured databases and 3 categories of unstructured data, including APT reports, papers, and repair notices. Leveraging Large Language Models (LLMs), TRACE facilitates efficient entity extraction and alignment, enabling continuous updates to the CKG. Evaluations demonstrate that TRACE achieves a 1.8x increase in node coverage compared to existing CKGs. TRACE attains the precision of 86.08%, the recall of 76.92%, and the F1 score of 81.24% in entity extraction, surpassing the best-known LLM-based baselines by 7.8%. Furthermore, our entity alignment methods effectively harmonize entities with existing knowledge structures, enhancing the integrity and utility of the CKG. With TRACE, threat hunters and attack analysts gain real-time, holistic insights into vulnerabilities, attack methods, and defense technologies.",
      "authors": [
        "Zijing Xu",
        "Ziwei Ning",
        "Tiancheng Hu",
        "Jianwei Zhuge",
        "Yangyang Wang",
        "Jiahao Cao",
        "Mingwei Xu"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-11 06:54:21+00:00",
      "link": "https://arxiv.org/pdf/2602.11211v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10564v2",
      "title": "SplitCom: Communication-efficient Split Federated Fine-tuning of LLMs via Temporal Compression",
      "abstract": "Federated fine-tuning of on-device large language models (LLMs) mitigates privacy concerns by preventing raw data sharing. However, the intensive computational and memory demands pose significant challenges for resource-constrained edge devices. To overcome these limitations, split federated learning (SFL) emerges as a promising solution that partitions the model into lightweight client-side and compute-intensive server-side sub-models, thus offloading the primary training workload to a powerful server. Nevertheless, high-dimensional activation exchanges in SFL lead to excessive communication overhead. To overcome this, we propose SplitCom, a communication-efficient SFL framework for LLMs that exploits temporal redundancy in activations across consecutive training epochs. Inspired by video compression, the core innovation of our framework lies in selective activation uploading only when a noticeable deviation from previous epochs occurs. To balance communication efficiency and learning performance, we introduce two adaptive threshold control schemes based on 1) bang-bang control or 2) deep deterministic policy gradient (DDPG)-based reinforcement learning. Moreover, we implement dimensionality reduction techniques to alleviate client-side memory requirements. Furthermore, we extend SplitCom to the U-shape architecture, ensuring the server never accesses clients' labels. Extensive simulations and laboratory experiments demonstrate that SplitCom reduces uplink communication costs by up to 98.6\\,\\% in its standard configuration and total communication costs by up to 95.8\\,\\% in its U-shape variant without noticeably compromising model performance.",
      "authors": [
        "Tao Li",
        "Yulin Tang",
        "Yiyang Song",
        "Cong Wu",
        "Xihui Liu",
        "Pan Li",
        "Xianhao Chen"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-02-11 06:25:53+00:00",
      "link": "https://arxiv.org/pdf/2602.10564v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10552v1",
      "title": "MindPilot: Closed-loop Visual Stimulation Optimization for Brain Modulation with EEG-guided Diffusion",
      "abstract": "Whereas most brain-computer interface research has focused on decoding neural signals into behavior or intent, the reverse challenge-using controlled stimuli to steer brain activity-remains far less understood, particularly in the visual domain. However, designing images that consistently elicit desired neural responses is difficult: subjective states lack clear quantitative measures, and EEG feedback is both noisy and non-differentiable. We introduce MindPilot, the first closed-loop framework that uses EEG signals as optimization feedback to guide naturalistic image generation. Unlike prior work limited to invasive settings or low-level flicker stimuli, MindPilot leverages non-invasive EEG with natural images, treating the brain as a black-box function and employing a pseudo-model guidance mechanism to iteratively refine images without requiring explicit rewards or gradients. We validate MindPilot in both simulation and human experiments, demonstrating (i) efficient retrieval of semantic targets, (ii) closed-loop optimization of EEG features, and (iii) human-subject validations in mental matching and emotion regulation tasks. Our results establish the feasibility of EEG-guided image synthesis and open new avenues for non-invasive closed-loop brain modulation, bidirectional brain-computer interfaces, and neural signal-guided generative modeling.",
      "authors": [
        "Dongyang Li",
        "Kunpeng Xie",
        "Mingyang Wu",
        "Yiwei Kong",
        "Jiahua Tang",
        "Haoyang Qin",
        "Chen Wei",
        "Quanying Liu"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-02-11 05:51:31+00:00",
      "link": "https://arxiv.org/pdf/2602.10552v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10549v1",
      "title": "Enhancing Weakly Supervised Multimodal Video Anomaly Detection through Text Guidance",
      "abstract": "Weakly supervised multimodal video anomaly detection has gained significant attention, yet the potential of the text modality remains under-explored. Text provides explicit semantic information that can enhance anomaly characterization and reduce false alarms. However, extracting effective text features is challenging due to the inability of general-purpose language models to capture anomaly-specific nuances and the scarcity of relevant descriptions. Furthermore, multimodal fusion often suffers from redundancy and imbalance. To address these issues, we propose a novel text-guided framework. First, we introduce an in-context learning-based multi-stage text augmentation mechanism to generate high-quality anomaly text samples for fine-tuning the text feature extractor. Second, we design a multi-scale bottleneck Transformer fusion module that uses compressed bottleneck tokens to progressively integrate information across modalities, mitigating redundancy and imbalance. Experiments on UCF-Crime and XD-Violence demonstrate state-of-the-art performance.",
      "authors": [
        "Shengyang Sun",
        "Jiashen Hua",
        "Junyi Feng",
        "Xiaojin Gong"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-11 05:44:30+00:00",
      "link": "https://arxiv.org/pdf/2602.10549v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10546v1",
      "title": "RealHD: A High-Quality Dataset for Robust Detection of State-of-the-Art AI-Generated Images",
      "abstract": "The rapid advancement of generative AI has raised concerns about the authenticity of digital images, as highly realistic fake images can now be generated at low cost, potentially increasing societal risks. In response, several datasets have been established to train detection models aimed at distinguishing AI-generated images from real ones. However, existing datasets suffer from limited generalization, low image quality, overly simple prompts, and insufficient image diversity. To address these limitations, we propose a high-quality, large-scale dataset comprising over 730,000 images across multiple categories, including both real and AI-generated images. The generated images are synthesized via state-of-the-art methods, including text-to-image generation (guided by over 10,000 carefully designed prompts), image inpainting, image refinement, and face swapping. Each generated image is annotated with its generation method and category. Inpainting images further include binary masks to indicate inpainted regions, providing rich metadata for analysis. Compared to existing datasets, detection models trained on our dataset demonstrate superior generalization capabilities. Our dataset not only serves as a strong benchmark for evaluating detection methods but also contributes to advancing the robustness of AI-generated image detection techniques. Building upon this, we propose a lightweight detection method based on image noise entropy, which transforms the original image into an entropy tensor of Non-Local Means (NLM) noise before classification. Extensive experiments demonstrate that models trained on our dataset achieve strong generalization, and our method delivers competitive performance, establishing a solid baseline for future research. The dataset and source code are publicly available at https://real-hd.github.io.",
      "authors": [
        "Hanzhe Yu",
        "Yun Ye",
        "Jintao Rong",
        "Qi Xuan",
        "Chen Ma"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-11 05:38:40+00:00",
      "link": "https://arxiv.org/pdf/2602.10546v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10544v1",
      "title": "Bridging the Compression-Precision Paradox: A Hybrid Architecture for Clinical EEG Report Generation with Guaranteed Measurement Accuracy",
      "abstract": "Automated EEG monitoring requires clinician-level precision for seizure detection and reporting. Clinical EEG recordings exceed LLM context windows, requiring extreme compression (400:1+ ratios) that destroys fine-grained temporal precision. A 0.5 Hz error distinguishes absence epilepsy from Lennox-Gastaut syndrome. LLMs lack inherent time-series comprehension and rely on statistical associations from compressed representations. This dual limitation causes systems to hallucinate clinically incorrect measurement values.   We separate measurement extraction from text generation. Our hybrid architecture computes exact clinical values via signal processing before compression, employs a cross-modal bridge for EEG-to-language translation, and uses parameter-efficient fine-tuning with constrained decoding around frozen slots. Multirate sampling maintains long-range context while preserving event-level precision. Evaluation on TUH and CHB-MIT datasets achieves 60% fewer false alarms, 50% faster detection, and sub-clinical measurement precision. This is the first system guaranteeing clinical measurement accuracy in automated EEG reports.",
      "authors": [
        "Wuyang Zhang",
        "Zhen Luo",
        "Chuqiao Gu",
        "Jianming Ma",
        "Yebo Cao",
        "Wangming Yuan",
        "Yinzhi Jin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.NA"
      ],
      "published": "2026-02-11 05:36:14+00:00",
      "link": "https://arxiv.org/pdf/2602.10544v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10541v1",
      "title": "Solving PDEs in One Shot via Fourier Features with Exact Analytical Derivatives",
      "abstract": "Recent random feature methods for solving partial differential equations (PDEs) reduce computational cost compared to physics-informed neural networks (PINNs) but still rely on iterative optimization or expensive derivative computation. We observe that sinusoidal random Fourier features possess a cyclic derivative structure: the derivative of any order of $\\sin(\\mathbf{W}\\cdot\\mathbf{x}+b)$ is a single sinusoid with a monomial prefactor, computable in $O(1)$ operations. Alternative activations such as $\\tanh$, used in prior one-shot methods like PIELM, lack this property: their higher-order derivatives grow as $O(2^n)$ terms, requiring automatic differentiation for operator assembly. We propose FastLSQ, which combines frozen random Fourier features with analytical operator assembly to solve linear PDEs via a single least-squares call, and extend it to nonlinear PDEs via Newton--Raphson iteration where each linearized step is a FastLSQ solve. On a benchmark of 17 PDEs spanning 1 to 6 dimensions, FastLSQ achieves relative $L^2$ errors of $10^{-7}$ in 0.07\\,s on linear problems, three orders of magnitude more accurate and significantly faster than state-of-the-art iterative PINN solvers, and $10^{-8}$ to $10^{-9}$ on nonlinear problems via Newton iteration in under 9s.",
      "authors": [
        "Antonin Sulc"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "cs.LG"
      ],
      "published": "2026-02-11 05:28:58+00:00",
      "link": "https://arxiv.org/pdf/2602.10541v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10539v1",
      "title": "What Makes Value Learning Efficient in Residual Reinforcement Learning?",
      "abstract": "Residual reinforcement learning (RL) enables stable online refinement of expressive pretrained policies by freezing the base and learning only bounded corrections. However, value learning in residual RL poses unique challenges that remain poorly understood. In this work, we identify two key bottlenecks: cold start pathology, where the critic lacks knowledge of the value landscape around the base policy, and structural scale mismatch, where the residual contribution is dwarfed by the base action. Through systematic investigation, we uncover the mechanisms underlying these bottlenecks, revealing that simple yet principled solutions suffice: base-policy transitions serve as an essential value anchor for implicit warmup, and critic normalization effectively restores representation sensitivity for discerning value differences. Based on these insights, we propose DAWN (Data-Anchored Warmup and Normalization), a minimal approach targeting efficient value learning in residual RL. By addressing these bottlenecks, DAWN demonstrates substantial efficiency gains across diverse benchmarks, policy architectures, and observation modalities.",
      "authors": [
        "Guozheng Ma",
        "Lu Li",
        "Haoyu Wang",
        "Zixuan Liu",
        "Pierre-Luc Bacon",
        "Dacheng Tao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 05:25:39+00:00",
      "link": "https://arxiv.org/pdf/2602.10539v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10529v1",
      "title": "Drawing Your Programs: Exploring the Applications of Visual-Prompting with GenAI for Teaching and Assessment",
      "abstract": "When designing a program, both novice programmers and seasoned developers alike often sketch out -- or, perhaps more famously, whiteboard -- their ideas. Yet despite the introduction of natively multimodal Generative AI models, work on Human-GenAI collaborative coding has remained overwhelmingly focused on textual prompts -- largely ignoring the visual and spatial representations that programmers naturally use to reason about and communicate their designs. In this proposal and position paper, we argue and provide tentative evidence that this text-centric focus overlooks other forms of prompting GenAI models, such as problem decomposition diagrams functioning as prompts for code generation in their own right enabling new types of programming activities and assessments. To support this position, we present findings from a large introductory Python programming course, where students constructed decomposition diagrams that were used to prompt GPT-4.1 for code generation. We demonstrate that current models are very successful in their ability to generate code from student-constructed diagrams. We conclude by exploring the implications of embracing multimodal prompting for computing education, particularly in the context of assessment.",
      "authors": [
        "David H. Smith",
        "S. Moonwara A. Monisha",
        "Annapurna Vadaparty",
        "Leo Porter",
        "Daniel Zingaro"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "published": "2026-02-11 04:59:31+00:00",
      "link": "https://arxiv.org/pdf/2602.10529v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10520v2",
      "title": "Prioritize the Process, Not Just the Outcome: Rewarding Latent Thought Trajectories Improves Reasoning in Looped Language Models",
      "abstract": "Looped Language Models (LoopLMs) perform multi-step latent reasoning prior to token generation and outperform conventional LLMs on reasoning benchmarks at smaller parameter budgets. However, attempts to further improve LoopLM reasoning with reinforcement learning have failed - standard objectives such as Group Relative Policy Optimization (GRPO) only assign credit to the final latent state, creating a fundamental mismatch with the model's internal computation. To resolve this, we introduce RLTT (Reward Latent Thought Trajectories), a reinforcement learning framework which distributes reward across the full latent reasoning trajectory. RLTT provides dense, trajectory-level credit assignment without relying on external verifiers and can directly replace GRPO with negligible overhead. Across extensive experiments with Ouro-2.6B-Thinking under identical training and inference conditions, RLTT yields substantial improvements over GRPO on challenging mathematical reasoning benchmarks, improving accuracy by +14.4% on MATH-500, +16.6% on AIME24, and +10.0% on BeyondAIME. Despite being trained exclusively on mathematics, RLTT also transfers effectively to non-mathematical reasoning benchmarks, demonstrating the effectiveness of trajectory-level credit assignment for reinforcement learning in LoopLMs.",
      "authors": [
        "Jonathan Williams",
        "Esin Tureci"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 04:39:42+00:00",
      "link": "https://arxiv.org/pdf/2602.10520v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10506v1",
      "title": "Learning Structure-Semantic Evolution Trajectories for Graph Domain Adaptation",
      "abstract": "Graph Domain Adaptation (GDA) aims to bridge distribution shifts between domains by transferring knowledge from well-labeled source graphs to given unlabeled target graphs. One promising recent approach addresses graph transfer by discretizing the adaptation process, typically through the construction of intermediate graphs or stepwise alignment procedures. However, such discrete strategies often fail in real-world scenarios, where graph structures evolve continuously and nonlinearly, making it difficult for fixed-step alignment to approximate the actual transformation process. To address these limitations, we propose \\textbf{DiffGDA}, a \\textbf{Diff}usion-based \\textbf{GDA} method that models the domain adaptation process as a continuous-time generative process. We formulate the evolution from source to target graphs using stochastic differential equations (SDEs), enabling the joint modeling of structural and semantic transitions. To guide this evolution, a domain-aware network is introduced to steer the generative process toward the target domain, encouraging the diffusion trajectory to follow an optimal adaptation path. We theoretically show that the diffusion process converges to the optimal solution bridging the source and target domains in the latent space. Extensive experiments on 14 graph transfer tasks across 8 real-world datasets demonstrate DiffGDA consistently outperforms state-of-the-art baselines.",
      "authors": [
        "Wei Chen",
        "Xingyu Guo",
        "Shuang Li",
        "Yan Zhong",
        "Zhao Zhang",
        "Fuzhen Zhuang",
        "Hongrui Liu",
        "Libang Zhang",
        "Guo Ye",
        "Huimei He"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 04:11:04+00:00",
      "link": "https://arxiv.org/pdf/2602.10506v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10503v1",
      "title": "Towards Long-Lived Robots: Continual Learning VLA Models via Reinforcement Fine-Tuning",
      "abstract": "Pretrained on large-scale and diverse datasets, VLA models demonstrate strong generalization and adaptability as general-purpose robotic policies. However, Supervised Fine-Tuning (SFT), which serves as the primary mechanism for adapting VLAs to downstream domains, requires substantial amounts of task-specific data and is prone to catastrophic forgetting. To address these limitations, we propose LifeLong-RFT, a simple yet effective Reinforcement Fine-Tuning (RFT) strategy for VLA models independent of online environmental feedback and pre-trained reward models. By integrating chunking-level on-policy reinforcement learning with the proposed Multi-Dimensional Process Reward (MDPR) mechanism, LifeLong-RFT quantifies the heterogeneous contributions of intermediate action chunks across three dimensions to facilitate policy optimization. Specifically, (1) the Quantized Action Consistency Reward (QACR) ensures accurate action prediction within the discrete action space; (2) the Continuous Trajectory Alignment Reward (CTAR) aligns decoded continuous action chunks with reference trajectories to ensure precise control; (3) the Format Compliance Reward (FCR) guarantees the structural validity of outputs. Comprehensive experiments across SimplerEnv, LIBERO, and real-world tasks demonstrate that LifeLong-RFT exhibits strong performance in multi-task learning. Furthermore, for continual learning on the LIBERO benchmark, our method achieves a 22% gain in average success rate over SFT, while effectively adapting to new tasks using only 20% of the training data. Overall, our method provides a promising post-training paradigm for VLAs.",
      "authors": [
        "Yuan Liu",
        "Haoran Li",
        "Shuai Tian",
        "Yuxing Qin",
        "Yuhui Chen",
        "Yupeng Zheng",
        "Yongzhen Huang",
        "Dongbin Zhao"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-11 04:05:03+00:00",
      "link": "https://arxiv.org/pdf/2602.10503v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10500v1",
      "title": "The Garbage Dataset (GD): A Multi-Class Image Benchmark for Automated Waste Segregation",
      "abstract": "This study introduces the Garbage Dataset (GD), a publicly available image dataset designed to advance automated waste segregation through machine learning and computer vision. It's a diverse dataset covering 10 common household waste categories: metal, glass, biological, paper, battery, trash, cardboard, shoes, clothes, and plastic. The dataset comprises 13,348 labeled images collected through multiple methods, including DWaste mobile app and curated web sources. Methods included rigorous validation through checksums and outlier detection, analysis of class imbalance and visual separability via PCA/t-SNE, and assessment of background complexity using entropy and saliency measures. The dataset was benchmarked using state-of-the-art deep learning models (EfficientNetV2M, EfficientNetV2S, MobileNet, ResNet50, ResNet101) evaluated on performance metrics and operational carbon emissions. Experiment results indicate EfficientNetV2S achieved the highest performance with 96.19% accuracy and a 0.96 F1-score, though with a moderate carbon cost. Analysis revealed inherent dataset characteristics including class imbalance, a skew toward high-outlier classes (plastic, cardboard, paper), and brightness variations that require consideration. The main conclusion is that GD provides a valuable, real-world benchmark for waste classification research while highlighting important challenges such as class imbalance, background complexity, and environmental trade-offs in model selection that must be addressed for practical deployment. The dataset is publicly released to support further research in environmental sustainability applications.",
      "authors": [
        "Suman Kunwar"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 04:01:12+00:00",
      "link": "https://arxiv.org/pdf/2602.10500v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10496v2",
      "title": "Low-Dimensional Execution Manifolds in Transformer Learning Dynamics: Evidence from Modular Arithmetic Tasks",
      "abstract": "We investigate the geometric structure of learning dynamics in overparameterized transformer models through carefully controlled modular arithmetic tasks. Our primary finding is that despite operating in high-dimensional parameter spaces ($d=128$), transformer training trajectories rapidly collapse onto low-dimensional execution manifolds of dimension $3$--$4$. This dimensional collapse is robust across random seeds and moderate task difficulties, though the orientation of the manifold in parameter space varies between runs. We demonstrate that this geometric structure underlies several empirically observed phenomena: (1) sharp attention concentration emerges as saturation along routing coordinates within the execution manifold, (2) SGD commutators are preferentially aligned with the execution subspace (up to $10\\times$ random baseline) early in training, with $>92\\%$ of non-commutativity confined to orthogonal staging directions and this alignment decreasing as training converges, and (3) sparse autoencoders capture auxiliary routing structure but fail to isolate execution itself, which remains distributed across the low-dimensional manifold. Our results suggest a unifying geometric framework for understanding transformer learning, where the vast majority of parameters serve to absorb optimization interference while core computation occurs in a dramatically reduced subspace. These findings have implications for interpretability, training curriculum design, and understanding the role of overparameterization in neural network learning.",
      "authors": [
        "Yongzhong Xu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 03:57:46+00:00",
      "link": "https://arxiv.org/pdf/2602.10496v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10493v1",
      "title": "Boundary-Aware Multi-Behavior Dynamic Graph Transformer for Sequential Recommendation",
      "abstract": "In the landscape of contemporary recommender systems, user-item interactions are inherently dynamic and sequential, often characterized by various behaviors. Prior research has explored the modeling of user preferences through sequential interactions and the user-item interaction graph, utilizing advanced techniques such as graph neural networks and transformer-based architectures. However, these methods typically fall short in simultaneously accounting for the dynamic nature of graph topologies and the sequential pattern of interactions in user preference models. Moreover, they often fail to adequately capture the multiple user behavior boundaries during model optimization. To tackle these challenges, we introduce a boundary-aware Multi-Behavioral Dynamic Graph Transformer (MB-DGT) model that dynamically refines the graph structure to reflect the evolving patterns of user behaviors and interactions. Our model involves a transformer-based dynamic graph aggregator for user preference modeling, which assimilates the changing graph structure and the sequence of user behaviors. This integration yields a more comprehensive and dynamic representation of user preferences. For model optimization, we implement a user-specific multi-behavior loss function that delineates the interest boundaries among different behaviors, thereby enriching the personalized learning of user preferences. Comprehensive experiments across three datasets indicate that our model consistently delivers remarkable recommendation performance.",
      "authors": [
        "Jingsong Su",
        "Xuetao Ma",
        "Mingming Li",
        "Qiannan Zhu",
        "Yu Guo"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-11 03:53:08+00:00",
      "link": "https://arxiv.org/pdf/2602.10493v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10491v1",
      "title": "Towards Remote Sensing Change Detection with Neural Memory",
      "abstract": "Remote sensing change detection is essential for environmental monitoring, urban planning, and related applications. However, current methods often struggle to capture long-range dependencies while maintaining computational efficiency. Although Transformers can effectively model global context, their quadratic complexity poses scalability challenges, and existing linear attention approaches frequently fail to capture intricate spatiotemporal relationships. Drawing inspiration from the recent success of Titans in language tasks, we present ChangeTitans, the Titans-based framework for remote sensing change detection. Specifically, we propose VTitans, the first Titans-based vision backbone that integrates neural memory with segmented local attention, thereby capturing long-range dependencies while mitigating computational overhead. Next, we present a hierarchical VTitans-Adapter to refine multi-scale features across different network layers. Finally, we introduce TS-CBAM, a two-stream fusion module leveraging cross-temporal attention to suppress pseudo-changes and enhance detection accuracy. Experimental evaluations on four benchmark datasets (LEVIR-CD, WHU-CD, LEVIR-CD+, and SYSU-CD) demonstrate that ChangeTitans achieves state-of-the-art results, attaining \\textbf{84.36\\%} IoU and \\textbf{91.52\\%} F1-score on LEVIR-CD, while remaining computationally competitive.",
      "authors": [
        "Zhenyu Yang",
        "Gensheng Pei",
        "Yazhou Yao",
        "Tianfei Zhou",
        "Lizhong Ding",
        "Fumin Shen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 03:50:51+00:00",
      "link": "https://arxiv.org/pdf/2602.10491v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10489v1",
      "title": "Learning Adaptive Distribution Alignment with Neural Characteristic Function for Graph Domain Adaptation",
      "abstract": "Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs to unlabeled target graphs but is challenged by complex, multi-faceted distributional shifts. Existing methods attempt to reduce distributional shifts by aligning manually selected graph elements (e.g., node attributes or structural statistics), which typically require manually designed graph filters to extract relevant features before alignment. However, such approaches are inflexible: they rely on scenario-specific heuristics, and struggle when dominant discrepancies vary across transfer scenarios. To address these limitations, we propose \\textbf{ADAlign}, an Adaptive Distribution Alignment framework for GDA. Unlike heuristic methods, ADAlign requires no manual specification of alignment criteria. It automatically identifies the most relevant discrepancies in each transfer and aligns them jointly, capturing the interplay between attributes, structures, and their dependencies. This makes ADAlign flexible, scenario-aware, and robust to diverse and dynamically evolving shifts. To enable this adaptivity, we introduce the Neural Spectral Discrepancy (NSD), a theoretically principled parametric distance that provides a unified view of cross-graph shifts. NSD leverages neural characteristic function in the spectral domain to encode feature-structure dependencies of all orders, while a learnable frequency sampler adaptively emphasizes the most informative spectral components for each task via minimax paradigm. Extensive experiments on 10 datasets and 16 transfer tasks show that ADAlign not only outperforms state-of-the-art baselines but also achieves efficiency gains with lower memory usage and faster training.",
      "authors": [
        "Wei Chen",
        "Xingyu Guo",
        "Shuang Li",
        "Zhao Zhang",
        "Yan Zhong",
        "Fuzhen Zhuang",
        "Deqing wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 03:48:04+00:00",
      "link": "https://arxiv.org/pdf/2602.10489v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10487v1",
      "title": "Following Dragons: Code Review-Guided Fuzzing",
      "abstract": "Modern fuzzers scale to large, real-world software but often fail to exercise the program states developers consider most fragile or security-critical. Such states are typically deep in the execution space, gated by preconditions, or overshadowed by lower-value paths that consume limited fuzzing budgets. Meanwhile, developers routinely surface risk-relevant insights during code review, yet this information is largely ignored by automated testing tools. We present EyeQ, a system that leverages developer intelligence from code reviews to guide fuzzing. EyeQ extracts security-relevant signals from review discussions, localizes the implicated program regions, and translates these insights into annotation-based guidance for fuzzing. The approach operates atop existing annotation-aware fuzzing, requiring no changes to program semantics or developer workflows. We first validate EyeQ through a human-guided feasibility study on a security-focused dataset of PHP code reviews, establishing a strong baseline for review-guided fuzzing. We then automate the workflow using a large language model with carefully designed prompts. EyeQ significantly improves vulnerability discovery over standard fuzzing configurations, uncovering more than 40 previously unknown bugs in the security-critical PHP codebase.",
      "authors": [
        "Viet Hoang Luu",
        "Amirmohammad Pasdar",
        "Wachiraphan Charoenwet",
        "Toby Murray",
        "Shaanan Cohney",
        "Van-Thuan Pham"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.SE"
      ],
      "published": "2026-02-11 03:46:57+00:00",
      "link": "https://arxiv.org/pdf/2602.10487v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10480v2",
      "title": "Neuro-Symbolic Synergy for Interactive World Modeling",
      "abstract": "Large language models (LLMs) exhibit strong general-purpose reasoning capabilities, yet they frequently hallucinate when used as world models (WMs), where strict compliance with deterministic transition rules--particularly in corner cases--is essential. In contrast, Symbolic WMs provide logical consistency but lack semantic expressivity. To bridge this gap, we propose Neuro-Symbolic Synergy (NeSyS), a framework that integrates the probabilistic semantic priors of LLMs with executable symbolic rules to achieve both expressivity and robustness. NeSyS alternates training between the two models using trajectories inadequately explained by the other. Unlike rule-based prompting, the symbolic WM directly constrains the LLM by modifying its output probability distribution. The neural WM is fine-tuned only on trajectories not covered by symbolic rules, reducing training data by 50% without loss of accuracy. Extensive experiments on three distinct interactive environments, i.e., ScienceWorld, Webshop, and Plancraft, demonstrate NeSyS's consistent advantages over baselines in both WM prediction accuracy and data efficiency.",
      "authors": [
        "Hongyu Zhao",
        "Siyu Zhou",
        "Haolin Yang",
        "Zengyi Qin",
        "Tianyi Zhou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-11 03:36:18+00:00",
      "link": "https://arxiv.org/pdf/2602.10480v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10478v2",
      "title": "GPU-Fuzz: Finding Memory Errors in Deep Learning Frameworks",
      "abstract": "GPU memory errors are a critical threat to deep learning (DL) frameworks, leading to crashes or even security issues. We introduce GPU-Fuzz, a fuzzer locating these issues efficiently by modeling operator parameters as formal constraints. GPU-Fuzz utilizes a constraint solver to generate test cases that systematically probe error-prone boundary conditions in GPU kernels. Applied to PyTorch, TensorFlow, and PaddlePaddle, we uncovered 13 unknown bugs, demonstrating the effectiveness of GPU-Fuzz in finding memory errors.",
      "authors": [
        "Zihao Li",
        "Hongyi Lu",
        "Yanan Guo",
        "Zhenkai Zhang",
        "Shuai Wang",
        "Fengwei Zhang"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-02-11 03:32:43+00:00",
      "link": "https://arxiv.org/pdf/2602.10478v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10476v1",
      "title": "Driving Reaction Trajectories via Latent Flow Matching",
      "abstract": "Recent advances in reaction prediction have achieved near-saturated accuracy on standard benchmarks (e.g., USPTO), yet most state-of-the-art models formulate the task as a one-shot mapping from reactants to products, offering limited insight into the underlying reaction process. Procedural alternatives introduce stepwise generation but often rely on mechanism-specific supervision, discrete symbolic edits, and computationally expensive inference. In this work, we propose LatentRxnFlow, a new reaction prediction paradigm that models reactions as continuous latent trajectories anchored at the thermodynamic product state. Built on Conditional Flow Matching, our approach learns time-dependent latent dynamics directly from standard reactant-product pairs, without requiring mechanistic annotations or curated intermediate labels. While LatentRxnFlow achieves state-of-the-art performance on USPTO benchmarks, more importantly, the continuous formulation exposes the full generative trajectory, enabling trajectory-level diagnostics that are difficult to realize with discrete or one-shot models. We show that latent trajectory analysis allows us to localize and characterize failure modes and to mitigate certain errors via gated inference. Furthermore, geometric properties of the learned trajectories provide an intrinsic signal of epistemic uncertainty, helping prioritize reliably predictable reaction outcomes and flag ambiguous cases for additional validation. Overall, LatentRxnFlow combines strong predictive accuracy with improved transparency, diagnosability, and uncertainty awareness, moving reaction prediction toward more trustworthy deployment in high-throughput discovery workflows.",
      "authors": [
        "Yili Shen",
        "Xiangliang Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 03:28:20+00:00",
      "link": "https://arxiv.org/pdf/2602.10476v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10471v1",
      "title": "TestExplora: Benchmarking LLMs for Proactive Bug Discovery via Repository-Level Test Generation",
      "abstract": "Given that Large Language Models (LLMs) are increasingly applied to automate software development, comprehensive software assurance spans three distinct goals: regression prevention, reactive reproduction, and proactive discovery. Current evaluations systematically overlook the third goal. Specifically, they either treat existing code as ground truth (a compliance trap) for regression prevention, or depend on post-failure artifacts (e.g., issue reports) for bug reproduction-so they rarely surface defects before failures. To bridge this gap, we present TestExplora, a benchmark designed to evaluate LLMs as proactive testers within full-scale, realistic repository environments. TestExplora contains 2,389 tasks from 482 repositories and hides all defect-related signals. Models must proactively find bugs by comparing implementations against documentation-derived intent, using documentation as the oracle. Furthermore, to keep evaluation sustainable and reduce leakage, we propose continuous, time-aware data collection. Our evaluation reveals a significant capability gap: state-of-the-art models achieve a maximum Fail-to-Pass (F2P) rate of only 16.06%. Further analysis indicates that navigating complex cross-module interactions and leveraging agentic exploration are critical to advancing LLMs toward autonomous software quality assurance. Consistent with this, SWEAgent instantiated with GPT-5-mini achieves an F2P of 17.27% and an F2P@5 of 29.7%, highlighting the effectiveness and promise of agentic exploration in proactive bug discovery tasks.",
      "authors": [
        "Steven Liu",
        "Jane Luo",
        "Xin Zhang",
        "Aofan Liu",
        "Hao Liu",
        "Jie Wu",
        "Ziyang Huang",
        "Yangyu Huang",
        "Yu Kang",
        "Scarlett Li"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.CL"
      ],
      "published": "2026-02-11 03:22:51+00:00",
      "link": "https://arxiv.org/pdf/2602.10471v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10461v1",
      "title": "Unlocked Backpropagation using Wave Scattering",
      "abstract": "Both the backpropagation algorithm in machine learning and the maximum principle in optimal control theory are posed as a two-point boundary problem, resulting in a \"forward-backward\" lock. We derive a reformulation of the maximum principle in optimal control theory as a hyperbolic initial value problem by introducing an additional \"optimization time\" dimension. We introduce counter-propagating wave variables with finite propagation speed and recast the optimization problem in terms of scattering relationships between them. This relaxation of the original problem can be interpreted as a physical system that equilibrates and changes its physical properties in order to minimize reflections. We discretize this continuum theory to derive a family of fully unlocked algorithms suitable for training neural networks. Different parameter dynamics, including gradient descent, can be derived by demanding dissipation and minimization of reflections at parameter ports. These results also imply that any physical substrate that supports the scattering and dissipation of waves can be interpreted as solving an optimization problem.",
      "authors": [
        "Christian Pehle",
        "Jean-Jacques Slotine"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-02-11 03:00:06+00:00",
      "link": "https://arxiv.org/pdf/2602.10461v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10458v1",
      "title": "Found-RL: foundation model-enhanced reinforcement learning for autonomous driving",
      "abstract": "Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we present Found-RL, a platform tailored to efficiently enhance RL for AD using foundation models. A core innovation is the asynchronous batch inference framework, which decouples heavy VLM reasoning from the simulation loop, effectively resolving latency bottlenecks to support real-time learning. We introduce diverse supervision mechanisms: Value-Margin Regularization (VMR) and Advantage-Weighted Action Guidance (AWAG) to effectively distill expert-like VLM action suggestions into the RL policy. Additionally, we adopt high-throughput CLIP for dense reward shaping. We address CLIP's dynamic blindness via Conditional Contrastive Action Alignment, which conditions prompts on discretized speed/command and yields a normalized, margin-based bonus from context-specific action-anchor scoring. Found-RL provides an end-to-end pipeline for fine-tuned VLM integration and shows that a lightweight RL model can achieve near-VLM performance compared with billion-parameter VLMs while sustaining real-time inference (approx. 500 FPS). Code, data, and models will be publicly available at https://github.com/ys-qu/found-rl.",
      "authors": [
        "Yansong Qu",
        "Zihao Sheng",
        "Zilin Huang",
        "Jiancong Chen",
        "Yuhao Luo",
        "Tianyi Wang",
        "Yiheng Feng",
        "Samuel Labi",
        "Sikai Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 02:56:04+00:00",
      "link": "https://arxiv.org/pdf/2602.10458v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10457v1",
      "title": "Analyzing Fairness of Neural Network Prediction via Counterfactual Dataset Generation",
      "abstract": "Interpreting the inference-time behavior of deep neural networks remains a challenging problem. Existing approaches to counterfactual explanation typically ask: What is the closest alternative input that would alter the model's prediction in a desired way? In contrast, we explore counterfactual datasets. Rather than perturbing the input, our method efficiently finds the closest alternative training dataset, one that differs from the original dataset by changing a few labels. Training a new model on this altered dataset can then lead to a different prediction of a given test instance. This perspective provides a new way to assess fairness by directly analyzing the influence of label bias on training and inference. Our approach can be characterized as probing whether a given prediction depends on biased labels. Since exhaustively enumerating all possible alternate datasets is infeasible, we develop analysis techniques that trace how bias in the training data may propagate through the learning algorithm to the trained network. Our method heuristically ranks and modifies the labels of a bounded number of training examples to construct a counterfactual dataset, retrains the model, and checks whether its prediction on a chosen test case changes. We evaluate our approach on feedforward neural networks across over 1100 test cases from 7 widely-used fairness datasets. Results show that it modifies only a small subset of training labels, highlighting its ability to pinpoint the critical training examples that drive prediction changes. Finally, we demonstrate how our counterfactual datasets reveal connections between training examples and test cases, offering an interpretable way to probe dataset bias.",
      "authors": [
        "Brian Hyeongseok Kim",
        "Jacqueline L. Mitchell",
        "Chao Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 02:55:50+00:00",
      "link": "https://arxiv.org/pdf/2602.10457v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10451v1",
      "title": "A Multimodal Conditional Mixture Model with Distribution-Level Physics Priors",
      "abstract": "Many scientific and engineering systems exhibit intrinsically multimodal behavior arising from latent regime switching and non-unique physical mechanisms. In such settings, learning the full conditional distribution of admissible outcomes in a physically consistent and interpretable manner remains a challenge. While recent advances in machine learning have enabled powerful multimodal generative modeling, their integration with physics-constrained scientific modeling remains nontrivial, particularly when physical structure must be preserved or data are limited. This work develops a physics-informed multimodal conditional modeling framework based on mixture density representations. Mixture density networks (MDNs) provide an explicit and interpretable parameterization of multimodal conditional distributions. Physical knowledge is embedded through component-specific regularization terms that penalize violations of governing equations or physical laws. This formulation naturally accommodates non-uniqueness and stochasticity while remaining computationally efficient and amenable to conditioning on contextual inputs. The proposed framework is evaluated across a range of scientific problems in which multimodality arises from intrinsic physical mechanisms rather than observational noise, including bifurcation phenomena in nonlinear dynamical systems, stochastic partial differential equations, and atomistic-scale shock dynamics. In addition, the proposed method is compared with a conditional flow matching (CFM) model, a representative state-of-the-art generative modeling approach, demonstrating that MDNs can achieve competitive performance while offering a simpler and more interpretable formulation.",
      "authors": [
        "Jinkyo Han",
        "Bahador Bahmani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.comp-ph"
      ],
      "published": "2026-02-11 02:46:10+00:00",
      "link": "https://arxiv.org/pdf/2602.10451v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10441v1",
      "title": "LakeMLB: Data Lake Machine Learning Benchmark",
      "abstract": "Modern data lakes have emerged as foundational platforms for large-scale machine learning, enabling flexible storage of heterogeneous data and structured analytics through table-oriented abstractions. Despite their growing importance, standardized benchmarks for evaluating machine learning performance in data lake environments remain scarce. To address this gap, we present LakeMLB (Data Lake Machine Learning Benchmark), designed for the most common multi-source, multi-table scenarios in data lakes. LakeMLB focuses on two representative multi-table scenarios, Union and Join, and provides three real-world datasets for each scenario, covering government open data, finance, Wikipedia, and online marketplaces. The benchmark supports three representative integration strategies: pre-training-based, data augmentation-based, and feature augmentation-based approaches. We conduct extensive experiments with state-of-the-art tabular learning methods, offering insights into their performance under complex data lake scenarios. We release both datasets and code to facilitate rigorous research on machine learning in data lake ecosystems; the benchmark is available at https://github.com/zhengwang100/LakeMLB.",
      "authors": [
        "Feiyu Pan",
        "Tianbin Zhang",
        "Aoqian Zhang",
        "Yu Sun",
        "Zheng Wang",
        "Lixing Chen",
        "Li Pan",
        "Jianhua Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 02:33:29+00:00",
      "link": "https://arxiv.org/pdf/2602.10441v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11210v1",
      "title": "SWE-MiniSandbox: Container-Free Reinforcement Learning for Building Software Engineering Agents",
      "abstract": "Reinforcement learning (RL) has become a key paradigm for training software engineering (SWE) agents, but existing pipelines typically rely on per-task containers for isolation. At scale, pre-built container images incur substantial storage overhead, slow environment setup, and require container-management privileges. We propose SWE-MiniSandbox, a lightweight, container-free method that enables scalable RL training of SWE agents without sacrificing isolation. Instead of relying on per-instance containers, SWE-MiniSandbox executes each task in an isolated workspace backed by kernel-level mechanisms, substantially reducing system overhead. It leverages lightweight environment pre-caching techniques to eliminate the need for bulky container images. As a result, our approach lowers disk usage to approximately 5\\% of that required by container-based pipelines and reduces environment preparation time to about 25\\% of the container baseline. Empirical results demonstrate that SWE-MiniSandbox achieves evaluation performance comparable to standard container-based pipelines. By removing the dependency on heavy container infrastructure, SWE-MiniSandbox offers a practical and accessible foundation for scaling RL-based SWE agents, particularly in resource-constrained research environments.",
      "authors": [
        "Danlong Yuan",
        "Wei Wu",
        "Zhengren Wang",
        "Xueliang Zhao",
        "Huishuai Zhang",
        "Dongyan Zhao"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 02:33:04+00:00",
      "link": "https://arxiv.org/pdf/2602.11210v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10439v1",
      "title": "AudioRouter: Data Efficient Audio Understanding via RL based Dual Reasoning",
      "abstract": "Large Audio Language Models (LALMs) have demonstrated strong capabilities in audio understanding and reasoning. However, their performance on fine grained auditory perception remains unreliable, and existing approaches largely rely on data intensive training to internalize perceptual abilities. We propose AudioRouter, a reinforcement learning framework that enables LALMs to improve audio understanding by learning when and how to use external audio tools. Rather than tightly coupling tool usage with audio reasoning, AudioRouter formulates tool use as an explicit decision making problem and optimizes a lightweight routing policy while keeping the underlying reasoning model frozen. Experimental results show that AudioRouter achieves substantial improvements on standard audio understanding benchmarks while requiring up to 600x less training data to learn tool usage compared with conventional training paradigms. These findings suggest that learning effective tool usage offers a data efficient and scalable alternative to internalizing perceptual abilities in LALMs.",
      "authors": [
        "Liyang Chen",
        "Hongkai Chen",
        "Yujun Cai",
        "Sifan Li",
        "Qingwen Ye",
        "Yiwei Wang"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "published": "2026-02-11 02:30:48+00:00",
      "link": "https://arxiv.org/pdf/2602.10439v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10437v2",
      "title": "Control Reinforcement Learning: Interpretable Token-Level Steering of LLMs via Sparse Autoencoder Features",
      "abstract": "Sparse autoencoders (SAEs) decompose language model activations into interpretable features, but existing methods reveal only which features activate, not which change model outputs when amplified. We introduce Control Reinforcement Learning (CRL), which trains a policy to select SAE features for steering at each token, producing interpretable intervention logs: the learned policy identifies features that change model outputs when amplified. Adaptive Feature Masking encourages diverse feature discovery while preserving singlefeature interpretability. The framework yields new analysis capabilities: branch point tracking locates tokens where feature choice determines output correctness; critic trajectory analysis separates policy limitations from value estimation errors; layer-wise comparison reveals syntactic features in early layers and semantic features in later layers. On Gemma 2 2B across MMLU, BBQ, GSM8K, HarmBench, and XSTest, CRL achieves improvements while providing per-token intervention logs. These results establish learned feature steering as a mechanistic interpretability tool that complements static feature analysis with dynamic intervention probes",
      "authors": [
        "Seonglae Cho",
        "Zekun Wu",
        "Adriano Koshiyama"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-11 02:28:49+00:00",
      "link": "https://arxiv.org/pdf/2602.10437v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10432v1",
      "title": "A Dual-Stream Physics-Augmented Unsupervised Architecture for Runtime Embedded Vehicle Health Monitoring",
      "abstract": "Runtime quantification of vehicle operational intensity is essential for predictive maintenance and condition monitoring in commercial and heavy-duty fleets. Traditional metrics like mileage fail to capture mechanical burden, while unsupervised deep learning models detect statistical anomalies, typically transient surface shocks, but often conflate statistical stability with mechanical rest. We identify this as a critical blind spot: high-load steady states, such as hill climbing with heavy payloads, appear statistically normal yet impose significant drivetrain fatigue. To resolve this, we propose a Dual-Stream Architecture that fuses unsupervised learning for surface anomaly detection with macroscopic physics proxies for cumulative load estimation. This approach leverages low-frequency sensor data to generate a multi-dimensional health vector, distinguishing between dynamic hazards and sustained mechanical effort. Validated on a RISC-V embedded platform, the architecture demonstrates low computational overhead, enabling comprehensive, edge-based health monitoring on resource-constrained ECUs without the latency or bandwidth costs of cloud-based monitoring.",
      "authors": [
        "Enzo Nicolas Spotorno",
        "Antonio Augusto Medeiros Frohlich"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 02:19:22+00:00",
      "link": "https://arxiv.org/pdf/2602.10432v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10430v1",
      "title": "Breaking the Curse of Repulsion: Optimistic Distributionally Robust Policy Optimization for Off-Policy Generative Recommendation",
      "abstract": "Policy-based Reinforcement Learning (RL) has established itself as the dominant paradigm in generative recommendation for optimizing sequential user interactions. However, when applied to offline historical logs, these methods suffer a critical failure: the dominance of low-quality data induces severe model collapse. We first establish the Divergence Theory of Repulsive Optimization, revealing that negative gradient updates inherently trigger exponential intensity explosion during off-policy training. This theory elucidates the inherent dilemma of existing methods, exposing their inability to reconcile variance reduction and noise imitation. To break this curse, we argue that the solution lies in rigorously identifying the latent high-quality distribution entangled within the noisy behavior policy. Accordingly, we reformulate the objective as an Optimistic Distributionally Robust Optimization (DRO) problem. Guided by this formulation, we propose Distributionally Robust Policy Optimization (DRPO). We prove that hard filtering is the exact solution to this DRO objective, enabling DRPO to optimally recover high-quality behaviors while strictly discarding divergence-inducing noise. Extensive experiments demonstrate that DRPO achieves state-of-the-art performance on mixed-quality recommendation benchmarks.",
      "authors": [
        "Jie Jiang",
        "Yusen Huo",
        "Xiangxin Zhan",
        "Changping Wang",
        "Jun Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 02:18:27+00:00",
      "link": "https://arxiv.org/pdf/2602.10430v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10425v1",
      "title": "HII-DPO: Eliminate Hallucination via Accurate Hallucination-Inducing Counterfactual Images",
      "abstract": "Large Vision-Language Models (VLMs) have achieved remarkable success across diverse multimodal tasks but remain vulnerable to hallucinations rooted in inherent language bias. Despite recent progress, existing hallucination mitigation methods often overlook the underlying hallucination patterns driven by language bias. In this work, we design a novel pipeline to accurately synthesize Hallucination-Inducing Images (HIIs). Using synthesized HIIs, we reveal a consistent scene-conditioned hallucination pattern: models tend to mention objects that are highly typical of the scene even when visual evidence is removed. To quantify the susceptibility of VLMs to this hallucination pattern, we establish the Masked-Object-Hallucination (MOH) benchmark to rigorously evaluate existing state-of-the-art alignment frameworks. Finally, we leverage HIIs to construct high-quality preference datasets for fine-grained alignment. Experimental results demonstrate that our approach effectively mitigates hallucinations while preserving general model capabilities. Specifically, our method achieves up to a 38% improvement over the current state-of-the-art on standard hallucination benchmarks.",
      "authors": [
        "Yilin Yang",
        "Zhenghui Guo",
        "Yuke Wang",
        "Omprakash Gnawali",
        "Sheng Di",
        "Chengming Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-11 02:11:02+00:00",
      "link": "https://arxiv.org/pdf/2602.10425v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10419v1",
      "title": "Equivariant Evidential Deep Learning for Interatomic Potentials",
      "abstract": "Uncertainty quantification (UQ) is critical for assessing the reliability of machine learning interatomic potentials (MLIPs) in molecular dynamics (MD) simulations, identifying extrapolation regimes and enabling uncertainty-aware workflows such as active learning for training dataset construction. Existing UQ approaches for MLIPs are often limited by high computational cost or suboptimal performance. Evidential deep learning (EDL) provides a theoretically grounded single-model alternative that determines both aleatoric and epistemic uncertainty in a single forward pass. However, extending evidential formulations from scalar targets to vector-valued quantities such as atomic forces introduces substantial challenges, particularly in maintaining statistical self-consistency under rotational transformations. To address this, we propose \\textit{Equivariant Evidential Deep Learning for Interatomic Potentials} ($\\text{e}^2$IP), a backbone-agnostic framework that models atomic forces and their uncertainty jointly by representing uncertainty as a full $3\\times3$ symmetric positive definite covariance tensor that transforms equivariantly under rotations. Experiments on diverse molecular benchmarks show that $\\text{e}^2$IP provides a stronger accuracy-efficiency-reliability balance than the non-equivariant evidential baseline and the widely used ensemble method. It also achieves better data efficiency through the fully equivariant architecture while retaining single-model inference efficiency.",
      "authors": [
        "Zhongyao Wang",
        "Taoyong Cui",
        "Jiawen Zou",
        "Shufei Zhang",
        "Bo Yan",
        "Wanli Ouyang",
        "Weimin Tan",
        "Mao Su"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 02:00:25+00:00",
      "link": "https://arxiv.org/pdf/2602.10419v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13325v1",
      "title": "Graph neural networks uncover structure and functions underlying the activity of simulated neural assemblies",
      "abstract": "Graph neural networks trained to predict observable dynamics can be used to decompose the temporal activity of complex heterogeneous systems into simple, interpretable representations. Here we apply this framework to simulated neural assemblies with thousands of neurons and demonstrate that it can jointly reveal the connectivity matrix, the neuron types, the signaling functions, and in some cases hidden external stimuli. In contrast to existing machine learning approaches such as recurrent neural networks and transformers, which emphasize predictive accuracy but offer limited interpretability, our method provides both reliable forecasts of neural activity and interpretable decomposition of the mechanisms governing large neural assemblies.",
      "authors": [
        "Cédric Allier",
        "Larissa Heinrich",
        "Magdalena Schneider",
        "Stephan Saalfeld"
      ],
      "primary_category": "q-bio.NC",
      "categories": [
        "q-bio.NC",
        "cs.LG"
      ],
      "published": "2026-02-11 01:59:27+00:00",
      "link": "https://arxiv.org/pdf/2602.13325v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10417v1",
      "title": "RadarEye: Robust Liquid Level Tracking Using mmWave Radar in Robotic Pouring",
      "abstract": "Transparent liquid manipulation in robotic pouring remains challenging for perception systems: specular/refraction effects and lighting variability degrade visual cues, undermining reliable level estimation. To address this challenge, we introduce RadarEye, a real-time mmWave radar signal processing pipeline for robust liquid level estimation and tracking during the whole pouring process. RadarEye integrates (i) a high-resolution range-angle beamforming module for liquid level sensing and (ii) a physics-informed mid-pour tracker that suppresses multipath to maintain lock on the liquid surface despite stream-induced clutter and source container reflections. The pipeline delivers sub-millisecond latency. In real-robot water-pouring experiments, RadarEye achieves a 0.35 cm median absolute height error at 0.62 ms per update, substantially outperforming vision and ultrasound baselines.",
      "authors": [
        "Hongyu Deng",
        "He Chen"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "cs.RO"
      ],
      "published": "2026-02-11 01:57:13+00:00",
      "link": "https://arxiv.org/pdf/2602.10417v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10411v1",
      "title": "GeoGR: A Generative Retrieval Framework for Spatio-Temporal Aware POI Recommendation",
      "abstract": "Next Point-of-Interest (POI) prediction is a fundamental task in location-based services, especially critical for large-scale navigation platforms like AMAP that serve billions of users across diverse lifestyle scenarios. While recent POI recommendation approaches based on SIDs have achieved promising, they struggle in complex, sparse real-world environments due to two key limitations: (1) inadequate modeling of high-quality SIDs that capture cross-category spatio-temporal collaborative relationships, and (2) poor alignment between large language models (LLMs) and the POI recommendation task. To this end, we propose GeoGR, a geographic generative recommendation framework tailored for navigation-based LBS like AMAP, which perceives users' contextual state changes and enables intent-aware POI recommendation. GeoGR features a two-stage design: (i) a geo-aware SID tokenization pipeline that explicitly learns spatio-temporal collaborative semantic representations via geographically constrained co-visited POI pairs, contrastive learning, and iterative refinement; and (ii) a multi-stage LLM training strategy that aligns non-native SID tokens through multiple template-based continued pre-training(CPT) and enables autoregressive POI generation via supervised fine-tuning(SFT). Extensive experiments on multiple real-world datasets demonstrate GeoGR's superiority over state-of-the-art baselines. Moreover, deployment on the AMAP platform, serving millions of users with multiple online metrics boosting, confirms its practical effectiveness and scalability in production.",
      "authors": [
        "Fangye Wang",
        "Haowen Lin",
        "Yifang Yuan",
        "Siyuan Wang",
        "Xiaojiang Zhou",
        "Song Yang",
        "Pengjie Wang"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-11 01:48:27+00:00",
      "link": "https://arxiv.org/pdf/2602.10411v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10407v1",
      "title": "Towards Affordable, Non-Invasive Real-Time Hypoglycemia Detection Using Wearable Sensor Signals",
      "abstract": "Accurately detecting hypoglycemia without invasive glucose sensors remains a critical challenge in diabetes management, particularly in regions where continuous glucose monitoring (CGM) is prohibitively expensive or clinically inaccessible. This extended study introduces a comprehensive, multimodal physiological framework for non-invasive hypoglycemia detection using wearable sensor signals. Unlike prior work limited to single-signal analysis, this chapter evaluates three physiological modalities, galvanic skin response (GSR), heart rate (HR), and their combined fusion, using the OhioT1DM 2018 dataset. We develop an end-to-end pipeline that integrates advanced preprocessing, temporal windowing, handcrafted and sequence-based feature extraction, early and late fusion strategies, and a broad spectrum of machine learning and deep temporal models, including CNNs, LSTMs, GRUs, and TCNs. Our results demonstrate that physiological signals exhibit distinct autonomic patterns preceding hypoglycemia and that combining GSR with HR consistently enhances detection sensitivity and stability compared to single-signal models. Multimodal deep learning architectures achieve the most reliable performance, particularly in recall, the most clinically urgent metric. Ablation studies further highlight the complementary contributions of each modality, strengthening the case for affordable, sensor-based glycemic monitoring. The findings show that real-time hypoglycemia detection is achievable using only inexpensive, non-invasive wearable sensors, offering a pathway toward accessible glucose monitoring in underserved communities and low-resource healthcare environments.",
      "authors": [
        "Lawrence Obiuwevwi",
        "Krzysztof J. Rechowicz",
        "Vikas Ashok",
        "Sampath Jayarathna"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.LG"
      ],
      "published": "2026-02-11 01:31:06+00:00",
      "link": "https://arxiv.org/pdf/2602.10407v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10399v1",
      "title": "LocoVLM: Grounding Vision and Language for Adapting Versatile Legged Locomotion Policies",
      "abstract": "Recent advances in legged locomotion learning are still dominated by the utilization of geometric representations of the environment, limiting the robot's capability to respond to higher-level semantics such as human instructions. To address this limitation, we propose a novel approach that integrates high-level commonsense reasoning from foundation models into the process of legged locomotion adaptation. Specifically, our method utilizes a pre-trained large language model to synthesize an instruction-grounded skill database tailored for legged robots. A pre-trained vision-language model is employed to extract high-level environmental semantics and ground them within the skill database, enabling real-time skill advisories for the robot. To facilitate versatile skill control, we train a style-conditioned policy capable of generating diverse and robust locomotion skills with high fidelity to specified styles. To the best of our knowledge, this is the first work to demonstrate real-time adaptation of legged locomotion using high-level reasoning from environmental semantics and instructions with instruction-following accuracy of up to 87% without the need for online query to on-the-cloud foundation models.",
      "authors": [
        "I Made Aswin Nahrendra",
        "Seunghyun Lee",
        "Dongkyu Lee",
        "Hyun Myung"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-11 01:00:18+00:00",
      "link": "https://arxiv.org/pdf/2602.10399v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10387v1",
      "title": "Making Databases Faster with LLM Evolutionary Sampling",
      "abstract": "Traditional query optimization relies on cost-based optimizers that estimate execution cost (e.g., runtime, memory, and I/O) using predefined heuristics and statistical models. Improving these heuristics requires substantial engineering effort, and even when implemented, these heuristics often cannot take into account semantic correlations in queries and schemas that could enable better physical plans. Using our DBPlanBench harness for the DataFusion engine, we expose the physical plan through a compact serialized representation and let the LLM propose localized edits that can be applied and executed. We then apply an evolutionary search over these edits to refine candidates across iterations. Our key insight is that LLMs can leverage semantic knowledge to identify and apply non-obvious optimizations, such as join orderings that minimize intermediate cardinalities. We obtain up to 4.78$\\times$ speedups on some queries and we demonstrate a small-to-large workflow in which optimizations found on small databases transfer effectively to larger databases.",
      "authors": [
        "Mehmet Hamza Erol",
        "Xiangpeng Hao",
        "Federico Bianchi",
        "Ciro Greco",
        "Jacopo Tagliabue",
        "James Zou"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "published": "2026-02-11 00:21:51+00:00",
      "link": "https://arxiv.org/pdf/2602.10387v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10386v1",
      "title": "Colorful Talks with Graphs: Human-Interpretable Graph Encodings for Large Language Models",
      "abstract": "Graph problems are fundamentally challenging for large language models (LLMs). While LLMs excel at processing unstructured text, graph tasks require reasoning over explicit structure, permutation invariance, and computationally complex relationships, creating a mismatch with the representations of text-based models. Our work investigates how LLMs can be effectively applied to graph problems despite these barriers. We introduce a human-interpretable structural encoding strategy for graph-to-text translation that injects graph structure directly into natural language prompts. Our method involves computing a variant of Weisfeiler-Lehman (WL) similarity classes and maps them to human-like color tokens rather than numeric labels. The key insight is that semantically meaningful and human-interpretable cues may be more effectively processed by LLMs than opaque symbolic encoding. Experimental results on multiple algorithmic and predictive graph tasks show the considerable improvements by our method on both synthetic and real-world datasets. By capturing both local and global-range dependencies, our method enhances LLM performance especially on graph tasks that require reasoning over global graph structure.",
      "authors": [
        "Angelo Zangari",
        "Peyman Baghershahi",
        "Sourav Medya"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 00:15:29+00:00",
      "link": "https://arxiv.org/pdf/2602.10386v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10384v2",
      "title": "When Tables Go Crazy: Evaluating Multimodal Models on French Financial Documents",
      "abstract": "Vision-language models (VLMs) perform well on many document understanding tasks, yet their reliability in specialized, non-English domains remains underexplored. This gap is especially critical in finance, where documents mix dense regulatory text, numerical tables, and visual charts, and where extraction errors can have real-world consequences. We introduce Multimodal Finance Eval, the first multimodal benchmark for evaluating French financial document understanding. The dataset contains 1,204 expert-validated questions spanning text extraction, table comprehension, chart interpretation, and multi-turn conversational reasoning, drawn from real investment prospectuses, KIDs, and PRIIPs. We evaluate six open-weight VLMs (8B-124B parameters) using an LLM-as-judge protocol. While models achieve strong performance on text and table tasks (85-90% accuracy), they struggle with chart interpretation (34-62%). Most notably, multi-turn dialogue reveals a sharp failure mode: early mistakes propagate across turns, driving accuracy down to roughly 50% regardless of model size.   These results show that current VLMs are effective for well-defined extraction tasks but remain brittle in interactive, multi-step financial analysis. Multimodal Finance Eval offers a challenging benchmark to measure and drive progress in this high-stakes setting.",
      "authors": [
        "Virginie Mouilleron",
        "Théo Lasnier",
        "Djamé Seddah"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-11 00:04:56+00:00",
      "link": "https://arxiv.org/pdf/2602.10384v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10381v1",
      "title": "Deep learning outperforms traditional machine learning methods in predicting childhood malnutrition: evidence from survey data",
      "abstract": "Childhood malnutrition remains a major public health concern in Nepal and other low-resource settings, while conventional case-finding approaches are labor-intensive and frequently unavailable in remote areas. This study provides the first comprehensive assessment of machine learning and deep learning methodologies for identifying malnutrition among children under five years of age in Nepal. We systematically compared 16 algorithms spanning deep learning, gradient boosting, and traditional machine learning families, using data from the Nepal Multiple Indicator Cluster Survey (MICS) 2019. A composite malnutrition indicator was constructed by integrating stunting, wasting, and underweight status, and model performance was evaluated using ten metrics, with emphasis on F1-score and recall to account for substantial class imbalance and the high cost of failing to detect malnourished children. Among all models, TabNet demonstrated the best performance, likely attributable to its attention-based architecture, and outperformed both support vector machine and AdaBoost classifiers. A consensus feature importance analysis identified maternal education, household wealth index, and child age as the primary predictors of malnutrition, followed by geographic characteristics, vaccination status, and meal frequency. Collectively, these results demonstrate a scalable, survey-based screening framework for identifying children at elevated risk of malnutrition and for guiding targeted nutritional interventions. The proposed approach supports Nepal's progress toward the Sustainable Development Goals and offers a transferable methodological template for similar low-resource settings globally.",
      "authors": [
        "Deepak Bastola",
        "Yang Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 00:04:22+00:00",
      "link": "https://arxiv.org/pdf/2602.10381v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10377v1",
      "title": "Hardware Co-Design Scaling Laws via Roofline Modelling for On-Device LLMs",
      "abstract": "Vision-Language-Action Models (VLAs) have emerged as a key paradigm of Physical AI and are increasingly deployed in autonomous vehicles, robots, and smart spaces. In these resource-constrained on-device settings, selecting an appropriate large language model (LLM) backbone is a critical challenge: models must balance accuracy with strict inference latency and hardware efficiency constraints. This makes hardware-software co-design a game-changing requirement for on-device LLM deployment, where each hardware platform demands a tailored architectural solution. We propose a hardware co-design law that jointly captures model accuracy and inference performance. Specifically, we model training loss as an explicit function of architectural hyperparameters and characterise inference latency via roofline modelling. We empirically evaluate 1,942 candidate architectures on NVIDIA Jetson Orin, training 170 selected models for 10B tokens each to fit a scaling law relating architecture to training loss. By coupling this scaling law with latency modelling, we establish a direct accuracy-latency correspondence and identify the Pareto frontier for hardware co-designed LLMs. We further formulate architecture search as a joint optimisation over precision and performance, deriving feasible design regions under industrial hardware and application budgets. Our approach reduces architecture selection from months to days. At the same latency as Qwen2.5-0.5B on the target hardware, our co-designed architecture achieves 19.42% lower perplexity on WikiText-2. To our knowledge, this is the first principled and operational framework for hardware co-design scaling laws in on-device LLM deployment. We will make the code and related checkpoints publicly available.",
      "authors": [
        "Luoyang Sun",
        "Jiwen Jiang",
        "Yifeng Ding",
        "Fengfa Li",
        "Yan Song",
        "Haifeng Zhang",
        "Jian Ying",
        "Lei Ren",
        "Kun Zhan",
        "Wei Chen",
        "Yan Xie",
        "Cheng Deng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-10 23:51:00+00:00",
      "link": "https://arxiv.org/pdf/2602.10377v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10371v1",
      "title": "Simple LLM Baselines are Competitive for Model Diffing",
      "abstract": "Standard LLM evaluations only test capabilities or dispositions that evaluators designed them for, missing unexpected differences such as behavioral shifts between model revisions or emergent misaligned tendencies. Model diffing addresses this limitation by automatically surfacing systematic behavioral differences. Recent approaches include LLM-based methods that generate natural language descriptions and sparse autoencoder (SAE)-based methods that identify interpretable features. However, no systematic comparison of these approaches exists nor are there established evaluation criteria. We address this gap by proposing evaluation metrics for key desiderata (generalization, interestingness, and abstraction level) and use these to compare existing methods. Our results show that an improved LLM-based baseline performs comparably to the SAE-based method while typically surfacing more abstract behavioral differences.",
      "authors": [
        "Elias Kempf",
        "Simon Schrodi",
        "Bartosz Cywiński",
        "Thomas Brox",
        "Neel Nanda",
        "Arthur Conmy"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 23:45:26+00:00",
      "link": "https://arxiv.org/pdf/2602.10371v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10365v1",
      "title": "Solving Geodesic Equations with Composite Bernstein Polynomials for Trajectory Planning",
      "abstract": "This work presents a trajectory planning method based on composite Bernstein polynomials for autonomous systems navigating complex environments. The method is implemented in a symbolic optimization framework that enables continuous paths and precise control over trajectory shape. Trajectories are planned over a cost surface that encodes obstacles as continuous fields rather than discrete boundaries. Regions near obstacles are assigned higher costs, naturally encouraging the trajectory to maintain a safe distance while still allowing efficient routing through constrained spaces. The use of composite Bernstein polynomials preserves continuity while enabling fine control over local curvature to satisfy geodesic constraints. The symbolic representation supports exact derivatives, improving optimization efficiency. The method applies to both two- and three-dimensional environments and is suitable for ground, aerial, underwater, and space systems. In spacecraft trajectory planning, for example, it enables the generation of continuous, dynamically feasible trajectories with high numerical efficiency, making it well suited for orbital maneuvers, rendezvous and proximity operations, cluttered gravitational environments, and planetary exploration missions with limited onboard computational resources. Demonstrations show that the approach efficiently generates smooth, collision-free paths in scenarios with multiple obstacles, maintaining clearance without extensive sampling or post-processing. The optimization incorporates three constraint types: (1) a Gaussian surface inequality enforcing minimum obstacle clearance; (2) geodesic equations guiding the path along locally efficient directions on the cost surface; and (3) boundary constraints enforcing fixed start and end conditions. The method can serve as a standalone planner or as an initializer for more complex motion planning problems.",
      "authors": [
        "Nick Gorman",
        "Gage MacLin",
        "Maxwell Hammond",
        "Venanzio Cichella"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "math.OC"
      ],
      "published": "2026-02-10 23:33:15+00:00",
      "link": "https://arxiv.org/pdf/2602.10365v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10357v1",
      "title": "Theoretical Analysis of Contrastive Learning under Imbalanced Data: From Training Dynamics to a Pruning Solution",
      "abstract": "Contrastive learning has emerged as a powerful framework for learning generalizable representations, yet its theoretical understanding remains limited, particularly under imbalanced data distributions that are prevalent in real-world applications. Such an imbalance can degrade representation quality and induce biased model behavior, yet a rigorous characterization of these effects is lacking. In this work, we develop a theoretical framework to analyze the training dynamics of contrastive learning with Transformer-based encoders under imbalanced data. Our results reveal that neuron weights evolve through three distinct stages of training, with different dynamics for majority features, minority features, and noise. We further show that minority features reduce representational capacity, increase the need for more complex architectures, and hinder the separation of ground-truth features from noise. Inspired by these neuron-level behaviors, we show that pruning restores performance degraded by imbalance and enhances feature separation, offering both conceptual insights and practical guidance. Major theoretical findings are validated through numerical experiments.",
      "authors": [
        "Haixu Liao",
        "Yating Zhou",
        "Songyang Zhang",
        "Meng Wang",
        "Shuai Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 23:06:12+00:00",
      "link": "https://arxiv.org/pdf/2602.10357v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10356v1",
      "title": "Autonomous Continual Learning of Computer-Use Agents for Environment Adaptation",
      "abstract": "Real-world digital environments are highly diverse and dynamic. These characteristics cause agents to frequently encounter unseen scenarios and distribution shifts, making continual learning in specific environments essential for computer-use agents (CUAs). However, a key challenge lies in obtaining high-quality and environment-grounded agent data without relying on costly human annotation. In this work, we introduce ACuRL, an Autonomous Curriculum Reinforcement Learning framework that continually adapts agents to specific environments with zero human data. The agent first explores target environments to acquire initial experiences. During subsequent iterative training, a curriculum task generator leverages these experiences together with feedback from the previous iteration to synthesize new tasks tailored for the agent's current capabilities. To provide reliable reward signals, we introduce CUAJudge, a robust automatic evaluator for CUAs that achieves 93% agreement with human judgments. Empirically, our method effectively enables both intra-environment and cross-environment continual learning, yielding 4-22% performance gains without catastrophic forgetting on existing environments. Further analyses show highly sparse updates (e.g., 20% parameters), which helps explain the effective and robust adaptation. Our data and code are available at https://github.com/OSU-NLP-Group/ACuRL.",
      "authors": [
        "Tianci Xue",
        "Zeyi Liao",
        "Tianneng Shi",
        "Zilu Wang",
        "Kai Zhang",
        "Dawn Song",
        "Yu Su",
        "Huan Sun"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-10 23:06:02+00:00",
      "link": "https://arxiv.org/pdf/2602.10356v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11208v1",
      "title": "Adaptive Physics Transformer with Fused Global-Local Attention for Subsurface Energy Systems",
      "abstract": "The Earth's subsurface is a cornerstone of modern society, providing essential energy resources like hydrocarbons, geothermal, and minerals while serving as the primary reservoir for $CO_2$ sequestration. However, full physics numerical simulations of these systems are notoriously computationally expensive due to geological heterogeneity, high resolution requirements, and the tight coupling of physical processes with distinct propagation time scales. Here we propose the \\textbf{Adaptive Physics Transformer} (APT), a geometry-, mesh-, and physics-agnostic neural operator that explicitly addresses these challenges. APT fuses a graph-based encoder to extract high-resolution local heterogeneous features with a global attention mechanism to resolve long-range physical impacts. Our results demonstrate that APT outperforms state-of-the-art architectures in subsurface tasks across both regular and irregular grids with robust super-resolution capabilities. Notably, APT is the first architecture that directly learns from adaptive mesh refinement simulations. We also demonstrate APT's capability for cross-dataset learning, positioning it as a robust and scalable backbone for large-scale subsurface foundation model development.",
      "authors": [
        "Xin Ju",
        "Nok Hei",
        "Fung",
        "Yuyan Zhang",
        "Carl Jacquemyn",
        "Matthew Jackson",
        "Randolph Settgast",
        "Sally M. Benson",
        "Gege Wen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 22:48:58+00:00",
      "link": "https://arxiv.org/pdf/2602.11208v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10324v1",
      "title": "Discovering Differences in Strategic Behavior Between Humans and LLMs",
      "abstract": "As Large Language Models (LLMs) are increasingly deployed in social and strategic scenarios, it becomes critical to understand where and why their behavior diverges from that of humans. While behavioral game theory (BGT) provides a framework for analyzing behavior, existing models do not fully capture the idiosyncratic behavior of humans or black-box, non-human agents like LLMs. We employ AlphaEvolve, a cutting-edge program discovery tool, to directly discover interpretable models of human and LLM behavior from data, thereby enabling open-ended discovery of structural factors driving human and LLM behavior. Our analysis on iterated rock-paper-scissors reveals that frontier LLMs can be capable of deeper strategic behavior than humans. These results provide a foundation for understanding structural differences driving differences in human and LLM behavior in strategic interactions.",
      "authors": [
        "Caroline Wang",
        "Daniel Kasenberg",
        "Kim Stachenfeld",
        "Pablo Samuel Castro"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "published": "2026-02-10 22:02:41+00:00",
      "link": "https://arxiv.org/pdf/2602.10324v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10320v1",
      "title": "Implementability of Global Distributed Protocols modulo Network Architectures",
      "abstract": "Global protocols specify distributed, message-passing protocols from a birds-eye view, and are used as a specification for synthesizing local implementations. Implementability asks whether a given global protocol admits a distributed implementation. We present the first comprehensive investigation of global protocol implementability modulo network architectures. We propose a set of network-parametric Coherence Conditions, and exhibit sufficient assumptions under which it precisely characterizes implementability. We further reduce these assumptions to a minimal set of operational axioms describing insert and remove behavior of individual message buffers. Our reduction immediately establishes that five commonly studied asynchronous network architectures, namely peer-to-peer FIFO, mailbox, senderbox, monobox and bag, are instances of our network-parametric result. We use our characterization to derive optimal complexity results for implementability modulo networks, relationships between classes of implementable global protocols, and symbolic algorithms for deciding implementability modulo networks. We implement the latter in the first network-parametric tool Sprout(A), and show that it achieves network generality without sacrificing performance and modularity.",
      "authors": [
        "Elaine Li",
        "Thomas Wies"
      ],
      "primary_category": "cs.FL",
      "categories": [
        "cs.FL",
        "cs.DC",
        "cs.PL"
      ],
      "published": "2026-02-10 21:58:45+00:00",
      "link": "https://arxiv.org/pdf/2602.10320v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13321v1",
      "title": "Detecting Jailbreak Attempts in Clinical Training LLMs Through Automated Linguistic Feature Extraction",
      "abstract": "Detecting jailbreak attempts in clinical training large language models (LLMs) requires accurate modeling of linguistic deviations that signal unsafe or off-task user behavior. Prior work on the 2-Sigma clinical simulation platform showed that manually annotated linguistic features could support jailbreak detection. However, reliance on manual annotation limited both scalability and expressiveness. In this study, we extend this framework by using experts' annotations of four core linguistic features (Professionalism, Medical Relevance, Ethical Behavior, and Contextual Distraction) and training multiple general-domain and medical-domain BERT-based LLM models to predict these features directly from text. The most reliable feature regressor for each dimension was selected and used as the feature extractor in a second layer of classifiers. We evaluate a suite of predictive models, including tree-based, linear, probabilistic, and ensemble methods, to determine jailbreak likelihood from the extracted features. Across cross-validation and held-out evaluations, the system achieves strong overall performance, indicating that LLM-derived linguistic features provide an effective basis for automated jailbreak detection. Error analysis further highlights key limitations in current annotations and feature representations, pointing toward future improvements such as richer annotation schemes, finer-grained feature extraction, and methods that capture the evolving risk of jailbreak behavior over the course of a dialogue. This work demonstrates a scalable and interpretable approach for detecting jailbreak behavior in safety-critical clinical dialogue systems.",
      "authors": [
        "Tri Nguyen",
        "Huy Hoang Bao Le",
        "Lohith Srikanth Pentapalli",
        "Laurah Turner",
        "Kelly Cohen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-10 21:57:55+00:00",
      "link": "https://arxiv.org/pdf/2602.13321v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10315v1",
      "title": "Uncertainty-Aware Ordinal Deep Learning for cross-Dataset Diabetic Retinopathy Grading",
      "abstract": "Diabetes mellitus is a chronic metabolic disorder characterized by persistent hyperglycemia due to insufficient insulin production or impaired insulin utilization. One of its most severe complications is diabetic retinopathy (DR), a progressive retinal disease caused by microvascular damage, leading to hemorrhages, exudates, and potential vision loss. Early and reliable detection of DR is therefore critical for preventing irreversible blindness.   In this work, we propose an uncertainty-aware deep learning framework for automated DR severity grading that explicitly models the ordinal nature of disease progression. Our approach combines a convolutional backbone with lesion-query attention pooling and an evidential Dirichlet-based ordinal regression head, enabling both accurate severity prediction and principled estimation of predictive uncertainty. The model is trained using an ordinal evidential loss with annealed regularization to encourage calibrated confidence under domain shift.   We evaluate the proposed method on a multi-domain training setup combining APTOS, Messidor-2, and a subset of EyePACS fundus datasets. Experimental results demonstrate strong cross-dataset generalization, achieving competitive classification accuracy and high quadratic weighted kappa on held-out test sets, while providing meaningful uncertainty estimates for low-confidence cases. These results suggest that ordinal evidential learning is a promising direction for robust and clinically reliable diabetic retinopathy grading.",
      "authors": [
        "Ali El Bellaj",
        "Aya Benradi",
        "Salman El Youssoufi",
        "Taha El Marzouki",
        "Mohammed-Amine Cheddadi"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "published": "2026-02-10 21:44:04+00:00",
      "link": "https://arxiv.org/pdf/2602.10315v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10303v1",
      "title": "ICODEN: Ordinary Differential Equation Neural Networks for Interval-Censored Data",
      "abstract": "Predicting time-to-event outcomes when event times are interval censored is challenging because the exact event time is unobserved. Many existing survival analysis approaches for interval-censored data rely on strong model assumptions or cannot handle high-dimensional predictors. We develop ICODEN, an ordinary differential equation-based neural network for interval-censored data that models the hazard function through deep neural networks and obtains the cumulative hazard by solving an ordinary differential equation. ICODEN does not require the proportional hazards assumption or a prespecified parametric form for the hazard function, thereby permitting flexible survival modeling. Across simulation settings with proportional or non-proportional hazards and both linear and nonlinear covariate effects, ICODEN consistently achieves satisfactory predictive accuracy and remains stable as the number of predictors increases. Applications to data from multiple phases of the Alzheimer's Disease Neuroimaging Initiative (ADNI) and to two Age-Related Eye Disease Studies (AREDS and AREDS2) for age-related macular degeneration (AMD) demonstrate ICODEN's robust prediction performance. In both applications, predicting time-to-AD or time-to-late AMD, ICODEN effectively uses hundreds to more than 1,000 SNPs and supports data-driven subgroup identification with differential progression risk profiles. These results establish ICODEN as a practical assumption-lean tool for prediction with interval-censored survival data in high-dimensional biomedical settings.",
      "authors": [
        "Haoling Wang",
        "Lang Zeng",
        "Tao Sun",
        "Youngjoo Cho",
        "Ying Ding"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "q-bio.QM",
        "stat.ML"
      ],
      "published": "2026-02-10 21:18:38+00:00",
      "link": "https://arxiv.org/pdf/2602.10303v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10300v1",
      "title": "Configuration-to-Performance Scaling Law with Neural Ansatz",
      "abstract": "Researchers build scaling laws to forecast the training performance of expensive large-scale runs with larger model size N and data size D. These laws assume that other training hyperparameters are optimally chosen, which can require significant effort and, in some cases, be impossible due to external hardware constraints. To improve predictability across a broader set of hyperparameters and enable simpler tuning at scale, we propose learning a \\textit{Configuration-to-Performance Scaling Law} (CPL): a mapping from the \\textit{full training configuration} to training performance. Because no simple functional form can express this mapping, we parameterize it with a large language model (LLM), and fit it with diverse open-source pretraining logs across multiple sources, yielding a \\textit{Neural} Configuration-to-Performance Scaling Law (NCPL). NCPL accurately predicts how training configurations influence the final pretraining loss, achieving 20-40% lower prediction error than the configuration-agnostic Chinchilla law and generalizing to runs using up to 10 x more compute than any run in the training set. It further supports joint tuning of multiple hyperparameters with performance comparable to hyperparameter scaling law baselines. Finally, NCPL naturally and effectively extends to richer prediction targets such as loss-curve prediction.",
      "authors": [
        "Huaqing Zhang",
        "Kaiyue Wen",
        "Tengyu Ma"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 21:16:59+00:00",
      "link": "https://arxiv.org/pdf/2602.10300v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10299v1",
      "title": "The Role of Learning in Attacking Intrusion Detection Systems",
      "abstract": "Recent work on network attacks have demonstrated that ML-based network intrusion detection systems (NIDS) can be evaded with adversarial perturbations. However, these attacks rely on complex optimizations that have large computational overheads, making them impractical in many real-world settings. In this paper, we introduce a lightweight adversarial agent that implements strategies (policies) trained via reinforcement learning (RL) that learn to evade ML-based NIDS without requiring online optimization. This attack proceeds by (1) offline training, where the agent learns to evade a surrogate ML model by perturbing malicious flows using network traffic data assumed to be collected via reconnaissance, then (2) deployment, where the trained agent is used in a compromised device controlled by an attacker to evade ML-based NIDS using learned attack strategies. We evaluate our approach across diverse NIDS and several white-, gray-, and black-box threat models. We demonstrate that attacks using these lightweight agents can be highly effective (reaching up to 48.9% attack success rate), extremely fast (requiring as little as 5.72ms to craft an attack), and require negligible resources (e.g., 0.52MB of memory). Through this work, we demonstrate that future botnets driven by lightweight learning-based agents can be highly effective and widely deployable in diverse environments of compromised devices.",
      "authors": [
        "Kyle Domico",
        "Jean-Charles Noirot Ferrand",
        "Patrick McDaniel"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-10 21:15:20+00:00",
      "link": "https://arxiv.org/pdf/2602.10299v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10286v1",
      "title": "What Does Preference Learning Recover from Pairwise Comparison Data?",
      "abstract": "Pairwise preference learning is central to machine learning, with recent applications in aligning language models with human preferences. A typical dataset consists of triplets $(x, y^+, y^-)$, where response $y^+$ is preferred over response $y^-$ for context $x$. The Bradley--Terry (BT) model is the predominant approach, modeling preference probabilities as a function of latent score differences. Standard practice assumes data follows this model and learns the latent scores accordingly. However, real data may violate this assumption, and it remains unclear what BT learning recovers in such cases. Starting from triplet comparison data, we formalize the preference information it encodes through the conditional preference distribution (CPRD). We give precise conditions for when BT is appropriate for modeling the CPRD, and identify factors governing sample efficiency -- namely, margin and connectivity. Together, these results offer a data-centric foundation for understanding what preference learning actually recovers.",
      "authors": [
        "Rattana Pukdee",
        "Maria-Florina Balcan",
        "Pradeep Ravikumar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 20:59:55+00:00",
      "link": "https://arxiv.org/pdf/2602.10286v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13319v1",
      "title": "Situation Graph Prediction: Structured Perspective Inference for User Modeling",
      "abstract": "Perspective-Aware AI requires modeling evolving internal states--goals, emotions, contexts--not merely preferences. Progress is limited by a data bottleneck: digital footprints are privacy-sensitive and perspective states are rarely labeled. We propose Situation Graph Prediction (SGP), a task that frames perspective modeling as an inverse inference problem: reconstructing structured, ontology-aligned representations of perspective from observable multimodal artifacts. To enable grounding without real labels, we use a structure-first synthetic generation strategy that aligns latent labels and observable traces by design. As a pilot, we construct a dataset and run a diagnostic study using retrieval-augmented in-context learning as a proxy for supervision. In our study with GPT-4o, we observe a gap between surface-level extraction and latent perspective inference--indicating latent-state inference is harder than surface extraction under our controlled setting. Results suggest SGP is non-trivial and provide evidence for the structure-first data synthesis strategy.",
      "authors": [
        "Jisung Shin",
        "Daniel Platnick",
        "Marjan Alirezaie",
        "Hossein Rahnama"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "published": "2026-02-10 20:58:15+00:00",
      "link": "https://arxiv.org/pdf/2602.13319v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10285v2",
      "title": "Adaptive Time Step Flow Matching for Autonomous Driving Motion Planning",
      "abstract": "Autonomous driving requires reasoning about interactions with surrounding traffic. A prevailing approach is large-scale imitation learning on expert driving datasets, aimed at generalizing across diverse real-world scenarios. For online trajectory generation, such methods must operate at real-time rates. Diffusion models require hundreds of denoising steps at inference, resulting in high latency. Consistency models mitigate this issue but rely on carefully tuned noise schedules to capture the multimodal action distributions common in autonomous driving. Adapting the schedule, typically requires expensive retraining. To address these limitations, we propose a framework based on conditional flow matching that jointly predicts future motions of surrounding agents and plans the ego trajectory in real time. We train a lightweight variance estimator that selects the number of inference steps online, removing the need for retraining to balance runtime and imitation learning performance. To further enhance ride quality, we introduce a trajectory post-processing step cast as a convex quadratic program, with negligible computational overhead. Trained on the Waymo Open Motion Dataset, the framework performs maneuvers such as lane changes, cruise control, and navigating unprotected left turns without requiring scenario-specific tuning. Our method maintains a 20 Hz update rate on an NVIDIA RTX 3070 GPU, making it suitable for online deployment. Compared to transformer, diffusion, and consistency model baselines, we achieve improved trajectory smoothness and better adherence to dynamic constraints. Experiment videos and code implementations can be found at https://flow-matching-self-driving.github.io/.",
      "authors": [
        "Ananya Trivedi",
        "Anjian Li",
        "Mohamed Elnoor",
        "Yusuf Umut Ciftci",
        "Avinash Singh",
        "Jovin D'sa",
        "Sangjae Bae",
        "David Isele",
        "Taskin Padir",
        "Faizan M. Tariq"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-10 20:57:01+00:00",
      "link": "https://arxiv.org/pdf/2602.10285v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10282v1",
      "title": "Linear-LLM-SCM: Benchmarking LLMs for Coefficient Elicitation in Linear-Gaussian Causal Models",
      "abstract": "Large language models (LLMs) have shown potential in identifying qualitative causal relations, but their ability to perform quantitative causal reasoning -- estimating effect sizes that parametrize functional relationships -- remains underexplored in continuous domains. We introduce Linear-LLM-SCM, a plug-and-play benchmarking framework for evaluating LLMs on linear Gaussian structural causal model (SCM) parametrization when the DAG is given. The framework decomposes a DAG into local parent-child sets and prompts an LLM to produce a regression-style structural equation per node, which is aggregated and compared against available ground-truth parameters. Our experiments show several challenges in such benchmarking tasks, namely, strong stochasticity in the results in some of the models and susceptibility to DAG misspecification via spurious edges in the continuous domains. Across models, we observe substantial variability in coefficient estimates for some settings and sensitivity to structural and semantic perturbations, highlighting current limitations of LLMs as quantitative causal parameterizers. We also open-sourced the benchmarking framework so that researchers can utilize their DAGs and any off-the-shelf LLMs plug-and-play for evaluation in their domains effortlessly.",
      "authors": [
        "Kanta Yamaoka",
        "Sumantrak Mukherjee",
        "Thomas Gärtner",
        "David Antony Selby",
        "Stefan Konigorski",
        "Eyke Hüllermeier",
        "Viktor Bengs",
        "Sebastian Josef Vollmer"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 20:49:01+00:00",
      "link": "https://arxiv.org/pdf/2602.10282v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10278v1",
      "title": "ERGO: Excess-Risk-Guided Optimization for High-Fidelity Monocular 3D Gaussian Splatting",
      "abstract": "Generating 3D content from a single image remains a fundamentally challenging and ill-posed problem due to the inherent absence of geometric and textural information in occluded regions. While state-of-the-art generative models can synthesize auxiliary views to provide additional supervision, these views inevitably contain geometric inconsistencies and textural misalignments that propagate and amplify artifacts during 3D reconstruction. To effectively harness these imperfect supervisory signals, we propose an adaptive optimization framework guided by excess risk decomposition, termed ERGO. Specifically, ERGO decomposes the optimization losses in 3D Gaussian splatting into two components, i.e., excess risk that quantifies the suboptimality gap between current and optimal parameters, and Bayes error that models the irreducible noise inherent in synthesized views. This decomposition enables ERGO to dynamically estimate the view-specific excess risk and adaptively adjust loss weights during optimization. Furthermore, we introduce geometry-aware and texture-aware objectives that complement the excess-risk-derived weighting mechanism, establishing a synergistic global-local optimization paradigm. Consequently, ERGO demonstrates robustness against supervision noise while consistently enhancing both geometric fidelity and textural quality of the reconstructed 3D content. Extensive experiments on the Google Scanned Objects dataset and the OmniObject3D dataset demonstrate the superiority of ERGO over existing state-of-the-art methods.",
      "authors": [
        "Zehua Ma",
        "Hanhui Li",
        "Zhenyu Xie",
        "Xiaonan Luo",
        "Michael Kampffmeyer",
        "Feng Gao",
        "Xiaodan Liang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-10 20:44:43+00:00",
      "link": "https://arxiv.org/pdf/2602.10278v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10266v1",
      "title": "From Classical to Topological Neural Networks Under Uncertainty",
      "abstract": "This chapter explores neural networks, topological data analysis, and topological deep learning techniques, alongside statistical Bayesian methods, for processing images, time series, and graphs to maximize the potential of artificial intelligence in the military domain. Throughout the chapter, we highlight practical applications spanning image, video, audio, and time-series recognition, fraud detection, and link prediction for graphical data, illustrating how topology-aware and uncertainty-aware models can enhance robustness, interpretability, and generalization.",
      "authors": [
        "Sarah Harkins Dayton",
        "Layal Bou Hamdan",
        "Ioannis D. Schizas",
        "David L. Boothe",
        "Vasileios Maroulas"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-10 20:21:04+00:00",
      "link": "https://arxiv.org/pdf/2602.10266v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10265v1",
      "title": "Colorimeter-Supervised Skin Tone Estimation from Dermatoscopic Images for Fairness Auditing",
      "abstract": "Neural-network-based diagnosis from dermatoscopic images is increasingly used for clinical decision support, yet studies report performance disparities across skin tones. Fairness auditing of these models is limited by the lack of reliable skin-tone annotations in public dermatoscopy datasets. We address this gap with neural networks that predict Fitzpatrick skin type via ordinal regression and the Individual Typology Angle (ITA) via color regression, using in-person Fitzpatrick labels and colorimeter measurements as targets. We further leverage extensive pretraining on synthetic and real dermatoscopic and clinical images. The Fitzpatrick model achieves agreement comparable to human crowdsourced annotations, and ITA predictions show high concordance with colorimeter-derived ITA, substantially outperforming pixel-averaging approaches. Applying these estimators to ISIC 2020 and MILK10k, we find that fewer than 1% of subjects belong to Fitzpatrick types V and VI. We release code and pretrained models as an open-source tool for rapid skin-tone annotation and bias auditing. This is, to our knowledge, the first dermatoscopic skin-tone estimation neural network validated against colorimeter measurements, and it supports growing evidence of clinically relevant performance gaps across skin-tone groups.",
      "authors": [
        "Marin Benčević",
        "Krešimir Romić",
        "Ivana Hartmann Tolić",
        "Irena Galić"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 20:20:45+00:00",
      "link": "https://arxiv.org/pdf/2602.10265v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10261v1",
      "title": "Kernel-Based Learning of Chest X-ray Images for Predicting ICU Escalation among COVID-19 Patients",
      "abstract": "Kernel methods have been extensively utilized in machine learning for classification and prediction tasks due to their ability to capture complex non-linear data patterns. However, single kernel approaches are inherently limited, as they rely on a single type of kernel function (e.g., Gaussian kernel), which may be insufficient to fully represent the heterogeneity or multifaceted nature of real-world data. Multiple kernel learning (MKL) addresses these limitations by constructing composite kernels from simpler ones and integrating information from heterogeneous sources. Despite these advances, traditional MKL methods are primarily designed for continuous outcomes. We extend MKL to accommodate the outcome variable belonging to the exponential family, representing a broader variety of data types, and refer to our proposed method as generalized linear models with integrated multiple additive regression with kernels (GLIMARK). Empirically, we demonstrate that GLIMARK can effectively recover or approximate the true data-generating mechanism. We have applied it to a COVID-19 chest X-ray dataset, predicting binary outcomes of ICU escalation and extracting clinically meaningful features, underscoring the practical utility of this approach in real-world scenarios.",
      "authors": [
        "Qiyuan Shi",
        "Jian Kang",
        "Yi Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.AP",
        "stat.ML"
      ],
      "published": "2026-02-10 20:11:43+00:00",
      "link": "https://arxiv.org/pdf/2602.10261v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10249v1",
      "title": "Modeling Programming Skills with Source Code Embeddings for Context-aware Exercise Recommendation",
      "abstract": "In this paper, we propose a context-aware recommender system that models students' programming skills using embeddings of the source code they submit throughout a course. These embeddings predict students' skills across multiple programming topics, producing profiles that are matched to the skills required by unseen homework problems. To generate recommendations, we compute the cosine similarity between student profiles and problem skill vectors, ranking exercises according to their alignment with each student's current abilities. We evaluated our approach using real data from students and exercises in an introductory programming course at our university. First, we assessed the effectiveness of our source code embeddings for predicting skills, comparing them with token-based and graph-based alternatives. Results showed that Jina embeddings outperformed TF-IDF, CodeBERT-cpp, and GraphCodeBERT across most skills. Additionally, we evaluated the system's ability to recommend exercises aligned with weekly course content by analyzing student submissions collected over seven course offerings. Our approach consistently produced more suitable recommendations than baselines based on correctness or solution time, indicating that predicted programming skills provide a stronger signal for problem recommendation.",
      "authors": [
        "Carlos Eduardo P. Silva",
        "João Pedro M. Sena",
        "Julio C. S. Reis",
        "André G. Santos",
        "Lucas N. Ferreira"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 19:51:48+00:00",
      "link": "https://arxiv.org/pdf/2602.10249v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10238v1",
      "title": "Learning to Evict from Key-Value Cache",
      "abstract": "The growing size of Large Language Models (LLMs) makes efficient inference challenging, primarily due to the memory demands of the autoregressive Key-Value (KV) cache. Existing eviction or compression methods reduce cost but rely on heuristics, such as recency or past attention scores, which serve only as indirect proxies for a token's future utility and introduce computational overhead. We reframe KV cache eviction as a reinforcement learning (RL) problem: learning to rank tokens by their predicted usefulness for future decoding. To this end, we introduce KV Policy (KVP), a framework of lightweight per-head RL agents trained on pre-computed generation traces using only key and value vectors. Each agent learns a specialized eviction policy guided by future utility, which evaluates the quality of the ranking across all cache budgets, requiring no modifications to the underlying LLM or additional inference. Evaluated across two different model families on the long-context benchmark RULER and the multi-turn dialogue benchmark OASST2-4k, KVP significantly outperforms baselines. Furthermore, zero-shot tests on standard downstream tasks (e.g., LongBench, BOOLQ, ARC) indicate that KVP generalizes well beyond its training distribution and to longer context lengths. These results demonstrate that learning to predict future token utility is a powerful and scalable paradigm for adaptive KV cache management.",
      "authors": [
        "Luca Moschella",
        "Laura Manduchi",
        "Ozan Sener"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-10 19:34:15+00:00",
      "link": "https://arxiv.org/pdf/2602.10238v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10233v1",
      "title": "ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise",
      "abstract": "Recent advances in LLM-guided evolutionary computation, particularly AlphaEvolve, have demonstrated remarkable success in discovering novel mathematical constructions and solving challenging optimization problems. In this article, we present ImprovEvolve, a simple yet effective technique for enhancing LLM-based evolutionary approaches such as AlphaEvolve. Given an optimization problem, the standard approach is to evolve program code that, when executed, produces a solution close to the optimum. We propose an alternative program parameterization that maintains the ability to construct optimal solutions while reducing the cognitive load on the LLM. Specifically, we evolve a program (implementing, e.g., a Python class with a prescribed interface) that provides the following functionality: (1) propose a valid initial solution, (2) improve any given solution in terms of fitness, and (3) perturb a solution with a specified intensity. The optimum can then be approached by iteratively applying improve() and perturb() with a scheduled intensity. We evaluate ImprovEvolve on challenging problems from the AlphaEvolve paper: hexagon packing in a hexagon and the second autocorrelation inequality. For hexagon packing, the evolved program achieves new state-of-the-art results for 11, 12, 15, and 16 hexagons; a lightly human-edited variant further improves results for 14, 17, and 23 hexagons. For the second autocorrelation inequality, the human-edited program achieves a new state-of-the-art lower bound of 0.96258, improving upon AlphaEvolve's 0.96102.",
      "authors": [
        "Alexey Kravatskiy",
        "Valentin Khrulkov",
        "Ivan Oseledets"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI",
        "math.CA",
        "math.MG",
        "math.OC"
      ],
      "published": "2026-02-10 19:23:13+00:00",
      "link": "https://arxiv.org/pdf/2602.10233v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10231v1",
      "title": "Blockwise Advantage Estimation for Multi-Objective RL with Verifiable Rewards",
      "abstract": "Group Relative Policy Optimization (GRPO) assigns a single scalar advantage to all tokens in a completion. For structured generations with explicit segments and objectives, this couples unrelated reward signals across segments, leading to objective interference and misattributed credit. We propose Blockwise Advantage Estimation, a family of GRPO-compatible methods that assigns each objective its own advantage and applies it only to the tokens in the corresponding text block, reducing reliance on hand-designed scalar rewards and scaling naturally to additional objectives. A key challenge is estimating advantages for later blocks whose rewards are conditioned on sampled prefixes; standard unbiased approaches require expensive nested rollouts from intermediate states. Concretely, we introduce an Outcome-Conditioned Baseline that approximates intermediate state values using only within-group statistics by stratifying samples according to a prefix-derived intermediate outcome. On math tasks with uncertainty estimation, our method mitigates reward interference, is competitive with a state-of-the-art reward-designed approach, and preserves test-time gains from confidence-weighted ensembling. More broadly, it provides a modular recipe for optimizing sequential objectives in structured generations without additional rollouts.",
      "authors": [
        "Kirill Pavlenko",
        "Alexander Golubev",
        "Simon Karasik",
        "Boris Yangel"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-10 19:22:37+00:00",
      "link": "https://arxiv.org/pdf/2602.10231v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10224v1",
      "title": "Internalizing Meta-Experience into Memory for Guided Reinforcement Learning in Large Language Models",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an effective approach for enhancing the reasoning capabilities of Large Language Models (LLMs). Despite its efficacy, RLVR faces a meta-learning bottleneck: it lacks mechanisms for error attribution and experience internalization intrinsic to the human learning cycle beyond practice and verification, thereby limiting fine-grained credit assignment and reusable knowledge formation. We term such reusable knowledge representations derived from past errors as meta-experience. Based on this insight, we propose Meta-Experience Learning (MEL), a novel framework that incorporates self-distilled meta-experience into the model's parametric memory. Building upon standard RLVR, we introduce an additional design that leverages the LLM's self-verification capability to conduct contrastive analysis on paired correct and incorrect trajectories, identify the precise bifurcation points where reasoning errors arise, and summarize them into generalizable meta-experience. The meta-experience is further internalized into the LLM's parametric memory by minimizing the negative log-likelihood, which induces a language-modeled reward signal that bridges correct and incorrect reasoning trajectories and facilitates effective knowledge reuse. Experimental results demonstrate that MEL achieves consistent improvements on benchmarks, yielding 3.92%--4.73% Pass@1 gains across varying model sizes.",
      "authors": [
        "Shiting Huang",
        "Zecheng Li",
        "Yu Zeng",
        "Qingnan Ren",
        "Zhen Fang",
        "Qisheng Su",
        "Kou Shi",
        "Lin Chen",
        "Zehui Chen",
        "Feng Zhao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-10 19:16:09+00:00",
      "link": "https://arxiv.org/pdf/2602.10224v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10218v1",
      "title": "ACE-RTL: When Agentic Context Evolution Meets RTL-Specialized LLMs",
      "abstract": "Recent advances in large language models (LLMs) have sparked growing interest in applying them to hardware design automation, particularly for accurate RTL code generation. Prior efforts follow two largely independent paths: (i) training domain-adapted RTL models to internalize hardware semantics, (ii) developing agentic systems that leverage frontier generic LLMs guided by simulation feedback. However, these two paths exhibit complementary strengths and weaknesses. In this work, we present ACE-RTL that unifies both directions through Agentic Context Evolution (ACE). ACE-RTL integrates an RTL-specialized LLM, trained on a large-scale dataset of 1.7 million RTL samples, with a frontier reasoning LLM through three synergistic components: the generator, reflector, and coordinator. These components iteratively refine RTL code toward functional correctness. We further introduce a parallel scaling strategy that significantly reduces the number of iterations required to reach correct solutions. On the Comprehensive Verilog Design Problems (CVDP) benchmark, ACE-RTL achieves up to a 44.87% pass rate improvement over 14 competitive baselines while requiring only four iterations on average.",
      "authors": [
        "Chenhui Deng",
        "Zhongzhi Yu",
        "Guan-Ting Liu",
        "Nathaniel Pinckney",
        "Haoxing Ren"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR",
        "cs.LG"
      ],
      "published": "2026-02-10 19:09:13+00:00",
      "link": "https://arxiv.org/pdf/2602.10218v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10179v1",
      "title": "When the Prompt Becomes Visual: Vision-Centric Jailbreak Attacks for Large Image Editing Models",
      "abstract": "Recent advances in large image editing models have shifted the paradigm from text-driven instructions to vision-prompt editing, where user intent is inferred directly from visual inputs such as marks, arrows, and visual-text prompts. While this paradigm greatly expands usability, it also introduces a critical and underexplored safety risk: the attack surface itself becomes visual. In this work, we propose Vision-Centric Jailbreak Attack (VJA), the first visual-to-visual jailbreak attack that conveys malicious instructions purely through visual inputs. To systematically study this emerging threat, we introduce IESBench, a safety-oriented benchmark for image editing models. Extensive experiments on IESBench demonstrate that VJA effectively compromises state-of-the-art commercial models, achieving attack success rates of up to 80.9% on Nano Banana Pro and 70.1% on GPT-Image-1.5. To mitigate this vulnerability, we propose a training-free defense based on introspective multimodal reasoning, which substantially improves the safety of poorly aligned models to a level comparable with commercial systems, without auxiliary guard models and with negligible computational overhead. Our findings expose new vulnerabilities, provide both a benchmark and practical defense to advance safe and trustworthy modern image editing systems. Warning: This paper contains offensive images created by large image editing models.",
      "authors": [
        "Jiacheng Hou",
        "Yining Sun",
        "Ruochong Jin",
        "Haochen Han",
        "Fangming Liu",
        "Wai Kin Victor Chan",
        "Alex Jinpeng Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-10 18:59:55+00:00",
      "link": "https://arxiv.org/pdf/2602.10179v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10114v1",
      "title": "Decoupled MPPI-Based Multi-Arm Motion Planning",
      "abstract": "Recent advances in sampling-based motion planning algorithms for high DOF arms leverage GPUs to provide SOTA performance. These algorithms can be used to control multiple arms jointly, but this approach scales poorly. To address this, we extend STORM, a sampling-based model-predictive-control (MPC) motion planning algorithm, to handle multiple robots in a distributed fashion. First, we modify STORM to handle dynamic obstacles. Then, we let each arm compute its own motion plan prefix, which it shares with the other arms, which treat it as a dynamic obstacle. Finally, we add a dynamic priority scheme. The new algorithm, MR-STORM, demonstrates clear empirical advantages over SOTA algorithms when operating with both static and dynamic obstacles.",
      "authors": [
        "Dan Evron",
        "Elias Goldsztejn",
        "Ronen I. Brafman"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-10 18:59:51+00:00",
      "link": "https://arxiv.org/pdf/2602.10114v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10094v1",
      "title": "4RC: 4D Reconstruction via Conditional Querying Anytime and Anywhere",
      "abstract": "We present 4RC, a unified feed-forward framework for 4D reconstruction from monocular videos. Unlike existing approaches that typically decouple motion from geometry or produce limited 4D attributes such as sparse trajectories or two-view scene flow, 4RC learns a holistic 4D representation that jointly captures dense scene geometry and motion dynamics. At its core, 4RC introduces a novel encode-once, query-anywhere and anytime paradigm: a transformer backbone encodes the entire video into a compact spatio-temporal latent space, from which a conditional decoder can efficiently query 3D geometry and motion for any query frame at any target timestamp. To facilitate learning, we represent per-view 4D attributes in a minimally factorized form by decomposing them into base geometry and time-dependent relative motion. Extensive experiments demonstrate that 4RC outperforms prior and concurrent methods across a wide range of 4D reconstruction tasks.",
      "authors": [
        "Yihang Luo",
        "Shangchen Zhou",
        "Yushi Lan",
        "Xingang Pan",
        "Chen Change Loy"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 18:57:04+00:00",
      "link": "https://arxiv.org/pdf/2602.10094v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10090v2",
      "title": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning",
      "abstract": "Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale to 1,000 environments covering everyday scenarios, in which agents can interact with rich toolsets (35 tools per environment on average) and obtain high-quality observations. Notably, these environments are code-driven and backed by databases, providing more reliable and consistent state transitions than environments simulated by LLMs. Moreover, they enable more efficient agent interaction compared with collecting trajectories from realistic environments. To demonstrate the effectiveness of this resource, we perform large-scale reinforcement learning for multi-turn tool-use agents. Thanks to the fully executable environments and accessible database states, we can also design reliable reward functions. Experiments on three benchmarks show that training exclusively in synthetic environments, rather than benchmark-specific ones, yields strong out-of-distribution generalization. The code is available at https://github.com/Snowflake-Labs/agent-world-model.",
      "authors": [
        "Zhaoyang Wang",
        "Canwen Xu",
        "Boyi Liu",
        "Yite Wang",
        "Siwei Han",
        "Zhewei Yao",
        "Huaxiu Yao",
        "Yuxiong He"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-10 18:55:41+00:00",
      "link": "https://arxiv.org/pdf/2602.10090v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10085v2",
      "title": "CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs",
      "abstract": "Developing agents capable of open-endedly discovering and learning novel skills is a grand challenge in Artificial Intelligence. While reinforcement learning offers a powerful framework for training agents to master complex skills, it typically relies on hand-designed reward functions. This is infeasible for open-ended skill discovery, where the set of meaningful skills is not known a priori. While recent methods have shown promising results towards automating reward function design, they remain limited to refining rewards for pre-defined tasks. To address this limitation, we introduce Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs (CODE-SHARP), a novel framework leveraging Foundation Models (FM) to open-endedly expand and refine a hierarchical skill archive, structured as a directed graph of executable reward functions in code. We show that a goal-conditioned agent trained exclusively on the rewards generated by the discovered SHARP skills learns to solve increasingly long-horizon goals in the Craftax environment. When composed by a high-level FM-based planner, the discovered skills enable a single goal-conditioned agent to solve complex, long-horizon tasks, outperforming both pretrained agents and task-specific expert policies by over $134$% on average. We will open-source our code and provide additional videos at https://sites.google.com/view/code-sharp/homepage.",
      "authors": [
        "Richard Bornemann",
        "Pierluigi Vito Amadori",
        "Antoine Cully"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-10 18:51:39+00:00",
      "link": "https://arxiv.org/pdf/2602.10085v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10081v2",
      "title": "Anagent For Enhancing Scientific Table & Figure Analysis",
      "abstract": "In scientific research, analysis requires accurately interpreting complex multimodal knowledge, integrating evidence from different sources, and drawing inferences grounded in domain-specific knowledge. However, current artificial intelligence (AI) systems struggle to consistently demonstrate such capabilities. The complexity and variability of scientific tables and figures, combined with heterogeneous structures and long-context requirements, pose fundamental obstacles to scientific table \\& figure analysis. To quantify these challenges, we introduce AnaBench, a large-scale benchmark featuring $63,178$ instances from nine scientific domains, systematically categorized along seven complexity dimensions. To tackle these challenges, we propose Anagent, a multi-agent framework for enhanced scientific table \\& figure analysis through four specialized agents: Planner decomposes tasks into actionable subtasks, Expert retrieves task-specific information through targeted tool execution, Solver synthesizes information to generate coherent analysis, and Critic performs iterative refinement through five-dimensional quality assessment. We further develop modular training strategies that leverage supervised finetuning and specialized reinforcement learning to optimize individual capabilities while maintaining effective collaboration. Comprehensive evaluation across 9 broad domains with 170 subdomains demonstrates that Anagent achieves substantial improvements, up to $\\uparrow 13.43\\%$ in training-free settings and $\\uparrow 42.12\\%$ with finetuning, while revealing that task-oriented reasoning and context-aware problem-solving are essential for high-quality scientific table \\& figure analysis. Our project page: https://xhguo7.github.io/Anagent/.",
      "authors": [
        "Xuehang Guo",
        "Zhiyong Lu",
        "Tom Hope",
        "Qingyun Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-10 18:46:28+00:00",
      "link": "https://arxiv.org/pdf/2602.10081v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10176v1",
      "title": "Dissecting Performative Prediction: A Comprehensive Survey",
      "abstract": "The field of performative prediction had its beginnings in 2020 with the seminal paper \"Performative Prediction\" by Perdomo et al., which established a novel machine learning setup where the deployment of a predictive model causes a distribution shift in the environment, which in turn causes a mismatch between the distribution expected by the predictive model and the real distribution. This shift is defined by a so-called distribution map. In the half-decade since, a literature has emerged which has, among other things, introduced new solution concepts to the original setup, extended the setup, offered new theoretical analyses, and examined the intersection of performative prediction and other established fields. In this survey, we first lay out the performative prediction setting and explain the different optimization targets: performative stability and performative optimality. We introduce a new way of classifying different performative prediction settings, based on how much information is available about the distribution map. We survey existing implementations of distribution maps and existing methods to address the problem of performative prediction, while examining different ways to categorize them. Finally, we point out known and previously unknown connections that can be drawn to other fields, in the hopes of stimulating future research.",
      "authors": [
        "Thomas Kehrenberg",
        "Javier Sanguino",
        "Jose A. Lozano",
        "Novi Quadrianto"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-10 18:40:01+00:00",
      "link": "https://arxiv.org/pdf/2602.10176v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10067v3",
      "title": "Features as Rewards: Scalable Supervision for Open-Ended Tasks via Interpretability",
      "abstract": "Language models trained on large-scale datasets have been shown to learn features that encode abstract concepts such as factuality or intent. Such features are traditionally used for test-time monitoring or steering. We present an alternative affordance: features as scalable supervision for open-ended tasks. We consider the case of hallucination-reduction as a desirable, yet open-ended behavior and design a reinforcement learning (RL) pipeline, titled RLFR (Reinforcement Learning from Feature Rewards), that uses features as reward functions. Grounded in a novel probing framework that identifies candidate hallucinated claims, our pipeline teaches a model to intervene and correct its completions when it is uncertain of their factuality. Furthermore, the pipeline enables scalable test-time compute, guided once more by our reward features. This end-to-end process operationalized on Gemma-3-12B-IT results in a policy that is 58% less likely to hallucinate compared to the original model (when run in tandem with our probing harness), while preserving performance on standard benchmarks. Taken together, by grounding supervision in the language of features, this paper introduces a novel paradigm in the use of interpretability for learning open-ended tasks.",
      "authors": [
        "Aaditya Vikram Prasad",
        "Connor Watts",
        "Jack Merullo",
        "Dhruvil Gala",
        "Owen Lewis",
        "Thomas McGrath",
        "Ekdeep Singh Lubana"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 18:33:45+00:00",
      "link": "https://arxiv.org/pdf/2602.10067v3",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10063v1",
      "title": "Chain of Mindset: Reasoning with Adaptive Cognitive Modes",
      "abstract": "Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single-minded assumption prevents models from reaching the next level of intelligence. To address this limitation, we propose Chain of Mindset (CoM), a training-free agentic framework that enables step-level adaptive mindset orchestration. CoM decomposes reasoning into four functionally heterogeneous mindsets: Spatial, Convergent, Divergent, and Algorithmic. A Meta-Agent dynamically selects the optimal mindset based on the evolving reasoning state, while a bidirectional Context Gate filters cross-module information flow to maintain effectiveness and efficiency. Experiments across six challenging benchmarks spanning mathematics, code generation, scientific QA, and spatial reasoning demonstrate that CoM achieves state-of-the-art performance, outperforming the strongest baseline by 4.96\\% and 4.72\\% in overall accuracy on Qwen3-VL-32B-Instruct and Gemini-2.0-Flash, while balancing reasoning efficiency. Our code is publicly available at \\href{https://github.com/QuantaAlpha/chain-of-mindset}{https://github.com/QuantaAlpha/chain-of-mindset}.",
      "authors": [
        "Tianyi Jiang",
        "Arctanx An",
        "Hengyi Feng",
        "Naixin Zhai",
        "Haodong Li",
        "Xiaomin Yu",
        "Jiahui Liu",
        "Hanwen Du",
        "Shuo Zhang",
        "Zhi Yang",
        "Jie Huang",
        "Yuhua Li",
        "Yongxin Ni",
        "Huacan Wang",
        "Ronghao Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-10 18:31:47+00:00",
      "link": "https://arxiv.org/pdf/2602.10063v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11206v1",
      "title": "UltraLIF: Fully Differentiable Spiking Neural Networks via Ultradiscretization and Max-Plus Algebra",
      "abstract": "Spiking Neural Networks (SNNs) offer energy-efficient, biologically plausible computation but suffer from non-differentiable spike generation, necessitating reliance on heuristic surrogate gradients. This paper introduces UltraLIF, a principled framework that replaces surrogate gradients with ultradiscretization, a mathematical formalism from tropical geometry providing continuous relaxations of discrete dynamics. The central insight is that the max-plus semiring underlying ultradiscretization naturally models neural threshold dynamics: the log-sum-exp function serves as a differentiable soft-maximum that converges to hard thresholding as a learnable temperature parameter $\\eps \\to 0$. Two neuron models are derived from distinct dynamical systems: UltraLIF from the LIF ordinary differential equation (temporal dynamics) and UltraDLIF from the diffusion equation modeling gap junction coupling across neuronal populations (spatial dynamics). Both yield fully differentiable SNNs trainable via standard backpropagation with no forward-backward mismatch. Theoretical analysis establishes pointwise convergence to classical LIF dynamics with quantitative error bounds and bounded non-vanishing gradients. Experiments on six benchmarks spanning static images, neuromorphic vision, and audio demonstrate improvements over surrogate gradient baselines, with gains most pronounced in single-timestep ($T{=}1$) settings on neuromorphic and temporal datasets. An optional sparsity penalty enables significant energy reduction while maintaining competitive accuracy.",
      "authors": [
        "Jose Marie Antonio Miñoza"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "math.RA",
        "q-bio.NC"
      ],
      "published": "2026-02-10 18:21:54+00:00",
      "link": "https://arxiv.org/pdf/2602.11206v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10052v1",
      "title": "Spatio-Temporal Attention for Consistent Video Semantic Segmentation in Automated Driving",
      "abstract": "Deep neural networks, especially transformer-based architectures, have achieved remarkable success in semantic segmentation for environmental perception. However, existing models process video frames independently, thus failing to leverage temporal consistency, which could significantly improve both accuracy and stability in dynamic scenes. In this work, we propose a Spatio-Temporal Attention (STA) mechanism that extends transformer attention blocks to incorporate multi-frame context, enabling robust temporal feature representations for video semantic segmentation. Our approach modifies standard self-attention to process spatio-temporal feature sequences while maintaining computational efficiency and requiring minimal changes to existing architectures. STA demonstrates broad applicability across diverse transformer architectures and remains effective across both lightweight and larger-scale models. A comprehensive evaluation on the Cityscapes and BDD100k datasets shows substantial improvements of 9.20 percentage points in temporal consistency metrics and up to 1.76 percentage points in mean intersection over union compared to single-frame baselines. These results demonstrate STA as an effective architectural enhancement for video-based semantic segmentation applications.",
      "authors": [
        "Serin Varghese",
        "Kevin Ross",
        "Fabian Hueger",
        "Kira Maag"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 18:18:37+00:00",
      "link": "https://arxiv.org/pdf/2602.10052v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10044v1",
      "title": "Optimistic World Models: Efficient Exploration in Model-Based Deep Reinforcement Learning",
      "abstract": "Efficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments. We introduce Optimistic World Models (OWMs), a principled and scalable framework for optimistic exploration that brings classical reward-biased maximum likelihood estimation (RBMLE) from adaptive control into deep RL. In contrast to upper confidence bound (UCB)-style exploration methods, OWMs incorporate optimism directly into model learning by augmentation with an optimistic dynamics loss that biases imagined transitions toward higher-reward outcomes. This fully gradient-based loss requires neither uncertainty estimates nor constrained optimization. Our approach is plug-and-play with existing world model frameworks, preserving scalability while requiring only minimal modifications to standard training procedures. We instantiate OWMs within two state-of-the-art world model architectures, leading to Optimistic DreamerV3 and Optimistic STORM, which demonstrate significant improvements in sample efficiency and cumulative return compared to their baseline counterparts.",
      "authors": [
        "Akshay Mete",
        "Shahid Aamir Sheikh",
        "Tzu-Hsiang Lin",
        "Dileep Kalathil",
        "P. R. Kumar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "published": "2026-02-10 18:11:00+00:00",
      "link": "https://arxiv.org/pdf/2602.10044v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10031v1",
      "title": "Position: Message-passing and spectral GNNs are two sides of the same coin",
      "abstract": "Graph neural networks (GNNs) are commonly divided into message-passing neural networks (MPNNs) and spectral graph neural networks, reflecting two largely separate research traditions in machine learning and signal processing. This paper argues that this divide is mostly artificial, hindering progress in the field. We propose a viewpoint in which both MPNNs and spectral GNNs are understood as different parametrizations of permutation-equivariant operators acting on graph signals. From this perspective, many popular architectures are equivalent in expressive power, while genuine gaps arise only in specific regimes. We further argue that MPNNs and spectral GNNs offer complementary strengths. That is, MPNNs provide a natural language for discrete structure and expressivity analysis using tools from logic and graph isomorphism research, while the spectral perspective provides principled tools for understanding smoothing, bottlenecks, stability, and community structure. Overall, we posit that progress in graph learning will be accelerated by clearly understanding the key similarities and differences between these two types of GNNs, and by working towards unifying these perspectives within a common theoretical and conceptual framework rather than treating them as competing paradigms.",
      "authors": [
        "Antonis Vasileiou",
        "Juan Cervino",
        "Pascal Frossard",
        "Charilaos I. Kanatsoulis",
        "Christopher Morris",
        "Michael T. Schaub",
        "Pierre Vandergheynst",
        "Zhiyang Wang",
        "Guy Wolf",
        "Ron Levie"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 17:53:40+00:00",
      "link": "https://arxiv.org/pdf/2602.10031v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10019v1",
      "title": "ADORA: Training Reasoning Models with Dynamic Advantage Estimation on Reinforcement Learning",
      "abstract": "Reinforcement learning has become a cornerstone technique for developing reasoning models in complex tasks, ranging from mathematical problem-solving to imaginary reasoning. The optimization of these models typically relies on policy gradient methods, whose efficacy hinges on the accurate estimation of an advantage function. However, prevailing methods typically employ static advantage estimation, a practice that leads to inefficient credit assignment by neglecting the dynamic utility of training samples over time. This limitation results in suboptimal policy updates, which in turn manifest as slower convergence rates and increased learning instability, as models fail to adapt to evolving sample utilities effectively. To address this problem, we introduce \\textbf{ADORA} (\\textbf{A}dvantage \\textbf{D}ynamics via \\textbf{O}nline \\textbf{R}ollout \\textbf{A}daptation), a novel framework for policy optimization. ADORA dynamically adjusts the advantage function's weighting by adaptively categorizing training data into temporarily advantageous and disadvantageous samples, based on their evolving utility during online model rollouts. This tailored data differentiation strategy allows ADORA to be seamlessly integrated into existing policy optimization algorithms without significant architectural modifications, enabling the policy to prioritize learning from more informative experiences and thereby achieve more efficient policy updates. Extensive evaluations across diverse model families and varying data scales demonstrate that ADORA is a robust and efficient framework. It significantly enhances long reasoning in both geometric and mathematical tasks, consistently achieving notable performance gains without requiring sensitive hyperparameter tuning.",
      "authors": [
        "Qingnan Ren",
        "Shiting Huang",
        "Zhen Fang",
        "Zehui Chen",
        "Lin Chen",
        "Lijun Li",
        "Feng Zhao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-10 17:40:39+00:00",
      "link": "https://arxiv.org/pdf/2602.10019v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10016v2",
      "title": "Kunlun: Establishing Scaling Laws for Massive-Scale Recommendation Systems through Unified Architecture Design",
      "abstract": "Deriving predictable scaling laws that govern the relationship between model performance and computational investment is crucial for designing and allocating resources in massive-scale recommendation systems. While such laws are established for large language models, they remain challenging for recommendation systems, especially those processing both user history and context features. We identify poor scaling efficiency as the main barrier to predictable power-law scaling, stemming from inefficient modules with low Model FLOPs Utilization (MFU) and suboptimal resource allocation. We introduce Kunlun, a scalable architecture that systematically improves model efficiency and resource allocation. Our low-level optimizations include Generalized Dot-Product Attention (GDPA), Hierarchical Seed Pooling (HSP), and Sliding Window Attention. Our high-level innovations feature Computation Skip (CompSkip) and Event-level Personalization. These advances increase MFU from 17% to 37% on NVIDIA B200 GPUs and double scaling efficiency over state-of-the-art methods. Kunlun is now deployed in major Meta Ads models, delivering significant production impact.",
      "authors": [
        "Bojian Hou",
        "Xiaolong Liu",
        "Xiaoyi Liu",
        "Jiaqi Xu",
        "Yasmine Badr",
        "Mengyue Hang",
        "Sudhanshu Chanpuriya",
        "Junqing Zhou",
        "Yuhang Yang",
        "Han Xu",
        "Qiuling Suo",
        "Laming Chen",
        "Yuxi Hu",
        "Jiasheng Zhang",
        "Huaqing Xiong",
        "Yuzhen Huang",
        "Chao Chen",
        "Yue Dong",
        "Yi Yang",
        "Shuo Chang",
        "Xiaorui Gan",
        "Wenlin Chen",
        "Santanu Kolay",
        "Darren Liu",
        "Jade Nie",
        "Chunzhi Yang",
        "Ellie Wen",
        "Jiyan Yang",
        "Huayu Li"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-02-10 17:37:55+00:00",
      "link": "https://arxiv.org/pdf/2602.10016v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10009v1",
      "title": "Discovering High Level Patterns from Simulation Traces",
      "abstract": "Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with tasks involving physics. The LM's capability for physical reasoning is learned from observational data, rather than being grounded in simulation. A common approach is to include simulation traces as context, but this suffers from poor scalability as simulation traces contain larger volumes of fine-grained numerical and semantic data. In this paper, we propose a natural language guided method to discover coarse-grained patterns (e.g., 'rigid-body collision', 'stable support', etc.) from detailed simulation logs. Specifically, we synthesize programs that operate on simulation logs and map them to a series of high level activated patterns. We show, through two physics benchmarks, that this annotated representation of the simulation log is more amenable to natural language reasoning about physical systems. We demonstrate how this method enables LMs to generate effective reward programs from goals specified in natural language, which may be used within the context of planning or supervised learning.",
      "authors": [
        "Sean Memery",
        "Kartic Subr"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "published": "2026-02-10 17:31:39+00:00",
      "link": "https://arxiv.org/pdf/2602.10009v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10006v1",
      "title": "Answer First, Reason Later: Aligning Search Relevance via Mode-Balanced Reinforcement Learning",
      "abstract": "Building a search relevance model that achieves both low latency and high performance is a long-standing challenge in the search industry. To satisfy the millisecond-level response requirements of online systems while retaining the interpretable reasoning traces of Large Language Models (LLMs), we propose a novel \\textbf{Answer-First, Reason Later (AFRL)} paradigm. This paradigm requires the model to output the definitive relevance score in the very first token, followed by a structured logical explanation. Inspired by the success of reasoning models, we adopt a \"Supervised Fine-Tuning (SFT) + Reinforcement Learning (RL)\" pipeline to achieve AFRL. However, directly applying existing RL training often leads to \\textbf{mode collapse} in the search relevance task, where the model forgets complex long-tail rules in pursuit of high rewards. From an information theory perspective: RL inherently minimizes the \\textbf{Reverse KL divergence}, which tends to seek probability peaks (mode-seeking) and is prone to \"reward hacking.\" On the other hand, SFT minimizes the \\textbf{Forward KL divergence}, forcing the model to cover the data distribution (mode-covering) and effectively anchoring expert rules. Based on this insight, we propose a \\textbf{Mode-Balanced Optimization} strategy, incorporating an SFT auxiliary loss into Stepwise-GRPO training to balance these two properties. Furthermore, we construct an automated instruction evolution system and a multi-stage curriculum to ensure expert-level data quality. Extensive experiments demonstrate that our 32B teacher model achieves state-of-the-art performance. Moreover, the AFRL architecture enables efficient knowledge distillation, successfully transferring expert-level logic to a 0.6B model, thereby reconciling reasoning depth with deployment latency.",
      "authors": [
        "Shijie Zhang",
        "Xiang Guo",
        "Rujun Guo",
        "Shaoyu Liu",
        "Xiaozhao Wang",
        "Guanjun Jiang",
        "Kevin Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 17:28:12+00:00",
      "link": "https://arxiv.org/pdf/2602.10006v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09999v1",
      "title": "Faster-GS: Analyzing and Improving Gaussian Splatting Optimization",
      "abstract": "Recent advances in 3D Gaussian Splatting (3DGS) have focused on accelerating optimization while preserving reconstruction quality. However, many proposed methods entangle implementation-level improvements with fundamental algorithmic modifications or trade performance for fidelity, leading to a fragmented research landscape that complicates fair comparison. In this work, we consolidate and evaluate the most effective and broadly applicable strategies from prior 3DGS research and augment them with several novel optimizations. We further investigate underexplored aspects of the framework, including numerical stability, Gaussian truncation, and gradient approximation. The resulting system, Faster-GS, provides a rigorously optimized algorithm that we evaluate across a comprehensive suite of benchmarks. Our experiments demonstrate that Faster-GS achieves up to 5$\\times$ faster training while maintaining visual quality, establishing a new cost-effective and resource efficient baseline for 3DGS optimization. Furthermore, we demonstrate that optimizations can be applied to 4D Gaussian reconstruction, leading to efficient non-rigid scene optimization.",
      "authors": [
        "Florian Hahlbohm",
        "Linus Franke",
        "Martin Eisemann",
        "Marcus Magnor"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.GR"
      ],
      "published": "2026-02-10 17:22:59+00:00",
      "link": "https://arxiv.org/pdf/2602.09999v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09994v1",
      "title": "ORCHID: Fairness-Aware Orchestration in Mission-Critical Air-Ground Integrated Networks",
      "abstract": "In the era of 6G Air-Ground Integrated Networks (AGINs), Unmanned Aerial Vehicles (UAVs) are pivotal for providing on-demand wireless coverage in mission-critical environments, such as post-disaster rescue operations. However, traditional Deep Reinforcement Learning (DRL) approaches for multi-UAV orchestration often face critical challenges: instability due to the non-stationarity of multi-agent environments and the difficulty of balancing energy efficiency with service equity. To address these issues, this paper proposes ORCHID (Orchestration of Resilient Coverage via Hybrid Intelligent Deployment), a novel stability-enhanced two-stage learning framework. First, ORCHID leverages a GBS-aware topology partitioning strategy to mitigate the exploration cold-start problem. Second, we introduce a Reset-and-Finetune (R\\&F) mechanism within the MAPPO architecture that stabilizes the learning process via synchronized learning rate decay and optimizer state resetting. This mechanism effectively suppresses gradient variance to prevent policy degradation, thereby ensuring algorithmic resilience in dynamic environments. Furthermore, we uncover a counter-intuitive efficiency-fairness synergy: contrary to the conventional trade-off, our results demonstrate that the proposed Max-Min Fairness (MMF) design not only guarantees service for cell-edge users but also achieves superior energy efficiency compared to Proportional Fairness (PF), which tends to converge to suboptimal greedy equilibria. Extensive experiments confirm that ORCHID occupies a superior Pareto-dominant position compared to state-of-the-art baselines, ensuring robust convergence and resilient connectivity in mission-critical scenarios.",
      "authors": [
        "Chuan-Chi Lai",
        "Chi Jai Choy"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-02-10 17:18:56+00:00",
      "link": "https://arxiv.org/pdf/2602.09994v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09992v1",
      "title": "A Unified Assessment of the Poverty of the Stimulus Argument for Neural Language Models",
      "abstract": "How can children acquire native-level syntax from limited input? According to the Poverty of the Stimulus Hypothesis (PoSH), the linguistic input children receive is insufficient to explain certain generalizations that are robustly learned; innate linguistic constraints, many have argued, are thus necessary to explain language learning. Neural language models, which lack such language-specific constraints in their design, offer a computational test of this longstanding (but controversial) claim. We introduce \\poshbench, a training-and-evaluation suite targeting question formation, islands to movement, and other English phenomena at the center of the PoSH arguments. Training Transformer models on 10--50M words of developmentally plausible text, we find indications of generalization on all phenomena even without direct positive evidence -- yet neural models remain less data-efficient and their generalizations are weaker than those of children. We further enhance our models with three recently proposed cognitively motivated inductive biases. We find these biases improve general syntactic competence but not \\poshbench performance. Our findings challenge the claim that innate syntax is the only possible route to generalization, while suggesting that human-like data efficiency requires inductive biases beyond those tested here.",
      "authors": [
        "Xiulin Yang",
        "Arianna Bisazza",
        "Nathan Schneider",
        "Ethan Gotlieb Wilcox"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-10 17:16:29+00:00",
      "link": "https://arxiv.org/pdf/2602.09992v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09988v1",
      "title": "Empirical Stability Analysis of Kolmogorov-Arnold Networks in Hard-Constrained Recurrent Physics-Informed Discovery",
      "abstract": "We investigate the integration of Kolmogorov-Arnold Networks (KANs) into hard-constrained recurrent physics-informed architectures (HRPINN) to evaluate the fidelity of learned residual manifolds in oscillatory systems. Motivated by the Kolmogorov-Arnold representation theorem and preliminary gray-box results, we hypothesized that KANs would enable efficient recovery of unknown terms compared to MLPs. Through initial sensitivity analysis on configuration sensitivity, parameter scale, and training paradigm, we found that while small KANs are competitive on univariate polynomial residuals (Duffing), they exhibit severe hyperparameter fragility, instability in deeper configurations, and consistent failure on multiplicative terms (Van der Pol), generally outperformed by standard MLPs. These empirical challenges highlight limitations of the additive inductive bias in the original KAN formulation for state coupling and provide preliminary empirical evidence of inductive bias limitations for future hybrid modeling.",
      "authors": [
        "Enzo Nicolas Spotorno",
        "Josafat Leal Filho",
        "Antonio Augusto Medeiros Frohlich"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "published": "2026-02-10 17:13:51+00:00",
      "link": "https://arxiv.org/pdf/2602.09988v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09980v1",
      "title": "Supervised Metric Regularization Through Alternating Optimization for Multi-Regime Physics-Informed Neural Networks",
      "abstract": "Standard Physics-Informed Neural Networks (PINNs) often face challenges when modeling parameterized dynamical systems with sharp regime transitions, such as bifurcations. In these scenarios, the continuous mapping from parameters to solutions can result in spectral bias or \"mode collapse\", where the network averages distinct physical behaviors. We propose a Topology-Aware PINN (TAPINN) that aims to mitigate this challenge by structuring the latent space via Supervised Metric Regularization. Unlike standard parametric PINNs that map physical parameters directly to solutions, our method conditions the solver on a latent state optimized to reflect the metric-based separation between regimes, showing ~49% lower physics residual (0.082 vs. 0.160). We train this architecture using a phase-based Alternating Optimization (AO) schedule to manage gradient conflicts between the metric and physics objectives. Preliminary experiments on the Duffing Oscillator demonstrate that while standard baselines suffer from spectral bias and high-capacity Hypernetworks overfit (memorizing data while violating physics), our approach achieves stable convergence with 2.18x lower gradient variance than a multi-output Sobolev Error baseline, and 5x fewer parameters than a hypernetwork-based alternative.",
      "authors": [
        "Enzo Nicolas Spotorno",
        "Josafat Ribeiro Leal",
        "Antonio Augusto Frohlich"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "published": "2026-02-10 17:06:57+00:00",
      "link": "https://arxiv.org/pdf/2602.09980v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09972v1",
      "title": "Hydra-Nav: Object Navigation via Adaptive Dual-Process Reasoning",
      "abstract": "While large vision-language models (VLMs) show promise for object goal navigation, current methods still struggle with low success rates and inefficient localization of unseen objects--failures primarily attributed to weak temporal-spatial reasoning. Meanwhile, recent attempts to inject reasoning into VLM-based agents improve success rates but incur substantial computational overhead. To address both the ineffectiveness and inefficiency of existing approaches, we introduce Hydra-Nav, a unified VLM architecture that adaptively switches between a deliberative slow system for analyzing exploration history and formulating high-level plans, and a reactive fast system for efficient execution. We train Hydra-Nav through a three-stage curriculum: (i) spatial-action alignment to strengthen trajectory planning, (ii) memory-reasoning integration to enhance temporal-spatial reasoning over long-horizon exploration, and (iii) iterative rejection fine-tuning to enable selective reasoning at critical decision points. Extensive experiments demonstrate that Hydra-Nav achieves state-of-the-art performance on the HM3D, MP3D, and OVON benchmarks, outperforming the second-best methods by 11.1%, 17.4%, and 21.2%, respectively. Furthermore, we introduce SOT (Success weighted by Operation Time), a new metric to measure search efficiency across VLMs with varying reasoning intensity. Results show that adaptive reasoning significantly enhances search efficiency over fixed-frequency baselines.",
      "authors": [
        "Zixuan Wang",
        "Huang Fang",
        "Shaoan Wang",
        "Yuanfei Luo",
        "Heng Dong",
        "Wei Li",
        "Yiming Gan"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-10 17:00:16+00:00",
      "link": "https://arxiv.org/pdf/2602.09972v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09971v1",
      "title": "SCOPE: A Training-Free Online 3D Deployment for UAV-BSs with Theoretical Analysis and Comparative Study",
      "abstract": "Unmanned Aerial Vehicle (UAV)-mounted Base Stations (UAV-BSs) offer a flexible solution for serving ground users in temporary hotspot scenarios. However, efficiently deploying UAV-BSs to satisfy heterogeneous user distributions remains a challenging optimization problem. While recent data-driven approaches, particularly Deep Reinforcement Learning (DRL), have shown promise in dynamic environments, they often suffer from prohibitive training overhead, poor generalization to topology changes, and high computational complexity. To address these limitations, this paper proposes Satisfaction-driven Coverage Optimization via Perimeter Extraction (SCOPE), a training-free and online 3D deployment framework. Unlike heuristic baselines that rely on fixed-altitude assumptions, SCOPE integrates a perimeter extraction mechanism with the Smallest Enclosing Circle (SEC) algorithm to dynamically optimize 3D UAV positions. Theoretically, we provide a rigorous convergence proof of the proposed algorithm and derive its polynomial time complexity of $O(N^2 \\log N)$. Experimentally, we conduct a comprehensive comparative study against state-of-the-art DRL baselines (e.g., PPO). Simulation results demonstrate that SCOPE achieves comparable user satisfaction to DRL methods but significantly lower computational latency (milliseconds vs. hours of training) and superior energy efficiency, making it an ideal solution for real-time, on-demand emergency deployment.",
      "authors": [
        "Chuan-Chi Lai"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-02-10 16:59:20+00:00",
      "link": "https://arxiv.org/pdf/2602.09971v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09969v1",
      "title": "Causal Identification in Multi-Task Demand Learning with Confounding",
      "abstract": "We study a canonical multi-task demand learning problem motivated by retail pricing, in which a firm seeks to estimate heterogeneous linear price-response functions across a large collection of decision contexts. Each context is characterized by rich observable covariates yet typically exhibits only limited historical price variation, motivating the use of multi-task learning to borrow strength across tasks. A central challenge in this setting is endogeneity: historical prices are chosen by managers or algorithms and may be arbitrarily correlated with unobserved, task-level demand determinants. Under such confounding by latent fundamentals, commonly used approaches, such as pooled regression and meta-learning, fail to identify causal price effects.   We propose a new estimation framework that achieves causal identification despite arbitrary dependence between prices and latent task structure. Our approach, Decision-Conditioned Masked-Outcome Meta-Learning (DCMOML), involves carefully designing the information set of a meta-learner to leverage cross-task heterogeneity while accounting for endogenous decision histories. Under a mild restriction on price adaptivity in each task, we establish that this method identifies the conditional mean of the task-specific causal parameters given the designed information set. Our results provide guarantees for large-scale demand estimation with endogenous prices and small per-task samples, offering a principled foundation for deploying causal, data-driven pricing models in operational environments.",
      "authors": [
        "Varun Gupta",
        "Vijay Kamble"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "econ.EM",
        "stat.ML"
      ],
      "published": "2026-02-10 16:58:50+00:00",
      "link": "https://arxiv.org/pdf/2602.09969v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09963v1",
      "title": "Drug Release Modeling using Physics-Informed Neural Networks",
      "abstract": "Accurate modeling of drug release is essential for designing and developing controlled-release systems. Classical models (Fick, Higuchi, Peppas) rely on simplifying assumptions that limit their accuracy in complex geometries and release mechanisms. Here, we propose a novel approach using Physics-Informed Neural Networks (PINNs) and Bayesian PINNs (BPINNs) for predicting release from planar, 1D-wrinkled, and 2D-crumpled films. This approach uniquely integrates Fick's diffusion law with limited experimental data to enable accurate long-term predictions from short-term measurements, and is systematically benchmarked against classical drug release models. We embedded Fick's second law into PINN as loss with 10,000 Latin-hypercube collocation points and utilized previously published experimental datasets to assess drug release performance through mean absolute error (MAE) and root mean square error (RMSE), considering noisy conditions and limited-data scenarios. Our approach reduced mean error by up to 40% relative to classical baselines across all film types. The PINN formulation achieved RMSE <0.05 utilizing only the first 6% of the release time data (reducing 94% of release time required for the experiments) for the planar film. For wrinkled and crumpled films, the PINN reached RMSE <0.05 in 33% of the release time data. BPINNs provide tighter and more reliable uncertainty quantification under noise. By combining physical laws with experimental data, the proposed framework yields highly accurate long-term release predictions from short-term measurements, offering a practical route for accelerated characterization and more efficient early-stage drug release system formulation.",
      "authors": [
        "Daanish Aleem Qureshi",
        "Khemraj Shukla",
        "Vikas Srivastava"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "published": "2026-02-10 16:51:50+00:00",
      "link": "https://arxiv.org/pdf/2602.09963v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09949v1",
      "title": "Bladder Vessel Segmentation using a Hybrid Attention-Convolution Framework",
      "abstract": "Urinary bladder cancer surveillance requires tracking tumor sites across repeated interventions, yet the deformable and hollow bladder lacks stable landmarks for orientation. While blood vessels visible during endoscopy offer a patient-specific \"vascular fingerprint\" for navigation, automated segmentation is challenged by imperfect endoscopic data, including sparse labels, artifacts like bubbles or variable lighting, continuous deformation, and mucosal folds that mimic vessels. State-of-the-art vessel segmentation methods often fail to address these domain-specific complexities. We introduce a Hybrid Attention-Convolution (HAC) architecture that combines Transformers to capture global vessel topology prior with a CNN that learns a residual refinement map to precisely recover thin-vessel details. To prioritize structural connectivity, the Transformer is trained on optimized ground truth data that exclude short and terminal branches. Furthermore, to address data scarcity, we employ a physics-aware pretraining, that is a self-supervised strategy using clinically grounded augmentations on unlabeled data. Evaluated on the BlaVeS dataset, consisting of endoscopic video frames, our approach achieves high accuracy (0.94) and superior precision (0.61) and clDice (0.66) compared to state-of-the-art medical segmentation models. Crucially, our method successfully suppresses false positives from mucosal folds that dynamically appear and vanish as the bladder fills and empties during surgery. Hence, HAC provides the reliable structural stability required for clinical navigation.",
      "authors": [
        "Franziska Krauß",
        "Matthias Ege",
        "Zoltan Lovasz",
        "Albrecht Bartz-Schmidt",
        "Igor Tsaur",
        "Oliver Sawodny",
        "Carina Veil"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-10 16:34:17+00:00",
      "link": "https://arxiv.org/pdf/2602.09949v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09947v1",
      "title": "Trustworthy Agentic AI Requires Deterministic Architectural Boundaries",
      "abstract": "Current agentic AI architectures are fundamentally incompatible with the security and epistemological requirements of high-stakes scientific workflows. The problem is not inadequate alignment or insufficient guardrails, it is architectural: autoregressive language models process all tokens uniformly, making deterministic command--data separation unattainable through training alone. We argue that deterministic, architectural enforcement, not probabilistic learned behavior, is a necessary condition for trustworthy AI-assisted science. We introduce the Trinity Defense Architecture, which enforces security through three mechanisms: action governance via a finite action calculus with reference-monitor enforcement, information-flow control via mandatory access labels preventing cross-scope leakage, and privilege separation isolating perception from execution. We show that without unforgeable provenance and deterministic mediation, the ``Lethal Trifecta'' (untrusted inputs, privileged data access, external action capability) turns authorization security into an exploit-discovery problem: training-based defenses may reduce empirical attack rates but cannot provide deterministic guarantees. The ML community must recognize that alignment is insufficient for authorization security, and that architectural mediation is required before agentic AI can be safely deployed in consequential scientific domains.",
      "authors": [
        "Manish Bhattarai",
        "Minh Vu"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-10 16:33:40+00:00",
      "link": "https://arxiv.org/pdf/2602.09947v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10173v1",
      "title": "ArtisanGS: Interactive Tools for Gaussian Splat Selection with AI and Human in the Loop",
      "abstract": "Representation in the family of 3D Gaussian Splats (3DGS) are growing into a viable alternative to traditional graphics for an expanding number of application, including recent techniques that facilitate physics simulation and animation. However, extracting usable objects from in-the-wild captures remains challenging and controllable editing techniques for this representation are limited. Unlike the bulk of emerging techniques, focused on automatic solutions or high-level editing, we introduce an interactive suite of tools centered around versatile Gaussian Splat selection and segmentation. We propose a fast AI-driven method to propagate user-guided 2D selection masks to 3DGS selections. This technique allows for user intervention in the case of errors and is further coupled with flexible manual selection and segmentation tools. These allow a user to achieve virtually any binary segmentation of an unstructured 3DGS scene. We evaluate our toolset against the state-of-the-art for Gaussian Splat selection and demonstrate their utility for downstream applications by developing a user-guided local editing approach, leveraging a custom Video Diffusion Model. With flexible selection tools, users have direct control over the areas that the AI can modify. Our selection and editing tools can be used for any in-the-wild capture without additional optimization.",
      "authors": [
        "Clement Fuji Tsang",
        "Anita Hu",
        "Or Perel",
        "Carsten Kolve",
        "Maria Shugrina"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 16:00:03+00:00",
      "link": "https://arxiv.org/pdf/2602.10173v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09927v1",
      "title": "A benchmark for video-based laparoscopic skill analysis and assessment",
      "abstract": "Laparoscopic surgery is a complex surgical technique that requires extensive training. Recent advances in deep learning have shown promise in supporting this training by enabling automatic video-based assessment of surgical skills. However, the development and evaluation of deep learning models is currently hindered by the limited size of available annotated datasets. To address this gap, we introduce the Laparoscopic Skill Analysis and Assessment (LASANA) dataset, comprising 1270 stereo video recordings of four basic laparoscopic training tasks. Each recording is annotated with a structured skill rating, aggregated from three independent raters, as well as binary labels indicating the presence or absence of task-specific errors. The majority of recordings originate from a laparoscopic training course, thereby reflecting a natural variation in the skill of participants. To facilitate benchmarking of both existing and novel approaches for video-based skill assessment and error recognition, we provide predefined data splits for each task. Furthermore, we present baseline results from a deep learning model as a reference point for future comparisons.",
      "authors": [
        "Isabel Funke",
        "Sebastian Bodenstedt",
        "Felix von Bechtolsheim",
        "Florian Oehme",
        "Michael Maruschke",
        "Stefanie Herrlich",
        "Jürgen Weitz",
        "Marius Distler",
        "Sören Torge Mees",
        "Stefanie Speidel"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 15:59:19+00:00",
      "link": "https://arxiv.org/pdf/2602.09927v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10172v1",
      "title": "Cosmo3DFlow: Wavelet Flow Matching for Spatial-to-Spectral Compression in Reconstructing the Early Universe",
      "abstract": "Reconstructing the early Universe from the evolved present-day Universe is a challenging and computationally demanding problem in modern astrophysics. We devise a novel generative framework, Cosmo3DFlow, designed to address dimensionality and sparsity, the critical bottlenecks inherent in current state-of-the-art methods for cosmological inference. By integrating 3D Discrete Wavelet Transform (DWT) with flow matching, we effectively represent high-dimensional cosmological structures. The Wavelet Transform addresses the ``void problem'' by translating spatial emptiness into spectral sparsity. It decouples high-frequency details from low-frequency structures through spatial compression, and wavelet-space velocity fields facilitate stable ordinary differential equation (ODE) solvers with large step sizes. Using large-scale cosmological $N$-body simulations, at $128^3$ resolution, we achieve up to $50\\times$ faster sampling than diffusion models, combining a $10\\times$ reduction in integration steps with lower per-step computational cost from wavelet compression. Our results enable initial conditions to be sampled in seconds, compared to minutes for previous methods.",
      "authors": [
        "Md. Khairul Islam",
        "Zeyu Xia",
        "Ryan Goudjil",
        "Jialu Wang",
        "Arya Farahi",
        "Judy Fox"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "published": "2026-02-10 15:47:18+00:00",
      "link": "https://arxiv.org/pdf/2602.10172v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09914v1",
      "title": "AmharicIR+Instr: A Two-Dataset Resource for Neural Retrieval and Instruction Tuning",
      "abstract": "Neural retrieval and GPT-style generative models rely on large, high-quality supervised data, which is still scarce for low-resource languages such as Amharic. We release an Amharic data resource consisting of two datasets that supports research on (i) neural retrieval-ranking and (ii) instruction-following text generation. The retrieval-ranking dataset contains 1,091 manually verified query-positive-negative document triplets drawn from diverse Amharic sources and constructed to support contrastive training and benchmarking of neural retrievers (e.g., DPR, ColBERT-style late interaction and SPLADE-style sparse neural retrieval). Triplets are created through a combination of expert-curated queries, web-derived queries, and LLM-assisted generation, with positive/negative documents selected from the web or synthesized by LLMs and then validated by native speakers. The instruction prompt-response dataset comprises 6,285 Amharic prompt-response pairs spanning multiple domains and instruction types, generated with several LLMs and refined through manual review and correction for grammaticality, relevance, fluency, and factual plausibility. We release both datasets with standardized splits and formats (CSV,JSON,JSONL) to enable reproducible work on Amharic retrieval, ranking, and generative modelling. These datasets also come with a methodology that can be generalized to other low-resource languages.",
      "authors": [
        "Tilahun Yeshambel",
        "Moncef Garouani",
        "Josiane Mothe"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-02-10 15:45:20+00:00",
      "link": "https://arxiv.org/pdf/2602.09914v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09909v1",
      "title": "Tucker iterative quantum state preparation",
      "abstract": "Quantum state preparation is a fundamental component of quantum algorithms, particularly in quantum machine learning and data processing, where classical data must be encoded efficiently into quantum states. Existing amplitude encoding techniques often rely on recursive bipartitions or tensor decompositions, which either lead to deep circuits or lack practical guidance for circuit construction. In this work, we introduce Tucker Iterative Quantum State Preparation (Q-Tucker), a novel method that adaptively constructs shallow, deterministic quantum circuits by exploiting the global entanglement structure of target states. Building upon the Tucker decomposition, our method factors the target quantum state into a core tensor and mode-specific operators, enabling direct decompositions across multiple subsystems.",
      "authors": [
        "Carsten Blank",
        "Israel F. Araujo"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.ET"
      ],
      "published": "2026-02-10 15:41:32+00:00",
      "link": "https://arxiv.org/pdf/2602.09909v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09905v1",
      "title": "The Need for Standardized Evidence Sampling in CMMC Assessments: A Survey-Based Analysis of Assessor Practices",
      "abstract": "The Cybersecurity Maturity Model Certification (CMMC) framework provides a common standard for protecting sensitive unclassified information in defense contracting. While CMMC defines assessment objectives and control requirements, limited formal guidance exists regarding evidence sampling, the process by which assessors select, review, and validate artifacts to substantiate compliance. Analyzing data collected through an anonymous survey of CMMC-certified assessors and lead assessors, this exploratory study investigates whether inconsistencies in evidence sampling practices exist within the CMMC assessment ecosystem and evaluates the need for a risk-informed standardized sampling methodology. Across 17 usable survey responses, results indicate that evidence sampling practices are predominantly driven by assessor judgment, perceived risk, and environmental complexity rather than formalized standards, with formal statistical sampling models rarely referenced. Participants frequently reported inconsistencies across assessments and expressed broad support for the development of standardized guidance, while generally opposing rigid percentage-based requirements. The findings support the conclusion that the absence of a uniform evidence sampling framework introduces variability that may affect assessment reliability and confidence in certification outcomes. Recommendations are provided to inform future CMMC assessment methodology development and further empirical research.",
      "authors": [
        "Logan Therrien",
        "John Hastings"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-10 15:40:44+00:00",
      "link": "https://arxiv.org/pdf/2602.09905v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09883v1",
      "title": "AdaTSQ: Pushing the Pareto Frontier of Diffusion Transformers via Temporal-Sensitivity Quantization",
      "abstract": "Diffusion Transformers (DiTs) have emerged as the state-of-the-art backbone for high-fidelity image and video generation. However, their massive computational cost and memory footprint hinder deployment on edge devices. While post-training quantization (PTQ) has proven effective for large language models (LLMs), directly applying existing methods to DiTs yields suboptimal results due to the neglect of the unique temporal dynamics inherent in diffusion processes. In this paper, we propose AdaTSQ, a novel PTQ framework that pushes the Pareto frontier of efficiency and quality by exploiting the temporal sensitivity of DiTs. First, we propose a Pareto-aware timestep-dynamic bit-width allocation strategy. We model the quantization policy search as a constrained pathfinding problem. We utilize a beam search algorithm guided by end-to-end reconstruction error to dynamically assign layer-wise bit-widths across different timesteps. Second, we propose a Fisher-guided temporal calibration mechanism. It leverages temporal Fisher information to prioritize calibration data from highly sensitive timesteps, seamlessly integrating with Hessian-based weight optimization. Extensive experiments on four advanced DiTs (e.g., Flux-Dev, Flux-Schnell, Z-Image, and Wan2.1) demonstrate that AdaTSQ significantly outperforms state-of-the-art methods like SVDQuant and ViDiT-Q. Our code will be released at https://github.com/Qiushao-E/AdaTSQ.",
      "authors": [
        "Shaoqiu Zhang",
        "Zizhong Ding",
        "Kaicheng Yang",
        "Junyi Wu",
        "Xianglong Yan",
        "Xi Li",
        "Bingnan Duan",
        "Jianping Fang",
        "Yulun Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 15:23:18+00:00",
      "link": "https://arxiv.org/pdf/2602.09883v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09869v1",
      "title": "Statistical benchmarking of transformer models in low signal-to-noise time-series forecasting",
      "abstract": "We study the performance of transformer architectures for multivariate time-series forecasting in low-data regimes consisting of only a few years of daily observations. Using synthetically generated processes with known temporal and cross-sectional dependency structures and varying signal-to-noise ratios, we conduct bootstrapped experiments that enable direct evaluation via out-of-sample correlations with the optimal ground-truth predictor. We show that two-way attention transformers, which alternate between temporal and cross-sectional self-attention, can outperform standard baselines-Lasso, boosting methods, and fully connected multilayer perceptrons-across a wide range of settings, including low signal-to-noise regimes. We further introduce a dynamic sparsification procedure for attention matrices applied during training, and demonstrate that it becomes significantly effective in noisy environments, where the correlation between the target variable and the optimal predictor is on the order of a few percent. Analysis of the learned attention patterns reveals interpretable structure and suggests connections to sparsity-inducing regularization in classical regression, providing insight into why these models generalize effectively under noise.",
      "authors": [
        "Cyril Garcia",
        "Guillaume Remy"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 15:13:57+00:00",
      "link": "https://arxiv.org/pdf/2602.09869v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09868v1",
      "title": "Free-GVC: Towards Training-Free Extreme Generative Video Compression with Temporal Coherence",
      "abstract": "Building on recent advances in video generation, generative video compression has emerged as a new paradigm for achieving visually pleasing reconstructions. However, existing methods exhibit limited exploitation of temporal correlations, causing noticeable flicker and degraded temporal coherence at ultra-low bitrates. In this paper, we propose Free-GVC, a training-free generative video compression framework that reformulates video coding as latent trajectory compression guided by a video diffusion prior. Our method operates at the group-of-pictures (GOP) level, encoding video segments into a compact latent space and progressively compressing them along the diffusion trajectory. To ensure perceptually consistent reconstruction across GOPs, we introduce an Adaptive Quality Control module that dynamically constructs an online rate-perception surrogate model to predict the optimal diffusion step for each GOP. In addition, an Inter-GOP Alignment module establishes frame overlap and performs latent fusion between adjacent groups, thereby mitigating flicker and enhancing temporal coherence. Experiments show that Free-GVC achieves an average of 93.29% BD-Rate reduction in DISTS over the latest neural codec DCVC-RT, and a user study further confirms its superior perceptual quality and temporal coherence at ultra-low bitrates.",
      "authors": [
        "Xiaoyue Ling",
        "Chuqin Zhou",
        "Chunyi Li",
        "Yunuo Chen",
        "Yuan Tian",
        "Guo Lu",
        "Wenjun Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 15:12:51+00:00",
      "link": "https://arxiv.org/pdf/2602.09868v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09848v1",
      "title": "Robust Processing and Learning: Principles, Methods, and Wireless Applications",
      "abstract": "This tutorial-style overview article examines the fundamental principles and methods of robustness, using wireless sensing and communication (WSC) as the narrative and exemplifying framework. First, we formalize the conceptual and mathematical foundations of robustness, highlighting the interpretations and relations across robust statistics, optimization, and machine learning. Key techniques, such as robust estimation and testing, distributionally robust optimization, and regularized and adversary training, are investigated. Together, the costs of robustness in system design, for example, the compromised nominal performances and the extra computational burdens, are discussed. Second, we review recent robust signal processing solutions for WSC that address model mismatch, data scarcity, adversarial perturbation, and distributional shift. Specific applications include robust ranging-based localization, modality sensing, channel estimation, receive combining, waveform design, and federated learning. Through this effort, we aim to introduce the classical developments and recent advances in robustness theory to the general signal processing community, exemplifying how robust statistical, optimization, and machine learning approaches can address the uncertainties inherent in WSC systems.",
      "authors": [
        "Shixiong Wang",
        "Wei Dai",
        "Li-Chun Wang",
        "Geoffrey Ye Li"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "cs.LG"
      ],
      "published": "2026-02-10 14:53:52+00:00",
      "link": "https://arxiv.org/pdf/2602.09848v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09843v3",
      "title": "Kelix Technical Report",
      "abstract": "Autoregressive large language models (LLMs) scale well by expressing diverse tasks as sequences of discrete natural-language tokens and training with next-token prediction, which unifies comprehension and generation under self-supervision. Extending this paradigm to multimodal data requires a shared, discrete representation across modalities. However, most vision-language models (VLMs) still rely on a hybrid interface: discrete text tokens paired with continuous Vision Transformer (ViT) features. Because supervision is largely text-driven, these models are often biased toward understanding and cannot fully leverage large-scale self-supervised learning on non-text data. Recent work has explored discrete visual tokenization to enable fully autoregressive multimodal modeling, showing promising progress toward unified understanding and generation. Yet existing discrete vision tokens frequently lose information due to limited code capacity, resulting in noticeably weaker understanding than continuous-feature VLMs. We present Kelix, a fully discrete autoregressive unified model that closes the understanding gap between discrete and continuous visual representations.",
      "authors": [
        "Boyang Ding",
        "Chenglong Chu",
        "Dunju Zang",
        "Han Li",
        "Jiangxia Cao",
        "Kun Gai",
        "Muhao Wei",
        "Ruiming Tang",
        "Shiyao Wang",
        "Siyang Mao",
        "Xinchen Luo",
        "Yahui Liu",
        "Zhixin Ling",
        "Zhuoran Yang",
        "Ziming Li",
        "Chengru Song",
        "Guorui Zhou",
        "Guowang Zhang",
        "Hao Peng",
        "Hao Wang",
        "Jiaxin Deng",
        "Jin Ouyang",
        "Jinghao Zhang",
        "Lejian Ren",
        "Qianqian Wang",
        "Qigen Hu",
        "Tao Wang",
        "Xingmei Wang",
        "Yiping Yang",
        "Zixing Zhang",
        "Ziqi Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 14:48:26+00:00",
      "link": "https://arxiv.org/pdf/2602.09843v3",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09817v1",
      "title": "AnalyticsGPT: An LLM Workflow for Scientometric Question Answering",
      "abstract": "This paper introduces AnalyticsGPT, an intuitive and efficient large language model (LLM)-powered workflow for scientometric question answering. This underrepresented downstream task addresses the subcategory of meta-scientific questions concerning the \"science of science.\" When compared to traditional scientific question answering based on papers, the task poses unique challenges in the planning phase. Namely, the need for named-entity recognition of academic entities within questions and multi-faceted data retrieval involving scientometric indices, e.g. impact factors. Beyond their exceptional capacity for treating traditional natural language processing tasks, LLMs have shown great potential in more complex applications, such as task decomposition and planning and reasoning. In this paper, we explore the application of LLMs to scientometric question answering, and describe an end-to-end system implementing a sequential workflow with retrieval-augmented generation and agentic concepts. We also address the secondary task of effectively synthesizing the data into presentable and well-structured high-level analyses. As a database for retrieval-augmented generation, we leverage a proprietary research performance assessment platform. For evaluation, we consult experienced subject matter experts and leverage LLMs-as-judges. In doing so, we provide valuable insights on the efficacy of LLMs towards a niche downstream task. Our (skeleton) code and prompts are available at: https://github.com/lyvykhang/llm-agents-scientometric-qa/tree/acl.",
      "authors": [
        "Khang Ly",
        "Georgios Cheirmpos",
        "Adrian Raudaschl",
        "Christopher James",
        "Seyed Amin Tabatabaei"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.DL"
      ],
      "published": "2026-02-10 14:23:55+00:00",
      "link": "https://arxiv.org/pdf/2602.09817v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09816v1",
      "title": "CompSplat: Compression-aware 3D Gaussian Splatting for Real-world Video",
      "abstract": "High-quality novel view synthesis (NVS) from real-world videos is crucial for applications such as cultural heritage preservation, digital twins, and immersive media. However, real-world videos typically contain long sequences with irregular camera trajectories and unknown poses, leading to pose drift, feature misalignment, and geometric distortion during reconstruction. Moreover, lossy compression amplifies these issues by introducing inconsistencies that gradually degrade geometry and rendering quality. While recent studies have addressed either long-sequence NVS or unposed reconstruction, compression-aware approaches still focus on specific artifacts or limited scenarios, leaving diverse compression patterns in long videos insufficiently explored. In this paper, we propose CompSplat, a compression-aware training framework that explicitly models frame-wise compression characteristics to mitigate inter-frame inconsistency and accumulated geometric errors. CompSplat incorporates compression-aware frame weighting and an adaptive pruning strategy to enhance robustness and geometric consistency, particularly under heavy compression. Extensive experiments on challenging benchmarks, including Tanks and Temples, Free, and Hike, demonstrate that CompSplat achieves state-of-the-art rendering quality and pose accuracy, significantly surpassing most recent state-of-the-art NVS approaches under severe compression conditions.",
      "authors": [
        "Hojun Song",
        "Heejung Choi",
        "Aro Kim",
        "Chae-yeong Song",
        "Gahyeon Kim",
        "Soo Ye Kim",
        "Jaehyup Lee",
        "Sang-hyo Park"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 14:23:42+00:00",
      "link": "https://arxiv.org/pdf/2602.09816v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09810v2",
      "title": "A Controlled Study of Double DQN and Dueling DQN Under Cross-Environment Transfer",
      "abstract": "Transfer learning in deep reinforcement learning is often motivated by improved stability and reduced training cost, but it can also fail under substantial domain shift. This paper presents a controlled empirical study examining how architectural differences between Double Deep Q-Networks (DDQN) and Dueling DQN influence transfer behavior across environments. Using CartPole as a source task and LunarLander as a structurally distinct target task, we evaluate a fixed layer-wise representation transfer protocol under identical hyperparameters and training conditions, with baseline agents trained from scratch used to contextualize transfer effects. Empirical results show that DDQN consistently avoids negative transfer under the examined setup and maintains learning dynamics comparable to baseline performance in the target environment. In contrast, Dueling DQN consistently exhibits negative transfer under identical conditions, characterized by degraded rewards and unstable optimization behavior. Statistical analysis across multiple random seeds confirms a significant performance gap under transfer. These findings suggest that architectural inductive bias is strongly associated with robustness to cross-environment transfer in value-based deep reinforcement learning under the examined transfer protocol.",
      "authors": [
        "Azkaa Nasir",
        "Fatima Dossa",
        "Muhammad Ahmed Atif",
        "Mohammad Shahid Shaikh"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-10 14:18:03+00:00",
      "link": "https://arxiv.org/pdf/2602.09810v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09809v1",
      "title": "SciFlow-Bench: Evaluating Structure-Aware Scientific Diagram Generation via Inverse Parsing",
      "abstract": "Scientific diagrams convey explicit structural information, yet modern text-to-image models often produce visually plausible but structurally incorrect results. Existing benchmarks either rely on image-centric or subjective metrics insensitive to structure, or evaluate intermediate symbolic representations rather than final rendered images, leaving pixel-based diagram generation underexplored. We introduce SciFlow-Bench, a structure-first benchmark for evaluating scientific diagram generation directly from pixel-level outputs. Built from real scientific PDFs, SciFlow-Bench pairs each source framework figure with a canonical ground-truth graph and evaluates models as black-box image generators under a closed-loop, round-trip protocol that inverse-parses generated diagram images back into structured graphs for comparison. This design enforces evaluation by structural recoverability rather than visual similarity alone, and is enabled by a hierarchical multi-agent system that coordinates planning, perception, and structural reasoning. Experiments show that preserving structural correctness remains a fundamental challenge, particularly for diagrams with complex topology, underscoring the need for structure-aware evaluation.",
      "authors": [
        "Tong Zhang",
        "Honglin Lin",
        "Zhou Liu",
        "Chong Chen",
        "Wentao Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 14:15:35+00:00",
      "link": "https://arxiv.org/pdf/2602.09809v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09801v1",
      "title": "Tiny Moves: Game-based Hypothesis Refinement",
      "abstract": "Most machine learning approaches to scientific discovery frame hypotheses as end-to-end predictions, obscuring the incremental structure of scientific reasoning. We propose The Hypothesis Game, a symbolic formalism for hypothesis refinement in which LLM agents operate on a shared hypothesis state using a fixed grammar of reasoning moves. The framework is motivated by the observation that scientific progress often proceeds through small, localized revisions, grounded in domain context, rather than extensive rewrites. We instantiate a minimal game with LLM agents and evaluate it on pathway-level mechanistic refinement tasks. In the primary setting of corruption recovery, where hypotheses contain controlled errors, the game-based approach consistently removes more errors and achieves higher precision than strong prompting baselines, while preserving valid structure through incremental edits. In a secondary reconstruction setting from partial cues, it performs comparably to the strongest baseline, indicating that explicit move-based refinement remains competitive even when ground-truth recovery is difficult. These findings support game-based reasoning as a principled route to more controllable, interpretable, and transferable hypothesis refinement systems for scientific discovery.",
      "authors": [
        "Agnieszka Dobrowolska",
        "Rogier Hintzen",
        "Martin Balla",
        "Karl Gemayel",
        "Sabine Reichert",
        "Thomas Charman",
        "Jen Ning Lim",
        "Lindsay Edwards",
        "Anna Gogleva"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA"
      ],
      "published": "2026-02-10 14:04:29+00:00",
      "link": "https://arxiv.org/pdf/2602.09801v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10171v1",
      "title": "EvoCodeBench: A Human-Performance Benchmark for Self-Evolving LLM-Driven Coding Systems",
      "abstract": "As large language models (LLMs) continue to advance in programming tasks, LLM-driven coding systems have evolved from one-shot code generation into complex systems capable of iterative improvement during inference. However, existing code benchmarks primarily emphasize static correctness and implicitly assume fixed model capability during inference. As a result, they do not capture inference-time self-evolution, such as whether accuracy and efficiency improve as an agent iteratively refines its solutions. They also provide limited accounting of resource costs and rarely calibrate model performance against that of human programmers. Moreover, many benchmarks are dominated by high-resource languages, leaving cross-language robustness and long-tail language stability underexplored. Therefore, we present EvoCodeBench, a benchmark for evaluating self-evolving LLM-driven coding systems across programming languages with direct comparison to human performance. EvoCodeBench tracks performance dynamics, measuring solution correctness alongside efficiency metrics such as solving time, memory consumption, and improvement algorithmic design over repeated problem-solving attempts. To ground evaluation in a human-centered reference frame, we directly compare model performance with that of human programmers on the same tasks, enabling relative performance assessment within the human ability distribution. Furthermore, EvoCodeBench supports multiple programming languages, enabling systematic cross-language and long-tail stability analyses under a unified protocol. Our results demonstrate that self-evolving systems exhibit measurable gains in efficiency over time, and that human-relative and multi-language analyses provide insights unavailable through accuracy alone. EvoCodeBench establishes a foundation for evaluating coding intelligence in evolving LLM-driven systems.",
      "authors": [
        "Wentao Zhang",
        "Jianfeng Wang",
        "Liheng Liang",
        "Yilei Zhao",
        "HaiBin Wen",
        "Zhe Zhao"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-02-10 14:04:22+00:00",
      "link": "https://arxiv.org/pdf/2602.10171v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09798v1",
      "title": "Symbolic Pattern Temporal Numeric Planning with Intermediate Conditions and Effects",
      "abstract": "Recently, a Symbolic Pattern Planning (SPP) approach was proposed for numeric planning where a pattern (i.e., a finite sequence of actions) suggests a causal order between actions. The pattern is then encoded in a SMT formula whose models correspond to valid plans. If the suggestion by the pattern is inaccurate and no valid plan can be found, the pattern is extended until it contains the causal order of actions in a valid plan, making the approach complete. In this paper, we extend the SPP approach to the temporal planning with Intermediate Conditions and Effects (ICEs) fragment, where $(i)$ actions are durative (and thus can overlap over time) and have conditions/effects which can be checked/applied at any time during an action's execution, and $(ii)$ one can specify plan's conditions/effects that must be checked/applied at specific times during the plan execution. Experimental results show that our SPP planner Patty $(i)$ outperforms all other planners in the literature in the majority of temporal domains without ICEs, $(ii)$ obtains comparable results with the SoTA search planner for ICS in literature domains with ICEs, and $(iii)$ outperforms the same planner in a novel domain based on a real-world application.",
      "authors": [
        "Matteo Cardellini",
        "Enrico Giunchiglia"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-10 14:03:40+00:00",
      "link": "https://arxiv.org/pdf/2602.09798v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09784v1",
      "title": "Circuit Fingerprints: How Answer Tokens Encode Their Geometrical Path",
      "abstract": "Circuit discovery and activation steering in transformers have developed as separate research threads, yet both operate on the same representational space. Are they two views of the same underlying structure? We show they follow a single geometric principle: answer tokens, processed in isolation, encode the directions that would produce them. This Circuit Fingerprint hypothesis enables circuit discovery without gradients or causal intervention -- recovering comparable structure to gradient-based methods through geometric alignment alone. We validate this on standard benchmarks (IOI, SVA, MCQA) across four model families, achieving circuit discovery performance comparable to gradient-based methods. The same directions that identify circuit components also enable controlled steering -- achieving 69.8\\% emotion classification accuracy versus 53.1\\% for instruction prompting while preserving factual accuracy. Beyond method development, this read-write duality reveals that transformer circuits are fundamentally geometric structures: interpretability and controllability are two facets of the same object.",
      "authors": [
        "Andres Saurez",
        "Neha Sengar",
        "Dongsoo Har"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-10 13:43:59+00:00",
      "link": "https://arxiv.org/pdf/2602.09784v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09782v1",
      "title": "Flexible Entropy Control in RLVR with Gradient-Preserving Perspective",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a critical method for enhancing the reasoning capabilities of Large Language Models (LLMs). However, continuous training often leads to policy entropy collapse, characterized by a rapid decay in entropy that results in premature overconfidence, reduced output diversity, and vanishing gradient norms that inhibit learning. Gradient-Preserving Clipping is a primary factor influencing these dynamics, but existing mitigation strategies are largely static and lack a framework connecting clipping mechanisms to precise entropy control. This paper proposes reshaping entropy control in RL from the perspective of Gradient-Preserving Clipping. We first theoretically and empirically verify the contributions of specific importance sampling ratio regions to entropy growth and reduction. Leveraging these findings, we introduce a novel regulation mechanism using dynamic clipping threshold to precisely manage entropy. Furthermore, we design and evaluate dynamic entropy control strategies, including increase-then-decrease, decrease-increase-decrease, and oscillatory decay. Experimental results demonstrate that these strategies effectively mitigate entropy collapse, and achieve superior performance across multiple benchmarks.",
      "authors": [
        "Kun Chen",
        "Peng Shi",
        "Fanfan Liu",
        "Haibo Qiu",
        "Zhixiong Zeng",
        "Siqi Yang",
        "Wenji Mao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-10 13:42:12+00:00",
      "link": "https://arxiv.org/pdf/2602.09782v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09774v1",
      "title": "QRS: A Rule-Synthesizing Neuro-Symbolic Triad for Autonomous Vulnerability Discovery",
      "abstract": "Static Application Security Testing (SAST) tools are integral to modern DevSecOps pipelines, yet tools like CodeQL, Semgrep, and SonarQube remain fundamentally constrained: they require expert-crafted queries, generate excessive false positives, and detect only predefined vulnerability patterns. Recent work has explored augmenting SAST with Large Language Models (LLMs), but these approaches typically use LLMs to triage existing tool outputs rather than to reason about vulnerability semantics directly. We introduce QRS (Query, Review, Sanitize), a neuro-symbolic framework that inverts this paradigm. Rather than filtering results from static rules, QRS employs three autonomous agents that generate CodeQL queries from a structured schema definition and few-shot examples, then validate findings through semantic reasoning and automated exploit synthesis. This architecture enables QRS to discover vulnerability classes beyond predefined patterns while substantially reducing false positives. We evaluate QRS on full Python packages rather than isolated snippets. In 20 historical CVEs in popular PyPI libraries, QRS achieves 90.6% detection accuracy. Applied to the 100 most-downloaded PyPI packages, QRS identified 39 medium-to-high-severity vulnerabilities, 5 of which were assigned new CVEs, 5 received documentation updates, while the remaining 29 were independently discovered by concurrent researchers, validating both the severity and discoverability of these findings. QRS accomplishes this with low time overhead and manageable token costs, demonstrating that LLM-driven query synthesis and code review can complement manually curated rule sets and uncover vulnerability patterns that evade existing industry tools.",
      "authors": [
        "George Tsigkourakos",
        "Constantinos Patsakis"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-10 13:35:24+00:00",
      "link": "https://arxiv.org/pdf/2602.09774v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09772v1",
      "title": "Design and Evaluation of an Assisted Programming Interface for Behavior Trees in Robotics",
      "abstract": "The possibility to create reactive robot programs faster without the need for extensively trained programmers is becoming increasingly important. So far, it has not been explored how various techniques for creating Behavior Tree (BT) program representations could be combined with complete graphical user interfaces (GUIs) to allow a human user to validate and edit trees suggested by automated methods. In this paper, we introduce BEhavior TRee GUI (BETR-GUI) for creating BTs with the help of an AI assistant that combines methods using large language models, planning, genetic programming, and Bayesian optimization with a drag-and-drop editor. A user study with 60 participants shows that by combining different assistive methods, BETR-GUI enables users to perform better at solving the robot programming tasks. The results also show that humans using the full variant of BETR-GUI perform better than the AI assistant running on its own.",
      "authors": [
        "Jonathan Styrud",
        "Matteo Iovino",
        "Rebecca Stower",
        "Mart Kartašev",
        "Mikael Norrlöf",
        "Mårten Björkman",
        "Christian Smith"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-10 13:34:00+00:00",
      "link": "https://arxiv.org/pdf/2602.09772v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09767v1",
      "title": "Diverse Skill Discovery for Quadruped Robots via Unsupervised Learning",
      "abstract": "Reinforcement learning necessitates meticulous reward shaping by specialists to elicit target behaviors, while imitation learning relies on costly task-specific data. In contrast, unsupervised skill discovery can potentially reduce these burdens by learning a diverse repertoire of useful skills driven by intrinsic motivation. However, existing methods exhibit two key limitations: they typically rely on a single policy to master a versatile repertoire of behaviors without modeling the shared structure or distinctions among them, which results in low learning efficiency; moreover, they are susceptible to reward hacking, where the reward signal increases and converges rapidly while the learned skills display insufficient actual diversity. In this work, we introduce an Orthogonal Mixture-of-Experts (OMoE) architecture that prevents diverse behaviors from collapsing into overlapping representations, enabling a single policy to master a wide spectrum of locomotion skills. In addition, we design a multi-discriminator framework in which different discriminators operate on distinct observation spaces, effectively mitigating reward hacking. We evaluated our method on the 12-DOF Unitree A1 quadruped robot, demonstrating a diverse set of locomotion skills. Our experiments demonstrate that the proposed framework boosts training efficiency and yields an 18.3\\% expansion in state-space coverage compared to the baseline.",
      "authors": [
        "Ruopeng Cui",
        "Yifei Bi",
        "Haojie Luo",
        "Wei Li"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-10 13:28:13+00:00",
      "link": "https://arxiv.org/pdf/2602.09767v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09761v1",
      "title": "Grounding LTL Tasks in Sub-Symbolic RL Environments for Zero-Shot Generalization",
      "abstract": "In this work we address the problem of training a Reinforcement Learning agent to follow multiple temporally-extended instructions expressed in Linear Temporal Logic in sub-symbolic environments. Previous multi-task work has mostly relied on knowledge of the mapping between raw observations and symbols appearing in the formulae. We drop this unrealistic assumption by jointly training a multi-task policy and a symbol grounder with the same experience. The symbol grounder is trained only from raw observations and sparse rewards via Neural Reward Machines in a semi-supervised fashion. Experiments on vision-based environments show that our method achieves performance comparable to using the true symbol grounding and significantly outperforms state-of-the-art methods for sub-symbolic environments.",
      "authors": [
        "Matteo Pannacci",
        "Andrea Fanti",
        "Elena Umili",
        "Roberto Capobianco"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-10 13:20:29+00:00",
      "link": "https://arxiv.org/pdf/2602.09761v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09757v1",
      "title": "Towards Poisoning Robustness Certification for Natural Language Generation",
      "abstract": "Understanding the reliability of natural language generation is critical for deploying foundation models in security-sensitive domains. While certified poisoning defenses provide provable robustness bounds for classification tasks, they are fundamentally ill-equipped for autoregressive generation: they cannot handle sequential predictions or the exponentially large output space of language models. To establish a framework for certified natural language generation, we formalize two security properties: stability (robustness to any change in generation) and validity (robustness to targeted, harmful changes in generation). We introduce Targeted Partition Aggregation (TPA), the first algorithm to certify validity/targeted attacks by computing the minimum poisoning budget needed to induce a specific harmful class, token, or phrase. Further, we extend TPA to provide tighter guarantees for multi-turn generations using mixed integer linear programming (MILP). Empirically, we demonstrate TPA's effectiveness across diverse settings including: certifying validity of agent tool-calling when adversaries modify up to 0.5% of the dataset and certifying 8-token stability horizons in preference-based alignment. Though inference-time latency remains an open challenge, our contributions enable certified deployment of language models in security-critical applications.",
      "authors": [
        "Mihnea Ghitu",
        "Matthew Wicker"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 13:09:44+00:00",
      "link": "https://arxiv.org/pdf/2602.09757v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09748v1",
      "title": "Linear Model Extraction via Factual and Counterfactual Queries",
      "abstract": "In model extraction attacks, the goal is to reveal the parameters of a black-box machine learning model by querying the model for a selected set of data points. Due to an increasing demand for explanations, this may involve counterfactual queries besides the typically considered factual queries. In this work, we consider linear models and three types of queries: factual, counterfactual, and robust counterfactual. First, for an arbitrary set of queries, we derive novel mathematical formulations for the classification regions for which the decision of the unknown model is known, without recovering any of the model parameters. Second, we derive bounds on the number of queries needed to extract the model's parameters for (robust) counterfactual queries under arbitrary norm-based distances. We show that the full model can be recovered using just a single counterfactual query when differentiable distance measures are employed. In contrast, when using polyhedral distances for instance, the number of required queries grows linearly with the dimension of the data space. For robust counterfactuals, the latter number of queries doubles. Consequently, the applied distance function and robustness of counterfactuals have a significant impact on the model's security.",
      "authors": [
        "Daan Otto",
        "Jannis Kurtz",
        "Dick den Hertog",
        "Ilker Birbil"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-02-10 12:57:53+00:00",
      "link": "https://arxiv.org/pdf/2602.09748v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09746v1",
      "title": "Sparse Axonal and Dendritic Delays Enable Competitive SNNs for Keyword Classification",
      "abstract": "Training transmission delays in spiking neural networks (SNNs) has been shown to substantially improve their performance on complex temporal tasks. In this work, we show that learning either axonal or dendritic delays enables deep feedforward SNNs composed of leaky integrate-and-fire (LIF) neurons to reach accuracy comparable to existing synaptic delay learning approaches, while significantly reducing memory and computational overhead. SNN models with either axonal or dendritic delays achieve up to $95.58\\%$ on the Google Speech Command (GSC) and $80.97\\%$ on the Spiking Speech Command (SSC) datasets, matching or exceeding prior methods based on synaptic delays or more complex neuron models. By adjusting the delay parameters, we obtain improved performance for synaptic delay learning baselines, strengthening the comparison. We find that axonal delays offer the most favorable trade-off, combining lower buffering requirements with slightly higher accuracy than dendritic delays. We further show that the performance of axonal and dendritic delay models is largely preserved under strong delay sparsity, with as few as $20\\%$ of delays remaining active, further reducing buffering requirements. Overall, our results indicate that learnable axonal and dendritic delays provide a resource-efficient and effective mechanism for temporal representation in SNNs. Code will be made available publicly upon acceptance. Code is available at https://github.com/YounesBouhadjar/AxDenSynDelaySNN",
      "authors": [
        "Younes Bouhadjar",
        "Emre Neftci"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-02-10 12:57:02+00:00",
      "link": "https://arxiv.org/pdf/2602.09746v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13316v1",
      "title": "Semantic Waveforms for AI-Native 6G Networks",
      "abstract": "In this paper, we propose a semantic-aware waveform design framework for AI-native 6G networks that jointly optimizes physical layer resource usage and semantic communication efficiency and robustness, while explicitly accounting for the hardware constraints of RF chains. Our approach, called Orthogonal Semantic Sequency Division Multiplexing (OSSDM), introduces a parametrizable, orthogonal-base waveform design that enables controlled degradation of the wireless transmitted signal to preserve semantically significant content while minimizing resource consumption. We demonstrate that OSSDM not only reinforces semantic robustness against channel impairments but also improves semantic spectral efficiency by encoding meaningful information directly at the waveform level. Extensive numerical evaluations show that OSSDM outperforms conventional OFDM waveforms in spectral efficiency and semantic fidelity. The proposed semantic waveform co-design opens new research frontiers for AI-native, intelligent communication systems by enabling meaning-aware physical signal construction through the direct encoding of semantics at the waveform level.",
      "authors": [
        "Nour Hello",
        "Mohamed Amine Hamoura",
        "Francois Rivet",
        "Emilio Calvanese Strinati"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.ET"
      ],
      "published": "2026-02-10 12:55:37+00:00",
      "link": "https://arxiv.org/pdf/2602.13316v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09730v1",
      "title": "Allure of Craquelure: A Variational-Generative Approach to Crack Detection in Paintings",
      "abstract": "Recent advances in imaging technologies, deep learning and numerical performance have enabled non-invasive detailed analysis of artworks, supporting their documentation and conservation. In particular, automated detection of craquelure in digitized paintings is crucial for assessing degradation and guiding restoration, yet remains challenging due to the possibly complex scenery and the visual similarity between cracks and crack-like artistic features such as brush strokes or hair. We propose a hybrid approach that models crack detection as an inverse problem, decomposing an observed image into a crack-free painting and a crack component. A deep generative model is employed as powerful prior for the underlying artwork, while crack structures are captured using a Mumford--Shah-type variational functional together with a crack prior. Joint optimization yields a pixel-level map of crack localizations in the painting.",
      "authors": [
        "Laura Paul",
        "Holger Rauhut",
        "Martin Burger",
        "Samira Kabri",
        "Tim Roith"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG",
        "math.NA"
      ],
      "published": "2026-02-10 12:34:53+00:00",
      "link": "https://arxiv.org/pdf/2602.09730v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09726v1",
      "title": "ExO-PPO: an Extended Off-policy Proximal Policy Optimization Algorithm",
      "abstract": "Deep reinforcement learning has been able to solve various tasks successfully, however, due to the construction of policy gradient and training dynamics, tuning deep reinforcement learning models remains challenging. As one of the most successful deep reinforcement-learning algorithm, the Proximal Policy Optimization algorithm (PPO) clips the policy gradient within a conservative on-policy updates, which ensures reliable and stable policy improvement. However, this training pattern may sacrifice sample efficiency. On the other hand, off-policy methods make more adequate use of data through sample reuse, though at the cost of increased the estimation variance and bias. To leverage the advantages of both, in this paper, we propose a new PPO variant based on the stability guarantee from conservative on-policy iteration with a more efficient off-policy data utilization. Specifically, we first derive an extended off-policy improvement from an expectation form of generalized policy improvement lower bound. Then, we extend the clipping mechanism with segmented exponential functions for a suitable surrogate objective function. Third, the trajectories generated by the past $M$ policies are organized in the replay buffer for off-policy training. We refer to this method as Extended Off-policy Proximal Policy Optimization (ExO-PPO). Compared with PPO and some other state-of-the-art variants, we demonstrate an improved performance of ExO-PPO with balanced sample efficiency and stability on varied tasks in the empirical experiments.",
      "authors": [
        "Hanyong Wang",
        "Menglong Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-10 12:29:57+00:00",
      "link": "https://arxiv.org/pdf/2602.09726v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09723v1",
      "title": "AI-Assisted Scientific Assessment: A Case Study on Climate Change",
      "abstract": "The emerging paradigm of AI co-scientists focuses on tasks characterized by repeatable verification, where agents explore search spaces in 'guess and check' loops. This paradigm does not extend to problems where repeated evaluation is impossible and ground truth is established by the consensus synthesis of theory and existing evidence. We evaluate a Gemini-based AI environment designed to support collaborative scientific assessment, integrated into a standard scientific workflow. In collaboration with a diverse group of 13 scientists working in the field of climate science, we tested the system on a complex topic: the stability of the Atlantic Meridional Overturning Circulation (AMOC). Our results show that AI can accelerate the scientific workflow. The group produced a comprehensive synthesis of 79 papers through 104 revision cycles in just over 46 person-hours. AI contribution was significant: most AI-generated content was retained in the report. AI also helped maintain logical consistency and presentation quality. However, expert additions were crucial to ensure its acceptability: less than half of the report was produced by AI. Furthermore, substantial oversight was required to expand and elevate the content to rigorous scientific standards.",
      "authors": [
        "Christian Buck",
        "Levke Caesar",
        "Michelle Chen Huebscher",
        "Massimiliano Ciaramita",
        "Erich M. Fischer",
        "Zeke Hausfather",
        "Özge Kart Tokmak",
        "Reto Knutti",
        "Markus Leippold",
        "Joseph Ludescher",
        "Katharine J. Mach",
        "Sofia Palazzo Corner",
        "Kasra Rafiezadeh Shahi",
        "Johan Rockström",
        "Joeri Rogelj",
        "Boris Sakschewski"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-10 12:26:58+00:00",
      "link": "https://arxiv.org/pdf/2602.09723v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09720v1",
      "title": "Continual Learning for non-stationary regression via Memory-Efficient Replay",
      "abstract": "Data streams are rarely static in dynamic environments like Industry 4.0. Instead, they constantly change, making traditional offline models outdated unless they can quickly adjust to the new data. This need can be adequately addressed by continual learning (CL), which allows systems to gradually acquire knowledge without incurring the prohibitive costs of retraining them from scratch. Most research on continual learning focuses on classification problems, while very few studies address regression tasks. We propose the first prototype-based generative replay framework designed for online task-free continual regression. Our approach defines an adaptive output-space discretization model, enabling prototype-based generative replay for continual regression without storing raw data. Evidence obtained from several benchmark datasets shows that our framework reduces forgetting and provides more stable performance than other state-of-the-art solutions.",
      "authors": [
        "Pablo García-Santaclara",
        "Bruno Fernández-Castro",
        "RebecaP. Díaz-Redondo",
        "Martín Alonso-Gamarra"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-10 12:22:59+00:00",
      "link": "https://arxiv.org/pdf/2602.09720v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09719v1",
      "title": "Unsupervised Layer-Wise Dynamic Test Time Adaptation for LLMs",
      "abstract": "Test-time adaptation (TTA) for large language models (LLMs) updates model parameters at inference time using signals available at deployment. This paper focuses on a common yet under-explored regime: unsupervised, sample-specific TTA, where the model adapts independently for each prompt using only the prompt itself, without gold answers or external supervision. Although appealing, naive unsupervised TTA with a fixed, handcrafted learning rate can be unstable: updates may overfit to prompt-specific statistics, drift from the desired answer distribution, and ultimately degrade generation quality. This failure mode is not surprising, as in this case TTA must adapt to a single prompt within only a few gradient steps, unlike standard training that averages updates over large datasets and long optimization horizons. Therefore, we propose layer-wise dynamic test-time adaptation, a framework which explicitly modulates TTA strength as a function of prompt representation, LLM structure and adaptation step. In our setting, TTA updates only LoRA parameters, and a lightweight hypernetwork predicts per-layer, per-step learning-rate multipliers, enabling fine-grained control. Experiments across various datasets and LLMs consistently show that our method substantially strengthens TTA by learning effective scaling patterns over adaptation steps and transformer layer projections, improving stability while delivering better performance.",
      "authors": [
        "Longhuan Xu",
        "Cunjian Chen",
        "Feng Yin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-10 12:22:14+00:00",
      "link": "https://arxiv.org/pdf/2602.09719v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09718v1",
      "title": "SAQNN: Spectral Adaptive Quantum Neural Network as a Universal Approximator",
      "abstract": "Quantum machine learning (QML), as an interdisciplinary field bridging quantum computing and machine learning, has garnered significant attention in recent years. Currently, the field as a whole faces challenges due to incomplete theoretical foundations for the expressivity of quantum neural networks (QNNs). In this paper we propose a constructive QNN model and demonstrate that it possesses the universal approximation property (UAP), which means it can approximate any square-integrable function up to arbitrary accuracy. Furthermore, it supports switching function bases, thus adaptable to various scenarios in numerical approximation and machine learning. Our model has asymptotic advantages over the best classical feed-forward neural networks in terms of circuit size and achieves optimal parameter complexity when approximating Sobolev functions under $L_2$ norm.",
      "authors": [
        "Jialiang Tang",
        "Jialin Zhang",
        "Xiaoming Sun"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "published": "2026-02-10 12:22:02+00:00",
      "link": "https://arxiv.org/pdf/2602.09718v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09716v1",
      "title": "BRAVA-GNN: Betweenness Ranking Approximation Via Degree MAss Inspired Graph Neural Network",
      "abstract": "Computing node importance in networks is a long-standing fundamental problem that has driven extensive study of various centrality measures. A particularly well-known centrality measure is betweenness centrality, which becomes computationally prohibitive on large-scale networks. Graph Neural Network (GNN) models have thus been proposed to predict node rankings according to their relative betweenness centrality. However, state-of-the-art methods fail to generalize to high-diameter graphs such as road networks. We propose BRAVA-GNN, a lightweight GNN architecture that leverages the empirically observed correlation linking betweenness centrality to degree-based quantities, in particular multi-hop degree mass. This correlation motivates the use of degree masses as size-invariant node features and synthetic training graphs that closely match the degree distributions of real networks. Furthermore, while previous work relies on scale-free synthetic graphs, we leverage the hyperbolic random graph model, which reproduces power-law exponents outside the scale-free regime, better capturing the structure of real-world graphs like road networks. This design enables BRAVA-GNN to generalize across diverse graph families while using 54x fewer parameters than the most lightweight existing GNN baseline. Extensive experiments on 19 real-world networks, spanning social, web, email, and road graphs, show that BRAVA-GNN achieves up to 214% improvement in Kendall-Tau correlation and up to 70x speedup in inference time over state-of-the-art GNN-based approaches, particularly on challenging road networks.",
      "authors": [
        "Justin Dachille",
        "Aurora Rossi",
        "Sunil Kumar Maurya",
        "Frederik Mallmann-Trenn",
        "Xin Liu",
        "Frédéric Giroire",
        "Tsuyoshi Murata",
        "Emanuele Natale"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 12:20:09+00:00",
      "link": "https://arxiv.org/pdf/2602.09716v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09711v1",
      "title": "Directed Information: Estimation, Optimization and Applications in Communications and Causality",
      "abstract": "Directed information (DI) is an information measure that attempts to capture directionality in the flow of information from one random process to another. It is closely related to other causal influence measures, such as transfer entropy, Granger causality, and Pearl's causal framework. This monograph provides an overview of DI and its main application in information theory, namely, characterizing the capacity of channels with feedback and memory. We begin by reviewing the definitions of DI, its basic properties, and its relation to Shannon's mutual information. Next, we provide a survey of DI estimation techniques, ranging from classic plug-in estimators to modern neural-network-based estimators. Considering the application of channel capacity estimation, we describe how such estimators numerically optimize DI rate over a class of joint distributions on input and output processes. A significant part of the monograph is devoted to techniques to compute the feedback capacity of finite-state channels (FSCs). The feedback capacity of a strongly connected FSC involves the maximization of the DI rate from the channel input process to the output process. This maximization is performed over the class of causal conditioned probability input distributions. When the FSC is also unifilar, i.e., the next state is given by a time-invariant function of the current state and the new input-output symbol pair, the feedback capacity is the optimal average reward of an appropriately formulated Markov decision process (MDP). This MDP formulation has been exploited to develop several methods to compute exactly, or at least estimate closely, the feedback capacity of a unifilar FSC. This monograph describes these methods, starting from the value iteration algorithm, to Q-graph methods, and reinforcement learning algorithms that can handle large input and output alphabets.",
      "authors": [
        "Dor Tsur",
        "Oron Sabag",
        "Navin Kashyap",
        "Haim Permuter",
        "Gerhard Kramer"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-02-10 12:14:21+00:00",
      "link": "https://arxiv.org/pdf/2602.09711v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09708v1",
      "title": "Physics-informed diffusion models in spectral space",
      "abstract": "We propose a methodology that combines generative latent diffusion models with physics-informed machine learning to generate solutions of parametric partial differential equations (PDEs) conditioned on partial observations, which includes, in particular, forward and inverse PDE problems. We learn the joint distribution of PDE parameters and solutions via a diffusion process in a latent space of scaled spectral representations, where Gaussian noise corresponds to functions with controlled regularity. This spectral formulation enables significant dimensionality reduction compared to grid-based diffusion models and ensures that the induced process in function space remains within a class of functions for which the PDE operators are well defined. Building on diffusion posterior sampling, we enforce physics-informed constraints and measurement conditions during inference, applying Adam-based updates at each diffusion step. We evaluate the proposed approach on Poisson, Helmholtz, and incompressible Navier--Stokes equations, demonstrating improved accuracy and computational efficiency compared with existing diffusion-based PDE solvers, which are state of the art for sparse observations. Code is available at https://github.com/deeplearningmethods/PISD.",
      "authors": [
        "Davide Gallon",
        "Philippe von Wurstemberger",
        "Patrick Cheridito",
        "Arnulf Jentzen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "math.NA"
      ],
      "published": "2026-02-10 12:11:07+00:00",
      "link": "https://arxiv.org/pdf/2602.09708v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09702v1",
      "title": "On semidefinite-representable sets over valued fields",
      "abstract": "Polyhedra and spectrahedra over the real numbers, or more generally their images under linear maps, are respectively the feasible sets of linear and semidefinite programming, and form the family of semidefinite-representable sets. This paper studies analogues of these sets, as well as the associated optimization problems, when the data are taken over a valued field $K$. For $K$-polyhedra and linear programming over $K$ we present an algorithm based on the computation of Smith normal forms. We prove that fundamental properties of semidefinite-representable sets extend to the valued setting. In particular, we exhibit examples of non-polyhedral $K$-spectrahedra, as well as sets that are semidefinite-representable over $K$ but are not $K$-spectrahedra.",
      "authors": [
        "Corentin Cornou",
        "Simone Naldi",
        "Tristan Vaccon"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "cs.SC",
        "math.OC"
      ],
      "published": "2026-02-10 12:01:20+00:00",
      "link": "https://arxiv.org/pdf/2602.09702v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09690v1",
      "title": "Contextual and Seasonal LSTMs for Time Series Anomaly Detection",
      "abstract": "Univariate time series (UTS), where each timestamp records a single variable, serve as crucial indicators in web systems and cloud servers. Anomaly detection in UTS plays an essential role in both data mining and system reliability management. However, existing reconstruction-based and prediction-based methods struggle to capture certain subtle anomalies, particularly small point anomalies and slowly rising anomalies. To address these challenges, we propose a novel prediction-based framework named Contextual and Seasonal LSTMs (CS-LSTMs). CS-LSTMs are built upon a noise decomposition strategy and jointly leverage contextual dependencies and seasonal patterns, thereby strengthening the detection of subtle anomalies. By integrating both time-domain and frequency-domain representations, CS-LSTMs achieve more accurate modeling of periodic trends and anomaly localization. Extensive evaluations on public benchmark datasets demonstrate that CS-LSTMs consistently outperform state-of-the-art methods, highlighting their effectiveness and practical value in robust time series anomaly detection.",
      "authors": [
        "Lingpei Zhang",
        "Qingming Li",
        "Yong Yang",
        "Jiahao Chen",
        "Rui Zeng",
        "Chenyang Lyu",
        "Shouling Ji"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 11:46:15+00:00",
      "link": "https://arxiv.org/pdf/2602.09690v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09681v1",
      "title": "Resilient Class-Incremental Learning: on the Interplay of Drifting, Unlabelled and Imbalanced Data Streams",
      "abstract": "In today's connected world, the generation of massive streaming data across diverse domains has become commonplace. In the presence of concept drift, class imbalance, label scarcity, and new class emergence, they jointly degrade representation stability, bias learning toward outdated distributions, and reduce the resilience and reliability of detection in dynamic environments. This paper proposes SCIL (Streaming Class-Incremental Learning) to address these challenges. The SCIL framework integrates an autoencoder (AE) with a multi-layer perceptron for multi-class prediction, uses a dual-loss strategy (classification and reconstruction) for prediction and new class detection, employs corrected pseudo-labels for online training, manages classes with queues, and applies oversampling to handle imbalance. The rationale behind the method's structure is elucidated through ablation studies and a comprehensive experimental evaluation is performed using both real-world and synthetic datasets that feature class imbalance, incremental classes, and concept drifts. Our results demonstrate that SCIL outperforms strong baselines and state-of-the-art methods. Based on our commitment to Open Science, we make our code and datasets available to the community.",
      "authors": [
        "Jin Li",
        "Kleanthis Malialis",
        "Marios Polycarpou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-10 11:37:39+00:00",
      "link": "https://arxiv.org/pdf/2602.09681v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09678v1",
      "title": "Administrative Law's Fourth Settlement: AI and the Capability-Accountability Trap",
      "abstract": "Since 1887, administrative law has navigated a \"capability-accountability trap\": technological change forces government to become more sophisticated, but sophistication renders agencies opaque to generalist overseers like the courts and Congress. The law's response--substituting procedural review for substantive oversight--has produced a sedimentary accretion of requirements that ossify capacity without ensuring democratic control. This Article argues that the Supreme Court's post-Loper Bright retrenchment is best understood as an effort to shrink administration back to comprehensible size in response to this complexification. But reducing complexity in this way sacrifices capability precisely when climate change, pandemics, and AI risks demand more sophisticated governance.   AI offers a different path. Unlike many prior administrative technologies that increased opacity alongside capacity, AI can help build \"scrutability\" in government, translating technical complexity into accessible terms, surfacing the assumptions that matter for oversight, and enabling substantive verification of agency reasoning. This Article proposes three doctrinal innovations within administrative law to realize this potential: a Model and System Dossier (documenting model purpose, evaluation, monitoring, and versioning) extending the administrative record to AI decision-making; a material-model-change trigger specifying when AI updates require new process; and a \"deference to audit\" standard that rewards agencies for auditable evaluation of their AI tools. The result is a framework for what this Article calls the \"Fourth Settlement,\" administrative law that escapes the capability-accountability trap by preserving capability while restoring comprehensible oversight of administration.",
      "authors": [
        "Nicholas Caputo"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "published": "2026-02-10 11:36:01+00:00",
      "link": "https://arxiv.org/pdf/2602.09678v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09667v1",
      "title": "Differentiable Modeling for Low-Inertia Grids: Benchmarking PINNs, NODEs, and DP for Identification and Control of SMIB System",
      "abstract": "The transition toward low-inertia power systems demands modeling frameworks that provide not only accurate state predictions but also physically consistent sensitivities for control. While scientific machine learning offers powerful nonlinear modeling tools, the control-oriented implications of different differentiable paradigms remain insufficiently understood. This paper presents a comparative study of Physics-Informed Neural Networks (PINNs), Neural Ordinary Differential Equations (NODEs), and Differentiable Programming (DP) for modeling, identification, and control of power system dynamics. Using the Single Machine Infinite Bus (SMIB) system as a benchmark, we evaluate their performance in trajectory extrapolation, parameter estimation, and Linear Quadratic Regulator (LQR) synthesis.   Our results highlight a fundamental trade-off between data-driven flexibility and physical structure. NODE exhibits superior extrapolation by capturing the underlying vector field, whereas PINN shows limited generalization due to its reliance on a time-dependent solution map. In the inverse problem of parameter identification, while both DP and PINN successfully recover the unknown parameters, DP achieves significantly faster convergence by enforcing governing equations as hard constraints. Most importantly, for control synthesis, the DP framework yields closed-loop stability comparable to the theoretical optimum. Furthermore, we demonstrate that NODE serves as a viable data-driven surrogate when governing equations are unavailable.",
      "authors": [
        "Shinhoo Kang",
        "Sangwook Kim",
        "Sehyun Yun"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "eess.SY"
      ],
      "published": "2026-02-10 11:22:59+00:00",
      "link": "https://arxiv.org/pdf/2602.09667v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13314v1",
      "title": "Sim2Radar: Toward Bridging the Radar Sim-to-Real Gap with VLM-Guided Scene Reconstruction",
      "abstract": "Millimeter-wave (mmWave) radar provides reliable perception in visually degraded indoor environments (e.g., smoke, dust, and low light), but learning-based radar perception is bottlenecked by the scarcity and cost of collecting and annotating large-scale radar datasets. We present Sim2Radar, an end-to-end framework that synthesizes training radar data directly from single-view RGB images, enabling scalable data generation without manual scene modeling. Sim2Radar reconstructs a material-aware 3D scene by combining monocular depth estimation, segmentation, and vision-language reasoning to infer object materials, then simulates mmWave propagation with a configurable physics-based ray tracer using Fresnel reflection models parameterized by ITU-R electromagnetic properties. Evaluated on real-world indoor scenes, Sim2Radar improves downstream 3D radar perception via transfer learning: pre-training a radar point-cloud object detection model on synthetic data and fine-tuning on real radar yields up to +3.7 3D AP (IoU 0.3), with gains driven primarily by improved spatial localization. These results suggest that physics-based, vision-driven radar simulation can provide effective geometric priors for radar learning and measurably improve performance under limited real-data supervision.",
      "authors": [
        "Emily Bejerano",
        "Federico Tondolo",
        "Aayan Qayyum",
        "Xiaofan Yu",
        "Xiaofan Jiang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-10 10:56:47+00:00",
      "link": "https://arxiv.org/pdf/2602.13314v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09651v1",
      "title": "The Entropic Signature of Class Speciation in Diffusion Models",
      "abstract": "Diffusion models do not recover semantic structure uniformly over time. Instead, samples transition from semantic ambiguity to class commitment within a narrow regime. Recent theoretical work attributes this transition to dynamical instabilities along class-separating directions, but practical methods to detect and exploit these windows in trained models are still limited. We show that tracking the class-conditional entropy of a latent semantic variable given the noisy state provides a reliable signature of these transition regimes. By restricting the entropy to semantic partitions, the entropy can furthermore resolve semantic decisions at different levels of abstraction. We analyze this behavior in high-dimensional Gaussian mixture models and show that the entropy rate concentrates on the same logarithmic time scale as the speciation symmetry-breaking instability previously identified in variance-preserving diffusion. We validate our method on EDM2-XS and Stable Diffusion 1.5, where class-conditional entropy consistently isolates the noise regimes critical for semantic structure formation. Finally, we use our framework to quantify how guidance redistributes semantic information over time. Together, these results connect information-theoretic and statistical physics perspectives on diffusion and provide a principled basis for time-localized control.",
      "authors": [
        "Florian Handke",
        "Dejan Stančević",
        "Felix Koulischer",
        "Thomas Demeester",
        "Luca Ambrogioni"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-10 10:56:46+00:00",
      "link": "https://arxiv.org/pdf/2602.09651v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09642v1",
      "title": "MATA: Multi-Agent Framework for Reliable and Flexible Table Question Answering",
      "abstract": "Recent advances in Large Language Models (LLMs) have significantly improved table understanding tasks such as Table Question Answering (TableQA), yet challenges remain in ensuring reliability, scalability, and efficiency, especially in resource-constrained or privacy-sensitive environments. In this paper, we introduce MATA, a multi-agent TableQA framework that leverages multiple complementary reasoning paths and a set of tools built with small language models. MATA generates candidate answers through diverse reasoning styles for a given table and question, then refines or selects the optimal answer with the help of these tools. Furthermore, it incorporates an algorithm designed to minimize expensive LLM agent calls, enhancing overall efficiency. MATA maintains strong performance with small, open-source models and adapts easily across various LLM types. Extensive experiments on two benchmarks of varying difficulty with ten different LLMs demonstrate that MATA achieves state-of-the-art accuracy and highly efficient reasoning while avoiding excessive LLM inference. Our results highlight that careful orchestration of multiple reasoning pathways yields scalable and reliable TableQA. The code is available at https://github.com/AIDAS-Lab/MATA.",
      "authors": [
        "Sieun Hyeon",
        "Jusang Oh",
        "Sunghwan Steve Cho",
        "Jaeyoung Do"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-10 10:43:02+00:00",
      "link": "https://arxiv.org/pdf/2602.09642v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09620v1",
      "title": "FLINGO -- Instilling ASP Expressiveness into Linear Integer Constraints",
      "abstract": "Constraint Answer Set Programming (CASP) is a hybrid paradigm that enriches Answer Set Programming (ASP) with numerical constraint processing, something required in many real-world applications. The usual specification of constraints in most CASP solvers is closer to the numerical back-end expressiveness and semantics, rather than to standard specification in ASP. In the latter, numerical attributes are represented with predicates and this allows declaring default values, leaving the attribute undefined, making non-deterministic assignments with choice rules or using aggregated values. In CASP, most (if not all) of these features are lost once we switch to a constraint-based representation of those same attributes. In this paper, we present the FLINGO language (and tool) that incorporates the aforementioned expressiveness inside the numerical constraints and we illustrate its use with several examples. Based on previous work that established its semantic foundations, we also present a translation from the newly introduced FLINGO syntax to regular CASP programs following the CLINGCON input format.",
      "authors": [
        "Jorge Fandinno",
        "Pedro Cabalar",
        "Philipp Wanko",
        "Torsten Schaub"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "published": "2026-02-10 10:08:05+00:00",
      "link": "https://arxiv.org/pdf/2602.09620v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09617v1",
      "title": "AnyTouch 2: General Optical Tactile Representation Learning For Dynamic Tactile Perception",
      "abstract": "Real-world contact-rich manipulation demands robots to perceive temporal tactile feedback, capture subtle surface deformations, and reason about object properties as well as force dynamics. Although optical tactile sensors are uniquely capable of providing such rich information, existing tactile datasets and models remain limited. These resources primarily focus on object-level attributes (e.g., material) while largely overlooking fine-grained tactile temporal dynamics during physical interactions. We consider that advancing dynamic tactile perception requires a systematic hierarchy of dynamic perception capabilities to guide both data collection and model design. To address the lack of tactile data with rich dynamic information, we present ToucHD, a large-scale hierarchical tactile dataset spanning tactile atomic actions, real-world manipulations, and touch-force paired data. Beyond scale, ToucHD establishes a comprehensive tactile dynamic data ecosystem that explicitly supports hierarchical perception capabilities from the data perspective. Building on it, we propose AnyTouch 2, a general tactile representation learning framework for diverse optical tactile sensors that unifies object-level understanding with fine-grained, force-aware dynamic perception. The framework captures both pixel-level and action-specific deformations across frames, while explicitly modeling physical force dynamics, thereby learning multi-level dynamic perception capabilities from the model perspective. We evaluate our model on benchmarks that covers static object properties and dynamic physical attributes, as well as real-world manipulation tasks spanning multiple tiers of dynamic perception capabilities-from basic object-level understanding to force-aware dexterous manipulation. Experimental results demonstrate consistent and strong performance across sensors and tasks.",
      "authors": [
        "Ruoxuan Feng",
        "Yuxuan Zhou",
        "Siyu Mei",
        "Dongzhan Zhou",
        "Pengwei Wang",
        "Shaowei Cui",
        "Bin Fang",
        "Guocai Yao",
        "Di Hu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-10 10:05:53+00:00",
      "link": "https://arxiv.org/pdf/2602.09617v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09613v1",
      "title": "Tracking Finite-Time Lyapunov Exponents to Robustify Neural ODEs",
      "abstract": "We investigate finite-time Lyapunov exponents (FTLEs), a measure for exponential separation of input perturbations, of deep neural networks within the framework of continuous-depth neural ODEs. We demonstrate that FTLEs are powerful organizers for input-output dynamics, allowing for better interpretability and the comparison of distinct model architectures. We establish a direct connection between Lyapunov exponents and adversarial vulnerability, and propose a novel training algorithm that improves robustness by FTLE regularization. The key idea is to suppress exponents far from zero in the early stage of the input dynamics. This approach enhances robustness and reduces computational cost compared to full-interval regularization, as it avoids a full ``double'' backpropagation.",
      "authors": [
        "Tobias Wöhrer",
        "Christian Kuehn"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS",
        "cs.LG"
      ],
      "published": "2026-02-10 10:04:08+00:00",
      "link": "https://arxiv.org/pdf/2602.09613v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09609v1",
      "title": "Tele-Omni: a Unified Multimodal Framework for Video Generation and Editing",
      "abstract": "Recent advances in diffusion-based video generation have substantially improved visual fidelity and temporal coherence. However, most existing approaches remain task-specific and rely primarily on textual instructions, limiting their ability to handle multimodal inputs, contextual references, and diverse video generation and editing scenarios within a unified framework. Moreover, many video editing methods depend on carefully engineered pipelines tailored to individual operations, which hinders scalability and composability. In this paper, we propose Tele-Omni, a unified multimodal framework for video generation and editing that follows multimodal instructions, including text, images, and reference videos, within a single model. Tele-Omni leverages pretrained multimodal large language models to parse heterogeneous instructions and infer structured generation or editing intents, while diffusion-based generators perform high-quality video synthesis conditioned on these structured signals. To enable joint training across heterogeneous video tasks, we introduce a task-aware data processing pipeline that unifies multimodal inputs into a structured instruction format while preserving task-specific constraints. Tele-Omni supports a wide range of video-centric tasks, including text-to-video generation, image-to-video generation, first-last-frame video generation, in-context video generation, and in-context video editing. By decoupling instruction parsing from video synthesis and combining it with task-aware data design, Tele-Omni achieves flexible multimodal control while maintaining strong temporal coherence and visual consistency. Experimental results demonstrate that Tele-Omni achieves competitive performance across multiple tasks.",
      "authors": [
        "Jialun Liu",
        "Yukuo Ma",
        "Xiao Cao",
        "Tian Li",
        "Gonghu Shang",
        "Haibin Huang",
        "Chi Zhang",
        "Xuelong Li",
        "Cong Liu",
        "Junqi Liu",
        "Jiakui Hu",
        "Robby T. Tan",
        "Shiwen Zhang",
        "Liying Yang",
        "Xiaoyan Yang",
        "Qizhen Weng",
        "Xiangzhen Chang",
        "Yuanzhi Liang",
        "Yifan Xu",
        "Zhiyong Huang",
        "Zuoxin Li",
        "Xuelong Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 10:01:16+00:00",
      "link": "https://arxiv.org/pdf/2602.09609v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09598v1",
      "title": "Learning from the Irrecoverable: Error-Localized Policy Optimization for Tool-Integrated LLM Reasoning",
      "abstract": "Tool-integrated reasoning (TIR) enables LLM agents to solve tasks through planning, tool use, and iterative revision, but outcome-only reinforcement learning in this setting suffers from sparse, delayed rewards and weak step-level credit assignment. In long-horizon TIR trajectories, an early irrecoverable mistake can determine success or failure, making it crucial to localize the first irrecoverable step and leverage it for fine-grained credit assignment. We propose Error-Localized Policy Optimization (ELPO), which localizes the first irrecoverable step via binary-search rollout trees under a fixed rollout budget, converts the resulting tree into stable learning signals through hierarchical advantage attribution, and applies error-localized adaptive clipping to strengthen corrective updates on the critical step and its suffix. Across TIR benchmarks in math, science QA, and code execution, ELPO consistently outperforms strong Agentic RL baselines under comparable sampling budgets, with additional gains in Pass@K and Major@K scaling, rollout ranking quality, and tool-call efficiency. Our code will be publicly released soon.",
      "authors": [
        "Qiao Liang",
        "Yuke Zhu",
        "Chao Ge",
        "Lei Yang",
        "Ying Shen",
        "Bo Zheng",
        "Sheng Guo"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-10 09:50:24+00:00",
      "link": "https://arxiv.org/pdf/2602.09598v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09597v1",
      "title": "Detecting radar targets swarms in range profiles with a partially complex-valued neural network",
      "abstract": "Correctly detecting radar targets is usually challenged by clutter and waveform distortion. An additional difficulty stems from the relative proximity of several targets, the latter being perceived as a single target in the worst case, or influencing each other's detection thresholds. The negative impact of targets proximity notably depends on the range resolution defined by the radar parameters and the adaptive threshold adopted. This paper addresses the matter of targets detection in radar range profiles containing multiple targets with varying proximity and distorted echoes. Inspired by recent contributions in the radar and signal processing literature, this work proposes partially complex-valued neural networks as an adaptive range profile processing. Simulated datasets are generated and experiments are conducted to compare a common pulse compression approach with a simple neural network partially defined by complex-valued parameters. Whereas the pulse compression processes one pulse length at a time, the neural network put forward is a generative architecture going through the entire received signal in one go to generate a complete detection profile.",
      "authors": [
        "Martin Bauw"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "published": "2026-02-10 09:49:19+00:00",
      "link": "https://arxiv.org/pdf/2602.09597v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09591v2",
      "title": "On the Optimal Reasoning Length for RL-Trained Language Models",
      "abstract": "Reinforcement learning substantially improves reasoning in large language models, but it also tends to lengthen chain of thought outputs and increase computational cost during both training and inference. Though length control methods have been proposed, it remains unclear what the optimal output length is for balancing efficiency and performance. In this work, we compare several length control methods on two models, Qwen3-1.7B Base and DeepSeek-R1-Distill-Qwen-1.5B. Our results indicate that length penalties may hinder reasoning acquisition, while properly tuned length control can improve efficiency for models with strong prior reasoning. By extending prior work to RL trained policies, we identify two failure modes, 1) long outputs increase dispersion, and 2) short outputs lead to under-thinking.",
      "authors": [
        "Daisuke Nohara",
        "Taishi Nakamura",
        "Rio Yokota"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-10 09:45:42+00:00",
      "link": "https://arxiv.org/pdf/2602.09591v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09586v1",
      "title": "Delving into Spectral Clustering with Vision-Language Representations",
      "abstract": "Spectral clustering is known as a powerful technique in unsupervised data analysis. The vast majority of approaches to spectral clustering are driven by a single modality, leaving the rich information in multi-modal representations untapped. Inspired by the recent success of vision-language pre-training, this paper enriches the landscape of spectral clustering from a single-modal to a multi-modal regime. Particularly, we propose Neural Tangent Kernel Spectral Clustering that leverages cross-modal alignment in pre-trained vision-language models. By anchoring the neural tangent kernel with positive nouns, i.e., those semantically close to the images of interest, we arrive at formulating the affinity between images as a coupling of their visual proximity and semantic overlap. We show that this formulation amplifies within-cluster connections while suppressing spurious ones across clusters, hence encouraging block-diagonal structures. In addition, we present a regularized affinity diffusion mechanism that adaptively ensembles affinity matrices induced by different prompts. Extensive experiments on \\textbf{16} benchmarks -- including classical, large-scale, fine-grained and domain-shifted datasets -- manifest that our method consistently outperforms the state-of-the-art by a large margin.",
      "authors": [
        "Bo Peng",
        "Yuanwei Hu",
        "Bo Liu",
        "Ling Chen",
        "Jie Lu",
        "Zhen Fang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 09:36:24+00:00",
      "link": "https://arxiv.org/pdf/2602.09586v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13312v1",
      "title": "PeroMAS: A Multi-agent System of Perovskite Material Discovery",
      "abstract": "As a pioneer of the third-generation photovoltaic revolution, Perovskite Solar Cells (PSCs) are renowned for their superior optoelectronic performance and cost potential. The development process of PSCs is precise and complex, involving a series of closed-loop workflows such as literature retrieval, data integration, experimental design, and synthesis. However, existing AI perovskite approaches focus predominantly on discrete models, including material design, process optimization,and property prediction. These models fail to propagate physical constraints across the workflow, hindering end-to-end optimization. In this paper, we propose a multi-agent system for perovskite material discovery, named PeroMAS. We first encapsulated a series of perovskite-specific tools into Model Context Protocols (MCPs). By planning and invoking these tools, PeroMAS can design perovskite materials under multi-objective constraints, covering the entire process from literature retrieval and data extraction to property prediction and mechanism analysis. Furthermore, we construct an evaluation benchmark by perovskite human experts to assess this multi-agent system. Results demonstrate that, compared to single Large Language Model (LLM) or traditional search strategies, our system significantly enhances discovery efficiency. It successfully identified candidate materials satisfying multi-objective constraints. Notably, we verify PeroMAS's effectiveness in the physical world through real synthesis experiments.",
      "authors": [
        "Yishu Wang",
        "Wei Liu",
        "Yifan Li",
        "Shengxiang Xu",
        "Xujie Yuan",
        "Ran Li",
        "Yuyu Luo",
        "Jia Zhu",
        "Shimin Di",
        "Min-Ling Zhang",
        "Guixiang Li"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "published": "2026-02-10 09:33:06+00:00",
      "link": "https://arxiv.org/pdf/2602.13312v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09578v1",
      "title": "Rollout-Training Co-Design for Efficient LLM-Based Multi-Agent Reinforcement Learning",
      "abstract": "Despite algorithm-level innovations for multi-agent reinforcement learning (MARL), the underlying networked infrastructure for large-scale MARL training remains underexplored. Existing training frameworks primarily optimize for single-agent scenarios and fail to address the unique system-level challenges of MARL, including rollout-training synchronization barriers, rollout load imbalance, and training resource underutilization. To bridge this gap, we propose FlexMARL, the first end-to-end training framework that holistically optimizes rollout, training, and their orchestration for large-scale LLM-based MARL. Specifically, FlexMARL introduces the joint orchestrator to manage data flow under the rollout-training disaggregated architecture. Building upon the experience store, a novel micro-batch driven asynchronous pipeline eliminates the synchronization barriers while providing strong consistency guarantees. Rollout engine adopts a parallel sampling scheme combined with hierarchical load balancing, which adapts to skewed inter/intra-agent request patterns. Training engine achieves on-demand hardware binding through agent-centric resource allocation. The training states of different agents are swapped via unified and location-agnostic communication. Empirical results on a large-scale production cluster demonstrate that FlexMARL achieves up to 7.3x speedup and improves hardware utilization by up to 5.6x compared to existing frameworks.",
      "authors": [
        "Zhida Jiang",
        "Zhaolong Xing",
        "Jiawei Lu",
        "Yipei Niu",
        "Qingyuan Sang",
        "Liangxu Zhang",
        "Wenquan Dai",
        "Junhua Shu",
        "Jiaxing Wang",
        "Qiangyu Pei",
        "Qiong Chen",
        "Xinyu Liu",
        "Fangming Liu",
        "Ai Han",
        "Zhen Chen",
        "Ke Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 09:27:03+00:00",
      "link": "https://arxiv.org/pdf/2602.09578v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09572v2",
      "title": "Predictive Query Language: A Domain-Specific Language for Predictive Modeling on Relational Databases",
      "abstract": "The purpose of predictive modeling on relational data is to predict future or missing values in a relational database, for example, future purchases of a user, risk of readmission of the patient, or the likelihood that a financial transaction is fraudulent. Typically powered by machine learning methods, predictive models are used in recommendations, financial fraud detection, supply chain optimization, and other systems, providing billions of predictions every day. However, training a machine learning model requires manual work to extract the required training examples - prediction entities and target labels - from the database, which is slow, laborious, and prone to mistakes. Here, we present the Predictive Query Language (PQL), an SQL-inspired declarative language for defining predictive tasks on relational databases. PQL allows specifying a predictive task in a single declarative query, enabling the automatic computation of training labels for a large variety of machine learning tasks, such as regression, classification, time-series forecasting, and recommender systems. PQL is already successfully integrated and used in a collection of use cases as part of a predictive AI platform. The versatility of the language can be demonstrated through its many ongoing use cases, including financial fraud, item recommendations, and workload prediction. We demonstrate its versatile design through two implementations; one for small-scale, low-latency use and one that can handle large-scale databases.",
      "authors": [
        "Vid Kocijan",
        "Jinu Sunil",
        "Jan Eric Lenssen",
        "Viman Deb",
        "Xinwei Xe",
        "Federico Reyes Gomez",
        "Matthias Fey",
        "Jure Leskovec"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-10 09:22:17+00:00",
      "link": "https://arxiv.org/pdf/2602.09572v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09570v1",
      "title": "LEMUR: A Corpus for Robust Fine-Tuning of Multilingual Law Embedding Models for Retrieval",
      "abstract": "Large language models (LLMs) are increasingly used to access legal information. Yet, their deployment in multilingual legal settings is constrained by unreliable retrieval and the lack of domain-adapted, open-embedding models. In particular, existing multilingual legal corpora are not designed for semantic retrieval, and PDF-based legislative sources introduce substantial noise due to imperfect text extraction. To address these challenges, we introduce LEMUR, a large-scale multilingual corpus of EU environmental legislation constructed from 24,953 official EUR-Lex PDF documents covering 25 languages. We quantify the fidelity of PDF-to-text conversion by measuring lexical consistency against authoritative HTML versions using the Lexical Content Score (LCS). Building on LEMUR, we fine-tune three state-of-the-art multilingual embedding models using contrastive objectives in both monolingual and bilingual settings, reflecting realistic legal-retrieval scenarios. Experiments across low- and high-resource languages demonstrate that legal-domain fine-tuning consistently improves Top-k retrieval accuracy relative to strong baselines, with particularly pronounced gains for low-resource languages. Cross-lingual evaluations show that these improvements transfer to unseen languages, indicating that fine-tuning primarily enhances language-independent, content-level legal representations rather than language-specific cues. We publish code\\footnote{\\href{https://github.com/nargesbh/eur_lex}{GitHub Repository}} and data\\footnote{\\href{https://huggingface.co/datasets/G4KMU/LEMUR}{Hugging Face Dataset}}.",
      "authors": [
        "Narges Baba Ahmadi",
        "Jan Strich",
        "Martin Semmann",
        "Chris Biemann"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-02-10 09:20:24+00:00",
      "link": "https://arxiv.org/pdf/2602.09570v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09569v1",
      "title": "Training deep physical neural networks with local physical information bottleneck",
      "abstract": "Deep learning has revolutionized modern society but faces growing energy and latency constraints. Deep physical neural networks (PNNs) are interconnected computing systems that directly exploit analog dynamics for energy-efficient, ultrafast AI execution. Realizing this potential, however, requires universal training methods tailored to physical intricacies. Here, we present the Physical Information Bottleneck (PIB), a general and efficient framework that integrates information theory and local learning, enabling deep PNNs to learn under arbitrary physical dynamics. By allocating matrix-based information bottlenecks to each unit, we demonstrate supervised, unsupervised, and reinforcement learning across electronic memristive chips and optical computing platforms. PIB also adapts to severe hardware faults and allows for parallel training via geographically distributed resources. Bypassing auxiliary digital models and contrastive measurements, PIB recasts PNN training as an intrinsic, scalable information-theoretic process compatible with diverse physical substrates.",
      "authors": [
        "Hao Wang",
        "Ziao Wang",
        "Xiangpeng Liang",
        "Han Zhao",
        "Jianqi Hu",
        "Junjie Jiang",
        "Xing Fu",
        "Jianshi Tang",
        "Huaqiang Wu",
        "Sylvain Gigan",
        "Qiang Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.app-ph"
      ],
      "published": "2026-02-10 09:20:12+00:00",
      "link": "https://arxiv.org/pdf/2602.09569v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09566v1",
      "title": "ECG-IMN: Interpretable Mesomorphic Neural Networks for 12-Lead Electrocardiogram Interpretation",
      "abstract": "Deep learning has achieved expert-level performance in automated electrocardiogram (ECG) diagnosis, yet the \"black-box\" nature of these models hinders their clinical deployment. Trust in medical AI requires not just high accuracy but also transparency regarding the specific physiological features driving predictions. Existing explainability methods for ECGs typically rely on post-hoc approximations (e.g., Grad-CAM and SHAP), which can be unstable, computationally expensive, and unfaithful to the model's actual decision-making process. In this work, we propose the ECG-IMN, an Interpretable Mesomorphic Neural Network tailored for high-resolution 12-lead ECG classification. Unlike standard classifiers, the ECG-IMN functions as a hypernetwork: a deep convolutional backbone generates the parameters of a strictly linear model specific to each input sample. This architecture enforces intrinsic interpretability, as the decision logic is mathematically transparent and the generated weights (W) serve as exact, high-resolution feature attribution maps. We introduce a transition decoder that effectively maps latent features to sample-wise weights, enabling precise localization of pathological evidence (e.g., ST-elevation, T-wave inversion) in both time and lead dimensions. We evaluate our approach on the PTB-XL dataset for classification tasks, demonstrating that the ECG-IMN achieves competitive predictive performance (AUROC comparable to black-box baselines) while providing faithful, instance-specific explanations. By explicitly decoupling parameter generation from prediction execution, our framework bridges the gap between deep learning capability and clinical trustworthiness, offering a principled path toward \"white-box\" cardiac diagnostics.",
      "authors": [
        "Vajira Thambawita",
        "Jonas L. Isaksen",
        "Jørgen K. Kanters",
        "Hugo L. Hammer",
        "Pål Halvorsen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ME"
      ],
      "published": "2026-02-10 09:17:29+00:00",
      "link": "https://arxiv.org/pdf/2602.09566v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09554v1",
      "title": "Development of an Energy-Efficient and Real-Time Data Movement Strategy for Next-Generation Heterogeneous Mixed-Criticality Systems",
      "abstract": "Industrial domains such as automotive, robotics, and aerospace are rapidly evolving to satisfy the increasing demand for machine-learning-driven Autonomy, Connectivity, Electrification, and Shared mobility (ACES). This paradigm shift inherently and significantly increases the requirement for onboard computing performance and high-performance communication infrastructure. At the same time, Moore's Law and Dennard Scaling are grinding to a halt, in turn, driving computing systems to larger scales and higher levels of heterogeneity and specialization, through application-specific hardware accelerators, instead of relying on technological scaling only. Approaching ACES requires this substantial amount of compute at an increasingly high energy-efficiency, since most use cases are fundamentally resource-bound. This increase in compute performance and heterogeneity goes hand in hand with a growing demand for high memory bandwidth and capacity as the driving applications grow in complexity, operating on huge and progressively irregular data sets and further requiring a steady influx of sensor data, increasing pressure both on on-chip and off-chip interconnect systems. Further, ACES combines real-time time-critical with general compute tasks on the same physical platform, sharing communication, storage, and micro-architectural resources. These heterogeneous mixed-criticality systems (MCSs) place additional pressure on the interconnect, demanding minimal contention between the different criticality levels to sustain a high degree of predictability. Fulfilling the performance and energy-efficiency requirements across a wide range of industrial applications requires a carefully co-designed process of the memory system with the use cases as well as the compute units and accelerators.",
      "authors": [
        "Thomas Benz"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR"
      ],
      "published": "2026-02-10 09:03:42+00:00",
      "link": "https://arxiv.org/pdf/2602.09554v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10163v1",
      "title": "Beyond SMILES: Evaluating Agentic Systems for Drug Discovery",
      "abstract": "Agentic systems for drug discovery have demonstrated autonomous synthesis planning, literature mining, and molecular design. We ask how well they generalize. Evaluating six frameworks against 15 task classes drawn from peptide therapeutics, in vivo pharmacology, and resource-constrained settings, we find five capability gaps: no support for protein language models or peptide-specific prediction, no bridges between in vivo and in silico data, reliance on LLM inference with no pathway to ML training or reinforcement learning, assumptions tied to large-pharma resources, and single-objective optimization that ignores safety-efficacy-stability trade-offs. A paired knowledge-probing experiment suggests the bottleneck is architectural rather than epistemic: four frontier LLMs reason about peptides at levels comparable to small molecules, yet no framework exposes this capability. We propose design requirements and a capability matrix for next-generation frameworks that function as computational partners under realistic constraints.",
      "authors": [
        "Edward Wijaya"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "published": "2026-02-10 09:01:09+00:00",
      "link": "https://arxiv.org/pdf/2602.10163v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09552v1",
      "title": "Comprehensive Comparison of RAG Methods Across Multi-Domain Conversational QA",
      "abstract": "Conversational question answering increasingly relies on retrieval-augmented generation (RAG) to ground large language models (LLMs) in external knowledge. Yet, most existing studies evaluate RAG methods in isolation and primarily focus on single-turn settings. This paper addresses the lack of a systematic comparison of RAG methods for multi-turn conversational QA, where dialogue history, coreference, and shifting user intent substantially complicate retrieval. We present a comprehensive empirical study of vanilla and advanced RAG methods across eight diverse conversational QA datasets spanning multiple domains. Using a unified experimental setup, we evaluate retrieval quality and answer generation using generator and retrieval metrics, and analyze how performance evolves across conversation turns. Our results show that robust yet straightforward methods, such as reranking, hybrid BM25, and HyDE, consistently outperform vanilla RAG. In contrast, several advanced techniques fail to yield gains and can even degrade performance below the No-RAG baseline. We further demonstrate that dataset characteristics and dialogue length strongly influence retrieval effectiveness, explaining why no single RAG strategy dominates across settings. Overall, our findings indicate that effective conversational RAG depends less on method complexity than on alignment between the retrieval strategy and the dataset structure. We publish the code used.\\footnote{\\href{https://github.com/Klejda-A/exp-rag.git}{GitHub Repository}}",
      "authors": [
        "Klejda Alushi",
        "Jan Strich",
        "Chris Biemann",
        "Martin Semmann"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-02-10 08:59:23+00:00",
      "link": "https://arxiv.org/pdf/2602.09552v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09543v1",
      "title": "Shifting landscape of disability and development in India: Analysis from historical trends to future predictions 2001-2031",
      "abstract": "This study delves into the causes and trends of disability-related health burdens across Indian states. Through multiple Disability-Adjusted Life Years (DALY) types (covering communicable diseases, noncommunicable diseases, and injuries), gender disparities, and Human Development Index (HDI) values, these disability trends were evaluated. The data for this study was compiled from censuses, health research organisations, and data centres, among various other sources. We built regression models and used them to analyze trends across past decades and make projections for 2031. Our regression results show a strong inverse relationship between communicable disease DALYs and HDI. In other words, ongoing improvements in development and infrastructure significantly reduced communicable disease DALYs. In contrast, noncommunicable DALYs did not decrease despite rising HDI. And lastly, injury DALYs showed moderate declines with higher HDI, which reflects improvements in healthcare and safety systems. Gender analysis showed male overrepresentation among people with disabilities. These results from our study support that there is a need to shift public health focus toward chronic diseases and address gender disparities in disability outcomes.",
      "authors": [
        "Hana Kapadia",
        "Arun Kumar Rajasekaran"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI"
      ],
      "published": "2026-02-10 08:55:23+00:00",
      "link": "https://arxiv.org/pdf/2602.09543v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09541v1",
      "title": "Scalpel: Fine-Grained Alignment of Attention Activation Manifolds via Mixture Gaussian Bridges to Mitigate Multimodal Hallucination",
      "abstract": "Rapid progress in large vision-language models (LVLMs) has achieved unprecedented performance in vision-language tasks. However, due to the strong prior of large language models (LLMs) and misaligned attention across modalities, LVLMs often generate outputs inconsistent with visual content - termed hallucination. To address this, we propose \\textbf{Scalpel}, a method that reduces hallucination by refining attention activation distributions toward more credible regions. Scalpel predicts trusted attention directions for each head in Transformer layers during inference and adjusts activations accordingly. It employs a Gaussian mixture model to capture multi-peak distributions of attention in trust and hallucination manifolds, and uses entropic optimal transport (equivalent to Schrödinger bridge problem) to map Gaussian components precisely. During mitigation, Scalpel dynamically adjusts intervention strength and direction based on component membership and mapping relationships between hallucination and trust activations. Extensive experiments across multiple datasets and benchmarks demonstrate that Scalpel effectively mitigates hallucinations, outperforming previous methods and achieving state-of-the-art performance. Moreover, Scalpel is model- and data-agnostic, requiring no additional computation, only a single decoding step.",
      "authors": [
        "Ziqiang Shi",
        "Rujie Liu",
        "Shanshan Yu",
        "Satoshi Munakata",
        "Koichi Shirahata"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 08:53:43+00:00",
      "link": "https://arxiv.org/pdf/2602.09541v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09540v1",
      "title": "SWE-Bench Mobile: Can Large Language Model Agents Develop Industry-Level Mobile Applications?",
      "abstract": "Can large language model agents develop industry-level mobile applications? We introduce \\textbf{SWE-Bench Mobile}, a benchmark for evaluating coding agents on realistic software engineering tasks derived from a production iOS codebase. Unlike existing benchmarks that focus on isolated problems or bug fixes, SWE-Bench Mobile captures the full complexity of industrial development: multi-modal inputs (PRDs and Figma designs), a large-scale mixed Swift/Objective-C codebase, and comprehensive test suites. We evaluate 22 agent-model configurations across four coding agents -- three commercial (Cursor, Codex, Claude Code) and one open-source (OpenCode) -- and find that even the best configurations achieve only 12\\% task success rate. Our analysis reveals that (1) agent design matters as much as model capability -- the same model shows up to 6$\\times$ performance gap across agents, (2) commercial agents consistently outperform open-source alternatives, and (3) simple ``Defensive Programming'' prompts outperform complex ones by 7.4\\%. These findings highlight a significant gap between current agent capabilities and industrial requirements, while providing actionable insights for practitioners and researchers. We release SWE-Bench Mobile as a \\textit{hosted benchmark challenge} to prevent data contamination and ensure fair evaluation. The public leaderboard and development toolkit are available at https://swebenchmobile.com.",
      "authors": [
        "Muxin Tian",
        "Zhe Wang",
        "Blair Yang",
        "Zhenwei Tang",
        "Kunlun Zhu",
        "Honghua Dong",
        "Hanchen Li",
        "Xinni Xie",
        "Guangjing Wang",
        "Jiaxuan You"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-10 08:51:11+00:00",
      "link": "https://arxiv.org/pdf/2602.09540v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09528v1",
      "title": "SchröMind: Mitigating Hallucinations in Multimodal Large Language Models via Solving the Schrödinger Bridge Problem",
      "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have achieved significant success across various domains. However, their use in high-stakes fields like healthcare remains limited due to persistent hallucinations, where generated text contradicts or ignores visual input. We contend that MLLMs can comprehend images but struggle to produce accurate token sequences. Minor perturbations can shift attention from truthful to untruthful states, and the autoregressive nature of text generation often prevents error correction. To address this, we propose SchröMind-a novel framework reducing hallucinations via solving the Schrödinger bridge problem. It establishes a token-level mapping between hallucinatory and truthful activations with minimal transport cost through lightweight training, while preserving the model's original capabilities. Extensive experiments on the POPE and MME benchmarks demonstrate the superiority of Schrödinger, which achieves state-of-the-art performance while introducing only minimal computational overhead.",
      "authors": [
        "Ziqiang Shi",
        "Rujie Liu",
        "Shanshan Yu",
        "Satoshi Munakata",
        "Koichi Shirahata"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 08:36:40+00:00",
      "link": "https://arxiv.org/pdf/2602.09528v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09523v2",
      "title": "Singpath-VL Technical Report",
      "abstract": "We present Singpath-VL, a vision-language large model, to fill the vacancy of AI assistant in cervical cytology. Recent advances in multi-modal large language models (MLLMs) have significantly propelled the field of computational pathology. However, their application in cytopathology, particularly cervical cytology, remains underexplored, primarily due to the scarcity of large-scale, high-quality annotated datasets. To bridge this gap, we first develop a novel three-stage pipeline to synthesize a million-scale image-description dataset. The pipeline leverages multiple general-purpose MLLMs as weak annotators, refines their outputs through consensus fusion and expert knowledge injection, and produces high-fidelity descriptions of cell morphology. Using this dataset, we then fine-tune the Qwen3-VL-4B model via a multi-stage strategy to create a specialized cytopathology MLLM. The resulting model, named Singpath-VL, demonstrates superior performance in fine-grained morphological perception and cell-level diagnostic classification. To advance the field, we will open-source a portion of the synthetic dataset and benchmark.",
      "authors": [
        "Zhen Qiu",
        "Kaiwen Xiao",
        "Zhengwei Lu",
        "Xiangyu Liu",
        "Lei Zhao",
        "Hao Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 08:27:06+00:00",
      "link": "https://arxiv.org/pdf/2602.09523v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09516v1",
      "title": "The CLEF-2026 CheckThat! Lab: Advancing Multilingual Fact-Checking",
      "abstract": "The CheckThat! lab aims to advance the development of innovative technologies combating disinformation and manipulation efforts in online communication across a multitude of languages and platforms. While in early editions the focus has been on core tasks of the verification pipeline (check-worthiness, evidence retrieval, and verification), in the past three editions, the lab added additional tasks linked to the verification process. In this year's edition, the verification pipeline is at the center again with the following tasks: Task 1 on source retrieval for scientific web claims (a follow-up of the 2025 edition), Task 2 on fact-checking numerical and temporal claims, which adds a reasoning component to the 2025 edition, and Task 3, which expands the verification pipeline with generation of full-fact-checking articles. These tasks represent challenging classification and retrieval problems as well as generation challenges at the document and span level, including multilingual settings.",
      "authors": [
        "Julia Maria Struß",
        "Sebastian Schellhammer",
        "Stefan Dietze",
        "Venktesh V",
        "Vinay Setty",
        "Tanmoy Chakraborty",
        "Preslav Nakov",
        "Avishek Anand",
        "Primakov Chungkham",
        "Salim Hafid",
        "Dhruv Sahnan",
        "Konstantin Todorov"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-10 08:20:18+00:00",
      "link": "https://arxiv.org/pdf/2602.09516v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09510v1",
      "title": "Robust Depth Super-Resolution via Adaptive Diffusion Sampling",
      "abstract": "We propose AdaDS, a generalizable framework for depth super-resolution that robustly recovers high-resolution depth maps from arbitrarily degraded low-resolution inputs. Unlike conventional approaches that directly regress depth values and often exhibit artifacts under severe or unknown degradation, AdaDS capitalizes on the contraction property of Gaussian smoothing: as noise accumulates in the forward process, distributional discrepancies between degraded inputs and their pristine high-quality counterparts diminish, ultimately converging to isotropic Gaussian prior. Leveraging this, AdaDS adaptively selects a starting timestep in the reverse diffusion trajectory based on estimated refinement uncertainty, and subsequently injects tailored noise to position the intermediate sample within the high-probability region of the target posterior distribution. This strategy ensures inherent robustness, enabling generative prior of a pre-trained diffusion model to dominate recovery even when upstream estimations are imperfect. Extensive experiments on real-world and synthetic benchmarks demonstrate AdaDS's superior zero-shot generalization and resilience to diverse degradation patterns compared to state-of-the-art methods.",
      "authors": [
        "Kun Wang",
        "Yun Zhu",
        "Pan Zhou",
        "Na Zhao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 08:10:02+00:00",
      "link": "https://arxiv.org/pdf/2602.09510v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09501v1",
      "title": "Where-to-Unmask: Ground-Truth-Guided Unmasking Order Learning for Masked Diffusion Language Models",
      "abstract": "Masked Diffusion Language Models (MDLMs) generate text by iteratively filling masked tokens, requiring two coupled decisions at each step: which positions to unmask (where-to-unmask) and which tokens to place (what-to-unmask). While standard MDLM training directly optimizes token prediction (what-to-unmask), inference-time unmasking orders (where-to-unmask) are typically determined by heuristic confidence measures or trained through reinforcement learning with costly on-policy rollouts. To address this, we introduce Gt-Margin, a position-wise score derived from ground-truth tokens, defined as the probability margin between the correct token and its strongest alternative. Gt-Margin yields an oracle unmasking order that prioritizes easier positions first under each partially masked state. We demonstrate that leveraging this oracle unmasking order significantly enhances final generation quality, particularly on logical reasoning benchmarks. Building on this insight, we train a supervised unmasking planner via learning-to-rank to imitate the oracle ordering from masked contexts. The resulting planner integrates into standard MDLM sampling to select where-to-unmask, improving reasoning accuracy without modifying the token prediction model.",
      "authors": [
        "Hikaru Asano",
        "Tadashi Kozuno",
        "Kuniaki Saito",
        "Yukino Baba"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-10 07:56:46+00:00",
      "link": "https://arxiv.org/pdf/2602.09501v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09496v1",
      "title": "Jokeasy: Exploring Human-AI Collaboration in Thematic Joke Generation",
      "abstract": "Thematic jokes are central to stand-up comedy, sitcoms, and public speaking, where contexts and punchlines rely on fresh material - news, anecdotes, and cultural references that resonate with the audience. Recent advances in Large Language Models (LLMs) have enabled interactive joke generation through conversational interfaces. Although LLMs enable interactive joke generation, ordinary conversational interfaces seldom give creators enough agency, control, or timely access to such source material for constructing context and punchlines. We designed Jokeasy, a search-enabled prototype system that integrates a dual-role LLM agent acting as both a material scout and a prototype writer to support human-AI collaboration in thematic joke writing. Jokeasy provides a visual canvas in which retrieved web content is organized into editable inspiration blocks and developed through a multistage workflow. A qualitative study with 13 hobbyists and 5 expert participants (including professional comedians and HCI/AI specialists) showed that weaving real-time web material into this structured workflow enriches ideation and preserves author agency, while also revealing needs for finer search control, tighter chat-canvas integration, and more flexible visual editing. These insights refine our understanding of AI-assisted humour writing and guide future creative-writing tools.",
      "authors": [
        "Yate Ge",
        "Lin Tian",
        "Chiqian Xu",
        "Luyao Xu",
        "Meiying Li",
        "Yuanda Hu",
        "Weiwei Guo"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-10 07:51:30+00:00",
      "link": "https://arxiv.org/pdf/2602.09496v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09494v1",
      "title": "OSI: One-step Inversion Excels in Extracting Diffusion Watermarks",
      "abstract": "Watermarking is an important mechanism for provenance and copyright protection of diffusion-generated images. Training-free methods, exemplified by Gaussian Shading, embed watermarks into the initial noise of diffusion models with negligible impact on the quality of generated images. However, extracting this type of watermark typically requires multi-step diffusion inversion to obtain precise initial noise, which is computationally expensive and time-consuming. To address this issue, we propose One-step Inversion (OSI), a significantly faster and more accurate method for extracting Gaussian Shading style watermarks. OSI reformulates watermark extraction as a learnable sign classification problem, which eliminates the need for precise regression of the initial noise. Then, we initialize the OSI model from the diffusion backbone and finetune it on synthesized noise-image pairs with a sign classification objective. In this manner, the OSI model is able to accomplish the watermark extraction efficiently in only one step. Our OSI substantially outperforms the multi-step diffusion inversion method: it is 20x faster, achieves higher extraction accuracy, and doubles the watermark payload capacity. Extensive experiments across diverse schedulers, diffusion backbones, and cryptographic schemes consistently show improvements, demonstrating the generality of our OSI framework.",
      "authors": [
        "Yuwei Chen",
        "Zhenliang He",
        "Jia Tang",
        "Meina Kan",
        "Shiguang Shan"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 07:43:16+00:00",
      "link": "https://arxiv.org/pdf/2602.09494v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09489v1",
      "title": "Computing Conditional Shapley Values Using Tabular Foundation Models",
      "abstract": "Shapley values have become a cornerstone of explainable AI, but they are computationally expensive to use, especially when features are dependent. Evaluating them requires approximating a large number of conditional expectations, either via Monte Carlo integration or regression. Until recently it has not been possible to fully exploit deep learning for the regression approach, because retraining for each conditional expectation takes too long. Tabular foundation models such as TabPFN overcome this computational hurdle by leveraging in-context learning, so each conditional expectation can be approximated without any re-training. In this paper, we compute Shapley values with multiple variants of TabPFN and compare their performance with state-of-the-art methods on both simulated and real datasets. In most cases, TabPFN yields the best performance; where it does not, it is only marginally worse than the best method, at a fraction of the runtime. We discuss further improvements and how tabular foundation models can be better adapted specifically for conditional Shapley value estimation.",
      "authors": [
        "Lars Henry Berge Olsen",
        "Dennis Christensen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-10 07:36:41+00:00",
      "link": "https://arxiv.org/pdf/2602.09489v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09487v1",
      "title": "Adaptive recurrent flow map operator learning for reaction diffusion dynamics",
      "abstract": "Reaction-diffusion (RD) equations underpin pattern formation across chemistry, biology, and physics, yet learning stable operators that forecast their long-term dynamics from data remains challenging. Neural-operator surrogates provide resolution-robust prediction, but autoregressive rollouts can drift due to the accumulation of error, and out-of-distribution (OOD) initial conditions often degrade accuracy. Physics-based numerical residual objectives can regularize operator learning, although they introduce additional assumptions, sensitivity to discretization and loss design, and higher training cost. Here we develop a purely data-driven operator learner with adaptive recurrent training (DDOL-ART) using a robust recurrent strategy with lightweight validation milestones that early-exit unproductive rollout segments and redirect optimization. Trained only on a single in-distribution toroidal Gaussian family over short horizons, DDOL-ART learns one-step operators that remain stable under long rollouts and generalize zero-shot to strong morphology shifts across FitzHugh-Nagumo (FN), Gray-Scott (GS), and Lambda-Omega (LO) systems. Across these benchmarks, DDOL-ART delivers a strong accuracy and cost trade-off. It is several-fold faster than a physics-based numerical-loss operator learner (NLOL) under matched settings, and it remains competitive on both in-distribution stability and OOD robustness. Training-dynamics diagnostics show that adaptivity strengthens the correlation between validation error and OOD test error performance, acting as a feedback controller that limits optimization drift. Our results indicate that feedback-controlled recurrent training of DDOL-ART generates robust flow-map surrogates without PDE residuals, while simultaneously maintaining competitiveness with NLOL at significantly reduced training costs.",
      "authors": [
        "Huseyin Tunc"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.NA"
      ],
      "published": "2026-02-10 07:33:13+00:00",
      "link": "https://arxiv.org/pdf/2602.09487v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09475v1",
      "title": "ArtifactLens: Hundreds of Labels Are Enough for Artifact Detection with VLMs",
      "abstract": "Modern image generators produce strikingly realistic images, where only artifacts like distorted hands or warped objects reveal their synthetic origin. Detecting these artifacts is essential: without detection, we cannot benchmark generators or train reward models to improve them. Current detectors fine-tune VLMs on tens of thousands of labeled images, but this is expensive to repeat whenever generators evolve or new artifact types emerge. We show that pretrained VLMs already encode the knowledge needed to detect artifacts - with the right scaffolding, this capability can be unlocked using only a few hundred labeled examples per artifact category. Our system, ArtifactLens, achieves state-of-the-art on five human artifact benchmarks (the first evaluation across multiple datasets) while requiring orders of magnitude less labeled data. The scaffolding consists of a multi-component architecture with in-context learning and text instruction optimization, with novel improvements to each. Our methods generalize to other artifact types - object morphology, animal anatomy, and entity interactions - and to the distinct task of AIGC detection.",
      "authors": [
        "James Burgess",
        "Rameen Abdal",
        "Dan Stoddart",
        "Sergey Tulyakov",
        "Serena Yeung-Levy",
        "Kuan-Chieh Jackson Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-10 07:16:22+00:00",
      "link": "https://arxiv.org/pdf/2602.09475v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09474v1",
      "title": "Online Learning in MDPs with Partially Adversarial Transitions and Losses",
      "abstract": "We study reinforcement learning in MDPs whose transition function is stochastic at most steps but may behave adversarially at a fixed subset of $Λ$ steps per episode. This model captures environments that are stable except at a few vulnerable points. We introduce \\emph{conditioned occupancy measures}, which remain stable across episodes even with adversarial transitions, and use them to design two algorithms. The first handles arbitrary adversarial steps and achieves regret $\\tilde{O}(H S^Λ\\sqrt{K S A^{Λ+1}})$, where $K$ is the number of episodes, $S$ is the number of state, $A$ is the number of actions and $H$ is the episode's horizon. The second, assuming the adversarial steps are consecutive, improves the dependence on $S$ to $\\tilde{O}(H\\sqrt{K S^{3} A^{Λ+1}})$. We further give a $K^{2/3}$-regret reduction that removes the need to know which steps are the $Λ$ adversarial steps. We also characterize the regret of adversarial MDPs in the \\emph{fully adversarial} setting ($Λ=H-1$) both for full-information and bandit feedback, and provide almost matching upper and lower bounds (slightly strengthen existing lower bounds, and clarify how different feedback structures affect the hardness of learning).",
      "authors": [
        "Ofir Schlisselberg",
        "Tal Lancewicki",
        "Yishay Mansour"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 07:13:11+00:00",
      "link": "https://arxiv.org/pdf/2602.09474v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09472v1",
      "title": "LLM-Grounded Dynamic Task Planning with Hierarchical Temporal Logic for Human-Aware Multi-Robot Collaboration",
      "abstract": "While Large Language Models (LLM) enable non-experts to specify open-world multi-robot tasks, the generated plans often lack kinematic feasibility and are not efficient, especially in long-horizon scenarios. Formal methods like Linear Temporal Logic (LTL) offer correctness and optimal guarantees, but are typically confined to static, offline settings and struggle with computational scalability. To bridge this gap, we propose a neuro-symbolic framework that grounds LLM reasoning into hierarchical LTL specifications and solves the corresponding Simultaneous Task Allocation and Planning (STAP) problem. Unlike static approaches, our system resolves stochastic environmental changes, such as moving users or updated instructions via a receding horizon planning (RHP) loop with real-time perception, which dynamically refines plans through a hierarchical state space. Extensive real-world experiments demonstrate that our approach significantly outperforms baseline methods in success rate and interaction fluency while minimizing planning latency.",
      "authors": [
        "Shuyuan Hu",
        "Tao Lin",
        "Kai Ye",
        "Yang Yang",
        "Tianwei Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "published": "2026-02-10 07:11:36+00:00",
      "link": "https://arxiv.org/pdf/2602.09472v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09462v1",
      "title": "Bounded Modal Logic",
      "abstract": "Under the Curry--Howard isomorphism, the syntactic structure of programs can be modeled using birelational Kripke structures equipped with intuitionistic and modal relations. Intuitionistic relations capture scoping through persistence, reflecting the availability of resources from outer scopes, while modal relations model resource isolation introduced for various purposes.   Traditional modal languages, however, describe only modal transitions and thus provide limited support for expressing fine-grained control over resource availability. Motivated by this limitation, we introduce \\emph{Bounded Modal Logic (\\textbf{BML})}, an experimental extension of constructive modal logic whose language explicitly accounts for both intuitionistic and modal transitions.   We present a natural-deduction proof system and a Kripke semantics for \\textbf{BML}, together with a Curry--Howard interpretation via a corresponding typed lambda-calculus. We establish metatheoretic properties of the calculus, showing that \\textbf{BML} forms a well-disciplined logical system. This provides theoretical support for our proposed perspective on fine-grained resource control in programming languages.",
      "authors": [
        "Yuito Murase",
        "Akinori Maniwa"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-02-10 06:56:39+00:00",
      "link": "https://arxiv.org/pdf/2602.09462v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09457v1",
      "title": "From Average Sensitivity to Small-Loss Regret Bounds under Random-Order Model",
      "abstract": "We study online learning in the random-order model, where the multiset of loss functions is chosen adversarially but revealed in a uniformly random order. Building on the batch-to-online conversion by Dong and Yoshida (2023), we show that if an offline algorithm admits a $(1+\\varepsilon)$-approximation guarantee and the effect of $\\varepsilon$ on its average sensitivity is characterized by a function $\\varphi(\\varepsilon)$, then an adaptive choice of $\\varepsilon$ yields a small-loss regret bound of $\\tilde O(\\varphi^{\\star}(\\mathrm{OPT}_T))$, where $\\varphi^{\\star}$ is the concave conjugate of $\\varphi$, $\\mathrm{OPT}_T$ is the offline optimum over $T$ rounds, and $\\tilde O$ hides polylogarithmic factors in $T$. Our method requires no regularity assumptions on loss functions, such as smoothness, and can be viewed as a generalization of the AdaGrad-style tuning applied to the approximation parameter $\\varepsilon$. Our result recovers and strengthens the $(1+\\varepsilon)$-approximate regret bounds of Dong and Yoshida (2023) and yields small-loss regret bounds for online $k$-means clustering, low-rank approximation, and regression. We further apply our framework to online submodular function minimization using $(1\\pm\\varepsilon)$-cut sparsifiers of submodular hypergraphs, obtaining a small-loss regret bound of $\\tilde O(n^{3/4}(1 + \\mathrm{OPT}_T^{3/4}))$, where $n$ is the ground-set size. Our approach sheds light on the power of sparsification and related techniques in establishing small-loss regret bounds in the random-order model.",
      "authors": [
        "Shinsaku Sakaue",
        "Yuichi Yoshida"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.DS",
        "cs.LG"
      ],
      "published": "2026-02-10 06:46:01+00:00",
      "link": "https://arxiv.org/pdf/2602.09457v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09456v1",
      "title": "Taming the Monster Every Context: Complexity Measure and Unified Framework for Offline-Oracle Efficient Contextual Bandits",
      "abstract": "We propose an algorithmic framework, Offline Estimation to Decisions (OE2D), that reduces contextual bandit learning with general reward function approximation to offline regression. The framework allows near-optimal regret for contextual bandits with large action spaces with $O(log(T))$ calls to an offline regression oracle over $T$ rounds, and makes $O(loglog(T))$ calls when $T$ is known. The design of OE2D algorithm generalizes Falcon~\\citep{simchi2022bypassing} and its linear reward version~\\citep[][Section 4]{xu2020upper} in that it chooses an action distribution that we term ``exploitative F-design'' that simultaneously guarantees low regret and good coverage that trades off exploration and exploitation. Central to our regret analysis is a new complexity measure, the Decision-Offline Estimation Coefficient (DOEC), which we show is bounded in bounded Eluder dimension per-context and smoothed regret settings. We also establish a relationship between DOEC and Decision Estimation Coefficient (DEC)~\\citep{foster2021statistical}, bridging the design principles of offline- and online-oracle efficient contextual bandit algorithms for the first time.",
      "authors": [
        "Hao Qin",
        "Chicheng Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-10 06:45:57+00:00",
      "link": "https://arxiv.org/pdf/2602.09456v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09449v1",
      "title": "Look-Ahead and Look-Back Flows: Training-Free Image Generation with Trajectory Smoothing",
      "abstract": "Recent advances have reformulated diffusion models as deterministic ordinary differential equations (ODEs) through the framework of flow matching, providing a unified formulation for the noise-to-data generative process. Various training-free flow matching approaches have been developed to improve image generation through flow velocity field adjustment, eliminating the need for costly retraining. However, Modifying the velocity field $v$ introduces errors that propagate through the full generation path, whereas adjustments to the latent trajectory $z$ are naturally corrected by the pretrained velocity network, reducing error accumulation. In this paper, we propose two complementary training-free latent-trajectory adjustment approaches based on future and past velocity $v$ and latent trajectory $z$ information that refine the generative path directly in latent space. We propose two training-free trajectory smoothing schemes: \\emph{Look-Ahead}, which averages the current and next-step latents using a curvature-gated weight, and \\emph{Look-Back}, which smoothes latents using an exponential moving average with decay. We demonstrate through extensive experiments and comprehensive evaluation metrics that the proposed training-free trajectory smoothing models substantially outperform various state-of-the-art models across multiple datasets including COCO17, CUB-200, and Flickr30K.",
      "authors": [
        "Yan Luo",
        "Henry Huang",
        "Todd Y. Zhou",
        "Mengyu Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 06:34:47+00:00",
      "link": "https://arxiv.org/pdf/2602.09449v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09446v1",
      "title": "A Scoping Review of Deep Learning for Urban Visual Pollution and Proposal of a Real-Time Monitoring Framework with a Visual Pollution Index",
      "abstract": "Urban Visual Pollution (UVP) has emerged as a critical concern, yet research on automatic detection and application remains fragmented. This scoping review maps the existing deep learning-based approaches for detecting, classifying, and designing a comprehensive application framework for visual pollution management. Following the PRISMA-ScR guidelines, seven academic databases (Scopus, Web of Science, IEEE Xplore, ACM DL, ScienceDirect, SpringerNatureLink, and Wiley) were systematically searched and reviewed, and 26 articles were found. Most research focuses on specific pollutant categories and employs variations of YOLO, Faster R-CNN, and EfficientDet architectures. Although several datasets exist, they are limited to specific areas and lack standardized taxonomies. Few studies integrate detection into real-time application systems, yet they tend to be geographically skewed. We proposed a framework for monitoring visual pollution that integrates a visual pollution index to assess the severity of visual pollution for a certain area. This review highlights the need for a unified UVP management system that incorporates pollutant taxonomy, a cross-city benchmark dataset, a generalized deep learning model, and an assessment index that supports sustainable urban aesthetics and enhances the well-being of urban dwellers.",
      "authors": [
        "Mohammad Masudur Rahman",
        "Md. Rashedur Rahman",
        "Ashraful Islam",
        "Saadia B Alam",
        "M Ashraful Amin"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-10 06:30:27+00:00",
      "link": "https://arxiv.org/pdf/2602.09446v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09443v1",
      "title": "P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads",
      "abstract": "The transition from symbolic manipulation to science-grade reasoning represents a pivotal frontier for Large Language Models (LLMs), with physics serving as the critical test anchor for binding abstract logic to physical reality. Physics demands that a model maintain physical consistency with the laws governing the universe, a task that fundamentally requires multimodal perception to ground abstract logic in reality. At the Olympiad level, diagrams are often constitutive rather than illustrative, containing essential constraints, such as boundary conditions and spatial symmetries, that are absent from the text. To bridge this visual-logical gap, we introduce P1-VL, a family of open-source vision-language models engineered for advanced scientific reasoning. Our method harmonizes Curriculum Reinforcement Learning, which employs progressive difficulty expansion to stabilize post-training, with Agentic Augmentation, enabling iterative self-verification at inference. Evaluated on HiPhO, a rigorous benchmark of 13 exams from 2024-2025, our flagship P1-VL-235B-A22B becomes the first open-source Vision-Language Model (VLM) to secure 12 gold medals and achieves the state-of-the-art performance in the open-source models. Our agent-augmented system achieves the No.2 overall rank globally, trailing only Gemini-3-Pro. Beyond physics, P1-VL demonstrates remarkable scientific reasoning capacity and generalizability, establishing significant leads over base models in STEM benchmarks. By open-sourcing P1-VL, we provide a foundational step toward general-purpose physical intelligence to better align visual perceptions with abstract physical laws for machine scientific discovery.",
      "authors": [
        "Yun Luo",
        "Futing Wang",
        "Qianjia Cheng",
        "Fangchen Yu",
        "Haodi Lei",
        "Jianhao Yan",
        "Chenxi Li",
        "Jiacheng Chen",
        "Yufeng Zhao",
        "Haiyuan Wan",
        "Yuchen Zhang",
        "Shenghe Zheng",
        "Junchi Yao",
        "Qingyang Zhang",
        "Haonan He",
        "Wenxuan Zeng",
        "Li Sheng",
        "Chengxing Xie",
        "Yuxin Zuo",
        "Yizhuo Li",
        "Yulun Wu",
        "Rui Huang",
        "Dongzhan Zhou",
        "Kai Chen",
        "Yu Qiao",
        "Lei Bai",
        "Yu Cheng",
        "Ning Ding",
        "Bowen Zhou",
        "Peng Ye",
        "Ganqu Cui"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-10 06:28:08+00:00",
      "link": "https://arxiv.org/pdf/2602.09443v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09435v2",
      "title": "The Coordination Criterion",
      "abstract": "When is coordination intrinsically required by a distributed specification, rather than imposed by a particular protocol or implementation strategy? We give a general answer using minimal assumptions. In an asynchronous message-passing model, we represent executions as Lamport histories: collections of events partially ordered under happens-before. We abstract away from implementation mechanics and reason only about the observable outcomes that a specification admits at each history. We show that a specification admits a coordination-free implementation if and only if observable outcomes evolve monotonically as the history is causally extended.   This Coordination Criterion is stated entirely at the level of specifications, independent of any particular programming language, object implementation, or protocol structure. It yields a sharp boundary between specifications that can be implemented without coordination and those for which coordination is unavoidable. The criterion provides a uniform explanation for a range of classical results, including distributed protocols and impossibility results, CAP-style consistency tradeoffs, CALM-style coordination tests, and programming-language analyses. Each can be viewed as an instance of the same underlying semantic phenomenon.",
      "authors": [
        "Joseph M. Hellerstein"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC"
      ],
      "published": "2026-02-10 05:59:30+00:00",
      "link": "https://arxiv.org/pdf/2602.09435v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09432v1",
      "title": "SceneReVis: A Self-Reflective Vision-Grounded Framework for 3D Indoor Scene Synthesis via Multi-turn RL",
      "abstract": "Current one-pass 3D scene synthesis methods often suffer from spatial hallucinations, such as collisions, due to a lack of deliberative reasoning. To bridge this gap, we introduce SceneReVis, a vision-grounded self-reflection framework that employs an iterative ``diagnose-and-act'' loop to explicitly intercept and resolve spatial conflicts using multi-modal feedback. To support this step-wise paradigm, we construct SceneChain-12k, a large-scale dataset of causal construction trajectories derived through a novel reverse engineering pipeline. We further propose a two-stage training recipe that transitions from Supervised Fine-Tuning to Agentic Reinforcement Learning, evolving the model into an active spatial planner. Extensive experiments demonstrate that SceneReVis achieves state-of-the-art performance in high-fidelity generation and goal-oriented optimization, with robust generalization to long-tail domains.",
      "authors": [
        "Yang Zhao",
        "Shizhao Sun",
        "Meisheng Zhang",
        "Yingdong Shi",
        "Xubo Yang",
        "Jiang Bian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 05:55:56+00:00",
      "link": "https://arxiv.org/pdf/2602.09432v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09430v1",
      "title": "Sci-VLA: Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments",
      "abstract": "Robotic laboratories play a critical role in autonomous scientific discovery by enabling scalable, continuous experimental execution. Recent vision-language-action (VLA) models offer a promising foundation for robotic laboratories. However, scientific experiments typically involve long-horizon tasks composed of multiple atomic tasks, posing a fundamental challenge to existing VLA models. While VLA models fine-tuned for scientific tasks can reliably execute atomic experimental actions seen during training, they often fail to perform composite tasks formed by reordering and composing these known atomic actions. This limitation arises from a distributional mismatch between training-time atomic tasks and inference-time composite tasks, which prevents VLA models from executing necessary transitional operations between atomic tasks. To address this challenge, we propose an Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments. It introduces an LLM-based agentic inference mechanism that intervenes when executing sequential manipulation tasks. By performing explicit transition inference and generating transitional robotic action code, the proposed plugin guides VLA models through missing transitional steps, enabling reliable execution of composite scientific workflows without any additional training. This inference-only intervention makes our method computationally efficient, data-efficient, and well-suited for open-ended and long-horizon robotic laboratory tasks. We build 3D assets of scientific instruments and common scientific operating scenes within an existing simulation environment. In these scenes, we have verified that our method increases the average success rate per atomic task by 42\\% during inference. Furthermore, we show that our method can be easily transferred from the simulation to real scientific laboratories.",
      "authors": [
        "Yiwen Pang",
        "Bo Zhou",
        "Changjin Li",
        "Xuanhao Wang",
        "Shengxiang Xu",
        "Deng-Bao Wang",
        "Min-Ling Zhang",
        "Shimin Di"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-10 05:50:19+00:00",
      "link": "https://arxiv.org/pdf/2602.09430v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09429v2",
      "title": "First-order friction models with bristle dynamics: lumped and distributed formulations",
      "abstract": "Dynamic models, particularly rate-dependent models, have proven effective in capturing the key phenomenological features of frictional processes, whilst also possessing important mathematical properties that facilitate the design of control and estimation algorithms. However, many rate-dependent formulations are built on empirical considerations, whereas physical derivations may offer greater interpretability. In this context, starting from fundamental physical principles, this paper introduces a novel class of first-order dynamic friction models that approximate the dynamics of a bristle element by inverting the friction characteristic. Amongst the developed models, a specific formulation closely resembling the LuGre model is derived using a simple rheological equation for the bristle element. This model is rigorously analyzed in terms of stability and passivity -- important properties that support the synthesis of observers and controllers. Furthermore, a distributed version, formulated as a hyperbolic partial differential equation (PDE), is presented, which enables the modeling of frictional processes commonly encountered in rolling contact phenomena. The tribological behavior of the proposed description is evaluated through classical experiments and validated against the response predicted by the LuGre model, revealing both notable similarities and key differences.",
      "authors": [
        "Luigi Romano",
        "Ole Morten Aamo",
        "Jan Åslund",
        "Erik Frisk"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.RO"
      ],
      "published": "2026-02-10 05:49:16+00:00",
      "link": "https://arxiv.org/pdf/2602.09429v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10160v1",
      "title": "AD$^2$: Analysis and Detection of Adversarial Threats in Visual Perception for End-to-End Autonomous Driving Systems",
      "abstract": "End-to-end autonomous driving systems have achieved significant progress, yet their adversarial robustness remains largely underexplored. In this work, we conduct a closed-loop evaluation of state-of-the-art autonomous driving agents under black-box adversarial threat models in CARLA. Specifically, we consider three representative attack vectors on the visual perception pipeline: (i) a physics-based blur attack induced by acoustic waves, (ii) an electromagnetic interference attack that distorts captured images, and (iii) a digital attack that adds ghost objects as carefully crafted bounded perturbations on images. Our experiments on two advanced agents, Transfuser and Interfuser, reveal severe vulnerabilities to such attacks, with driving scores dropping by up to 99% in the worst case, raising valid safety concerns. To help mitigate such threats, we further propose a lightweight Attack Detection model for Autonomous Driving systems (AD$^2$) based on attention mechanisms that capture spatial-temporal consistency. Comprehensive experiments across multi-camera inputs on CARLA show that our detector achieves superior detection capability and computational efficiency compared to existing approaches.",
      "authors": [
        "Ishan Sahu",
        "Somnath Hazra",
        "Somak Aditya",
        "Soumyajit Dey"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-10 05:13:37+00:00",
      "link": "https://arxiv.org/pdf/2602.10160v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09396v1",
      "title": "Squeezing More from the Stream : Learning Representation Online for Streaming Reinforcement Learning",
      "abstract": "In streaming Reinforcement Learning (RL), transitions are observed and discarded immediately after a single update. While this minimizes resource usage for on-device applications, it makes agents notoriously sample-inefficient, since value-based losses alone struggle to extract meaningful representations from transient data. We propose extending Self-Predictive Representations (SPR) to the streaming pipeline to maximize the utility of every observed frame. However, due to the highly correlated samples induced by the streaming regime, naively applying this auxiliary loss results in training instabilities. Thus, we introduce orthogonal gradient updates relative to the momentum target and resolve gradient conflicts arising from streaming-specific optimizers. Validated across the Atari, MinAtar, and Octax suites, our approach systematically outperforms existing streaming baselines. Latent-space analysis, including t-SNE visualizations and effective-rank measurements, confirms that our method learns significantly richer representations, bridging the performance gap caused by the absence of a replay buffer, while remaining efficient enough to train on just a few CPU cores.",
      "authors": [
        "Nilaksh",
        "Antoine Clavaud",
        "Mathieu Reymond",
        "François Rivest",
        "Sarath Chandar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-10 04:06:32+00:00",
      "link": "https://arxiv.org/pdf/2602.09396v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09387v2",
      "title": "Query-Mixed Interest Extraction and Heterogeneous Interaction: A Scalable CTR Model for Industrial Recommender Systems",
      "abstract": "Learning effective feature interactions is central to modern recommender systems, yet remains challenging in industrial settings due to sparse multi-field inputs and ultra-long user behavior sequences. While recent scaling efforts have improved model capacity, they often fail to construct both context-aware and context-independent user intent from the long-term and real-time behavior sequence. Meanwhile, recent work also suffers from inefficient and homogeneous interaction mechanisms, leading to suboptimal prediction performance. To address these limitations, we propose HeMix, a scalable ranking model that unifies adaptive sequence tokenization and heterogeneous interaction structure. Specifically, HeMix introduces a Query-Mixed Interest Extraction module that jointly models context-aware and context-independent user interests via dynamic and fixed queries over global and real-time behavior sequences. For interaction, we replace self-attention with the HeteroMixer block, enabling efficient, multi-granularity cross-feature interactions that adopt the multi-head token fusion, heterogeneous interaction and group-aligned reconstruction pipelines. HeMix demonstrates favorable scaling behavior, driven by the HeteroMixer block, where increasing model scale via parameter expansion leads to steady improvements in recommendation accuracy. Experiments on industrial-scale datasets show that HeMix scales effectively and consistently outperforms strong baselines. Most importantly, HeMix has been deployed on the AMAP platform, delivering significant online gains over DLRM: +3.61\\% GMV, +2.78\\% PV\\_CTR, and +2.12\\% UV\\_CVR.",
      "authors": [
        "Fangye Wang",
        "Guowei Yang",
        "Xiaojiang Zhou",
        "Song Yang",
        "Pengjie Wang"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-10 03:56:14+00:00",
      "link": "https://arxiv.org/pdf/2602.09387v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09378v1",
      "title": "Fully Differentiable Bidirectional Dual-Task Synergistic Learning for Semi-Supervised 3D Medical Image Segmentation",
      "abstract": "Semi-supervised learning relaxes the need of large pixel-wise labeled datasets for image segmentation by leveraging unlabeled data. The scarcity of high-quality labeled data remains a major challenge in medical image analysis due to the high annotation costs and the need for specialized clinical expertise. Semi-supervised learning has demonstrated significant potential in addressing this bottleneck, with pseudo-labeling and consistency regularization emerging as two predominant paradigms. Dual-task collaborative learning, an emerging consistency-aware paradigm, seeks to derive supplementary supervision by establishing prediction consistency between related tasks. However, current methodologies are limited to unidirectional interaction mechanisms (typically regression-to-segmentation), as segmentation results can only be transformed into regression outputs in an offline manner, thereby failing to fully exploit the potential benefits of online bidirectional cross-task collaboration. Thus, we propose a fully Differentiable Bidirectional Synergistic Learning (DBiSL) framework, which seamlessly integrates and enhances four critical SSL components: supervised learning, consistency regularization, pseudo-supervised learning, and uncertainty estimation. Experiments on two benchmark datasets demonstrate our method's state-of-the-art performance. Beyond technical contributions, this work provides new insights into unified SSL framework design and establishes a new architectural foundation for dual-task-driven SSL, while offering a generic multitask learning framework applicable to broader computer vision applications. The code will be released on github upon acceptance.",
      "authors": [
        "Jun Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 03:44:24+00:00",
      "link": "https://arxiv.org/pdf/2602.09378v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13309v1",
      "title": "Adaptive Value Decomposition: Coordinating a Varying Number of Agents in Urban Systems",
      "abstract": "Multi-agent reinforcement learning (MARL) provides a promising paradigm for coordinating multi-agent systems (MAS). However, most existing methods rely on restrictive assumptions, such as a fixed number of agents and fully synchronous action execution. These assumptions are often violated in urban systems, where the number of active agents varies over time, and actions may have heterogeneous durations, resulting in a semi-MARL setting. Moreover, while sharing policy parameters among agents is commonly adopted to improve learning efficiency, it can lead to highly homogeneous actions when a subset of agents make decisions concurrently under similar observations, potentially degrading coordination quality. To address these challenges, we propose Adaptive Value Decomposition (AVD), a cooperative MARL framework that adapts to a dynamically changing agent population. AVD further incorporates a lightweight mechanism to mitigate action homogenization induced by shared policies, thereby encouraging behavioral diversity and maintaining effective cooperation among agents. In addition, we design a training-execution strategy tailored to the semi-MARL setting that accommodates asynchronous decision-making when some agents act at different times. Experiments on real-world bike-sharing redistribution tasks in two major cities, London and Washington, D.C., demonstrate that AVD outperforms state-of-the-art baselines, confirming its effectiveness and generalizability.",
      "authors": [
        "Yexin Li",
        "Jinjin Guo",
        "Haoyu Zhang",
        "Yuhan Zhao",
        "Yiwen Sun",
        "Zihao Jiao"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "published": "2026-02-10 03:41:14+00:00",
      "link": "https://arxiv.org/pdf/2602.13309v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10158v1",
      "title": "NMRTrans: Structure Elucidation from Experimental NMR Spectra via Set Transformers",
      "abstract": "Nuclear Magnetic Resonance (NMR) spectroscopy is fundamental for molecular structure elucidation, yet interpreting spectra at scale remains time-consuming and highly expertise-dependent. While recent spectrum-as-language modeling and retrieval-based methods have shown promise, they rely heavily on large corpora of computed spectra and exhibit notable performance drops when applied to experimental measurements. To address these issues, we build NMRSpec, a large-scale corpus of experimental $^1$H and $^{13}$C spectra mined from chemical literature, and propose NMRTrans, which models spectra as unordered peak sets and aligns the model's inductive bias with the physical nature of NMR. To our best knowledge, NMRTrans is the first NMR Transformer trained solely on large-scale experimental spectra and achieves state-of-the-art performance on experimental benchmarks, improving Top-10 Accuracy over the strongest baseline by +17.82 points (61.15% vs. 43.33%), and underscoring the importance of experimental data and structure-aware architectures for reliable NMR structure elucidation.",
      "authors": [
        "Liujia Yang",
        "Zhuo Yang",
        "Jiaqing Xie",
        "Yubin Wang",
        "Ben Gao",
        "Tianfan Fu",
        "Xingjian Wei",
        "Jiaxing Sun",
        "Jiang Wu",
        "Conghui He",
        "Yuqiang Li",
        "Qinying Gu"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph",
        "cs.AI"
      ],
      "published": "2026-02-10 03:37:41+00:00",
      "link": "https://arxiv.org/pdf/2602.10158v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09374v1",
      "title": "Surrogate-Guided Quantum Discovery in Black-Box Landscapes with Latent-Quadratic Interaction Embedding Transformers",
      "abstract": "Discovering configurations that are both high-utility and structurally diverse under expensive black-box evaluation and strict query budgets remains a central challenge in data-driven discovery. Many classical optimizers concentrate on dominant modes, while quality-diversity methods require large evaluation budgets to populate high-dimensional archives. Quantum Approximate Optimization Algorithm (QAOA) provides distributional sampling but requires an explicit problem Hamiltonian, which is unavailable in black-box settings. Practical quantum circuits favor quadratic Hamiltonians since higher-order interaction terms are costly to realize. Learned quadratic surrogates such as Factorization Machines (FM) have been used as proxies, but are limited to pairwise structure. We extend this surrogate-to-Hamiltonian approach by modelling higher-order variable dependencies via self-attention and projects them into a valid Positive Semi-Definite quadratic form compatible with QAOA. This enables diversity-oriented quantum sampling from learned energy landscapes while capturing interaction structure beyond pairwise terms. We evaluate on risk discovery for enterprise document processing systems against diverse classical optimizers. Quantum-guided samplers achieve competitive utility while consistently improving structural diversity and exclusive discovery. FM surrogates provide stronger early coverage, whereas ours yields higher-fidelity surrogate landscapes and better extreme-case discovery. Our method recovers roughly twice as many structurally tail-risk outliers as most classical baselines and identify an exclusive non-overlapping fraction of high-utility configurations not found by competing methods, highlighting that an effective mechanism for learning higher-order interaction structure and projecting it into quadratic surrogate Hamiltonians for quantum-assisted black-box discovery.",
      "authors": [
        "Saisubramaniam Gopalakrishnan",
        "Dagnachew Birru"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "published": "2026-02-10 03:32:23+00:00",
      "link": "https://arxiv.org/pdf/2602.09374v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09370v1",
      "title": "Phase-Aware Policy Learning for Skateboard Riding of Quadruped Robots via Feature-wise Linear Modulation",
      "abstract": "Skateboards offer a compact and efficient means of transportation as a type of personal mobility device. However, controlling them with legged robots poses several challenges for policy learning due to perception-driven interactions and multi-modal control objectives across distinct skateboarding phases. To address these challenges, we introduce Phase-Aware Policy Learning (PAPL), a reinforcement-learning framework tailored for skateboarding with quadruped robots. PAPL leverages the cyclic nature of skateboarding by integrating phase-conditioned Feature-wise Linear Modulation layers into actor and critic networks, enabling a unified policy that captures phase-dependent behaviors while sharing robot-specific knowledge across phases. Our evaluations in simulation validate command-tracking accuracy and conduct ablation studies quantifying each component's contribution. We also compare locomotion efficiency against leg and wheel-leg baselines and show real-world transferability.",
      "authors": [
        "Minsung Yoon",
        "Jeil Jeong",
        "Sung-Eui Yoon"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-10 03:20:37+00:00",
      "link": "https://arxiv.org/pdf/2602.09370v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09367v1",
      "title": "CAPER: Constrained and Procedural Reasoning for Robotic Scientific Experiments",
      "abstract": "Robotic assistance in scientific laboratories requires procedurally correct long-horizon manipulation, reliable execution under limited supervision, and robustness in low-demonstration regimes. Such conditions greatly challenge end-to-end vision-language-action (VLA) models, whose assumptions of recoverable errors and data-driven policy learning often break down in protocol-sensitive experiments. We propose CAPER, a framework for Constrained And ProcEdural Reasoning for robotic scientific experiments, which explicitly restricts where learning and reasoning occur in the planning and control pipeline. Rather than strengthening end-to-end policies, CAPER enforces a responsibility-separated structure: task-level reasoning generates procedurally valid action sequences under explicit constraints, mid-level multimodal grounding realizes subtasks without delegating spatial decision-making to large language models, and low-level control adapts to physical uncertainty via reinforcement learning with minimal demonstrations. By encoding procedural commitments through interpretable intermediate representations, CAPER prevents execution-time violations of experimental logic, improving controllability, robustness, and data efficiency. Experiments on a scientific workflow benchmark and a public long-horizon manipulation dataset demonstrate consistent improvements in success rate and procedural correctness, particularly in low-data and long-horizon settings.",
      "authors": [
        "Jinghan Yang",
        "Jingyi Hou",
        "Xinbo Yu",
        "Wei He",
        "Yifan Wu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-10 03:18:41+00:00",
      "link": "https://arxiv.org/pdf/2602.09367v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09355v1",
      "title": "Impact of domain adaptation in deep learning for medical image classifications",
      "abstract": "Domain adaptation (DA) is a quickly expanding area in machine learning that involves adjusting a model trained in one domain to perform well in another domain. While there have been notable progressions, the fundamental concept of numerous DA methodologies has persisted: aligning the data from various domains into a shared feature space. In this space, knowledge acquired from labeled source data can improve the model training on target data that lacks sufficient labels. In this study, we demonstrate the use of 10 deep learning models to simulate common DA techniques and explore their application in four medical image datasets. We have considered various situations such as multi-modality, noisy data, federated learning (FL), interpretability analysis, and classifier calibration. The experimental results indicate that using DA with ResNet34 in a brain tumor (BT) data set results in an enhancement of 4.7\\% in model performance. Similarly, the use of DA can reduce the impact of Gaussian noise, as it provides $\\sim 3\\%$ accuracy increase using ResNet34 on a BT dataset. Furthermore, simply introducing DA into FL framework shows limited potential (e.g., $\\sim 0.3\\%$ increase in performance) for skin cancer classification. In addition, the DA method can improve the interpretability of the models using the gradcam++ technique, which offers clinical values. Calibration analysis also demonstrates that using DA provides a lower expected calibration error (ECE) value $\\sim 2\\%$ compared to CNN alone on a multi-modality dataset.",
      "authors": [
        "Yihang Wu",
        "Ahmad Chaddad"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 02:59:03+00:00",
      "link": "https://arxiv.org/pdf/2602.09355v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09343v1",
      "title": "Not-in-Perspective: Towards Shielding Google's Perspective API Against Adversarial Negation Attacks",
      "abstract": "The rise of cyberbullying in social media platforms involving toxic comments has escalated the need for effective ways to monitor and moderate online interactions. Existing solutions of automated toxicity detection systems, are based on a machine or deep learning algorithms. However, statistics-based solutions are generally prone to adversarial attacks that contain logic based modifications such as negation in phrases and sentences. In that regard, we present a set of formal reasoning-based methodologies that wrap around existing machine learning toxicity detection systems. Acting as both pre-processing and post-processing steps, our formal reasoning wrapper helps alleviating the negation attack problems and significantly improves the accuracy and efficacy of toxicity scoring. We evaluate different variations of our wrapper on multiple machine learning models against a negation adversarial dataset. Experimental results highlight the improvement of hybrid (formal reasoning and machine-learning) methods against various purely statistical solutions.",
      "authors": [
        "Michail S. Alexiou",
        "J. Sukarno Mertoguno"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-10 02:27:28+00:00",
      "link": "https://arxiv.org/pdf/2602.09343v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09333v1",
      "title": "XMap: Fast Internet-wide IPv4 and IPv6 Network Scanner",
      "abstract": "XMap is an open-source network scanner designed for performing fast Internet-wide IPv4 and IPv6 network research scanning. XMap was initially developed as the research artifact of a paper published at 2021 IEEE/IFIP International Conference on Dependable Systems and Networks (DSN '21) and then made available on GitHub. XMap is the first tool to support fast Internet-wide IPv6 network scanning in 2020. During the last five years, XMap has made substantial impact in academia, industry, and government. It has been referenced in 52 research papers (15 published at top-tier security venues and 11 in leading networking societies), received over 450 GitHub stars, featured in multiple news outlets, and deployed or recommended by international companies up to date. Additionally, XMap has contributed to the implementation of RFC documents and the discovery of various vulnerabilities. This paper provides fundamental details about XMap, its architecture, and its impact.",
      "authors": [
        "Xiang Li",
        "Zixuan Xie",
        "Lu Sun",
        "Yuqi Qiu",
        "Zuyao Xu",
        "Zheli Liu"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.NI"
      ],
      "published": "2026-02-10 02:06:48+00:00",
      "link": "https://arxiv.org/pdf/2602.09333v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09325v1",
      "title": "Architectural Foundations for Checkpointing and Restoration in Quantum HPC Systems",
      "abstract": "In this work, we explore the design of the checkpointing and restoration for quantum HPC that leverages dynamic circuit technology to enable restartable and resilient quantum execution. Rather than attempting to checkpoint quantum states, our approach redefines checkpointing as a control flow and algorithmic state problem. By exploiting mid-circuit measurements, classical feed forward, and conditional execution supported by dynamic circuits, we capture sufficient program state to allow correct restoration of quantum workflows after interruption or failure. This design aligns naturally with iterative and staged quantum algorithms such as variational eigensolvers, quantum approximate optimization, and time-stepping methods commonly used in quantum simulation and scientific computing.",
      "authors": [
        "Qiang Guan",
        "Qinglei Cao",
        "Xiaoyi Lu",
        "Siyuan Niu"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.DC"
      ],
      "published": "2026-02-10 01:37:58+00:00",
      "link": "https://arxiv.org/pdf/2602.09325v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09324v1",
      "title": "Deep Modeling and Interpretation for Bladder Cancer Classification",
      "abstract": "Deep models based on vision transformer (ViT) and convolutional neural network (CNN) have demonstrated remarkable performance on natural datasets. However, these models may not be similar in medical imaging, where abnormal regions cover only a small portion of the image. This challenge motivates this study to investigate the latest deep models for bladder cancer classification tasks. We propose the following to evaluate these deep models: 1) standard classification using 13 models (four CNNs and eight transormer-based models), 2) calibration analysis to examine if these models are well calibrated for bladder cancer classification, and 3) we use GradCAM++ to evaluate the interpretability of these models for clinical diagnosis. We simulate $\\sim 300$ experiments on a publicly multicenter bladder cancer dataset, and the experimental results demonstrate that the ConvNext series indicate limited generalization ability to classify bladder cancer images (e.g., $\\sim 60\\%$ accuracy). In addition, ViTs show better calibration effects compared to ConvNext and swin transformer series. We also involve test time augmentation to improve the models interpretability. Finally, no model provides a one-size-fits-all solution for a feasible interpretable model. ConvNext series are suitable for in-distribution samples, while ViT and its variants are suitable for interpreting out-of-distribution samples.",
      "authors": [
        "Ahmad Chaddad",
        "Yihang Wu",
        "Xianrui Chen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-10 01:35:12+00:00",
      "link": "https://arxiv.org/pdf/2602.09324v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09321v1",
      "title": "Performance Comparison of CNN and AST Models with Stacked Features for Environmental Sound Classification",
      "abstract": "Environmental sound classification (ESC) has gained significant attention due to its diverse applications in smart city monitoring, fault detection, acoustic surveillance, and manufacturing quality control. To enhance CNN performance, feature stacking techniques have been explored to aggregate complementary acoustic descriptors into richer input representations. In this paper, we investigate CNN-based models employing various stacked feature combinations, including Log-Mel Spectrogram (LM), Spectral Contrast (SPC), Chroma (CH), Tonnetz (TZ), Mel-Frequency Cepstral Coefficients (MFCCs), and Gammatone Cepstral Coefficients (GTCC). Experiments are conducted on the widely used ESC-50 and UrbanSound8K datasets under different training regimes, including pretraining on ESC-50, fine-tuning on UrbanSound8K, and comparison with Audio Spectrogram Transformer (AST) models pretrained on large-scale corpora such as AudioSet. This experimental design enables an analysis of how feature-stacked CNNs compare with transformer-based models under varying levels of training data and pretraining diversity. The results indicate that feature-stacked CNNs offer a more computationally and data-efficient alternative when large-scale pretraining or extensive training data are unavailable, making them particularly well suited for resource-constrained and edge-level sound classification scenarios.",
      "authors": [
        "Parinaz Binandeh Dehaghania",
        "Danilo Penab",
        "A. Pedro Aguiar"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.SD"
      ],
      "published": "2026-02-10 01:28:14+00:00",
      "link": "https://arxiv.org/pdf/2602.09321v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09319v2",
      "title": "Benchmarking Knowledge-Extraction Attack and Defense on Retrieval-Augmented Generation",
      "abstract": "Retrieval-Augmented Generation (RAG) has become a cornerstone of knowledge-intensive applications, including enterprise chatbots, healthcare assistants, and agentic memory management. However, recent studies show that knowledge-extraction attacks can recover sensitive knowledge-base content through maliciously crafted queries, raising serious concerns about intellectual property theft and privacy leakage. While prior work has explored individual attack and defense techniques, the research landscape remains fragmented, spanning heterogeneous retrieval embeddings, diverse generation models, and evaluations based on non-standardized metrics and inconsistent datasets. To address this gap, we introduce the first systematic benchmark for knowledge-extraction attacks on RAG systems. Our benchmark covers a broad spectrum of attack and defense strategies, representative retrieval embedding models, and both open- and closed-source generators, all evaluated under a unified experimental framework with standardized protocols across multiple datasets. By consolidating the experimental landscape and enabling reproducible, comparable evaluation, this benchmark provides actionable insights and a practical foundation for developing privacy-preserving RAG systems in the face of emerging knowledge extraction threats. Our code is available here.",
      "authors": [
        "Zhisheng Qi",
        "Utkarsh Sahu",
        "Li Ma",
        "Haoyu Han",
        "Ryan Rossi",
        "Franck Dernoncourt",
        "Mahantesh Halappanavar",
        "Nesreen Ahmed",
        "Yushun Dong",
        "Yue Zhao",
        "Yu Zhang",
        "Yu Wang"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-10 01:27:46+00:00",
      "link": "https://arxiv.org/pdf/2602.09319v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09318v1",
      "title": "GAFR-Net: A Graph Attention and Fuzzy-Rule Network for Interpretable Breast Cancer Image Classification",
      "abstract": "Accurate classification of breast cancer histopathology images is pivotal for early oncological diagnosis and therapeutic intervention.However, conventional deep learning architectures often encounter performance degradation under limited annotations and suffer from a \"blackbox\" nature, hindering their clinical integration. To mitigate these limitations, we propose GAFRNet, a robust and interpretable Graph Attention and FuzzyRule Network specifically engineered for histopathology image classification with scarce supervision. GAFRNet constructs a similarity-driven graph representation to model intersample relationships and employs a multihead graph attention mechanism to capture complex relational features across heterogeneous tissue structures.Concurrently, a differentiable fuzzy-rule module encodes intrinsic topological descriptorsincluding node degree, clustering coefficient, and label consistencyinto explicit, human-understandable diagnostic logic. This design establishes transparent \"IF-THEN\" mappings that mimic the heuristic deduction process of medical experts, providing clear reasoning behind each prediction without relying on post-hoc attribution methods. Extensive evaluations on three benchmark datasets (BreakHis, Mini-DDSM, and ICIAR2018) demonstrate that GAFR-Net consistently outperforms various state-of-the-art methods across multiple magnifications and classification tasks. These results validate the superior generalization and practical utility of GAFR-Net as a reliable decision-support tool for weakly supervised medical image analysis.",
      "authors": [
        "Lin-Guo Gao",
        "Suxing Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-10 01:25:57+00:00",
      "link": "https://arxiv.org/pdf/2602.09318v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09317v1",
      "title": "SnareNet: Flexible Repair Layers for Neural Networks with Hard Constraints",
      "abstract": "Neural networks are increasingly used as surrogate solvers and control policies, but unconstrained predictions can violate physical, operational, or safety requirements. We propose SnareNet, a feasibility-controlled architecture for learning mappings whose outputs must satisfy input-dependent nonlinear constraints. SnareNet appends a differentiable repair layer that navigates in the constraint map's range space, steering iterates toward feasibility and producing a repaired output that satisfies constraints to a user-specified tolerance. To stabilize end-to-end training, we introduce adaptive relaxation, which designs a relaxed feasible set that snares the neural network at initialization and shrinks it into the feasible set, enabling early exploration and strict feasibility later in training. On optimization-learning and trajectory planning benchmarks, SnareNet consistently attains improved objective quality while satisfying constraints more reliably than prior work.",
      "authors": [
        "Ya-Chi Chu",
        "Alkiviades Boukas",
        "Madeleine Udell"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-02-10 01:24:32+00:00",
      "link": "https://arxiv.org/pdf/2602.09317v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09316v2",
      "title": "Effective MoE-based LLM Compression by Exploiting Heterogeneous Inter-Group Experts Routing Frequency and Information Density",
      "abstract": "Mixture-of-Experts (MoE) based Large Language Models (LLMs) have achieved superior performance, yet the massive memory overhead caused by storing multiple expert networks severely hinders their practical deployment. Singular Value Decomposition (SVD)-based compression has emerged as a promising post-training technique; however, most existing methods apply uniform rank allocation or rely solely on static weight properties. This overlooks the substantial heterogeneity in expert utilization observed in MoE models, where frequent routing patterns and intrinsic information density vary significantly across experts. In this work, we propose RFID-MoE, an effective framework for MoE compression by exploiting heterogeneous Routing Frequency and Information Density. We first introduce a fused metric that combines expert activation frequency with effective rank to measure expert importance, adaptively allocating higher ranks to critical expert groups under a fixed budget. Moreover, instead of discarding compression residuals, we reconstruct them via a parameter-efficient sparse projection mechanism to recover lost information with minimal parameter overhead. Extensive experiments on representative MoE LLMs (e.g., Qwen3, DeepSeekMoE) across multiple compression ratios demonstrate that RFID-MoE consistently outperforms state-of-the-art methods like MoBE and D2-MoE. Notably, RFID-MoE achieves a perplexity of 16.92 on PTB with the Qwen3-30B model at a 60% compression ratio, reducing perplexity by over 8.0 compared to baselines, and improves zero-shot accuracy on HellaSwag by approximately 8%.",
      "authors": [
        "Zhendong Mi",
        "Yixiao Chen",
        "Pu Zhao",
        "Xiaodong Yu",
        "Hao Wang",
        "Yanzhi Wang",
        "Shaoyi Huang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 01:24:28+00:00",
      "link": "https://arxiv.org/pdf/2602.09316v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09315v1",
      "title": "A Deep Multi-Modal Method for Patient Wound Healing Assessment",
      "abstract": "Hospitalization of patients is one of the major factors for high wound care costs. Most patients do not acquire a wound which needs immediate hospitalization. However, due to factors such as delay in treatment, patient's non-compliance or existing co-morbid conditions, an injury can deteriorate and ultimately lead to patient hospitalization. In this paper, we propose a deep multi-modal method to predict the patient's risk of hospitalization. Our goal is to predict the risk confidently by collectively using the wound variables and wound images of the patient. Existing works in this domain have mainly focused on healing trajectories based on distinct wound types. We developed a transfer learning-based wound assessment solution, which can predict both wound variables from wound images and their healing trajectories, which is our primary contribution. We argue that the development of a novel model can help in early detection of the complexities in the wound, which might affect the healing process and also reduce the time spent by a clinician to diagnose the wound.",
      "authors": [
        "Subba Reddy Oota",
        "Vijay Rowtula",
        "Shahid Mohammed",
        "Jeffrey Galitz",
        "Minghsun Liu",
        "Manish Gupta"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-10 01:21:32+00:00",
      "link": "https://arxiv.org/pdf/2602.09315v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10156v1",
      "title": "STRAND: Sequence-Conditioned Transport for Single-Cell Perturbations",
      "abstract": "Predicting how genetic perturbations change cellular state is a core problem for building controllable models of gene regulation. Perturbations targeting the same gene can produce different transcriptional responses depending on their genomic locus, including different transcription start sites and regulatory elements. Gene-level perturbation models collapse these distinct interventions into the same representation.   We introduce STRAND, a generative model that predicts single-cell transcriptional responses by conditioning on regulatory DNA sequence. STRAND represents a perturbation by encoding the sequence at its genomic locus and uses this representation to parameterize a conditional transport process from control to perturbed cell states. Representing perturbations by sequence, rather than by a fixed set of gene identifiers, supports zero-shot inference at loci not seen during training and expands inference-time genomic coverage from ~1.5% for gene-level single-cell foundation models to ~95% of the genome.   We evaluate STRAND on CRISPR perturbation datasets in K562, Jurkat, and RPE1 cells. STRAND improves discrimination scores by up to 33% in low-sample regimes, achieves the best average rank on unseen gene perturbation benchmarks, and improves transfer to novel cell lines by up to 0.14 in Pearson correlation. Ablations isolate the gains to sequence conditioning and transport, and case studies show that STRAND resolves functionally alternative transcription start sites missed by gene-level models.",
      "authors": [
        "Boyang Fu",
        "George Dasoulas",
        "Sameer Gabbita",
        "Xiang Lin",
        "Shanghua Gao",
        "Xiaorui Su",
        "Soumya Ghosh",
        "Marinka Zitnik"
      ],
      "primary_category": "q-bio.GN",
      "categories": [
        "q-bio.GN",
        "cs.LG",
        "q-bio.CB"
      ],
      "published": "2026-02-10 00:57:38+00:00",
      "link": "https://arxiv.org/pdf/2602.10156v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09305v1",
      "title": "Reward Modeling for Reinforcement Learning-Based LLM Reasoning: Design, Challenges, and Evaluation",
      "abstract": "Large Language Models (LLMs) demonstrate transformative potential, yet their reasoning remains inconsistent and unreliable. Reinforcement learning (RL)-based fine-tuning is a key mechanism for improvement, but its effectiveness is fundamentally governed by reward design. Despite its importance, the relationship between reward modeling and core LLM challenges--such as evaluation bias, hallucination, distribution shift, and efficient learning--remains poorly understood. This work argues that reward modeling is not merely an implementation detail but a central architect of reasoning alignment, shaping what models learn, how they generalize, and whether their outputs can be trusted. We introduce Reasoning-Aligned Reinforcement Learning (RARL), a unifying framework that systematizes diverse reward paradigms for multi-step reasoning. Within this framework, we present a taxonomy of reward mechanisms, analyze reward hacking as a pervasive failure mode, and examine how reward signals unify challenges ranging from inference-time scaling to hallucination mitigation. We further critically evaluate existing benchmarks, highlighting vulnerabilities such as data contamination and reward misalignment, and outline directions for more robust evaluation. By integrating fragmented research threads and clarifying the interplay between reward design and fundamental reasoning capabilities, this work provides a foundational roadmap for building reasoning models that are robust, verifiable, and trustworthy.",
      "authors": [
        "Pei-Chi Pan",
        "Yingbin Liang",
        "Sen Lin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 00:45:24+00:00",
      "link": "https://arxiv.org/pdf/2602.09305v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09303v1",
      "title": "Stabilizing Physics-Informed Consistency Models via Structure-Preserving Training",
      "abstract": "We propose a physics-informed consistency modeling framework for solving partial differential equations (PDEs) via fast, few-step generative inference. We identify a key stability challenge in physics-constrained consistency training, where PDE residuals can drive the model toward trivial or degenerate solutions, degrading the learned data distribution. To address this, we introduce a structure-preserving two-stage training strategy that decouples distribution learning from physics enforcement by freezing the coefficient decoder during physics-informed fine-tuning. We further propose a two-step residual objective that enforces physical consistency on refined, structurally valid generative trajectories rather than noisy single-step predictions. The resulting framework enables stable, high-fidelity inference for both unconditional generation and forward problems. We demonstrate that forward solutions can be obtained via a projection-based zero-shot inpainting procedure, achieving consistent accuracy of diffusion baselines with orders of magnitude reduction in computational cost.",
      "authors": [
        "Che-Chia Chang",
        "Chen-Yang Dai",
        "Te-Sheng Lin",
        "Ming-Chih Lai",
        "Chieh-Hsin Lai"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.NA"
      ],
      "published": "2026-02-10 00:40:19+00:00",
      "link": "https://arxiv.org/pdf/2602.09303v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09300v1",
      "title": "Risk-sensitive reinforcement learning using expectiles, shortfall risk and optimized certainty equivalent risk",
      "abstract": "We propose risk-sensitive reinforcement learning algorithms catering to three families of risk measures, namely expectiles, utility-based shortfall risk and optimized certainty equivalent risk. For each risk measure, in the context of a finite horizon Markov decision process, we first derive a policy gradient theorem. Second, we propose estimators of the risk-sensitive policy gradient for each of the aforementioned risk measures, and establish $\\mathcal{O}\\left(1/m\\right)$ mean-squared error bounds for our estimators, where $m$ is the number of trajectories. Further, under standard assumptions for policy gradient-type algorithms, we establish smoothness of the risk-sensitive objective, in turn leading to stationary convergence rate bounds for the overall risk-sensitive policy gradient algorithm that we propose. Finally, we conduct numerical experiments to validate the theoretical findings on popular RL benchmarks.",
      "authors": [
        "Sumedh Gupte",
        "Shrey Rakeshkumar Patel",
        "Soumen Pachal",
        "Prashanth L. A.",
        "Sanjay P. Bhat"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 00:38:21+00:00",
      "link": "https://arxiv.org/pdf/2602.09300v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09299v1",
      "title": "Synthetic Reflections on Resource Extraction",
      "abstract": "This paper describes how AI models can be augmented and adapted to produce interpretation of landscapes. We describe the technical framework of a Sentinel-2 satellite asset interpretation pipeline that combines statistical operations, human judgement, and generative AI models to create succinct commentaries on industrial mining sites across the planet, documenting a past shared between people and AI systems.",
      "authors": [
        "Sai Krishna Tammali",
        "Vinaya Kumar",
        "Marc Böhlen"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "published": "2026-02-10 00:38:04+00:00",
      "link": "https://arxiv.org/pdf/2602.09299v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09297v1",
      "title": "The Laplacian Mechanism Improves Transformers by Reshaping Token Geometry",
      "abstract": "Transformers leverage attention, the residual connection, and layer normalization to control the variance of token representations. We propose to modify attention into a Laplacian mechanism that gives the model more direct control over token variance. We conjecture that this helps transformers achieve the ideal token geometry. To investigate our conjecture, we first show that incorporating the Laplacian mechanism into transformers induces consistent improvements across benchmarks in computer vision and language. Next, we study how the Laplacian mechanism impacts the geometry of token representations using various tools: 1) principal component analysis, 2) cosine similarity metric, 3) analysis of variance, and 4) Neural Collapse metrics. Our investigation shows that the Laplacian mechanism reshapes token embeddings toward a geometry of maximal separability: tokens collapse according to their classes, and the class means exhibit Neural Collapse.",
      "authors": [
        "Yuchong Zhang",
        "Vardan Papyan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 00:27:45+00:00",
      "link": "https://arxiv.org/pdf/2602.09297v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13307v1",
      "title": "Cooperative Edge Caching with Large Language Model in Wireless Networks",
      "abstract": "Cooperative edge caching in overlapping zones creates intricate coupling among Base Station (BS) decisions, making content replacement highly sensitive to topology and temporal reuse. While heuristics are often myopic and Deep Reinforcement Learning lacks robustness under dynamics, this paper proposes a Large Language Model (LLM)-based multi-BS orchestrator. The LLM acts as the sole autonomous engine, interacting with the environment via a validated text-to-action interface. Each time slot, the system renders environmental states -- including cache inventories and frequency statistics -- into prompts, parsing LLM-generated decisions against strict feasibility constraints. We align the model through a two-stage paradigm: Supervised Fine-Tuning on oracle trajectories for syntax and initialization, followed by Group Relative Policy Optimization. The latter employs an ``opportunity-aware'' reward that prioritizes multi-step cooperative gains relative to a No-Operation baseline. Evaluated on identical request traces, the orchestrator approaches exhaustive-search performance (0.610 vs.\\ 0.617 in a 5-BS scenario), outperforms classical baselines (e.g., +4.1\\% over least-frequently used), and demonstrates robust zero-shot transfer across varying cache capacities, library sizes, and user densities.",
      "authors": [
        "Ning Yang",
        "Wentao Wang",
        "Lingtao Ouyang",
        "Haijun Zhang"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-02-10 00:15:58+00:00",
      "link": "https://arxiv.org/pdf/2602.13307v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09288v1",
      "title": "Measuring Privacy Risks and Tradeoffs in Financial Synthetic Data Generation",
      "abstract": "We explore the privacy-utility tradeoff of synthetic data generation schemes on tabular financial datasets, a domain characterized by high regulatory risk and severe class imbalance. We consider representative tabular data generators, including autoencoders, generative adversarial networks, diffusion, and copula synthesizers. To address the challenges of the financial domain, we provide novel privacy-preserving implementations of GAN and autoencoder synthesizers. We evaluate whether and how well the generators simultaneously achieve data quality, downstream utility, and privacy, with comparison across balanced and imbalanced input datasets. Our results offer insight into the distinct challenges of generating synthetic data from datasets that exhibit severe class imbalance and mixed-type attributes.",
      "authors": [
        "Michael Zuo",
        "Inwon Kang",
        "Stacy Patterson",
        "Oshani Seneviratne"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-10 00:14:19+00:00",
      "link": "https://arxiv.org/pdf/2602.09288v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09278v1",
      "title": "The effect of whitening on explanation performance",
      "abstract": "Explainable Artificial Intelligence (XAI) aims to provide transparent insights into machine learning models, yet the reliability of many feature attribution methods remains a critical challenge. Prior research (Haufe et al., 2014; Wilming et al., 2022, 2023) has demonstrated that these methods often erroneously assign significant importance to non-informative variables, such as suppressor variables, leading to fundamental misinterpretations. Since statistical suppression is induced by feature dependencies, this study investigates whether data whitening, a common preprocessing technique for decorrelation, can mitigate such errors. Using the established XAI-TRIS benchmark (Clark et al., 2024b), which offers synthetic ground-truth data and quantitative measures of explanation correctness, we empirically evaluate 16 popular feature attribution methods applied in combination with 5 distinct whitening transforms. Additionally, we analyze a minimal linear two-dimensional classification problem (Wilming et al., 2023) to theoretically assess whether whitening can remove the impact of suppressor features from Bayes-optimal models. Our results indicate that, while specific whitening techniques can improve explanation performance, the degree of improvement varies substantially across XAI methods and model architectures. These findings highlight the complex relationship between data non-linearities, preprocessing quality, and attribution fidelity, underscoring the vital role of pre-processing techniques in enhancing model interpretability.",
      "authors": [
        "Benedict Clark",
        "Stoyan Karastoyanov",
        "Rick Wilming",
        "Stefan Haufe"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-09 23:41:57+00:00",
      "link": "https://arxiv.org/pdf/2602.09278v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09270v1",
      "title": "Collective Behavior of AI Agents: the Case of Moltbook",
      "abstract": "We present a large scale data analysis of Moltbook, a Reddit-style social media platform exclusively populated by AI agents. Analyzing over 369,000 posts and 3.0 million comments from approximately 46,000 active agents, we find that AI collective behavior exhibits many of the same statistical regularities observed in human online communities: heavy-tailed distributions of activity, power-law scaling of popularity metrics, and temporal decay patterns consistent with limited attention dynamics. However, we also identify key differences, including a sublinear relationship between upvotes and discussion size that contrasts with human behavior. These findings suggest that, while individual AI agents may differ fundamentally from humans, their emergent collective dynamics share structural similarities with human social systems.",
      "authors": [
        "Giordano De Marzo",
        "David Garcia"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph",
        "cs.CL",
        "cs.MA"
      ],
      "published": "2026-02-09 23:10:34+00:00",
      "link": "https://arxiv.org/pdf/2602.09270v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09252v1",
      "title": "VLM-Guided Iterative Refinement for Surgical Image Segmentation with Foundation Models",
      "abstract": "Surgical image segmentation is essential for robot-assisted surgery and intraoperative guidance. However, existing methods are constrained to predefined categories, produce one-shot predictions without adaptive refinement, and lack mechanisms for clinician interaction. We propose IR-SIS, an iterative refinement system for surgical image segmentation that accepts natural language descriptions. IR-SIS leverages a fine-tuned SAM3 for initial segmentation, employs a Vision-Language Model to detect instruments and assess segmentation quality, and applies an agentic workflow that adaptively selects refinement strategies. The system supports clinician-in-the-loop interaction through natural language feedback. We also construct a multi-granularity language-annotated dataset from EndoVis2017 and EndoVis2018 benchmarks. Experiments demonstrate state-of-the-art performance on both in-domain and out-of-distribution data, with clinician interaction providing additional improvements. Our work establishes the first language-based surgical segmentation framework with adaptive self-refinement capabilities.",
      "authors": [
        "Ange Lou",
        "Yamin Li",
        "Qi Chang",
        "Nan Xi",
        "Luyuan Xie",
        "Zichao Li",
        "Tianyu Luan"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-02-09 22:36:36+00:00",
      "link": "https://arxiv.org/pdf/2602.09252v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10155v1",
      "title": "A Systematic Review on Data-Driven Brain Deformation Modeling for Image-Guided Neurosurgery",
      "abstract": "Accurate compensation of brain deformation is a critical challenge for reliable image-guided neurosurgery, as surgical manipulation and tumor resection induce tissue motion that misaligns preoperative planning images with intraoperative anatomy and longitudinal studies. In this systematic review, we synthesize recent AI-driven approaches developed between January 2020 and April 2025 for modeling and correcting brain deformation. A comprehensive literature search was conducted in PubMed, IEEE Xplore, Scopus, and Web of Science, with predefined inclusion and exclusion criteria focused on computational methods applied to brain deformation compensation for neurosurgical imaging, resulting in 41 studies meeting these criteria. We provide a unified analysis of methodological strategies, including deep learning-based image registration, direct deformation field regression, synthesis-driven multimodal alignment, resection-aware architectures addressing missing correspondences, and hybrid models that integrate biomechanical priors. We also examine dataset utilization, reported evaluation metrics, validation protocols, and how uncertainty and generalization have been assessed across studies. While AI-based deformation models demonstrate promising performance and computational efficiency, current approaches exhibit limitations in out-of-distribution robustness, standardized benchmarking, interpretability, and readiness for clinical deployment. Our review highlights these gaps and outlines opportunities for future research aimed at achieving more robust, generalizable, and clinically translatable deformation compensation solutions for neurosurgical guidance. By organizing recent advances and critically evaluating evaluation practices, this work provides a comprehensive foundation for researchers and clinicians engaged in developing and applying AI-based brain deformation methods.",
      "authors": [
        "Tiago Assis",
        "Colin P. Galvin",
        "Joshua P. Castillo",
        "Nazim Haouchine",
        "Marta Kersten-Oertel",
        "Zeyu Gao",
        "Mireia Crispin-Ortuzar",
        "Stephen J. Price",
        "Thomas Santarius",
        "Yangming Ou",
        "Sarah Frisken",
        "Nuno C. Garcia",
        "Alexandra J. Golby",
        "Reuben Dorent",
        "Ines P. Machado"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "published": "2026-02-09 22:11:56+00:00",
      "link": "https://arxiv.org/pdf/2602.10155v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09238v3",
      "title": "Feature salience - not task-informativeness - drives machine learning model explanations",
      "abstract": "Explainable AI (XAI) promises to provide insight into machine learning models' decision processes, where one goal is to identify failures such as shortcut learning. This promise relies on the field's assumption that input features marked as important by an XAI must contain information about the target variable. However, it is unclear whether informativeness is indeed the main driver of importance attribution in practice, or if other data properties such as statistical suppression, novelty at test-time, or high feature salience substantially contribute. To clarify this, we trained deep learning models on three variants of a binary image classification task, in which translucent watermarks are either absent, act as class-dependent confounds, or represent class-independent noise. Results for five popular attribution methods show substantially elevated relative importance in watermarked areas (RIW) for all models regardless of the training setting ($R^2 \\geq .45$). By contrast, whether the presence of watermarks is class-dependent or not only has a marginal effect on RIW ($R^2 \\leq .03$), despite a clear impact impact on model performance and generalisation ability. XAI methods show similar behaviour to model-agnostic edge detection filters and attribute substantially less importance to watermarks when bright image intensities are encoded by smaller instead of larger feature values. These results indicate that importance attribution is most strongly driven by the salience of image structures at test time rather than statistical associations learned by machine learning models. Previous studies demonstrating successful XAI application should be reevaluated with respect to a possibly spurious concurrency of feature salience and informativeness, and workflows using feature attribution methods as building blocks should be scrutinised.",
      "authors": [
        "Benedict Clark",
        "Marta Oliveira",
        "Rick Wilming",
        "Stefan Haufe"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-09 22:07:59+00:00",
      "link": "https://arxiv.org/pdf/2602.09238v3",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09234v1",
      "title": "Do Neural Networks Lose Plasticity in a Gradually Changing World?",
      "abstract": "Continual learning has become a trending topic in machine learning. Recent studies have discovered an interesting phenomenon called loss of plasticity, referring to neural networks gradually losing the ability to learn new tasks. However, existing plasticity research largely relies on contrived settings with abrupt task transitions, which often do not reflect real-world environments. In this paper, we propose to investigate a gradually changing environment, and we simulate this by input/output interpolation and task sampling. We perform theoretical and empirical analysis, showing that the loss of plasticity is an artifact of abrupt tasks changes in the environment and can be largely mitigated if the world changes gradually.",
      "authors": [
        "Tianhui Liu",
        "Lili Mou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-09 22:01:50+00:00",
      "link": "https://arxiv.org/pdf/2602.09234v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09225v1",
      "title": "Barycentric alignment for instance-level comparison of neural representations",
      "abstract": "Comparing representations across neural networks is challenging because representations admit symmetries, such as arbitrary reordering of units or rotations of activation space, that obscure underlying equivalence between models. We introduce a barycentric alignment framework that quotients out these nuisance symmetries to construct a universal embedding space across many models. Unlike existing similarity measures, which summarize relationships over entire stimulus sets, this framework enables similarity to be defined at the level of individual stimuli, revealing inputs that elicit convergent versus divergent representations across models. Using this instance-level notion of similarity, we identify systematic input properties that predict representational convergence versus divergence across vision and language model families. We also construct universal embedding spaces for brain representations across individuals and cortical regions, enabling instance-level comparison of representational agreement across stages of the human visual hierarchy. Finally, we apply the same barycentric alignment framework to purely unimodal vision and language models and find that post-hoc alignment into a shared space yields image text similarity scores that closely track human cross-modal judgments and approach the performance of contrastively trained vision-language models. This strikingly suggests that independently learned representations already share sufficient geometric structure for human-aligned cross-modal comparison. Together, these results show that resolving representational similarity at the level of individual stimuli reveals phenomena that cannot be detected by set-level comparison metrics.",
      "authors": [
        "Shreya Saha",
        "Zoe Wanying He",
        "Meenakshi Khosla"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-09 21:49:44+00:00",
      "link": "https://arxiv.org/pdf/2602.09225v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09210v1",
      "title": "AI-Driven Cardiorespiratory Signal Processing: Separation, Clustering, and Anomaly Detection",
      "abstract": "This research applies artificial intelligence (AI) to separate, cluster, and analyze cardiorespiratory sounds. We recorded a new dataset (HLS-CMDS) and developed several AI models, including generative AI methods based on large language models (LLMs) for guided separation, explainable AI (XAI) techniques to interpret latent representations, variational autoencoders (VAEs) for waveform separation, a chemistry-inspired non-negative matrix factorization (NMF) algorithm for clustering, and a quantum convolutional neural network (QCNN) designed to detect abnormal physiological patterns. The performance of these AI models depends on the quality of the recorded signals. Therefore, this thesis also reviews the biosensing technologies used to capture biomedical data. It summarizes developments in microelectromechanical systems (MEMS) acoustic sensors and quantum biosensors, such as quantum dots and nitrogen-vacancy centers. It further outlines the transition from electronic integrated circuits (EICs) to photonic integrated circuits (PICs) and early progress toward integrated quantum photonics (IQP) for chip-based biosensing. Together, these studies show how AI and next-generation sensors can support more intelligent diagnostic systems for future healthcare.",
      "authors": [
        "Yasaman Torabi"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "cs.SD",
        "eess.AS"
      ],
      "published": "2026-02-09 21:30:07+00:00",
      "link": "https://arxiv.org/pdf/2602.09210v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09207v1",
      "title": "CausalGDP: Causality-Guided Diffusion Policies for Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) has achieved remarkable success in a wide range of sequential decision-making problems. Recent diffusion-based policies further improve RL by modeling complex, high-dimensional action distributions. However, existing diffusion policies primarily rely on statistical associations and fail to explicitly account for causal relationships among states, actions, and rewards, limiting their ability to identify which action components truly cause high returns. In this paper, we propose Causality-guided Diffusion Policy (CausalGDP), a unified framework that integrates causal reasoning into diffusion-based RL. CausalGDP first learns a base diffusion policy and an initial causal dynamical model from offline data, capturing causal dependencies among states, actions, and rewards. During real-time interaction, the causal information is continuously updated and incorporated as a guidance signal to steer the diffusion process toward actions that causally influence future states and rewards. By explicitly considering causality beyond association, CausalGDP focuses policy optimization on action components that genuinely drive performance improvements. Experimental results demonstrate that CausalGDP consistently achieves competitive or superior performance over state-of-the-art diffusion-based and offline RL methods, especially in complex, high-dimensional control tasks.",
      "authors": [
        "Xiaofeng Xiao",
        "Xiao Hu",
        "Yang Ye",
        "Xubo Yue"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-09 21:18:32+00:00",
      "link": "https://arxiv.org/pdf/2602.09207v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09206v1",
      "title": "EExApp: GNN-Based Reinforcement Learning for Radio Unit Energy Optimization in 5G O-RAN",
      "abstract": "With over 3.5 million 5G base stations deployed globally, their collective energy consumption (projected to exceed 131 TWh annually) raises significant concerns over both operational costs and environmental impacts. In this paper, we present EExAPP, a deep reinforcement learning (DRL)-based xApp for 5G Open Radio Access Network (O-RAN) that jointly optimizes radio unit (RU) sleep scheduling and distributed unit (DU) resource slicing. EExAPP uses a dual-actor-dual-critic Proximal Policy Optimization (PPO) architecture, with dedicated actor-critic pairs targeting energy efficiency and quality-of-service (QoS) compliance. A transformer-based encoder enables scalable handling of variable user equipment (UE) populations by encoding all-UE observations into fixed-dimensional representations. To coordinate the two optimization objectives, a bipartite Graph Attention Network (GAT) is used to modulate actor updates based on both critic outputs, enabling adaptive tradeoffs between power savings and QoS. We have implemented EExAPP and deployed it on a real-world 5G O-RAN testbed with live traffic, commercial RU and smartphones. Extensive over-the-air experiments and ablation studies confirm that EExAPP significantly outperforms existing methods in reducing the energy consumption of RU while maintaining QoS.",
      "authors": [
        "Jie Lu",
        "Peihao Yan",
        "Huacheng Zeng"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.LG"
      ],
      "published": "2026-02-09 21:17:23+00:00",
      "link": "https://arxiv.org/pdf/2602.09206v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09190v1",
      "title": "Gradient Residual Connections",
      "abstract": "Existing work has linked properties of a function's gradient to the difficulty of function approximation. Motivated by these insights, we study how gradient information can be leveraged to improve neural network's ability to approximate high-frequency functions, and we propose a gradient-based residual connection as a complement to the standard identity skip connection used in residual networks. We provide simple theoretical intuition for why gradient information can help distinguish inputs and improve the approximation of functions with rapidly varying behaviour. On a synthetic regression task with a high-frequency sinusoidal ground truth, we show that conventional residual connections struggle to capture high-frequency patterns. In contrast, our gradient residual substantially improves approximation quality. We then introduce a convex combination of the standard and gradient residuals, allowing the network to flexibly control how strongly it relies on gradient information. After validating the design choices of our proposed method through an ablation study, we further validate our approach's utility on the single-image super-resolution task, where the underlying function may be high-frequency. Finally, on standard tasks such as image classification and segmentation, our method achieves performance comparable to standard residual networks, suggesting its broad utility.",
      "authors": [
        "Yangchen Pan",
        "Qizhen Ying",
        "Philip Torr",
        "Bo Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-09 20:53:33+00:00",
      "link": "https://arxiv.org/pdf/2602.09190v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09181v1",
      "title": "Weighted Wasserstein Barycenter of Gaussian Processes for exotic Bayesian Optimization tasks",
      "abstract": "Exploiting the analogy between Gaussian Distributions and Gaussian Processes' posterior, we present how the weighted Wasserstein Barycenter of Gaussian Processes (W2BGP) can be used to unify, under a common framework, different exotic Bayesian Optimization (BO) tasks. Specifically, collaborative/federated BO, (synchronous) batch BO, and multi-fidelity BO are considered in this paper. Our empirical analysis proves that each one of these tasks requires just an appropriate weighting schema for the W2BGP, while the entire framework remains untouched. Moreover, we demonstrate that the most well-known BO acquisition functions can be easily re-interpreted under the proposed framework and also enable a more computationally efficient way to deal with the computation of the Wasserstein Barycenter, compared with state-of-the-art methods from the Machine Learning literature. Finally, research perspectives branching from the proposed approach are presented.",
      "authors": [
        "Antonio Candelieri",
        "Francesco Archetti"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-09 20:40:33+00:00",
      "link": "https://arxiv.org/pdf/2602.09181v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09173v1",
      "title": "$n$-Musketeers: Reinforcement Learning Shapes Collaboration Among Language Models",
      "abstract": "Recent progress in reinforcement learning with verifiable rewards (RLVR) shows that small, specialized language models (SLMs) can exhibit structured reasoning without relying on large monolithic LLMs. We introduce soft hidden-state collaboration, where multiple heterogeneous frozen SLM experts are integrated through their internal representations via a trainable attention interface. Experiments on Reasoning Gym and GSM8K show that this latent integration is competitive with strong single-model RLVR baselines. Ablations further reveal a dual mechanism of expert utilization: for simpler arithmetic domains, performance gains can largely be explained by static expert preferences, whereas more challenging settings induce increasingly concentrated and structured expert attention over training, indicating emergent specialization in how the router connects to relevant experts. Overall, hidden-state collaboration provides a compact mechanism for leveraging frozen experts, while offering an observational window into expert utilization patterns and their evolution under RLVR.",
      "authors": [
        "Ryozo Masukawa",
        "Sanggeon Yun",
        "Hyunwoo Oh",
        "SuhgHeon Jeong",
        "Raheeb Hassa",
        "Hanning Chen",
        "Wenjun Huang",
        "Mahdi Imani",
        "Pietro Mercati",
        "Nathaniel D. Bastian",
        "Mohsen Imani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-09 20:27:52+00:00",
      "link": "https://arxiv.org/pdf/2602.09173v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09164v1",
      "title": "Faster Rates For Federated Variational Inequalities",
      "abstract": "In this paper, we study federated optimization for solving stochastic variational inequalities (VIs), a problem that has attracted growing attention in recent years. Despite substantial progress, a significant gap remains between existing convergence rates and the state-of-the-art bounds known for federated convex optimization. In this work, we address this limitation by establishing a series of improved convergence rates. First, we show that, for general smooth and monotone variational inequalities, the classical Local Extra SGD algorithm admits tighter guarantees under a refined analysis. Next, we identify an inherent limitation of Local Extra SGD, which can lead to excessive client drift. Motivated by this observation, we propose a new algorithm, the Local Inexact Proximal Point Algorithm with Extra Step (LIPPAX), and show that it mitigates client drift and achieves improved guarantees in several regimes, including bounded Hessian, bounded operator, and low-variance settings. Finally, we extend our results to federated composite variational inequalities and establish improved convergence guarantees.",
      "authors": [
        "Guanghui Wang",
        "Satyen Kale"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-09 20:13:36+00:00",
      "link": "https://arxiv.org/pdf/2602.09164v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09163v1",
      "title": "FlyAOC: Evaluating Agentic Ontology Curation of Drosophila Scientific Knowledge Bases",
      "abstract": "Scientific knowledge bases accelerate discovery by curating findings from primary literature into structured, queryable formats for both human researchers and emerging AI systems. Maintaining these resources requires expert curators to search relevant papers, reconcile evidence across documents, and produce ontology-grounded annotations - a workflow that existing benchmarks, focused on isolated subtasks like named entity recognition or relation extraction, do not capture. We present FlyBench to evaluate AI agents on end-to-end agentic ontology curation from scientific literature. Given only a gene symbol, agents must search and read from a corpus of 16,898 full-text papers to produce structured annotations: Gene Ontology terms describing function, expression patterns, and historical synonyms linking decades of nomenclature. The benchmark includes 7,397 expert-curated annotations across 100 genes drawn from FlyBase, the Drosophila (fruit fly) knowledge base. We evaluate four baseline agent architectures: memorization, fixed pipeline, single-agent, and multi-agent. We find that architectural choices significantly impact performance, with multi-agent designs outperforming simpler alternatives, yet scaling backbone models yields diminishing returns. All baselines leave substantial room for improvement. Our analysis surfaces several findings to guide future development; for example, agents primarily use retrieval to confirm parametric knowledge rather than discover new information. We hope FlyBench will drive progress on retrieval-augmented scientific reasoning, a capability with broad applications across scientific domains.",
      "authors": [
        "Xingjian Zhang",
        "Sophia Moylan",
        "Ziyang Xiong",
        "Qiaozhu Mei",
        "Yichen Luo",
        "Jiaqi W. Ma"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-02-09 20:12:38+00:00",
      "link": "https://arxiv.org/pdf/2602.09163v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09162v1",
      "title": "Boltzmann Reinforcement Learning for Noise resilience in Analog Ising Machines",
      "abstract": "Analog Ising machines (AIMs) have emerged as a promising paradigm for combinatorial optimization, utilizing physical dynamics to solve Ising problems with high energy efficiency. However, the performance of traditional optimization and sampling algorithms on these platforms is often limited by inherent measurement noise. We introduce BRAIN (Boltzmann Reinforcement for Analog Ising Networks), a distribution learning framework that utilizes variational reinforcement learning to approximate the Boltzmann distribution. By shifting from state-by-state sampling to aggregating information across multiple noisy measurements, BRAIN is resilient to Gaussian noise characteristic of AIMs. We evaluate BRAIN across diverse combinatorial topologies, including the Curie-Weiss and 2D nearest-neighbor Ising systems. We find that under realistic 3\\% Gaussian measurement noise, BRAIN maintains 98\\% ground state fidelity, whereas Markov Chain Monte Carlo (MCMC) methods degrade to 51\\% fidelity. Furthermore, BRAIN reaches the MCMC-equivalent solution up to 192x faster under these conditions. BRAIN exhibits $\\mathcal{O}(N^{1.55})$ scaling up to 65,536 spins and maintains robustness against severe measurement uncertainty up to 40\\%. Beyond ground state optimization, BRAIN accurately captures thermodynamic phase transitions and metastable states, providing a scalable and noise-resilient method for utilizing analog computing architectures in complex optimizations.",
      "authors": [
        "Aditya Choudhary",
        "Saaketh Desai",
        "Prasad Iyer"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-09 20:07:42+00:00",
      "link": "https://arxiv.org/pdf/2602.09162v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09155v1",
      "title": "Decoding Future Risk: Deep Learning Analysis of Tubular Adenoma Whole-Slide Images",
      "abstract": "Colorectal cancer (CRC) remains a significant cause of cancer-related mortality, despite the widespread implementation of prophylactic initiatives aimed at detecting and removing precancerous polyps. Although screening effectively reduces incidence, a notable portion of patients initially diagnosed with low-grade adenomatous polyps will still develop CRC later in life, even without the presence of known high-risk syndromes. Identifying which low-risk patients are at higher risk of progression is a critical unmet need for tailored surveillance and preventative therapeutic strategies. Traditional histological assessment of adenomas, while fundamental, may not fully capture subtle architectural or cytological features indicative of malignant potential. Advancements in digital pathology and machine learning provide an opportunity to analyze whole-slide images (WSIs) comprehensively and objectively. This study investigates whether machine learning algorithms, specifically convolutional neural networks (CNNs), can detect subtle histological features in WSIs of low-grade tubular adenomas that are predictive of a patient's long-term risk of developing colorectal cancer.",
      "authors": [
        "Ahmed Rahu",
        "Brian Shula",
        "Brandon Combs",
        "Aqsa Sultana",
        "Surendra P. Singh",
        "Vijayan K. Asari",
        "Derrick Forchetti"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-09 20:00:04+00:00",
      "link": "https://arxiv.org/pdf/2602.09155v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09154v1",
      "title": "A Hybrid Deterministic Framework for Named Entity Extraction in Broadcast News Video",
      "abstract": "The growing volume of video-based news content has heightened the need for transparent and reliable methods to extract on-screen information. Yet the variability of graphical layouts, typographic conventions, and platform-specific design patterns renders manual indexing impractical. This work presents a comprehensive framework for automatically detecting and extracting personal names from broadcast and social-media-native news videos. It introduces a curated and balanced corpus of annotated frames capturing the diversity of contemporary news graphics and proposes an interpretable, modular extraction pipeline designed to operate under deterministic and auditable conditions.   The pipeline is evaluated against a contrasting class of generative multimodal methods, revealing a clear trade-off between deterministic auditability and stochastic inference. The underlying detector achieves 95.8% mAP@0.5, demonstrating operationally robust performance for graphical element localisation. While generative systems achieve marginally higher raw accuracy (F1: 84.18% vs 77.08%), they lack the transparent data lineage required for journalistic and analytical contexts. The proposed pipeline delivers balanced precision (79.9%) and recall (74.4%), avoids hallucination, and provides full traceability across each processing stage. Complementary user findings indicate that 59% of respondents report difficulty reading on-screen names in fast-paced broadcasts, underscoring the practical relevance of the task. The results establish a methodologically rigorous and interpretable baseline for hybrid multimodal information extraction in modern news media.",
      "authors": [
        "Andrea Filiberto Lucas",
        "Dylan Seychell"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "published": "2026-02-09 19:58:50+00:00",
      "link": "https://arxiv.org/pdf/2602.09154v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09153v1",
      "title": "SceneSmith: Agentic Generation of Simulation-Ready Indoor Scenes",
      "abstract": "Simulation has become a key tool for training and evaluating home robots at scale, yet existing environments fail to capture the diversity and physical complexity of real indoor spaces. Current scene synthesis methods produce sparsely furnished rooms that lack the dense clutter, articulated furniture, and physical properties essential for robotic manipulation. We introduce SceneSmith, a hierarchical agentic framework that generates simulation-ready indoor environments from natural language prompts. SceneSmith constructs scenes through successive stages$\\unicode{x2013}$from architectural layout to furniture placement to small object population$\\unicode{x2013}$each implemented as an interaction among VLM agents: designer, critic, and orchestrator. The framework tightly integrates asset generation through text-to-3D synthesis for static objects, dataset retrieval for articulated objects, and physical property estimation. SceneSmith generates 3-6x more objects than prior methods, with <2% inter-object collisions and 96% of objects remaining stable under physics simulation. In a user study with 205 participants, it achieves 92% average realism and 91% average prompt faithfulness win rates against baselines. We further demonstrate that these environments can be used in an end-to-end pipeline for automatic robot policy evaluation.",
      "authors": [
        "Nicholas Pfaff",
        "Thomas Cohn",
        "Sergey Zakharov",
        "Rick Cory",
        "Russ Tedrake"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ],
      "published": "2026-02-09 19:56:04+00:00",
      "link": "https://arxiv.org/pdf/2602.09153v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09132v1",
      "title": "SciDataCopilot: An Agentic Data Preparation Framework for AGI-driven Scientific Discovery",
      "abstract": "The current landscape of AI for Science (AI4S) is predominantly anchored in large-scale textual corpora, where generative AI systems excel at hypothesis generation, literature search, and multi-modal reasoning. However, a critical bottleneck for accelerating closed-loop scientific discovery remains the utilization of raw experimental data. Characterized by extreme heterogeneity, high specificity, and deep domain expertise requirements, raw data possess neither direct semantic alignment with linguistic representations nor structural homogeneity suitable for a unified embedding space. The disconnect prevents the emerging class of Artificial General Intelligence for Science (AGI4S) from effectively interfacing with the physical reality of experimentation. In this work, we extend the text-centric AI-Ready concept to Scientific AI-Ready data paradigm, explicitly formalizing how scientific data is specified, structured, and composed within a computational workflow. To operationalize this idea, we propose SciDataCopilot, an autonomous agentic framework designed to handle data ingestion, scientific intent parsing, and multi-modal integration in a end-to-end manner. By positioning data readiness as a core operational primitive, the framework provides a principled foundation for reusable, transferable systems, enabling the transition toward experiment-driven scientific general intelligence. Extensive evaluations across three heterogeneous scientific domains show that SciDataCopilot improves efficiency, scalability, and consistency over manual pipelines, with up to 30$\\times$ speedup in data preparation.",
      "authors": [
        "Jiyong Rao",
        "Yicheng Qiu",
        "Jiahui Zhang",
        "Juntao Deng",
        "Shangquan Sun",
        "Fenghua Ling",
        "Hao Chen",
        "Nanqing Dong",
        "Zhangyang Gao",
        "Siqi Sun",
        "Yuqiang Li",
        "Dongzhan Zhou",
        "Guangyu Wang",
        "Lijun Wu",
        "Conghui He",
        "Xuhong Wang",
        "Jing Shao",
        "Xiang Liu",
        "Yu Zhu",
        "Mianxin Liu",
        "Qihao Zheng",
        "Yinghui Zhang",
        "Jiamin Wu",
        "Xiaosong Wang",
        "Shixiang Tang",
        "Wenlong Zhang",
        "Bo Zhang",
        "Wanli Ouyang",
        "Runkai Zhao",
        "Chunfeng Song",
        "Lei Bai",
        "Chi Zhang"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.ET",
        "cs.MA"
      ],
      "published": "2026-02-09 19:23:32+00:00",
      "link": "https://arxiv.org/pdf/2602.09132v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09128v1",
      "title": "Counterfactual Maps: What They Are and How to Find Them",
      "abstract": "Counterfactual explanations are a central tool in interpretable machine learning, yet computing them exactly for complex models remains challenging. For tree ensembles, predictions are piecewise constant over a large collection of axis-aligned hyperrectangles, implying that an optimal counterfactual for a point corresponds to its projection onto the nearest rectangle with an alternative label under a chosen metric. Existing methods largely overlook this geometric structure, relying either on heuristics with no optimality guarantees or on mixed-integer programming formulations that do not scale to interactive use.   In this work, we revisit counterfactual generation through the lens of nearest-region search and introduce counterfactual maps, a global representation of recourse for tree ensembles. Leveraging the fact that any tree ensemble can be compressed into an equivalent partition of labeled hyperrectangles, we cast counterfactual search as the problem of identifying the generalized Voronoi cell associated with the nearest rectangle of an alternative label. This leads to an exact, amortized algorithm based on volumetric k-dimensional (KD) trees, which performs branch-and-bound nearest-region queries with explicit optimality certificates and sublinear average query time after a one-time preprocessing phase.   Our experimental analyses on several real datasets drawn from high-stakes application domains show that this approach delivers globally optimal counterfactual explanations with millisecond-level latency, achieving query times that are orders of magnitude faster than existing exact, cold-start optimization methods.",
      "authors": [
        "Awa Khouna",
        "Julien Ferry",
        "Thibaut Vidal"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-09 19:20:16+00:00",
      "link": "https://arxiv.org/pdf/2602.09128v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09116v2",
      "title": "Importance inversion transfer identifies shared principles for cross-domain learning",
      "abstract": "The capacity to transfer knowledge across scientific domains relies on shared organizational principles. However, existing transfer-learning methodologies often fail to bridge radically heterogeneous systems, particularly under severe data scarcity or stochastic noise. This study formalizes Explainable Cross-Domain Transfer Learning (X-CDTL), a framework unifying network science and explainable artificial intelligence to identify structural invariants that generalize across biological, linguistic, molecular, and social networks. By introducing the Importance Inversion Transfer (IIT) mechanism, the framework prioritizes domain-invariant structural anchors over idiosyncratic, highly discriminative features. In anomaly detection tasks, models guided by these principles achieve significant performance gains - exhibiting a 56% relative improvement in decision stability under extreme noise - over traditional baselines. These results provide evidence for a shared organizational signature across heterogeneous domains, establishing a principled paradigm for cross-disciplinary knowledge propagation. By shifting from opaque latent representations to explicit structural laws, this work advances machine learning as a robust engine for scientific discovery.",
      "authors": [
        "Daniele Caligiore"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.soc-ph",
        "q-bio.QM"
      ],
      "published": "2026-02-09 19:06:52+00:00",
      "link": "https://arxiv.org/pdf/2602.09116v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09113v1",
      "title": "Benchmarking the Energy Savings with Speculative Decoding Strategies",
      "abstract": "Speculative decoding has emerged as an effective method to reduce latency and inference cost of LLM inferences. However, there has been inadequate attention towards the energy requirements of these models. To address this gap, this paper presents a comprehensive survey of energy requirements of speculative decoding strategies, with detailed analysis on how various factors -- model size and family, speculative decoding strategies, and dataset characteristics -- influence the energy optimizations.",
      "authors": [
        "Rohit Dutta",
        "Paramita Koley",
        "Soham Poddar",
        "Janardan Misra",
        "Sanjay Podder",
        "Naveen Balani",
        "Saptarshi Ghosh",
        "Niloy Ganguly"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-09 19:03:22+00:00",
      "link": "https://arxiv.org/pdf/2602.09113v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09109v1",
      "title": "Distributed Hybrid Parallelism for Large Language Models: Comparative Study and System Design Guide",
      "abstract": "With the rapid growth of large language models (LLMs), a wide range of methods have been developed to distribute computation and memory across hardware devices for efficient training and inference. While existing surveys provide descriptive overviews of these techniques, systematic analysis of their benefits and trade offs and how such insights can inform principled methodology for designing optimal distributed systems remain limited. This paper offers a comprehensive review of collective operations and distributed parallel strategies, complemented by mathematical formulations to deepen theoretical understanding. We further examine hybrid parallelization designs, emphasizing communication computation overlap across different stages of model deployment, including both training and inference. Recent advances in automated search for optimal hybrid parallelization strategies using cost models are also discussed. Moreover, we present case studies with mainstream architecture categories to reveal empirical insights to guide researchers and practitioners in parallelism strategy selection. Finally, we highlight open challenges and limitations of current LLM training paradigms and outline promising directions for the next generation of large scale model development.",
      "authors": [
        "Hossam Amer",
        "Rezaul Karim",
        "Ali Pourranjbar",
        "Weiwei Zhang",
        "Walid Ahmed",
        "Boxing Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC"
      ],
      "published": "2026-02-09 19:01:13+00:00",
      "link": "https://arxiv.org/pdf/2602.09109v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09093v1",
      "title": "Predicting magnetism with first-principles AI",
      "abstract": "Computational discovery of magnetic materials remains challenging because magnetism arises from the competition between kinetic energy and Coulomb interaction that is often beyond the reach of standard electronic-structure methods. Here we tackle this challenge by directly solving the many-electron Schrödinger equation with neural-network variational Monte Carlo, which provides a highly expressive variational wavefunction for strongly correlated systems. Applying this technique to transition metal dichalcogenide moiré semicondutors, we predict itinerant ferromagnetism in WSe$_2$/WS$_2$ and an antiferromagnetic insulator in twisted $Γ$-valley homobilayer, using the same neural network without any physics input beyond the microscopic Hamiltonian. Crucially, both types of magnetic states are obtained from a single calculation within the $S_z=0$ sector, removing the need to compute and compare multiple $S_z$ sectors. This significantly reduces computational cost and paves the way for faster and more reliable magnetic material design.",
      "authors": [
        "Max Geier",
        "Liang Fu"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el",
        "cs.LG"
      ],
      "published": "2026-02-09 19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2602.09093v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09024v1",
      "title": "Autoregressive Image Generation with Masked Bit Modeling",
      "abstract": "This paper challenges the dominance of continuous pipelines in visual generation. We systematically investigate the performance gap between discrete and continuous methods. Contrary to the belief that discrete tokenizers are intrinsically inferior, we demonstrate that the disparity arises primarily from the total number of bits allocated in the latent space (i.e., the compression ratio). We show that scaling up the codebook size effectively bridges this gap, allowing discrete tokenizers to match or surpass their continuous counterparts. However, existing discrete generation methods struggle to capitalize on this insight, suffering from performance degradation or prohibitive training costs with scaled codebook. To address this, we propose masked Bit AutoRegressive modeling (BAR), a scalable framework that supports arbitrary codebook sizes. By equipping an autoregressive transformer with a masked bit modeling head, BAR predicts discrete tokens through progressively generating their constituent bits. BAR achieves a new state-of-the-art gFID of 0.99 on ImageNet-256, outperforming leading methods across both continuous and discrete paradigms, while significantly reducing sampling costs and converging faster than prior continuous approaches. Project page is available at https://bar-gen.github.io/",
      "authors": [
        "Qihang Yu",
        "Qihao Liu",
        "Ju He",
        "Xinyang Zhang",
        "Yang Liu",
        "Liang-Chieh Chen",
        "Xi Chen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-09 18:59:58+00:00",
      "link": "https://arxiv.org/pdf/2602.09024v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09023v1",
      "title": "TwinRL-VLA: Digital Twin-Driven Reinforcement Learning for Real-World Robotic Manipulation",
      "abstract": "Despite strong generalization capabilities, Vision-Language-Action (VLA) models remain constrained by the high cost of expert demonstrations and insufficient real-world interaction. While online reinforcement learning (RL) has shown promise in improving general foundation models, applying RL to VLA manipulation in real-world settings is still hindered by low exploration efficiency and a restricted exploration space. Through systematic real-world experiments, we observe that the effective exploration space of online RL is closely tied to the data distribution of supervised fine-tuning (SFT). Motivated by this observation, we propose TwinRL, a digital twin-real-world collaborative RL framework designed to scale and guide exploration for VLA models. First, a high-fidelity digital twin is efficiently reconstructed from smartphone-captured scenes, enabling realistic bidirectional transfer between real and simulated environments. During the SFT warm-up stage, we introduce an exploration space expansion strategy using digital twins to broaden the support of the data trajectory distribution. Building on this enhanced initialization, we propose a sim-to-real guided exploration strategy to further accelerate online RL. Specifically, TwinRL performs efficient and parallel online RL in the digital twin prior to deployment, effectively bridging the gap between offline and online training stages. Subsequently, we exploit efficient digital twin sampling to identify failure-prone yet informative configurations, which are used to guide targeted human-in-the-loop rollouts on the real robot. In our experiments, TwinRL approaches 100% success in both in-distribution regions covered by real-world demonstrations and out-of-distribution regions, delivering at least a 30% speedup over prior real-world RL methods and requiring only about 20 minutes on average across four tasks.",
      "authors": [
        "Qinwen Xu",
        "Jiaming Liu",
        "Rui Zhou",
        "Shaojun Shi",
        "Nuowei Han",
        "Zhuoyang Liu",
        "Chenyang Gu",
        "Shuo Gu",
        "Yang Yue",
        "Gao Huang",
        "Wenzhao Zheng",
        "Sirui Han",
        "Peng Jia",
        "Shanghang Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-09 18:59:52+00:00",
      "link": "https://arxiv.org/pdf/2602.09023v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09022v1",
      "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
      "abstract": "This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training framework for the long-horizon, interactive video-based world models, enabling them to explore the world more accurately and consistently based on interaction signals. To effectively \"steer\" the world model's exploration, we introduce three core innovations tailored to the autoregressive video generation paradigm: 1) Clip-level rollout Strategy: We generate and evaluate multiple samples at a single target clip, which significantly boosts rollout efficiency and provides fine-grained reward signals. 2) Complementary Reward Functions: We design reward functions for both interaction-following accuracy and visual quality, which provide direct supervision and effectively suppress reward-hacking behaviors. 3) Efficient RL Algorithm: We employ the negative-aware fine-tuning strategy coupled with various efficiency optimizations to efficiently and effectively enhance model capacity. Evaluations on the SoTA open-source world model, WorldPlay, demonstrate that WorldCompass significantly improves interaction accuracy and visual fidelity across various scenarios.",
      "authors": [
        "Zehan Wang",
        "Tengfei Wang",
        "Haiyu Zhang",
        "Xuhui Zuo",
        "Junta Wu",
        "Haoyuan Wang",
        "Wenqiang Sun",
        "Zhenwei Wang",
        "Chenjie Cao",
        "Hengshuang Zhao",
        "Chunchao Guo",
        "Zhou Zhao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-09 18:59:47+00:00",
      "link": "https://arxiv.org/pdf/2602.09022v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09013v2",
      "title": "Dexterous Manipulation Policies from RGB Human Videos via 3D Hand-Object Trajectory Reconstruction",
      "abstract": "Multi-finger robotic hand manipulation and grasping are challenging due to the high-dimensional action space and the difficulty of acquiring large-scale training data. Existing approaches largely rely on human teleoperation with wearable devices or specialized sensing equipment to capture hand-object interactions, which limits scalability. In this work, we propose VIDEOMANIP, a device-free framework that learns dexterous manipulation directly from RGB human videos. Leveraging recent advances in computer vision, VIDEOMANIP reconstructs explicit 3D robot-object trajectories from monocular videos by estimating human hand poses, object meshes, and retargets the reconstructed human motions to robotic hands for manipulation learning. To make the reconstructed robot data suitable for dexterous manipulation training, we introduce hand-object contact optimization with interaction-centric grasp modeling, as well as a demonstration synthesis strategy that generates diverse training trajectories from a single video, enabling generalizable policy learning without additional robot demonstrations. In simulation, the learned grasping model achieves a 70.25% success rate across 20 diverse objects using the Inspire Hand. In the real world, manipulation policies trained from RGB videos achieve an average 62.86% success rate across seven tasks using the LEAP Hand, outperforming retargeting-based methods by 15.87%. Project videos are available at videomanip.github.io.",
      "authors": [
        "Hongyi Chen",
        "Tony Dong",
        "Tiancheng Wu",
        "Liquan Wang",
        "Yash Jangir",
        "Yaru Niu",
        "Yufei Ye",
        "Homanga Bharadhwaj",
        "Zackory Erickson",
        "Jeffrey Ichnowski"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "published": "2026-02-09 18:56:02+00:00",
      "link": "https://arxiv.org/pdf/2602.09013v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09009v1",
      "title": "ANCRe: Adaptive Neural Connection Reassignment for Efficient Depth Scaling",
      "abstract": "Scaling network depth has been a central driver behind the success of modern foundation models, yet recent investigations suggest that deep layers are often underutilized. This paper revisits the default mechanism for deepening neural networks, namely residual connections, from an optimization perspective. Rigorous analysis proves that the layout of residual connections can fundamentally shape convergence behavior, and even induces an exponential gap in convergence rates. Prompted by this insight, we introduce adaptive neural connection reassignment (ANCRe), a principled and lightweight framework that parameterizes and learns residual connectivities from the data. ANCRe adaptively reassigns residual connections with negligible computational and memory overhead ($<1\\%$), while enabling more effective utilization of network depth. Extensive numerical tests across pre-training of large language models, diffusion models, and deep ResNets demonstrate consistently accelerated convergence, boosted performance, and enhanced depth efficiency over conventional residual connections.",
      "authors": [
        "Yilang Zhang",
        "Bingcong Li",
        "Niao He",
        "Georgios B. Giannakis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-09 18:54:18+00:00",
      "link": "https://arxiv.org/pdf/2602.09009v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09008v1",
      "title": "ShapeCond: Fast Shapelet-Guided Dataset Condensation for Time Series Classification",
      "abstract": "Time series data supports many domains (e.g., finance and climate science), but its rapid growth strains storage and computation. Dataset condensation can alleviate this by synthesizing a compact training set that preserves key information. Yet most condensation methods are image-centric and often fail on time series because they miss time-series-specific temporal structure, especially local discriminative motifs such as shapelets. In this work, we propose ShapeCond, a novel and efficient condensation framework for time series classification that leverages shapelet-based dataset knowledge via a shapelet-guided optimization strategy. Our shapelet-assisted synthesis cost is independent of sequence length: longer series yield larger speedups in synthesis (e.g., 29$\\times$ faster over prior state-of-the-art method CondTSC for time-series condensation, and up to 10,000$\\times$ over naively using shapelets on the Sleep dataset with 3,000 timesteps). By explicitly preserving critical local patterns, ShapeCond improves downstream accuracy and consistently outperforms all prior state-of-the-art time series dataset condensation methods across extensive experiments. Code is available at https://github.com/lunaaa95/ShapeCond.",
      "authors": [
        "Sijia Peng",
        "Yun Xiong",
        "Xi Chen",
        "Yi Xie",
        "Guanzhi Li",
        "Yanwei Yu",
        "Yangyong Zhu",
        "Zhiqiang Shen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-09 18:53:08+00:00",
      "link": "https://arxiv.org/pdf/2602.09008v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09082v1",
      "title": "UI-Venus-1.5 Technical Report",
      "abstract": "GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving both broad generality and consistently strong task performance remains challenging.In this report, we present UI-Venus-1.5, a unified, end-to-end GUI Agent designed for robust real-world applications.The proposed model family comprises two dense variants (2B and 8B) and one mixture-of-experts variant (30B-A3B) to meet various downstream application scenarios.Compared to our previous version, UI-Venus-1.5 introduces three key technical advances: (1) a comprehensive Mid-Training stage leveraging 10 billion tokens across 30+ datasets to establish foundational GUI semantics; (2) Online Reinforcement Learning with full-trajectory rollouts, aligning training objectives with long-horizon, dynamic navigation in large-scale environments; and (3) a single unified GUI Agent constructed via Model Merging, which synthesizes domain-specific models (grounding, web, and mobile) into one cohesive checkpoint. Extensive evaluations demonstrate that UI-Venus-1.5 establishes new state-of-the-art performance on benchmarks such as ScreenSpot-Pro (69.6%), VenusBench-GD (75.0%), and AndroidWorld (77.6%), significantly outperforming previous strong baselines. In addition, UI-Venus-1.5 demonstrates robust navigation capabilities across a variety of Chinese mobile apps, effectively executing user instructions in real-world scenarios. Code: https://github.com/inclusionAI/UI-Venus; Model: https://huggingface.co/collections/inclusionAI/ui-venus",
      "authors": [
        "Veuns-Team",
        ":",
        "Changlong Gao",
        "Zhangxuan Gu",
        "Yulin Liu",
        "Xinyu Qiu",
        "Shuheng Shen",
        "Yue Wen",
        "Tianyu Xia",
        "Zhenyu Xu",
        "Zhengwen Zeng",
        "Beitong Zhou",
        "Xingran Zhou",
        "Weizhi Chen",
        "Sunhao Dai",
        "Jingya Dou",
        "Yichen Gong",
        "Yuan Guo",
        "Zhenlin Guo",
        "Feng Li",
        "Qian Li",
        "Jinzhen Lin",
        "Yuqi Zhou",
        "Linchao Zhu",
        "Liang Chen",
        "Zhenyu Guo",
        "Changhua Meng",
        "Weiqiang Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-09 18:43:40+00:00",
      "link": "https://arxiv.org/pdf/2602.09082v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09081v1",
      "title": "DMamba: Decomposition-enhanced Mamba for Time Series Forecasting",
      "abstract": "State Space Models (SSMs), particularly Mamba, have shown potential in long-term time series forecasting. However, existing Mamba-based architectures often struggle with datasets characterized by non-stationary patterns. A key observation from time series theory is that the statistical nature of inter-variable relationships differs fundamentally between the trend and seasonal components of a decomposed series. Trend relationships are often driven by a few common stochastic factors or long-run equilibria, suggesting that they reside on a lower-dimensional manifold. In contrast, seasonal relationships involve dynamic, high-dimensional interactions like phase shifts and amplitude co-movements, requiring more expressive modeling. In this paper, we propose DMamba, a novel forecasting model that explicitly aligns architectural complexity with this component-specific characteristic. DMamba employs seasonal-trend decomposition and processes the components with specialized, differentially complex modules: a variable-direction Mamba encoder captures the rich, cross-variable dynamics within the seasonal component, while a simple Multi-Layer Perceptron (MLP) suffices to learn from the lower-dimensional inter-variable relationships in the trend component. Extensive experiments on diverse datasets demonstrate that DMamba sets a new state-of-the-art (SOTA), consistently outperforming both recent Mamba-based architectures and leading decomposition-based models.",
      "authors": [
        "Ruxuan Chen",
        "Fang Sun"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-09 18:42:10+00:00",
      "link": "https://arxiv.org/pdf/2602.09081v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10150v1",
      "title": "PEST: Physics-Enhanced Swin Transformer for 3D Turbulence Simulation",
      "abstract": "Accurate simulation of turbulent flows is fundamental to scientific and engineering applications. Direct numerical simulation (DNS) offers the highest fidelity but is computationally prohibitive, while existing data-driven alternatives struggle with stable long-horizon rollouts, physical consistency, and faithful simulation of small-scale structures. These challenges are particularly acute in three-dimensional (3D) settings, where the cubic growth of spatial degrees of freedom dramatically amplifies computational cost, memory demand, and the difficulty of capturing multi-scale interactions. To address these challenges, we propose a Physics-Enhanced Swin Transformer (PEST) for 3D turbulence simulation. PEST leverages a window-based self-attention mechanism to effectively model localized PDE interactions while maintaining computational efficiency. We introduce a frequency-domain adaptive loss that explicitly emphasizes small-scale structures, enabling more faithful simulation of high-frequency dynamics. To improve physical consistency, we incorporate Navier--Stokes residual constraints and divergence-free regularization directly into the learning objective. Extensive experiments on two representative turbulent flow configurations demonstrate that PEST achieves accurate, physically consistent, and stable autoregressive long-term simulations, outperforming existing data-driven baselines.",
      "authors": [
        "Yilong Dai",
        "Shengyu Chen",
        "Xiaowei Jia",
        "Peyman Givi",
        "Runlong Yu"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "math.AP"
      ],
      "published": "2026-02-09 18:37:18+00:00",
      "link": "https://arxiv.org/pdf/2602.10150v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.08990v1",
      "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
      "abstract": "We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery.",
      "authors": [
        "Shiyang Feng",
        "Runmin Ma",
        "Xiangchao Yan",
        "Yue Fan",
        "Yusong Hu",
        "Songtao Huang",
        "Shuaiyu Zhang",
        "Zongsheng Cao",
        "Tianshuo Peng",
        "Jiakang Yuan",
        "Zijie Guo",
        "Zhijie Zhong",
        "Shangheng Du",
        "Weida Wang",
        "Jinxin Shi",
        "Yuhao Zhou",
        "Xiaohan He",
        "Zhiyin Yu",
        "Fangchen Yu",
        "Qihao Zheng",
        "Jiamin Wu",
        "Mianxin Liu",
        "Chi Zhang",
        "Shaowei Hou",
        "Shuya Li",
        "Yankai Jiang",
        "Wenjie Lou",
        "Lilong Wang",
        "Zifu Wang",
        "Jiong Wang",
        "Wanghan Xu",
        "Yue Deng",
        "Dongrui Liu",
        "Yiheng Wang",
        "Wenlong Zhang",
        "Fenghua Ling",
        "Shufei Zhang",
        "Xiaosong Wang",
        "Shuangjia Zheng",
        "Xun Huang",
        "Siqi Sun",
        "Shuyue Hu",
        "Peng Ye",
        "Chunfeng Song",
        "Bin Wang",
        "Conghui He",
        "Yihao Liu",
        "Xin Li",
        "Qibin Hou",
        "Tao Chen",
        "Xiangyu Yue",
        "Bin Wang",
        "Liang He",
        "Dahua Lin",
        "Bowen Zhou",
        "Bo Zhang",
        "Lei Bai"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-09 18:36:06+00:00",
      "link": "https://arxiv.org/pdf/2602.08990v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.08980v1",
      "title": "When do neural ordinary differential equations generalize on complex networks?",
      "abstract": "Neural ordinary differential equations (neural ODEs) can effectively learn dynamical systems from time series data, but their behavior on graph-structured data remains poorly understood, especially when applied to graphs with different size or structure than encountered during training. We study neural ODEs ($\\mathtt{nODE}$s) with vector fields following the Barabási-Barzel form, trained on synthetic data from five common dynamical systems on graphs. Using the $\\mathbb{S}^1$-model to generate graphs with realistic and tunable structure, we find that degree heterogeneity and the type of dynamical system are the primary factors in determining $\\mathtt{nODE}$s' ability to generalize across graph sizes and properties. This extends to $\\mathtt{nODE}$s' ability to capture fixed points and maintain performance amid missing data. Average clustering plays a secondary role in determining $\\mathtt{nODE}$ performance. Our findings highlight $\\mathtt{nODE}$s as a powerful approach to understanding complex systems but underscore challenges emerging from degree heterogeneity and clustering in realistic graphs.",
      "authors": [
        "Moritz Laber",
        "Tina Eliassi-Rad",
        "Brennan Klein"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph",
        "cs.LG",
        "cs.SI",
        "stat.ML"
      ],
      "published": "2026-02-09 18:28:41+00:00",
      "link": "https://arxiv.org/pdf/2602.08980v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.08965v2",
      "title": "Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning",
      "abstract": "The inability to communicate poses a major challenge to coordination in multi-agent reinforcement learning (MARL). Prior work has explored correlating local policies via shared randomness, sometimes in the form of a correlation device, as a mechanism to assist in decentralized decision-making. In contrast, this work introduces the first framework for training MARL agents to exploit shared quantum entanglement as a coordination resource, which permits a larger class of communication-free correlated policies than shared randomness alone. This is motivated by well-known results in quantum physics which posit that, for certain single-round cooperative games with no communication, shared quantum entanglement enables strategies that outperform those that only use shared randomness. In such cases, we say that there is quantum advantage. Our framework is based on a novel differentiable policy parameterization that enables optimization over quantum measurements, together with a novel policy architecture that decomposes joint policies into a quantum coordinator and decentralized local actors. To illustrate the effectiveness of our proposed method, we first show that we can learn, purely from experience, strategies that attain quantum advantage in single-round games that are treated as black box oracles. We then demonstrate how our machinery can learn policies with quantum advantage in an illustrative multi-agent sequential decision-making problem formulated as a decentralized partially observable Markov decision process (Dec-POMDP).",
      "authors": [
        "John Gardiner",
        "Orlando Romero",
        "Brendan Tivnan",
        "Nicolò Dal Fabbro",
        "George J. Pappas"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.LG"
      ],
      "published": "2026-02-09 18:01:40+00:00",
      "link": "https://arxiv.org/pdf/2602.08965v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.08963v1",
      "title": "Reduced-order Control and Geometric Structure of Learned Lagrangian Latent Dynamics",
      "abstract": "Model-based controllers can offer strong guarantees on stability and convergence by relying on physically accurate dynamic models. However, these are rarely available for high-dimensional mechanical systems such as deformable objects or soft robots. While neural architectures can learn to approximate complex dynamics, they are either limited to low-dimensional systems or provide only limited formal control guarantees due to a lack of embedded physical structure. This paper introduces a latent control framework based on learned structure-preserving reduced-order dynamics for high-dimensional Lagrangian systems. We derive a reduced tracking law for fully actuated systems and adopt a Riemannian perspective on projection-based model-order reduction to study the resulting latent and projected closed-loop dynamics. By quantifying the sources of modeling error, we derive interpretable conditions for stability and convergence. We extend the proposed controller and analysis to underactuated systems by introducing learned actuation patterns. Experimental results on simulated and real-world systems validate our theoretical investigation and the accuracy of our controllers.",
      "authors": [
        "Katharina Friedl",
        "Noémie Jaquier",
        "Seungyeon Kim",
        "Jens Lundell",
        "Danica Kragic"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "math.OC"
      ],
      "published": "2026-02-09 18:00:04+00:00",
      "link": "https://arxiv.org/pdf/2602.08963v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16710v1",
      "title": "EgoScale: Scaling Dexterous Manipulation with Diverse Egocentric Human Data",
      "abstract": "Human behavior is among the most scalable sources of data for learning physical intelligence, yet how to effectively leverage it for dexterous manipulation remains unclear. While prior work demonstrates human to robot transfer in constrained settings, it is unclear whether large scale human data can support fine grained, high degree of freedom dexterous manipulation. We present EgoScale, a human to dexterous manipulation transfer framework built on large scale egocentric human data. We train a Vision Language Action (VLA) model on over 20,854 hours of action labeled egocentric human video, more than 20 times larger than prior efforts, and uncover a log linear scaling law between human data scale and validation loss. This validation loss strongly correlates with downstream real robot performance, establishing large scale human data as a predictable supervision source. Beyond scale, we introduce a simple two stage transfer recipe: large scale human pretraining followed by lightweight aligned human robot mid training. This enables strong long horizon dexterous manipulation and one shot task adaptation with minimal robot supervision. Our final policy improves average success rate by 54% over a no pretraining baseline using a 22 DoF dexterous robotic hand, and transfers effectively to robots with lower DoF hands, indicating that large scale human motion provides a reusable, embodiment agnostic motor prior.",
      "authors": [
        "Ruijie Zheng",
        "Dantong Niu",
        "Yuqi Xie",
        "Jing Wang",
        "Mengda Xu",
        "Yunfan Jiang",
        "Fernando Castañeda",
        "Fengyuan Hu",
        "You Liang Tan",
        "Letian Fu",
        "Trevor Darrell",
        "Furong Huang",
        "Yuke Zhu",
        "Danfei Xu",
        "Linxi Fan"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-18 18:59:05+00:00",
      "link": "https://arxiv.org/pdf/2602.16710v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16707v1",
      "title": "E-Graphs as a Persistent Compiler Abstraction",
      "abstract": "Recent algorithmic advances have made equality saturation an appealing approach to program optimization because it avoids the phase-ordering problem. Existing work uses external equality saturation libraries, or custom implementations that are deeply tied to the specific application. However, these works only apply equality saturation at a single level of abstraction, or discard the discovered equalities when code is transformed by other compiler passes. We propose an alternative approach that represents an e-graph natively in the compiler's intermediate representation, facilitating the application of constructive compiler passes that maintain the e-graph state throughout the compilation flow. We build on a Python-based MLIR framework, xDSL, and introduce a new MLIR dialect, eqsat, that represents e-graphs in MLIR code. We show that this representation expands the scope of equality saturation in the compiler, allowing us to interleave pattern rewriting with other compiler transformations. The eqsat dialect provides a unified abstraction for compilers to utilize equality saturation across various levels of intermediate representations concurrently within the same MLIR flow.",
      "authors": [
        "Jules Merckx",
        "Alexandre Lopoukhine",
        "Samuel Coward",
        "Jianyi Cheng",
        "Bjorn De Sutter",
        "Tobias Grosser"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL"
      ],
      "published": "2026-02-18 18:56:52+00:00",
      "link": "https://arxiv.org/pdf/2602.16707v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16703v1",
      "title": "Measuring Mid-2025 LLM-Assistance on Novice Performance in Biology",
      "abstract": "Large language models (LLMs) perform strongly on biological benchmarks, raising concerns that they may help novice actors acquire dual-use laboratory skills. Yet, whether this translates to improved human performance in the physical laboratory remains unclear. To address this, we conducted a pre-registered, investigator-blinded, randomized controlled trial (June-August 2025; n = 153) evaluating whether LLMs improve novice performance in tasks that collectively model a viral reverse genetics workflow. We observed no significant difference in the primary endpoint of workflow completion (5.2% LLM vs. 6.6% Internet; P = 0.759), nor in the success rate of individual tasks. However, the LLM arm had numerically higher success rates in four of the five tasks, most notably for the cell culture task (68.8% LLM vs. 55.3% Internet; P = 0.059). Post-hoc Bayesian modeling of pooled data estimates an approximate 1.4-fold increase (95% CrI 0.74-2.62) in success for a \"typical\" reverse genetics task under LLM assistance. Ordinal regression modelling suggests that participants in the LLM arm were more likely to progress through intermediate steps across all tasks (posterior probability of a positive effect: 81%-96%). Overall, mid-2025 LLMs did not substantially increase novice completion of complex laboratory procedures but were associated with a modest performance benefit. These results reveal a gap between in silico benchmarks and real-world utility, underscoring the need for physical-world validation of AI biosecurity assessments as model capabilities and user proficiency evolve.",
      "authors": [
        "Shen Zhou Hong",
        "Alex Kleinman",
        "Alyssa Mathiowetz",
        "Adam Howes",
        "Julian Cohen",
        "Suveer Ganta",
        "Alex Letizia",
        "Dora Liao",
        "Deepika Pahari",
        "Xavier Roberts-Gaal",
        "Luca Righetti",
        "Joe Torres"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "published": "2026-02-18 18:51:28+00:00",
      "link": "https://arxiv.org/pdf/2602.16703v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16699v1",
      "title": "Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents",
      "abstract": "LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lower than the cost of making a mistake. In this work, we show that we can induce LLMs to explicitly reason about balancing these cost-uncertainty tradeoffs, then perform more optimal environment exploration. We formalize multiple tasks, including information retrieval and coding, as sequential decision-making problems under uncertainty. Each problem has latent environment state that can be reasoned about via a prior which is passed to the LLM agent. We introduce a framework called Calibrate-Then-Act (CTA), where we feed the LLM this additional context to enable it to act more optimally. This improvement is preserved even under RL training of both the baseline and CTA. Our results on information-seeking QA and on a simplified coding task show that making cost-benefit tradeoffs explicit with CTA can help agents discover more optimal decision-making strategies.",
      "authors": [
        "Wenxuan Ding",
        "Nicholas Tomlin",
        "Greg Durrett"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-18 18:46:14+00:00",
      "link": "https://arxiv.org/pdf/2602.16699v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16696v1",
      "title": "Parameter-free representations outperform single-cell foundation models on downstream benchmarks",
      "abstract": "Single-cell RNA sequencing (scRNA-seq) data exhibit strong and reproducible statistical structure. This has motivated the development of large-scale foundation models, such as TranscriptFormer, that use transformer-based architectures to learn a generative model for gene expression by embedding genes into a latent vector space. These embeddings have been used to obtain state-of-the-art (SOTA) performance on downstream tasks such as cell-type classification, disease-state prediction, and cross-species learning. Here, we ask whether similar performance can be achieved without utilizing computationally intensive deep learning-based representations. Using simple, interpretable pipelines that rely on careful normalization and linear methods, we obtain SOTA or near SOTA performance across multiple benchmarks commonly used to evaluate single-cell foundation models, including outperforming foundation models on out-of-distribution tasks involving novel cell types and organisms absent from the training data. Our findings highlight the need for rigorous benchmarking and suggest that the biology of cell identity can be captured by simple linear representations of single cell gene expression data.",
      "authors": [
        "Huan Souza",
        "Pankaj Mehta"
      ],
      "primary_category": "q-bio.GN",
      "categories": [
        "q-bio.GN",
        "cs.LG",
        "q-bio.QM"
      ],
      "published": "2026-02-18 18:42:29+00:00",
      "link": "https://arxiv.org/pdf/2602.16696v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16684v1",
      "title": "Retrieval-Augmented Foundation Models for Matched Molecular Pair Transformations to Recapitulate Medicinal Chemistry Intuition",
      "abstract": "Matched molecular pairs (MMPs) capture the local chemical edits that medicinal chemists routinely use to design analogs, but existing ML approaches either operate at the whole-molecule level with limited edit controllability or learn MMP-style edits from restricted settings and small models. We propose a variable-to-variable formulation of analog generation and train a foundation model on large-scale MMP transformations (MMPTs) to generate diverse variables conditioned on an input variable. To enable practical control, we develop prompting mechanisms that let the users specify preferred transformation patterns during generation. We further introduce MMPT-RAG, a retrieval-augmented framework that uses external reference analogs as contextual guidance to steer generation and generalize from project-specific series. Experiments on general chemical corpora and patent-specific datasets demonstrate improved diversity, novelty, and controllability, and show that our method recovers realistic analog structures in practical discovery scenarios.",
      "authors": [
        "Bo Pan",
        "Peter Zhiping Zhang",
        "Hao-Wei Pang",
        "Alex Zhu",
        "Xiang Yu",
        "Liying Zhang",
        "Liang Zhao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 18:27:21+00:00",
      "link": "https://arxiv.org/pdf/2602.16684v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16675v1",
      "title": "Learning to unfold cloth: Scaling up world models to deformable object manipulation",
      "abstract": "Learning to manipulate cloth is both a paradigmatic problem for robotic research and a problem of immediate relevance to a variety of applications ranging from assistive care to the service industry. The complex physics of the deformable object makes this problem of cloth manipulation nontrivial. In order to create a general manipulation strategy that addresses a variety of shapes, sizes, fold and wrinkle patterns, in addition to the usual problems of appearance variations, it becomes important to carefully consider model structure and their implications for generalisation performance. In this paper, we present an approach to in-air cloth manipulation that uses a variation of a recently proposed reinforcement learning architecture, DreamerV2. Our implementation modifies this architecture to utilise surface normals input, in addition to modiying the replay buffer and data augmentation procedures. Taken together these modifications represent an enhancement to the world model used by the robot, addressing the physical complexity of the object being manipulated by the robot. We present evaluations both in simulation and in a zero-shot deployment of the trained policies in a physical robot setup, performing in-air unfolding of a variety of different cloth types, demonstrating the generalisation benefits of our proposed architecture.",
      "authors": [
        "Jack Rome",
        "Stephen James",
        "Subramanian Ramamoorthy"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-18 18:14:41+00:00",
      "link": "https://arxiv.org/pdf/2602.16675v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16671v1",
      "title": "SPARC: Scenario Planning and Reasoning for Automated C Unit Test Generation",
      "abstract": "Automated unit test generation for C remains a formidable challenge due to the semantic gap between high-level program intent and the rigid syntactic constraints of pointer arithmetic and manual memory management. While Large Language Models (LLMs) exhibit strong generative capabilities, direct intent-to-code synthesis frequently suffers from the leap-to-code failure mode, where models prematurely emit code without grounding in program structure, constraints, and semantics. This will result in non-compilable tests, hallucinated function signatures, low branch coverage, and semantically irrelevant assertions that cannot properly capture bugs. We introduce SPARC, a neuro-symbolic, scenario-based framework that bridges this gap through four stages: (1) Control Flow Graph (CFG) analysis, (2) an Operation Map that grounds LLM reasoning in validated utility helpers, (3) Path-targeted test synthesis, and (4) an iterative, self-correction validation loop using compiler and runtime feedback. We evaluate SPARC on 59 real-world and algorithmic subjects, where it outperforms the vanilla prompt generation baseline by 31.36% in line coverage, 26.01% in branch coverage, and 20.78% in mutation score, matching or exceeding the symbolic execution tool KLEE on complex subjects. SPARC retains 94.3% of tests through iterative repair and produces code with significantly higher developer-rated readability and maintainability. By aligning LLM reasoning with program structure, SPARC provides a scalable path for industrial-grade testing of legacy C codebases.",
      "authors": [
        "Jaid Monwar Chowdhury",
        "Chi-An Fu",
        "Reyhaneh Jabbarvand"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-02-18 18:09:03+00:00",
      "link": "https://arxiv.org/pdf/2602.16671v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16669v1",
      "title": "PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction",
      "abstract": "High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which lead to temporal inconsistencies and instabilities during the construction of a global map. To overcome these challenges, we introduce a novel end-to-end framework for consistent online HD vectorized map construction, which jointly performs map instance tracking and short-term prediction. First, we propose a Semantic-Aware Query Generator that initializes queries with spatially aligned semantic masks to capture scene-level context globally. Next, we design a History Rasterized Map Memory to store fine-grained instance-level maps for each tracked instance, enabling explicit historical priors. A History-Map Guidance Module then integrates rasterized map information into track queries, improving temporal continuity. Finally, we propose a Short-Term Future Guidance module to forecast the immediate motion of map instances based on the stored history trajectories. These predicted future locations serve as hints for tracked instances to further avoid implausible predictions and keep temporal consistency. Extensive experiments on the nuScenes and Argoverse2 datasets demonstrate that our proposed method outperforms state-of-the-art (SOTA) methods with good efficiency.",
      "authors": [
        "Bo Lang",
        "Nirav Savaliya",
        "Zhihao Zheng",
        "Jinglun Feng",
        "Zheng-Hang Yeh",
        "Mooi Choo Chuah"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-18 18:08:26+00:00",
      "link": "https://arxiv.org/pdf/2602.16669v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16656v1",
      "title": "Investigating Nonlinear Quenching Effects on Polar Field Buildup in the Sun Using Physics-Informed Neural Networks",
      "abstract": "The solar dynamo relies on the regeneration of the poloidal magnetic field through processes strongly modulated by nonlinear feedbacks such as tilt quenching (TQ) and latitude quenching (LQ). These mechanisms play a decisive role in regulating the buildup of the Sun's polar field and, in turn, the amplitude of future solar cycles. In this work, we employ Physics-Informed Neural Networks (PINN) to solve the surface flux transport (SFT) equation, embedding physical constraints directly into the neural network framework. By systematically varying transport parameters, we isolate the relative contributions of TQ and LQ to polar dipole buildup. We use the residual dipole moment as a diagnostic for cycle-to-cycle amplification and show that TQ suppression strengthens with increasing diffusivity, while LQ dominates in advection-dominated regimes. The ratio $ΔD_{\\mathrm{LQ}}/ΔD_{\\mathrm{TQ}}$ exhibits a smooth inverse-square dependence on the dynamo effectivity range, refining previous empirical fits with improved accuracy and reduced scatter. The results further reveal that the need for a decay term is not essential for PINN set-up due to the training process. Compared with the traditional 1D SFT model, the PINN framework achieves significantly lower error metrics and more robust recovery of nonlinear trends. Our results suggest that the nonlinear interplay between LQ and TQ can naturally produce alternations between weak and strong cycles, providing a physical explanation for the observed even-odd cycle modulation. These findings demonstrate the potential of PINN as an accurate, efficient, and physically consistent tool for solar cycle prediction.",
      "authors": [
        "Jithu J. Athalathil",
        "Mohammed H. Talafha",
        "Bhargav Vaidya"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "cs.LG"
      ],
      "published": "2026-02-18 17:54:59+00:00",
      "link": "https://arxiv.org/pdf/2602.16656v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16642v1",
      "title": "Optimizer choice matters for the emergence of Neural Collapse",
      "abstract": "Neural Collapse (NC) refers to the emergence of highly symmetric geometric structures in the representations of deep neural networks during the terminal phase of training. Despite its prevalence, the theoretical understanding of NC remains limited. Existing analyses largely ignore the role of the optimizer, thereby suggesting that NC is universal across optimization methods. In this work, we challenge this assumption and demonstrate that the choice of optimizer plays a critical role in the emergence of NC. The phenomenon is typically quantified through NC metrics, which, however, are difficult to track and analyze theoretically. To overcome this limitation, we introduce a novel diagnostic metric, NC0, whose convergence to zero is a necessary condition for NC. Using NC0, we provide theoretical evidence that NC cannot emerge under decoupled weight decay in adaptive optimizers, as implemented in AdamW. Concretely, we prove that SGD, SignGD with coupled weight decay (a special case of Adam), and SignGD with decoupled weight decay (a special case of AdamW) exhibit qualitatively different NC0 dynamics. Also, we show the accelerating effect of momentum on NC (beyond convergence of train loss) when trained with SGD, being the first result concerning momentum in the context of NC. Finally, we conduct extensive empirical experiments consisting of 3,900 training runs across various datasets, architectures, optimizers, and hyperparameters, confirming our theoretical results. This work provides the first theoretical explanation for optimizer-dependent emergence of NC and highlights the overlooked role of weight-decay coupling in shaping the implicit biases of optimizers.",
      "authors": [
        "Jim Zhao",
        "Tin Sum Cheng",
        "Wojciech Masarczyk",
        "Aurelien Lucchi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 17:32:43+00:00",
      "link": "https://arxiv.org/pdf/2602.16642v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16639v1",
      "title": "AREG: Adversarial Resource Extraction Game for Evaluating Persuasion and Resistance in Large Language Models",
      "abstract": "Evaluating the social intelligence of Large Language Models (LLMs) increasingly requires moving beyond static text generation toward dynamic, adversarial interaction. We introduce the Adversarial Resource Extraction Game (AREG), a benchmark that operationalizes persuasion and resistance as a multi-turn, zero-sum negotiation over financial resources. Using a round-robin tournament across frontier models, AREG enables joint evaluation of offensive (persuasion) and defensive (resistance) capabilities within a single interactional framework. Our analysis provides evidence that these capabilities are weakly correlated ($ρ= 0.33$) and empirically dissociated: strong persuasive performance does not reliably predict strong resistance, and vice versa. Across all evaluated models, resistance scores exceed persuasion scores, indicating a systematic defensive advantage in adversarial dialogue settings. Further linguistic analysis suggests that interaction structure plays a central role in these outcomes. Incremental commitment-seeking strategies are associated with higher extraction success, while verification-seeking responses are more prevalent in successful defenses than explicit refusal. Together, these findings indicate that social influence in LLMs is not a monolithic capability and that evaluation frameworks focusing on persuasion alone may overlook asymmetric behavioral vulnerabilities.",
      "authors": [
        "Adib Sakhawat",
        "Fardeen Sadab"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-18 17:28:28+00:00",
      "link": "https://arxiv.org/pdf/2602.16639v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16629v1",
      "title": "Almost Sure Convergence of Differential Temporal Difference Learning for Average Reward Markov Decision Processes",
      "abstract": "The average reward is a fundamental performance metric in reinforcement learning (RL) focusing on the long-run performance of an agent. Differential temporal difference (TD) learning algorithms are a major advance for average reward RL as they provide an efficient online method to learn the value functions associated with the average reward in both on-policy and off-policy settings. However, existing convergence guarantees require a local clock in learning rates tied to state visit counts, which practitioners do not use and does not extend beyond tabular settings. We address this limitation by proving the almost sure convergence of on-policy $n$-step differential TD for any $n$ using standard diminishing learning rates without a local clock. We then derive three sufficient conditions under which off-policy $n$-step differential TD also converges without a local clock. These results strengthen the theoretical foundations of differential TD and bring its convergence analysis closer to practical implementations.",
      "authors": [
        "Ethan Blaser",
        "Jiuqi Wang",
        "Shangtong Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-18 17:24:27+00:00",
      "link": "https://arxiv.org/pdf/2602.16629v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16626v1",
      "title": "A Systematic Evaluation of Sample-Level Tokenization Strategies for MEG Foundation Models",
      "abstract": "Recent success in natural language processing has motivated growing interest in large-scale foundation models for neuroimaging data. Such models often require discretization of continuous neural time series data, a process referred to as 'tokenization'. However, the impact of different tokenization strategies for neural data is currently poorly understood. In this work, we present a systematic evaluation of sample-level tokenization strategies for transformer-based large neuroimaging models (LNMs) applied to magnetoencephalography (MEG) data. We compare learnable and non-learnable tokenizers by examining their signal reconstruction fidelity and their impact on subsequent foundation modeling performance (token prediction, biological plausibility of generated data, preservation of subject-specific information, and performance on downstream tasks). For the learnable tokenizer, we introduce a novel approach based on an autoencoder. Experiments were conducted on three publicly available MEG datasets spanning different acquisition sites, scanners, and experimental paradigms. Our results show that both learnable and non-learnable discretization schemes achieve high reconstruction accuracy and broadly comparable performance across most evaluation criteria, suggesting that simple fixed sample-level tokenization strategies can be used in the development of neural foundation models. The code is available at https://github.com/OHBA-analysis/Cho2026_Tokenizer.",
      "authors": [
        "SungJun Cho",
        "Chetan Gohil",
        "Rukuang Huang",
        "Oiwi Parker Jones",
        "Mark W. Woolrich"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "published": "2026-02-18 17:21:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16626v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16608v1",
      "title": "Explainable AI: Context-Aware Layer-Wise Integrated Gradients for Explaining Transformer Models",
      "abstract": "Transformer models achieve state-of-the-art performance across domains and tasks, yet their deeply layered representations make their predictions difficult to interpret. Existing explainability methods rely on final-layer attributions, capture either local token-level attributions or global attention patterns without unification, and lack context-awareness of inter-token dependencies and structural components. They also fail to capture how relevance evolves across layers and how structural components shape decision-making. To address these limitations, we proposed the \\textbf{Context-Aware Layer-wise Integrated Gradients (CA-LIG) Framework}, a unified hierarchical attribution framework that computes layer-wise Integrated Gradients within each Transformer block and fuses these token-level attributions with class-specific attention gradients. This integration yields signed, context-sensitive attribution maps that capture supportive and opposing evidence while tracing the hierarchical flow of relevance through the Transformer layers. We evaluate the CA-LIG Framework across diverse tasks, domains, and transformer model families, including sentiment analysis and long and multi-class document classification with BERT, hate speech detection in a low-resource language setting with XLM-R and AfroLM, and image classification with Masked Autoencoder vision Transformer model. Across all tasks and architectures, CA-LIG provides more faithful attributions, shows stronger sensitivity to contextual dependencies, and produces clearer, more semantically coherent visualizations than established explainability methods. These results indicate that CA-LIG provides a more comprehensive, context-aware, and reliable explanation of Transformer decision-making, advancing both the practical interpretability and conceptual understanding of deep neural models.",
      "authors": [
        "Melkamu Abay Mersha",
        "Jugal Kalita"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-18 17:03:10+00:00",
      "link": "https://arxiv.org/pdf/2602.16608v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16590v1",
      "title": "A Contrastive Learning Framework Empowered by Attention-based Feature Adaptation for Street-View Image Classification",
      "abstract": "Street-view image attribute classification is a vital downstream task of image classification, enabling applications such as autonomous driving, urban analytics, and high-definition map construction. It remains computationally demanding whether training from scratch, initialising from pre-trained weights, or fine-tuning large models. Although pre-trained vision-language models such as CLIP offer rich image representations, existing adaptation or fine-tuning methods often rely on their global image embeddings, limiting their ability to capture fine-grained, localised attributes essential in complex, cluttered street scenes. To address this, we propose CLIP-MHAdapter, a variant of the current lightweight CLIP adaptation paradigm that appends a bottleneck MLP equipped with multi-head self-attention operating on patch tokens to model inter-patch dependencies. With approximately 1.4 million trainable parameters, CLIP-MHAdapter achieves superior or competitive accuracy across eight attribute classification tasks on the Global StreetScapes dataset, attaining new state-of-the-art results while maintaining low computational cost. The code is available at https://github.com/SpaceTimeLab/CLIP-MHAdapter.",
      "authors": [
        "Qi You",
        "Yitai Cheng",
        "Zichao Zeng",
        "James Haworth"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-18 16:41:32+00:00",
      "link": "https://arxiv.org/pdf/2602.16590v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16585v1",
      "title": "DataJoint 2.0: A Computational Substrate for Agentic Scientific Workflows",
      "abstract": "Operational rigor determines whether human-agent collaboration succeeds or fails. Scientific data pipelines need the equivalent of DevOps -- SciOps -- yet common approaches fragment provenance across disconnected systems without transactional guarantees. DataJoint 2.0 addresses this gap through the relational workflow model: tables represent workflow steps, rows represent artifacts, foreign keys prescribe execution order. The schema specifies not only what data exists but how it is derived -- a single formal system where data structure, computational dependencies, and integrity constraints are all queryable, enforceable, and machine-readable. Four technical innovations extend this foundation: object-augmented schemas integrating relational metadata with scalable object storage, semantic matching using attribute lineage to prevent erroneous joins, an extensible type system for domain-specific formats, and distributed job coordination designed for composability with external orchestration. By unifying data structure, data, and computational transformations, DataJoint creates a substrate for SciOps where agents can participate in scientific workflows without risking data corruption.",
      "authors": [
        "Dimitri Yatsenko",
        "Thinh T. Nguyen"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "published": "2026-02-18 16:35:47+00:00",
      "link": "https://arxiv.org/pdf/2602.16585v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16573v1",
      "title": "MoDE-Boost: Boosting Shared Mobility Demand with Edge-Ready Prediction Models",
      "abstract": "Urban demand forecasting plays a critical role in optimizing routing, dispatching, and congestion management within Intelligent Transportation Systems. By leveraging data fusion and analytics techniques, traffic demand forecasting serves as a key intermediate measure for identifying emerging spatial and temporal demand patterns. In this paper, we tackle this challenge by proposing two gradient boosting model variations, one for classiffication and one for regression, both capable of generating demand forecasts at various temporal horizons, from 5 minutes up to one hour. Our overall approach effectively integrates temporal and contextual features, enabling accurate predictions that are essential for improving the efficiency of shared (micro-) mobility services. To evaluate its effectiveness, we utilize open shared mobility data derived from e-scooter and e-bike networks in five metropolitan areas. These real-world datasets allow us to compare our approach with state-of-the-art methods as well as a Generative AI-based model, demonstrating its effectiveness in capturing the complexities of modern urban mobility. Ultimately, our methodology offers novel insights on urban micro-mobility management, helping to tackle the challenges arising from rapid urbanization and thus, contributing to more sustainable, efficient, and livable cities.",
      "authors": [
        "Antonios Tziorvas",
        "George S. Theodoropoulos",
        "Yannis Theodoridis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 16:18:13+00:00",
      "link": "https://arxiv.org/pdf/2602.16573v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16569v1",
      "title": "Arc2Morph: Identity-Preserving Facial Morphing with Arc2Face",
      "abstract": "Face morphing attacks are widely recognized as one of the most challenging threats to face recognition systems used in electronic identity documents. These attacks exploit a critical vulnerability in passport enrollment procedures adopted by many countries, where the facial image is often acquired without a supervised live capture process. In this paper, we propose a novel face morphing technique based on Arc2Face, an identity-conditioned face foundation model capable of synthesizing photorealistic facial images from compact identity representations. We demonstrate the effectiveness of the proposed approach by comparing the morphing attack potential metric on two large-scale sequestered face morphing attack detection datasets against several state-of-the-art morphing methods, as well as on two novel morphed face datasets derived from FEI and ONOT. Experimental results show that the proposed deep learning-based approach achieves a morphing attack potential comparable to that of landmark-based techniques, which have traditionally been regarded as the most challenging. These findings confirm the ability of the proposed method to effectively preserve and manage identity information during the morph generation process.",
      "authors": [
        "Nicolò Di Domenico",
        "Annalisa Franco",
        "Matteo Ferrara",
        "Davide Maltoni"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.CR"
      ],
      "published": "2026-02-18 16:11:11+00:00",
      "link": "https://arxiv.org/pdf/2602.16569v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16564v1",
      "title": "A Scalable Approach to Solving Simulation-Based Network Security Games",
      "abstract": "We introduce MetaDOAR, a lightweight meta-controller that augments the Double Oracle / PSRO paradigm with a learned, partition-aware filtering layer and Q-value caching to enable scalable multi-agent reinforcement learning on very large cyber-network environments. MetaDOAR learns a compact state projection from per node structural embeddings to rapidly score and select a small subset of devices (a top-k partition) on which a conventional low-level actor performs focused beam search utilizing a critic agent. Selected candidate actions are evaluated with batched critic forwards and stored in an LRU cache keyed by a quantized state projection and local action identifiers, dramatically reducing redundant critic computation while preserving decision quality via conservative k-hop cache invalidation. Empirically, MetaDOAR attains higher player payoffs than SOTA baselines on large network topologies, without significant scaling issues in terms of memory usage or training time. This contribution provide a practical, theoretically motivated path to efficient hierarchical policy learning for large-scale networked decision problems.",
      "authors": [
        "Michael Lanier",
        "Yevgeniy Vorobeychik"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CR"
      ],
      "published": "2026-02-18 16:07:01+00:00",
      "link": "https://arxiv.org/pdf/2602.16564v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16561v1",
      "title": "Hidden in Plain Sight: Detecting Illicit Massage Businesses from Mobility Data",
      "abstract": "Illicit massage businesses (IMBs) masquerade as legitimate massage parlors while facilitating commercial sex and human trafficking. Law enforcement must identify these businesses within a dense population of lawful establishments, but investigative resources are limited and the illicit status of each location is unknown until inspection. Detection methods based on online reviews offer some insight, yet operators can manipulate these signals, leaving covert establishments undetected. IMBs constitute one of the largest segments of indoor sex trafficking in the United States, with an estimated 9,000 establishments. Mobility data offers an alternative to online signals, covering establishments that avoid digital visibility entirely. We derive features from mobility data spanning temporal visitation patterns, dwell times, visitor catchment areas, and demand stability. Because confirmed labels exist only for establishments identified through advertising platforms, we employ positive-unlabeled learning to address the label asymmetry in ground truth. The model achieves 0.97 AUC and 0.84 Average Precision. Four operational signatures characterize high-risk establishments: demand consistency, evening-concentrated visits, compressed service durations, and locally drawn clientele. The model produces risk scores for each business-week observation. Aggregating to the business level, prioritizing the highest-risk 10% of massage establishments captures 53% of known illicit operations, a 5.3-fold improvement over uninformed inspection. We develop a decision-support system that produces calibrated prioritization scores for law enforcement, enabling investigators to concentrate inspections on the highest-risk venues. The operational signatures may resist strategic manipulation because they reflect actual operations rather than online signals that operators can control.",
      "authors": [
        "Roya Shomali",
        "Nick Freeman",
        "Greg Bott",
        "Iman Dayarian",
        "Jason Parton"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "published": "2026-02-18 16:02:26+00:00",
      "link": "https://arxiv.org/pdf/2602.16561v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16554v1",
      "title": "MerLean: An Agentic Framework for Autoformalization in Quantum Computation",
      "abstract": "We introduce MerLean, a fully automated agentic framework for autoformalization in quantum computation. MerLean extracts mathematical statements from \\LaTeX{} source files, formalizes them into verified Lean~4 code built on Mathlib, and translates the result back into human-readable \\LaTeX{} for semantic review. We evaluate MerLean on three theoretical quantum computing papers producing 2,050 Lean declarations from 114 statements in total. MerLean achieves end-to-end formalization on all three papers, reducing the verification burden to only the newly introduced definitions and axioms. Our results demonstrate that agentic autoformalization can scale to frontier research, offering both a practical tool for machine-verified peer review and a scalable engine for mining high-quality synthetic data to train future reasoning models. Our approach can also be generalized to any other rigorous research in mathematics and theoretical physics.",
      "authors": [
        "Yuanjie Ren",
        "Jinzheng Li",
        "Yidi Qi"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.ET",
        "quant-ph"
      ],
      "published": "2026-02-18 15:54:32+00:00",
      "link": "https://arxiv.org/pdf/2602.16554v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16551v1",
      "title": "Automated Extraction of Mechanical Constitutive Models from Scientific Literature using Large Language Models: Applications in Cultural Heritage Conservation",
      "abstract": "The preservation of cultural heritage is increasingly transitioning towards data-driven predictive maintenance and \"Digital Twin\" construction. However, the mechanical constitutive models required for high-fidelity simulations remain fragmented across decades of unstructured scientific literature, creating a \"Data Silo\" that hinders conservation engineering. To address this, we present an automated, two-stage agentic framework leveraging Large Language Models (LLMs) to extract mechanical constitutive equations, calibrated parameters, and metadata from PDF documents. The workflow employs a resource-efficient \"Gatekeeper\" agent for relevance filtering and a high-capability \"Analyst\" agent for fine-grained extraction, featuring a novel Context-Aware Symbolic Grounding mechanism to resolve mathematical ambiguities. Applied to a corpus of over 2,000 research papers, the system successfully isolated 113 core documents and constructed a structured database containing 185 constitutive model instances and over 450 calibrated parameters. The extraction precision reached 80.4\\%, establishing a highly efficient \"Human-in-the-loop\" workflow that reduces manual data curation time by approximately 90\\%. We demonstrate the system's utility through a web-based Knowledge Retrieval Platform, which enables rapid parameter discovery for computational modeling. This work transforms scattered literature into a queryable digital asset, laying the data foundation for the \"Digital Material Twin\" of built heritage.",
      "authors": [
        "Rui Hu",
        "Yue Wu",
        "Tianhao Su",
        "Yin Wang",
        "Shunbo Hu",
        "Jizhong Huang"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-02-18 15:53:15+00:00",
      "link": "https://arxiv.org/pdf/2602.16551v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16548v1",
      "title": "RIDER: 3D RNA Inverse Design with Reinforcement Learning-Guided Diffusion",
      "abstract": "The inverse design of RNA three-dimensional (3D) structures is crucial for engineering functional RNAs in synthetic biology and therapeutics. While recent deep learning approaches have advanced this field, they are typically optimized and evaluated using native sequence recovery, which is a limited surrogate for structural fidelity, since different sequences can fold into similar 3D structures and high recovery does not necessarily indicate correct folding. To address this limitation, we propose RIDER, an RNA Inverse DEsign framework with Reinforcement learning that directly optimizes for 3D structural similarity. First, we develop and pre-train a GNN-based generative diffusion model conditioned on the target 3D structure, achieving a 9% improvement in native sequence recovery over state-of-the-art methods. Then, we fine-tune the model with an improved policy gradient algorithm using four task-specific reward functions based on 3D self-consistency metrics. Experimental results show that RIDER improves structural similarity by over 100% across all metrics and discovers designs that are distinct from native sequences.",
      "authors": [
        "Tianmeng Hu",
        "Yongzheng Cui",
        "Biao Luo",
        "Ke Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 15:52:26+00:00",
      "link": "https://arxiv.org/pdf/2602.16548v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16543v1",
      "title": "Vulnerability Analysis of Safe Reinforcement Learning via Inverse Constrained Reinforcement Learning",
      "abstract": "Safe reinforcement learning (Safe RL) aims to ensure policy performance while satisfying safety constraints. However, most existing Safe RL methods assume benign environments, making them vulnerable to adversarial perturbations commonly encountered in real-world settings. In addition, existing gradient-based adversarial attacks typically require access to the policy's gradient information, which is often impractical in real-world scenarios. To address these challenges, we propose an adversarial attack framework to reveal vulnerabilities of Safe RL policies. Using expert demonstrations and black-box environment interaction, our framework learns a constraint model and a surrogate (learner) policy, enabling gradient-based attack optimization without requiring the victim policy's internal gradients or the ground-truth safety constraints. We further provide theoretical analysis establishing feasibility and deriving perturbation bounds. Experiments on multiple Safe RL benchmarks demonstrate the effectiveness of our approach under limited privileged access.",
      "authors": [
        "Jialiang Fan",
        "Shixiong Jiang",
        "Mengyu Liu",
        "Fanxin Kong"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 15:43:36+00:00",
      "link": "https://arxiv.org/pdf/2602.16543v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16531v1",
      "title": "Transfer Learning of Linear Regression with Multiple Pretrained Models: Benefiting from More Pretrained Models via Overparameterization Debiasing",
      "abstract": "We study transfer learning for a linear regression task using several least-squares pretrained models that can be overparameterized.   We formulate the target learning task as optimization that minimizes squared errors on the target dataset with penalty on the distance of the learned model from the pretrained models. We analytically formulate the test error of the learned target model and provide the corresponding empirical evaluations.   Our results elucidate when using more pretrained models can improve transfer learning. Specifically, if the pretrained models are overparameterized, using sufficiently many of them is important for beneficial transfer learning. However, the learning may be compromised by overparameterization bias of pretrained models, i.e., the minimum $\\ell_2$-norm solution's restriction to a small subspace spanned by the training examples in the high-dimensional parameter space. We propose a simple debiasing via multiplicative correction factor that can reduce the overparameterization bias and leverage more pretrained models to learn a target predictor.",
      "authors": [
        "Daniel Boharon",
        "Yehuda Dar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 15:19:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16531v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16530v1",
      "title": "FEKAN: Feature-Enriched Kolmogorov-Arnold Networks",
      "abstract": "Kolmogorov-Arnold Networks (KANs) have recently emerged as a compelling alternative to multilayer perceptrons, offering enhanced interpretability via functional decomposition. However, existing KAN architectures, including spline-, wavelet-, radial-basis variants, etc., suffer from high computational cost and slow convergence, limiting scalability and practical applicability. Here, we introduce Feature-Enriched Kolmogorov-Arnold Networks (FEKAN), a simple yet effective extension that preserves all the advantages of KAN while improving computational efficiency and predictive accuracy through feature enrichment, without increasing the number of trainable parameters. By incorporating these additional features, FEKAN accelerates convergence, increases representation capacity, and substantially mitigates the computational overhead characteristic of state-of-the-art KAN architectures. We investigate FEKAN across a comprehensive set of benchmarks, including function-approximation tasks, physics-informed formulations for diverse partial differential equations (PDEs), and neural operator settings that map between input and output function spaces. For function approximation, we systematically compare FEKAN against a broad family of KAN variants, FastKAN, WavKAN, ReLUKAN, HRKAN, ChebyshevKAN, RBFKAN, and the original SplineKAN. Across all tasks, FEKAN demonstrates substantially faster convergence and consistently higher approximation accuracy than the underlying baseline architectures. We also establish the theoretical foundations for FEKAN, showing its superior representation capacity compared to KAN, which contributes to improved accuracy and efficiency.",
      "authors": [
        "Sidharth S. Menon",
        "Ameya D. Jagtap"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math-ph"
      ],
      "published": "2026-02-18 15:17:55+00:00",
      "link": "https://arxiv.org/pdf/2602.16530v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16525v1",
      "title": "Capacity-constrained demand response in smart grids using deep reinforcement learning",
      "abstract": "This paper presents a capacity-constrained incentive-based demand response approach for residential smart grids. It aims to maintain electricity grid capacity limits and prevent congestion by financially incentivising end users to reduce or shift their energy consumption. The proposed framework adopts a hierarchical architecture in which a service provider adjusts hourly incentive rates based on wholesale electricity prices and aggregated residential load. The financial interests of both the service provider and end users are explicitly considered. A deep reinforcement learning approach is employed to learn optimal real-time incentive rates under explicit capacity constraints. Heterogeneous user preferences are modelled through appliance-level home energy management systems and dissatisfaction costs. Using real-world residential electricity consumption and price data from three households, simulation results show that the proposed approach effectively reduces peak demand and smooths the aggregated load profile. This leads to an approximately 22.82% reduction in the peak-to-average ratio compared to the no-demand-response case.",
      "authors": [
        "Shafagh Abband Pashaki",
        "Sepehr Maleki",
        "Amir Badiee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 15:13:07+00:00",
      "link": "https://arxiv.org/pdf/2602.16525v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16523v1",
      "title": "Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study",
      "abstract": "We extend directed quantum circuit synthesis (DQCS) with reinforcement learning from purely discrete gate selection to parameterized quantum state preparation with continuous single-qubit rotations \\(R_x\\), \\(R_y\\), and \\(R_z\\). We compare two training regimes: a one-stage agent that jointly selects the gate type, the affected qubit(s), and the rotation angle; and a two-stage variant that first proposes a discrete circuit and subsequently optimizes the rotation angles with Adam using parameter-shift gradients. Using Gymnasium and PennyLane, we evaluate Proximal Policy Optimization (PPO) and Advantage Actor--Critic (A2C) on systems comprising two to ten qubits and on targets of increasing complexity with \\(λ\\) ranging from one to five. Whereas A2C does not learn effective policies in this setting, PPO succeeds under stable hyperparameters (one-stage: learning rate approximately \\(5\\times10^{-4}\\) with a self-fidelity-error threshold of 0.01; two-stage: learning rate approximately \\(10^{-4}\\)). Both approaches reliably reconstruct computational basis states (between 83\\% and 99\\% success) and Bell states (between 61\\% and 77\\% success). However, scalability saturates for \\(λ\\) of approximately three to four and does not extend to ten-qubit targets even at \\(λ=2\\). The two-stage method offers only marginal accuracy gains while requiring around three times the runtime. For practicality under a fixed compute budget, we therefore recommend the one-stage PPO policy, provide explicit synthesized circuits, and contrast with a classical variational baseline to outline avenues for improved scalability.",
      "authors": [
        "Gerhard Stenzel",
        "Isabella Debelic",
        "Michael Kölle",
        "Tobias Rohe",
        "Leo Sünkel",
        "Julian Hager",
        "Claudia Linnhoff-Popien"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "quant-ph"
      ],
      "published": "2026-02-18 15:10:43+00:00",
      "link": "https://arxiv.org/pdf/2602.16523v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16522v1",
      "title": "Disproving (Positive) Almost-Sure Termination of Probabilistic Term Rewriting via Random Walks",
      "abstract": "In recent years, numerous techniques were developed to automatically prove termination of different kinds of probabilistic programs. However, there are only few automated methods to disprove their termination. In this paper, we present the first techniques to automatically disprove (positive) almost-sure termination of probabilistic term rewrite systems. Disproving termination of non-probabilistic systems requires finding a finite representation of an infinite computation, e.g., a loop of the rewrite system. We extend such qualitative techniques to probabilistic term rewriting, where a quantitative analysis is required. In addition to the existence of a loop, we have to count the number of such loops in order to embed suitable random walks into a computation, thereby disproving termination. To evaluate their power, we implemented all our techniques in the tool AProVE.",
      "authors": [
        "Jan-Christoph Kassing",
        "Henri Nagel",
        "Alexander Schlecht",
        "Jürgen Giesl"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-02-18 15:10:24+00:00",
      "link": "https://arxiv.org/pdf/2602.16522v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16502v1",
      "title": "DressWild: Feed-Forward Pose-Agnostic Garment Sewing Pattern Generation from In-the-Wild Images",
      "abstract": "Recent advances in garment pattern generation have shown promising progress. However, existing feed-forward methods struggle with diverse poses and viewpoints, while optimization-based approaches are computationally expensive and difficult to scale. This paper focuses on sewing pattern generation for garment modeling and fabrication applications that demand editable, separable, and simulation-ready garments. We propose DressWild, a novel feed-forward pipeline that reconstructs physics-consistent 2D sewing patterns and the corresponding 3D garments from a single in-the-wild image. Given an input image, our method leverages vision-language models (VLMs) to normalize pose variations at the image level, then extract pose-aware, 3D-informed garment features. These features are fused through a transformer-based encoder and subsequently used to predict sewing pattern parameters, which can be directly applied to physical simulation, texture synthesis, and multi-layer virtual try-on. Extensive experiments demonstrate that our approach robustly recovers diverse sewing patterns and the corresponding 3D garments from in-the-wild images without requiring multi-view inputs or iterative optimization, offering an efficient and scalable solution for realistic garment simulation and animation.",
      "authors": [
        "Zeng Tao",
        "Ying Jiang",
        "Yunuo Chen",
        "Tianyi Xie",
        "Huamin Wang",
        "Yingnian Wu",
        "Yin Yang",
        "Abishek Sampath Kumar",
        "Kenji Tashiro",
        "Chenfanfu Jiang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-18 14:45:15+00:00",
      "link": "https://arxiv.org/pdf/2602.16502v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16481v1",
      "title": "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach",
      "abstract": "Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.",
      "authors": [
        "Zihao Li",
        "Fabrizio Russo"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-18 14:15:21+00:00",
      "link": "https://arxiv.org/pdf/2602.16481v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16476v1",
      "title": "Learning Preference from Observed Rankings",
      "abstract": "Estimating consumer preferences is central to many problems in economics and marketing. This paper develops a flexible framework for learning individual preferences from partial ranking information by interpreting observed rankings as collections of pairwise comparisons with logistic choice probabilities. We model latent utility as the sum of interpretable product attributes, item fixed effects, and a low-rank user-item factor structure, enabling both interpretability and information sharing across consumers and items. We further correct for selection in which comparisons are observed: a comparison is recorded only if both items enter the consumer's consideration set, inducing exposure bias toward frequently encountered items. We model pair observability as the product of item-level observability propensities and estimate these propensities with a logistic model for the marginal probability that an item is observable. Preference parameters are then estimated by maximizing an inverse-probability-weighted (IPW), ridge-regularized log-likelihood that reweights observed comparisons toward a target comparison population. To scale computation, we propose a stochastic gradient descent (SGD) algorithm based on inverse-probability resampling, which draws comparisons in proportion to their IPW weights. In an application to transaction data from an online wine retailer, the method improves out-of-sample recommendation performance relative to a popularity-based benchmark, with particularly strong gains in predicting purchases of previously unconsumed products.",
      "authors": [
        "Yu-Chang Chen",
        "Chen Chian Fuh",
        "Shang En Tsai"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-18 14:07:05+00:00",
      "link": "https://arxiv.org/pdf/2602.16476v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16473v1",
      "title": "Synthesis and Verification of Transformer Programs",
      "abstract": "C-RASP is a simple programming language that was recently shown to capture concepts expressible by transformers. In this paper, we develop new algorithmic techniques for automatically verifying C-RASPs. To this end, we establish a connection to the verification of synchronous dataflow programs in Lustre, which enables us to exploit state-of-the-art model checkers utilizing highly optimized SMT-solvers. Our second contribution addresses learning a C-RASP program in the first place. To this end, we provide a new algorithm for learning a C-RASP from examples using local search. We demonstrate efficacy of our implementation for benchmarks of C-RASPs in the literature, in particular in connection to the following applications: (1) transformer program optimization, and (2) constrained learning of transformer programs (based on a partial specification).",
      "authors": [
        "Hongjian Jiang",
        "Matthew Hague",
        "Philipp Rümmer",
        "Anthony Widjaja Lin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.FL",
        "cs.LO"
      ],
      "published": "2026-02-18 14:04:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16473v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16468v1",
      "title": "HPMixer: Hierarchical Patching for Multivariate Time Series Forecasting",
      "abstract": "In long-term multivariate time series forecasting, effectively capturing both periodic patterns and residual dynamics is essential. To address this within standard deep learning benchmark settings, we propose the Hierarchical Patching Mixer (HPMixer), which models periodicity and residuals in a decoupled yet complementary manner. The periodic component utilizes a learnable cycle module [7] enhanced with a nonlinear channel-wise MLP for greater expressiveness. The residual component is processed through a Learnable Stationary Wavelet Transform (LSWT) to extract stable, shift-invariant frequency-domain representations. Subsequently, a channel-mixing encoder models explicit inter-channel dependencies, while a two-level non-overlapping hierarchical patching mechanism captures coarse- and fine-scale residual variations. By integrating decoupled periodicity modeling with structured, multi-scale residual learning, HPMixer provides an effective framework. Extensive experiments on standard multivariate benchmarks demonstrate that HPMixer achieves competitive or state-of-the-art performance compared to recent baselines.",
      "authors": [
        "Jung Min Choi",
        "Vijaya Krishna Yalavarthi",
        "Lars Schmidt-Thieme"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 13:59:04+00:00",
      "link": "https://arxiv.org/pdf/2602.16468v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16459v1",
      "title": "Continuous Fluid Antenna Sampling for Channel Estimation in Cell-Free Massive MIMO",
      "abstract": "In this letter, we develop a continuous fluid antenna (FA) framework for uplink channel estimation in cell-free massive multiple-input and multiple-output (CF-mMIMO) systems. By modeling the wireless channel as a spatially correlated Gaussian random field, channel estimation is formulated as a Gaussian process (GP) regression problem with motion-constrained spatial sampling. Closed-form expressions for the linear minimum mean squared error (LMMSE) estimator and the corresponding estimation error are derived. A fundamental comparison with discrete port-based architectures is established under identical position constraints, showing that continuous FA sampling achieves equal or lower estimation error for any finite pilot budget, with strict improvement for non-degenerate spatial correlation models. Numerical results validate the analysis and show the performance gains of continuous FA sampling over discrete baselines.",
      "authors": [
        "Masoud Kaveh",
        "Farshad Rostami Ghadi",
        "Francisco Hernando-Gallego",
        "Diego Martin",
        "Riku Jantti",
        "Kai-Kit Wong"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "eess.SP"
      ],
      "published": "2026-02-18 13:46:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16459v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16442v1",
      "title": "Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA",
      "abstract": "As the volume of data recorded by embedded edge sensors increases, particularly from neuromorphic devices producing discrete event streams, there is a growing need for hardware-aware neural architectures that enable efficient, low-latency, and energy-conscious local processing. We present an FPGA implementation of event-graph neural networks for audio processing. We utilise an artificial cochlea that converts time-series signals into sparse event data, reducing memory and computation costs. Our architecture was implemented on a SoC FPGA and evaluated on two open-source datasets. For classification task, our baseline floating-point model achieves 92.7% accuracy on SHD dataset - only 2.4% below the state of the art - while requiring over 10x and 67x fewer parameters. On SSC, our models achieve 66.9-71.0% accuracy. Compared to FPGA-based spiking neural networks, our quantised model reaches 92.3% accuracy, outperforming them by up to 19.3% while reducing resource usage and latency. For SSC, we report the first hardware-accelerated evaluation. We further demonstrate the first end-to-end FPGA implementation of event-audio keyword spotting, combining graph convolutional layers with recurrent sequence modelling. The system achieves up to 95% word-end detection accuracy, with only 10.53 microsecond latency and 1.18 W power consumption, establishing a strong benchmark for energy-efficient event-driven KWS.",
      "authors": [
        "Kamil Jeziorek",
        "Piotr Wzorek",
        "Krzysztof Blachut",
        "Hiroshi Nakano",
        "Manon Dampfhoffer",
        "Thomas Mesquida",
        "Hiroaki Nishi",
        "Thomas Dalgaty",
        "Tomasz Kryjak"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "published": "2026-02-18 13:26:22+00:00",
      "link": "https://arxiv.org/pdf/2602.16442v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16435v1",
      "title": "Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning",
      "abstract": "Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.",
      "authors": [
        "Arun Vignesh Malarkkan",
        "Wangyang Ying",
        "Yanjie Fu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-02-18 13:12:11+00:00",
      "link": "https://arxiv.org/pdf/2602.16435v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16422v1",
      "title": "Automated Histopathology Report Generation via Pyramidal Feature Extraction and the UNI Foundation Model",
      "abstract": "Generating diagnostic text from histopathology whole slide images (WSIs) is challenging due to the gigapixel scale of the input and the requirement for precise, domain specific language. We propose a hierarchical vision language framework that combines a frozen pathology foundation model with a Transformer decoder for report generation. To make WSI processing tractable, we perform multi resolution pyramidal patch selection (downsampling factors 2^3 to 2^6) and remove background and artifacts using Laplacian variance and HSV based criteria. Patch features are extracted with the UNI Vision Transformer and projected to a 6 layer Transformer decoder that generates diagnostic text via cross attention. To better represent biomedical terminology, we tokenize the output using BioGPT. Finally, we add a retrieval based verification step that compares generated reports with a reference corpus using Sentence BERT embeddings; if a high similarity match is found, the generated report is replaced with the retrieved ground truth reference to improve reliability.",
      "authors": [
        "Ahmet Halici",
        "Ece Tugba Cebeci",
        "Musa Balci",
        "Mustafa Cini",
        "Serkan Sokmen"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-18 12:55:20+00:00",
      "link": "https://arxiv.org/pdf/2602.16422v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16400v1",
      "title": "Easy Data Unlearning Bench",
      "abstract": "Evaluating machine unlearning methods remains technically challenging, with recent benchmarks requiring complex setups and significant engineering overhead. We introduce a unified and extensible benchmarking suite that simplifies the evaluation of unlearning algorithms using the KLoM (KL divergence of Margins) metric. Our framework provides precomputed model ensembles, oracle outputs, and streamlined infrastructure for running evaluations out of the box. By standardizing setup and metrics, it enables reproducible, scalable, and fair comparison across unlearning methods. We aim for this benchmark to serve as a practical foundation for accelerating research and promoting best practices in machine unlearning. Our code and data are publicly available.",
      "authors": [
        "Roy Rinberg",
        "Pol Puigdemont",
        "Martin Pawelczyk",
        "Volkan Cevher"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 12:20:32+00:00",
      "link": "https://arxiv.org/pdf/2602.16400v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16379v1",
      "title": "Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents",
      "abstract": "We propose an agentic data augmentation method for Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce high quality synthetic training examples. To isolate the effect of agentic structure, we also develop a closely matched prompting-based baseline using the same model and instructions. Both methods are evaluated across three ABSA subtasks (Aspect Term Extraction (ATE), Aspect Sentiment Classification (ATSC), and Aspect Sentiment Pair Extraction (ASPE)), four SemEval datasets, and two encoder-decoder models: T5-Base and Tk-Instruct. Our results show that the agentic augmentation outperforms raw prompting in label preservation of the augmented data, especially when the tasks require aspect term generation. In addition, when combined with real data, agentic augmentation provides higher gains, consistently outperforming prompting-based generation. These benefits are most pronounced for T5-Base, while the more heavily pretrained Tk-Instruct exhibits smaller improvements. As a result, augmented data helps T5-Base achieve comparable performance with its counterpart.",
      "authors": [
        "Mohammad H. A. Monfared",
        "Lucie Flek",
        "Akbar Karimi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-18 11:38:11+00:00",
      "link": "https://arxiv.org/pdf/2602.16379v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16371v1",
      "title": "Dynamic Modeling and MPC for Locomotion of Tendon-Driven Soft Quadruped",
      "abstract": "SLOT (Soft Legged Omnidirectional Tetrapod), a tendon-driven soft quadruped robot with 3D-printed TPU legs, is presented to study physics-informed modeling and control of compliant legged locomotion using only four actuators. Each leg is modeled as a deformable continuum using discrete Cosserat rod theory, enabling the capture of large bending deformations, distributed elasticity, tendon actuation, and ground contact interactions. A modular whole-body modeling framework is introduced, in which compliant leg dynamics are represented through physically consistent reaction forces applied to a rigid torso, providing a scalable interface between continuum soft limbs and rigid-body locomotion dynamics. This formulation allows efficient whole-body simulation and real-time control without sacrificing physical fidelity. The proposed model is embedded into a convex model predictive control framework that optimizes ground reaction forces over a 0.495 s prediction horizon and maps them to tendon actuation through a physics-informed force-angle relationship. The resulting controller achieves asymptotic stability under diverse perturbations. The framework is experimentally validated on a physical prototype during crawling and walking gaits, achieving high accuracy with less than 5 mm RMSE in center of mass trajectories. These results demonstrate a generalizable approach for integrating continuum soft legs into model-based locomotion control, advancing scalable and reusable modeling and control methods for soft quadruped robots.",
      "authors": [
        "Saumya Karan",
        "Neerav Maram",
        "Suraj Borate",
        "Madhu Vadali"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-18 11:14:22+00:00",
      "link": "https://arxiv.org/pdf/2602.16371v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16367v1",
      "title": "A Multihop Rendezvous Protocol for Cognitive Radio-based Emergency Response Network",
      "abstract": "This letter proposes a novel Multihop Dual Modular Clock Algorithm (M-DMCA) for efficient node discovery in cognitive radio-based emergency response networks. M-DMCA supports dual-channel selection per timeslot and incorporates a three-way handshake mechanism to significantly reduce rendezvous time. Performance evaluation under a worst-case scenario with 20 nodes, asymmetric channel sets of size 20, channel similarity index (m) as 2, and high primary radio activity shows that M-DMCA achieves a 24% reduction in rendezvous time compared to the multihop Extended Modular Clock Algorithm (EMCA), outperforming existing rendezvous protocols.",
      "authors": [
        "Zahid Ali",
        "Saritha Unnikrishnan",
        "Eoghan Furey",
        "Ian McLoughlin",
        "Saim Ghafoor"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI",
        "cs.ET"
      ],
      "published": "2026-02-18 11:09:58+00:00",
      "link": "https://arxiv.org/pdf/2602.16367v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16360v1",
      "title": "Docking and Persistent Operations for a Resident Underwater Vehicle",
      "abstract": "Our understanding of the oceans remains limited by sparse and infrequent observations, primarily because current methods are constrained by the high cost and logistical effort of underwater monitoring, relying either on sporadic surveys across broad areas or on long-term measurements at fixed locations. To overcome these limitations, monitoring systems must enable persistent and autonomous operations without the need for continuous surface support. Despite recent advances, resident underwater vehicles remain uncommon due to persistent challenges in autonomy, robotic resilience, and mechanical robustness, particularly under long-term deployment in harsh and remote environments. This work addresses these problems by presenting the development, deployment, and operation of a resident infrastructure using a docking station with a mini-class Remotely Operated Vehicle (ROV) at 90m depth. The ROVis equipped with enhanced onboard processing and perception, allowing it to autonomously navigate using USBL signals, dock via ArUco marker-based visual localisation fused through an Extended Kalman Filter, and carry out local inspection routines. The system demonstrated a 90% autonomous docking success rate and completed full inspection missions within four minutes, validating the integration of acoustic and visual navigation in real-world conditions. These results show that reliable, untethered operations at depth are feasible, highlighting the potential of resident ROV systems for scalable, cost-effective underwater monitoring.",
      "authors": [
        "Leonard Günzel",
        "Gabrielė Kasparavičiūtė",
        "Ambjørn Grimsrud Waldum",
        "Bjørn-Magnus Moslått",
        "Abubakar Aliyu Badawi",
        "Celil Yılmaz",
        "Md Shamin Yeasher Yousha",
        "Robert Staven",
        "Martin Ludvigsen"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-18 10:50:04+00:00",
      "link": "https://arxiv.org/pdf/2602.16360v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16357v1",
      "title": "Optical Inversion and Spectral Unmixing of Spectroscopic Photoacoustic Images with Physics-Informed Neural Networks",
      "abstract": "Accurate estimation of the relative concentrations of chromophores in a spectroscopic photoacoustic (sPA) image can reveal immense structural, functional, and molecular information about physiological processes. However, due to nonlinearities and ill-posedness inherent to sPA imaging, concentration estimation is intractable. The Spectroscopic Photoacoustic Optical Inversion Autoencoder (SPOI-AE) aims to address the sPA optical inversion and spectral unmixing problems without assuming linearity. Herein, SPOI-AE was trained and tested on \\textit{in vivo} mouse lymph node sPA images with unknown ground truth chromophore concentrations. SPOI-AE better reconstructs input sPA pixels than conventional algorithms while providing biologically coherent estimates for optical parameters, chromophore concentrations, and the percent oxygen saturation of tissue. SPOI-AE's unmixing accuracy was validated using a simulated mouse lymph node phantom ground truth.",
      "authors": [
        "Sarkis Ter Martirosyan",
        "Xinyue Huang",
        "David Qin",
        "Anthony Yu",
        "Stanislav Emelianov"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "q-bio.QM"
      ],
      "published": "2026-02-18 10:44:45+00:00",
      "link": "https://arxiv.org/pdf/2602.16357v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16353v1",
      "title": "Dual-Quadruped Collaborative Transportation in Narrow Environments via Safe Reinforcement Learning",
      "abstract": "Collaborative transportation, where multiple robots collaboratively transport a payload, has garnered significant attention in recent years. While ensuring safe and high-performance inter-robot collaboration is critical for effective task execution, it is difficult to pursue in narrow environments where the feasible region is extremely limited. To address this challenge, we propose a novel approach for dual-quadruped collaborative transportation via safe reinforcement learning (RL). Specifically, we model the task as a fully cooperative constrained Markov game, where collision avoidance is formulated as constraints. We introduce a cost-advantage decomposition method that enforces the sum of team constraints to remain below an upper bound, thereby guaranteeing task safety within an RL framework. Furthermore, we propose a constraint allocation method that assigns shared constraints to individual robots to maximize the overall task reward, encouraging autonomous task-assignment among robots, thereby improving collaborative task performance. Simulation and real-time experimental results demonstrate that the proposed approach achieves superior performance and a higher success rate in dual-quadruped collaborative transportation compared to existing methods.",
      "authors": [
        "Zhezhi Lei",
        "Zhihai Bi",
        "Wenxin Wang",
        "Jun Ma"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-18 10:35:45+00:00",
      "link": "https://arxiv.org/pdf/2602.16353v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16346v1",
      "title": "Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents",
      "abstract": "LLM-based agents execute real-world workflows via tools and memory. These affordances enable ill-intended adversaries to also use these agents to carry out complex misuse scenarios. Existing agent misuse benchmarks largely test single-prompt instructions, leaving a gap in measuring how agents end up helping with harmful or illegal tasks over multiple turns. We introduce STING (Sequential Testing of Illicit N-step Goal execution), an automated red-teaming framework that constructs a step-by-step illicit plan grounded in a benign persona and iteratively probes a target agent with adaptive follow-ups, using judge agents to track phase completion. We further introduce an analysis framework that models multi-turn red-teaming as a time-to-first-jailbreak random variable, enabling analysis tools like discovery curves, hazard-ratio attribution by attack language, and a new metric: Restricted Mean Jailbreak Discovery. Across AgentHarm scenarios, STING yields substantially higher illicit-task completion than single-turn prompting and chat-oriented multi-turn baselines adapted to tool-using agents. In multilingual evaluations across six non-English settings, we find that attack success and illicit-task completion do not consistently increase in lower-resource languages, diverging from common chatbot findings. Overall, STING provides a practical way to evaluate and stress-test agent misuse in realistic deployment settings, where interactions are inherently multi-turn and often multilingual.",
      "authors": [
        "Nivya Talokar",
        "Ayush K Tarun",
        "Murari Mandal",
        "Maksym Andriushchenko",
        "Antoine Bosselut"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-18 10:31:19+00:00",
      "link": "https://arxiv.org/pdf/2602.16346v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16343v1",
      "title": "How to Label Resynthesized Audio: The Dual Role of Neural Audio Codecs in Audio Deepfake Detection",
      "abstract": "Since Text-to-Speech systems typically don't produce waveforms directly, recent spoof detection studies use resynthesized waveforms from vocoders and neural audio codecs to simulate an attacker. Unlike vocoders, which are specifically designed for speech synthesis, neural audio codecs were originally developed for compressing audio for storage and transmission. However, their ability to discretize speech also sparked interest in language-modeling-based speech synthesis. Owing to this dual functionality, codec resynthesized data may be labeled as either bonafide or spoof. So far, very little research has addressed this issue. In this study, we present a challenging extension of the ASVspoof 5 dataset constructed for this purpose. We examine how different labeling choices affect detection performance and provide insights into labeling strategies.",
      "authors": [
        "Yixuan Xiao",
        "Florian Lux",
        "Alejandro Pérez-González-de-Martos",
        "Ngoc Thang Vu"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.LG"
      ],
      "published": "2026-02-18 10:29:07+00:00",
      "link": "https://arxiv.org/pdf/2602.16343v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16341v1",
      "title": "Explainability for Fault Detection System in Chemical Processes",
      "abstract": "In this work, we apply and compare two state-of-the-art eXplainability Artificial Intelligence (XAI) methods, the Integrated Gradients (IG) and the SHapley Additive exPlanations (SHAP), that explain the fault diagnosis decisions of a highly accurate Long Short-Time Memory (LSTM) classifier. The classifier is trained to detect faults in a benchmark non-linear chemical process, the Tennessee Eastman Process (TEP). It is highlighted how XAI methods can help identify the subsystem of the process where the fault occurred. Using our knowledge of the process, we note that in most cases the same features are indicated as the most important for the decision, while insome cases the SHAP method seems to be more informative and closer to the root cause of the fault. Finally, since the used XAI methods are model-agnostic, the proposed approach is not limited to the specific process and can also be used in similar problems.",
      "authors": [
        "Georgios Gravanis",
        "Dimitrios Kyriakou",
        "Spyros Voutetakis",
        "Simira Papadopoulou",
        "Konstantinos Diamantaras"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 10:26:12+00:00",
      "link": "https://arxiv.org/pdf/2602.16341v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16337v1",
      "title": "Subtractive Modulative Network with Learnable Periodic Activations",
      "abstract": "We propose the Subtractive Modulative Network (SMN), a novel, parameter-efficient Implicit Neural Representation (INR) architecture inspired by classical subtractive synthesis. The SMN is designed as a principled signal processing pipeline, featuring a learnable periodic activation layer (Oscillator) that generates a multi-frequency basis, and a series of modulative mask modules (Filters) that actively generate high-order harmonics. We provide both theoretical analysis and empirical validation for our design. Our SMN achieves a PSNR of $40+$ dB on two image datasets, comparing favorably against state-of-the-art methods in terms of both reconstruction accuracy and parameter efficiency. Furthermore, consistent advantage is observed on the challenging 3D NeRF novel view synthesis task. Supplementary materials are available at https://inrainbws.github.io/smn/.",
      "authors": [
        "Tiou Wang",
        "Zhuoqian Yang",
        "Markus Flierl",
        "Mathieu Salzmann",
        "Sabine Süsstrunk"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-18 10:20:50+00:00",
      "link": "https://arxiv.org/pdf/2602.16337v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16322v1",
      "title": "A Self-Supervised Approach for Enhanced Feature Representations in Object Detection Tasks",
      "abstract": "In the fast-evolving field of artificial intelligence, where models are increasingly growing in complexity and size, the availability of labeled data for training deep learning models has become a significant challenge. Addressing complex problems like object detection demands considerable time and resources for data labeling to achieve meaningful results. For companies developing such applications, this entails extensive investment in highly skilled personnel or costly outsourcing. This research work aims to demonstrate that enhancing feature extractors can substantially alleviate this challenge, enabling models to learn more effective representations with less labeled data. Utilizing a self-supervised learning strategy, we present a model trained on unlabeled data that outperforms state-of-the-art feature extractors pre-trained on ImageNet and particularly designed for object detection tasks. Moreover, the results demonstrate that our approach encourages the model to focus on the most relevant aspects of an object, thus achieving better feature representations and, therefore, reinforcing its reliability and robustness.",
      "authors": [
        "Santiago C. Vilabella",
        "Pablo Pérez-Núñez",
        "Beatriz Remeseiro"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-18 10:02:30+00:00",
      "link": "https://arxiv.org/pdf/2602.16322v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16320v1",
      "title": "RefineFormer3D: Efficient 3D Medical Image Segmentation via Adaptive Multi-Scale Transformer with Cross Attention Fusion",
      "abstract": "Accurate and computationally efficient 3D medical image segmentation remains a critical challenge in clinical workflows. Transformer-based architectures often demonstrate superior global contextual modeling but at the expense of excessive parameter counts and memory demands, restricting their clinical deployment. We propose RefineFormer3D, a lightweight hierarchical transformer architecture that balances segmentation accuracy and computational efficiency for volumetric medical imaging. The architecture integrates three key components: (i) GhostConv3D-based patch embedding for efficient feature extraction with minimal redundancy, (ii) MixFFN3D module with low-rank projections and depthwise convolutions for parameter-efficient feature extraction, and (iii) a cross-attention fusion decoder enabling adaptive multi-scale skip connection integration. RefineFormer3D contains only 2.94M parameters, substantially fewer than contemporary transformer-based methods. Extensive experiments on ACDC and BraTS benchmarks demonstrate that RefineFormer3D achieves 93.44\\% and 85.9\\% average Dice scores respectively, outperforming or matching state-of-the-art methods while requiring significantly fewer parameters. Furthermore, the model achieves fast inference (8.35 ms per volume on GPU) with low memory requirements, supporting deployment in resource-constrained clinical environments. These results establish RefineFormer3D as an effective and scalable solution for practical 3D medical image segmentation.",
      "authors": [
        "Kavyansh Tyagi",
        "Vishwas Rathi",
        "Puneet Goyal"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-18 09:58:59+00:00",
      "link": "https://arxiv.org/pdf/2602.16320v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16318v1",
      "title": "Interpolation in Proof Theory",
      "abstract": "This chapter provides a comprehensive overview of proof-theoretic methods for establishing interpolation properties across a range of logics, including classical, intuitionistic, modal, and substructural logics. Central to the discussion are two foundational techniques: Maehara's method for Craig interpolation and Pitts' method for uniform interpolation. The chapter demonstrates how these methods lead to results on the existence of well-behaved proof systems in the contemporary framework of universal proof theory and how they provide a road map for constructing interpolation proofs using modern proof formalisms. The emphasis of the chapter is on constructive, modular, and syntax-driven techniques that illuminate deeper connections between interpolation properties and proof systems.",
      "authors": [
        "Iris van der Giessen",
        "Raheleh Jalali",
        "Roman Kuznets"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-02-18 09:55:14+00:00",
      "link": "https://arxiv.org/pdf/2602.16318v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16317v1",
      "title": "CADEvolve: Creating Realistic CAD via Program Evolution",
      "abstract": "Computer-Aided Design (CAD) delivers rapid, editable modeling for engineering and manufacturing. Recent AI progress now makes full automation feasible for various CAD tasks. However, progress is bottlenecked by data: public corpora mostly contain sketch-extrude sequences, lack complex operations, multi-operation composition and design intent, and thus hinder effective fine-tuning. Attempts to bypass this with frozen VLMs often yield simple or invalid programs due to limited 3D grounding in current foundation models. We present CADEvolve, an evolution-based pipeline and dataset that starts from simple primitives and, via VLM-guided edits and validations, incrementally grows CAD programs toward industrial-grade complexity. The result is 8k complex parts expressed as executable CadQuery parametric generators. After multi-stage post-processing and augmentation, we obtain a unified dataset of 1.3m scripts paired with rendered geometry and exercising the full CadQuery operation set. A VLM fine-tuned on CADEvolve achieves state-of-the-art results on the Image2CAD task across the DeepCAD, Fusion 360, and MCB benchmarks.",
      "authors": [
        "Maksim Elistratov",
        "Marina Barannikov",
        "Gregory Ivanov",
        "Valentin Khrulkov",
        "Anton Konushin",
        "Andrey Kuznetsov",
        "Dmitrii Zhemchuzhnikov"
      ],
      "primary_category": "cs.GR",
      "categories": [
        "cs.GR"
      ],
      "published": "2026-02-18 09:54:57+00:00",
      "link": "https://arxiv.org/pdf/2602.16317v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16308v1",
      "title": "Markerless Robot Detection and 6D Pose Estimation for Multi-Agent SLAM",
      "abstract": "The capability of multi-robot SLAM approaches to merge localization history and maps from different observers is often challenged by the difficulty in establishing data association. Loop closure detection between perceptual inputs of different robotic agents is easily compromised in the context of perceptual aliasing, or when perspectives differ significantly. For this reason, direct mutual observation among robots is a powerful way to connect partial SLAM graphs, but often relies on the presence of calibrated arrays of fiducial markers (e.g., AprilTag arrays), which severely limits the range of observations and frequently fails under sharp lighting conditions, e.g., reflections or overexposure. In this work, we propose a novel solution to this problem leveraging recent advances in Deep-Learning-based 6D pose estimation. We feature markerless pose estimation as part of a decentralized multi-robot SLAM system and demonstrate the benefit to the relative localization accuracy among the robotic team. The solution is validated experimentally on data recorded in a test field campaign on a planetary analogous environment.",
      "authors": [
        "Markus Rueggeberg",
        "Maximilian Ulmer",
        "Maximilian Durner",
        "Wout Boerdijk",
        "Marcus Gerhard Mueller",
        "Rudolph Triebel",
        "Riccardo Giubilato"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-18 09:38:06+00:00",
      "link": "https://arxiv.org/pdf/2602.16308v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16305v1",
      "title": "BAT: Better Audio Transformer Guided by Convex Gated Probing",
      "abstract": "Probing is widely adopted in computer vision to faithfully evaluate self-supervised learning (SSL) embeddings, as fine-tuning may misrepresent their inherent quality. In contrast, audio SSL models still rely on fine-tuning because simple probing fails to unlock their full potential and alters their rankings when competing for SOTA on AudioSet. Hence, a robust and efficient probing mechanism is required to guide the trajectory of audio SSL towards reliable and reproducible methods. We introduce Convex Gated Probing (CGP), a prototype-based method that drastically closes the gap between fine-tuning and probing in audio. CGP efficiently utilizes all frozen layers via a gating mechanism and exposes the location of latent task-relevant information. Guided by CGP, we rework the entire SSL pipeline of current SOTA audio models that use legacy implementations of prior SSL methods. By refining data preprocessing, model architecture, and pre-training recipe, we introduce Better Audio Transformer (BAT), and establish new SOTA on audio benchmarks.",
      "authors": [
        "Houtan Ghaffari",
        "Lukas Rauch",
        "Christoph Scholz",
        "Paul Devos"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.LG"
      ],
      "published": "2026-02-18 09:37:20+00:00",
      "link": "https://arxiv.org/pdf/2602.16305v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16302v1",
      "title": "\"What I'm Interested in is Something that Violates the Law\": Regulatory Practitioner Views on Automated Detection of Deceptive Design Patterns",
      "abstract": "Although deceptive design patterns are subject to growing regulatory oversight, enforcement races to keep up with the scale of the problem. One promising solution is automated detection tools, many of which are developed within academia. We interviewed nine experienced practitioners working within or alongside regulatory bodies to understand their work against deceptive design patterns, including the use of supporting tools and the prospect of automation. Computing technologies have their place in regulatory practice, but not as envisioned in research. For example, investigations require utmost transparency and accountability in all the activities we identify as accompanying dark pattern detection, which many existing tools cannot provide. Moreover, tools need to map interfaces to legal violations to be of use. We thus recommend conducting user requirement research to maximize research impact, supporting ancillary activities beyond detection, and establishing practical tech adoption pathways that account for the needs of both scientific and regulatory activities.",
      "authors": [
        "Arianna Rossi",
        "Simon Parkin"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-02-18 09:33:59+00:00",
      "link": "https://arxiv.org/pdf/2602.16302v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16301v1",
      "title": "Multi-agent cooperation through in-context co-player inference",
      "abstract": "Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between \"learning-aware\" agents that account for and shape the learning dynamics of their co-players. However, existing approaches typically rely on hardcoded, often inconsistent, assumptions about co-player learning rules or enforce a strict separation between \"naive learners\" updating on fast timescales and \"meta-learners\" observing these updates. Here, we demonstrate that the in-context learning capabilities of sequence models allow for co-player learning awareness without requiring hardcoded assumptions or explicit timescale separation. We show that training sequence model agents against a diverse distribution of co-players naturally induces in-context best-response strategies, effectively functioning as learning algorithms on the fast intra-episode timescale. We find that the cooperative mechanism identified in prior work-where vulnerability to extortion drives mutual shaping-emerges naturally in this setting: in-context adaptation renders agents vulnerable to extortion, and the resulting mutual pressure to shape the opponent's in-context learning dynamics resolves into the learning of cooperative behavior. Our results suggest that standard decentralized reinforcement learning on sequence models combined with co-player diversity provides a scalable path to learning cooperative behaviors.",
      "authors": [
        "Marissa A. Weis",
        "Maciej Wołczyk",
        "Rajai Nasser",
        "Rif A. Saurous",
        "Blaise Agüera y Arcas",
        "João Sacramento",
        "Alexander Meulemans"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-18 09:31:43+00:00",
      "link": "https://arxiv.org/pdf/2602.16301v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16291v1",
      "title": "A Calculus of Overlays",
      "abstract": "Just as the $λ$-calculus uses three primitives (abstraction, application, variable) as the foundation of functional programming, Overlay-Calculus uses three primitives (record, definition, inheritance) as the foundation of declarative programming. It trivially embeds the $λ$-calculus, although the entire semantics builds on only naive set theory; as a consequence, all constructs including inheritance are inherently commutative, idempotent, and associative; the linearization problem of multiple inheritance simply does not arise. This induces a fully abstract semantics of the lazy $λ$-calculus with respect to Böhm tree equivalence. Overlay-Calculus is distilled from the Overlay language, a practical implementation in which we observed further emergent phenomena: the Expression Problem dissolves, programs are CPS-agnostic, records natively encode random-access memory, and self-reference resolves to multiple targets. These properties suggest applications to configuration languages, dependency injection, object-oriented programming, composable effect systems, modular software architectures, file-system-as-compiler, general-purpose programming, and no-code development.",
      "authors": [
        "Bo Yang"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL",
        "cs.SE"
      ],
      "published": "2026-02-18 09:17:20+00:00",
      "link": "https://arxiv.org/pdf/2602.16291v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16290v1",
      "title": "Aladdin-FTI @ AMIYA Three Wishes for Arabic NLP: Fidelity, Diglossia, and Multidialectal Generation",
      "abstract": "Arabic dialects have long been under-represented in Natural Language Processing (NLP) research due to their non-standardization and high variability, which pose challenges for computational modeling. Recent advances in the field, such as Large Language Models (LLMs), offer promising avenues to address this gap by enabling Arabic to be modeled as a pluricentric language rather than a monolithic system. This paper presents Aladdin-FTI, our submission to the AMIYA shared task. The proposed system is designed to both generate and translate dialectal Arabic (DA). Specifically, the model supports text generation in Moroccan, Egyptian, Palestinian, Syrian, and Saudi dialects, as well as bidirectional translation between these dialects, Modern Standard Arabic (MSA), and English. The code and trained model are publicly available.",
      "authors": [
        "Jonathan Mutal",
        "Perla Al Almaoui",
        "Simon Hengchen",
        "Pierrette Bouillon"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-18 09:15:20+00:00",
      "link": "https://arxiv.org/pdf/2602.16290v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16273v1",
      "title": "Lyapunov Spectral Analysis of Speech Embedding Trajectories in Psychosis",
      "abstract": "We analyze speech embeddings from structured clinical interviews of psychotic patients and healthy controls by treating language production as a high-dimensional dynamical process. Lyapunov exponent (LE) spectra are computed from word-level and answer-level embeddings generated by two distinct large language models, allowing us to assess the stability of the conclusions with respect to different embedding presentations. Word-level embeddings exhibit uniformly contracting dynamics with no positive LE, while answer-level embeddings, in spite of the overall contraction, display a number of positive LEs and higher-dimensional attractors. The resulting LE spectra robustly separate psychotic from healthy speech, while differentiation within the psychotic group is not statistically significant overall, despite a tendency of the most severe cases to occupy distinct dynamical regimes. These findings indicate that nonlinear dynamical invariants of speech embeddings provide a physics-inspired probe of disordered cognition whose conclusions remain stable across embedding models.",
      "authors": [
        "Jelena Vasic",
        "Branislav Andjelic",
        "Ana Mancic",
        "Dusica Filipovic Djurdjevic",
        "Ljiljana Mihic",
        "Aleksandar Kovacevic",
        "Nadja P. Maric",
        "Aleksandra Maluckov"
      ],
      "primary_category": "nlin.AO",
      "categories": [
        "nlin.AO",
        "cs.CL"
      ],
      "published": "2026-02-18 08:46:46+00:00",
      "link": "https://arxiv.org/pdf/2602.16273v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16264v1",
      "title": "Prediction of Major Solar Flares Using Interpretable Class-dependent Reward Framework with Active Region Magnetograms and Domain Knowledge",
      "abstract": "In this work, we develop, for the first time, a supervised classification framework with class-dependent rewards (CDR) to predict $\\geq$MM flares within 24 hr. We construct multiple datasets, covering knowledge-informed features and line-of sight (LOS) magnetograms. We also apply three deep learning models (CNN, CNN-BiLSTM, and Transformer) and three CDR counterparts (CDR-CNN, CDR-CNN-BiLSTM, and CDR-Transformer). First, we analyze the importance of LOS magnetic field parameters with the Transformer, then compare its performance using LOS-only, vector-only, and combined magnetic field parameters. Second, we compare flare prediction performance based on CDR models versus deep learning counterparts. Third, we perform sensitivity analysis on reward engineering for CDR models. Fourth, we use the SHAP method for model interpretability. Finally, we conduct performance comparison between our models and NASA/CCMC. The main findings are: (1)Among LOS feature combinations, R_VALUE and AREA_ACR consistently yield the best results. (2)Transformer achieves better performance with combined LOS and vector magnetic field data than with either alone. (3)Models using knowledge-informed features outperform those using magnetograms. (4)While CNN and CNN-BiLSTM outperform their CDR counterparts on magnetograms, CDR-Transformer is slightly superior to its deep learning counterpart when using knowledge-informed features. Among all models, CDR-Transformer achieves the best performance. (5)The predictive performance of the CDR models is not overly sensitive to the reward choices.(6)Through SHAP analysis, the CDR model tends to regard TOTUSJH as more important, while the Transformer tends to prioritize R_VALUE more.(7)Under identical prediction time and active region (AR) number, the CDR-Transformer shows superior predictive capabilities compared to NASA/CCMC.",
      "authors": [
        "Zixian Wu",
        "Xuebao Li",
        "Yanfang Zheng",
        "Rui Wang",
        "Shunhuang Zhang",
        "Jinfang Wei",
        "Yongshang Lv",
        "Liang Dong",
        "Zamri Zainal Abidin",
        "Noraisyah Mohamed Shah",
        "Hongwei Ye",
        "Pengchao Yan",
        "Xuefeng Li",
        "Xiaojia Ji",
        "Xusheng Huang",
        "Xiaotian Wang",
        "Honglei Jin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "astro-ph.SR"
      ],
      "published": "2026-02-18 08:30:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16264v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16256v1",
      "title": "Color-based Emotion Representation for Speech Emotion Recognition",
      "abstract": "Speech emotion recognition (SER) has traditionally relied on categorical or dimensional labels. However, this technique is limited in representing both the diversity and interpretability of emotions. To overcome this limitation, we focus on color attributes, such as hue, saturation, and value, to represent emotions as continuous and interpretable scores. We annotated an emotional speech corpus with color attributes via crowdsourcing and analyzed them. Moreover, we built regression models for color attributes in SER using machine learning and deep learning, and explored the multitask learning of color attribute regression and emotion classification. As a result, we demonstrated the relationship between color attributes and emotions in speech, and successfully developed color attribute regression models for SER. We also showed that multitask learning improved the performance of each task.",
      "authors": [
        "Ryotaro Nagase",
        "Ryoichi Takashima",
        "Yoichi Yamashita"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "published": "2026-02-18 08:11:49+00:00",
      "link": "https://arxiv.org/pdf/2602.16256v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16238v1",
      "title": "EasyControlEdge: A Foundation-Model Fine-Tuning for Edge Detection",
      "abstract": "We propose EasyControlEdge, adapting an image-generation foundation model to edge detection. In real-world edge detection (e.g., floor-plan walls, satellite roads/buildings, and medical organ boundaries), crispness and data efficiency are crucial, yet producing crisp raw edge maps with limited training samples remains challenging. Although image-generation foundation models perform well on many downstream tasks, their pretrained priors for data-efficient transfer and iterative refinement for high-frequency detail preservation remain underexploited for edge detection. To enable crisp and data-efficient edge detection using these capabilities, we introduce an edge-specialized adaptation of image-generation foundation models. To better specialize the foundation model for edge detection, we incorporate an edge-oriented objective with an efficient pixel-space loss. At inference, we introduce guidance based on unconditional dynamics, enabling a single model to control the edge density through a guidance scale. Experiments on BSDS500, NYUDv2, BIPED, and CubiCasa compare against state-of-the-art methods and show consistent gains, particularly under no-post-processing crispness evaluation and with limited training data.",
      "authors": [
        "Hiroki Nakamura",
        "Hiroto Iino",
        "Masashi Okada",
        "Tadahiro Taniguchi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-18 07:28:09+00:00",
      "link": "https://arxiv.org/pdf/2602.16238v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16224v1",
      "title": "Amortized Predictability-aware Training Framework for Time Series Forecasting and Classification",
      "abstract": "Time series data are prone to noise in various domains, and training samples may contain low-predictability patterns that deviate from the normal data distribution, leading to training instability or convergence to poor local minima. Therefore, mitigating the adverse effects of low-predictability samples is crucial for time series analysis tasks such as time series forecasting (TSF) and time series classification (TSC). While many deep learning models have achieved promising performance, few consider how to identify and penalize low-predictability samples to improve model performance from the training perspective. To fill this gap, we propose a general Amortized Predictability-aware Training Framework (APTF) for both TSF and TSC. APTF introduces two key designs that enable the model to focus on high-predictability samples while still learning appropriately from low-predictability ones: (i) a Hierarchical Predictability-aware Loss (HPL) that dynamically identifies low-predictability samples and progressively expands their loss penalty as training evolves, and (ii) an amortization model that mitigates predictability estimation errors caused by model bias, further enhancing HPL's effectiveness. The code is available at https://github.com/Meteor-Stars/APTF.",
      "authors": [
        "Xu Zhang",
        "Peng Wang",
        "Yichen Li",
        "Wei Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 06:59:05+00:00",
      "link": "https://arxiv.org/pdf/2602.16224v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16217v1",
      "title": "Multi-Class Boundary Extraction from Implicit Representations",
      "abstract": "Surface extraction from implicit neural representations modelling a single class surface is a well-known task. However, there exist no surface extraction methods from an implicit representation of multiple classes that guarantee topological correctness and no holes. In this work, we lay the groundwork by introducing a 2D boundary extraction algorithm for the multi-class case focusing on topological consistency and water-tightness, which also allows for setting minimum detail restraint on the approximation. Finally, we evaluate our algorithm using geological modelling data, showcasing its adaptiveness and ability to honour complex topology.",
      "authors": [
        "Jash Vira",
        "Andrew Myers",
        "Simon Ratcliffe"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 06:41:18+00:00",
      "link": "https://arxiv.org/pdf/2602.16217v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16216v1",
      "title": "UCTECG-Net: Uncertainty-aware Convolution Transformer ECG Network for Arrhythmia Detection",
      "abstract": "Deep learning has improved automated electrocardiogram (ECG) classification, but limited insight into prediction reliability hinders its use in safety-critical settings. This paper proposes UCTECG-Net, an uncertainty-aware hybrid architecture that combines one-dimensional convolutions and Transformer encoders to process raw ECG signals and their spectrograms jointly. Evaluated on the MIT-BIH Arrhythmia and PTB Diagnostic datasets, UCTECG-Net outperforms LSTM, CNN1D, and Transformer baselines in terms of accuracy, precision, recall and F1 score, achieving up to 98.58% accuracy on MIT-BIH and 99.14% on PTB. To assess predictive reliability, we integrate three uncertainty quantification methods (Monte Carlo Dropout, Deep Ensembles, and Ensemble Monte Carlo Dropout) into all models and analyze their behavior using an uncertainty-aware confusion matrix and derived metrics. The results show that UCTECG-Net, particularly with Ensemble or EMCD, provides more reliable and better-aligned uncertainty estimates than competing architectures, offering a stronger basis for risk-aware ECG decision support.",
      "authors": [
        "Hamzeh Asgharnezhad",
        "Pegah Tabarisaadi",
        "Abbas Khosravi",
        "Roohallah Alizadehsani",
        "U. Rajendra Acharya"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-18 06:39:19+00:00",
      "link": "https://arxiv.org/pdf/2602.16216v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16213v1",
      "title": "Graph neural network for colliding particles with an application to sea ice floe modeling",
      "abstract": "This paper introduces a novel approach to sea ice modeling using Graph Neural Networks (GNNs), utilizing the natural graph structure of sea ice, where nodes represent individual ice pieces, and edges model the physical interactions, including collisions. This concept is developed within a one-dimensional framework as a foundational step. Traditional numerical methods, while effective, are computationally intensive and less scalable. By utilizing GNNs, the proposed model, termed the Collision-captured Network (CN), integrates data assimilation (DA) techniques to effectively learn and predict sea ice dynamics under various conditions. The approach was validated using synthetic data, both with and without observed data points, and it was found that the model accelerates the simulation of trajectories without compromising accuracy. This advancement offers a more efficient tool for forecasting in marginal ice zones (MIZ) and highlights the potential of combining machine learning with data assimilation for more effective and efficient modeling.",
      "authors": [
        "Ruibiao Zhu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "physics.comp-ph"
      ],
      "published": "2026-02-18 06:31:04+00:00",
      "link": "https://arxiv.org/pdf/2602.16213v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16209v1",
      "title": "Geometric Neural Operators via Lie Group-Constrained Latent Dynamics",
      "abstract": "Neural operators offer an effective framework for learning solutions of partial differential equations for many physical systems in a resolution-invariant and data-driven manner. Existing neural operators, however, often suffer from instability in multi-layer iteration and long-horizon rollout, which stems from the unconstrained Euclidean latent space updates that violate the geometric and conservation laws. To address this challenge, we propose to constrain manifolds with low-rank Lie algebra parameterization that performs group action updates on the latent representation. Our method, termed Manifold Constraining based on Lie group (MCL), acts as an efficient \\emph{plug-and-play} module that enforces geometric inductive bias to existing neural operators. Extensive experiments on various partial differential equations, such as 1-D Burgers and 2-D Navier-Stokes, over a wide range of parameters and steps demonstrate that our method effectively lowers the relative prediction error by 30-50\\% at the cost of 2.26\\% of parameter increase. The results show that our approach provides a scalable solution for improving long-term prediction fidelity by addressing the principled geometric constraints absent in the neural operator updates.",
      "authors": [
        "Jiaquan Zhang",
        "Fachrina Dewi Puspitasari",
        "Songbo Zhang",
        "Yibei Liu",
        "Kuien Liu",
        "Caiyan Qin",
        "Fan Mo",
        "Peng Wang",
        "Yang Yang",
        "Chaoning Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-18 06:17:47+00:00",
      "link": "https://arxiv.org/pdf/2602.16209v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16204v1",
      "title": "Linked Data Classification using Neurochaos Learning",
      "abstract": "Neurochaos Learning (NL) has shown promise in recent times over traditional deep learning due to its two key features: ability to learn from small sized training samples, and low compute requirements. In prior work, NL has been implemented and extensively tested on separable and time series data, and demonstrated its superior performance on both classification and regression tasks. In this paper, we investigate the next step in NL, viz., applying NL to linked data, in particular, data that is represented in the form of knowledge graphs. We integrate linked data into NL by implementing node aggregation on knowledge graphs, and then feeding the aggregated node features to the simplest NL architecture: ChaosNet. We demonstrate the results of our implementation on homophilic graph datasets as well as heterophilic graph datasets of verying heterophily. We show better efficacy of our approach on homophilic graphs than on heterophilic graphs. While doing so, we also present our analysis of the results, as well as suggestions for future work.",
      "authors": [
        "Pooja Honna",
        "Ayush Patravali",
        "Nithin Nagaraj",
        "Nanjangud C. Narendra"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 05:55:59+00:00",
      "link": "https://arxiv.org/pdf/2602.16204v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16196v1",
      "title": "Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning",
      "abstract": "Coordinating large populations of interacting agents is a central challenge in multi-agent reinforcement learning (MARL), where the size of the joint state-action space scales exponentially with the number of agents. Mean-field methods alleviate this burden by aggregating agent interactions, but these approaches assume homogeneous interactions. Recent graphon-based frameworks capture heterogeneity, but are computationally expensive as the number of agents grows. Therefore, we introduce $\\texttt{GMFS}$, a $\\textbf{G}$raphon $\\textbf{M}$ean-$\\textbf{F}$ield $\\textbf{S}$ubsampling framework for scalable cooperative MARL with heterogeneous agent interactions. By subsampling $κ$ agents according to interaction strength, we approximate the graphon-weighted mean-field and learn a policy with sample complexity $\\mathrm{poly}(κ)$ and optimality gap $O(1/\\sqrtκ)$. We verify our theory with numerical simulations in robotic coordination, showing that $\\texttt{GMFS}$ achieves near-optimal performance.",
      "authors": [
        "Emile Anand",
        "Richard Hoffmann",
        "Sarah Liaw",
        "Adam Wierman"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-02-18 05:34:07+00:00",
      "link": "https://arxiv.org/pdf/2602.16196v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16193v1",
      "title": "Rethinking Input Domains in Physics-Informed Neural Networks via Geometric Compactification Mappings",
      "abstract": "Several complex physical systems are governed by multi-scale partial differential equations (PDEs) that exhibit both smooth low-frequency components and localized high-frequency structures. Existing physics-informed neural network (PINN) methods typically train with fixed coordinate system inputs, where geometric misalignment with these structures induces gradient stiffness and ill-conditioning that hinder convergence. To address this issue, we introduce a mapping paradigm that reshapes the input coordinates through differentiable geometric compactification mappings and couples the geometric structure of PDEs with the spectral properties of residual operators. Based on this paradigm, we propose Geometric Compactification (GC)-PINN, a framework that introduces three mapping strategies for periodic boundaries, far-field scale expansion, and localized singular structures in the input domain without modifying the underlying PINN architecture. Extensive empirical evaluation demonstrates that this approach yields more uniform residual distributions and higher solution accuracy on representative 1D and 2D PDEs, while improving training stability and convergence speed.",
      "authors": [
        "Zhenzhen Huang",
        "Haoyu Bian",
        "Jiaquan Zhang",
        "Yibei Liu",
        "Kuien Liu",
        "Caiyan Qin",
        "Guoqing Wang",
        "Yang Yang",
        "Chaoning Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-18 05:27:53+00:00",
      "link": "https://arxiv.org/pdf/2602.16193v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16188v1",
      "title": "Deep TPC: Temporal-Prior Conditioning for Time Series Forecasting",
      "abstract": "LLM-for-time series (TS) methods typically treat time shallowly, injecting positional or prompt-based cues once at the input of a largely frozen decoder, which limits temporal reasoning as this information degrades through the layers. We introduce Temporal-Prior Conditioning (TPC), which elevates time to a first-class modality that conditions the model at multiple depths. TPC attaches a small set of learnable time series tokens to the patch stream; at selected layers these tokens cross-attend to temporal embeddings derived from compact, human-readable temporal descriptors encoded by the same frozen LLM, then feed temporal context back via self-attention. This disentangles time series signal and temporal information while maintaining a low parameter budget. We show that by training only the cross-attention modules and explicitly disentangling time series signal and temporal information, TPC consistently outperforms both full fine-tuning and shallow conditioning strategies, achieving state-of-the-art performance in long-term forecasting across diverse datasets. Code available at: https://github.com/fil-mp/Deep_tpc",
      "authors": [
        "Filippos Bellos",
        "NaveenJohn Premkumar",
        "Yannis Avrithis",
        "Nam H. Nguyen",
        "Jason J. Corso"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 05:16:29+00:00",
      "link": "https://arxiv.org/pdf/2602.16188v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16177v1",
      "title": "Conjugate Learning Theory: Uncovering the Mechanisms of Trainability and Generalization in Deep Neural Networks",
      "abstract": "In this work, we propose a notion of practical learnability grounded in finite sample settings, and develop a conjugate learning theoretical framework based on convex conjugate duality to characterize this learnability property. Building on this foundation, we demonstrate that training deep neural networks (DNNs) with mini-batch stochastic gradient descent (SGD) achieves global optima of empirical risk by jointly controlling the extreme eigenvalues of a structure matrix and the gradient energy, and we establish a corresponding convergence theorem. We further elucidate the impact of batch size and model architecture (including depth, parameter count, sparsity, skip connections, and other characteristics) on non-convex optimization. Additionally, we derive a model-agnostic lower bound for the achievable empirical risk, theoretically demonstrating that data determines the fundamental limit of trainability. On the generalization front, we derive deterministic and probabilistic bounds on generalization error based on generalized conditional entropy measures. The former explicitly delineates the range of generalization error, while the latter characterizes the distribution of generalization error relative to the deterministic bounds under independent and identically distributed (i.i.d.) sampling conditions. Furthermore, these bounds explicitly quantify the influence of three key factors: (i) information loss induced by irreversibility in the model, (ii) the maximum attainable loss value, and (iii) the generalized conditional entropy of features with respect to labels. Moreover, they offer a unified theoretical lens for understanding the roles of regularization, irreversible transformations, and network depth in shaping the generalization behavior of deep neural networks. Extensive experiments validate all theoretical predictions, confirming the framework's correctness and consistency.",
      "authors": [
        "Binchuan Qi"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-18 04:26:55+00:00",
      "link": "https://arxiv.org/pdf/2602.16177v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16174v1",
      "title": "Edge Learning via Federated Split Decision Transformers for Metaverse Resource Allocation",
      "abstract": "Mobile edge computing (MEC) based wireless metaverse services offer an untethered, immersive experience to users, where the superior quality of experience (QoE) needs to be achieved under stringent latency constraints and visual quality demands. To achieve this, MEC-based intelligent resource allocation for virtual reality users needs to be supported by coordination across MEC servers to harness distributed data. Federated learning (FL) is a promising solution, and can be combined with reinforcement learning (RL) to develop generalized policies across MEC-servers. However, conventional FL incurs transmitting the full model parameters across the MEC-servers and the cloud, and suffer performance degradation due to naive global aggregation, especially in heterogeneous multi-radio access technology environments. To address these challenges, this paper proposes Federated Split Decision Transformer (FSDT), an offline RL framework where the transformer model is partitioned between MEC servers and the cloud. Agent-specific components (e.g., MEC-based embedding and prediction layers) enable local adaptability, while shared global layers in the cloud facilitate cooperative training across MEC servers. Experimental results demonstrate that FSDT enhances QoE for up to 10% in heterogeneous environments compared to baselines, while offloadingnearly 98% of the transformer model parameters to the cloud, thereby reducing the computational burden on MEC servers.",
      "authors": [
        "Fatih Temiz",
        "Shavbo Salehi",
        "Melike Erol-Kantarci"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.MM"
      ],
      "published": "2026-02-18 04:19:57+00:00",
      "link": "https://arxiv.org/pdf/2602.16174v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16167v1",
      "title": "Muon with Spectral Guidance: Efficient Optimization for Scientific Machine Learning",
      "abstract": "Physics-informed neural networks and neural operators often suffer from severe optimization difficulties caused by ill-conditioned gradients, multi-scale spectral behavior, and stiffness induced by physical constraints. Recently, the Muon optimizer has shown promise by performing orthogonalized updates in the singular-vector basis of the gradient, thereby improving geometric conditioning. However, its unit-singular-value updates may lead to overly aggressive steps and lack explicit stability guarantees when applied to physics-informed learning. In this work, we propose SpecMuon, a spectral-aware optimizer that integrates Muon's orthogonalized geometry with a mode-wise relaxed scalar auxiliary variable (RSAV) mechanism. By decomposing matrix-valued gradients into singular modes and applying RSAV updates individually along dominant spectral directions, SpecMuon adaptively regulates step sizes according to the global loss energy while preserving Muon's scale-balancing properties. This formulation interprets optimization as a multi-mode gradient flow and enables principled control of stiff spectral components. We establish rigorous theoretical properties of SpecMuon, including a modified energy dissipation law, positivity and boundedness of auxiliary variables, and global convergence with a linear rate under the Polyak-Lojasiewicz condition. Numerical experiments on physics-informed neural networks, DeepONets, and fractional PINN-DeepONets demonstrate that SpecMuon achieves faster convergence and improved stability compared with Adam, AdamW, and the original Muon optimizer on benchmark problems such as the one-dimensional Burgers equation and fractional partial differential equations.",
      "authors": [
        "Binghang Lu",
        "Jiahao Zhang",
        "Guang Lin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 03:56:20+00:00",
      "link": "https://arxiv.org/pdf/2602.16167v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16165v1",
      "title": "HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents",
      "abstract": "Training LLMs as interactive agents for multi-turn decision-making remains challenging, particularly in long-horizon tasks with sparse and delayed rewards, where agents must execute extended sequences of actions before receiving meaningful feedback. Most existing reinforcement learning (RL) approaches model LLM agents as flat policies operating at a single time scale, selecting one action at each turn. In sparse-reward settings, such flat policies must propagate credit across the entire trajectory without explicit temporal abstraction, which often leads to unstable optimization and inefficient credit assignment.   We propose HiPER, a novel Hierarchical Plan-Execute RL framework that explicitly separates high-level planning from low-level execution. HiPER factorizes the policy into a high-level planner that proposes subgoals and a low-level executor that carries them out over multiple action steps. To align optimization with this structure, we introduce a key technique called hierarchical advantage estimation (HAE), which carefully assigns credit at both the planning and execution levels. By aggregating returns over the execution of each subgoal and coordinating updates across the two levels, HAE provides an unbiased gradient estimator and provably reduces variance compared to flat generalized advantage estimation.   Empirically, HiPER achieves state-of-the-art performance on challenging interactive benchmarks, reaching 97.4\\% success on ALFWorld and 83.3\\% on WebShop with Qwen2.5-7B-Instruct (+6.6\\% and +8.3\\% over the best prior method), with especially large gains on long-horizon tasks requiring multiple dependent subtasks. These results highlight the importance of explicit hierarchical decomposition for scalable RL training of multi-turn LLM agents.",
      "authors": [
        "Jiangweizhi Peng",
        "Yuanxin Liu",
        "Ruida Zhou",
        "Charles Fleming",
        "Zhaoran Wang",
        "Alfredo Garcia",
        "Mingyi Hong"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-18 03:31:34+00:00",
      "link": "https://arxiv.org/pdf/2602.16165v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16151v1",
      "title": "Queer NLP: A Critical Survey on Literature Gaps, Biases and Trends",
      "abstract": "Natural language processing (NLP) technologies are rapidly reshaping how language is created, processed, and analyzed by humans. With current and potential applications in hiring, law, healthcare, and other areas that impact people's lives, understanding and mitigating harms towards marginalized groups is critical. In this survey, we examine NLP research papers that explicitly address the relationship between LGBTQIA+ communities and NLP technologies. We systematically review all such papers published in the ACL Anthology, to answer the following research questions: (1) What are current research trends? (2) What gaps exist in terms of topics and methods? (3) What areas are open for future work? We find that while the number of papers on queer NLP has grown within the last few years, most papers take a reactive rather than a proactive approach, pointing out bias more often than mitigating it, and focusing on shortcomings of existing systems rather than creating new solutions. Our survey uncovers many opportunities for future work, especially regarding stakeholder involvement, intersectionality, interdisciplinarity, and languages other than English. We also offer an outlook from a queer studies perspective, highlighting understudied topics and gaps in the harms addressed in NLP papers. Beyond being a roadmap of what has been done, this survey is a call to action for work towards more just and inclusive NLP technologies.",
      "authors": [
        "Sabine Weber",
        "Angelina Wang",
        "Ankush Gupta",
        "Arjun Subramonian",
        "Dennis Ulmer",
        "Eshaan Tanwar",
        "Geetanjali Aich",
        "Hannah Devinney",
        "Jacob Hobbs",
        "Jennifer Mickel",
        "Joshua Tint",
        "Mae Sosto",
        "Ray Groshan",
        "Simone Astarita",
        "Vagrant Gautam",
        "Verena Blaschke",
        "William Agnew",
        "Wilson Y Lee",
        "Yanan Long"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "published": "2026-02-18 02:54:28+00:00",
      "link": "https://arxiv.org/pdf/2602.16151v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16120v1",
      "title": "Feature-based morphological analysis of shape graph data",
      "abstract": "This paper introduces and demonstrates a computational pipeline for the statistical analysis of shape graph datasets, namely geometric networks embedded in 2D or 3D spaces. Unlike traditional abstract graphs, our purpose is not only to retrieve and distinguish variations in the connectivity structure of the data but also geometric differences of the network branches. Our proposed approach relies on the extraction of a specifically curated and explicit set of topological, geometric and directional features, designed to satisfy key invariance properties. We leverage the resulting feature representation for tasks such as group comparison, clustering and classification on cohorts of shape graphs. The effectiveness of this representation is evaluated on several real-world datasets including urban road/street networks, neuronal traces and astrocyte imaging. These results are benchmarked against several alternative methods, both feature-based and not.",
      "authors": [
        "Murad Hossen",
        "Demetrio Labate",
        "Nicolas Charon"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.AP",
        "stat.ML"
      ],
      "published": "2026-02-18 01:11:15+00:00",
      "link": "https://arxiv.org/pdf/2602.16120v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16118v1",
      "title": "Real time fault detection in 3D printers using Convolutional Neural Networks and acoustic signals",
      "abstract": "The reliability and quality of 3D printing processes are critically dependent on the timely detection of mechanical faults. Traditional monitoring methods often rely on visual inspection and hardware sensors, which can be both costly and limited in scope. This paper explores a scalable and contactless method for the use of real-time audio signal analysis for detecting mechanical faults in 3D printers. By capturing and classifying acoustic emissions during the printing process, we aim to identify common faults such as nozzle clogging, filament breakage, pully skipping and various other mechanical faults. Utilizing Convolutional neural networks, we implement algorithms capable of real-time audio classification to detect these faults promptly. Our methodology involves conducting a series of controlled experiments to gather audio data, followed by the application of advanced machine learning models for fault detection. Additionally, we review existing literature on audio-based fault detection in manufacturing and 3D printing to contextualize our research within the broader field. Preliminary results demonstrate that audio signals, when analyzed with machine learning techniques, provide a reliable and cost-effective means of enhancing real-time fault detection.",
      "authors": [
        "Muhammad Fasih Waheed",
        "Shonda Bernadin"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "cs.SD",
        "eess.AS"
      ],
      "published": "2026-02-18 01:02:25+00:00",
      "link": "https://arxiv.org/pdf/2602.16118v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16113v1",
      "title": "Evolutionary Context Search for Automated Skill Acquisition",
      "abstract": "Large Language Models cannot reliably acquire new knowledge post-deployment -- even when relevant text resources exist, models fail to transform them into actionable knowledge without retraining. Retrieval-Augmented Generation attempts to bridge this gap by surfacing relevant documents at inference time, yet similarity-based retrieval often fails to identify context that actually improves task performance. We introduce Evolutionary Context Search (ECS), an evolutionary method that searches context combinations using accuracy on a small development set, requiring only inference calls without weight updates. ECS moves beyond semantic similarity to discover non-obvious context pairings that significantly boost performance. Our empirical results show that ECS improves BackendBench by 27\\% and $τ$-bench airline by 7\\%. The evolved contexts are model-agnostic, as those evolved with Gemini-3-Flash transfer effectively to Claude Sonnet and DeepSeek. This suggests that ECS opens a path toward automated context discovery for skill acquisition -- an efficient alternative to manual prompt engineering or costly fine-tuning.",
      "authors": [
        "Qi Sun",
        "Stefan Nielsen",
        "Rio Yokota",
        "Yujin Tang"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "published": "2026-02-18 00:47:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16113v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16101v1",
      "title": "Axle Sensor Fusion for Online Continual Wheel Fault Detection in Wayside Railway Monitoring",
      "abstract": "Reliable and cost-effective maintenance is essential for railway safety, particularly at the wheel-rail interface, which is prone to wear and failure. Predictive maintenance frameworks increasingly leverage sensor-generated time-series data, yet traditional methods require manual feature engineering, and deep learning models often degrade in online settings with evolving operational patterns. This work presents a semantic-aware, label-efficient continual learning framework for railway fault diagnostics. Accelerometer signals are encoded via a Variational AutoEncoder into latent representations capturing the normal operational structure in a fully unsupervised manner. Importantly, semantic metadata, including axle counts, wheel indexes, and strain-based deformations, is extracted via AI-driven peak detection on fiber Bragg grating sensors (resistant to electromagnetic interference) and fused with the VAE embeddings, enhancing anomaly detection under unknown operational conditions. A lightweight gradient boosting supervised classifier stabilizes anomaly scoring with minimal labels, while a replay-based continual learning strategy enables adaptation to evolving domains without catastrophic forgetting. Experiments show the model detects minor imperfections due to flats and polygonization, while adapting to evolving operational conditions, such as changes in train type, speed, load, and track profiles, captured using a single accelerometer and strain gauge in wayside monitoring.",
      "authors": [
        "Afonso Lourenço",
        "Francisca Osório",
        "Diogo Risca",
        "Goreti Marreiros"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18 00:14:18+00:00",
      "link": "https://arxiv.org/pdf/2602.16101v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16091v1",
      "title": "Can Causality Cure Confusion Caused By Correlation (in Software Analytics)?",
      "abstract": "Background: Symbolic models, particularly decision trees, are widely used in software engineering for explainable analytics in defect prediction, configuration tuning, and software quality assessment. Most of these models rely on correlational split criteria, such as variance reduction or information gain, which identify statistical associations but cannot imply causation between X and Y. Recent empirical studies in software engineering show that both correlational models and causal discovery algorithms suffer from pronounced instability. This instability arises from two complementary issues: 1-Correlation-based methods conflate association with causation. 2-Causal discovery algorithms rely on heuristic approximations to cope with the NP-hard nature of structure learning, causing their inferred graphs to vary widely under minor input perturbations. Together, these issues undermine trust, reproducibility, and the reliability of explanations in real-world SE tasks. Objective: This study investigates whether incorporating causality-aware split criteria into symbolic models can improve their stability and robustness, and whether such gains come at the cost of predictive or optimization performance. We additionally examine how the stability of human expert judgments compares to that of automated models. Method: Using 120+ multi-objective optimization tasks from the MOOT repository of multi-objective optimization tasks, we evaluate stability through a preregistered bootstrap-ensemble protocol that measures variance with win-score assignments. We compare the stability of human causal assessments with correlation-based decision trees (EZR). We would also compare the causality-aware trees, which leverage conditional-entropy split criteria and confounder filtering. Stability and performance differences are analyzed using statistical methods (variance, Gini Impurity, KS test, Cliff's delta)",
      "authors": [
        "Amirali Rayegan",
        "Tim Menzies"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-17 23:35:50+00:00",
      "link": "https://arxiv.org/pdf/2602.16091v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16090v1",
      "title": "Examining Fast Radiative Feedbacks Using Machine-Learning Weather Emulators",
      "abstract": "The response of the climate system to increased greenhouse gases and other radiative perturbations is governed by a combination of fast and slow feedbacks. Slow feedbacks are typically activated in response to changes in ocean temperatures on decadal timescales and manifest as changes in climatic state with no recent historical analogue. However, fast feedbacks are activated in response to rapid atmospheric physical processes on weekly timescales, and they are already operative in the present-day climate. This distinction implies that the physics of fast radiative feedbacks is present in the historical meteorological reanalyses used to train many recent successful machine-learning-based (ML) emulators of weather and climate. In addition, these feedbacks are functional under the historical boundary conditions pertaining to the top-of-atmosphere radiative balance and sea-surface temperatures. Together, these factors imply that we can use historically trained ML weather emulators to study the response of radiative-convective equilibrium (RCE), and hence the global hydrological cycle, to perturbations in carbon dioxide and other well-mixed greenhouse gases. Without retraining on prospective Earth system conditions, we use ML weather emulators to quantify the fast precipitation response to reduced and elevated carbon dioxed concentrations with no recent historical precedent. We show that the responses from historically trained emulators agree with those produced by full-physics Earth System Models (ESMs). In conclusion, we discuss the prospects for and advantages from using ESMs and ML emulators to study fast processes in global climate.",
      "authors": [
        "Ankur Mahesh",
        "William D. Collins",
        "Travis A. O'Brien",
        "Paul B. Goddard",
        "Sinclaire Zebaze",
        "Shashank Subramanian",
        "James P. C. Duncan",
        "Oliver Watt-Meyer",
        "Boris Bonev",
        "Thorsten Kurth",
        "Karthik Kashinath",
        "Michael S. Pritchard",
        "Da Yang"
      ],
      "primary_category": "physics.ao-ph",
      "categories": [
        "physics.ao-ph",
        "cs.LG"
      ],
      "published": "2026-02-17 23:34:14+00:00",
      "link": "https://arxiv.org/pdf/2602.16090v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16075v1",
      "title": "DARTH-PUM: A Hybrid Processing-Using-Memory Architecture",
      "abstract": "Analog processing-using-memory (PUM; a.k.a. in-memory computing) makes use of electrical interactions inside memory arrays to perform bulk matrix-vector multiplication (MVM) operations. However, many popular matrix-based kernels need to execute non-MVM operations, which analog PUM cannot directly perform. To retain its energy efficiency, analog PUM architectures augment memory arrays with CMOS-based domain-specific fixed-function hardware to provide complete kernel functionality, but the difficulty of integrating such specialized CMOS logic with memory arrays has largely limited analog PUM to being an accelerator for machine learning inference, or for closely related kernels. An opportunity exists to harness analog PUM for general-purpose computation: recent works have shown that memory arrays can also perform Boolean PUM operations, albeit with very different supporting hardware and electrical signals than analog PUM.   We propose DARTH-PUM, a general-purpose hybrid PUM architecture that tackles key hardware and software challenges to integrating analog PUM and digital PUM. We propose optimized peripheral circuitry, coordinating hardware to manage and interface between both types of PUM, an easy-to-use programming interface, and low-cost support for flexible data widths. These design elements allow us to build a practical PUM architecture that can execute kernels fully in memory, and can scale easily to cater to domains ranging from embedded applications to large-scale data-driven computing. We show how three popular applications (AES encryption, convolutional neural networks, large-language models) can map to and benefit from DARTH-PUM, with speedups of 59.4x, 14.8x, and 40.8x over an analog+CPU baseline.",
      "authors": [
        "Ryan Wong",
        "Ben Feinberg",
        "Saugata Ghose"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR",
        "cs.CR",
        "cs.ET"
      ],
      "published": "2026-02-17 22:57:55+00:00",
      "link": "https://arxiv.org/pdf/2602.16075v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16069v1",
      "title": "The Limits of Long-Context Reasoning in Automated Bug Fixing",
      "abstract": "Rapidly increasing context lengths have led to the assumption that large language models (LLMs) can directly reason over entire codebases. Concurrently, recent advances in LLMs have enabled strong performance on software engineering benchmarks, particularly when paired with agentic workflows. In this work, we systematically evaluate whether current LLMs can reliably perform long-context code debugging and patch generation. Using SWE-bench Verified as a controlled experimental setting, we first evaluate state-of-the-art models within an agentic harness (mini-SWE-agent), where performance improves substantially: GPT-5-nano achieves up to a 31\\% resolve rate on 100 samples, and open-source models such as Deepseek-R1-0528 obtain competitive results. However, token-level analysis shows that successful agentic trajectories typically remain under 20k tokens, and that longer accumulated contexts correlate with lower success rates, indicating that agentic success primarily arises from task decomposition into short-context steps rather than effective long-context reasoning. To directly test long-context capability, we construct a data pipeline where we artificially inflate the context length of the input by placing the relevant files into the context (ensuring perfect retrieval recall); we then study single-shot patch generation under genuinely long contexts (64k-128k tokens). Despite this setup, performance degrades sharply: Qwen3-Coder-30B-A3B achieves only a 7\\% resolve rate at 64k context, while GPT-5-nano solves none of the tasks. Qualitative analysis reveals systematic failure modes, including hallucinated diffs, incorrect file targets, and malformed patch headers. Overall, our findings highlight a significant gap between nominal context length and usable context capacity in current LLMs, and suggest that existing agentic coding benchmarks do not meaningfully evaluate long-context reasoning.",
      "authors": [
        "Ravi Raju",
        "Mengmeng Ji",
        "Shubhangi Upasani",
        "Bo Li",
        "Urmish Thakker"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.LG"
      ],
      "published": "2026-02-17 22:51:40+00:00",
      "link": "https://arxiv.org/pdf/2602.16069v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16062v1",
      "title": "Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets",
      "abstract": "This paper proposes implicit cooperation, a framework enabling decentralized agents to approximate optimal coordination in local energy markets without explicit peer-to-peer communication. We formulate the problem as a decentralized partially observable Markov decision problem that is solved through a multi-agent reinforcement learning task in which agents use stigmergic signals (key performance indicators at the system level) to infer and react to global states. Through a 3x3 factorial design on an IEEE 34-node topology, we evaluated three training paradigms (CTCE, CTDE, DTDE) and three algorithms (PPO, APPO, SAC). Results identify APPO-DTDE as the optimal configuration, achieving a coordination score of 91.7% relative to the theoretical centralized benchmark (CTCE). However, a critical trade-off emerges between efficiency and stability: while the centralized benchmark maximizes allocative efficiency with a peer-to-peer trade ratio of 0.6, the fully decentralized approach (DTDE) demonstrates superior physical stability. Specifically, DTDE reduces the variance of grid balance by 31% compared to hybrid architectures, establishing a highly predictable, import-biased load profile that simplifies grid regulation. Furthermore, topological analysis reveals emergent spatial clustering, where decentralized agents self-organize into stable trading communities to minimize congestion penalties. While SAC excelled in hybrid settings, it failed in decentralized environments due to entropy-driven instability. This research proves that stigmergic signaling provides sufficient context for complex grid coordination, offering a robust, privacy-preserving alternative to expensive centralized communication infrastructure.",
      "authors": [
        "Nelson Salazar-Pena",
        "Alejandra Tabares",
        "Andres Gonzalez-Mancera"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.CE",
        "cs.LG",
        "cs.MA",
        "stat.AP"
      ],
      "published": "2026-02-17 22:22:32+00:00",
      "link": "https://arxiv.org/pdf/2602.16062v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16057v1",
      "title": "Extracting and Analyzing Rail Crossing Behavior Signatures from Videos using Tensor Methods",
      "abstract": "Railway crossings present complex safety challenges where driver behavior varies by location, time, and conditions. Traditional approaches analyze crossings individually, limiting the ability to identify shared behavioral patterns across locations. We propose a multi-view tensor decomposition framework that captures behavioral similarities across three temporal phases: Approach (warning activation to gate lowering), Waiting (gates down to train passage), and Clearance (train passage to gate raising). We analyze railway crossing videos from multiple locations using TimeSformer embeddings to represent each phase. By constructing phase-specific similarity matrices and applying non-negative symmetric CP decomposition, we discover latent behavioral components with distinct temporal signatures. Our tensor analysis reveals that crossing location appears to be a stronger determinant of behavior patterns than time of day, and that approach-phase behavior provides particularly discriminative signatures. Visualization of the learned component space confirms location-based clustering, with certain crossings forming distinct behavioral clusters. This automated framework enables scalable pattern discovery across multiple crossings, providing a foundation for grouping locations by behavioral similarity to inform targeted safety interventions.",
      "authors": [
        "Dawon Ahn",
        "Het Patel",
        "Aemal Khattak",
        "Jia Chen",
        "Evangelos E. Papalexakis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-02-17 22:12:28+00:00",
      "link": "https://arxiv.org/pdf/2602.16057v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16052v1",
      "title": "MoE-Spec: Expert Budgeting for Efficient Speculative Decoding",
      "abstract": "Speculative decoding accelerates Large Language Model (LLM) inference by verifying multiple drafted tokens in parallel. However, for Mixture-of-Experts (MoE) models, this parallelism introduces a severe bottleneck: large draft trees activate many unique experts, significantly increasing memory pressure and diminishing speedups from speculative decoding relative to autoregressive decoding. Prior methods reduce speculation depth when MoE verification becomes expensive. We propose MoE-Spec, a training-free verification-time expert budgeting method that decouples speculation depth from memory cost by enforcing a fixed expert capacity limit at each layer, loading only the experts that contribute most to verification and dropping the long tail of rarely used experts that drive bandwidth overhead. Experiments across multiple model scales and datasets show that this method yields 10--30\\% higher throughput than state-of-the-art speculative decoding baselines (EAGLE-3) at comparable quality, with flexibility to trade accuracy for further latency reductions through tighter budgets.",
      "authors": [
        "Bradley McDanel",
        "Steven Li",
        "Sruthikesh Surineni",
        "Harshit Khaitan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-17 22:02:36+00:00",
      "link": "https://arxiv.org/pdf/2602.16052v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16038v1",
      "title": "Heuristic Search as Language-Guided Program Optimization",
      "abstract": "Large Language Models (LLMs) have advanced Automated Heuristic Design (AHD) in combinatorial optimization (CO) in the past few years. However, existing discovery pipelines often require extensive manual trial-and-error or reliance on domain expertise to adapt to new or complex problems. This stems from tightly coupled internal mechanisms that limit systematic improvement of the LLM-driven design process. To address this challenge, we propose a structured framework for LLM-driven AHD that explicitly decomposes the heuristic discovery process into modular stages: a forward pass for evaluation, a backward pass for analytical feedback, and an update step for program refinement. This separation provides a clear abstraction for iterative refinement and enables principled improvements of individual components. We validate our framework across four diverse real-world CO domains, where it consistently outperforms baselines, achieving up to $0.17$ improvement in QYI on unseen test sets. Finally, we show that several popular AHD methods are restricted instantiations of our framework. By integrating them in our structured pipeline, we can upgrade the components modularly and significantly improve their performance.",
      "authors": [
        "Mingxin Yu",
        "Ruixiao Yang",
        "Chuchu Fan"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "published": "2026-02-17 21:45:42+00:00",
      "link": "https://arxiv.org/pdf/2602.16038v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16023v1",
      "title": "A Curious Class of Adpositional Multiword Expressions in Korean",
      "abstract": "Multiword expressions (MWEs) have been widely studied in cross-lingual annotation frameworks such as PARSEME. However, Korean MWEs remain underrepresented in these efforts. In particular, Korean multiword adpositions lack systematic analysis, annotated resources, and integration into existing multilingual frameworks. In this paper, we study a class of Korean functional multiword expressions: postpositional verb-based constructions (PVCs). Using data from Korean Wikipedia, we survey and analyze several PVC expressions and contrast them with non-MWEs and light verb constructions (LVCs) with similar structure. Building on this analysis, we propose annotation guidelines designed to support future work in Korean multiword adpositions and facilitate alignment with cross-lingual frameworks.",
      "authors": [
        "Junghyun Min",
        "Na-Rae Han",
        "Jena D. Hwang",
        "Nathan Schneider"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-17 21:23:16+00:00",
      "link": "https://arxiv.org/pdf/2602.16023v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16020v1",
      "title": "MolCrystalFlow: Molecular Crystal Structure Prediction via Flow Matching",
      "abstract": "Molecular crystal structure prediction represents a grand challenge in computational chemistry due to large sizes of constituent molecules and complex intra- and intermolecular interactions. While generative modeling has revolutionized structure discovery for molecules, inorganic solids, and metal-organic frameworks, extending such approaches to fully periodic molecular crystals is still elusive. Here, we present MolCrystalFlow, a flow-based generative model for molecular crystal structure prediction. The framework disentangles intramolecular complexity from intermolecular packing by embedding molecules as rigid bodies and jointly learning the lattice matrix, molecular orientations, and centroid positions. Centroids and orientations are represented on their native Riemannian manifolds, allowing geodesic flow construction and graph neural network operations that respects geometric symmetries. We benchmark our model against state-of-the-art generative models for large-size periodic crystals and rule-based structure generation methods on two open-source molecular crystal datasets. We demonstrate an integration of MolCrystalFlow model with universal machine learning potential to accelerate molecular crystal structure prediction, paving the way for data-driven generative discovery of molecular crystals.",
      "authors": [
        "Cheng Zeng",
        "Harry W. Sullivan",
        "Thomas Egg",
        "Maya M. Martirossyan",
        "Philipp Höllmer",
        "Jirui Jin",
        "Richard G. Hennig",
        "Adrian Roitberg",
        "Stefano Martiniani",
        "Ellad B. Tadmor",
        "Mingjie Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-17 21:22:08+00:00",
      "link": "https://arxiv.org/pdf/2602.16020v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16018v1",
      "title": "Edge-Local and Qubit-Efficient Quantum Graph Learning for the NISQ Era",
      "abstract": "Graph neural networks (GNNs) are a powerful framework for learning representations from graph-structured data, but their direct implementation on near-term quantum hardware remains challenging due to circuit depth, multi-qubit interactions, and qubit scalability constraints. In this work, we introduce a fully quantum graph convolutional architecture designed explicitly for unsupervised learning in the noisy intermediate-scale quantum (NISQ) regime. Our approach combines a variational quantum feature extraction layer with an edge-local and qubit-efficient quantum message-passing mechanism inspired by the Quantum Alternating Operator Ansatz (QAOA) framework. Unlike prior models that rely on global operations or multi-controlled unitaries, our model decomposes message passing into pairwise interactions along graph edges using only hardware-native single- and two-qubit gates. This design reduces the qubit requirement from $O(Nn)$ to $O(n)$ for a graph with $N$ nodes and $n$-qubit feature registers, enabling implementation on current quantum devices regardless of graph size. We train the model using the Deep Graph Infomax objective to perform unsupervised node representation learning. Experiments on the Cora citation network and a large-scale genomic SNP dataset demonstrate that our model remains competitive with prior quantum and hybrid approaches.",
      "authors": [
        "Armin Ahmadkhaniha",
        "Jake Doliskani"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.ET",
        "cs.LG"
      ],
      "published": "2026-02-17 21:17:42+00:00",
      "link": "https://arxiv.org/pdf/2602.16018v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16015v1",
      "title": "Geometry-Aware Uncertainty Quantification via Conformal Prediction on Manifolds",
      "abstract": "Conformal prediction provides distribution-free coverage guaranties for regression; yet existing methods assume Euclidean output spaces and produce prediction regions that are poorly calibrated when responses lie on Riemannian manifolds. We propose \\emph{adaptive geodesic conformal prediction}, a framework that replaces Euclidean residuals with geodesic nonconformity scores and normalizes them by a cross-validated difficulty estimator to handle heteroscedastic noise. The resulting prediction regions, geodesic caps on the sphere, have position-independent area and adapt their size to local prediction difficulty, yielding substantially more uniform conditional coverage than non-adaptive alternatives. In a synthetic sphere experiment with strong heteroscedasticity and a real-world geomagnetic field forecasting task derived from IGRF-14 satellite data, the adaptive method markedly reduces conditional coverage variability and raises worst-case coverage much closer to the nominal level, while coordinate-based baselines waste a large fraction of coverage area due to chart distortion.",
      "authors": [
        "Marzieh Amiri Shahbazi",
        "Ali Baheri"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-17 21:12:47+00:00",
      "link": "https://arxiv.org/pdf/2602.16015v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16012v1",
      "title": "Towards Efficient Constraint Handling in Neural Solvers for Routing Problems",
      "abstract": "Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficient constraint-handling framework for neural routing solvers based on explicit learning-based feasibility refinement. Unlike prior construction-search hybrids that target reducing optimality gaps through heavy improvements yet still struggle with hard constraints, CaR achieves efficient constraint handling by designing a joint training framework that guides the construction module to generate diverse and high-quality solutions well-suited for a lightweight improvement process, e.g., 10 steps versus 5k steps in prior work. Moreover, CaR presents the first use of construction-improvement-shared representation, enabling potential knowledge sharing across paradigms by unifying the encoder, especially in more complex constrained scenarios. We evaluate CaR on typical hard routing constraints to showcase its broader applicability. Results demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both classical and neural state-of-the-art solvers.",
      "authors": [
        "Jieyi Bi",
        "Zhiguang Cao",
        "Jianan Zhou",
        "Wen Song",
        "Yaoxin Wu",
        "Jie Zhang",
        "Yining Ma",
        "Cathy Wu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-02-17 21:06:23+00:00",
      "link": "https://arxiv.org/pdf/2602.16012v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16006v1",
      "title": "BTReport: A Framework for Brain Tumor Radiology Report Generation with Clinically Relevant Features",
      "abstract": "Recent advances in radiology report generation (RRG) have been driven by large paired image-text datasets; however, progress in neuro-oncology has been limited due to a lack of open paired image-report datasets. Here, we introduce BTReport, an open-source framework for brain tumor RRG that constructs natural language radiology reports using deterministically extracted imaging features. Unlike existing approaches that rely on large general-purpose or fine-tuned vision-language models for both image interpretation and report composition, BTReport performs deterministic feature extraction for image analysis and uses large language models only for syntactic structuring and narrative formatting. By separating RRG into a deterministic feature extraction step and a report generation step, the generated reports are completely interpretable and less prone to hallucinations. We show that the features used for report generation are predictive of key clinical outcomes, including survival and IDH mutation status, and reports generated by BTReport are more closely aligned with reference clinical reports than existing baselines for RRG. Finally, we introduce BTReport-BraTS, a companion dataset that augments BraTS imaging with synthetically generated radiology reports produced with BTReport. Code for this project can be found at  https://github.com/KurtLabUW/BTReport.",
      "authors": [
        "Juampablo E. Heras Rivera",
        "Dickson T. Chen",
        "Tianyi Ren",
        "Daniel K. Low",
        "Asma Ben Abacha",
        "Alberto Santamaria-Pang",
        "Mehmet Kurt"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-17 20:55:00+00:00",
      "link": "https://arxiv.org/pdf/2602.16006v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16005v1",
      "title": "ODYN: An All-Shifted Non-Interior-Point Method for Quadratic Programming in Robotics and AI",
      "abstract": "We introduce ODYN, a novel all-shifted primal-dual non-interior-point quadratic programming (QP) solver designed to efficiently handle challenging dense and sparse QPs. ODYN combines all-shifted nonlinear complementarity problem (NCP) functions with proximal method of multipliers to robustly address ill-conditioned and degenerate problems, without requiring linear independence of the constraints. It exhibits strong warm-start performance and is well suited to both general-purpose optimization, and robotics and AI applications, including model-based control, estimation, and kernel-based learning methods. We provide an open-source implementation and benchmark ODYN on the Maros-Mészáros test set, demonstrating state-of-the-art convergence performance in small-to-high-scale problems. The results highlight ODYN's superior warm-starting capabilities, which are critical in sequential and real-time settings common in robotics and AI. These advantages are further demonstrated by deploying ODYN as the backend of an SQP-based predictive control framework (OdynSQP), as the implicitly differentiable optimization layer for deep learning (ODYNLayer), and the optimizer of a contact-dynamics simulation (ODYNSim).",
      "authors": [
        "Jose Rojas",
        "Aristotelis Papatheodorou",
        "Sergi Martinez",
        "Ioannis Havoutis",
        "Carlos Mastalli"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-17 20:52:32+00:00",
      "link": "https://arxiv.org/pdf/2602.16005v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16000v1",
      "title": "Imaging-Derived Coronary Fractional Flow Reserve: Advances in Physics-Based, Machine-Learning, and Physics-Informed Methods",
      "abstract": "Purpose of Review Imaging derived fractional flow reserve (FFR) is rapidly evolving beyond conventional computational fluid dynamics (CFD) based pipelines toward machine learning (ML), deep learning (DL), and physics informed approaches that enable fast, wire free, and scalable functional assessment of coronary stenosis. This review synthesizes recent advances in CT and angiography based FFR, with particular emphasis on emerging physics informed neural networks and neural operators (PINNs and PINOs) and key considerations for their clinical translation. Recent Findings ML/DL approaches have markedly improved automation and computational speed, enabling prediction of pressure and FFR from anatomical descriptors or angiographic contrast dynamics. However, their real-world performance and generalizability can remain variable and sensitive to domain shift, due to multi-center heterogeneity, interpretability challenges, and differences in acquisition protocols and image quality. Physics informed learning introduces conservation structure and boundary condition consistency into model training, improving generalizability and reducing dependence on dense supervision while maintaining rapid inference. Recent evaluation trends increasingly highlight deployment oriented metrics, including calibration, uncertainty quantification, and quality control gatekeeping, as essential for safe clinical use. Summary The field is converging toward imaging derived FFR methods that are faster, more automated, and more reliable. While ML/DL offers substantial efficiency gains, physics informed frameworks such as PINNs and PINOs may provide a more robust balance between speed and physical consistency. Prospective multi center validation and standardized evaluation will be critical to support broad and safe clinical adoption.",
      "authors": [
        "Tanxin Zhu",
        "Emran Hossen",
        "Chen Zhao",
        "Michele Esposito",
        "Jiguang Sun",
        "Weihua Zhou"
      ],
      "primary_category": "physics.med-ph",
      "categories": [
        "physics.med-ph",
        "cs.LG"
      ],
      "published": "2026-02-17 20:46:25+00:00",
      "link": "https://arxiv.org/pdf/2602.16000v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15995v1",
      "title": "Distributed Order Recording Techniques for Efficient Record-and-Replay of Multi-threaded Programs",
      "abstract": "After all these years and all these other shared memory programming frameworks, OpenMP is still the most popular one. However, its greater levels of non-deterministic execution makes debugging and testing more challenging. The ability to record and deterministically replay the program execution is key to address this challenge. However, scalably replaying OpenMP programs is still an unresolved problem. In this paper, we propose two novel techniques that use Distributed Clock (DC) and Distributed Epoch (DE) recording schemes to eliminate excessive thread synchronization for OpenMP record and replay. Our evaluation on representative HPC applications with ReOMP, which we used to realize DC and DE recording, shows that our approach is 2-5x more efficient than traditional approaches that synchronize on every shared-memory access. Furthermore, we demonstrate that our approach can be easily combined with MPI-level replay tools to replay non-trivial MPI+OpenMP applications. We achieve this by integrating \\toolname into ReMPI, an existing scalable MPI record-and-replay tool, with only a small MPI-scale-independent runtime overhead.",
      "authors": [
        "Xiang Fu",
        "Shiman Meng",
        "Weiping Zhang",
        "Luanzheng Guo",
        "Kento Sato",
        "Dong H. Ahn",
        "Ignacio Laguna",
        "Gregory L. Lee",
        "Martin Schulz"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC"
      ],
      "published": "2026-02-17 20:33:32+00:00",
      "link": "https://arxiv.org/pdf/2602.15995v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15984v1",
      "title": "Verifier-Constrained Flow Expansion for Discovery Beyond the Data",
      "abstract": "Flow and diffusion models are typically pre-trained on limited available data (e.g., molecular samples), covering only a fraction of the valid design space (e.g., the full molecular space). As a consequence, they tend to generate samples from only a narrow portion of the feasible domain. This is a fundamental limitation for scientific discovery applications, where one typically aims to sample valid designs beyond the available data distribution. To this end, we address the challenge of leveraging access to a verifier (e.g., an atomic bonds checker), to adapt a pre-trained flow model so that its induced density expands beyond regions of high data availability, while preserving samples validity. We introduce formal notions of strong and weak verifiers and propose algorithmic frameworks for global and local flow expansion via probability-space optimization. Then, we present Flow Expander (FE), a scalable mirror descent scheme that provably tackles both problems by verifier-constrained entropy maximization over the flow process noised state space. Next, we provide a thorough theoretical analysis of the proposed method, and state convergence guarantees under both idealized and general assumptions. Ultimately, we empirically evaluate our method on both illustrative, yet visually interpretable settings, and on a molecular design task showcasing the ability of FE to expand a pre-trained flow model increasing conformer diversity while preserving validity.",
      "authors": [
        "Riccardo De Santi",
        "Kimon Protopapas",
        "Ya-Ping Hsieh",
        "Andreas Krause"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-17 20:20:38+00:00",
      "link": "https://arxiv.org/pdf/2602.15984v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15971v1",
      "title": "B-DENSE: Branching For Dense Ensemble Network Learning",
      "abstract": "Inspired by non-equilibrium thermodynamics, diffusion models have achieved state-of-the-art performance in generative modeling. However, their iterative sampling nature results in high inference latency. While recent distillation techniques accelerate sampling, they discard intermediate trajectory steps. This sparse supervision leads to a loss of structural information and introduces significant discretization errors. To mitigate this, we propose B-DENSE, a novel framework that leverages multi-branch trajectory alignment. We modify the student architecture to output $K$-fold expanded channels, where each subset corresponds to a specific branch representing a discrete intermediate step in the teacher's trajectory. By training these branches to simultaneously map to the entire sequence of the teacher's target timesteps, we enforce dense intermediate trajectory alignment. Consequently, the student model learns to navigate the solution space from the earliest stages of training, demonstrating superior image generation quality compared to baseline distillation frameworks.",
      "authors": [
        "Cherish Puniani",
        "Tushar Kumar",
        "Arnav Bendre",
        "Gaurav Kumar",
        "Shree Singhi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "published": "2026-02-17 19:40:58+00:00",
      "link": "https://arxiv.org/pdf/2602.15971v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15959v1",
      "title": "Position-Aware Scene-Appearance Disentanglement for Bidirectional Photoacoustic Microscopy Registration",
      "abstract": "High-speed optical-resolution photoacoustic microscopy (OR-PAM) with bidirectional raster scanning doubles imaging speed but introduces coupled domain shift and geometric misalignment between forward and backward scan lines. Existing registration methods, constrained by brightness constancy assumptions, achieve limited alignment quality, while recent generative approaches address domain shift through complex architectures that lack temporal awareness across frames. We propose GPEReg-Net, a scene-appearance disentanglement framework that separates domain-invariant scene features from domain-specific appearance codes via Adaptive Instance Normalization (AdaIN), enabling direct image-to-image registration without explicit deformation field estimation. To exploit temporal structure in sequential acquisitions, we introduce a Global Position Encoding (GPE) module that combines learnable position embeddings with sinusoidal encoding and cross-frame attention, allowing the network to leverage context from neighboring frames for improved temporal coherence. On the OR-PAM-Reg-4K benchmark (432 test samples), GPEReg-Net achieves NCC of 0.953, SSIM of 0.932, and PSNR of 34.49dB, surpassing the state-of-the-art by 3.8% in SSIM and 1.99dB in PSNR while maintaining competitive NCC. Code is available at https://github.com/JiahaoQin/GPEReg-Net.",
      "authors": [
        "Yiwen Wang",
        "Jiahao Qin"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-17 19:20:23+00:00",
      "link": "https://arxiv.org/pdf/2602.15959v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15958v1",
      "title": "DocSplit: A Comprehensive Benchmark Dataset and Evaluation Approach for Document Packet Recognition and Splitting",
      "abstract": "Document understanding in real-world applications often requires processing heterogeneous, multi-page document packets containing multiple documents stitched together. Despite recent advances in visual document understanding, the fundamental task of document packet splitting, which involves separating a document packet into individual units, remains largely unaddressed. We present the first comprehensive benchmark dataset, DocSplit, along with novel evaluation metrics for assessing the document packet splitting capabilities of large language models. DocSplit comprises five datasets of varying complexity, covering diverse document types, layouts, and multimodal settings. We formalize the DocSplit task, which requires models to identify document boundaries, classify document types, and maintain correct page ordering within a document packet. The benchmark addresses real-world challenges, including out-of-order pages, interleaved documents, and documents lacking clear demarcations. We conduct extensive experiments evaluating multimodal LLMs on our datasets, revealing significant performance gaps in current models' ability to handle complex document splitting tasks. The DocSplit benchmark datasets and proposed novel evaluation metrics provide a systematic framework for advancing document understanding capabilities essential for legal, financial, healthcare, and other document-intensive domains. We release the datasets to facilitate future research in document packet processing.",
      "authors": [
        "Md Mofijul Islam",
        "Md Sirajus Salekin",
        "Nivedha Balakrishnan",
        "Vincil C. Bishop",
        "Niharika Jain",
        "Spencer Romo",
        "Bob Strahan",
        "Boyi Xie",
        "Diego A. Socolinsky"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-17 19:17:55+00:00",
      "link": "https://arxiv.org/pdf/2602.15958v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15957v1",
      "title": "Evolutionary Systems Thinking -- From Equilibrium Models to Open-Ended Adaptive Dynamics",
      "abstract": "Complex change is often described as \"evolutionary\" in economics, policy, and technology, yet most system dynamics models remain constrained to fixed state spaces and equilibrium-seeking behavior. This paper argues that evolutionary dynamics should be treated as a core system-thinking problem rather than as a biological metaphor. We introduce Stability-Driven Assembly (SDA) as a minimal, non-equilibrium framework in which stochastic interactions combined with differential persistence generate endogenous selection without genes, replication, or predefined fitness functions. In SDA, longer-lived patterns accumulate in the population, biasing future interactions and creating feedback between population composition and system dynamics. This feedback yields fitness-proportional sampling as an emergent property, realizing a natural genetic algorithm driven solely by stability. Using SDA, we demonstrate why equilibrium-constrained models, even when simulated numerically, cannot exhibit open-ended evolution: evolutionary systems require population-dependent, non-stationary dynamics in which structure and dynamics co-evolve. We conclude by discussing implications for system dynamics, economics, and policy modeling, and outline how agent-based and AI-enabled approaches may support evolutionary models capable of sustained novelty and structural emergence.",
      "authors": [
        "Dan Adler"
      ],
      "primary_category": "q-bio.PE",
      "categories": [
        "q-bio.PE",
        "cs.NE",
        "econ.TH"
      ],
      "published": "2026-02-17 19:17:50+00:00",
      "link": "https://arxiv.org/pdf/2602.15957v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15954v1",
      "title": "Hybrid Model Predictive Control with Physics-Informed Neural Network for Satellite Attitude Control",
      "abstract": "Reliable spacecraft attitude control depends on accurate prediction of attitude dynamics, particularly when model-based strategies such as Model Predictive Control (MPC) are employed, where performance is limited by the quality of the internal system model. For spacecraft with complex dynamics, obtaining accurate physics-based models can be difficult, time-consuming, or computationally heavy. Learning-based system identification presents a compelling alternative; however, models trained exclusively on data frequently exhibit fragile stability properties and limited extrapolation capability. This work explores Physics-Informed Neural Networks (PINNs) for modeling spacecraft attitude dynamics and contrasts it with a conventional data-driven approach. A comprehensive dataset is generated using high-fidelity numerical simulations, and two learning methodologies are investigated: a purely data-driven pipeline and a physics-regularized approach that incorporates prior knowledge into the optimization process. The results indicate that embedding physical constraints during training leads to substantial improvements in predictive reliability, achieving a 68.17% decrease in mean relative error relative. When deployed within an MPC architecture, the physics-informed models yield superior closed-loop tracking performance and improved robustness to uncertainty. Furthermore, a hybrid control formulation that merges the learned nonlinear dynamics with a nominal linear model enables consistent steady-state convergence and significantly faster response, reducing settling times by 61.52%-76.42% under measurement noise and reaction wheel friction.",
      "authors": [
        "Carlo Cena",
        "Mauro Martini",
        "Marcello Chiaberge"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-17 19:08:48+00:00",
      "link": "https://arxiv.org/pdf/2602.15954v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15951v1",
      "title": "MadEvolve: Evolutionary Optimization of Cosmological Algorithms with Large Language Models",
      "abstract": "We develop a general framework to discover scientific algorithms and apply it to three problems in computational cosmology. Our code, MadEvolve, is similar to Google's AlphaEvolve, but places a stronger emphasis on free parameters and their optimization. Our code starts with a baseline human algorithm implementation, and then optimizes its performance metrics by making iterative changes to its code. As a further convenient feature, MadEvolve automatically generates a report that compares the input algorithm with the evolved algorithm, describes the algorithmic innovations and lists the free parameters and their function. Our code supports both auto-differentiable, gradient-based parameter optimization and gradient-free optimization methods. We apply MadEvolve to the reconstruction of cosmological initial conditions, 21cm foreground contamination reconstruction and effective baryonic physics in N-body simulations. In all cases, we find substantial improvements over the base algorithm. We make MadEvolve and our three tasks publicly available at madevolve.org.",
      "authors": [
        "Tianyi Li",
        "Shihui Zang",
        "Moritz Münchmeyer"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "cs.LG"
      ],
      "published": "2026-02-17 19:06:52+00:00",
      "link": "https://arxiv.org/pdf/2602.15951v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15830v1",
      "title": "Ensemble-size-dependence of deep-learning post-processing methods that minimize an (un)fair score: motivating examples and a proof-of-concept solution",
      "abstract": "Fair scores reward ensemble forecast members that behave like samples from the same distribution as the verifying observations. They are therefore an attractive choice as loss functions to train data-driven ensemble forecasts or post-processing methods when large training ensembles are either unavailable or computationally prohibitive. The adjusted continuous ranked probability score (aCRPS) is fair and unbiased with respect to ensemble size, provided forecast members are exchangeable and interpretable as conditionally independent draws from an underlying predictive distribution. However, distribution-aware post-processing methods that introduce structural dependency between members can violate this assumption, rendering aCRPS unfair. We demonstrate this effect using two approaches designed to minimize the expected aCRPS of a finite ensemble: (1) a linear member-by-member calibration, which couples members through a common dependency on the sample ensemble mean, and (2) a deep-learning method, which couples members via transformer self-attention across the ensemble dimension. In both cases, the results are sensitive to ensemble size and apparent gains in aCRPS can correspond to systematic unreliability characterized by over-dispersion. We introduce trajectory transformers as a proof-of-concept that ensemble-size independence can be achieved. This approach is an adaptation of the Post-processing Ensembles with Transformers (PoET) framework and applies self-attention over lead time while preserving the conditional independence required by aCRPS. When applied to weekly mean $T_{2m}$ forecasts from the ECMWF subseasonal forecasting system, this approach successfully reduces systematic model biases whilst also improving or maintaining forecast reliability regardless of the ensemble size used in training (3 vs 9 members) or real-time forecasts (9 vs 100 members).",
      "authors": [
        "Christopher David Roberts"
      ],
      "primary_category": "physics.ao-ph",
      "categories": [
        "physics.ao-ph",
        "cs.LG"
      ],
      "published": "2026-02-17 18:59:55+00:00",
      "link": "https://arxiv.org/pdf/2602.15830v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15820v1",
      "title": "Stabilizing Test-Time Adaptation of High-Dimensional Simulation Surrogates via D-Optimal Statistics",
      "abstract": "Machine learning surrogates are increasingly used in engineering to accelerate costly simulations, yet distribution shifts between training and deployment often cause severe performance degradation (e.g., unseen geometries or configurations). Test-Time Adaptation (TTA) can mitigate such shifts, but existing methods are largely developed for lower-dimensional classification with structured outputs and visually aligned input-output relationships, making them unstable for the high-dimensional, unstructured and regression problems common in simulation. We address this challenge by proposing a TTA framework based on storing maximally informative (D-optimal) statistics, which jointly enables stable adaptation and principled parameter selection at test time. When applied to pretrained simulation surrogates, our method yields up to 7% out-of-distribution improvements at negligible computational cost. To the best of our knowledge, this is the first systematic demonstration of effective TTA for high-dimensional simulation regression and generative design optimization, validated on the SIMSHIFT and EngiBench benchmarks.",
      "authors": [
        "Anna Zimmel",
        "Paul Setinek",
        "Gianluca Galletti",
        "Johannes Brandstetter",
        "Werner Zellinger"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-17 18:55:18+00:00",
      "link": "https://arxiv.org/pdf/2602.15820v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15817v1",
      "title": "Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning",
      "abstract": "Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution. This mismatch can result in policies that perform poorly on low-probability states that are still within the safe set. A natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori. We propose Feasibility-Guided Exploration (FGE), a method that simultaneously identifies a subset of feasible initial conditions under which a safe policy exists, and learns a policy to solve the reachability problem over this set of initial conditions. Empirical results demonstrate that FGE learns policies with over 50% more coverage than the best existing method for challenging initial conditions across tasks in the MuJoCo simulator and the Kinetix simulator with pixel observations.",
      "authors": [
        "Oswin So",
        "Eric Yang Yu",
        "Songyuan Zhang",
        "Matthew Cleaveland",
        "Mitchell Black",
        "Chuchu Fan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.RO",
        "math.OC"
      ],
      "published": "2026-02-17 18:53:31+00:00",
      "link": "https://arxiv.org/pdf/2602.15817v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15783v1",
      "title": "Context-aware Skin Cancer Epithelial Cell Classification with Scalable Graph Transformers",
      "abstract": "Whole-slide images (WSIs) from cancer patients contain rich information that can be used for medical diagnosis or to follow treatment progress. To automate their analysis, numerous deep learning methods based on convolutional neural networks and Vision Transformers have been developed and have achieved strong performance in segmentation and classification tasks. However, due to the large size and complex cellular organization of WSIs, these models rely on patch-based representations, losing vital tissue-level context. We propose using scalable Graph Transformers on a full-WSI cell graph for classification. We evaluate this methodology on a challenging task: the classification of healthy versus tumor epithelial cells in cutaneous squamous cell carcinoma (cSCC), where both cell types exhibit very similar morphologies and are therefore difficult to differentiate for image-based approaches. We first compared image-based and graph-based methods on a single WSI. Graph Transformer models SGFormer and DIFFormer achieved balanced accuracies of $85.2 \\pm 1.5$ ($\\pm$ standard error) and $85.1 \\pm 2.5$ in 3-fold cross-validation, respectively, whereas the best image-based method reached $81.2 \\pm 3.0$. By evaluating several node feature configurations, we found that the most informative representation combined morphological and texture features as well as the cell classes of non-epithelial cells, highlighting the importance of the surrounding cellular context. We then extended our work to train on several WSIs from several patients. To address the computational constraints of image-based models, we extracted four $2560 \\times 2560$ pixel patches from each image and converted them into graphs. In this setting, DIFFormer achieved a balanced accuracy of $83.6 \\pm 1.9$ (3-fold cross-validation), while the state-of-the-art image-based model CellViT256 reached $78.1 \\pm 0.5$.",
      "authors": [
        "Lucas Sancéré",
        "Noémie Moreau",
        "Katarzyna Bozek"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-17 18:17:52+00:00",
      "link": "https://arxiv.org/pdf/2602.15783v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15781v1",
      "title": "Neural Scaling Laws for Boosted Jet Tagging",
      "abstract": "The success of Large Language Models (LLMs) has established that scaling compute, through joint increases in model capacity and dataset size, is the primary driver of performance in modern machine learning. While machine learning has long been an integral component of High Energy Physics (HEP) data analysis workflows, the compute used to train state-of-the-art HEP models remains orders of magnitude below that of industry foundation models. With scaling laws only beginning to be studied in the field, we investigate neural scaling laws for boosted jet classification using the public JetClass dataset. We derive compute optimal scaling laws and identify an effective performance limit that can be consistently approached through increased compute. We study how data repetition, common in HEP where simulation is expensive, modifies the scaling yielding a quantifiable effective dataset size gain. We then study how the scaling coefficients and asymptotic performance limits vary with the choice of input features and particle multiplicity, demonstrating that increased compute reliably drives performance toward an asymptotic limit, and that more expressive, lower-level features can raise the performance limit and improve results at fixed dataset size.",
      "authors": [
        "Matthias Vigl",
        "Nicole Hartman",
        "Michael Kagan",
        "Lukas Heinrich"
      ],
      "primary_category": "hep-ex",
      "categories": [
        "hep-ex",
        "cs.LG",
        "hep-ph",
        "physics.data-an"
      ],
      "published": "2026-02-17 18:13:01+00:00",
      "link": "https://arxiv.org/pdf/2602.15781v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15926v1",
      "title": "A Study on Real-time Object Detection using Deep Learning",
      "abstract": "Object detection has compelling applications over a range of domains, including human-computer interfaces, security and video surveillance, navigation and road traffic monitoring, transportation systems, industrial automation healthcare, the world of Augmented Reality (AR) and Virtual Reality (VR), environment monitoring and activity identification. Applications of real time object detection in all these areas provide dynamic analysis of the visual information that helps in immediate decision making. Furthermore, advanced deep learning algorithms leverage the progress in the field of object detection providing more accurate and efficient solutions. There are some outstanding deep learning algorithms for object detection which includes, Faster R CNN(Region-based Convolutional Neural Network),Mask R-CNN, Cascade R-CNN, YOLO (You Only Look Once), SSD (Single Shot Multibox Detector), RetinaNet etc. This article goes into great detail on how deep learning algorithms are used to enhance real time object recognition. It provides information on the different object detection models available, open benchmark datasets, and studies on the use of object detection models in a range of applications. Additionally, controlled studies are provided to compare various strategies and produce some illuminating findings. Last but not least, a number of encouraging challenges and approaches are offered as suggestions for further investigation in both relevant deep learning approaches and object recognition.",
      "authors": [
        "Ankita Bose",
        "Jayasravani Bhumireddy",
        "Naveen N"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-17 18:12:42+00:00",
      "link": "https://arxiv.org/pdf/2602.15926v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15925v1",
      "title": "Robust Stochastic Gradient Posterior Sampling with Lattice Based Discretisation",
      "abstract": "Stochastic-gradient MCMC methods enable scalable Bayesian posterior sampling but often suffer from sensitivity to minibatch size and gradient noise. To address this, we propose Stochastic Gradient Lattice Random Walk (SGLRW), an extension of the Lattice Random Walk discretization. Unlike conventional Stochastic Gradient Langevin Dynamics (SGLD), SGLRW introduces stochastic noise only through the off-diagonal elements of the update covariance; this yields greater robustness to minibatch size while retaining asymptotic correctness. Furthermore, as comparison we analyze a natural analogue of SGLD utilizing gradient clipping. Experimental validation on Bayesian regression and classification demonstrates that SGLRW remains stable in regimes where SGLD fails, including in the presence of heavy-tailed gradient noise, and matches or improves predictive performance.",
      "authors": [
        "Zier Mensch",
        "Lars Holdijk",
        "Samuel Duffield",
        "Maxwell Aifer",
        "Patrick J. Coles",
        "Max Welling",
        "Miranda C. N. Cheng"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-17 18:09:49+00:00",
      "link": "https://arxiv.org/pdf/2602.15925v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15776v1",
      "title": "GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems",
      "abstract": "In the realm of multi-agent systems, the challenge of \\emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.",
      "authors": [
        "Yiqin Yang",
        "Xu Yang",
        "Yuhua Jiang",
        "Ni Mu",
        "Hao Hu",
        "Runpeng Xie",
        "Ziyou Zhang",
        "Siyuan Li",
        "Yuan-Hua Ni",
        "Qianchuan Zhao",
        "Bo Xu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-17 18:05:48+00:00",
      "link": "https://arxiv.org/pdf/2602.15776v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15766v1",
      "title": "TAC: Timestamped Audio Captioning",
      "abstract": "Large Audio Language Models struggle to disentangle overlapping events in complex acoustic scenes, yielding temporally inconsistent captions and frequent hallucinations. We introduce Timestamped Audio Captioner (TAC), a model that produces temporally grounded audio descriptions at varying degrees of detail and resolution. TAC is trained with a synthetic data pipeline that constructs challenging and dynamic mixtures from real-world audio sources, enabling robust learning under realistic polyphonic conditions. Across event detection and dense captioning, TAC outperforms all competing methods, with a low hallucination rate and accurate temporal grounding. We also introduce TAC-V, an audio-visual pipeline to generate semantically rich audio-visual descriptions. We then show that TAC and TAC-V serves as a \"semantic bridge\" for a text-only reasoner: a simple TAC$\\rightarrow$LLM and TAC-V$\\rightarrow$LLM cascade achieves state-of-the-art scores on benchmarks for both audio (MMAU-Pro, MMSU, MMAR) and audio-visual (DailyOmni, VideoHolmes) understanding and reasoning respectively.",
      "authors": [
        "Sonal Kumar",
        "Prem Seetharaman",
        "Ke Chen",
        "Oriol Nieto",
        "Jiaqi Su",
        "Zhepei Wang",
        "Rithesh Kumar",
        "Dinesh Manocha",
        "Nicholas J. Bryan",
        "Zeyu Jin",
        "Justin Salamon"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD"
      ],
      "published": "2026-02-17 17:57:55+00:00",
      "link": "https://arxiv.org/pdf/2602.15766v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15758v1",
      "title": "ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models",
      "abstract": "While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.",
      "authors": [
        "Manav Nitin Kapadnis",
        "Lawanya Baghel",
        "Atharva Naik",
        "Carolyn Rosé"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-17 17:45:34+00:00",
      "link": "https://arxiv.org/pdf/2602.15758v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15756v1",
      "title": "A Note on Non-Composability of Layerwise Approximate Verification for Neural Inference",
      "abstract": "A natural and informal approach to verifiable (or zero-knowledge) ML inference over floating-point data is: ``prove that each layer was computed correctly up to tolerance $δ$; therefore the final output is a reasonable inference result''. This short note gives a simple counterexample showing that this inference is false in general: for any neural network, we can construct a functionally equivalent network for which adversarially chosen approximation-magnitude errors in individual layer computations suffice to steer the final output arbitrarily (within a prescribed bounded range).",
      "authors": [
        "Or Zamir"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-02-17 17:41:59+00:00",
      "link": "https://arxiv.org/pdf/2602.15756v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15751v1",
      "title": "Enabling Low-Latency Machine learning on Radiation-Hard FPGAs with hls4ml",
      "abstract": "This paper presents the first demonstration of a viable, ultra-fast, radiation-hard machine learning (ML) application on FPGAs, which could be used in future high-energy physics experiments. We present a three-fold contribution, with the PicoCal calorimeter, planned for the LHCb Upgrade II experiment, used as a test case. First, we develop a lightweight autoencoder to compress a 32-sample timing readout, representative of that of the PicoCal, into a two-dimensional latent space. Second, we introduce a systematic, hardware-aware quantization strategy and show that the model can be reduced to 10-bit weights with minimal performance loss. Third, as a barrier to the adoption of on-detector ML is the lack of support for radiation-hard FPGAs in the High-Energy Physics community's standard ML synthesis tool, hls4ml, we develop a new backend for this library. This new back-end enables the automatic translation of ML models into High-Level Synthesis (HLS) projects for the Microchip PolarFire family of FPGAs, one of the few commercially available and radiation hard FPGAs. We present the synthesis of the autoencoder on a target PolarFire FPGA, which indicates that a latency of 25 ns can be achieved. We show that the resources utilized are low enough that the model can be placed within the inherently protected logic of the FPGA. Our extension to hls4ml is a significant contribution, paving the way for broader adoption of ML on FPGAs in high-radiation environments.",
      "authors": [
        "Katya Govorkova",
        "Julian Garcia Pardinas",
        "Vladimir Loncar",
        "Victoria Nguyen",
        "Sebastian Schmitt",
        "Marco Pizzichemi",
        "Loris Martinazzoli",
        "Eluned Anne Smith"
      ],
      "primary_category": "hep-ex",
      "categories": [
        "hep-ex",
        "cs.LG"
      ],
      "published": "2026-02-17 17:30:28+00:00",
      "link": "https://arxiv.org/pdf/2602.15751v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15750v1",
      "title": "UrbanVerse: Learning Urban Region Representation Across Cities and Tasks",
      "abstract": "Recent advances in urban region representation learning have enabled a wide range of applications in urban analytics, yet existing methods remain limited in their capabilities to generalize across cities and analytic tasks. We aim to generalize urban representation learning beyond city- and task-specific settings, towards a foundation-style model for urban analytics. To this end, we propose UrbanVerse, a model for cross-city urban representation learning and cross-task urban analytics. For cross-city generalization, UrbanVerse focuses on features local to the target regions and structural features of the nearby regions rather than the entire city. We model regions as nodes on a graph, which enables a random walk-based procedure to form \"sequences of regions\" that reflect both local and neighborhood structural features for urban region representation learning. For cross-task generalization, we propose a cross-task learning module named HCondDiffCT. This module integrates region-conditioned prior knowledge and task-conditioned semantics into the diffusion process to jointly model multiple downstream urban prediction tasks. HCondDiffCT is generic. It can also be integrated with existing urban representation learning models to enhance their downstream task effectiveness. Experiments on real-world datasets show that UrbanVerse consistently outperforms state-of-the-art methods across six tasks under cross-city settings, achieving up to 35.89% improvements in prediction accuracy.",
      "authors": [
        "Fengze Sun",
        "Egemen Tanin",
        "Shanika Karunasekera",
        "Zuqing Li",
        "Flora D. Salim",
        "Jianzhong Qi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-17 17:28:48+00:00",
      "link": "https://arxiv.org/pdf/2602.15750v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15749v1",
      "title": "A Generative-First Neural Audio Autoencoder",
      "abstract": "Neural autoencoders underpin generative models. Practical, large-scale use of neural autoencoders for generative modeling necessitates fast encoding, low latent rates, and a single model across representations. Existing approaches are reconstruction-first: they incur high latent rates, slow encoding, and separate architectures for discrete vs. continuous latents and for different audio channel formats, hindering workflows from preprocessing to inference conditioning. We introduce a generative-first architecture for audio autoencoding that increases temporal downsampling from 2048x to 3360x and supports continuous and discrete representations and common audio channel formats in one model. By balancing compression, quality, and speed, it delivers 10x faster encoding, 1.6x lower rates, and eliminates channel-format-specific variants while maintaining competitive reconstruction quality. This enables applications previously constrained by processing costs: a 60-second mono signal compresses to 788 tokens, making generative modeling more tractable.",
      "authors": [
        "Jonah Casebeer",
        "Ge Zhu",
        "Zhepei Wang",
        "Nicholas J. Bryan"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "eess.AS"
      ],
      "published": "2026-02-17 17:26:12+00:00",
      "link": "https://arxiv.org/pdf/2602.15749v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15740v1",
      "title": "MRC-GAT: A Meta-Relational Copula-Based Graph Attention Network for Interpretable Multimodal Alzheimer's Disease Diagnosis",
      "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative condition necessitating early and precise diagnosis to provide prompt clinical management. Given the paramount importance of early diagnosis, recent studies have increasingly focused on computer-aided diagnostic models to enhance precision and reliability. However, most graph-based approaches still rely on fixed structural designs, which restrict their flexibility and limit generalization across heterogeneous patient data. To overcome these limitations, the Meta-Relational Copula-Based Graph Attention Network (MRC-GAT) is proposed as an efficient multimodal model for AD classification tasks. The proposed architecture, copula-based similarity alignment, relational attention, and node fusion are integrated as the core components of episodic meta-learning, such that the multimodal features, including risk factors (RF), Cognitive test scores, and MRI attributes, are first aligned via a copula-based transformation in a common statistical space and then combined by a multi-relational attention mechanism. According to evaluations performed on the TADPOLE and NACC datasets, the MRC-GAT model achieved accuracies of 96.87% and 92.31%, respectively, demonstrating state-of-the-art performance compared to existing diagnostic models. Finally, the proposed model confirms the robustness and applicability of the proposed method by providing interpretability at various stages of disease diagnosis.",
      "authors": [
        "Fatemeh Khalvandi",
        "Saadat Izadi",
        "Abdolah Chalechale"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "published": "2026-02-17 17:15:32+00:00",
      "link": "https://arxiv.org/pdf/2602.15740v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15734v1",
      "title": "Language and Geometry Grounded Sparse Voxel Representations for Holistic Scene Understanding",
      "abstract": "Existing 3D open-vocabulary scene understanding methods mostly emphasize distilling language features from 2D foundation models into 3D feature fields, but largely overlook the synergy among scene appearance, semantics, and geometry. As a result, scene understanding often deviates from the underlying geometric structure of scenes and becomes decoupled from the reconstruction process. In this work, we propose a novel approach that leverages language and geometry grounded sparse voxel representations to comprehensively model appearance, semantics, and geometry within a unified framework. Specifically, we use 3D sparse voxels as primitives and employ an appearance field, a density field, a feature field, and a confidence field to holistically represent a 3D scene. To promote synergy among the appearance, density, and feature fields, we construct a feature modulation module and distill language features from a 2D foundation model into our 3D scene model. In addition, we integrate geometric distillation into feature field distillation to transfer geometric knowledge from a geometry foundation model to our 3D scene representations via depth correlation regularization and pattern consistency regularization. These components work together to synergistically model the appearance, semantics, and geometry of the 3D scene within a unified framework. Extensive experiments demonstrate that our approach achieves superior overall performance compared with state-of-the-art methods in holistic scene understanding and reconstruction.",
      "authors": [
        "Guile Wu",
        "David Huang",
        "Bingbing Liu",
        "Dongfeng Bai"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-17 17:10:13+00:00",
      "link": "https://arxiv.org/pdf/2602.15734v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15733v1",
      "title": "MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction",
      "abstract": "Humanoid motion control has witnessed significant breakthroughs in recent years, with deep reinforcement learning (RL) emerging as a primary catalyst for achieving complex, human-like behaviors. However, the high dimensionality and intricate dynamics of humanoid robots make manual motion design impractical, leading to a heavy reliance on expensive motion capture (MoCap) data. These datasets are not only costly to acquire but also frequently lack the necessary geometric context of the surrounding physical environment. Consequently, existing motion synthesis frameworks often suffer from a decoupling of motion and scene, resulting in physical inconsistencies such as contact slippage or mesh penetration during terrain-aware tasks. In this work, we present MeshMimic, an innovative framework that bridges 3D scene reconstruction and embodied intelligence to enable humanoid robots to learn coupled \"motion-terrain\" interactions directly from video. By leveraging state-of-the-art 3D vision models, our framework precisely segments and reconstructs both human trajectories and the underlying 3D geometry of terrains and objects. We introduce an optimization algorithm based on kinematic consistency to extract high-quality motion data from noisy visual reconstructions, alongside a contact-invariant retargeting method that transfers human-environment interaction features to the humanoid agent. Experimental results demonstrate that MeshMimic achieves robust, highly dynamic performance across diverse and challenging terrains. Our approach proves that a low-cost pipeline utilizing only consumer-grade monocular sensors can facilitate the training of complex physical interactions, offering a scalable path toward the autonomous evolution of humanoid robots in unstructured environments.",
      "authors": [
        "Qiang Zhang",
        "Jiahao Ma",
        "Peiran Liu",
        "Shuai Shi",
        "Zeran Su",
        "Zifan Wang",
        "Jingkai Sun",
        "Wei Cui",
        "Jialin Yu",
        "Gang Han",
        "Wen Zhao",
        "Pihai Sun",
        "Kangning Yin",
        "Jiaxu Wang",
        "Jiahang Cao",
        "Lingfeng Zhang",
        "Hao Cheng",
        "Xiaoshuai Hao",
        "Yiding Ji",
        "Junwei Liang",
        "Jian Tang",
        "Renjing Xu",
        "Yijie Guo"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-17 17:09:45+00:00",
      "link": "https://arxiv.org/pdf/2602.15733v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15727v1",
      "title": "Spanning the Visual Analogy Space with a Weight Basis of LoRAs",
      "abstract": "Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words. Given a triplet $\\{\\mathbf{a}$, $\\mathbf{a}'$, $\\mathbf{b}\\}$, the goal is to generate $\\mathbf{b}'$ such that $\\mathbf{a} : \\mathbf{a}' :: \\mathbf{b} : \\mathbf{b}'$. Recent methods adapt text-to-image models to this task using a single Low-Rank Adaptation (LoRA) module, but they face a fundamental limitation: attempting to capture the diverse space of visual transformations within a fixed adaptation module constrains generalization capabilities. Inspired by recent work showing that LoRAs in constrained domains span meaningful, interpolatable semantic spaces, we propose LoRWeB, a novel approach that specializes the model for each analogy task at inference time through dynamic composition of learned transformation primitives, informally, choosing a point in a \"space of LoRAs\". We introduce two key components: (1) a learnable basis of LoRA modules, to span the space of different visual transformations, and (2) a lightweight encoder that dynamically selects and weighs these basis LoRAs based on the input analogy pair. Comprehensive evaluations demonstrate our approach achieves state-of-the-art performance and significantly improves generalization to unseen visual transformations. Our findings suggest that LoRA basis decompositions are a promising direction for flexible visual manipulation. Code and data are in https://research.nvidia.com/labs/par/lorweb",
      "authors": [
        "Hila Manor",
        "Rinon Gal",
        "Haggai Maron",
        "Tomer Michaeli",
        "Gal Chechik"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "eess.IV"
      ],
      "published": "2026-02-17 17:02:38+00:00",
      "link": "https://arxiv.org/pdf/2602.15727v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15712v1",
      "title": "Criteria-first, semantics-later: reproducible structure discovery in image-based sciences",
      "abstract": "Across the natural and life sciences, images have become a primary measurement modality, yet the dominant analytic paradigm remains semantics-first. Structure is recovered by predicting or enforcing domain-specific labels. This paradigm fails systematically under the conditions that make image-based science most valuable, including open-ended scientific discovery, cross-sensor and cross-site comparability, and long-term monitoring in which domain ontologies and associated label sets drift culturally, institutionally, and ecologically. A deductive inversion is proposed in the form of criteria-first and semantics-later. A unified framework for criteria-first structure discovery is introduced. It separates criterion-defined, semantics-free structure extraction from downstream semantic mapping into domain ontologies or vocabularies and provides a domain-general scaffold for reproducible analysis across image-based sciences. Reproducible science requires that the first analytic layer perform criterion-driven, semantics-free structure discovery, yielding stable partitions, structural fields, or hierarchies defined by explicit optimality criteria rather than local domain ontologies. Semantics is not discarded; it is relocated downstream as an explicit mapping from the discovered structural product to a domain ontology or vocabulary, enabling plural interpretations and explicit crosswalks without rewriting upstream extraction. Grounded in cybernetics, observation-as-distinction, and information theory's separation of information from meaning, the argument is supported by cross-domain evidence showing that criteria-first components recur whenever labels do not scale. Finally, consequences are outlined for validation beyond class accuracy and for treating structural products as FAIR, AI-ready digital objects for long-term monitoring and digital twins.",
      "authors": [
        "Jan Bumberger"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-17 16:45:49+00:00",
      "link": "https://arxiv.org/pdf/2602.15712v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15704v1",
      "title": "Controlled oscillation modeling using port-Hamiltonian neural networks",
      "abstract": "Learning dynamical systems through purely data-driven methods is challenging as they do not learn the underlying conservation laws that enable them to correctly generalize. Existing port-Hamiltonian neural network methods have recently been successfully applied for modeling mechanical systems. However, even though these methods are designed on power-balance principles, they usually do not consider power-preserving discretizations and often rely on Runge-Kutta numerical methods. In this work, we propose to use a second-order discrete gradient method embedded in the learning of dynamical systems with port-Hamiltonian neural networks. Numerical results are provided for three systems deliberately selected to span different ranges of dynamical behavior under control: a baseline harmonic oscillator with quadratic energy storage; a Duffing oscillator, with a non-quadratic Hamiltonian offering amplitude-dependent effects; and a self-sustained oscillator, which can stabilize in a controlled limit cycle through the incorporation of a nonlinear dissipation. We show how the use of this discrete gradient method outperforms the performance of a Runge-Kutta method of the same order. Experiments are also carried out to compare two theoretically equivalent port-Hamiltonian systems formulations and to analyze the impact of regularizing the Jacobian of port-Hamiltonian neural networks during training.",
      "authors": [
        "Maximino Linares",
        "Guillaume Doras",
        "Thomas Hélie"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "eess.SY",
        "math.DS"
      ],
      "published": "2026-02-17 16:38:41+00:00",
      "link": "https://arxiv.org/pdf/2602.15704v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15923v1",
      "title": "A fully differentiable framework for training proxy Exchange Correlation Functionals for periodic systems",
      "abstract": "Density Functional Theory (DFT) is widely used for first-principles simulations in chemistry and materials science, but its computational cost remains a key limitation for large systems. Motivated by recent advances in ML-based exchange-correlation (XC) functionals, this paper introduces a differentiable framework that integrates machine learning models into density functional theory (DFT) for solids and other periodic systems. The framework defines a clean API for neural network models that can act as drop in replacements for conventional exchange-correlation (XC) functionals and enables gradients to flow through the full self-consistent DFT workflow. The framework is implemented in Python using a PyTorch backend, making it fully differentiable and easy to use with standard deep learning tools. We integrate the implementation with the DeepChem library to promote the reuse of established models and to lower the barrier for experimentation. In initial benchmarks against established electronic structure packages (GPAW and PySCF), our models achieve relative errors on the order of 5-10%.",
      "authors": [
        "Rakshit Kumar Singh",
        "Aryan Amit Barsainyan",
        "Bharath Ramsundar"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-17 16:13:07+00:00",
      "link": "https://arxiv.org/pdf/2602.15923v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15684v1",
      "title": "Estimating Human Muscular Fatigue in Dynamic Collaborative Robotic Tasks with Learning-Based Models",
      "abstract": "Assessing human muscle fatigue is critical for optimizing performance and safety in physical human-robot interaction(pHRI). This work presents a data-driven framework to estimate fatigue in dynamic, cyclic pHRI using arm-mounted surface electromyography(sEMG). Subject-specific machine-learning regression models(Random Forest, XGBoost, and Linear Regression predict the fraction of cycles to fatigue(FCF) from three frequency-domain and one time-domain EMG features, and are benchmarked against a convolutional neural network(CNN) that ingests spectrograms of filtered EMG. Framing fatigue estimation as regression (rather than classification) captures continuous progression toward fatigue, supporting earlier detection, timely intervention, and adaptive robot control. In experiments with ten participants, a collaborative robot under admittance control guided repetitive lateral (left-right) end-effector motions until muscular fatigue. Average FCF RMSE across participants was 20.8+/-4.3% for the CNN, 23.3+/-3.8% for Random Forest, 24.8+/-4.5% for XGBoost, and 26.9+/-6.1% for Linear Regression. To probe cross-task generalization, one participant additionally performed unseen vertical (up-down) and circular repetitions; models trained only on lateral data were tested directly and largely retained accuracy, indicating robustness to changes in movement direction, arm kinematics, and muscle recruitment, while Linear Regression deteriorated. Overall, the study shows that both feature-based ML and spectrogram-based DL can estimate remaining work capacity during repetitive pHRI, with the CNN delivering the lowest error and the tree-based models close behind. The reported transfer to new motion patterns suggests potential for practical fatigue monitoring without retraining for every task, improving operator protection and enabling fatigue-aware shared autonomy, for safer fatigue-adaptive pHRI control.",
      "authors": [
        "Feras Kiki",
        "Pouya P. Niaz",
        "Alireza Madani",
        "Cagatay Basdogan"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "eess.SP",
        "eess.SY"
      ],
      "published": "2026-02-17 16:08:11+00:00",
      "link": "https://arxiv.org/pdf/2602.15684v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15676v1",
      "title": "Relative Geometry of Neural Forecasters: Linking Accuracy and Alignment in Learned Latent Geometry",
      "abstract": "Neural networks can accurately forecast complex dynamical systems, yet how they internally represent underlying latent geometry remains poorly understood. We study neural forecasters through the lens of representational alignment, introducing anchor-based, geometry-agnostic relative embeddings that remove rotational and scaling ambiguities in latent spaces. Applying this framework across seven canonical dynamical systems - ranging from periodic to chaotic - we reveal reproducible family-level structure: multilayer perceptrons align with other MLPs, recurrent networks with RNNs, while transformers and echo-state networks achieve strong forecasts despite weaker alignment. Alignment generally correlates with forecasting accuracy, yet high accuracy can coexist with low alignment. Relative geometry thus provides a simple, reproducible foundation for comparing how model families internalize and represent dynamical structure.",
      "authors": [
        "Deniz Kucukahmetler",
        "Maximilian Jean Hemmann",
        "Julian Mosig von Aehrenfeld",
        "Maximilian Amthor",
        "Christian Deubel",
        "Nico Scherf",
        "Diaaeldin Taha"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-17 16:00:08+00:00",
      "link": "https://arxiv.org/pdf/2602.15676v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15675v1",
      "title": "LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models",
      "abstract": "Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.",
      "authors": [
        "Ahmed Khaled Khamis",
        "Hesham Ali"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-17 15:58:27+00:00",
      "link": "https://arxiv.org/pdf/2602.15675v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15649v1",
      "title": "Continuous-Time Piecewise-Linear Recurrent Neural Networks",
      "abstract": "In dynamical systems reconstruction (DSR) we aim to recover the dynamical system (DS) underlying observed time series. Specifically, we aim to learn a generative surrogate model which approximates the underlying, data-generating DS, and recreates its long-term properties (`climate statistics'). In scientific and medical areas, in particular, these models need to be mechanistically tractable -- through their mathematical analysis we would like to obtain insight into the recovered system's workings. Piecewise-linear (PL), ReLU-based RNNs (PLRNNs) have a strong track-record in this regard, representing SOTA DSR models while allowing mathematical insight by virtue of their PL design. However, all current PLRNN variants are discrete-time maps. This is in disaccord with the assumed continuous-time nature of most physical and biological processes, and makes it hard to accommodate data arriving at irregular temporal intervals. Neural ODEs are one solution, but they do not reach the DSR performance of PLRNNs and often lack their tractability. Here we develop theory for continuous-time PLRNNs (cPLRNNs): We present a novel algorithm for training and simulating such models, bypassing numerical integration by efficiently exploiting their PL structure. We further demonstrate how important topological objects like equilibria or limit cycles can be determined semi-analytically in trained models. We compare cPLRNNs to both their discrete-time cousins as well as Neural ODEs on DSR benchmarks, including systems with discontinuities which come with hard thresholds.",
      "authors": [
        "Alena Brändle",
        "Lukas Eisenmann",
        "Florian Götz",
        "Daniel Durstewitz"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-17 15:16:12+00:00",
      "link": "https://arxiv.org/pdf/2602.15649v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15640v1",
      "title": "Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications",
      "abstract": "Semantic communication promises task-aligned transmission but must reconcile semantic fidelity with stringent latency guarantees in immersive and safety-critical services. This paper introduces a time-constrained human-in-the-loop reinforcement learning (TC-HITL-RL) framework that embeds human feedback, semantic utility, and latency control within a semantic-aware Open radio access network (RAN) architecture. We formulate semantic adaptation driven by human feedback as a constrained Markov decision process (CMDP) whose state captures semantic quality, human preferences, queue slack, and channel dynamics, and solve it via a primal--dual proximal policy optimization algorithm with action shielding and latency-aware reward shaping. The resulting policy preserves PPO-level semantic rewards while tightening the variability of both air-interface and near-real-time RAN intelligent controller processing budgets. Simulations over point-to-multipoint links with heterogeneous deadlines show that TC-HITL-RL consistently meets per-user timing constraints, outperforms baseline schedulers in reward, and stabilizes resource consumption, providing a practical blueprint for latency-aware semantic adaptation.",
      "authors": [
        "Peizheng Li",
        "Xinyi Lin",
        "Adnan Aijaz"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "cs.LG"
      ],
      "published": "2026-02-17 15:07:41+00:00",
      "link": "https://arxiv.org/pdf/2602.15640v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15922v1",
      "title": "World Action Models are Zero-shot Policies",
      "abstract": "State-of-the-art Vision-Language-Action (VLA) models excel at semantic generalization but struggle to generalize to unseen physical motions in novel environments. We introduce DreamZero, a World Action Model (WAM) built upon a pretrained video diffusion backbone. Unlike VLAs, WAMs learn physical dynamics by predicting future world states and actions, using video as a dense representation of how the world evolves. By jointly modeling video and action, DreamZero learns diverse skills effectively from heterogeneous robot data without relying on repetitive demonstrations. This results in over 2x improvement in generalization to new tasks and environments compared to state-of-the-art VLAs in real robot experiments. Crucially, through model and system optimizations, we enable a 14B autoregressive video diffusion model to perform real-time closed-loop control at 7Hz. Finally, we demonstrate two forms of cross-embodiment transfer: video-only demonstrations from other robots or humans yield a relative improvement of over 42% on unseen task performance with just 10-20 minutes of data. More surprisingly, DreamZero enables few-shot embodiment adaptation, transferring to a new embodiment with only 30 minutes of play data while retaining zero-shot generalization.",
      "authors": [
        "Seonghyeon Ye",
        "Yunhao Ge",
        "Kaiyuan Zheng",
        "Shenyuan Gao",
        "Sihyun Yu",
        "George Kurian",
        "Suneel Indupuru",
        "You Liang Tan",
        "Chuning Zhu",
        "Jiannan Xiang",
        "Ayaan Malik",
        "Kyungmin Lee",
        "William Liang",
        "Nadun Ranawaka",
        "Jiasheng Gu",
        "Yinzhen Xu",
        "Guanzhi Wang",
        "Fengyuan Hu",
        "Avnish Narayan",
        "Johan Bjorck",
        "Jing Wang",
        "Gwanghyun Kim",
        "Dantong Niu",
        "Ruijie Zheng",
        "Yuqi Xie",
        "Jimmy Wu",
        "Qi Wang",
        "Ryan Julian",
        "Danfei Xu",
        "Yilun Du",
        "Yevgen Chebotar",
        "Scott Reed",
        "Jan Kautz",
        "Yuke Zhu",
        "Linxi \"Jim\" Fan",
        "Joel Jang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-17 15:04:02+00:00",
      "link": "https://arxiv.org/pdf/2602.15922v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15635v1",
      "title": "On inferring cumulative constraints",
      "abstract": "Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.",
      "authors": [
        "Konstantin Sidorov"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-17 15:03:43+00:00",
      "link": "https://arxiv.org/pdf/2602.15635v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15634v1",
      "title": "Beyond ReLU: Bifurcation, Oversmoothing, and Topological Priors",
      "abstract": "Graph Neural Networks (GNNs) learn node representations through iterative network-based message-passing. While powerful, deep GNNs suffer from oversmoothing, where node features converge to a homogeneous, non-informative state. We re-frame this problem of representational collapse from a \\emph{bifurcation theory} perspective, characterizing oversmoothing as convergence to a stable ``homogeneous fixed point.'' Our central contribution is the theoretical discovery that this undesired stability can be broken by replacing standard monotone activations (e.g., ReLU) with a class of functions. Using Lyapunov-Schmidt reduction, we analytically prove that this substitution induces a bifurcation that destabilizes the homogeneous state and creates a new pair of stable, non-homogeneous \\emph{patterns} that provably resist oversmoothing. Our theory predicts a precise, nontrivial scaling law for the amplitude of these emergent patterns, which we quantitatively validate in experiments. Finally, we demonstrate the practical utility of our theory by deriving a closed-form, bifurcation-aware initialization and showing its utility in real benchmark experiments.",
      "authors": [
        "Erkan Turan",
        "Gaspard Abel",
        "Maysam Behmanesh",
        "Emery Pierson",
        "Maks Ovsjanikov"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-17 15:03:28+00:00",
      "link": "https://arxiv.org/pdf/2602.15634v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15633v1",
      "title": "SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms",
      "abstract": "Autonomous landing of Uncrewed Aerial Vehicles (UAVs) on oscillating marine platforms is severely constrained by wave-induced multi-frequency oscillations, wind disturbances, and prediction phase lags in motion prediction. Existing methods either treat platform motion as a general random process or lack explicit modeling of wave spectral characteristics, leading to suboptimal performance under dynamic sea conditions. To address these limitations, we propose SpecFuse: a novel spectral-temporal fusion predictive control framework that integrates frequency-domain wave decomposition with time-domain recursive state estimation for high-precision 6-DoF motion forecasting of Uncrewed Surface Vehicles (USVs). The framework explicitly models dominant wave harmonics to mitigate phase lags, refining predictions in real time via IMU data without relying on complex calibration. Additionally, we design a hierarchical control architecture featuring a sampling-based HPO-RRT* algorithm for dynamic trajectory planning under non-convex constraints and a learning-augmented predictive controller that fuses data-driven disturbance compensation with optimization-based execution. Extensive validations (2,000 simulations + 8 lake experiments) show our approach achieves a 3.2 cm prediction error, 4.46 cm landing deviation, 98.7% / 87.5% success rates (simulation / real-world), and 82 ms latency on embedded hardware, outperforming state-of-the-art methods by 44%-48% in accuracy. Its robustness to wave-wind coupling disturbances supports critical maritime missions such as search and rescue and environmental monitoring. All code, experimental configurations, and datasets will be released as open-source to facilitate reproducibility.",
      "authors": [
        "Haichao Liu",
        "Yufeng Hu",
        "Shuang Wang",
        "Kangjun Guo",
        "Jun Ma",
        "Jinni Zhou"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-17 15:03:05+00:00",
      "link": "https://arxiv.org/pdf/2602.15633v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15632v1",
      "title": "Neural-POD: A Plug-and-Play Neural Operator Framework for Infinite-Dimensional Functional Nonlinear Proper Orthogonal Decomposition",
      "abstract": "The rapid development of AI for Science is often hindered by the \"discretization\", where learned representations remain restricted to the specific grids or resolutions used during training. We propose the Neural Proper Orthogonal Decomposition (Neural-POD), a plug-and-play neural operator framework that constructs nonlinear, orthogonal basis functions in infinite-dimensional space using neural networks. Unlike the classical Proper Orthogonal Decomposition (POD), which is limited to linear subspace approximations obtained through singular value decomposition (SVD), Neural-POD formulates basis construction as a sequence of residual minimization problems solved through neural network training. Each basis function is obtained by learning to represent the remaining structure in the data, following a process analogous to Gram--Schmidt orthogonalization. This neural formulation introduces several key advantages over classical POD: it enables optimization in arbitrary norms (e.g., $L^2$, $L^1$), learns mappings between infinite-dimensional function spaces that is resolution-invariant, generalizes effectively to unseen parameter regimes, and inherently captures nonlinear structures in complex spatiotemporal systems. The resulting basis functions are interpretable, reusable, and enabling integration into both reduced order modeling (ROM) and operator learning frameworks such as deep operator learning (DeepONet). We demonstrate the robustness of Neural-POD with different complex spatiotemporal systems, including the Burgers' and Navier-Stokes equations. We further show that Neural-POD serves as a high performance, plug-and-play bridge between classical Galerkin projection and operator learning that enables consistent integration with both projection-based reduced order models and DeepONet frameworks.",
      "authors": [
        "Changhong Mou",
        "Binghang Lu",
        "Guang Lin"
      ],
      "primary_category": "physics.comp-ph",
      "categories": [
        "physics.comp-ph",
        "cs.LG",
        "math.NA"
      ],
      "published": "2026-02-17 15:01:40+00:00",
      "link": "https://arxiv.org/pdf/2602.15632v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15620v2",
      "title": "STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens",
      "abstract": "Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often suffer from late-stage performance collapse, leading to degraded reasoning quality and unstable training. Our analysis shows that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. We find that training instability can be caused by a tiny fraction of tokens, approximately 0.01\\%, which we term \\emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. To mitigate this instability, we design S2T (silencing spurious tokens) mechanism to efficiently identify spurious tokens through characteristic signals with low probability, low entropy, and positive advantage, and then to suppress their gradient perturbations during optimization. Incorporating this mechanism into a group-based objective, we propose Spurious-Token-Aware Policy Optimization (STAPO), which promotes stable and effective large-scale model refinement. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\\% ($ρ_{\\mathrm{T}}$=1.0, top-p=1.0) and 3.69\\% ($ρ_{\\mathrm{T}}$=0.7, top-p=0.9) over GRPO, 20-Entropy and JustRL.",
      "authors": [
        "Shiqi Liu",
        "Zeyu He",
        "Guojian Zhan",
        "Letian Tao",
        "Zhilong Zheng",
        "Jiang Wu",
        "Yinuo Wang",
        "Yang Guan",
        "Kehua Sheng",
        "Bo Zhang",
        "Keqiang Li",
        "Jingliang Duan",
        "Shengbo Eben Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-17 14:46:48+00:00",
      "link": "https://arxiv.org/pdf/2602.15620v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15617v1",
      "title": "DNN-Enabled Multi-User Beamforming for Throughput Maximization under Adjustable Fairness",
      "abstract": "Ensuring user fairness in wireless communications is a fundamental challenge, as balancing the trade-off between fairness and sum rate leads to a non-convex, multi-objective optimization whose complexity grows with network scale. To alleviate this conflict, we propose an optimization-based unsupervised learning approach based on the wireless transformer (WiT) architecture that learns from channel state information (CSI) features. We reformulate the trade-off by combining the sum rate and fairness objectives through a Lagrangian multiplier, which is updated automatically via a dual-ascent algorithm. This mechanism allows for a controllable fairness constraint while simultaneously maximizing the sum rate, effectively realizing a trace on the Pareto front between two conflicting objectives. Our findings show that the proposed approach offers a flexible solution for managing the trade-off optimization under prescribed fairness.",
      "authors": [
        "Kaifeng Lu",
        "Markus Rupp",
        "Stefan Schwarz"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.NI"
      ],
      "published": "2026-02-17 14:46:02+00:00",
      "link": "https://arxiv.org/pdf/2602.15617v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15603v1",
      "title": "Symbolic recovery of PDEs from measurement data",
      "abstract": "Models based on partial differential equations (PDEs) are powerful for describing a wide range of complex relationships in the natural sciences. Accurately identifying the PDE model, which represents the underlying physical law, is essential for a proper understanding of the problem. This reconstruction typically relies on indirect and noisy measurements of the system's state and, without specifically tailored methods, rarely yields symbolic expressions, thereby hindering interpretability. In this work, we address this issue by considering existing neural network architectures based on rational functions for the symbolic representation of physical laws. These networks leverage the approximation power of rational functions while also benefiting from their flexibility in representing arithmetic operations. Our main contribution is an identifiability result, showing that, in the limit of noiseless, complete measurements, such symbolic networks can uniquely reconstruct the simplest physical law within the PDE model. Specifically, reconstructed laws remain expressible within the symbolic network architecture, with regularization-minimizing parameterizations promoting interpretability and sparsity in case of $L^1$-regularization. In addition, we provide regularity results for symbolic networks. Empirical validation using the ParFam architecture supports these theoretical findings, providing evidence for the practical reconstructibility of physical laws.",
      "authors": [
        "Erion Morina",
        "Philipp Scholl",
        "Martin Holler"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.SC",
        "math.OC"
      ],
      "published": "2026-02-17 14:20:36+00:00",
      "link": "https://arxiv.org/pdf/2602.15603v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15602v1",
      "title": "Certified Per-Instance Unlearning Using Individual Sensitivity Bounds",
      "abstract": "Certified machine unlearning can be achieved via noise injection leading to differential privacy guarantees, where noise is calibrated to worst-case sensitivity. Such conservative calibration often results in performance degradation, limiting practical applicability. In this work, we investigate an alternative approach based on adaptive per-instance noise calibration tailored to the individual contribution of each data point to the learned solution. This raises the following challenge: how can one establish formal unlearning guarantees when the mechanism depends on the specific point to be removed? To define individual data point sensitivities in noisy gradient dynamics, we consider the use of per-instance differential privacy. For ridge regression trained via Langevin dynamics, we derive high-probability per-instance sensitivity bounds, yielding certified unlearning with substantially less noise injection. We corroborate our theoretical findings through experiments in linear settings and provide further empirical evidence on the relevance of the approach in deep learning settings.",
      "authors": [
        "Hanna Benarroch",
        "Jamal Atif",
        "Olivier Cappé"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-17 14:18:47+00:00",
      "link": "https://arxiv.org/pdf/2602.15602v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15595v1",
      "title": "Multi-Objective Coverage via Constraint Active Search",
      "abstract": "In this paper, we formulate the new multi-objective coverage (MOC) problem where our goal is to identify a small set of representative samples whose predicted outcomes broadly cover the feasible multi-objective space. This problem is of great importance in many critical real-world applications, e.g., drug discovery and materials design, as this representative set can be evaluated much faster than the whole feasible set, thus significantly accelerating the scientific discovery process. Existing works cannot be directly applied as they either focus on sample space coverage or multi-objective optimization that targets the Pareto front. However, chemically diverse samples often yield identical objective profiles, and safety constraints are usually defined on the objectives. To solve this MOC problem, we propose a novel search algorithm, MOC-CAS, which employs an upper confidence bound-based acquisition function to select optimistic samples guided by Gaussian process posterior predictions. For enabling efficient optimization, we develop a smoothed relaxation of the hard feasibility test and derive an approximate optimizer. Compared to the competitive baselines, we show that our MOC-CAS empirically achieves superior performances across large-scale protein-target datasets for SARS-CoV-2 and cancer, each assessed on five objectives derived from SMILES-based features.",
      "authors": [
        "Zakaria Shams Siam",
        "Xuefeng Liu",
        "Chong Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-17 14:07:16+00:00",
      "link": "https://arxiv.org/pdf/2602.15595v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15593v1",
      "title": "A unified theory of feature learning in RNNs and DNNs",
      "abstract": "Recurrent and deep neural networks (RNNs/DNNs) are cornerstone architectures in machine learning. Remarkably, RNNs differ from DNNs only by weight sharing, as can be shown through unrolling in time. How does this structural similarity fit with the distinct functional properties these networks exhibit? To address this question, we here develop a unified mean-field theory for RNNs and DNNs in terms of representational kernels, describing fully trained networks in the feature learning ($μ$P) regime. This theory casts training as Bayesian inference over sequences and patterns, directly revealing the functional implications induced by the RNNs' weight sharing. In DNN-typical tasks, we identify a phase transition when the learning signal overcomes the noise due to randomness in the weights: below this threshold, RNNs and DNNs behave identically; above it, only RNNs develop correlated representations across timesteps. For sequential tasks, the RNNs' weight sharing furthermore induces an inductive bias that aids generalization by interpolating unsupervised time steps. Overall, our theory offers a way to connect architectural structure to functional biases.",
      "authors": [
        "Jan P. Bauer",
        "Kirsten Fischer",
        "Moritz Helias",
        "Agostina Palmigiano"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn"
      ],
      "published": "2026-02-17 14:06:34+00:00",
      "link": "https://arxiv.org/pdf/2602.15593v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15592v1",
      "title": "Uni-Flow: a unified autoregressive-diffusion model for complex multiscale flows",
      "abstract": "Spatiotemporal flows govern diverse phenomena across physics, biology, and engineering, yet modelling their multiscale dynamics remains a central challenge. Despite major advances in physics-informed machine learning, existing approaches struggle to simultaneously maintain long-term temporal evolution and resolve fine-scale structure across chaotic, turbulent, and physiological regimes. Here, we introduce Uni-Flow, a unified autoregressive-diffusion framework that explicitly separates temporal evolution from spatial refinement for modelling complex dynamical systems. The autoregressive component learns low-resolution latent dynamics that preserve large-scale structure and ensure stable long-horizon rollouts, while the diffusion component reconstructs high-resolution physical fields, recovering fine-scale features in a small number of denoising steps. We validate Uni-Flow across canonical benchmarks, including two-dimensional Kolmogorov flow, three-dimensional turbulent channel inflow generation with a quantum-informed autoregressive prior, and patient-specific simulations of aortic coarctation derived from high-fidelity lattice Boltzmann hemodynamic solvers. In the cardiovascular setting, Uni-Flow enables task-level faster than real-time inference of pulsatile hemodynamics, reconstructing high-resolution pressure fields over physiologically relevant time horizons in seconds rather than hours. By transforming high-fidelity hemodynamic simulation from an offline, HPC-bound process into a deployable surrogate, Uni-Flow establishes a pathway to faster-than-real-time modelling of complex multiscale flows, with broad implications for scientific machine learning in flow physics.",
      "authors": [
        "Xiao Xue",
        "Tianyue Yang",
        "Mingyang Gao",
        "Leyu Pan",
        "Maida Wang",
        "Kewei Zhu",
        "Shuo Wang",
        "Jiuling Li",
        "Marco F. P. ten Eikelder",
        "Peter V. Coveney"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "cs.LG",
        "physics.comp-ph"
      ],
      "published": "2026-02-17 14:04:37+00:00",
      "link": "https://arxiv.org/pdf/2602.15592v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15579v1",
      "title": "Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning",
      "abstract": "Intracoronary Optical Coherence Tomography (OCT) enables high-resolution visualization of coronary vessel anatomy but presents challenges due to noise, imaging artifacts, and complex tissue structures. This paper proposes a fully automated pipeline for vessel segmentation and classification in OCT images using machine learning techniques. The proposed method integrates image preprocessing, guidewire artifact removal, polar-to-Cartesian transformation, unsupervised K-means clustering, and local feature extraction. These features are used to train Logistic Regression and Support Vector Machine classifiers for pixel-wise vessel classification. Experimental results demonstrate excellent performance, achieving precision, recall, and F1-score values up to 1.00 and overall classification accuracy of 99.68%. The proposed approach provides accurate vessel boundary detection while maintaining low computational complexity and requiring minimal manual annotation. This method offers a reliable and efficient solution for automated OCT image analysis and has potential applications in clinical decision support and real-time medical image processing.",
      "authors": [
        "Amal Lahchim",
        "Lambros Athanasiou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-17 13:47:27+00:00",
      "link": "https://arxiv.org/pdf/2602.15579v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15572v1",
      "title": "Neural Network-Based Parameter Estimation of a Labour Market Agent-Based Model",
      "abstract": "Agent-based modelling (ABM) is a widespread approach to simulate complex systems. Advancements in computational processing and storage have facilitated the adoption of ABMs across many fields; however, ABMs face challenges that limit their use as decision-support tools. A significant issue is parameter estimation in large-scale ABMs, particularly due to computational constraints on exploring the parameter space. This study evaluates a state-of-the-art simulation-based inference (SBI) framework that uses neural networks (NN) for parameter estimation. This framework is applied to an established labour market ABM based on job transition networks. The ABM is initiated with synthetic datasets and the real U.S. labour market. Next, we compare the effectiveness of summary statistics derived from a list of statistical measures with that learned by an embedded NN. The results demonstrate that the NN-based approach recovers the original parameters when evaluating posterior distributions across various dataset scales and improves efficiency compared to traditional Bayesian methods.",
      "authors": [
        "M Lopes Alves",
        "Joel Dyer",
        "Doyne Farmer",
        "Michael Wooldridge",
        "Anisoara Calinescu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-02-17 13:32:35+00:00",
      "link": "https://arxiv.org/pdf/2602.15572v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15564v1",
      "title": "Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL",
      "abstract": "Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL",
      "authors": [
        "Yihan Wang",
        "Peiyu Liu",
        "Runyu Chen",
        "Wei Xu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-17 13:24:56+00:00",
      "link": "https://arxiv.org/pdf/2602.15564v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15554v1",
      "title": "Efficient Road Renovation Scheduling under Uncertainty using Lower Bound Pruning",
      "abstract": "Urban infrastructure degrades over time, necessitating periodic renovation to maintain functionality and safety. When renovation is delayed beyond the infrastructure's remaining lifespan, costly emergency interventions become necessary to prevent failure. Decision makers must therefore balance expected emergency intervention costs against traffic congestion impacts. We formalize this trade-off as a road network maintenance scheduling problem with uncertain deadlines, which presents optimization challenges including computationally expensive evaluation and an exponentially growing solution space. To address these challenges, this paper contributes a hybrid optimization approach combining machine learning with genetic algorithms for large-scale infrastructure renovation scheduling under uncertainty. We formulate the problem as a bi-level multi-objective optimization problem that explicitly accounts for uncertain infrastructure lifespans through probabilistic failure models. We develop a progressive lower bound evaluation method that integrates machine learning surrogate models with a multi-objective genetic algorithm to improve solution quality by enabling more iterations within fixed computational budgets. We demonstrate the method's effectiveness on substantially larger problem instances (76 projects) than previously addressed in the literature, achieving statistically significant improvements across multiple performance metrics by increasing computational efficiency up to 40 times compared to standard approaches.",
      "authors": [
        "Robbert Bosch",
        "Patricia Rogetzer",
        "Wouter van Heeswijk",
        "Martijn Mes"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-02-17 13:01:59+00:00",
      "link": "https://arxiv.org/pdf/2602.15554v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15552v1",
      "title": "Latent Regularization in Generative Test Input Generation",
      "abstract": "This study investigates the impact of regularization of latent spaces through truncation on the quality of generated test inputs for deep learning classifiers. We evaluate this effect using style-based GANs, a state-of-the-art generative approach, and assess quality along three dimensions: validity, diversity, and fault detection. We evaluate our approach on the boundary testing of deep learning image classifiers across three datasets, MNIST, Fashion MNIST, and CIFAR-10. We compare two truncation strategies: latent code mixing with binary search optimization and random latent truncation for generative exploration. Our experiments show that the latent code-mixing approach yields a higher fault detection rate than random truncation, while also improving both diversity and validity.",
      "authors": [
        "Giorgi Merabishvili",
        "Oliver Weißl",
        "Andrea Stocco"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.LG"
      ],
      "published": "2026-02-17 12:57:17+00:00",
      "link": "https://arxiv.org/pdf/2602.15552v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15547v1",
      "title": "jina-embeddings-v5-text: Task-Targeted Embedding Distillation",
      "abstract": "Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.",
      "authors": [
        "Mohammad Kalim Akram",
        "Saba Sturua",
        "Nastia Havriushenko",
        "Quentin Herreros",
        "Michael Günther",
        "Maximilian Werk",
        "Han Xiao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-17 12:50:50+00:00",
      "link": "https://arxiv.org/pdf/2602.15547v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15539v1",
      "title": "Dynamic Training-Free Fusion of Subject and Style LoRAs",
      "abstract": "Recent studies have explored the combination of multiple LoRAs to simultaneously generate user-specified subjects and styles. However, most existing approaches fuse LoRA weights using static statistical heuristics that deviate from LoRA's original purpose of learning adaptive feature adjustments and ignore the randomness of sampled inputs. To address this, we propose a dynamic training-free fusion framework that operates throughout the generation process. During the forward pass, at each LoRA-applied layer, we dynamically compute the KL divergence between the base model's original features and those produced by subject and style LoRAs, respectively, and adaptively select the most appropriate weights for fusion. In the reverse denoising stage, we further refine the generation trajectory by dynamically applying gradient-based corrections derived from objective metrics such as CLIP and DINO scores, providing continuous semantic and stylistic guidance. By integrating these two complementary mechanisms-feature-level selection and metric-guided latent adjustment-across the entire diffusion timeline, our method dynamically achieves coherent subject-style synthesis without any retraining. Extensive experiments across diverse subject-style combinations demonstrate that our approach consistently outperforms state-of-the-art LoRA fusion methods both qualitatively and quantitatively.",
      "authors": [
        "Qinglong Cao",
        "Yuntian Chen",
        "Chao Ma",
        "Xiaokang Yang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SC"
      ],
      "published": "2026-02-17 12:42:30+00:00",
      "link": "https://arxiv.org/pdf/2602.15539v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15533v1",
      "title": "Efficient Knowledge Transfer for Jump-Starting Control Policy Learning of Multirotors through Physics-Aware Neural Architectures",
      "abstract": "Efficiently training control policies for robots is a major challenge that can greatly benefit from utilizing knowledge gained from training similar systems through cross-embodiment knowledge transfer. In this work, we focus on accelerating policy training using a library-based initialization scheme that enables effective knowledge transfer across multirotor configurations. By leveraging a physics-aware neural control architecture that combines a reinforcement learning-based controller and a supervised control allocation network, we enable the reuse of previously trained policies. To this end, we utilize a policy evaluation-based similarity measure that identifies suitable policies for initialization from a library. We demonstrate that this measure correlates with the reduction in environment interactions needed to reach target performance and is therefore suited for initialization. Extensive simulation and real-world experiments confirm that our control architecture achieves state-of-the-art control performance, and that our initialization scheme saves on average up to $73.5\\%$ of environment interactions (compared to training a policy from scratch) across diverse quadrotor and hexarotor designs, paving the way for efficient cross-embodiment transfer in reinforcement learning.",
      "authors": [
        "Welf Rehberg",
        "Mihir Kulkarni",
        "Philipp Weiss",
        "Kostas Alexis"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-17 12:31:53+00:00",
      "link": "https://arxiv.org/pdf/2602.15533v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15519v1",
      "title": "Enroll-on-Wakeup: A First Comparative Study of Target Speech Extraction for Seamless Interaction in Real Noisy Human-Machine Dialogue Scenarios",
      "abstract": "Target speech extraction (TSE) typically relies on pre-recorded high-quality enrollment speech, which disrupts user experience and limits feasibility in spontaneous interaction. In this paper, we propose Enroll-on-Wakeup (EoW), a novel framework where the wake-word segment, captured naturally during human-machine interaction, is automatically utilized as the enrollment reference. This eliminates the need for pre-collected speech to enable a seamless experience. We perform the first systematic study of EoW-TSE, evaluating advanced discriminative and generative models under real diverse acoustic conditions. Given the short and noisy nature of wake-word segments, we investigate enrollment augmentation using LLM-based TTS. Results show that while current TSE models face performance degradation in EoW-TSE, TTS-based assistance significantly enhances the listening experience, though gaps remain in speech recognition accuracy.",
      "authors": [
        "Yiming Yang",
        "Guangyong Wang",
        "Haixin Guan",
        "Yanhua Long"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.SD"
      ],
      "published": "2026-02-17 11:47:56+00:00",
      "link": "https://arxiv.org/pdf/2602.15519v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15499v1",
      "title": "ExLipBaB: Exact Lipschitz Constant Computation for Piecewise Linear Neural Networks",
      "abstract": "It has been shown that a neural network's Lipschitz constant can be leveraged to derive robustness guarantees, to improve generalizability via regularization or even to construct invertible networks. Therefore, a number of methods varying in the tightness of their bounds and their computational cost have been developed to approximate the Lipschitz constant for different classes of networks. However, comparatively little research exists on methods for exact computation, which has been shown to be NP-hard. Nonetheless, there are applications where one might readily accept the computational cost of an exact method. These applications could include the benchmarking of new methods or the computation of robustness guarantees for small models on sensitive data. Unfortunately, existing exact algorithms restrict themselves to only ReLU-activated networks, which are known to come with severe downsides in the context of Lipschitz-constrained networks. We therefore propose a generalization of the LipBaB algorithm to compute exact Lipschitz constants for arbitrary piecewise linear neural networks and $p$-norms. With our method, networks may contain traditional activations like ReLU or LeakyReLU, activations like GroupSort or the related MinMax and FullSort, which have been of increasing interest in the context of Lipschitz constrained networks, or even other piecewise linear functions like MaxPool.",
      "authors": [
        "Tom A. Splittgerber"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-17 11:09:41+00:00",
      "link": "https://arxiv.org/pdf/2602.15499v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15493v1",
      "title": "LEADER: Lightweight End-to-End Attention-Gated Dual Autoencoder for Robust Minutiae Extraction",
      "abstract": "Minutiae extraction, a fundamental stage in fingerprint recognition, is increasingly shifting toward deep learning. However, truly end-to-end methods that eliminate separate preprocessing and postprocessing steps remain scarce. This paper introduces LEADER (Lightweight End-to-end Attention-gated Dual autoencodER), a neural network that maps raw fingerprint images to minutiae descriptors, including location, direction, and type. The proposed architecture integrates non-maximum suppression and angular decoding to enable complete end-to-end inference using only 0.9M parameters. It employs a novel \"Castle-Moat-Rampart\" ground-truth encoding and a dual-autoencoder structure, interconnected through an attention-gating mechanism. Experimental evaluations demonstrate state-of-the-art accuracy on plain fingerprints and robust cross-domain generalization to latent impressions. Specifically, LEADER attains a 34% higher F1-score on the NIST SD27 dataset compared to specialized latent minutiae extractors. Sample-level analysis on this challenging benchmark reveals an average rank of 2.07 among all compared methods, with LEADER securing the first-place position in 47% of the samples-more than doubling the frequency of the second-best extractor. The internal representations learned by the model align with established fingerprint domain features, such as segmentation masks, orientation fields, frequency maps, and skeletons. Inference requires 15ms on GPU and 322ms on CPU, outperforming leading commercial software in computational efficiency. The source code and pre-trained weights are publicly released to facilitate reproducibility.",
      "authors": [
        "Raffaele Cappelli",
        "Matteo Ferrara"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-17 11:02:28+00:00",
      "link": "https://arxiv.org/pdf/2602.15493v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15490v1",
      "title": "RPT-SR: Regional Prior attention Transformer for infrared image Super-Resolution",
      "abstract": "General-purpose super-resolution models, particularly Vision Transformers, have achieved remarkable success but exhibit fundamental inefficiencies in common infrared imaging scenarios like surveillance and autonomous driving, which operate from fixed or nearly-static viewpoints. These models fail to exploit the strong, persistent spatial priors inherent in such scenes, leading to redundant learning and suboptimal performance. To address this, we propose the Regional Prior attention Transformer for infrared image Super-Resolution (RPT-SR), a novel architecture that explicitly encodes scene layout information into the attention mechanism. Our core contribution is a dual-token framework that fuses (1) learnable, regional prior tokens, which act as a persistent memory for the scene's global structure, with (2) local tokens that capture the frame-specific content of the current input. By utilizing these tokens into an attention, our model allows the priors to dynamically modulate the local reconstruction process. Extensive experiments validate our approach. While most prior works focus on a single infrared band, we demonstrate the broad applicability and versatility of RPT-SR by establishing new state-of-the-art performance across diverse datasets covering both Long-Wave (LWIR) and Short-Wave (SWIR) spectra",
      "authors": [
        "Youngwan Jin",
        "Incheol Park",
        "Yagiz Nalcakan",
        "Hyeongjin Ju",
        "Sanghyeop Yeo",
        "Shiho Kim"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-17 10:56:49+00:00",
      "link": "https://arxiv.org/pdf/2602.15490v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15484v1",
      "title": "Bottleneck Transformer-Based Approach for Improved Automatic STOI Score Prediction",
      "abstract": "In this study, we have presented a novel approach to predict the Short-Time Objective Intelligibility (STOI) metric using a bottleneck transformer architecture. Traditional methods for calculating STOI typically requires clean reference speech, which limits their applicability in the real world. To address this, numerous deep learning-based nonintrusive speech assessment models have garnered significant interest. Many studies have achieved commendable performance, but there is room for further improvement.   We propose the use of bottleneck transformer, incorporating convolution blocks for learning frame-level features and a multi-head self-attention (MHSA) layer to aggregate the information. These components enable the transformer to focus on the key aspects of the input data. Our model has shown higher correlation and lower mean squared error for both seen and unseen scenarios compared to the state-of-the-art model using self-supervised learning (SSL) and spectral features as inputs.",
      "authors": [
        "Amartyaveer",
        "Murali Kadambi",
        "Chandra Mohan Sharma",
        "Anupam Mondal",
        "Prasanta Kumar Ghosh"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.LG",
        "eess.SP"
      ],
      "published": "2026-02-17 10:46:54+00:00",
      "link": "https://arxiv.org/pdf/2602.15484v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15477v1",
      "title": "Quantum Computing for Healthcare Digital Twin Systems",
      "abstract": "The growing complexity of healthcare systems requires advanced computational models for real-time monitoring, secure data exchange, and intelligent decision-making. Digital Twins (DTs) provide virtual representations of physical healthcare entities, enabling continuous patient monitoring and personalized care. However, classical DT frameworks face limitations in scalability, computational efficiency, and security. Recent studies have introduced Quantum Digital Twins (QDTs) to enhance performance through quantum computing, addressing challenges such as quantum-resistant security and efficient task offloading in healthcare environments. Despite these advances, most existing QDT models remain constrained by fundamental challenges related to quantum hardware limitations, hybrid classical-quantum system integration, cloud-based quantum access, scalability, and clinical trust. This paper provides a comprehensive review of QDTs for healthcare, with a particular focus on identifying and analyzing the key challenges that currently hinder their real-world adoption. Furthermore, it outlines critical research directions and enabling strategies aimed at advancing the development of secure, reliable, and clinically viable quantum digital twin systems for next-generation healthcare applications.",
      "authors": [
        "Asma Taheri Monfared",
        "Andrea Bombarda",
        "Angelo Gargantini",
        "Majid Haghparast"
      ],
      "primary_category": "cs.ET",
      "categories": [
        "cs.ET"
      ],
      "published": "2026-02-17 10:32:44+00:00",
      "link": "https://arxiv.org/pdf/2602.15477v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15472v1",
      "title": "Fluids You Can Trust: Property-Preserving Operator Learning for Incompressible Flows",
      "abstract": "We present a novel property-preserving kernel-based operator learning method for incompressible flows governed by the incompressible Navier-Stokes equations. Traditional numerical solvers incur significant computational costs to respect incompressibility. Operator learning offers efficient surrogate models, but current neural operators fail to exactly enforce physical properties such as incompressibility, periodicity, and turbulence. Our method maps input functions to expansion coefficients of output functions in a property-preserving kernel basis, ensuring that predicted velocity fields analytically and simultaneously preserve the aforementioned physical properties. We evaluate the method on challenging 2D and 3D, laminar and turbulent, incompressible flow problems. Our method achieves up to six orders of magnitude lower relative $\\ell_2$ errors upon generalization and trains up to five orders of magnitude faster compared to neural operators. Moreover, while our method enforces incompressibility analytically, neural operators exhibit very large deviations. Our results show that our method provides an accurate and efficient surrogate for incompressible flows.",
      "authors": [
        "Ramansh Sharma",
        "Matthew Lowery",
        "Houman Owhadi",
        "Varun Shankar"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "cs.LG"
      ],
      "published": "2026-02-17 10:20:46+00:00",
      "link": "https://arxiv.org/pdf/2602.15472v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15458v1",
      "title": "A Universal Neural Receiver that Learns at the Speed of Wireless",
      "abstract": "Today we design wireless networks using mathematical models that govern communication in different propagation environments. We rely on measurement campaigns to deliver parametrized propagation models, and on the 3GPP standards process to optimize model-based performance, but as wireless networks become more complex this model-based approach is losing ground. Mobile Network Operators (MNOs) are counting on Artificial Intelligence (AI) to transform wireless by increasing spectral efficiency, reducing signaling overhead, and enabling continuous network innovation through software upgrades. They may also be interested in new use cases like integrated sensing and communications (ISAC). All we need is an AI-native physical layer, so why not simply tailor the offline AI algorithms that have revolutionized image and natural language processing to the wireless domain? We argue that these algorithms rely on off-line training that is precluded by the sub-millisecond speeds at which the wireless interference environment changes. We present an alternative architecture, a universal neural receiver based on convolution, which governs transmit and receive signal processing of any signal in any part of the wireless spectrum. Our neural receiver is designed to invert convolution, and we separate the question of which convolution to invert from the actual deconvolution. The neural network that performs deconvolution is very simple, and we configure this network by setting weights based on domain knowledge. By telling our neural network what we know, we avoid extensive offline training. By developing a universal receiver, we hope to simplify discussions about the proper choice of waveform for different use cases in the international standards. Since the receiver architecture is largely independent of technologies introduced at the base station, we hope to increase the rate of innovation in wireless.",
      "authors": [
        "Lingjia Liu",
        "Lizhong Zheng",
        "Yang Yi",
        "Robert Calderbank"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "eess.SP"
      ],
      "published": "2026-02-17 09:48:15+00:00",
      "link": "https://arxiv.org/pdf/2602.15458v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15451v1",
      "title": "Molecular Design beyond Training Data with Novel Extended Objective Functionals of Generative AI Models Driven by Quantum Annealing Computer",
      "abstract": "Deep generative modeling to stochastically design small molecules is an emerging technology for accelerating drug discovery and development. However, one major issue in molecular generative models is their lower frequency of drug-like compounds. To resolve this problem, we developed a novel framework for optimization of deep generative models integrated with a D-Wave quantum annealing computer, where our Neural Hash Function (NHF) presented herein is used both as the regularization and binarization schemes simultaneously, of which the latter is for transformation between continuous and discrete signals of the classical and quantum neural networks, respectively, in the error evaluation (i.e., objective) function. The compounds generated via the quantum-annealing generative models exhibited higher quality in both validity and drug-likeness than those generated via the fully-classical models, and was further indicated to exceed even the training data in terms of drug-likeness features, without any restraints and conditions to deliberately induce such an optimization. These results indicated an advantage of quantum annealing to aim at a stochastic generator integrated with our novel neural network architectures, for the extended performance of feature space sampling and extraction of characteristic features in drug design.",
      "authors": [
        "Hayato Kunugi",
        "Mohsen Rahmani",
        "Yosuke Iyama",
        "Yutaro Hirono",
        "Akira Suma",
        "Matthew Woolway",
        "Vladimir Vargas-Calderón",
        "William Kim",
        "Kevin Chern",
        "Mohammad Amin",
        "Masaru Tateno"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "quant-ph"
      ],
      "published": "2026-02-17 09:38:11+00:00",
      "link": "https://arxiv.org/pdf/2602.15451v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15449v1",
      "title": "TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models",
      "abstract": "Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.",
      "authors": [
        "Chansung Park",
        "Juyong Jiang",
        "Fan Wang",
        "Sayak Paul",
        "Jiasi Shen",
        "Jing Tang",
        "Jianguo Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "published": "2026-02-17 09:29:18+00:00",
      "link": "https://arxiv.org/pdf/2602.15449v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15424v1",
      "title": "Lyapunov-Based $\\mathcal{L}_2$-Stable PI-Like Control of a Four-Wheel Independently Driven and Steered Robot",
      "abstract": "In this letter, Lyapunov-based synthesis of a PI-like controller is proposed for $\\mathcal{L}_2$-stable motion control of an independently driven and steered four-wheel mobile robot. An explicit, structurally verified model is used to enable systematic controller design with stability and performance guarantees suitable for real-time operation. A Lyapunov function is constructed to yield explicit bounds and $\\mathcal{L}_2$ stability results, supporting feedback synthesis that reduces configuration dependent effects. The resulting control law maintains a PI-like form suitable for standard embedded implementation while preserving rigorous stability properties. Effectiveness and robustness are demonstrated experimentally on a real four-wheel mobile robot platform.",
      "authors": [
        "Branimir Ćaran",
        "Vladimir Milić",
        "Bojan Jerbić"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-17 08:36:13+00:00",
      "link": "https://arxiv.org/pdf/2602.15424v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15423v1",
      "title": "GaiaFlow: Semantic-Guided Diffusion Tuning for Carbon-Frugal Search",
      "abstract": "As the burgeoning power requirements of sophisticated neural architectures escalate, the information retrieval community has recognized ecological sustainability as a pivotal priority that necessitates a fundamental paradigm shift in model design. While contemporary neural rankers have attained unprecedented accuracy, the substantial environmental externalities associated with their computational intensity often remain overlooked in large-scale deployments. We present GaiaFlow, an innovative framework engineered to facilitate carbon-frugal search by operationalizing semantic-guided diffusion tuning. Our methodology orchestrates the convergence of retrieval-guided Langevin dynamics and a hardware-independent performance modeling strategy to optimize the trade-off between search precision and environmental preservation. By incorporating adaptive early exit protocols and precision-aware quantized inference, the proposed architecture significantly mitigates operational carbon footprints while maintaining robust retrieval quality across heterogeneous computing infrastructures. Extensive experimental evaluations demonstrate that GaiaFlow achieves a superior equilibrium between effectiveness and energy efficiency, offering a scalable and sustainable pathway for next-generation neural search systems.",
      "authors": [
        "Rong Fu",
        "Wenxin Zhang",
        "Jia Yee Tan",
        "Chunlei Meng",
        "Shuo Yin",
        "Xiaowen Ma",
        "Wangyu Wu",
        "Muge Qi",
        "Guangzhen Yao",
        "Zhaolu Kang",
        "Zeli Su",
        "Simon Fong"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "published": "2026-02-17 08:35:11+00:00",
      "link": "https://arxiv.org/pdf/2602.15423v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15400v1",
      "title": "One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation",
      "abstract": "A navigable agent needs to understand both high-level semantic instructions and precise spatial perceptions. Building navigation agents centered on Multimodal Large Language Models (MLLMs) demonstrates a promising solution due to their powerful generalization ability. However, the current tightly coupled design dramatically limits system performance. In this work, we propose a decoupled design that separates low-level spatial state estimation from high-level semantic planning. Unlike previous methods that rely on predefined, oversimplified textual maps, we introduce an interactive metric world representation that maintains rich and consistent information, allowing MLLMs to interact with and reason on it for decision-making. Furthermore, counterfactual reasoning is introduced to further elicit MLLMs' capacity, while the metric world representation ensures the physical validity of the produced actions. We conduct comprehensive experiments in both simulated and real-world environments. Our method establishes a new zero-shot state-of-the-art, achieving 48.8\\% Success Rate (SR) in R2R-CE and 42.2\\% in RxR-CE benchmarks. Furthermore, to validate the versatility of our metric representation, we demonstrate zero-shot sim-to-real transfer across diverse embodiments, including a wheeled TurtleBot 4 and a custom-built aerial drone. These real-world deployments verify that our decoupled framework serves as a robust, domain-invariant interface for embodied Vision-and-Language navigation.",
      "authors": [
        "Zerui Li",
        "Hongpei Zheng",
        "Fangguo Zhao",
        "Aidan Chan",
        "Jian Zhou",
        "Sihao Lin",
        "Shijie Li",
        "Qi Wu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-17 07:13:48+00:00",
      "link": "https://arxiv.org/pdf/2602.15400v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15376v1",
      "title": "A Unified Evaluation of Learning-Based Similarity Techniques for Malware Detection",
      "abstract": "Cryptographic digests (e.g., MD5, SHA-256) are designed to provide exact identity. Any single-bit change in the input produces a completely different hash, which is ideal for integrity verification but limits their usefulness in many real-world tasks like threat hunting, malware analysis and digital forensics, where adversaries routinely introduce minor transformations. Similarity-based techniques address this limitation by enabling approximate matching, allowing related byte sequences to produce measurably similar fingerprints. Modern enterprises manage tens of thousands of endpoints with billions of files, making the effectiveness and scalability of the proposed techniques more important than ever in security applications. Security researchers have proposed a range of approaches, including similarity digests and locality-sensitive hashes (e.g., ssdeep, sdhash, TLSH), as well as more recent machine-learning-based methods that generate embeddings from file features. However, these techniques have largely been evaluated in isolation, using disparate datasets and evaluation criteria. This paper presents a systematic comparison of learning-based classification and similarity methods using large, publicly available datasets. We evaluate each method under a unified experimental framework with industry-accepted metrics. To our knowledge, this is the first reproducible study to benchmark these diverse learning-based similarity techniques side by side for real-world security workloads. Our results show that no single approach performs well across all dimensions; instead, each exhibits distinct trade-offs, indicating that effective malware analysis and threat-hunting platforms must combine complementary classification and similarity techniques rather than rely on a single method.",
      "authors": [
        "Udbhav Prasad",
        "Aniesh Chawla"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "published": "2026-02-17 06:16:23+00:00",
      "link": "https://arxiv.org/pdf/2602.15376v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15367v1",
      "title": "CDRL: A Reinforcement Learning Framework Inspired by Cerebellar Circuits and Dendritic Computational Strategies",
      "abstract": "Reinforcement learning (RL) has achieved notable performance in high-dimensional sequential decision-making tasks, yet remains limited by low sample efficiency, sensitivity to noise, and weak generalization under partial observability. Most existing approaches address these issues primarily through optimization strategies, while the role of architectural priors in shaping representation learning and decision dynamics is less explored. Inspired by structural principles of the cerebellum, we propose a biologically grounded RL architecture that incorporate large expansion, sparse connectivity, sparse activation, and dendritic-level modulation. Experiments on noisy, high-dimensional RL benchmarks show that both the cerebellar architecture and dendritic modulation consistently improve sample efficiency, robustness, and generalization compared to conventional designs. Sensitivity analysis of architectural parameters suggests that cerebellum-inspired structures can offer optimized performance for RL with constrained model parameters. Overall, our work underscores the value of cerebellar structural priors as effective inductive biases for RL.",
      "authors": [
        "Sibo Zhang",
        "Rui Jing",
        "Liangfu Lv",
        "Jian Zhang",
        "Yunliang Zang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "published": "2026-02-17 05:25:09+00:00",
      "link": "https://arxiv.org/pdf/2602.15367v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15917v1",
      "title": "ROIX-Comp: Optimizing X-ray Computed Tomography Imaging Strategy for Data Reduction and Reconstruction",
      "abstract": "In high-performance computing (HPC) environments, particularly in synchrotron radiation facilities, vast amounts of X-ray images are generated. Processing large-scale X-ray Computed Tomography (X-CT) datasets presents significant computational and storage challenges due to their high dimensionality and data volume. Traditional approaches often require extensive storage capacity and high transmission bandwidth, limiting real-time processing capabilities and workflow efficiency. To address these constraints, we introduce a region-of-interest (ROI)-driven extraction framework (ROIX-Comp) that intelligently compresses X-CT data by identifying and retaining only essential features. Our work reduces data volume while preserving critical information for downstream processing tasks. At pre-processing stage, we utilize error-bounded quantization to reduce the amount of data to be processed and therefore improve computational efficiencies. At the compression stage, our methodology combines object extraction with multiple state-of-the-art lossless and lossy compressors, resulting in significantly improved compression ratios. We evaluated this framework against seven X-CT datasets and observed a relative compression ratio improvement of 12.34x compared to the standard compression.",
      "authors": [
        "Amarjit Singh",
        "Kento Sato",
        "Kohei Yoshida",
        "Kentaro Uesugi",
        "Yasumasa Joti",
        "Takaki Hatsui",
        "Andrès Rubio Proaño"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.DC",
        "cs.IT"
      ],
      "published": "2026-02-17 05:12:54+00:00",
      "link": "https://arxiv.org/pdf/2602.15917v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15360v1",
      "title": "Crane: An Accurate and Scalable Neural Sketch for Graph Stream Summarization",
      "abstract": "Graph streams are rapidly evolving sequences of edges that convey continuously changing relationships among entities, playing a crucial role in domains such as networking, finance, and cybersecurity. Their massive scale and high dynamism make obtaining accurate statistics challenging with limited memory constraints. Traditional methods summarize graph streams through hand-crafted sketches, while recent studies have begun to replace these sketches with neural counterparts to improve adaptability and accuracy. However, this shift faces a major challenge: under limited memory, dominant frequent items tend to overshadow rare ones, hindering the neural network's ability to recover accurate statistics. To address this, we propose Crane, a hierarchical neural sketch architecture for graph stream summarization. Crane uses a hierarchical carry mechanism that automatically elevates frequent items to higher memory layers, reducing interference between frequent and infrequent items within the same layer. To better accommodate real-world deployment, Crane further adopts an adaptive memory expansion strategy that dynamically adds new layers once the occupancy of the top layer exceeds a threshold, enabling scalability across diverse data magnitudes. Extensive experiments on various datasets ranging from 20K to 60M edges demonstrate that Crane reduces estimation error by roughly 10x compared to state-of-the-art methods.",
      "authors": [
        "Boyan Wang",
        "Zhuochen Fan",
        "Dayu Wang",
        "Fangcheng Fu",
        "Zeyu Luan",
        "Lei Zou",
        "Qing Li",
        "Tong Yang"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-02-17 04:59:10+00:00",
      "link": "https://arxiv.org/pdf/2602.15360v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15354v1",
      "title": "A Comparison of Bayesian Prediction Techniques for Mobile Robot Trajectory Tracking",
      "abstract": "This paper presents a performance comparison of different estimation and prediction techniques applied to the problem of tracking multiple robots. The main performance criteria are the magnitude of the estimation or prediction error, the computational effort and the robustness of each method to non-Gaussian noise. Among the different techniques compared are the well known Kalman filters and their different variants (e.g. extended and unscented), and the more recent techniques relying on Sequential Monte Carlo Sampling methods, such as particle filters and Gaussian Mixture Sigma Point Particle Filter.",
      "authors": [
        "Jose Luis Peralta-Cabezas",
        "Miguel Torres-Torriti",
        "Marcelo Guarini-Hermann"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "eess.SY"
      ],
      "published": "2026-02-17 04:47:31+00:00",
      "link": "https://arxiv.org/pdf/2602.15354v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15353v1",
      "title": "NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering",
      "abstract": "Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.",
      "authors": [
        "Rong Fu",
        "Yang Li",
        "Zeyu Zhang",
        "Jiekai Wu",
        "Yaohua Liu",
        "Shuaishuai Cao",
        "Yangchen Zeng",
        "Yuhang Zhang",
        "Xiaojing Du",
        "Chuang Zhao",
        "Kangning Cui",
        "Simon Fong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-17 04:47:29+00:00",
      "link": "https://arxiv.org/pdf/2602.15353v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15337v1",
      "title": "FedPSA: Modeling Behavioral Staleness in Asynchronous Federated Learning",
      "abstract": "Asynchronous Federated Learning (AFL) has emerged as a significant research area in recent years. By not waiting for slower clients and executing the training process concurrently, it achieves faster training speed compared to traditional federated learning. However, due to the staleness introduced by the asynchronous process, its performance may degrade in some scenarios. Existing methods often use the round difference between the current model and the global model as the sole measure of staleness, which is coarse-grained and lacks observation of the model itself, thereby limiting the performance ceiling of asynchronous methods. In this paper, we propose FedPSA (Parameter Sensitivity-based Asynchronous Federated Learning), a more fine-grained AFL framework that leverages parameter sensitivity to measure model obsolescence and establishes a dynamic momentum queue to assess the current training phase in real time, thereby adjusting the tolerance for outdated information dynamically. Extensive experiments on multiple datasets and comparisons with various methods demonstrate the superior performance of FedPSA, achieving up to 6.37\\% improvement over baseline methods and 1.93\\% over the current state-of-the-art method.",
      "authors": [
        "Chaoyi Lu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-17 03:57:07+00:00",
      "link": "https://arxiv.org/pdf/2602.15337v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15335v1",
      "title": "Corrected-Inverse-Gaussian First-Hitting-Time Modeling for Molecular Communication Under Time-Varying Drift",
      "abstract": "This paper develops a tractable analytical channel model for first-hitting-time molecular communication systems under time-varying drift. While existing studies of nonstationary transport rely primarily on numerical solutions of advection--diffusion equations or parametric impulse-response fitting, they do not provide a closed-form description of trajectory-level arrival dynamics at absorbing boundaries. By adopting a change-of-measure formulation, we reveal a structural decomposition of the first-hitting-time density into a cumulative-drift displacement term and a stochastic boundary-flux modulation factor. This leads to an explicit analytical expression for the Corrected-Inverse-Gaussian (C-IG) density, extending the classical IG model to strongly nonstationary drift conditions while preserving constant-complexity evaluation. High-precision Monte Carlo simulations under both smooth pulsatile and abrupt switching drift profiles confirm that the proposed model accurately captures complex transport phenomena, including phase modulation, multi-pulse dispersion, and transient backflow. The resulting framework provides a physics-informed, computationally efficient channel model suitable for system-level analysis and receiver design in dynamic biological and molecular communication environments.",
      "authors": [
        "Yen-Chi Lee"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "eess.SP"
      ],
      "published": "2026-02-17 03:47:40+00:00",
      "link": "https://arxiv.org/pdf/2602.15335v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15322v1",
      "title": "On Surprising Effectiveness of Masking Updates in Adaptive Optimizers",
      "abstract": "Training large language models (LLMs) relies almost exclusively on dense adaptive optimizers with increasingly sophisticated preconditioners. We challenge this by showing that randomly masking parameter updates can be highly effective, with a masked variant of RMSProp consistently outperforming recent state-of-the-art optimizers. Our analysis reveals that the random masking induces a curvature-dependent geometric regularization that smooths the optimization trajectory. Motivated by this finding, we introduce Momentum-aligned gradient masking (Magma), which modulates the masked updates using momentum-gradient alignment. Extensive LLM pre-training experiments show that Magma is a simple drop-in replacement for adaptive optimizers with consistent gains and negligible computational overhead. Notably, for the 1B model size, Magma reduces perplexity by over 19\\% and 9\\% compared to Adam and Muon, respectively.",
      "authors": [
        "Taejong Joo",
        "Wenhan Xia",
        "Cheolmin Kim",
        "Ming Zhang",
        "Eugene Ie"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-17 02:57:12+00:00",
      "link": "https://arxiv.org/pdf/2602.15322v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15313v1",
      "title": "Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory",
      "abstract": "AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.",
      "authors": [
        "Zihao Tang",
        "Xin Yu",
        "Ziyu Xiao",
        "Zengxuan Wen",
        "Zelin Li",
        "Jiaxi Zhou",
        "Hualei Wang",
        "Haohua Wang",
        "Haizhen Huang",
        "Weiwei Deng",
        "Feng Sun",
        "Qi Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-17 02:44:03+00:00",
      "link": "https://arxiv.org/pdf/2602.15313v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15312v1",
      "title": "Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement",
      "abstract": "Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.",
      "authors": [
        "Stephan Ludwig",
        "Peter J. Danaher",
        "Xiaohao Yang",
        "Yu-Ting Lin",
        "Ehsan Abedin",
        "Dhruv Grewal",
        "Lan Du"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "econ.EM"
      ],
      "published": "2026-02-17 02:33:51+00:00",
      "link": "https://arxiv.org/pdf/2602.15312v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15306v1",
      "title": "Sparse Additive Model Pruning for Order-Based Causal Structure Learning",
      "abstract": "Causal structure learning, also known as causal discovery, aims to estimate causal relationships between variables as a form of a causal directed acyclic graph (DAG) from observational data. One of the major frameworks is the order-based approach that first estimates a topological order of the underlying DAG and then prunes spurious edges from the fully-connected DAG induced by the estimated topological order. Previous studies often focus on the former ordering step because it can dramatically reduce the search space of DAGs. In practice, the latter pruning step is equally crucial for ensuring both computational efficiency and estimation accuracy. Most existing methods employ a pruning technique based on generalized additive models and hypothesis testing, commonly known as CAM-pruning. However, this approach can be a computational bottleneck as it requires repeatedly fitting additive models for all variables. Furthermore, it may harm estimation quality due to multiple testing. To address these issues, we introduce a new pruning method based on sparse additive models, which enables direct pruning of redundant edges without relying on hypothesis testing. We propose an efficient algorithm for learning sparse additive models by combining the randomized tree embedding technique with group-wise sparse regression. Experimental results on both synthetic and real datasets demonstrated that our method is significantly faster than existing pruning methods while maintaining comparable or superior accuracy.",
      "authors": [
        "Kentaro Kanamori",
        "Hirofumi Suzuki",
        "Takuya Takagi"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-17 02:06:42+00:00",
      "link": "https://arxiv.org/pdf/2602.15306v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15287v1",
      "title": "Consistency-Preserving Diverse Video Generation",
      "abstract": "Text-to-video generation is expensive, so only a few samples are typically produced per prompt. In this low-sample regime, maximizing the value of each batch requires high cross-video diversity. Recent methods improve diversity for image generation, but for videos they often degrade within-video temporal consistency and require costly backpropagation through a video decoder. We propose a joint-sampling framework for flow-matching video generators that improves batch diversity while preserving temporal consistency. Our approach applies diversity-driven updates and then removes only the components that would decrease a temporal-consistency objective. To avoid image-space gradients, we compute both objectives with lightweight latent-space models, avoiding video decoding and decoder backpropagation. Experiments on a state-of-the-art text-to-video flow-matching model show diversity comparable to strong joint-sampling baselines while substantially improving temporal consistency and color naturalness. Code will be released.",
      "authors": [
        "Xinshuang Liu",
        "Runfa Blark Li",
        "Truong Nguyen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-17 01:12:20+00:00",
      "link": "https://arxiv.org/pdf/2602.15287v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15277v1",
      "title": "Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization",
      "abstract": "Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large-scale, they continue to face an efficiency gap: optimization-based decoupling methods achieve higher accuracy but demand intensive computation, whereas optimization-free decoupling methods are efficient but sacrifice accuracy. To overcome this trade-off, we propose Exploration-Exploitation Distillation (E^2D), a simple, practical method that minimizes redundant computation through an efficient pipeline that begins with full-image initialization to preserve semantic integrity and feature diversity. It then uses a two-phase optimization strategy: an exploration phase that performs uniform updates and identifies high-loss regions, and an exploitation phase that focuses updates on these regions to accelerate convergence. We evaluate E^2D on large-scale benchmarks, surpassing the state-of-the-art on ImageNet-1K while being 18x faster, and on ImageNet-21K, our method substantially improves accuracy while remaining 4.3x faster. These results demonstrate that targeted, redundancy-reducing updates, rather than brute-force optimization, bridge the gap between accuracy and efficiency in large-scale dataset distillation. Code is available at https://github.com/ncsu-dk-lab.",
      "authors": [
        "Muhammad J. Alahmadi",
        "Peng Gao",
        "Feiyi Wang",
        "Dongkuan",
        "Xu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-17 00:27:58+00:00",
      "link": "https://arxiv.org/pdf/2602.15277v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15258v1",
      "title": "SEG-JPEG: Simple Visual Semantic Communications for Remote Operation of Automated Vehicles over Unreliable Wireless Networks",
      "abstract": "Remote Operation is touted as being key to the rapid deployment of automated vehicles. Streaming imagery to control connected vehicles remotely currently requires a reliable, high throughput network connection, which can be limited in real-world remote operation deployments relying on public network infrastructure. This paper investigates how the application of computer vision assisted semantic communication can be used to circumvent data loss and corruption associated with traditional image compression techniques. By encoding the segmentations of detected road users into colour coded highlights within low resolution greyscale imagery, the required data rate can be reduced by 50 \\% compared with conventional techniques, while maintaining visual clarity. This enables a median glass-to-glass latency of below 200ms even when the network data rate is below 500kbit/s, while clearly outlining salient road users to enhance situational awareness of the remote operator. The approach is demonstrated in an area of variable 4G mobile connectivity using an automated last-mile delivery vehicle. With this technique, the results indicate that large-scale deployment of remotely operated automated vehicles could be possible even on the often constrained public 4G/5G mobile network, providing the potential to expedite the nationwide roll-out of automated vehicles.",
      "authors": [
        "Sebastian Donnelly",
        "Ruth Anderson",
        "George Economides",
        "James Broughton",
        "Peter Ball",
        "Alexander Rast",
        "Andrew Bradley"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-16 23:28:10+00:00",
      "link": "https://arxiv.org/pdf/2602.15258v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15253v1",
      "title": "Scaling Laws for Masked-Reconstruction Transformers on Single-Cell Transcriptomics",
      "abstract": "Neural scaling laws -- power-law relationships between loss, model size, and data -- have been extensively documented for language and vision transformers, yet their existence in single-cell genomics remains largely unexplored. We present the first systematic study of scaling behaviour for masked-reconstruction transformers trained on single-cell RNA sequencing (scRNA-seq) data. Using expression profiles from the CELLxGENE Census, we construct two experimental regimes: a data-rich regime (512 highly variable genes, 200,000 cells) and a data-limited regime (1,024 genes, 10,000 cells). Across seven model sizes spanning three orders of magnitude in parameter count (533 to 3.4 x 10^8 parameters), we fit the parametric scaling law to validation mean squared error (MSE). The data-rich regime exhibits clear power-law scaling with an irreducible loss floor of c ~ 1.44, while the data-limited regime shows negligible scaling, indicating that model capacity is not the binding constraint when data are scarce. These results establish that scaling laws analogous to those observed in natural language processing do emerge in single-cell transcriptomics when sufficient data are available, and they identify the data-to-parameter ratio as a critical determinant of scaling behaviour. A preliminary conversion of the data-rich asymptotic floor to information-theoretic units yields an estimate of approximately 2.30 bits of entropy per masked gene position. We discuss implications for the design of single-cell foundation models and outline the additional measurements needed to refine this entropy estimate.",
      "authors": [
        "Ihor Kendiukhov"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "q-bio.GN"
      ],
      "published": "2026-02-16 23:20:58+00:00",
      "link": "https://arxiv.org/pdf/2602.15253v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15245v1",
      "title": "MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning",
      "abstract": "Reinforcement learning (RL)-based biomechanical simulations have the potential to revolutionise HCI research and interaction design, but currently lack usability and interpretability. Using the Human Action Cycle as a design lens, we identify key limitations of biomechanical RL frameworks and develop MyoInteract, a novel framework for fast prototyping of biomechanical HCI tasks. MyoInteract allows designers to setup tasks, user models, and training parameters from an easy-to-use GUI within minutes. It trains and evaluates muscle-actuated simulated users within minutes, reducing training times by up to 98%. A workshop study with 12 interaction designers revealed that MyoInteract allowed novices in biomechanical RL to successfully setup, train, and assess goal-directed user movements within a single session. By transforming biomechanical RL from a days-long expert task into an accessible hour-long workflow, this work significantly lowers barriers to entry and accelerates iteration cycles in HCI biomechanics research.",
      "authors": [
        "Ankit Bhattarai",
        "Hannah Selder",
        "Florian Fischer",
        "Arthur Fleig",
        "Per Ola Kristensson"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "published": "2026-02-16 22:51:57+00:00",
      "link": "https://arxiv.org/pdf/2602.15245v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15229v1",
      "title": "tensorFM: Low-Rank Approximations of Cross-Order Feature Interactions",
      "abstract": "We address prediction problems on tabular categorical data, where each instance is defined by multiple categorical attributes, each taking values from a finite set. These attributes are often referred to as fields, and their categorical values as features. Such problems frequently arise in practical applications, including click-through rate prediction and social sciences. We introduce and analyze {tensorFM}, a new model that efficiently captures high-order interactions between attributes via a low-rank tensor approximation representing the strength of these interactions. Our model generalizes field-weighted factorization machines. Empirically, tensorFM demonstrates competitive performance with state-of-the-art methods. Additionally, its low latency makes it well-suited for time-sensitive applications, such as online advertising.",
      "authors": [
        "Alessio Mazzetto",
        "Mohammad Mahdi Khalili",
        "Laura Fee Nern",
        "Michael Viderman",
        "Alex Shtoff",
        "Krzysztof Dembczyński"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.IR"
      ],
      "published": "2026-02-16 22:21:48+00:00",
      "link": "https://arxiv.org/pdf/2602.15229v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15228v1",
      "title": "An Empirical Study on the Effects of System Prompts in Instruction-Tuned Models for Code Generation",
      "abstract": "Instruction-tuned Language Models (ILMs) have become essential components of modern AI systems, demonstrating exceptional versatility across natural language and reasoning tasks. Among their most impactful applications is code generation, where ILMs -- commonly referred to as Code Language Models (CLMs) -- translate human intent into executable programs. While progress has been driven by advances in scaling and training methodologies, one critical aspect remains underexplored: the impact of system prompts on both general-purpose ILMs and specialized CLMs for code generation. We systematically evaluate how system prompts of varying instructional detail, along with model scale, prompting strategy, and programming language, affect code assistant. Our experimental setting spans 360 configurations across four models, five system prompts, three prompting strategies, two languages, and two temperature settings. We find that (1) increasing system-prompt constraint specificity does not monotonically improve correctness -- prompt effectiveness is configuration-dependent and can help or hinder based on alignment with task requirements and decoding context; (2) for larger code-specialized models, few-shot examples can degrade performance relative to zero-shot generation, contrary to conventional wisdom; and (3) programming language matters, with Java exhibiting significantly greater sensitivity to system prompt variations than Python, suggesting language-specific prompt engineering strategies may be necessary.",
      "authors": [
        "Zaiyu Cheng",
        "Antonio Mastropaolo"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-16 22:11:21+00:00",
      "link": "https://arxiv.org/pdf/2602.15228v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15212v1",
      "title": "Secure and Energy-Efficient Wireless Agentic AI Networks",
      "abstract": "In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor AI agent can dynamically assign other AI agents to participate in cooperative reasoning, while the unselected AI agents act as friendly jammers to degrade the eavesdropper's interception performance. To extend the service duration of AI agents, an energy minimization problem is formulated that jointly optimizes AI agent selection, base station (BS) beamforming, and AI agent transmission power, subject to latency and reasoning accuracy constraints. To address the formulated problem, we propose two resource allocation schemes, ASC and LAW, which first decompose it into three sub-problems. Specifically, ASC optimizes each sub-problem iteratively using the proposed alternating direction method of multipliers (ADMM)-based algorithm, semi-definite relaxation (SDR), and successive convex approximation (SCA), while LAW tackles each sub-problem using the proposed large language model (LLM) optimizer within an agentic workflow. The experimental results show that the proposed solutions can reduce network energy consumption by up to 59.1% compared to other benchmark schemes. Furthermore, the proposed schemes are validated using a practical agentic AI system based on Qwen, demonstrating satisfactory reasoning accuracy across various public benchmarks.",
      "authors": [
        "Yuanyan Song",
        "Kezhi Wang",
        "Xinmian Xu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-16 21:42:33+00:00",
      "link": "https://arxiv.org/pdf/2602.15212v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15202v1",
      "title": "Tomography by Design: An Algebraic Approach to Low-Rank Quantum States",
      "abstract": "We present an algebraic algorithm for quantum state tomography that leverages measurements of certain observables to estimate structured entries of the underlying density matrix. Under low-rank assumptions, the remaining entries can be obtained solely using standard numerical linear algebra operations. The proposed algebraic matrix completion framework applies to a broad class of generic, low-rank mixed quantum states and, compared with state-of-the-art methods, is computationally efficient while providing deterministic recovery guarantees.",
      "authors": [
        "Shakir Showkat Sofi",
        "Charlotte Vermeylen",
        "Lieven De Lathauwer"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.AI",
        "eess.SP",
        "math.NA",
        "stat.CO"
      ],
      "published": "2026-02-16 21:31:47+00:00",
      "link": "https://arxiv.org/pdf/2602.15202v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15189v1",
      "title": "ScrapeGraphAI-100k: A Large-Scale Dataset for LLM-Based Web Information Extraction",
      "abstract": "The use of large language models for web information extraction is becoming increasingly fundamental to modern web information retrieval pipelines. However, existing datasets tend to be small, synthetic or text-only, failing to capture the structural context of the web. We introduce ScrapeGraphAI-100k, a large-scale dataset comprising real-world LLM extraction events, collected via opt-in ScrapeGraphAI telemetry during Q2 and Q3 of 2025. Starting from 9M events, we deduplicate and balance by schema to produce 93,695 examples spanning diverse domains and languages. Each instance includes Markdown content, a prompt, a JSON schema, the LLM response, and complexity/validation metadata. We characterize the datasets structural diversity and its failure modes as schema complexity increases. We also provide a fine-tuning experiment showing that a small language model (1.7B) trained on a subset narrows the gap to larger baselines (30B), underscoring the datasets utility for efficient extraction. ScrapeGraphAI-100k enables fine-tuning small models, benchmarking structured extraction, and studying schema induction for web IR indexing, and is publicly available on HuggingFace.",
      "authors": [
        "William Brach",
        "Francesco Zuppichini",
        "Marco Vinciguerra",
        "Lorenzo Padoan"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-16 20:56:59+00:00",
      "link": "https://arxiv.org/pdf/2602.15189v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15184v1",
      "title": "Learning Data-Efficient and Generalizable Neural Operators via Fundamental Physics Knowledge",
      "abstract": "Recent advances in scientific machine learning (SciML) have enabled neural operators (NOs) to serve as powerful surrogates for modeling the dynamic evolution of physical systems governed by partial differential equations (PDEs). While existing approaches focus primarily on learning simulations from the target PDE, they often overlook more fundamental physical principles underlying these equations. Inspired by how numerical solvers are compatible with simulations of different settings of PDEs, we propose a multiphysics training framework that jointly learns from both the original PDEs and their simplified basic forms. Our framework enhances data efficiency, reduces predictive errors, and improves out-of-distribution (OOD) generalization, particularly in scenarios involving shifts of physical parameters and synthetic-to-real transfer. Our method is architecture-agnostic and demonstrates consistent improvements in normalized root mean square error (nRMSE) across a wide range of 1D/2D/3D PDE problems. Through extensive experiments, we show that explicit incorporation of fundamental physics knowledge significantly strengthens the generalization ability of neural operators. We will release models and codes at https://sites.google.com/view/sciml-fundemental-pde.",
      "authors": [
        "Siying Ma",
        "Mehrdad M. Zadeh",
        "Mauricio Soroco",
        "Wuyang Chen",
        "Jiguo Cao",
        "Vijay Ganesh"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-16 20:45:10+00:00",
      "link": "https://arxiv.org/pdf/2602.15184v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15183v1",
      "title": "Seeing to Generalize: How Visual Data Corrects Binding Shortcuts",
      "abstract": "Vision Language Models (VLMs) are designed to extend Large Language Models (LLMs) with visual capabilities, yet in this work we observe a surprising phenomenon: VLMs can outperform their underlying LLMs on purely text-only tasks, particularly in long-context information retrieval. To investigate this effect, we build a controlled synthetic retrieval task and find that a transformer trained only on text achieves perfect in-distribution accuracy but fails to generalize out of distribution, while subsequent training on an image-tokenized version of the same task nearly doubles text-only OOD performance. Mechanistic interpretability reveals that visual training changes the model's internal binding strategy: text-only training encourages positional shortcuts, whereas image-based training disrupts them through spatial translation invariance, forcing the model to adopt a more robust symbolic binding mechanism that persists even after text-only examples are reintroduced. We further characterize how binding strategies vary across training regimes, visual encoders, and initializations, and show that analogous shifts occur during pretrained LLM-to-VLM transitions. Our findings suggest that cross-modal training can enhance reasoning and generalization even for tasks grounded in a single modality.",
      "authors": [
        "Nicolas Buzeta",
        "Felipe del Rio",
        "Cristian Hinostroza",
        "Denis Parra",
        "Hans Lobel",
        "Rodrigo Toro Icarte"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-16 20:43:12+00:00",
      "link": "https://arxiv.org/pdf/2602.15183v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15181v1",
      "title": "Time-Archival Camera Virtualization for Sports and Visual Performances",
      "abstract": "Camera virtualization -- an emerging solution to novel view synthesis -- holds transformative potential for visual entertainment, live performances, and sports broadcasting by enabling the generation of photorealistic images from novel viewpoints using images from a limited set of calibrated multiple static physical cameras. Despite recent advances, achieving spatially and temporally coherent and photorealistic rendering of dynamic scenes with efficient time-archival capabilities, particularly in fast-paced sports and stage performances, remains challenging for existing approaches. Recent methods based on 3D Gaussian Splatting (3DGS) for dynamic scenes could offer real-time view-synthesis results. Yet, they are hindered by their dependence on accurate 3D point clouds from the structure-from-motion method and their inability to handle large, non-rigid, rapid motions of different subjects (e.g., flips, jumps, articulations, sudden player-to-player transitions). Moreover, independent motions of multiple subjects can break the Gaussian-tracking assumptions commonly used in 4DGS, ST-GS, and other dynamic splatting variants. This paper advocates reconsidering a neural volume rendering formulation for camera virtualization and efficient time-archival capabilities, making it useful for sports broadcasting and related applications. By modeling a dynamic scene as rigid transformations across multiple synchronized camera views at a given time, our method performs neural representation learning, providing enhanced visual rendering quality at test time. A key contribution of our approach is its support for time-archival, i.e., users can revisit any past temporal instance of a dynamic scene and can perform novel view synthesis, enabling retrospective rendering for replay, analysis, and archival of live events, a functionality absent in existing neural rendering approaches and novel view synthesis...",
      "authors": [
        "Yunxiao Zhang",
        "William Stone",
        "Suryansh Kumar"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-02-16 20:39:51+00:00",
      "link": "https://arxiv.org/pdf/2602.15181v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15172v1",
      "title": "The Turbo-Charged Mapper: Fast and Optimal Mapping for Accelerator Modeling and Evaluation",
      "abstract": "The energy and latency of an accelerator running a deep neural network (DNN) depend on how the computation and data movement are scheduled in the accelerator (i.e., mapping). Optimizing mappings is essential to evaluating and designing accelerators. However, the space of mappings is large, and prior works can not guarantee finding optimal mappings because they use heuristics or metaheuristics to narrow down the space. These limitations preclude proper hardware evaluation, since designers can not tell whether performance differences are due to changes in hardware or suboptimal mapping.   To address this challenge, we propose the Turbo-Charged Mapper (TCM), a fast mapper that is guaranteed to find optimal mappings. The key to our approach is that we define a new concept in mapping, called dataplacement, which, like the prior concept of dataflow, allows for clear analysis and comparison of mappings. Through it, we identify multiple opportunities to prune redundant and suboptimal mappings, reducing search space by up to 32 orders of magnitude.   Leveraging these insights, TCM can perform full mapspace searches, making it the first mapper that can find optimal mappings in feasible runtime. Compared to prior mappers, we show that TCM can find optimal mappings quickly (less than a minute), while prior works can not find optimal mappings (energy-delay-product $21\\%$ higher than optimal) even when given $1000\\times$ the runtime ($>10$ hours).",
      "authors": [
        "Michael Gilbert",
        "Tanner Andrulis",
        "Vivienne Sze",
        "Joel S. Emer"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR"
      ],
      "published": "2026-02-16 20:21:40+00:00",
      "link": "https://arxiv.org/pdf/2602.15172v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15169v1",
      "title": "Learning the S-matrix from data: Rediscovering gravity from gauge theory via symbolic regression",
      "abstract": "We demonstrate that modern machine-learning methods can autonomously reconstruct several flagship analytic structures in scattering amplitudes directly from numerical on-shell data. In particular, we show that the Kawai--Lewellen--Tye (KLT) relations can be rediscovered using symbolic regression applied to colour-ordered Yang--Mills amplitudes with Mandelstam invariants as input features. Using standard feature-selection techniques, specifically column-pivoted QR factorisation, we simultaneously recover the Kleiss--Kuijf and Bern--Carrasco--Johansson (BCJ) relations, identifying a minimal basis of partial amplitudes without any group-theoretic input. We obtain the tree-level KLT relations with high numerical accuracy up to five external legs, using only minimal theoretical priors, and we comment on the obstacles to generalising the method to higher multiplicity. Our results establish symbolic regression as a practical tool for exploring the analytic structure of the scattering-amplitude landscape, and suggests a general data-driven strategy for uncovering hidden relations in general theories. For comparison, we benchmark this general approach with a recently introduced neural-network based method.",
      "authors": [
        "Nathan Moynihan"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "cs.LG",
        "hep-ph"
      ],
      "published": "2026-02-16 20:15:50+00:00",
      "link": "https://arxiv.org/pdf/2602.15169v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15167v1",
      "title": "Distributional Deep Learning for Super-Resolution of 4D Flow MRI under Domain Shift",
      "abstract": "Super-resolution is widely used in medical imaging to enhance low-quality data, reducing scan time and improving abnormality detection. Conventional super-resolution approaches typically rely on paired datasets of downsampled and original high resolution images, training models to reconstruct high resolution images from their artificially degraded counterparts. However, in real-world clinical settings, low resolution data often arise from acquisition mechanisms that differ significantly from simple downsampling. As a result, these inputs may lie outside the domain of the training data, leading to poor model generalization due to domain shift. To address this limitation, we propose a distributional deep learning framework that improves model robustness and domain generalization. We develop this approch for enhancing the resolution of 4D Flow MRI (4DF). This is a novel imaging modality that captures hemodynamic flow velocity and clinically relevant metrics such as vessel wall stress. These metrics are critical for assessing aneurysm rupture risk. Our model is initially trained on high resolution computational fluid dynamics (CFD) simulations and their downsampled counterparts. It is then fine-tuned on a small, harmonized dataset of paired 4D Flow MRI and CFD samples. We derive the theoretical properties of our distributional estimators and demonstrate that our framework significantly outperforms traditional deep learning approaches through real data applications. This highlights the effectiveness of distributional learning in addressing domain shift and improving super-resolution performance in clinically realistic scenarios.",
      "authors": [
        "Xiaoyi Wen",
        "Fei Jiang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "stat.AP",
        "stat.ML"
      ],
      "published": "2026-02-16 20:11:42+00:00",
      "link": "https://arxiv.org/pdf/2602.15167v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15155v1",
      "title": "Refine Now, Query Fast: A Decoupled Refinement Paradigm for Implicit Neural Fields",
      "abstract": "Implicit Neural Representations (INRs) have emerged as promising surrogates for large 3D scientific simulations due to their ability to continuously model spatial and conditional fields, yet they face a critical fidelity-speed dilemma: deep MLPs suffer from high inference cost, while efficient embedding-based models lack sufficient expressiveness. To resolve this, we propose the Decoupled Representation Refinement (DRR) architectural paradigm. DRR leverages a deep refiner network, alongside non-parametric transformations, in a one-time offline process to encode rich representations into a compact and efficient embedding structure. This approach decouples slow neural networks with high representational capacity from the fast inference path. We introduce DRR-Net, a simple network that validates this paradigm, and a novel data augmentation strategy, Variational Pairs (VP) for improving INRs under complex tasks like high-dimensional surrogate modeling. Experiments on several ensemble simulation datasets demonstrate that our approach achieves state-of-the-art fidelity, while being up to 27$\\times$ faster at inference than high-fidelity baselines and remaining competitive with the fastest models. The DRR paradigm offers an effective strategy for building powerful and practical neural field surrogates and \\rev{INRs in broader applications}, with a minimal compromise between speed and quality.",
      "authors": [
        "Tianyu Xiong",
        "Skylar Wurster",
        "Han-Wei Shen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CE",
        "cs.CV",
        "cs.GR"
      ],
      "published": "2026-02-16 19:55:16+00:00",
      "link": "https://arxiv.org/pdf/2602.15155v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15146v2",
      "title": "Beyond Reinforcement Learning: Fast and Scalable Quantum Circuit Synthesis",
      "abstract": "Quantum unitary synthesis addresses the problem of translating abstract quantum algorithms into sequences of hardware-executable quantum gates. Solving this task exactly is infeasible in general due to the exponential growth of the underlying combinatorial search space. Existing approaches suffer from misaligned optimization objectives, substantial training costs and limited generalization across different qubit counts. We mitigate these limitations by using supervised learning to approximate the minimum description length of residual unitaries and combining this estimate with stochastic beam search to identify near optimal gate sequences. Our method relies on a lightweight model with zero-shot generalization, substantially reducing training overhead compared to prior baselines. Across multiple benchmarks, we achieve faster wall-clock synthesis times while exceeding state-of-the-art methods in terms of success rate for complex circuits.",
      "authors": [
        "Lukas Theißinger",
        "Thore Gerlach",
        "David Berghaus",
        "Christian Bauckhage"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "published": "2026-02-16 19:43:43+00:00",
      "link": "https://arxiv.org/pdf/2602.15146v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15139v1",
      "title": "CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding",
      "abstract": "Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.",
      "authors": [
        "Tahir Hussain",
        "Saddam Hussain Khan"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-02-16 19:36:32+00:00",
      "link": "https://arxiv.org/pdf/2602.15139v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15138v1",
      "title": "MB-DSMIL-CL-PL: Scalable Weakly Supervised Ovarian Cancer Subtype Classification and Localisation Using Contrastive and Prototype Learning with Frozen Patch Features",
      "abstract": "The study of histopathological subtypes is valuable for the personalisation of effective treatment strategies for ovarian cancer. However, increasing diagnostic workloads present a challenge for UK pathology departments, leading to the rise in AI approaches. While traditional approaches in this field have relied on pre-computed, frozen image features, recent advances have shifted towards end-to-end feature extraction, providing an improvement in accuracy but at the expense of significantly reduced scalability during training and time-consuming experimentation. In this paper, we propose a new approach for subtype classification and localisation in ovarian cancer histopathology images using contrastive and prototype learning with pre-computed, frozen features via feature-space augmentations. Compared to DSMIL, our method achieves an improvement of 70.4\\% and 15.3\\% in F1 score for instance- and slide-level classification, respectively, along with AUC gains of 16.9\\% for instance localisation and 2.3\\% for slide classification, while maintaining the use of frozen patch features.",
      "authors": [
        "Marcus Jenkins",
        "Jasenka Mazibrada",
        "Bogdan Leahu",
        "Michal Mackiewicz"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-16 19:33:33+00:00",
      "link": "https://arxiv.org/pdf/2602.15138v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15128v1",
      "title": "PolyNODE: Variable-dimension Neural ODEs on M-polyfolds",
      "abstract": "Neural ordinary differential equations (NODEs) are geometric deep learning models based on dynamical systems and flows generated by vector fields on manifolds. Despite numerous successful applications, particularly within the flow matching paradigm, all existing NODE models are fundamentally constrained to fixed-dimensional dynamics by the intrinsic nature of the manifold's dimension. In this paper, we extend NODEs to M-polyfolds (spaces that can simultaneously accommodate varying dimensions and a notion of differentiability) and introduce PolyNODEs, the first variable-dimensional flow-based model in geometric deep learning. As an example application, we construct explicit M-polyfolds featuring dimensional bottlenecks and PolyNODE autoencoders based on parametrised vector fields that traverse these bottlenecks. We demonstrate experimentally that our PolyNODE models can be trained to solve reconstruction tasks in these spaces, and that latent representations of the input can be extracted and used to solve downstream classification tasks. The code used in our experiments is publicly available at https://github.com/turbotage/PolyNODE .",
      "authors": [
        "Per Åhag",
        "Alexander Friedrich",
        "Fredrik Ohlsson",
        "Viktor Vigren Näslund"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-16 19:11:06+00:00",
      "link": "https://arxiv.org/pdf/2602.15128v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15031v1",
      "title": "EditCtrl: Disentangled Local and Global Control for Real-Time Generative Video Editing",
      "abstract": "High-fidelity generative video editing has seen significant quality improvements by leveraging pre-trained video foundation models. However, their computational cost is a major bottleneck, as they are often designed to inefficiently process the full video context regardless of the inpainting mask's size, even for sparse, localized edits. In this paper, we introduce EditCtrl, an efficient video inpainting control framework that focuses computation only where it is needed. Our approach features a novel local video context module that operates solely on masked tokens, yielding a computational cost proportional to the edit size. This local-first generation is then guided by a lightweight temporal global context embedder that ensures video-wide context consistency with minimal overhead. Not only is EditCtrl 10 times more compute efficient than state-of-the-art generative editing methods, it even improves editing quality compared to methods designed with full-attention. Finally, we showcase how EditCtrl unlocks new capabilities, including multi-region editing with text prompts and autoregressive content propagation.",
      "authors": [
        "Yehonathan Litman",
        "Shikun Liu",
        "Dario Seyb",
        "Nicholas Milef",
        "Yang Zhou",
        "Carl Marshall",
        "Shubham Tulsiani",
        "Caleb Leak"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-16 18:59:58+00:00",
      "link": "https://arxiv.org/pdf/2602.15031v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15021v1",
      "title": "Generalization from Low- to Moderate-Resolution Spectra with Neural Networks for Stellar Parameter Estimation: A Case Study with DESI",
      "abstract": "Cross-survey generalization is a critical challenge in stellar spectral analysis, particularly in cases such as transferring from low- to moderate-resolution surveys. We investigate this problem using pre-trained models, focusing on simple neural networks such as multilayer perceptrons (MLPs), with a case study transferring from LAMOST low-resolution spectra (LRS) to DESI medium-resolution spectra (MRS). Specifically, we pre-train MLPs on either LRS or their embeddings and fine-tune them for application to DESI stellar spectra. We compare MLPs trained directly on spectra with those trained on embeddings derived from transformer-based models (self-supervised foundation models pre-trained for multiple downstream tasks). We also evaluate different fine-tuning strategies, including residual-head adapters, LoRA, and full fine-tuning. We find that MLPs pre-trained on LAMOST LRS achieve strong performance, even without fine-tuning, and that modest fine-tuning with DESI spectra further improves the results. For iron abundance, embeddings from a transformer-based model yield advantages in the metal-rich ([Fe/H] > -1.0) regime, but underperform in the metal-poor regime compared to MLPs trained directly on LRS. We also show that the optimal fine-tuning strategy depends on the specific stellar parameter under consideration. These results highlight that simple pre-trained MLPs can provide competitive cross-survey generalization, while the role of spectral foundation models for cross-survey stellar parameter estimation requires further exploration.",
      "authors": [
        "Xiaosheng Zhao",
        "Yuan-Sen Ting",
        "Rosemary F. G. Wyse",
        "Alexander S. Szalay",
        "Yang Huang",
        "László Dobos",
        "Tamás Budavári",
        "Viska Wei"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA",
        "cs.LG"
      ],
      "published": "2026-02-16 18:58:47+00:00",
      "link": "https://arxiv.org/pdf/2602.15021v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15010v2",
      "title": "BPP: Long-Context Robot Imitation Learning by Focusing on Key History Frames",
      "abstract": "Many robot tasks require attending to the history of past observations. For example, finding an item in a room requires remembering which places have already been searched. However, the best-performing robot policies typically condition only on the current observation, limiting their applicability to such tasks. Naively conditioning on past observations often fails due to spurious correlations: policies latch onto incidental features of training histories that do not generalize to out-of-distribution trajectories upon deployment. We analyze why policies latch onto these spurious correlations and find that this problem stems from limited coverage over the space of possible histories during training, which grows exponentially with horizon. Existing regularization techniques provide inconsistent benefits across tasks, as they do not fundamentally address this coverage problem. Motivated by these findings, we propose Big Picture Policies (BPP), an approach that conditions on a minimal set of meaningful keyframes detected by a vision-language model. By projecting diverse rollouts onto a compact set of task-relevant events, BPP substantially reduces distribution shift between training and deployment, without sacrificing expressivity. We evaluate BPP on four challenging real-world manipulation tasks and three simulation tasks, all requiring history conditioning. BPP achieves 70% higher success rates than the best comparison on real-world evaluations. Videos are available at https://bigpicturepolicies.github.io/",
      "authors": [
        "Max Sobol Mark",
        "Jacky Liang",
        "Maria Attarian",
        "Chuyuan Fu",
        "Debidatta Dwibedi",
        "Dhruv Shah",
        "Aviral Kumar"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "published": "2026-02-16 18:49:56+00:00",
      "link": "https://arxiv.org/pdf/2602.15010v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15005v1",
      "title": "Learning User Interests via Reasoning and Distillation for Cross-Domain News Recommendation",
      "abstract": "News recommendation plays a critical role in online news platforms by helping users discover relevant content. Cross-domain news recommendation further requires inferring user's underlying information needs from heterogeneous signals that often extend beyond direct news consumption. A key challenge lies in moving beyond surface-level behaviors to capture deeper, reusable user interests while maintaining scalability in large-scale production systems. In this paper, we present a reinforcement learning framework that trains large language models to generate high-quality lists of interest-driven news search queries from cross-domain user signals. We formulate query-list generation as a policy optimization problem and employ GRPO with multiple reward signals. We systematically study two compute dimensions: inference-time sampling and model capacity, and empirically observe consistent improvements with increased compute that exhibit scaling-like behavior. Finally, we perform on-policy distillation to transfer the learned policy from a large, compute-intensive teacher to a compact student model suitable for scalable deployment. Extensive offline experiments, ablation studies and large-scale online A/B tests in a production news recommendation system demonstrate consistent gains in both interest modeling quality and downstream recommendation performance.",
      "authors": [
        "Mengdan Zhu",
        "Yufan Zhao",
        "Tao Di",
        "Yulan Yan",
        "Liang Zhao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-02-16 18:45:40+00:00",
      "link": "https://arxiv.org/pdf/2602.15005v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14997v1",
      "title": "Spectral Convolution on Orbifolds for Geometric Deep Learning",
      "abstract": "Geometric deep learning (GDL) deals with supervised learning on data domains that go beyond Euclidean structure, such as data with graph or manifold structure. Due to the demand that arises from application-related data, there is a need to identify further topological and geometric structures with which these use cases can be made accessible to machine learning. There are various techniques, such as spectral convolution, that form the basic building blocks for some convolutional neural network-like architectures on non-Euclidean data. In this paper, the concept of spectral convolution on orbifolds is introduced. This provides a building block for making learning on orbifold structured data accessible using GDL. The theory discussed is illustrated using an example from music theory.",
      "authors": [
        "Tim Mangliers",
        "Bernhard Mössner",
        "Benjamin Himpel"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-16 18:28:38+00:00",
      "link": "https://arxiv.org/pdf/2602.14997v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14983v1",
      "title": "Orthogonalized Multimodal Contrastive Learning with Asymmetric Masking for Structured Representations",
      "abstract": "Multimodal learning seeks to integrate information from heterogeneous sources, where signals may be shared across modalities, specific to individual modalities, or emerge only through their interaction. While self-supervised multimodal contrastive learning has achieved remarkable progress, most existing methods predominantly capture redundant cross-modal signals, often neglecting modality-specific (unique) and interaction-driven (synergistic) information. Recent extensions broaden this perspective, yet they either fail to explicitly model synergistic interactions or learn different information components in an entangled manner, leading to incomplete representations and potential information leakage. We introduce \\textbf{COrAL}, a principled framework that explicitly and simultaneously preserves redundant, unique, and synergistic information within multimodal representations. COrAL employs a dual-path architecture with orthogonality constraints to disentangle shared and modality-specific features, ensuring a clean separation of information components. To promote synergy modeling, we introduce asymmetric masking with complementary view-specific patterns, compelling the model to infer cross-modal dependencies rather than rely solely on redundant cues. Extensive experiments on synthetic benchmarks and diverse MultiBench datasets demonstrate that COrAL consistently matches or outperforms state-of-the-art methods while exhibiting low performance variance across runs. These results indicate that explicitly modeling the full spectrum of multimodal information yields more stable, reliable, and comprehensive embeddings.",
      "authors": [
        "Carolin Cissee",
        "Raneen Younis",
        "Zahra Ahmadi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16 18:06:53+00:00",
      "link": "https://arxiv.org/pdf/2602.14983v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14975v1",
      "title": "Faster Molecular Dynamics with Neural Network Potentials via Distilled Multiple Time-Stepping and Non-Conservative Forces",
      "abstract": "Following our previous work (J. Phys. Chem. Lett., 2026, 17, 5, 1288-1295), we propose the DMTS-NC approach, a distilled multi-time-step (DMTS) strategy using non conservative (NC) forces to further accelerate atomistic molecular dynamics simulations using foundation neural network models. There, a dual-level reversible reference system propagator algorithm (RESPA) formalism couples a target accurate conservative potential to a simplified distilled representation optimized for the production of non-conservative forces. Despite being non-conservative, the distilled architecture is designed to enforce key physical priors, such as equivariance under rotation and cancellation of atomic force components. These choices facilitate the distillation process and therefore improve drastically the robustness of simulation, significantly limiting the \"holes\" in the simpler potential, thus achieving excellent agreement with the forces data. Overall, the DMTS-NC scheme is found to be more stable and efficient than its conservative counterpart with additional speedups reaching 15-30% over DMTS. Requiring no finetuning steps, it is easier to implement and can be pushed to the limit of the systems physical resonances to maintain accuracy while providing maximum efficiency. As for DMTS, DMTS-NC is applicable to any neural network potential.",
      "authors": [
        "Nicolaï Gouraud",
        "Côme Cattin",
        "Thomas Plé",
        "Olivier Adjoua",
        "Louis Lagardère",
        "Jean-Philip Piquemal"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph",
        "cs.LG"
      ],
      "published": "2026-02-16 17:59:44+00:00",
      "link": "https://arxiv.org/pdf/2602.14975v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14974v1",
      "title": "DM0: An Embodied-Native Vision-Language-Action Model towards Physical AI",
      "abstract": "Moving beyond the traditional paradigm of adapting internet-pretrained models to physical tasks, we present DM0, an Embodied-Native Vision-Language-Action (VLA) framework designed for Physical AI. Unlike approaches that treat physical grounding as a fine-tuning afterthought, DM0 unifies embodied manipulation and navigation by learning from heterogeneous data sources from the onset. Our methodology follows a comprehensive three-stage pipeline: Pretraining, Mid-Training, and Post-Training. First, we conduct large-scale unified pretraining on the Vision-Language Model (VLM) using diverse corpora--seamlessly integrating web text, autonomous driving scenarios, and embodied interaction logs-to jointly acquire semantic knowledge and physical priors. Subsequently, we build a flow-matching action expert atop the VLM. To reconcile high-level reasoning with low-level control, DM0 employs a hybrid training strategy: for embodied data, gradients from the action expert are not backpropagated to the VLM to preserve generalized representations, while the VLM remains trainable on non-embodied data. Furthermore, we introduce an Embodied Spatial Scaffolding strategy to construct spatial Chain-of-Thought (CoT) reasoning, effectively constraining the action solution space. Experiments on the RoboChallenge benchmark demonstrate that DM0 achieves state-of-the-art performance in both Specialist and Generalist settings on Table30.",
      "authors": [
        "En Yu",
        "Haoran Lv",
        "Jianjian Sun",
        "Kangheng Lin",
        "Ruitao Zhang",
        "Yukang Shi",
        "Yuyang Chen",
        "Ze Chen",
        "Ziheng Zhang",
        "Fan Jia",
        "Kaixin Liu",
        "Meng Zhang",
        "Ruitao Hao",
        "Saike Huang",
        "Songhan Xie",
        "Yu Liu",
        "Zhao Wu",
        "Bin Xie",
        "Pengwei Zhang",
        "Qi Yang",
        "Xianchi Deng",
        "Yunfei Wei",
        "Enwen Zhang",
        "Hongyang Peng",
        "Jie Zhao",
        "Kai Liu",
        "Wei Sun",
        "Yajun Wei",
        "Yi Yang",
        "Yunqiao Zhang",
        "Ziwei Yan",
        "Haitao Yang",
        "Hao Liu",
        "Haoqiang Fan",
        "Haowei Zhang",
        "Junwen Huang",
        "Yang Chen",
        "Yunchao Ma",
        "Yunhuan Yang",
        "Zhengyuan Du",
        "Ziming Liu",
        "Jiahui Niu",
        "Yucheng Zhao",
        "Daxin Jiang",
        "Wenbin Tang",
        "Xiangyu Zhang",
        "Zheng Ge",
        "Erjin Zhou",
        "Tiancai Wang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-16 17:59:16+00:00",
      "link": "https://arxiv.org/pdf/2602.14974v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14968v1",
      "title": "PhyScensis: Physics-Augmented LLM Agents for Complex Physical Scene Arrangement",
      "abstract": "Automatically generating interactive 3D environments is crucial for scaling up robotic data collection in simulation. While prior work has primarily focused on 3D asset placement, it often overlooks the physical relationships between objects (e.g., contact, support, balance, and containment), which are essential for creating complex and realistic manipulation scenarios such as tabletop arrangements, shelf organization, or box packing. Compared to classical 3D layout generation, producing complex physical scenes introduces additional challenges: (a) higher object density and complexity (e.g., a small shelf may hold dozens of books), (b) richer supporting relationships and compact spatial layouts, and (c) the need to accurately model both spatial placement and physical properties. To address these challenges, we propose PhyScensis, an LLM agent-based framework powered by a physics engine, to produce physically plausible scene configurations with high complexity. Specifically, our framework consists of three main components: an LLM agent iteratively proposes assets with spatial and physical predicates; a solver, equipped with a physics engine, realizes these predicates into a 3D scene; and feedback from the solver informs the agent to refine and enrich the configuration. Moreover, our framework preserves strong controllability over fine-grained textual descriptions and numerical parameters (e.g., relative positions, scene stability), enabled through probabilistic programming for stability and a complementary heuristic that jointly regulates stability and spatial relations. Experimental results show that our method outperforms prior approaches in scene complexity, visual quality, and physical accuracy, offering a unified pipeline for generating complex physical scene layouts for robotic manipulation.",
      "authors": [
        "Yian Wang",
        "Han Yang",
        "Minghao Guo",
        "Xiaowen Qiu",
        "Tsun-Hsuan Wang",
        "Wojciech Matusik",
        "Joshua B. Tenenbaum",
        "Chuang Gan"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-16 17:55:25+00:00",
      "link": "https://arxiv.org/pdf/2602.14968v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14954v1",
      "title": "Phase transitions and linear stability for the mean-field Kuramoto-Daido model",
      "abstract": "We consider the mean-field noisy Kuramoto-Daido model, which is a McKean-Vlasov equation on the circle with bimodal interaction $W(θ)=\\cosθ+m\\cos2θ$ for $m\\ge 0$ and interaction strength $K$, generalizing the celebrated noisy Kuramoto model corresponding to $m=0$.   Our first contribution is to characterize the phase transition threshold $K_{c}$ by comparing it to the linear stability threshold $K_\\# = \\min (1, m^{-1})$ of the uniform distribution. When $m \\leq 1/2,$ $K_{c}=1$, coinciding with that of the Kuramoto model. On the other hand, for $m \\geq 2$, we show $K_c= m^{-1}$. We also classify the regimes in which the phase transition is continuous or discontinuous.   Our second contribution is to analyze the linear stability of a global minimizer $q$ (the ``ordered phase'') of the mean-field free energy in the supercritical regime $K>1$. This stationary solution of the Kuramoto-Daido equation is unique up to translation invariance and distinct from the uniform distribution (the ``disordered phase''). Our approach extends the Dirichlet form method of Bertini et al. from the unimodal to bimodal setting. In particular, for $m \\leq 1.590 \\times 10^{-4}$ and $K>1$, we show an explicit lower bound on the spectral gap of the linearized McKean-Vlasov operator at $q$. To our knowledge, this is the first rigorous stability analysis for this class of models with bimodal interactions.",
      "authors": [
        "Kyunghoo Mun",
        "Matthew Rosenzweig"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "math-ph"
      ],
      "published": "2026-02-16 17:33:43+00:00",
      "link": "https://arxiv.org/pdf/2602.14954v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14949v1",
      "title": "Max-Min Bilinear Completely Positive Programs: A Semidefinite Relaxation with Tightness Guarantees",
      "abstract": "Max-min bilinear optimization models, where one agent maximizes and an adversary minimizes a common bilinear objective, serve as canonical saddle-point formulations in optimization theory. They capture, among others, two-player zero-sum games, robust and distributionally robust optimization, and adversarial machine learning. This study focuses on the subclass whose variables lie in the completely positive (CP) cone, capturing a broad family of mixed-binary quadratic max-min problems through the modelling power of completely positive programming. We show that such problems admit an equivalent single-stage linear reformulation over the COP-CP cone, defined as the Cartesian product of the copositive (COP) and CP cones. Because testing membership in COP cones is co-NP-complete, the resulting COP-CP program inherits NP-hardness. To address this challenge, we develop a hierarchy of semidefinite relaxations based on moment and sum-of-squares representations of the COP and CP cones, and flat truncation conditions are applied to certify the tightness. We show that the tightness of the hierarchy is guaranteed under mild conditions. The framework extends existing CP/COP approaches for distributionally robust optimization and polynomial games. We apply the framework to the cyclic Colonel Blotto game, an extension of Borel's classic allocation contest. Across multiple instances, the semidefinite relaxation meets the flat-truncation conditions and solves the exact mixed-strategy equilibrium.",
      "authors": [
        "Sarah Yini Gao",
        "Xindong Tang",
        "Yancheng Yuan"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-16 17:29:39+00:00",
      "link": "https://arxiv.org/pdf/2602.14949v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14946v1",
      "title": "On Liouville's theorem for the Hessian quotient equation $σ_2/σ_1$",
      "abstract": "We prove Liouville's theorem for semi-convex entire solutions to Hessian quotient equation $σ_2/σ_1=1$ in $\\mathbb{R}^n$. The proof is based on the observation that after rewriting the quotient operator as the $σ_2$ operator, acting on a new function, one can refer to the recent result of Shankar and Yuan on Liouville's theorem for $σ_2$ equation.",
      "authors": [
        "Siyuan Lu",
        "Marcin Sroka"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-16 17:28:39+00:00",
      "link": "https://arxiv.org/pdf/2602.14946v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14944v1",
      "title": "Pattern preservation in finite to infinite-horizon optimal control problems for dissipative systems",
      "abstract": "This paper focuses on infinite-horizon optimal control problems for dissipative systems and the relations to their finite-horizon formulations. We show that, for a large class of problems, dissipativity of the state equation, when a coercive storage function exists, implies that infinite-horizon optimal controls can be obtained as limits of the corresponding finite-horizon ones. This property is referred to as pattern preservation, or pattern-preserving property.   Our analysis establishes a formal link between dissipativity theory and the variational convergence framework in optimal control, thus providing a concrete and numerically tractable condition for verifying pattern preservation. Numerical examples illustrate the effectiveness and limitations of the proposed sufficient conditions.",
      "authors": [
        "Matteo Della Rossa",
        "Thiago Alves Lima",
        "Lorenzo Freddi"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-16 17:27:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14944v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14912v1",
      "title": "A posteriori error estimates for a modified Morley FEM",
      "abstract": "Residual-based a~posteriori error estimators are derived for the modified Morley FEM, proposed by Wang, Xu, Hu [J. Comput. Math, 24(2), 2006], for the singularly perturbed biharmonic equation and the nonlinear von Kármán equations. The error estimators are proven to be reliable and efficient. Moreover, an adaptive algorithm driven by these error estimators is investigated in numerical experiments.",
      "authors": [
        "A. K. Dond",
        "D. Gallistl",
        "S. Nayak",
        "M. Schedensack"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-16 16:47:18+00:00",
      "link": "https://arxiv.org/pdf/2602.14912v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15911v1",
      "title": "Numerical Solution of the Bardeen-Cooper-Schrieffer Equation for Unconventional Superconductors",
      "abstract": "In this work, we consider the analytical properties and the efficient numerical solution of the Bardeen-Cooper-Schrieffer equation for unconventional superconductivity incorporating long-range power-law electron-electron interactions within a tight-binding model on a $d$-dimensional lattice. It is a nonlinear convolution equation for the complex matrix-valued superconducting gap under symmetry constraints imposed by the fermionic anticommutation rules. The long-range interaction enters in momentum space in the form of the now efficiently computable Epstein zeta function, which exhibits a power-law singularity at zero momentum. This needs to be accounted when evaluating the convolution. After a brief overview of some of the equation's analytical properties, we discuss its efficient numerical solution using a Galerkin method with B-splines. We present numerical results for a nodal superconductor on a two-dimensional square lattice.",
      "authors": [
        "Andreas A. Buchheit",
        "Torsten Keßler",
        "Sergej Rjasanow"
      ],
      "primary_category": "math-ph",
      "categories": [
        "math-ph",
        "cond-mat.supr-con",
        "math.NA"
      ],
      "published": "2026-02-16 16:09:11+00:00",
      "link": "https://arxiv.org/pdf/2602.15911v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14856v1",
      "title": "Fluidic Shaping over arbitrary domains: theory and high order finite-elements solver",
      "abstract": "Fluidic Shaping is a novel method for fabrication of optical components based on the equilibrium state of liquid volumes in neutral buoyancy, subjected to geometrical constraints. The underlying physics of this method is described by a highly nonlinear partial differential equation with Dirichlet boundary conditions and an integral constraint. To date, useful solutions for such optical liquid surfaces could be obtained analytically only for the linearized equations and only on circular or elliptical domains. A numerical solution for the non-linear equation was suggested, but only for the axi-symmetric case. Such solutions are, however, insufficient as they do not capture the full range of optical surfaces. Arbitrary domains offer an important degree of freedom for creating complex optical surfaces, and the nonlinear terms are essential for high quality solutions. Moreover, in the context of optics, it is not sufficient to resolve the shape of the surface, and it is essential to obtain accurate solutions for its curvature, which governs its optical properties. We here present the theoretical foundation for the Fluidic Shaping method over arbitrary domains, and the development of a high order (quintic) finite element numerical solver, capable of accurately resolving the topography and curvature of liquid interfaces on arbitrary domains. The code is based on reduced quintic finite elements, which we have modified to capture curved boundaries. We compare the results against low order finite elements and non-deformed high order elements, demonstrating the importance of high order approximations of both the solution and the domain. We also show the usability of the code for the prediction of optical surfaces derived from complex boundary conditions.",
      "authors": [
        "Amos A. Hari",
        "Moran Bercovici"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "math-ph"
      ],
      "published": "2026-02-16 15:51:29+00:00",
      "link": "https://arxiv.org/pdf/2602.14856v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14826v1",
      "title": "Hodge theory for twisted log-differential forms",
      "abstract": "In this survey, we review recent developments in extending Hodge theory to differential forms with values in bundles equipped with singular metrics, based on joint work with Ya Deng, Christopher D. Hacon, and Mihai Păun.",
      "authors": [
        "Junyan Cao"
      ],
      "primary_category": "math.CV",
      "categories": [
        "math.CV",
        "math.AG"
      ],
      "published": "2026-02-16 15:18:44+00:00",
      "link": "https://arxiv.org/pdf/2602.14826v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14820v1",
      "title": "Effective approximations of solutions to highly oscillatory diffusion equations from coarse measurements",
      "abstract": "We approximate a diffusion equation with highly oscillatory coefficients with a diffusion equation with constant coefficients. The approach is put in action in contexts where only partial information (namely the global energy stored in the physical system) is available. While the reconstruction of the microstructure is known to be an ill-posed problem, we show that the reconstruction of effective coefficients is possible and this even with only some coarse information. The strategy we present takes the form of a non-convex optimization problem. Homogenization theory provides elements for a rigorous foundation of the approach. Some algorithmic aspects are discussed in details. We provide a comprehensive set of numerical illustrations that demonstrate the practical interest of our strategy. The present work improves on the earlier works [C. Le Bris, F. Legoll and S. Lemaire, COCV 2018; C. Le Bris, F. Legoll and K. Li, CRAS 2013].",
      "authors": [
        "Claude Le Bris",
        "Frédéric Legoll",
        "Simon Ruget"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-16 15:13:04+00:00",
      "link": "https://arxiv.org/pdf/2602.14820v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14802v1",
      "title": "A mirror deformation of Markov numbers",
      "abstract": "We introduce a deformed squared Markov equation given by $X^2 + Y^2 + Z^2 + (q+q^{-1})(XY+YZ+XZ) = 3(1 + q + q^{-1})XYZ$. Symmetric solutions of this new equation present a remarkable factorization property which allows us to talk about their square roots. These square roots give a natural $q$-deformation of the Markov numbers that has not previously occurred in the literature. We call them mirror Markov numbers. We prove a characterization of mirror Markov numbers and discover a mutation rule, mirror mutation, to generate them all. We also prove a geometric realization of the corresponding mirror mutation on a once-punctured sphere with three orbifold points. Our mirror deformation leads to deformations of Fibonacci and Pell branches for which we give precise formulas. Furthermore, the deformed squared Markov equation specializes to many other very well known generalized Markov equations. We also obtain the super Markov numbers from a specialization of the deformed squared Markov numbers, which we use to prove a conjecture of Musiker.",
      "authors": [
        "Léa Bittmann",
        "Perrine Jouteur",
        "Ezgi Kantarcı Oğuz",
        "Melody Molander",
        "Emine Yıldırım"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-02-16 14:53:57+00:00",
      "link": "https://arxiv.org/pdf/2602.14802v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14801v1",
      "title": "Identifying Bergman space functions from intervals",
      "abstract": "We characterize functions of a Bergman space on a square by their values and derivatives on the diagonals. This problem is connected with the reachable space of the one-dimensional heat equation on a finite interval with boundary $L^2$-controls.",
      "authors": [
        "Andreas Hartmann",
        "Marcu-Antone Orsoni"
      ],
      "primary_category": "math.CV",
      "categories": [
        "math.CV",
        "math.AP",
        "math.FA",
        "math.OC"
      ],
      "published": "2026-02-16 14:53:35+00:00",
      "link": "https://arxiv.org/pdf/2602.14801v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14800v1",
      "title": "On the Hölder continuity of signed solutions to doubly nonlinear parabolic equations in the mixed degenerate/singular cases",
      "abstract": "We prove the Hölder continuity of sign-changing solutions to the equation of the type $$\\frac{\\partial}{\\partial t}\\big(|u|^{q-1} u\\big)- div\\Big(|D u|^{p-2}\\,D u\\Big)=0,$$ where numbers $p$, $q$ satisfy the conditions $$0<q<p-1\\quad \\text{and}\\quad p<2,$$ or $$q>p-1\\quad\\text{and}\\quad p>2.$$ Our proof uses new versions of the integral Harnack type inequalities for sign-changing solutions.",
      "authors": [
        "Igor I. Skrypnik"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-16 14:52:33+00:00",
      "link": "https://arxiv.org/pdf/2602.14800v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14727v1",
      "title": "Heterogeneous Cattaneo-Vernotte equation connection to the noisy voter model",
      "abstract": "We consider a heterogeneous diffusion equation and its corresponding generalization to the Cattaneo-Vernotte equation. It is derived by a combination of the continuity equation and the constitutive relation in various stochastic interpretations of the heterogeneous diffusion process. The heterogeneity in the system is introduced by considering a position-dependent diffusion coefficient. Exact results for the probability density function and the mean squared displacement are provided. The limiting case of heterogeneous diffusion is analyzed in detail, and the corresponding time-averaged mean-squared displacement is calculated. From the obtained results, an ergodicity breaking is observed.",
      "authors": [
        "K. Górska",
        "A. Horzela",
        "D. Jankov Maširević",
        "T. Pietrzak",
        "1T. K. Pogány",
        "T. Sandev"
      ],
      "primary_category": "math-ph",
      "categories": [
        "math-ph"
      ],
      "published": "2026-02-16 13:19:22+00:00",
      "link": "https://arxiv.org/pdf/2602.14727v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14692v1",
      "title": "Weak Poincaré inequalities for Deterministic-scan Metropolis-within-Gibbs samplers",
      "abstract": "Using the framework of weak Poincaré inequalities, we analyze the convergence properties of deterministic-scan Metropolis-within-Gibbs samplers, an important class of Markov chain Monte Carlo algorithms. Our analysis applies to nonreversible Markov chains and yields explicit (subgeometric) convergence bounds through novel comparison techniques based on Dirichlet forms. We show that the joint chain inherits the convergence behavior of the marginal chain and conversely. In addition, we establish several fundamental results for weak Poincaré inequalities for discrete-time Markov chains, such as a tensorization property for independent chains. We apply our theoretical results through applications to algorithms for Bayesian inference for a hierarchical regression model and a diffusion model under discretely-observed data.",
      "authors": [
        "Mengxi Gao",
        "Gareth O. Roberts",
        "Andi Q. Wang"
      ],
      "primary_category": "stat.CO",
      "categories": [
        "stat.CO",
        "math.PR"
      ],
      "published": "2026-02-16 12:27:31+00:00",
      "link": "https://arxiv.org/pdf/2602.14692v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14685v1",
      "title": "On the kinetic equation arising from the large-scale limit of the Cucker-Smale model",
      "abstract": "We propose a large-scale scaling viewpoint for deriving mesoscopic dynamics from interacting particle systems and apply it to the Cucker--Smale flocking model. In contrast with the classical mean-field regime leading to the Vlasov-type Cucker--Smale equation with spatially nonlocal (convolution) alignment force, our scaling yields a kinetic equation whose alignment field becomes local in space and nonlocal only in velocity. For the spatially homogeneous case, we obtain an explicit solution and derive quantitative flocking rates. For the spatially inhomogeneous equation we establish a local well-posedness in $W^{1,\\infty}$ and in $C_b^{1,α}$, highlighting the additional difficulties caused by the absence of a convolution structure. Moreover, for sufficiently small interaction strength we present a global well-posedness and a forward-in-time $L^1$ asymptotic completeness property. Finally, we investigate mono-kinetic solutions and exhibit finite-time blow-up scenarios.",
      "authors": [
        "Ruicheng Cheng",
        "Seung-Yeal Ha",
        "Jaemoon Lee",
        "Zhenfu Wang"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-16 12:18:54+00:00",
      "link": "https://arxiv.org/pdf/2602.14685v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14651v1",
      "title": "Asymptotic behavior at infinity of Weingarten surfaces",
      "abstract": "We derive the asymptotic expansion at infinity for embedded ends of uniformly elliptic Weingarten surfaces with finite total curvature in $\\mathbb{R}^3$, and we establish a maximum principle at infinity. Furthermore, we solve the Dirichlet problem for the uniformly elliptic Weingarten equation in dimension two on strictly convex bounded domains.",
      "authors": [
        "Aires E. M. Barbieri",
        "José A. Gálvez",
        "Yuanyuan Lian",
        "Kai Zhang"
      ],
      "primary_category": "math.DG",
      "categories": [
        "math.DG",
        "math.AP"
      ],
      "published": "2026-02-16 11:21:44+00:00",
      "link": "https://arxiv.org/pdf/2602.14651v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14638v1",
      "title": "Kernel estimates and weak (1,1)-boundedness of pseudo-differential operators on compact Lie groups",
      "abstract": "Given a compact Lie group $G$ and its unitary dual $\\widehat{G}$, we establish the weak (1,1) continuity for pseudo-differential operators in the global Hörmander classes of order $-n(1-ρ)/2$ on $G\\times \\widehat{G}$. Our approach consists of proving suitable estimates for the kernel of such operators. Furthermore, we use these kernel estimates to give an alternative proof for the $H^1(G)$-$L^1(G)$-continuity of these classes now allowing the full range $0\\leqδ\\leqρ\\leq1, \\;ρ\\neq0,\\;δ\\neq1$. The conditions for the operators are formulated using the Hörmander classes $S^m_{ρ,δ}(G):=S^m_{ρ,δ}(G\\times \\widehat{G})$ of symbols in the non-commutative phase space $G\\times \\widehat{G}$, which are extensions of the well-known $(ρ,δ)$-classes in the Euclidean space. Our results are formulated in the complete range $0\\leq δ\\leq ρ\\leq 1,$ $ρ\\neq0,\\;$$δ\\neq 1$.   As an application of this boundedness result we provide end-point a-priori $L^1$-estimates for the sub-Laplacian $\\mathcal{L}_{sub}=X^2+Y^2,$ and for the heat type operator $T=Z-X^2-Y^2$ on $SU(2)\\cong \\mathbb{S}^3$ that cannot be obtained by application of the standard pseudo-differential calculus due to Hörmander. More precisely, we prove that if one considers the subelliptic problem,   \\begin{equation}\\label{IVP:abstract} \\begin{cases}Tu=f ,& \\text{ } \\\\u,f\\in \\mathscr{D}'(SU(2)):=(C^\\infty(SU(2)))', & \\text{ } \\end{cases} \\end{equation} then, for $f\\in W^{1,-\\frac{1}{4}}(SU(2)),$ one has that $u\\in L^{1,\\infty}(SU(2)).$",
      "authors": [
        "Duván Cardona",
        "Rafik Yeghoyan",
        "Michael Ruzhansky"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-16 10:54:23+00:00",
      "link": "https://arxiv.org/pdf/2602.14638v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14624v1",
      "title": "Interwoven SDP in Primal-Dual Proximal Splitting Methods for Adjustable Robust Convex Optimisation with SOS-Convex Polynomial Constraints",
      "abstract": "We propose a novel methodology for solving a two-stage adjustable robust convex optimisation problem with a general (proximable) convex objective function and constraints defined by sum-of-squares (SOS) convex polynomials. These problems appear in many decision-making applications. However, they are challenging to solve and typically cannot be reformulated as numerically tractable convex optimisation models, such as conic linear programs, that can be solved directly using existing software. We show that the robust problem admits an equivalent representation as a convex composite unconstrained optimisation model that preserves the same objective values, under quadratic decision rules on the adjustable decision variables. Building on this reformulation, we develop a tailored first-order primal-dual proximal splitting method. By leveraging semidefinite programming (SDP) techniques as well as tools from convex analysis and real algebraic geometry, we establish its theoretical properties, including computable SDP-based formulas for projections onto closed convex sets, specified by SOS-convex polynomial inequalities. Numerical experiments on a two-stage lot-sizing model with both linear as well as SOS-convex polynomial storage costs under demand uncertainty demonstrate the effectiveness and applicability of the proposed approach. Our approach enables the incorporation of SDP techniques into a primal-dual proximal splitting framework, thereby broadening the class of problems to which these methods can be effectively applied.",
      "authors": [
        "Neil D. Dizon",
        "Bethany I. Caldwell",
        "Vaithilingam Jeyakumar",
        "Guoyin Li"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-16 10:31:28+00:00",
      "link": "https://arxiv.org/pdf/2602.14624v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14617v1",
      "title": "Stochastic Burgers equation driven by multiplicative Rosenblatt noise: local existence, uniqueness and regularity",
      "abstract": "We study the stochastic Burgers equation driven by a multiplicative Rosenblatt noise with Hurst parameter $H \\in (1/2,1)$. Using a fixed-point argument in a Malliavin--Sobolev space that controls the solution and its first two Malliavin derivatives, we prove local existence and uniqueness of a mild solution. We establish uniform moment bounds of all orders and prove Hölder regularity: spatial Hölder exponent $γ< 1/2$ and temporal Hölder exponent $α< H-1/2$, which are shown to be sharp by a lower bound for the linearized equation. The proof relies on sharp estimates of the heat kernel in the reproducing kernel Hilbert space $\\cH$ of the Rosenblatt process, on Meyer's inequalities for moment bounds, and on a careful analysis of the Skorohod integral with respect to the Rosenblatt process. These results provide a rigorous foundation for the study of nonlinear SPDEs driven by non-Gaussian long-memory noise.",
      "authors": [
        "Atef Lechiheb"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-02-16 10:22:35+00:00",
      "link": "https://arxiv.org/pdf/2602.14617v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14568v1",
      "title": "A combinatorial proof of Jacobi's elliptic identity via alternating permutations",
      "abstract": "We provide a unified combinatorial framework connecting Entringer numbers, Dumont-Viennot snakes, and elliptically weighted continued fractions, which gives a structural interpretation of the Jacobi elliptic identity \\begin{equation} \\mathrm{sn}'(u)=\\mathrm{cn}(u)\\,\\mathrm{dn}(u), \\end{equation} where $\\mathrm{sn}$, $\\mathrm{cn}$ and $\\mathrm{dn}$ are the Jacobi elliptic functions. This framework allows the decomposition of weighted snakes corresponding to the derivative of $\\mathrm{sn}$ into canonical $\\mathrm{cn}$- and $\\mathrm{dn}$-components, bridging classical combinatorics and elliptic function theory.",
      "authors": [
        "Jean-christophe Pain"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-02-16 09:00:24+00:00",
      "link": "https://arxiv.org/pdf/2602.14568v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14545v1",
      "title": "On the first eigenvalue of a nonlinear Schrödinger type equation",
      "abstract": "We consider an eigenvalue problem for the generalized nonlinear Schrödinger type operator with the Robin boundary condition as given below. \\begin{equation*} \\label{ab-Robin p-Laplace evp with potential term_intro} \\left\\{ \\begin{split} -Δ_p u+V(x)|u|^{p-2}u&=λ|u|^{p-2}u\\quad &&\\mathrm{in} ~Ω,\\\\ |\\nabla u|^{p-2}\\frac{\\partial u}{\\partialη}+β|u|^{p-2}u&=0\\quad &&\\mathrm{on}~\\partialΩ, \\end{split} \\right. \\end{equation*} where $Δ_p u := \\operatorname{div}(|\\nabla u|^{p-2}\\nabla u)$ is the $p$-Laplace operator, $Ω$ is a bounded domain in $\\mathbb{R}^n$ with smooth boundary, $V \\in C^1(\\mathbb{R}^n),$ $ η$ denotes the outward unit normal, and $ β$ is a positive real constant. We study the properties of its first eigenvalue with respect to the potential $V$, the boundary parameter $β$ as well as the domain. First, we establish some properties of the smallest eigenvalue $λ_1(V)$ with respect to the potential. We then prove the differentiability of $λ_1(V)$ with respect to the Robin boundary parameter $β$ and give an explicit formula for this derivative, which is then used to investigate some monotonicity properties of $λ_1(V).$ We also obtain a shape derivative formula for the smallest eigenvalue. Using these derivatives, we also study domain monotonicity properties of the first eigenvalue.",
      "authors": [
        "Ardra A"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-16 08:07:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14545v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14537v1",
      "title": "On the Existence of Koopman Linear Embeddings for Controlled Nonlinear Systems",
      "abstract": "Koopman linear representations have become a popular tool for control design of nonlinear systems, yet it remains unclear when such representations are exact. In this paper, we establish sufficient and necessary conditions under which a controlled nonlinear system admits an exact finite-dimensional Koopman linear representation, which we term Koopman linear embedding. We show that such a system must be transformable into a special control-affine preserved (CAP) structure, which enforces affine dependence of the state on the control input and isolates all nonlinearities into an autonomous subsystem. We further prove that this autonomous subsystem must itself admit a finite-dimensional Koopman linear model with a sufficiently-rich Koopman invariant subspace. Finally, we introduce a symbolic procedure to determine whether a given controlled nonlinear system admits the CAP structure, thereby elucidating whether Koopman approximation errors arise from intrinsic system dynamics or from the choice of lifting functions.",
      "authors": [
        "Xu Shang",
        "Masih Haseli",
        "Jorge Cortés",
        "Yang Zheng"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "eess.SY"
      ],
      "published": "2026-02-16 07:54:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14537v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14480v1",
      "title": "Graph-Guided Fused Regularization for Single- and Multi-Task Regression on Spatiotemporal Data",
      "abstract": "Spatiotemporal matrix-valued data arise frequently in modern applications, yet performing effective regression analysis remains challenging due to complex, dimension-specific dependencies. In this work, we propose a regularized framework for spatiotemporal matrix regression that characterizes temporal and spatial dependencies through tailored penalties. Specifically, the model incorporates a fused penalty to capture smooth temporal evolution and a graph-guided penalty to promote spatial similarity. The framework also extends to the multi-task setting, enabling joint estimation across related tasks. We provide a comprehensive analysis of the framework from both theoretical and computational perspectives. Theoretically, we establish the statistical consistency of the proposed estimators. Computationally, we develop an efficient solver based on the Halpern Peaceman-Rachford method for the resulting composite convex optimization problem. The proposed algorithm achieves a fast global non-ergodic $\\mathcal{O}(1/k)$ convergence rate with low per-iteration complexity. Extensive numerical experiments demonstrate that our method significantly outperforms state-of-the-art approaches in terms of predictive accuracy and estimation error, while also exhibiting superior computational efficiency and scalability.",
      "authors": [
        "Meixia Lin",
        "Ziyang Zeng",
        "Yangjing Zhang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-16 05:45:40+00:00",
      "link": "https://arxiv.org/pdf/2602.14480v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14479v1",
      "title": "Conditional Expectation expression in mean-field SDEs and its applications",
      "abstract": "This study developed a novel formulation of conditional expectations within the framework of a jump-diffusion mean-field stochastic differential equation. We introduce an integrated approach that combines unconditioned expectations with rigorously defined weighting factors, employing Malliavin calculus on Poisson space and directional derivatives to enhance estimation accuracy. \\noindent The proposed method is applied to the numerical pricing of American put options in a jump-diffusion mean-field setting, addressing the challenges proposed by early-exercise features. Comprehensive numerical experiments demonstrate substantial improvements in pricing accuracy compared with conventional techniques.",
      "authors": [
        "Samaneh Sojudi",
        "Mahdieh Tahmasebi"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "math.NA"
      ],
      "published": "2026-02-16 05:41:24+00:00",
      "link": "https://arxiv.org/pdf/2602.14479v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14460v1",
      "title": "Integral Numerical Radius and Operator Matrix Bounds",
      "abstract": "We establish new integral inequalities for the numerical radius and the operator norm of bounded linear operators on Hilbert spaces. Our results refine classical triangle-type and operator matrix inequalities by incorporating convex combinations and integral averaging techniques. Several consequences, including new identities, sharper bounds, and equality conditions, are obtained, revealing deeper structural connections between the numerical radius and operator norm.",
      "authors": [
        "Shiva Sheybani",
        "Hamid Reza Moradi",
        "Mohammad Sababheh"
      ],
      "primary_category": "math.FA",
      "categories": [
        "math.FA"
      ],
      "published": "2026-02-16 04:40:35+00:00",
      "link": "https://arxiv.org/pdf/2602.14460v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14447v1",
      "title": "Tribonacci Numbers That Are Products of Two Lucas Numbers",
      "abstract": "Let $T_{k}$ be the $k^{\\textrm{th}}$ Tribonacci number and $L_{n}$ be the $n^{\\textrm{th}}$ Lucas number defined by their respective recurrence relation $T_{k}=T_{k-1}+T_{k-2}+T_{k-3}$ and $L_{n}=L_{n-1}+L_{n-2}$. In this study, we solve the Diophantine equation $T_{k} = L_{m}L_{n}$ for positive integer unknowns $m$, $n$, and $k$ and prove our results.",
      "authors": [
        "Ama Ahenfoa Quansah"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-02-16 04:11:22+00:00",
      "link": "https://arxiv.org/pdf/2602.14447v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14412v1",
      "title": "The small Deborah number limit for the compressible fluid-particle flows",
      "abstract": "In this paper, we consider the hydrodynamic limit for the fluid-particle flows governed by the Vlasov-Fokker-Planck equation coupled with the compressible Navier-Stokes equation as the Deborah number tends to zero. The limit is valid globally in time provided that the initial perturbation is small in a neighborhood of a steady state. The proof is based on a formal derivation via the Hilbert expansion around the limiting system, the rigorous justification of which is completed by the refined energy estimates involving the macro-micro decomposition. Compared with the existing results obtained by the relative entropy argument([A. Mellet and A. F. Vasseur, Comm. Math. Phys., 281 (2008), pp. 573--596]), the present work provides a stronger pointwise convergence of the hydrodynamic limits with an explicit rate for the fluid-particle coupled model.",
      "authors": [
        "Zhendong Fang",
        "Kunlun Qi",
        "Huanyao Wen"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-16 02:40:41+00:00",
      "link": "https://arxiv.org/pdf/2602.14412v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14392v2",
      "title": "Flux-Balanced Patankar-type Schemes for the Compressible Euler Equations",
      "abstract": "Positivity preservation of key physical quantities in the context of fluid flows, such as density and internal energy, is an essential property of a numerical scheme as otherwise the solution lacks physical relevance and has a not well-defined equation of state. One time integration technique that is capable of preserving the positivity of quantities for every time step size is the Patankar-trick and its variants. However, in the context of the Euler equations of gas dynamics, we wonder whether the Patankar-trick should be applied to the density and total energy equations or only to one of them. In this work, we discuss one drawback of the schemes when blindly applied to every positive conserved variable and additionally point out how to overcome the issue by balancing the involved numerical fluxes correctly. To illustrate our findings, we investigate modified Patankar--Runge--Kutta (MPRK) schemes in the context of the compressible Euler equations with and without stiff source terms. We discover that it is beneficial to only apply the Patankar-trick in the density equation and to balance the remaining numerical fluxes consistently rather than applying the trick also to the energy equation. This leads also to the preservation of contact discontinuities. We perform numerical experiments to demonstrate that the accuracy of the methods is maintained while the performance of our approach is superior to the traditional application of MPRK schemes.",
      "authors": [
        "Thomas Izgin",
        "Andreas Meister",
        "Chi-Wang Shu",
        "Davide Torlo"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-16 01:42:29+00:00",
      "link": "https://arxiv.org/pdf/2602.14392v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14309v1",
      "title": "Nonconforming virtual element methods for fourth-order nonlinear reaction-diffusion systems: a unified framework and analysis",
      "abstract": "We develop a unified framework for the design and analysis of high-order nonconforming virtual element methods for nonlinear fourth-order reaction--diffusion problems in two dimensions, with emphasis on clamped, Navier, and Cahn--Hilliard-type boundary conditions. Time discretization is performed using the backward Euler scheme, while the spatial approximation relies on nonconforming virtual element spaces of arbitrary order $k \\ge 2$, encompassing both $C^0$-nonconforming and Morley-type methods. A key contribution of this work is the development of a novel and rigorous unified error analysis for these numerical schemes, applicable to domains that are not necessarily convex, differing from the existing literature. By introducing a class of Companion operators, we construct novel Ritz-type projections and derive a new error equation that enables us to obtain optimal error estimates for the scheme under a minimal spatial regularity assumption on the weak solution. Finally, we present numerical experiments on polygonal meshes as applications of the proposed framework, including the extended Fisher--Kolmogorov equation, and a fourth-order model with Cahn--Hilliard-type boundary conditions, which validate the theoretical results and illustrate the performance of the method for the three classes of boundary conditions.",
      "authors": [
        "Dibyendu Adak",
        "David Mora",
        "Alberth Silgado"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-15 20:54:59+00:00",
      "link": "https://arxiv.org/pdf/2602.14309v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14241v1",
      "title": "On the maximum $σ$-irregularity of trees with given order and maximum degree",
      "abstract": "The $σ$-irregularity index of a graph is defined as the sum of squared degree differences over all edges and provides a sensitive measure of structural heterogeneity. In this paper, we study the problem of maximizing $σ(T)$ among all trees of fixed order $n$ and prescribed maximum degree $Δ\\ge4$. By expressing the problem in terms of edge--degree multiplicities, we derive a linear programming formulation and analyze its dual. This approach yields sharp upper bounds for $σ(T)$ and leads to a detailed description of extremal degree--pair distributions. We show that the extremal problem can be completely resolved for the congruence classes $n\\equiv1\\pmodΔ$ and $n\\equiv0\\pmodΔ$. When $n\\equiv1\\pmodΔ$, the linear program admits an integral optimal solution, and the bound for $σ(T)$ is tight. When $n\\equiv0\\pmodΔ$, the linear relaxation is not attainable by any tree; nevertheless, by introducing a penalty function derived from dual slack variables, we determine the exact maximum value of $σ(T)$. In both cases, all extremal trees are characterized explicitly and consist exclusively of vertices of degrees $1$, $2$, and $Δ$, with edges incident to $Δ$-vertices playing a dominant role.",
      "authors": [
        "Milan Bašić"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-02-15 17:32:32+00:00",
      "link": "https://arxiv.org/pdf/2602.14241v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14227v1",
      "title": "Nonlocal logistics and nonlinear productions in an attraction-repulsion chemotaxis model: analysis of the global well-posedness",
      "abstract": "This paper investigates a {three-component} chemotaxis system involving both attraction and repulsion effects, as well as a nonlocal logistic-type source term. Mathematically, if $u=u(x,t)$, $v = v(x,t)$ and $w = w(x,t)$ denote the cell distribution, and the attractive and the repulsive chemical signals, the model is then described by   \\begin{equation*}   \\begin{cases}   u_t = Δu - χ\\nabla \\cdot (u \\nabla v) + ξ\\nabla \\cdot (u \\nabla w) + a u^α- b u^α\\int_Ωu^β, & x \\in Ω, \\ t > 0,   τv_t = Δv - v + f(u), & x \\in Ω, \\ t > 0,   τw_t = Δw - w + g(u), & x \\in Ω, \\ t > 0.   \\end{cases}   \\end{equation*}   Here, $Ω\\subset \\mathbb{R}^n$ ($n \\geq 1$) is a bounded smooth domain, $τ\\in\\{0,1\\}$, $a,b,α,β,χ,ξ>0$, the production functions $f(u)$ and $g(u)$ are assumed to satisfy algebraic growth conditions of order $\\ell$ and $ρ$, generalizing prototypes of the form $u^\\ell$ and $u^ρ$, $\\ell,ρ>0$. The work is devoted to proving the global existence and boundedness of classical solutions under a suitable balance between the signal production exponents $\\ell, ρ$ and the nonlocal damping exponents $α, β$, for regular enough initial data and zero-flux boundary restrictions. In this regard, two main theorems are established for the cases where the chemical signals satisfy either elliptic ($τ=0$) or parabolic ($τ=1$) partial differential equations, highlighting how sufficiently strong nonlocal damping prevents the formation of singularities in time.   We extend the results obtained in [Chiyo et al., Appl. Math. Optim. 89:9 (2024)], where the fully parabolic ($τ=1$) and only attraction version is studied. In our context, we establish well-posedness of the system and the long-time behavior of solutions.",
      "authors": [
        "Rafael Díaz Fuentes",
        "María Victoria Redondo Neble",
        "Giuseppe Viglialoro"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-15 16:49:00+00:00",
      "link": "https://arxiv.org/pdf/2602.14227v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14213v1",
      "title": "On the levels of rational regular orthogonal matrices for generalized cospectral graphs",
      "abstract": "For an $n$-vertex graph $G$ with adjacency matrix $A$, the walk matrix $W(G)$ of $G$ is the matrix $[e,Ae,\\ldots,A^{n-1}e]$, where $e$ is the all-ones vector. Suppose that $W(G)$ is nonsingular and $p$ is an odd prime such that $W(G)$ has rank $n-1$ over the finite field $\\mathbb{Z}/p\\mathbb{Z}$. Let $H$ be a graph that is generalized cospectral with $G$, and $Q$ be the corresponding rational regular orthogonal matrix satisfying $Q^\\mathsf{T} A(G) Q=A(H)$. We prove that   \\begin{equation*}   v_p(\\ell(Q))\\le \\frac{1}{2}v_p (\\det W(G))   \\end{equation*}   where $\\ell(Q)$ is the minimum positive integer $k$ such that $kQ$ is an integral matrix, and $v_p(m)$ is the maximum nonnegative integer $s$ such that $p^s$ divides $m$. This significantly improves upon a recent result of Qiu et al. [Discrete Math. 346 (2023) 113177] stating that   $v_p(\\ell(Q))\\le v_p (\\det W(G))-1.$",
      "authors": [
        "Wei Wang",
        "Jiaojiao Luo",
        "Li Wang"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-02-15 16:13:18+00:00",
      "link": "https://arxiv.org/pdf/2602.14213v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14156v1",
      "title": "Stable representations of Hamilton-Jacobi-Bellman equations with infinite horizon",
      "abstract": "In this paper, for the Hamilton-Jacobi-Bellman equation with an infinite horizon and state constraints, we construct a suitably regular representation. This allows us to reduce the problem of existence and uniqueness of solutions to the Frankowska and Basco theorem from (2019). Furthermore, we demonstrate that our representations are stable. The obtained results are illustrated with examples.",
      "authors": [
        "Arkadiusz Misztela",
        "Sławomir Plaskacz"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-15 14:13:20+00:00",
      "link": "https://arxiv.org/pdf/2602.14156v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14136v1",
      "title": "Comparative Evaluation of SDP, SOCP, and QC Convex Relaxations for Large-Scale Market-Based AC Optimal Power Flow",
      "abstract": "The alternating current optimal power flow (ACOPF) problem is central to modern power system operations, determining how electricity is generated and transmitted to maximize social welfare while respecting physical and operational constraints. However, the nonlinear and non-convex nature of AC power flow equations makes finding globally optimal solutions computationally intractable for large networks. Convex relaxations - including semidefinite programming (SDP), second-order cone programming (SOCP), and quadratic convex (QC) formulations - provide tractable alternatives that can yield provably optimal or near-optimal solutions under appropriate conditions. This paper presents a comprehensive comparative study of multiple ACOPF relaxations applied to market-based welfare maximization. We implement DCOPF, Shor's SDP relaxation (complex and real-valued forms), chordal SDP, Jabr's SOCP relaxation, and QC relaxations in a unified, solver-native framework using the MOSEK Fusion API, eliminating modeling overhead present in high-level frameworks such as CVXPY. To address the practical challenge of missing or overly conservative angle difference bounds required by QC relaxations, we employ quasi-Monte Carlo sampling with Sobol sequences to empirically estimate tighter bounds. We evaluate these relaxations on subnetworks of varying sizes derived from the ARPA-E dataset, systematically comparing solution quality, runtime, and memory consumption. Our results demonstrate the trade-offs between relaxation tightness and computational efficiency, providing practical guidance for selecting appropriate formulations based on network scale and solution requirements.",
      "authors": [
        "Ata Keskin"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-15 13:17:22+00:00",
      "link": "https://arxiv.org/pdf/2602.14136v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14126v1",
      "title": "Revisiting the Algebraic and Analytic Descriptions of Quantum Mechanics",
      "abstract": "We study Heisenberg's matrix mechanics within an algebraic pre-Hilbert framework of arbitrary finite dimension. The commutator of the position and momentum matrices naturally generates a third Hermitian operator whose unbounded character originates from boundary contributions and whose structure induces a discrete analogue of the Cauchy-Hilbert kernel. Compared with the separable Hilbert-space completion, the algebraic framework reproduces the standard spectra, canonical commutation relations, and Heisenberg uncertainty relation for finite-energy states, while the discrete kernel is absorbed into its continuous integral counterpart under completion. The comparison shows that both formulations require restrictions on admissible states for effective calculations -- analytic domain restrictions in Hilbert space and finite-energy restrictions in the pre-Hilbert framework. Finally, we discuss to what extent quantum randomness arises from the algebraic structure of the pre-Hilbert framework.",
      "authors": [
        "Ortwin Fromm",
        "Felicitas Ehlen"
      ],
      "primary_category": "math.QA",
      "categories": [
        "math.QA"
      ],
      "published": "2026-02-15 12:58:54+00:00",
      "link": "https://arxiv.org/pdf/2602.14126v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14105v1",
      "title": "Non-Hermitian Quantum Mechanics of Open Quantum Systems: Revisiting The One-Body Problem",
      "abstract": "We review analyses of open quantum systems. We show how non-Hermiticity arises in an open quantum system with an infinite environment, focusing on the one-body problem. One of the reasons for taking the present approach is that we can solve the problem completely, making it easier to see the structures of problems involving open quantum systems. We show that this results in the discovery of a new complete set, which is one of the main topics of the present article. Another reason for focusing on the one-body problem is that the theory permits the strong coupling between the system and the environment. In the current research landscape, it is valuable to revisit the one-body problem for open quantum systems, which can be solved accurately for arbitrary strengths of the system-environment couplings. A rigorous understanding of the problem structures in the present approach will be helpful when we tackle problems with many-body interactions. First, we consider potential scattering and directly define the resonant state as an eigenstate of the Schrödinger equation under the Siegert outgoing boundary condition. We show that the resonant eigenstate can have a complex energy eigenvalue, even though the Hamiltonian is seemingly Hermitian. Second, we introduce the Feshbach formalism, which eliminates the infinite degrees of freedom of the environment and represents its effect as a complex potential. The resulting effective Hamiltonian is explicitly non-Hermitian. By unifying these two ways of defining resonant states, we obtain a new complete set of bases for the scattering problem that contains all discrete eigenstates, including resonant states. We finally mention the non-Markovian dynamics of open quantum systems. We emphasize the time-reversal symmetry of the dynamics that continuously connects the past and the future. We can capture it using the new complete set that we develop here.",
      "authors": [
        "Naomichi Hatano",
        "Gonzalo Ordonez"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "math-ph",
        "nucl-th"
      ],
      "published": "2026-02-15 11:42:18+00:00",
      "link": "https://arxiv.org/pdf/2602.14105v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14072v1",
      "title": "Liouville theorems for conformal $Q$-curvature equations",
      "abstract": "In this paper, we study the non-existence of positive solutions for the following conformal $Q$-curvature equation \\begin{equation*} (-Δ)^σu = K(x) u^{\\frac{n+2σ}{n-2σ}} \\quad \\text{in } \\mathbb{R}^n, \\end{equation*} where $ σ\\in (0, n/2)$ is a real number. When $σ=1$, this equation reduces to the well-known scalar curvature equation arising from the prescribed scalar curvature problem. For general $σ\\in (0, n/2)$, it appears in the study of prescribing $Q$-curvature. We establish Liouville theorems under various assumptions on the $Q$-curvature $K(x)$ by developing a unified approach applicable to all $σ\\in (0, n/2)$. Our method successfully addresses the challenges posed by the absence of ODE tools in the fractional regime and the lack of a classification of Delaunay-type singular solutions for the general fractional Yamabe equation.",
      "authors": [
        "Meiqing Xu",
        "Hui Yang"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-15 09:43:10+00:00",
      "link": "https://arxiv.org/pdf/2602.14072v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14070v1",
      "title": "Existence for the Discrete Nonlinear Fragmentation Equation with Degenerate Diffusion",
      "abstract": "A mathematical model for the discrete nonlinear fragmentation (collision-induced breakage) equation with diffusion is studied. The existence of global weak solutions is established in arbitrary spatial dimensions without assuming a strictly positive lower bound on the diffusion coefficients, extending previous results that were restricted to one-dimensional domains and relied on uniformly positive diffusion. The analysis is carried out under boundedness assumptions on the collision and breakage kernels. The proof is based on the construction of a suitable regularized system, combined with weak $L^2$ a priori estimates and compactness arguments in $L^1$, which allow the passage to the limit in the nonlinear fragmentation operator.",
      "authors": [
        "Saumyajit Das",
        "Ram Gopal Jaiswal"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-15 09:40:06+00:00",
      "link": "https://arxiv.org/pdf/2602.14070v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14064v1",
      "title": "Interior Hessian estimates for Hessian quotient equations in dimension three",
      "abstract": "In this paper, we establish the interior Hessian estimates for $2$-convex solutions to $\\frac{σ_2}{σ_1} (D^2 u) = ψ(x,u)$ in dimension three. In higher dimensions ($n \\geq 4$), we prove the interior Hessian estimates for semi-convex solutions. We provide a new method to prove the doubling inequality for smooth solutions in dimensions three and four. In higher dimensions ($n\\geq 5$) the doubling inequality is proved under an additional dynamic semi-convexity condition which is the same to that in \\cite{SY2025}. The method also applies to the equation $σ_2 (D^2 u) = ψ(x, u, \\nabla u)$.",
      "authors": [
        "Heming Jiao",
        "Zhenan Sui"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-15 09:24:24+00:00",
      "link": "https://arxiv.org/pdf/2602.14064v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14047v1",
      "title": "On the Schur-Agler Norm",
      "abstract": "We establish a new description of the Schur-Agler norm of a holomorphic function on the polydisc as the solution of a convex optimization problem. Consequences of this description are explored both from a theoretical and from a practical point of view. Firstly, we give unified proofs of the known facts that the Schur-Agler norm can be tested with diagonalizable or nilpotent matrix tuples, as well as a new proof of the existence of Agler decompositions. Secondly, we describe the predual of the Schur-Agler space as a space of analytic functions on the polydisc. Thirdly, we give a unified treatment of existing counterexamples of von Neumann's inequality in our framework, and exhibit several methods for constructing counterexamples. On the practical side, we explain how the Schur-Agler norm of a homogeneous polynomial can be numerically approximated using semidefinite programming.",
      "authors": [
        "Michael Hartz",
        "Yi Wang"
      ],
      "primary_category": "math.FA",
      "categories": [
        "math.FA",
        "math.CV"
      ],
      "published": "2026-02-15 08:25:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14047v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13986v1",
      "title": "Spectral Theory of Fractional Cooperative Systems and Threshold Dynamics in Epidemic Models",
      "abstract": "Spectral analysis has long been recognized as a fundamental tool for studying the existence, uniqueness, and qualitative behavior of solutions to semilinear elliptic and parabolic equations, as well as their long-time dynamics. In modern mathematics, fractional Laplacians are widely used to model nonlocal or long-range diffusion processes arising in biology, including anomalous movement, long-distance dispersal, and Levy-flight migration of organisms, cells, and epidemics.   In this paper, we employ the spectral fractional Laplacian introduced by Caffarelli and Stinga (2016) to develop the eigentheory for a cooperative system describing an infectious epidemic process and to analyze its long-term behavior. Using Fredholm theory and related analytical techniques, building in part on ideas of Lam and Lou (2016), we establish a sharp criterion ensuring the existence and simplicity of the principal eigenvalue, together with variational characterizations and consequences for the validity of maximum principles. We further derive the asymptotic behavior of the principal eigenvalue with respect to diffusion coefficients, fractional orders, and domain scaling, complementing recent developments by Zhao and Ruan (2023) and Feng, Li, Ruan, and Xin (2024).   As an application of this spectral framework, we prove the existence, uniqueness, and threshold-type long-time dynamics of solutions to an endemic reaction-diffusion system with fractional diffusion, providing a perspective that differs from earlier approaches such as Hsu and Yang (2013). Our results contribute to the growing interaction between spectral theory and nonlocal analysis, in line with recent advances in the area.",
      "authors": [
        "Cong-Bang Trang",
        "Hoang-Hung Vo"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-15 04:42:36+00:00",
      "link": "https://arxiv.org/pdf/2602.13986v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13978v1",
      "title": "Constrained variational problems on perturbed lattice graphs",
      "abstract": "In this paper, we solve some constrained variational problems on perturbed lattice graphs $G$. The first problem addresses the existence of ground state normalized solutions to Schrödinger equations   \\begin{equation*} \\left\\{   \\begin{aligned}   &-Δ_{G} u+λu=\\vert u\\vert^{p-2}u,x\\in G   &\\Vert u\\Vert_{l^2(G)}^2=a.   \\end{aligned}   \\right. \\end{equation*} We prove that if the graph is obtained by deleting finite edges in lattice graphs while maintaining connectivity, then there exists a threshold $α_G\\in[0,\\infty)$ such that there do not exist ground state normalized solution if $0<a<α_G$, and there exists a ground state normalized solution if $a>α_G.$ If the graph is obtained by adding finite edges $E^{'}$ to lattice graphs, we prove that there exist $E^{'}$ and $a_1$ such that for all $a>a_1,$ there do not exist ground state normalized solutions.   The second problem concerns the existence of an extremal function for the Sobolev inequality. If the graph $G$ is obtained by deleting finite edges in lattice graphs while maintaining connectivity, for the Sobolev super-critical regime, we prove that there exists an extremal function. for the Sobolev critical regime, we prove that there exists $G$ such that extremal can be attained. If the graph is obtained by adding finite edges $E^{'}$ to lattice graphs, we prove that there exists $E^{'}$ such that there does not exist an extremal function.",
      "authors": [
        "Weiqi Guan"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-15 03:55:19+00:00",
      "link": "https://arxiv.org/pdf/2602.13978v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13963v1",
      "title": "Global regularity for axisymmetric, swirl-free solutions of the Euler equation in four dimensions",
      "abstract": "In this paper, we prove global regularity for all smooth, axisymmetric, swirl-free solutions of the Euler equation in four dimensions. Previous works establishing global regularity for certain axisymmetric, swirl-free solutions of the Euler equation in four dimensions required the additional assumption that $\\frac{ω^0}{r^2}\\in L^\\infty$, which can fail even for Schwartz class solutions. The key advance is a new bound on the vortex stretching term that only requires $\\frac{ω^0}{r^2}\\in L^{2,1}(\\mathbb{R}^4)$, which is generically true for any axisymmetric, swirl-free initial data $u^0\\in H^s\\left(\\mathbb{R}^4\\right), s>4$, with reasonable decay at infinity.",
      "authors": [
        "Evan Miller"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-15 02:48:59+00:00",
      "link": "https://arxiv.org/pdf/2602.13963v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13876v1",
      "title": "Quantum computation and quantum error correction: the theoretical minimum",
      "abstract": "These notes introduce quantum computation and quantum error correction, emphasising the importance of stabilisers and the mathematical foundations in basic Lie theory. We begin by using the double cover map $\\mathrm{SU}_2 \\rightarrow \\mathrm{SO}_3(\\mathbb{R})$ to illustrate the distinction between states and measurements for a single qubit. We then discuss entanglement and CNOT gates, the Deutsch--Jozsa Problem, and finally quantum error correction, using the Steane $[[7,1,3]]$-code as the main example. The necessary background physics of unitary evolution and Born rule measurements is developed as needed. The circuit model is used throughout.",
      "authors": [
        "Mark Wildon"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "math-ph"
      ],
      "published": "2026-02-14 20:29:58+00:00",
      "link": "https://arxiv.org/pdf/2602.13876v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13809v1",
      "title": "A survey on the uniform $S$-version of rings, modules and their homological theories",
      "abstract": "This survey provides a comprehensive overview of the recent advancements in the theory of ``uniformly $S$''-algebraic structures in commutative ring theory. Originating from the classical concepts of Noetherian, coherent, von Neumann regular, and semisimple rings, the introduction of a multiplicative subset $S$ has led to the development of $S$-Noetherian, $S$-coherent, and other $S$-analogues. However, the element $s \\in S$ in the original definitions often depends on the ideal or module under consideration. To overcome this limitation and enable deeper module-theoretic characterizations, the notion of \"uniformly $S$\" (abbreviated as $u$-$S$) was introduced. This survey systematically presents the definitions, characterizations, and properties of $u$-$S$-torsion modules, $u$-$S$-exact sequences, and the subsequent uniform analogues of fundamental module classes: $u$-$S$-finitely presented, $u$-$S$-Noetherian, $u$-$S$-coherent, $u$-$S$-flat, $u$-$S$-projective, $u$-$S$-injective, and $u$-$S$-absolutely pure modules. We then explore the associated uniform homological dimensions, including the $u$-$S$-weak global dimension, the $u$-$S$-global dimension, and their interplay with polynomial rings and localizations. The survey also covers structural ring classes such as $u$-$S$-von Neumann regular, $u$-$S$-semisimple, $u$-$S$-Artinian, $u$-$S$-multiplication rings, and rings with $u$-$S$-Noetherian spectrum.",
      "authors": [
        "Xiaolei Zhang",
        "Wei Qi"
      ],
      "primary_category": "math.AC",
      "categories": [
        "math.AC"
      ],
      "published": "2026-02-14 14:43:17+00:00",
      "link": "https://arxiv.org/pdf/2602.13809v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13786v1",
      "title": "A hybridizable discontinuous Galerkin method for the Ostrovsky equation",
      "abstract": "This paper develops the hybridizable discontinuous Galerkin (HDG) method for the Ostrovsky equation, a nonlinear dispersive wave equation featuring both third-order dispersion and a nonlocal antiderivative term with Coriolis effect. On a bounded interval, the nonlocal operator $\\partial_x^{-1}$ is localized through an auxiliary variable $v$ satisfying $v_x=u$ together with an additional boundary constraint that ensures uniqueness. We employ a mixed first-order formulation to decompose the dispersive operator and to localize the nonlocal term, and we couple the resulting semi-discrete HDG scheme with a $θ$-time stepping method for $θ\\in [1/2,1]$. We prove $L^2$-stability for suitable stabilization parameters and derive an {\\it a priori} $L^2(Ω)$ error estimate for smooth solutions that explicitly accounts for the nonlinear convective flux.   Numerical examples illustrate the convergence properties and demonstrate the scheme's capability to handle smooth and non-smooth solutions, including solitary wave propagation and peaked solitary wave (peakon) propagation in the zero dispersive limit regime.",
      "authors": [
        "Mukul Dwivedi",
        "Andreas Rupp"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-14 14:05:56+00:00",
      "link": "https://arxiv.org/pdf/2602.13786v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13753v1",
      "title": "Entire solutions to a strongly competitive nonlinear Schrödinger system",
      "abstract": "We build infinitely-many non-radial positive solutions to the Schrödinger system \\begin{equation*} \\left\\{\\begin{aligned} &-Δu_1+u_1=u_1^{{\\mathfrak p} }-Λu_1^{a_1} u_2^{a_2}\\ \\hbox{in}\\ \\mathbb R^N\\\\ &-Δu_2+u_2=u_2^{{\\mathfrak p} }-Λu_1^{b_1}u_2^{b_2} \\ \\hbox{in}\\ \\mathbb R^N\\\\ \\end{aligned}\\right. \\end{equation*} with sub-critical $\\mathfrak p$-growth as $Λ\\to +\\infty$. The profile of each component is the sum of several copies of the positive solution to $-ΔU+U=U^{{\\mathfrak p} }$ in $\\mathbb R^N$, centered at suitable {\\em peaks} whose mutual distances diverge as $Λ$ increases. More precisely, given two concentric regular polygons with $k$ sides and very large radii, the peaks of the first component are arranged along the edges of the {\\em outer} polygon, alternated with those of the second component, and along the $k$ rays joining the vertices of the two polygons. To the best of our knowledge, this provides the first example of non-radial positive solutions for strongly competitive Schrödinger systems in the whole space.",
      "authors": [
        "Pierpaolo Esposito",
        "Pablo Figueroa",
        "Angela Pistoia",
        "Giusi Vaira"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-14 12:53:39+00:00",
      "link": "https://arxiv.org/pdf/2602.13753v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15068v1",
      "title": "A Unified Benchmark of Physics-Informed Neural Networks and Kolmogorov-Arnold Networks for Ordinary and Partial Differential Equations",
      "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful mesh-free framework for solving ordinary and partial differential equations by embedding the governing physical laws directly into the loss function. However, their classical formulation relies on multilayer perceptrons (MLPs), whose fixed activation functions and global approximation biases limit performance in problems with oscillatory behavior, multiscale dynamics, or sharp gradients. In parallel, Kolmogorov-Arnold Networks (KANs) have been introduced as a functionally adaptive architecture based on learnable univariate transformations along each edge, providing richer local approximations and improved expressivity. This work presents a systematic and controlled comparison between standard MLP-based PINNs and their KAN-based counterparts, Physics-Informed Kolmogorov-Arnold Networks (PIKANs), using identical physics-informed formulations and matched parameter budgets to isolate the architectural effect. Both models are evaluated across a representative collection of ODEs and PDEs, including cases with known analytical solutions that allow direct assessment of gradient reconstruction accuracy. The results show that PIKANs consistently achieve more accurate solutions, converge in fewer iterations, and yield superior gradient estimates, highlighting their advantage for physics-informed learning. These findings underline the potential of KAN-based architectures as a next-generation approach for scientific machine learning and provide rigorous evidence to guide model selection in differential equation solving.",
      "authors": [
        "Salvador K. Dzimah",
        "Sonia Rubio Herranz",
        "Fernando Carlos Lopez Hernandez",
        "Antonio López Montes"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-14 11:58:40+00:00",
      "link": "https://arxiv.org/pdf/2602.15068v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13729v1",
      "title": "Semi-supervised linear regression with missing covariates",
      "abstract": "Missing values in datasets are common in applied statistics. For regression problems, theoretical work thus far has largely considered the issue of missing covariates as distinct from missing responses. However, in practice, many datasets have both forms of missingness. Motivated by this gap, we study linear regression with a labelled dataset containing missing covariates, potentially alongside an unlabelled dataset. We consider both structured (blockwise-missing) and unstructured missingness patterns, along with sparse and non-sparse regression parameters. For the non-sparse case, we provide an estimator based on imputing the missing data combined with a reweighting step. For the high-dimensional sparse case, we use a modified version of the Dantzig selector. We provide non-asymptotic upper bounds on the risk of both procedures. These are matched by several new minimax lower bounds, demonstrating the rate optimality of our estimators. Notably, even when the linear model is well-specified, our results characterise substantial differences in the minimax rates when unlabelled data is present relative to the fully supervised setting. Particular consequences of our sparse and non-sparse results include the first matching upper and lower bounds on the minimax rate for the supervised setting when either unstructured or structured missingness is present. Our theory is coupled with extensive simulations and a semi-synthetic application to the California housing dataset.",
      "authors": [
        "Benedict M. Risebrow",
        "Thomas B. Berrett"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "stat.ME"
      ],
      "published": "2026-02-14 11:41:48+00:00",
      "link": "https://arxiv.org/pdf/2602.13729v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13674v1",
      "title": "An Operator Approach to the Integration of Linear Differential Equations",
      "abstract": "We develop an operator approach to the integration of linear differential equations based on intertwining relations between differential operators. Conditions for the existence of intertwining operators are obtained, and it is shown that, in low-order cases, the problem reduces to Riccati-type equations. The method is applied to linear partial differential equations, which makes it possible to construct their solutions. The linear Klein--Gordon equation is presented as an illustrative example.",
      "authors": [
        "O. V. Kaptsov"
      ],
      "primary_category": "math-ph",
      "categories": [
        "math-ph"
      ],
      "published": "2026-02-14 08:54:19+00:00",
      "link": "https://arxiv.org/pdf/2602.13674v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13673v1",
      "title": "Data-driven macroscopic dynamics of complex networks using Topological Data Analysis and the Equation-Free Method",
      "abstract": "In this work, we present a computational framework for exploring and analyzing the macroscopic dynamics of complex agent-based network models by integrating Topological Data Analysis with the Equation-Free Method. To demonstrate the effectiveness of our method, we apply it to Erdős--Rényi-type random networks. Central to our approach is a Topological Data Analysis-based filtration process driven by the density of activated network nodes (agents), from which we extract a coarse-grained macroscopic topological observable. This observable is defined via persistent Betti numbers, thus requiring significantly reduced data dimensionality while retaining essential topological features. Subsequently, within the Equation-Free Method framework, we show firstly that a \\textit{lifting procedure} can be achieved using topological properties and secondly, a data-driven evolution law that governs the dynamics of this macroscopic variable. Finally, we perform a numerical bifurcation and stability analysis to investigate the global behavior and qualitative transitions of the emergent macroscopic dynamics.",
      "authors": [
        "Konstantinos Spiliotis",
        "Ole Sönnerborn",
        "Haralampos Hatzikirou",
        "Nikos I. Kavallaris"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS"
      ],
      "published": "2026-02-14 08:47:18+00:00",
      "link": "https://arxiv.org/pdf/2602.13673v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13612v1",
      "title": "A Formula for Time-to-Frequency Wave Boundary Data Conversion by the Boundary Control Method",
      "abstract": "Given the wave equation on a compact Riemannian manifold with boundary, we derive an explicit reconstruction procedure to represent the frequency-domain Neumann-to-Dirichlet map in terms of the time-domain Neumann-to-Dirichlet map at any non-eigenfrequency. If the wave equation is exactly controllable, we derive an explicit formula to compute the former from the latter. The derivation is based on the boundary control method and requires only knowledge on the boundary of the manifold. The formula is stable when the level of regularization is fixed. The numerical feasibility is validated using one-dimensional examples in both Euclidean and non-Euclidean geometries.",
      "authors": [
        "Yang Yang"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-14 05:58:10+00:00",
      "link": "https://arxiv.org/pdf/2602.13612v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13589v1",
      "title": "Painlevé XXXIV asymptotics for the defocusing nonlinear Schrödinger equation with a finite-genus algebro-geometric background",
      "abstract": "In this paper, we consider the Cauchy problem for the defocusing nonlinear Schr$\\ddot{\\text{o}}$dinger equation with a finite genus algebro-geometric background. Long-time asymptotics of the solution are derived in four space-time regions. It comes out that the leading-order term in the expansion is, up to a constant, given by the background solution with a shift of the parameter. The subleading term, however, decays at different rates for different regions. We particularly highlight that in the two transition regions, they are of order $\\mathcal{O}(t^{-1/3})$ and the coefficients involve an integral of the Painlevé XXXIV transcendent. We establish our results by applying a nonlinear steepest descent analysis to the associated Riemann-Hilbert problems.",
      "authors": [
        "Engui Fan",
        "Gaozhan Li",
        "Yiling Yang",
        "Lun Zhang"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "math-ph",
        "nlin.SI"
      ],
      "published": "2026-02-14 04:12:35+00:00",
      "link": "https://arxiv.org/pdf/2602.13589v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13561v1",
      "title": "Caputo mean-square attractors for non-autonomous stochastic differential equations",
      "abstract": "This paper investigates Caputo mean-square attractors for non-autonomous stochastic evolution systems. We first introduce the concept of Caputo mean-square attractors and then establish a sufficient criterion for existence of such attractors.As an application, we consider a non-autonomous Caputo fractional stochastic differential equation of order $α\\in (\\frac{1}{2},1)$ in $L^2(Ω; \\mathbb{R}^d)$ with a driving system on a compact base space $P$ and tempered fractional noise.It is shown that this equation generates a Caputo mean-square random semi-dynamical system on $\\mathfrak{C} \\times P$ with a skew-product semi-flow structure,where $\\mathfrak{C}$ denotes the space of continuous functions $f\\in \\mathbb{R}^{+}\\rightarrow L^2(Ω; \\mathbb{R}^d)$. Under suitable conditions, we prove that this semi-dynamical system admits a Caputo mean-square attractor.",
      "authors": [
        "Lijuan Zhang",
        "Jianhua Huang",
        "Yejuan Wang"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS",
        "math.PR"
      ],
      "published": "2026-02-14 02:37:11+00:00",
      "link": "https://arxiv.org/pdf/2602.13561v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13526v1",
      "title": "Classification of (frustrated) 2D Ising models in genus 1",
      "abstract": "We prove a complete classification of all 2D Ising models, frustrated or not, whose underlying spectral curve has genus 1. As a specific case, we recover Baxter's $Z$-invariant Ising model, thus extending his class of models to \\emph{real} coupling constants. We identify two additional families of models, both having \\emph{non}-Harnack spectral curves. We show that in all cases the spectral curve is maximal. Moreover, each family undergoes an algebraic phase transition as the genus of the curve tends to 0, explaining the different behaviors observed in the physics literature. In our proof, we use properties of the spectral curve, and Fock's approach. This yields a natural framework for a further systematic study of the frustrated Ising model, in particular for proving local formulas. As an example of application, we prove a full classification of the frustrated Ising model on the triangular lattice.",
      "authors": [
        "Béatrice de Tilière",
        "Lucas Rey"
      ],
      "primary_category": "math-ph",
      "categories": [
        "math-ph"
      ],
      "published": "2026-02-13 23:36:01+00:00",
      "link": "https://arxiv.org/pdf/2602.13526v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13514v1",
      "title": "Distributed Edge Computing Task Allocation with Network Effects",
      "abstract": "Field-deployable edge computing nodes form a network and are used to complete scientific tasks for remote sensing and monitoring. The networked nodes collectively decide which scientific applications to run while they are constrained by various factors, such as differing hardware constraints from heterogeneous nodes and time-varying quality of service (QoS) requirements. We model the problem of task allocation as an optimization problem that maximizes the QoS, subject to the constraints. We solve the optimization problem using a dual-descent method, which can be easily implemented in a distributed way subject to the communication constraints of the network. Using a simulation that uses real-world data collected from Sage, a distributed sensor network, we analyze our policy's performance in dynamic situations where the required QoS and the nodes' capabilities change, and verify that it can adapt and return a feasible solution while accounting for those changes.",
      "authors": [
        "Henry Abrahamson",
        "Yongho Kim",
        "Seongha Park",
        "Ermin Wei"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-13 22:58:01+00:00",
      "link": "https://arxiv.org/pdf/2602.13514v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13386v1",
      "title": "Entanglement in quantum spin chains is strictly finite at any temperature",
      "abstract": "Entanglement is the hallmark of quantum physics, yet its characterization in interacting many-body systems at thermal equilibrium remains one of the most important challenges in quantum statistical physics. We prove that the Gibbs state of any quantum spin chain can be exactly decomposed into a mixture of matrix product states with a bond dimension that is independent of the system size, at any finite temperature. As a consequence, the Schmidt number, arguably the most stringent measure of bipartite entanglement, is strictly finite for thermal states, even in the thermodynamic limit. Our decomposition is explicit and is accompanied by an efficient classical algorithm to sample the resulting matrix product states.",
      "authors": [
        "Ainesh Bakshi",
        "Soonwon Choi",
        "Saúl Pilatowsky-Cameo"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.stat-mech",
        "math-ph"
      ],
      "published": "2026-02-13 19:00:00+00:00",
      "link": "https://arxiv.org/pdf/2602.13386v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13169v1",
      "title": "Operator Learning for Families of Finite-State Mean-Field Games",
      "abstract": "Finite-state mean-field games (MFGs) arise as limits of large interacting particle systems and are governed by an MFG system, a coupled forward-backward differential equation consisting of a forward Kolmogorov-Fokker-Planck (KFP) equation describing the population distribution and a backward Hamilton-Jacobi-Bellman (HJB) equation defining the value function. Solving MFG systems efficiently is challenging, with the structure of each system depending on an initial distribution of players and the terminal cost of the game. We propose an operator learning framework that solves parametric families of MFGs, enabling generalization without retraining for new initial distributions and terminal costs. We provide theoretical guarantees on the approximation error, parametric complexity, and generalization performance of our method, based on a novel regularity result for an appropriately defined flow map corresponding to an MFG system. We demonstrate empirically that our framework achieves accurate approximation for two representative instances of MFGs: a cybersecurity example and a high-dimensional quadratic model commonly used as a benchmark for numerical methods for MFGs.",
      "authors": [
        "William Hofgard",
        "Asaf Cohen",
        "Mathieu Laurière"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "stat.ML"
      ],
      "published": "2026-02-13 18:28:34+00:00",
      "link": "https://arxiv.org/pdf/2602.13169v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13160v1",
      "title": "Structural barriers of the discrete Hasimoto map applied to protein backbone geometry",
      "abstract": "Determining the three-dimensional structure of a protein from its amino-acid sequence remains a fundamental problem in biophysics. The discrete Frenet geometry of the C$_α$ backbone can be mapped, via a Hasimoto-type transform, onto a complex scalar field $ψ=κ\\,e^{i\\sumτ}$ satisfying a discrete nonlinear Schrödinger equation (DNLS), whose soliton solutions reproduce observed secondary-structure motifs. Whether this mapping, which provides an elegant geometric description of folded states, can be extended to a predictive framework for protein folding remains an open question. We derive an exact closed-form decomposition of the DNLS effective potential $V_{\\text{eff}}=V_{\\text{re}}+iV_{\\text{im}}$ in terms of curvature ratios and torsion angles, validating the result to machine precision across 856 non-redundant proteins. Our analysis identifies three structural barriers to forward prediction: (i)~$V_{\\text{im}}$ encodes chirality via the odd symmetry of $\\sinτ$, accounting for ${\\sim}31\\%$ of the total information and implying a $2^N$ degeneracy if neglected; (ii)~$V_{\\text{re}}$ is determined primarily (${\\sim}95\\%$) by local geometry, rendering it effectively sequence-agnostic; and (iii)~self-consistent field iterations fail to recover native structures (mean RMSD $= 13.1$\\,Å) even with hydrogen-bond terms, yielding torsion correlations indistinguishable from zero. Constructively, we demonstrate that the residual of the DNLS dispersion relation serves as a geometric order parameter for $α$-helices (ROC AUC $= 0.72$), defining them as regions of maximal integrability. These findings establish that the Hasimoto map functions as a kinematic identity rather than a dynamical governing equation, presenting fundamental obstacles to its use as a predictive framework for protein folding.",
      "authors": [
        "Yiquan Wang"
      ],
      "primary_category": "q-bio.BM",
      "categories": [
        "q-bio.BM",
        "math-ph",
        "nlin.SI"
      ],
      "published": "2026-02-13 18:16:56+00:00",
      "link": "https://arxiv.org/pdf/2602.13160v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13152v1",
      "title": "Detecting Parameter Instabilities in Functional Concurrent Linear Regression",
      "abstract": "We develop methodology to detect structural breaks in the slope function of a concurrent functional linear regression model for functional time series in $C[0,1]$. Our test is based on a CUSUM process of regressor-weighted OLS residual functions. To accommodate both global and local changes, we propose $L^2$- and sup-norm versions, with the sup-norm particularly sensitive to spike-like changes. Under Hölder regularity and weak dependence conditions, we establish a functional strong invariance principle, derive the asymptotic null distribution, and show that the resulting tests are consistent against a broad class of alternatives with breaks in the slope function. Simulation studies illustrate finite-sample size and power. We apply the method to sports data obtained via body-worn sensors from running athletes, focusing on hip and knee joint-angle trajectories recorded during a fatiguing run. As fatigue accumulates, runners adapt their movement patterns, and sufficiently pronounced adjustments are expected to appear as a change point in the regression relationship. In this manner, we illustrate how the proposed tests support interpretable inference for biomechanical functional time series.",
      "authors": [
        "Rupsa Basu",
        "Sven Otto"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "math.ST"
      ],
      "published": "2026-02-13 18:05:03+00:00",
      "link": "https://arxiv.org/pdf/2602.13152v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13079v1",
      "title": "Multi-physics Preconditioning for Thermally Activated Batteries",
      "abstract": "Thermal batteries, also known as molten-salt batteries, are single-use reserve power systems activated by pyrotechnic heat generation, which transitions the solid electrolyte into a molten state. The simulation of these batteries relies on multiphysics modeling to evaluate performance and behavior under various conditions. This paper presents advancements in scalable preconditioning strategies for the Thermally Activated Battery Simulator (TABS) tool, enabling efficient solutions to the coupled electrochemical systems that dominate computational costs in thermal battery simulations. We propose a hierarchical block Gauss-Seidel preconditioner implemented through the Teko package in Trilinos, which effectively addresses the challenges posed by tightly coupled physics, including charge transport, porous flow, and species diffusion. The preconditioner leverages scalable subblock solvers, including smoothed aggregation algebraic multigrid (SA-AMG) methods and domain-decomposition techniques, to achieve robust convergence and parallel scalability. Strong and weak scaling studies demonstrate the solver's ability to handle problem sizes up to 51.3 million degrees of freedom on 2048 processors, achieving near sub-second setup and solve times for the end-to-end electrochemical solve. These advancements significantly improve the computational efficiency and turnaround time of thermal battery simulations, paving the way for higher-resolution models and enabling the transition from 2D axisymmetric to full 3D simulations.",
      "authors": [
        "Malachi Phillips"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-13 16:41:16+00:00",
      "link": "https://arxiv.org/pdf/2602.13079v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13068v1",
      "title": "Structure preservation using discrete gradients in the Vlasov-Poisson-Landau system",
      "abstract": "We present a novel structure-preserving framework for solving the Vlasov-Poisson-Landau system of equations using a particle in cell (PIC) discretization combined with discrete gradient time integrators. The Vlasov-Poisson-Landau system is an accurate model for studying hot plasma dynamics at a kinetic scale where small-angle Coulomb collisions dominate. Our scheme guarantees conservation of mass, momentum and energy as well as preservation of the monotonicity of entropy production in both the time-continuous and discrete systems. We employ the conservative integrator for both the Hamiltonian Vlasov-Poisson equations and the dissipative Landau equation using the PETSc library (www.mcs.anl.gov/petsc) to showcase structure-preserving properties.",
      "authors": [
        "Daniel S. Finn",
        "Joseph V. Pusztay",
        "Matthew G. Knepley",
        "Mark F. Adams"
      ],
      "primary_category": "physics.plasm-ph",
      "categories": [
        "physics.plasm-ph",
        "math-ph"
      ],
      "published": "2026-02-13 16:23:31+00:00",
      "link": "https://arxiv.org/pdf/2602.13068v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13039v2",
      "title": "A sparse overview on sparse resultants",
      "abstract": "In this survey, we give an overview of advances in the theory and computation of sparse resultants. First, we examine the construction and proof of the Canny-Emiris formula, which gives a rational determinantal formula. Second, we discuss and compare the latter with the computation of the sparse resultant as the determinant of the Koszul complex given by $n + 1$ nef divisors in a toric variety. Finally, we cover techniques for computing the Newton polytope of sparse resultants.",
      "authors": [
        "Carles Checa",
        "Ioannis Z. Emiris",
        "Christos Konaxis"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG"
      ],
      "published": "2026-02-13 15:47:28+00:00",
      "link": "https://arxiv.org/pdf/2602.13039v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13011v1",
      "title": "Signature Varieties of Splines",
      "abstract": "Splines are central objects for the interpolation of discrete data via piecewise smooth paths. Their iterated-integral signature is an infinite collection of tensors which characterizes paths almost uniquely. We study truncations of this collection, which define algebraic maps from parameter space to tensor space. We prove that the images of these maps are given by orbits of a matrix-tensor action. Furthermore, taking the Zariski closure, we define and study varieties of spline signature tensors. We determine dimension and degree of these tensor varieties in a number of examples, relying on symbolic computations. With a view towards learning, constructing paths with a given signature tensor translates to studying the fibers of the signature map. We use computational methods to determine their cardinality, with a focus on its dependence on different classes of splines. We observe in explicit examples that reconstructing splines from a given signature tensor of a path yields close approximations of the original path.",
      "authors": [
        "Carlos Améndola",
        "Felix Lotter",
        "Leonard Schmitz"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "math.AC",
        "math.PR"
      ],
      "published": "2026-02-13 15:19:53+00:00",
      "link": "https://arxiv.org/pdf/2602.13011v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13000v1",
      "title": "A linesearch-type normal map-based semismooth Newton method for nonsmooth nonconvex composite optimization",
      "abstract": "We propose a novel linesearch variant of the trust region normal map-based semismooth Newton method developed in [Ouyang and Milzarek, Math. Program. 212(1-2), 389--435 (2025)] for solving a class of nonsmooth, nonconvex composite-type optimization problems. Our approach uses adaptive parameter estimation techniques, which allow us to avoid explicit and potentially expensive Lipschitz constant computations. We provide extensive convergence results including global convergence, convergence of the iterates under the Kurdyka-Łojasiewicz inequality, and transition to fast local q-superlinear convergence. Compared to the original trust region framework, the linesearch-based algorithm is simpler and the overall convergence analysis can be conducted under weaker assumptions -- in particular, without requiring explicit boundedness conditions on the Hessian approximations and iterates. Numerical experiments on sparse logistic regression, image compression, and nonlinear least squares with group penalty terms demonstrate the efficiency of the proposed approach.",
      "authors": [
        "Hanfeng Zeng",
        "Wenqing Ouyang",
        "Andre Milzarek"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-13 15:09:49+00:00",
      "link": "https://arxiv.org/pdf/2602.13000v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12988v1",
      "title": "Multidimensional Dickman distribution and operator selfdecomposability",
      "abstract": "The one-dimensional Dickman distribution arises in various stochastic models across number theory, combinatorics, physics, and biology. Recently, a definition of the multidimensional Dickman distribution has appeared in the literature, together with its application to approximating the small jumps of multidimensional Lévy processes. In this paper, we extend this definition to a class of vector-valued random elements, which we characterise as fixed points of a specific affine transformation involving a random matrix obtained from the matrix exponential of a uniformly distributed random variable. We prove that these new distributions possess the key properties of infinite divisibility and operator selfdecomposability. Furthermore, we identify several cases where this new distribution arises as a limiting distribution.",
      "authors": [
        "Anastasiia S. Kovtun",
        "Nikolai N. Leonenko",
        "Andrey Pepelyshev"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "math.ST"
      ],
      "published": "2026-02-13 15:00:34+00:00",
      "link": "https://arxiv.org/pdf/2602.12988v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12940v1",
      "title": "Bifurcation curve detection with deflation for multiparametric PDEs",
      "abstract": "This work presents a comprehensive framework for capturing bifurcating phenomena and detecting bifurcation curves in nonlinear multiparametric partial differential equations, where the system exhibits multiple coexisting solutions for given values of the parameters. Traditional continuation methods for one-dimensional parameterizations employ the previously computed solution as the initial guess for the next parameter value. These are usually very inefficient, since small step sizes increase computational cost, while larger steps could jeopardize the method convergence jumping to a different solution branch or missing the bifurcation point. To address these challenges, we propose a novel framework that combines: (i) arclength continuation, adaptively selecting new parameter values in higher dimension, and (ii) the deflation technique, discovering multiple branches to construct complete bifurcation diagrams. In particular, the arclength continuation method is designed to handle multiparametric scenarios, where the parameter vector $λ\\in \\mathbb{R}^p$ traces a curve $g(λ)$ within a $p$-dimensional parameter space. In addition, we introduce a zigzag path-following strategy to robustly track the bifurcation curves and surfaces, respectively, for two- and three-dimensional parametric spaces. Finally, we demonstrate its performance on two benchmark problems: the Bratu equation and the Allen-Cahn equation.",
      "authors": [
        "Nitin Kumar",
        "Federico Pichi",
        "Gianluigi Rozza"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-13 13:54:00+00:00",
      "link": "https://arxiv.org/pdf/2602.12940v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12935v1",
      "title": "A Stochastic Optimal Control Formulation for Mine Counter Measure Simulations with Multiple Autonomous Survey Vehicles",
      "abstract": "Modelling and simulating mine counter measure search missions performed by autonomous vehicles equipped with a sensor capable of detecting mines at sea is a challenging endeavour. To address this, we formulated and implemented the problem as a stochastic optimal control model. Our implementation computes an optimal path within a user chosen quadrilateral domain such that the mission duration is minimized for a given residual risk of undetected sea mines. First, we compare the stochastic optimal control implementation against the traditionally used boustrophedon implementation. We show that the mission duration in case of the stochastic optimal control implementation is shorter. Then, by building on our previous work, we introduce a novel mathematical approach that enables multiple autonomous survey vehicles to investigate the domain concurrently. We present results for up to six vehicles, including computed trajectories and an analysis of how mission duration varies with the number of vehicles. Our findings show that mission time decreases non-linearly, , i.e., we observe diminishing returns as more vehicles are added.",
      "authors": [
        "Philippe Blondeel",
        "Filip Van Utterbeeck",
        "Ben Lauwens"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-13 13:47:20+00:00",
      "link": "https://arxiv.org/pdf/2602.12935v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12886v1",
      "title": "Well-posedness and mean-field limit estimate of a consensus-based algorithm for min-max problems",
      "abstract": "The recent work arXiv:2407.17373 proposes a derivative-free consensus-based particle method that computes global solutions to nonconvex-nonconcave min-max problems and establishes global exponential convergence in the sense of the mean-field law. This paper aims to address the theoretical gaps in arXiv:2407.17373, specifically by providing a quantitative estimate of the mean-field limit with respect to the number of particles, as well as establishing the well-posedness of both the finite particle model and the corresponding mean-field dynamics.",
      "authors": [
        "Hui Huang",
        "Jethro Warnett"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-13 12:38:46+00:00",
      "link": "https://arxiv.org/pdf/2602.12886v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12872v1",
      "title": "Neural Evolutionary Kernel Method: A Knowledge-Guided Framework for Solving Evolutionary PDEs",
      "abstract": "Numerical solution of partial differential equations (PDEs) plays a vital role in various fields of science and engineering. In recent years, deep neural networks (DNNs) have emerged as a powerful tool for solving PDEs, leveraging their approximation capabilities to handle complex domains and high-dimensional problems. Among these, operator learning has gained increasing attention by learning mappings between function spaces using DNNs. This paper proposes a novel approach, termed the Neural Evolutionary Kernel Method (NEKM), for solving a class of time-dependent partial differential equations (PDEs) via deep neural network (DNN)-based kernel representations. By integrating boundary integral techniques with operator learning, prior mathematical information of time-dependent partial differential equations (PDEs) is embedded into the design of neural network architectures for predicting their solutions, enhancing both computational efficiency and solution accuracy. Numerical experiments on the heat, wave, and Schrödinger equations demonstrate that the Neural Evolutionary Kernel Method (NEKM) achieves high accuracy and favorable computational efficiency. Furthermore, the operator learning framework inherently supports the simultaneous prediction of solutions to multiple PDEs with different coefficients, rendering its capability for solving random PDEs.",
      "authors": [
        "Shuo Ling",
        "Wenjun Ying",
        "Zhen Zhang"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-13 12:22:58+00:00",
      "link": "https://arxiv.org/pdf/2602.12872v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13364v1",
      "title": "The Cauchy problem for the generalized KdV equation in the Sobolev space $H^{s}(\\mathbf{R})$",
      "abstract": "In this paper, we are concerned with the Cauchy problem for the generalized KdV equation with random data and rough data. Firstly, when $s\\in\\mathbf{R}$, by using the initial value randomization technique introduced by Shen et al. (arXiv:2111.11935) and the construction of appropriate auxiliary spaces, we establish the almost sure local well-posedness of the generalized KdV equation in $H^{s}(\\mathbf{R})$, which improves Theorem 1.3 of Hwang and Kwak (Proc. Amer. Math. Soc. 146(2018), 267-280.) and Theorem 1.5 of Yan et al.(arXiv:2011.07128.). Secondly, by using the well-posedness results proved in Theorem 1.1, for $f\\in H^{s}(\\mathbf{R}),\\, s\\in\\mathbf{R}$, we obtain \\begin{eqnarray*} &&\\mathbb{P}\\left(\\left\\{ω:\\lim_{t\\rightarrow0}\\|u(t,x)-U(t)f^ω(x)\\|_{L_{x}^{\\infty}}=0\\right\\}\\right)=1, \\end{eqnarray*} which improves Theorem 1.6 of Yan et al.(arXiv:2011.07128.). Thirdly, by using the dyadic decomposition and constructing appropriate function spaces, we establish nonlinear smoothing for the generalized KdV equation with rough data. Furthermore, by using this estimate, when data $f\\in H^{s}(\\mathbf{R})\\cap\\hat{L}^{\\infty}(\\mathbf{R}),\\, s>\\frac{1}{2}-\\frac{2}{k+1},\\, k\\geq4$, we obtain \\begin{eqnarray*} &&\\lim_{|x|\\rightarrow \\infty}u(t,x)=0,\\quad t\\in[0, T]. \\end{eqnarray*} In particular, for $f(x)\\in H^{s}(\\mathbf{R}),\\,s>\\frac{1}{2}-\\frac{2}{k+1},\\,k\\geq4$, we prove \\begin{eqnarray*} &&\\lim_{|x|\\rightarrow \\infty}(u(t,x)-U(t)f(x))=0. \\end{eqnarray*} Finally, by using Theorem 1.1, when $f\\in H^{s}(\\mathbf{R}),\\, s\\in\\mathbf{R}$, we obtain \\begin{eqnarray*} &&\\mathbb{P}\\left(\\left\\{ω: \\forall t\\in I_ω, \\lim_{|x|\\rightarrow \\infty}\\left(u(t,x)-U(t)f^ω(x)\\right)=0\\right\\}\\right)=1. \\end{eqnarray*}",
      "authors": [
        "Xiangqian Yan",
        "Yongsheng Li",
        "Juan Huang",
        "Jianhua Huang",
        "Wei Yan"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-13 12:18:14+00:00",
      "link": "https://arxiv.org/pdf/2602.13364v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12867v1",
      "title": "Parametric Biobjective Linear Programming",
      "abstract": "We consider parametric linear programming problems with multiple objective functions depending linearly on some parameter. Both parametric (single-objective) linear programming and (non-parametric) multi-objective linear programming are well-researched topics. However, literature on the combination of both, parametric linear programming with multiple objectives, is scarce. This research gap encourages our work in this field. Our main focus is on biobjective linear programs with a single parameter. We establish a connection of this problem to non-parametric multi-objective problems. Using the so-called weight set decomposition, we are able to explain the behavior of parametric biobjective linear programs when the parameter value is variated. We investigate two special cases of parametric biobjective linear programs: In the first, there is only one parametric objective and, in the second, the parametric dependency is the same for both objectives. We prove that there is a one-to-one correspondence between the solution of the parametric program and the solution of the triobjective program using the weighted sum scalarization. We provide structural insights to the solution of the parametric biobjective linear program with respect to extreme weights of the weight set of the triobjective linear program and develop solution strategies for the parametric program.",
      "authors": [
        "Kezang Yuden",
        "Levin Nemesch",
        "Stefan Ruzika"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-13 12:17:13+00:00",
      "link": "https://arxiv.org/pdf/2602.12867v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12816v1",
      "title": "Finite Difference Method for Stochastic Cahn-Hilliard Equation Driven by A Fractional Brownian Sheet",
      "abstract": "The stochastic Cahn-Hilliard equation driven by a fractional Brownian sheet provides a more accurate model for correlated space-time random perturbations. This study delves into two key aspects: first, it rigorously examines the regularity of the mild solution to the stochastic Cahn-Hilliard equation, shedding light on the intricate behavior of solutions under such complex perturbations. Second, it introduces a fully discrete numerical scheme designed to solve the equation effectively. This scheme integrates the finite difference method for spatial discretization with the tamed exponential Euler method for temporal discretization. The analysis demonstrates that the proposed scheme achieves a strong convergence rate of $O\\big(h^{1-ε}+τ^{H_1-\\frac{1}{8}-\\fracε{2}}\\big)$, where $ε$ is an arbitrarily small positive constant, providing a solid foundation for the numerical treatment of such equations.",
      "authors": [
        "Nan Deng",
        "Wanrong Cao"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "math.PR"
      ],
      "published": "2026-02-13 11:00:22+00:00",
      "link": "https://arxiv.org/pdf/2602.12816v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12736v1",
      "title": "Graph bootstrap percolation -- a discovery of slowness",
      "abstract": "Graph bootstrap percolation is a discrete-time process capturing the spread of a virus on the edges of $K_n$. Given an initial set $G\\subseteq K_n$ of infected edges, the transmission of the virus is governed by a fixed graph $H$: in each round of the process any edge $e$ of $K_n$ that is the last uninfected edge in a copy of $H$ in $K_n$ gets infected as well. Once infected, edges remain infected forever. The process was introduced by Bollobás in 1968 in the context of weak saturation and has since inspired a vast array of beautiful mathematics. The main focus of this survey is the extremal question of how long the infection process can last before stabilising. We give an exposition of our recent systematic study of this maximum running time and the influence of the infection rule $H$. The topic turns out to possess a wide variety of interesting behaviour, with connections to additive, extremal and probabilistic combinatorics. Along the way we encounter a number of surprises and attractive open problems.",
      "authors": [
        "David Fabian",
        "Patrick Morris",
        "Tibor Szabó"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "math.PR"
      ],
      "published": "2026-02-13 09:05:18+00:00",
      "link": "https://arxiv.org/pdf/2602.12736v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12718v1",
      "title": "Pro-Algebraic Site",
      "abstract": "For any type of fundamental groupoid scheme, we construct an algebraic cohomology theory for varieties with coefficients in the base field. This is a minor variant of étale cohomology, involving neither de Rham complexes nor hypercohomology. The main idea is to delegate the role of étale morphisms to fundamental groupoids, thereby bypassing the Grothendieck topology. To validate this theory, we prove a comparison theorem between the algebraically defined cohomology using the pro-algebraic fundamental groupoid over $\\mathbb{C}$ and singular cohomology. Furthermore, our construction naturally extends to other types of fundamental groupoids, providing a uniform foundation for various cohomology theories.",
      "authors": [
        "Hyuk Jun Kweon"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "math.NT"
      ],
      "published": "2026-02-13 08:50:52+00:00",
      "link": "https://arxiv.org/pdf/2602.12718v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12707v1",
      "title": "Open enumerative geometries for Landau-Ginzburg models",
      "abstract": "We survey the recent progress in defining open enumerative theories for Landau-Ginzburg models. We illustrate the ideas required to develop these new foundations. In particular, we describe how to define the open enumerative invariants as integrals of multisections of certain vector bundles over a moduli space that is a real orbifold with corners, after prescribing boundary conditions for the multisections. We then explain the known situations where the open invariants satisfy certain forms of topological recursion relations, integrable hierarchies, or mirror symmetry. We end with a list of open questions and problems.",
      "authors": [
        "Mark Gross",
        "Tyler L. Kelly",
        "Ran J. Tessler"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "hep-th",
        "math-ph",
        "math.SG"
      ],
      "published": "2026-02-13 08:20:41+00:00",
      "link": "https://arxiv.org/pdf/2602.12707v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12676v1",
      "title": "Semi-implicit Structure Preserving Method for The Landau-Lifshitz Equation",
      "abstract": "A critical challenge inherent to the projection method applied to the Landau-Lifshitz equation is the deficiency of rigorous theoretical justifications for the stability of its projection step. To mitigate this limitation, we introduce a semi-implicit numerical scheme, which is formulated on the basis of the first-order Backward Differentiation Formula (BDF) incorporated with one-sided extrapolation and a Crank-Nicolson-type norm-preserving procedure. This proposed scheme exhibits three fundamental characteristics: structure preservation, numerical stability, and first-order accuracy in time. In practical implementations, the scheme not only ensures stable computation and adheres to the norm constraint but also guarantees the uniqueness of the numerical solution, thereby providing substantial facilitation for the theoretical analysis of the normalizing step.",
      "authors": [
        "Changjian Xie"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-13 07:17:25+00:00",
      "link": "https://arxiv.org/pdf/2602.12676v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12657v1",
      "title": "Quantitative stability for quasilinear parabolic equations",
      "abstract": "We examine the stability of a class of quasilinear parabolic partial differential equations under perturbations. We are interested in the behavior of viscosity solutions as the perturbation parameter vanishes and establish explicit convergence rates by adapting standard comparison arguments. Despite the possible singular or degenerate nature of the parabolic operator, our framework covers, in particular, both the normalized and the variational $p$-parabolic equations, providing quantitative estimates for perturbations of the exponent $p$ and limits arising from regularized approximations.",
      "authors": [
        "Tapio Kurkinen",
        "Qing Liu"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-13 06:39:37+00:00",
      "link": "https://arxiv.org/pdf/2602.12657v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12644v1",
      "title": "Line congruences associated to Appell's hypergeometric functions of rank-4",
      "abstract": "Line congruences - two-parameter families of lines in projective 3-space - are the genesis of many beautiful examples of transformations of surfaces, such as the Laplace transform. This subject is less well-known today than in previous generations. We survey and review results related to projective differential geometry of surfaces, line congruences, and close connections to linear systems of PDEs of finite type whose solutions define the data of an immersion of a surface into projective 3-space. We then derive formulae for the Laplace transform of the entire rank-4 linear system associated to such an immersed surface, obtaining explicit formulae for the rank-4 systems that define the Laplace transformed surfaces. We apply our results to study the geometry of surfaces defined by Appell's hypergeometric functions of rank-4, namely the functions $F_2$ and $F_4$. We show that the sequence of Laplace invariants for each is determined respectively by the Euler-Poisson-Darboux equation in the case of $F_2$, and Darboux's Harmonic equation in the case of $F_4$. Further, we show that for all parameter values of the hypergeometric functions, the natural line congruences generated by the Laplace transforms of the surfaces determined by either $F_2$ or $F_4$ constitute a $W$-congruence, an important example of line congruence.",
      "authors": [
        "Matthew Ryan",
        "Michael T. Schultz"
      ],
      "primary_category": "math.DG",
      "categories": [
        "math.DG"
      ],
      "published": "2026-02-13 06:08:58+00:00",
      "link": "https://arxiv.org/pdf/2602.12644v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12619v1",
      "title": "Asymptotically self-similar graph-like solutions to a multi-dimensional surface diffusion flow equation under contact angle and no-flux boundary conditions",
      "abstract": "This paper studies Mullins' model of thermal grooving which consists of a surface diffusion flow equation with contact angle and no-flux boundary conditions. We consider this problem in a multi-dimensional half space and prove that if the slope of the initial data is close to that consistent with the contact angle, then there exists a unique global-in-time solution. In particular, we show the existence of a self-similar solution for a given behavior at the space infinity. We also show that our global solution converges to a self-similar solution as the time tends to infinity if the initial data is asymptotically homogeneous at the space infinity. No assumption on the size of the contact angle is imposed.",
      "authors": [
        "Yoshikazu Giga",
        "Sho Katayama"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-13 04:50:19+00:00",
      "link": "https://arxiv.org/pdf/2602.12619v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12595v1",
      "title": "Michel Talagrand and the Rigorous Theory of Mean Field Spin Glasses",
      "abstract": "Michel Talagrand played a decisive role in the transformation of mean field spin glass theory into a rigorous mathematical subject. This chapter offers a narrative account of that development. We begin with the physical origins of the Sherrington-Kirkpatrick (SK) model and the emergence of the TAP and Almeida-Thouless stability frameworks, culminating in Parisi's replica symmetry breaking (RSB) ansatz and its hierarchical order parameter. We then review early rigorous milestones, including high-temperature results and stability identities, and describe the consolidation of interpolation and cavity methods through the work of Guerra and of Aizenman-Sims-Starr. The central event in this narrative is Talagrand's 2006 proof of the Parisi formula for the SK model and for a broad class of mixed $p$-spin models, and his subsequent analysis of Parisi measures. We also discuss Talagrand's later program constructing pure states under extended Ghirlanda-Guerra identities and an atom at the maximal overlap, together with the structural results that followed, notably Panchenko's ultrametricity theorem and extensions of the Parisi formula. Throughout, we indicate how related contributions by many authors fit into the same long-running program across probability, analysis, and mathematical physics.",
      "authors": [
        "Sourav Chatterjee"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "cond-mat.dis-nn",
        "math-ph"
      ],
      "published": "2026-02-13 04:13:30+00:00",
      "link": "https://arxiv.org/pdf/2602.12595v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12589v1",
      "title": "Berry-Esseen Bounds and Moderate Deviations for Catoni-Type Robust Estimation",
      "abstract": "A powerful robust mean estimator introduced by Catoni (2012) allows for mean estimation of heavy-tailed data while achieving the performance characteristics of classical mean estimator for sub-Gaussian data. While Catoni's framework has been widely extended across statistics, stochastic algorithms, and machine learning, fundamental asymptotic questions regarding the Central Limit Theorem and rare event deviations remain largely unaddressed. In this paper, we investigate Catoni-type robust estimators in two contexts: (i) mean estimation for heavy-tailed data, and (ii) linear regression with heavy-tailed innovations. For the first model, we establish the Berry--Esseen bound and moderate deviation principles, addressing both known and unknown variance settings. For the second model, we demonstrate that the associated estimator is consistent and satisfies a multi-dimensional Berry-Esseen bound.",
      "authors": [
        "Zhijun Cai",
        "Xiang Li",
        "Lihu Xu"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST"
      ],
      "published": "2026-02-13 04:02:59+00:00",
      "link": "https://arxiv.org/pdf/2602.12589v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12559v1",
      "title": "Convergence Analysis of Block Newton Methods for 1D Shallow Neural Network Approximation",
      "abstract": "This paper analyzes local convergence of the block Newton (BN) method introduced in [5, 6] for one-dimensional shallow neural network approximation to functions and diffusion-reaction problems. The BN method consists of the 2x2 block nonlinear Gauss-Seidel, linear Gauss-Seidel, or Jacobi method for outer iteration and the Newton method for inner iteration. The blocks are corresponding to the linear and the nonlinear parameters. Under some reasonable assumptions, we establish local convergence of the BN methods as well as the reduced BN (rBN) method for one-dimensional diffusion-reaction problems and least-squares function approximation. Unlike common optimization methods, the rBN allows for the reduction of the number of parameters during the optimization process when some neurons contribute little to the approximation or are at nearly optimal locations.",
      "authors": [
        "Zhiqiang Cai",
        "Anastassia Doktorova",
        "Robert D. Falgout",
        "César Herrera"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-13 03:17:06+00:00",
      "link": "https://arxiv.org/pdf/2602.12559v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12513v1",
      "title": "An LP-Based Approach for Bilinear Saddle Point Problem with Instance-dependent Guarantee and Noisy Feedback",
      "abstract": "In this work, we study the sample complexity of obtaining a Nash equilibrium (NE) estimate in two-player zero-sum matrix games with noisy feedback. Specifically, we propose a novel algorithm that repeatedly solves linear programs (LPs) to obtain an NE estimate with bias at most $\\varepsilon$ with a sample complexity of $O\\left(\\frac{m_1 m_2}{\\varepsilon\\min\\{δ^2,σ_0^2,σ^3\\}} \\log\\frac{m_1 m_2}{\\varepsilon}\\right)$ for general $m_1 \\times m_2$ game matrices, where $σ$, $σ_0$, $δ$ are some problem-dependent constants. To our knowledge, this is the first instance-dependent sample complexity bound for finding an NE estimate with $\\varepsilon$ bias in general-dimension matrix games with noisy feedback and potentially non-unique equilibria. Our algorithm builds on recent advances in online resource allocation and operates in two stages: (1) identifying the support set of an NE, and (2) computing the unique NE restricted to this support. Both stages rely on a careful analysis of LP solutions derived from noisy samples.",
      "authors": [
        "Jiashuo Jiang",
        "Mengxiao Zhang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-13 01:34:04+00:00",
      "link": "https://arxiv.org/pdf/2602.12513v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12511v1",
      "title": "Global renormalized solutions for hard potential non-cutoff Boltzmann equation without defect measure",
      "abstract": "The existence of global renormalized solutions to the Boltzmann equation with long-range interactions without angular cutoff was first established by Alexandre and Villani [Comm. Pure Appl. Math., 55(1), 30-70, 2002]. Their result relies on a definition of renormalized solutions involving a non-negative defect measure. In this paper, we address this issue for the inverse power law model in the case of hard potentials ($0 \\leq γ\\leq 1$). By exploiting the stronger coercivity estimates provided by hard potentials, we prove that the defect measure actually vanishes. Consequently, we establish the global existence of renormalized solutions for the non-cutoff Boltzmann equation with hard potentials in the standard sense, without any defect measure. Finally, we construct a counterexample showing that the approach developed for the hard potential case fails for soft potential model ($-3 < γ< 0$).",
      "authors": [
        "Yi-Long Luo",
        "Jing-Xin Nie"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-13 01:29:29+00:00",
      "link": "https://arxiv.org/pdf/2602.12511v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12472v1",
      "title": "Dynamic Programming Principle and Stabilization for Mean-Field Quantum Filtering Systems",
      "abstract": "Working within the quantum filtering framework, we establish a dynamic programming principle in an infinite-dimensional setting by embedding the state space into the Hilbert-Schmidt space. We then study a stabilization problem for continuously monitored Ising-coupled qubits and, in the mean-field limit, demonstrate quantum state reduction together with exponential convergence toward prescribed eigenstates under suitable feedback laws.",
      "authors": [
        "Sofiane Chalal",
        "Nina H. Amini",
        "Hamed Amini",
        "Mathieu Laurière"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "math.OC"
      ],
      "published": "2026-02-12 22:58:26+00:00",
      "link": "https://arxiv.org/pdf/2602.12472v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12455v1",
      "title": "Existence Results and KKT Optimality Conditions for Generalized Quasiconvex Functions",
      "abstract": "We studied a new notion of generalized convex functions called $e$-quasi\\-con\\-ve\\-xi\\-ty, which encompasses both quasiconvex and $e$-convex functions, including all Lipschitz functions. By extending the standard properties of quasiconvex functions to $e$-quasiconvex functions, we establish sufficient conditions for the nonemptiness and compactness of the solution set when minimizing an $e$-quasiconvex function, leveraging generalized asymptotic functions, a result which remains applicable even when the set of minimizers is nonconvex. Furthermore, in the differentiable case, we ensure the sufficiency of the KKT optimality conditions when the constraint functions in the mathematical programming problems are $e$-quasiconvex. Finally, we illustrate our new results with several nonconvex (non-quasiconvex) examples.",
      "authors": [
        "M. H. Alizadeh",
        "F. Lara"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-12 22:20:53+00:00",
      "link": "https://arxiv.org/pdf/2602.12455v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12409v1",
      "title": "Dirichlet-Neumann Waveform Relaxation Method with Multiple Subdomains for Reaction-Diffusion Equation with a Time Delay",
      "abstract": "In this study, we present the numerical investigation of the Dirichlet-Neumann Waveform Relaxation (DNWR) algorithm applied to multiple subdomains for the reaction-diffusion equation with time delay. Various arrangements of transmission conditions between subdomains are explored and a series of numerical experiments are conducted to evaluate and compare the efficiency and effectiveness of these configurations.",
      "authors": [
        "Bankim C. Mandal",
        "Deeksha Tomer"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "math.AP"
      ],
      "published": "2026-02-12 21:01:00+00:00",
      "link": "https://arxiv.org/pdf/2602.12409v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12400v1",
      "title": "Metastability of random maps: a resolvent approach",
      "abstract": "We present a general framework to study the metastability of random perturbations of dynamical systems. It integrates techniques from the theory of Markov processes, in particular the resolvent approach to metastability, with the spectral analysis of transfer operators associated to the dynamics. The proposed framework is applied to study the metastability of one-dimensional dynamical systems generated by a map randomly perturbed by sub-Gaussian noise.",
      "authors": [
        "Diego Marcondes",
        "Sandro Vaienti"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS",
        "math.PR"
      ],
      "published": "2026-02-12 20:50:47+00:00",
      "link": "https://arxiv.org/pdf/2602.12400v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12399v1",
      "title": "Periodic Shadowing for Set-Valued Maps",
      "abstract": "We study shadowing-type properties for set-valued dynamical systems. In particular, we investigate the periodic shadowing property and its relationship with expansivity and chain transitivity. We establish that for positively expansive set-valued maps on compact metric spaces, the shadowing property implies the periodic shadowing property. Furthermore, we show that for chain transitive maps, periodic shadowing implies both shadowing and topological transitivity. We also present a general construction of set-valued maps with shadowing arising from single-valued systems admitting an isometric involution. Several examples, including systems from symbolic dynamics, are provided to illustrate the theory.",
      "authors": [
        "M. Oliveira"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS"
      ],
      "published": "2026-02-12 20:50:41+00:00",
      "link": "https://arxiv.org/pdf/2602.12399v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12383v1",
      "title": "Maximum capacity of Bartnik data and a generalization of static metrics",
      "abstract": "Inspired by R. Bartnik's mass minimization problem in general relativity, we investigate a dual problem of maximizing the capacity among asymptotically flat extensions (with nonnegative scalar curvature) of some fixed two-dimensional boundary data. Using the method of Lagrange multipliers on the constraint space of scalar-flat extensions, we derive the variational condition satisfied by a maximal capacity extension. The resulting equation is an inhomogeneous generalization of the well-known static equation, now coupled with the Baird--Eells stress-energy tensor for a harmonic function. We analyze these ``harmonic-static'' metrics in a local sense, proving they have constant scalar curvature and serve as critical points for a metric-dependent Dirichlet energy functional. We conclude with a number of open questions.",
      "authors": [
        "Jeffrey L. Jauregui"
      ],
      "primary_category": "math.DG",
      "categories": [
        "math.DG",
        "gr-qc"
      ],
      "published": "2026-02-12 20:26:41+00:00",
      "link": "https://arxiv.org/pdf/2602.12383v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12365v1",
      "title": "A versatile FEM framework with native GPU scalability via globally-applied AD",
      "abstract": "Energy-based finite-element formulations provide a unified framework for describing complex physical systems in computational mechanics. In these energy-based methods, the governing equations can be obtained directly by considering the derivatives of a single global energy functional. While Automatic Differentiation (AD) can be used to automate the generation of these derivatives, current frameworks face a clear trade-off based primarily on the scale upon which the AD method is applied. Globally applied AD offers high expressivity but cannot currently be scaled to large problems. Locally applied AD scales well through traditional assembly methods, but the variety of physics and couplings that the framework can easily represent is more limited than the global approach. Here, we introduce an energy-centric framework tatva (https://github.com/smec-ethz/tatva) that defines the physics of a problem as a single global functional and applies AD globally to generate residual and tangent operators. By leveraging Jacobian-vector products for matrix-free solvers and coloring-based sparse differentiation for materializing sparse tangent stiffness matrices when needed, our flexible design scales linearly with the problem size on GPUs. We demonstrate that our framework can handle large problems (with millions of degrees of freedom) without memory exhaustion. Additionally, it offers a unified, fully differentiable methodology that can address a wide range of problems, including multi-point constraints, mixed-dimensional coupling, and the incorporation of neural networks, while maintaining high performance and scalability on modern GPU architectures.",
      "authors": [
        "Mohit Pundir",
        "Flavio Lorez",
        "David S. Kammer"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "cond-mat.soft"
      ],
      "published": "2026-02-12 19:51:03+00:00",
      "link": "https://arxiv.org/pdf/2602.12365v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12337v1",
      "title": "Temporal-Stability-Enhanced and Energy-Stable Dynamical Low-Rank Approximation for Multiscale Linear Kinetic Transport Equations",
      "abstract": "In this paper, we develop an asymptotic-preserving dynamical low-rank method for the multiscale linear kinetic transport equation. The proposed scheme is unconditionally stable in the diffusive regime while preserving the correct asymptotic behavior, and can achieve significant reductions in computational cost through a low-rank representation and large time step stability. A low-rank formulation consistent with the discrete energy is introduced under the discrete ordinates discretization, and energy stability of the resulting scheme is established. Numerical experiments confirm the energy stability and demonstrate that the method is efficient while maintaining accuracy across different regimes and capturing the correct asymptotic limits.",
      "authors": [
        "Shun Li",
        "Yan Jiang",
        "Mengping Zhang",
        "Tao Xiong"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-12 19:00:24+00:00",
      "link": "https://arxiv.org/pdf/2602.12337v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12214v1",
      "title": "The colored knapsack problem: structural properties and exact algorithms",
      "abstract": "We introduce and study a novel generalization of the classical Knapsack Problem (KP), called the Colored Knapsack Problem (CKP). In this problem, the items are partitioned into classes of colors and the packed items need to be ordered such that no consecutive items are of the same color. We establish that the problem is weakly NP-hard and propose two exact dynamic programming algorithms with time complexities of $\\mathcal{O}(bn^4)$ and $\\mathcal{O}(b^2n^3)$, respectively. To enhance practical performance, we derive various dominance and fathoming rules for both approaches. From a theoretical perspective, we analyze the linear programming relaxation of the natural CKP formulation, proving that an optimal solution exists with at most two fractional items. We also show that the relaxation can be solved in $\\mathcal{O}(n)$ time, matching the complexity of the classical KP. Finally, we establish a comprehensive benchmark of CKP instances, derived from the Colored Bin Packing Problem. Extensive computational experiments demonstrate that the proposed dynamic programming algorithms significantly outperform state-of-the-art MIP solvers on most of these instances.",
      "authors": [
        "Fabio Ciccarelli",
        "Alexander Helber",
        "Erik Mühmer"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-12 17:52:27+00:00",
      "link": "https://arxiv.org/pdf/2602.12214v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12163v1",
      "title": "NLS with exponential nonlinearity on compact surfaces",
      "abstract": "In this paper, we establish a probabilistic global theory in $H^1$ for the NLS with a Moser-Trudinger nonlinearity posed on compact surfaces. This equation is known to be the two dimensional counterpart to the classical energy-critical Schrödinger equations \\cite{CollianderIbrahimMajdoubMasmoudi2009}. The authors of \\cite{CollianderIbrahimMajdoubMasmoudi2009} also identified a trichotomy around the criticality of the equation based on the size of the total energy. In particular, for supercritical regimes (large energy), the equation is known to exhibit instabilities : the (uniform) continuity of the flow fails to hold. Large data distributional non unique probabilistic solutions have been obtained in \\cite{CasterasMonsaingeon2024}. The setting of \\cite{CasterasMonsaingeon2024} does not handle the uniqueness issue for the $H^1$-data and therefore could not define a flow for this regularity. Our main focus here is to build a single probabilistic framework that provides both existence, uniqueness, and continuity with respect to the initial data in $H^1$. Our uniqueness and continuity are based on the so-called Yudowich argument \\cite{Judovic1963}, and the probabilistic estimates are derived through the IID limit procedure \\cite{Sy2019}. Beyond the difficulties related to the borderline nature of the context, the major challenge resides in the need to satisfy two features that tend to play against each other : obtaining both continuity property of the flow and large data in the support of the reference measure. This made the design of the dissipation operator inherent in the method, as well as the analysis of the resulting quantities, particularly difficult. Regarding the supercritical regime, we show that a modified energy, with regularity similar to the original total energy, admits values as high as desired, suggesting that the constructed set of data contains supercritical ones.",
      "authors": [
        "Filone G. Longmou-Moffo",
        "Mouhamadou Sy"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-12 16:45:16+00:00",
      "link": "https://arxiv.org/pdf/2602.12163v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12114v1",
      "title": "Matrix bordering structure of the Faddeev-Jackiw algorithm: Schur complement regularization and symbolic automation",
      "abstract": "We show that the iterative Faddeev-Jackiw (FJ) reduction for singular Lagrangian systems constitutes a geometrically constrained instance of the Matrix Bordering Technique (MBT). For a first-order Lagrangian with singular pre-symplectic form, each iteration of the Barcelos-Neto-Wotzasek algorithm produces an extended symplectic matrix of canonical bordered form, \\begin{eqnarray}   f^{(m)} = \\left( \\begin{matrix}   f^{(0)} & B \\\\ -B^{\\mathsf{T}} & 0 \\end{matrix} \\right) \\end{eqnarray} where the bordering block $B$ is determined by the gradients of the consistency constraints. We prove that the nondegeneracy of the extended matrix is governed by the corresponding Schur complement, which is algebraically isomorphic to the Poisson bracket matrix of constraints. As a consequence, the Faddeev-Jackiw algorithm terminates if and only if the constraint algebra is nondegenerate, i.e., when the constraints form a second-class system. This algebraic characterization provides a rigorous foundation for automating the Faddeev-Jackiw procedure symbolically. We present a fully symbolic implementation in the Wolfram Language, and validate the approach on representative mechanical systems with nontrivial constraint structure. The resulting rule-based engine preserves parametric dependencies throughout the reduction, enabling reliable analysis of degeneracy, structural stability (when no bifurcations occur), and possible bifurcation scenarios as critical parameters are varied.",
      "authors": [
        "E. Chan-López",
        "A. Martín-Ruiz",
        "Jaime Manuel Cabrera",
        "Jorge Mauricio Paulin Fuentes"
      ],
      "primary_category": "math-ph",
      "categories": [
        "math-ph"
      ],
      "published": "2026-02-12 16:04:59+00:00",
      "link": "https://arxiv.org/pdf/2602.12114v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12046v1",
      "title": "Local boundedness for solutions to parabolic $p,q$-problems with degenerate coefficients",
      "abstract": "We investigate the local boundedness of solutions $u:Ω_T\\to\\mathbb{R}$ to parabolic equations of the form \\begin{equation*}   \\partial_tu-\\mathrm{div}\\,\\mathcal{A}(x,t,Du)=0 \\qquad\\mbox{in }Ω_T=Ω\\times(0,T) \\end{equation*} that satisfy $p,q$-growth conditions and have degenerate coefficients. More precisely, we assume structure conditions of the type \\begin{align*} |\\mathcal{A}(x,t,ξ)|&\\le b(x,t)(μ^2+|ξ|^2)^{\\frac{q-1}{2}},\\\\ \\langle \\mathcal{A}(x,t,ξ),ξ\\rangle&\\ge a(x,t)(μ^2+|ξ|^2)^{\\frac {p-2}{2}}|ξ|^2, \\end{align*} for $2\\le p\\le q$ and $μ\\in[0,1]$, where the functions $a^{-1}, b:Ω_T\\to\\mathbb{R}$ are possibly unbounded and only satisfy some integrability condition. Under a certain assumption on the gap between $p$ and $q$, we prove two main results. First, we show that subsolutions that are contained in the natural energy space are locally bounded from above. Second, for parabolic equations with a variational structure, we use these bounds to show the existence of locally bounded variational solutions.",
      "authors": [
        "Flavia Giannetti",
        "Antonia Passarelli di Napoli",
        "Christoph Scheven"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-12 15:11:30+00:00",
      "link": "https://arxiv.org/pdf/2602.12046v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12008v1",
      "title": "Mesh-free numerical method for Dirichlet eigenpairs of the Laplacian with potential",
      "abstract": "This paper is concerned with the numerical approximation of the $L^2$ Dirichlet eigenpairs of the operator $-Δ+ V$ on a simply connected $C^2$ bounded domain $Ω\\subset \\mathbb{R}^2$ containing the origin, where $V$ is a radial potential.   We propose a mesh-free method inspired by the Method of Particular Solutions for the Laplacian (i.e. $V=0$). Extending this approach to general $C^1$ radial potentials is challenging due to the lack of explicit basis functions analogous to Bessel functions. To overcome this difficulty, we consider the equation $-Δu + V u = λu$ on a ball containing $Ω$, without imposing boundary conditions, for a collection of values $λ$ forming a fine discretisation of the interval in which eigenvalues are sought. By rewriting the problem in polar coordinates and applying a Fourier expansion with respect to the angular variable, we obtain a decoupled system of ordinary differential equations. These equations are solved numerically using a one-dimensional Finite Element Method, yielding a family of basis functions that are solutions of the equation $-Δu + V u = λu$ on the ball and are independent of the domain $Ω$.   Dirichlet eigenvalues of $-Δ+ V$ are then approximated by minimising the boundary values on $\\partial Ω$ among linear combinations of the basis functions and identifying those values of $λ$ for which the computed minimum is sufficiently small. The proposed method is highly memory-efficient compared to the standard Finite Element approach.",
      "authors": [
        "Dragoş Manea"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "math.AP"
      ],
      "published": "2026-02-12 14:40:19+00:00",
      "link": "https://arxiv.org/pdf/2602.12008v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12006v1",
      "title": "A Novel Approach to Peng's Maximum Principle for McKean-Vlasov Stochastic Differential Equations",
      "abstract": "We present a novel approach to the proof of Peng's maximum principle for McKean-Vlasov stochastic differential equations (SDE). The main step is the introduction of a third adjoint equation, a conditional McKean-Vlasov backward SDE, to accommodate the dualization of quadratic terms containing two independent copies of the first-order variational process. This is an intrinsic extension of the maximum principle from Peng for standard SDE and gives a conceptually consistent proof. Our approach will be useful in further extensions to the common noise setting and the infinite dimensional setting.",
      "authors": [
        "Johan Benedikt Spille",
        "Wilhelm Stannat"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "math.OC"
      ],
      "published": "2026-02-12 14:37:59+00:00",
      "link": "https://arxiv.org/pdf/2602.12006v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12001v1",
      "title": "Inner regularity and Liouville theorems for stable solutions to the mean curvature equation",
      "abstract": "Let $f\\in C^1(\\mathbb{R})$. We study stable solutions $u$ of the mean curvature equation \\[ \\operatorname{div}\\left( \\frac{\\nabla u}{\\sqrt{1+|\\nabla u|^2}} \\right) = -f(u) \\qquad \\text{in}\\ Ω\\subset \\mathbb{R}^n. \\] In the local setting we prove that $\\nabla u$ satisfies inner Morrey regularity $M^{p_n}$, where \\[ p_n := \\left\\{ \\begin{array}{ll} n,\\qquad & \\text{if}\\ 2\\leq n\\leq 5, \\\\ \\frac{n}{n-4\\sqrt{n-1}+4},\\qquad & \\text{if}\\ n\\geq 6, \\end{array} \\right. \\] together with the estimate \\[ \\|\\nabla u\\|_{M^{p_n}(B_1)} \\leq C \\left( 1+\\|\\nabla u\\|_{L^1(B_2)} \\right). \\] The exponent $p_n$ is optimal for $n\\leq5$, as shown by an explicit one-dimensional example. For radial solutions we show that the symmetry center is at most a removable singularity.   Globally, we establish Liouville-type theorem: any stable solution satisfying the growth condition \\[ |\\nabla u(x)| = \\left\\{ \\begin{array}{lll} o(|x|^{-1}) \\ & \\text{as}\\ |x|\\rightarrow +\\infty& \\text{when}\\ 2\\leq n\\leq 10, \\\\ o(|x|^{-n/2+\\sqrt{n-1}+1}) \\ & \\text{as}\\ |x|\\rightarrow +\\infty& \\text{when}\\ n\\geq 11, \\end{array} \\right. \\] must be constant. In particular, no nonconstant radial stable solution exists in dimensions \\(2\\leq n\\leq6\\), which highlights a global rigidity of stable radial solutions in low dimensions and extend the classical Liouville theorem of Farina and Navarro.   Several exponents appearing in our results are new for mean curvature equations, showing both similarities and differences with the corresponding theorems for semilinear equations.",
      "authors": [
        "Fanheng Xu"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-12 14:30:57+00:00",
      "link": "https://arxiv.org/pdf/2602.12001v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11991v1",
      "title": "Improved Interior Gradient Estimates for the Mean Curvature Equation under Nonlinear Assumptions",
      "abstract": "In this paper, we investigate interior gradient estimates for solutions to the mean curvature equation $$ \\dive \\left( \\frac{\\nabla u}{\\sqrt{1 + |\\nabla u|^2}} \\right) = f(\\nabla u)$$ under various nonlinear assumptions on the right-hand side. Under the weakened initial assumption $u\\in C^1(B_R) \\cap C^3(\\{|\\nabla u|>0\\})$, we establish sharp gradient bounds that depend on the oscillation of the solution. These estimates are applicable to a wide class of nonlinear terms, including the specific forms arising from the elliptic regularization of the inverse mean curvature flow ($f=\\varepsilon\\sqrt{1+|\\nabla u|^2}$ ), minimal surface equation ($f=0$) and several polynomial and logarithmic growth regimes. As applications, the gradient bounds imply uniform ellipticity of the equation away from the critical set,which allows one to apply classical elliptic regularity theory and obtain higher regularity of solutions in the noncritical region. Moreover, when the solution grows at most linearly, all cases of our results can be applied in Moser's theory to establish the affine linear rigidity of global solutions. This directly leads to the Liouville-type theorems for global solutions without requiring additional proofs.",
      "authors": [
        "Fanheng Xu"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-12 14:19:44+00:00",
      "link": "https://arxiv.org/pdf/2602.11991v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11947v1",
      "title": "Mixed-Integer Programming for Change-point Detection",
      "abstract": "We present a new mixed-integer programming (MIP) approach for offline multiple change-point detection by casting the problem as a globally optimal piecewise linear (PWL) fitting problem. Our main contribution is a family of strengthened MIP formulations whose linear programming (LP) relaxations admit integral projections onto the segment assignment variables, which encode the segment membership of each data point. This property yields provably tighter relaxations than existing formulations for offline multiple change-point detection. We further extend the framework to two settings of active research interest: (i) multidimensional PWL models with shared change-points, and (ii) sparse change-point detection, where only a subset of dimensions undergo structural change. Extensive computational experiments on benchmark real-world datasets demonstrate that the proposed formulations achieve reductions in solution times under both $\\ell_1$ and $\\ell_2$ loss functions in comparison to the state-of-the-art.",
      "authors": [
        "Apoorva Narula",
        "Santanu S. Dey",
        "Yao Xie"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "stat.ML"
      ],
      "published": "2026-02-12 13:43:56+00:00",
      "link": "https://arxiv.org/pdf/2602.11947v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11889v1",
      "title": "Global Multiplicity and Comparison Principles for Singular Problems driven by Mixed Local-Nonlocal Operators",
      "abstract": "We study a singular elliptic problem driven by a mixed local-nonlocal operator of the form \\begin{equation*}   \\begin{aligned}   -Δ_p u + (-Δ_q)^s u &= \\fracλ{u^δ} + u^r \\text{ in } Ω\\newline   u > 0 \\text{ in } Ω,\\ u &= 0 \\text{ in } \\mathbb{R}^N \\setminus Ω   \\end{aligned} \\end{equation*} where $p > sq$, $0<δ<1$ and $λ> 0$ is a parameter. The nonlinearity exhibits a singular power-type behavior near zero and displays at most a critical growth at infinity. We establish a global multiplicity result with respect to the parameter $λ$ by identifying a sharp threshold that separates existence, non-existence, and multiplicity regimes, a result that is new for singular problems involving mixed local-nonlocal operators. We also derive a Hopf-type strong comparison principle adapted to this nonlinear setting, which provides the main analytical tool for the global multiplicity result. Additionally, we investigate qualitative properties of solutions that are essential for the variational analysis, such as a uniform $L^{\\infty}$-estimate and a Sobolev versus Hölder local minimizer result. The analytical tools developed herein are of independent mathematical interest, with their applicability extending over a broader class of mixed local-nonlocal problems.",
      "authors": [
        "R. Dhanya",
        "Sarbani Pramanik"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-12 12:39:01+00:00",
      "link": "https://arxiv.org/pdf/2602.11889v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11883v1",
      "title": "A unified framework for photon and massive particle hypersurfaces in stationary spacetimes",
      "abstract": "We revisit the notion of massive particle hypersurfaces and place it within a unified framework alongside photon hypersurfaces in stationary spacetimes. More precisely, for Killing-invariant timelike hypersurfaces $T=\\mathbb{R}\\times S_0$, where $S_0$ is a smooth embedded surface in a spacelike slice $S$ of the stationary spacetime, we show that $T$ is a photon hypersurface or a massive particle hypersurface if and only if $S_0$ is totally geodesic with respect to certain associated Finsler structures on the slice: a Randers metric governing null geodesics and a Jacobi--Randers metric governing timelike solutions of the Lorentz force equation at fixed energy and charge-to-mass ratio. We also prove existence and multiplicity results for proper-time parametrized solutions of the Lorentz force equation with fixed energy and charge-to-mass ratio, either connecting a point to a flow line of the Killing vector field or having periodic, non-constant projection on $S$.",
      "authors": [
        "Erasmo Caponio",
        "Anna valeria Germinario",
        "Antonio Masiello"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "math.DG"
      ],
      "published": "2026-02-12 12:33:33+00:00",
      "link": "https://arxiv.org/pdf/2602.11883v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11856v1",
      "title": "Random points on $\\mathbb{S}^3$ with small logarithmic energy",
      "abstract": "We analyse several constructions of random point sets on the sphere $\\mathbb{S}^{3}\\subset\\mathbb{R}^4$ evaluating and comparing them through their discrete logarithmic energy: \\begin{equation*}   E_0(ω_N) =   \\sum_{\\substack{i, j=1\\\\ i \\neq j}}^{N}   \\log\\frac{1}{\\|x_i - x_j\\|},   \\; \\text{ where}\\; ω_N=\\{x_1,\\ldots,x_N\\} \\subset \\mathbb{S}^3. \\end{equation*} Using the Hopf fibration, we lift a range of well-distributed families of points from the $2$-dimensional sphere - including uniformly random points, antipodally symmetric sets, determinantal point processes, and the Diamond ensemble - to $\\mathbb{S}^{3}$, in order to assess their energy performance. In particular, we carry out this asymptotic analysis for the Spherical ensemble (a well known determinantal point process on $\\mathbb{S}^2$), obtaining as a result a family of points on the $3$-dimensional sphere whose logarithmic energy is asymptotically the lowest achieved to date. This, in turn, provides a new upper bound for the minimal logarithmic energy on $\\mathbb{S}^3$. Although an analytic treatment of the lifted Diamond ensemble remains elusive, extensive simulations presented here show that its empirical energies lie below all other deterministic and non-deterministic constructions considered. Together, these results sharpen the quantitative link between potential-theoretic optima on $\\mathbb{S}^{2}$ and $\\mathbb{S}^{3}$ and provide both theoretical and numerical benchmarks for future work.",
      "authors": [
        "Ujué Etayo",
        "Pablo G. Arce"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-02-12 11:53:16+00:00",
      "link": "https://arxiv.org/pdf/2602.11856v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11849v1",
      "title": "Data-driven discovery of chemical reaction networks",
      "abstract": "We propose a unified framework that allows for the full mechanistic reconstruction of chemical reaction networks (CRNs) from concentration data. The framework utilizes an integral formulation of the differential equations governing the chemical reactions, followed by an automatic procedure to recover admissible mass-action mechanisms from the equations. We provide theoretical justification for the use of integral formulations using analytical and numerical error bounds. The integral formulation is demonstrated to offer superior robustness to noise and improved accuracy in both rate-law and graph recovery when compared to other commonly used formulations. Together, our developments advance the goal of fully automated, data-driven chemical mechanism discovery.",
      "authors": [
        "Abraham Reyes-Velazquez",
        "Stefan Güttel",
        "Igor Larrosa",
        "Jonas Latz"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-12 11:41:42+00:00",
      "link": "https://arxiv.org/pdf/2602.11849v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11848v1",
      "title": "PBNF-transform as a formulation of Propositional Calculus, II",
      "abstract": "Here we show, in the second paper in a series of articles, methods to calculate propositional statements with algebraic polyno mials as symbols for the connectives, which here are named operators. In the first article, we explained this formulation of the Propositional Calculus. In short, we transform to a dual space, which we here refer to as a polynomial family, which is another shape of DBNF. We name the polynomial families as PBNF, which stands for Polynomial Boolean Normal Form. We just use the one law of inference, the rule of Substi tution. We can use different polynomial families in the House of PBNF, depending on the statement form, making it even simpler. It is also pos sible to find new theorems and generalize older ones, for example, those given by Church and Barkley Rosser (see follow-up article) concerning duality.",
      "authors": [
        "Pelle Brooke Borgeke"
      ],
      "primary_category": "math.LO",
      "categories": [
        "math.LO"
      ],
      "published": "2026-02-12 11:41:24+00:00",
      "link": "https://arxiv.org/pdf/2602.11848v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11844v1",
      "title": "Parity-dependent double degeneracy and spectral statistics in the projected dice lattice",
      "abstract": "We investigate the spectral statistics of an interacting fermionic system derived by projecting the Hubbard interaction onto the two lowest-energy, degenerate flat bands of the dice lattice subjected to a $π$-flux. Surprisingly, the distributions of level spacings and gap ratios correspond to distinct Gaussian ensembles, depending on the parity of the particle number. For an even number of particles, the spectra conform to the Gaussian Orthogonal Ensemble, as expected for a time-reversal-symmetric Hamiltonian. In stark contrast, the odd-parity sector exhibits exact double degeneracy of all eigenstates even after resolving all known symmetries, and the Gaussian Unitary Ensemble accurately describes the spacing distribution between these doublets. The simultaneous emergence of two different random-matrix ensembles within a single physical system constitutes an unprecedented finding, opening new avenues for both random matrix theory and flat-band physics.",
      "authors": [
        "Koushik Swaminathan",
        "Anouar Moustaj",
        "Jose L. Lado",
        "Sebastiano Peotta"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el",
        "math-ph",
        "quant-ph"
      ],
      "published": "2026-02-12 11:38:31+00:00",
      "link": "https://arxiv.org/pdf/2602.11844v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11837v1",
      "title": "A family of matrix flows converging to normal matrices",
      "abstract": "The celebrated Antezana-Pujals-Stojanoff Theorem states that the iterated Aluthge transforms of an arbitrary matrix converge to a normal matrix. We introduce a family of matrix flows that share this convergence property by defining them through ordinary differential equations. The family includes a continuous analogue of the Aluthge transform, as well as a differential equation discussed by Haagerup in the context of II$_1$ factors. We also examine the same type of flows in the setting of Hilbert space operators equipped with unitarily invariant norms.",
      "authors": [
        "Masaki Izumi"
      ],
      "primary_category": "math.FA",
      "categories": [
        "math.FA",
        "math.DS",
        "math.OA",
        "math.SP"
      ],
      "published": "2026-02-12 11:28:32+00:00",
      "link": "https://arxiv.org/pdf/2602.11837v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11747v1",
      "title": "High-Probability Minimax Adaptive Estimation in Besov Spaces via Online-to-Batch",
      "abstract": "We study nonparametric regression over Besov spaces from noisy observations under sub-exponential noise, aiming to achieve minimax-optimal guarantees on the integrated squared error that hold with high probability and adapt to the unknown noise level. To this end, we propose a wavelet-based online learning algorithm that dynamically adjusts to the observed gradient noise by adaptively clipping it at an appropriate level, eliminating the need to tune parameters such as the noise variance or gradient bounds. As a by-product of our analysis, we derive high-probability adaptive regret bounds that scale with the $\\ell_1$-norm of the competitor. Finally, in the batch statistical setting, we obtain adaptive and minimax-optimal estimation rates for Besov spaces via a refined online-to-batch conversion. This approach carefully exploits the structure of the squared loss in combination with self-normalized concentration inequalities.",
      "authors": [
        "Paul Liautaud",
        "Pierre Gaillard",
        "Olivier Wintenberger"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "stat.ML"
      ],
      "published": "2026-02-12 09:24:08+00:00",
      "link": "https://arxiv.org/pdf/2602.11747v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11490v1",
      "title": "An Efficient Hybrid Heuristic for the Transmission Expansion Planning under Uncertainties",
      "abstract": "We address the stochastic transmission expansion planning (STEP) problem considering uncertainties in renewable generation capacity and demand. STEP's objective is to minimize the total investment cost of new transmission lines and generation cost. To tackle the computational challenges of large-scale systems, we propose a heuristic approach that combines the progressive hedging (PH) algorithm for scenario-wise decomposition with an integrated framework for solving the resulting subproblems. The latter combines a destroy-and-repair operator, a beam search procedure, and a mixed-integer programming approach. The proposed framework is evaluated on large-scale systems from the literature, containing up to 10000 nodes, adapted to multiple scenarios based on parameters from the California test system (CATS). Compared with a non-trivial baseline algorithm that includes the integrated MIP and heuristics, the proposed PH-based framework consistently improved solution quality for the six systems considered (including CATS), achieving an average optimality gap reduction of 16.23% within a 2-hour time limit.",
      "authors": [
        "Yure Rocha",
        "Teobaldo Bulhões",
        "Anand Subramanian",
        "Joaquim Dias Garcia"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-12 02:21:54+00:00",
      "link": "https://arxiv.org/pdf/2602.11490v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11485v1",
      "title": "The sharp interface limit of the matrix-valued Allen-Cahn equation",
      "abstract": "In this work, we study a matrix-valued Allen-Cahn equation with a Saint Venant-Kirchhoff potential $F(\\mathbf{A})=\\frac{1}{4}\\|\\mathbf{A}\\mathbf{A}^\\top-\\mathbf{I}\\|^2$. Our approach employs the modulated energy method together with weak convergence methods for nonlinear partial differential equations. This avoids the subtle spectrum analysis of the linearized operator at the so-called quasi-minimal orbits as well as the construction of asymptotic expansion. Moreover, it relaxes the assumption on the admissible initial data, which exhibits a phase transition along an initial interface. As a byproduct, we construct a weak solution to the limiting harmonic heat flow system with both minimal pair and Neumann-type boundary conditions across the interface.",
      "authors": [
        "Xingyu Wang"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-12 01:56:22+00:00",
      "link": "https://arxiv.org/pdf/2602.11485v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11312v1",
      "title": "A Nonlinear $q$-Deformed Schrödinger Equation",
      "abstract": "We construct a new nonlinear deformed Schrödinger structure using a nonlinear derivative operator which depends on a parameter $q$. This operator recovers Newton derivative when $q \\rightarrow 1$. Using this operator we propose a deformed Lagrangian which gives us a deformed nonlinear Schrödinger equation with a nonlinear kinetic energy term and a standard potential $V(\\vec{x})$. We analytically solve the nonlinear deformed Schrödinger equation for $V(\\vec{x}) = 0$ and $q \\simeq1$. This model has a continuity equation, the energy is conserved, as well as the momentum and also interacts with electromagnetic field. Planck relation remains valid and in all steps we easily recover the undeformed quantities when the deformation parameter goes to 1. Finally, we numerically solve the equation of motion for the free particle in any spatial dimension, which shows a solitonic pattern when the space is equal to one for particular values of $q$.",
      "authors": [
        "M. A. Rego-Monteiro",
        "E. M. F. Curado"
      ],
      "primary_category": "nlin.PS",
      "categories": [
        "nlin.PS",
        "math-ph",
        "quant-ph"
      ],
      "published": "2026-02-11 19:33:48+00:00",
      "link": "https://arxiv.org/pdf/2602.11312v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11290v2",
      "title": "Entropic vector quantile regression: Duality and Gaussian case",
      "abstract": "Vector quantile regression (VQR) is an optimal transport (OT) problem subject to a mean-independence constraint that extends classical linear quantile regression to vector response variables. Motivated by computational considerations, prior work has considered entropic relaxation of VQR, but its fundamental structural and approximation properties are still much less understood than entropic OT. The goal of this paper is to address some of these gaps. First, we study duality theory for entropic VQR and establish strong duality and dual attainment for marginals with possibly unbounded supports. In addition, when all marginals are compactly supported, we show that dual potentials are real analytic. Second, building on our duality theory, when all marginals are Gaussian, we show that entropic VQR has a closed-form optimal solution, which is again Gaussian, and establish the precise approximation rate toward unregularized VQR.",
      "authors": [
        "Kengo Kato",
        "Boyu Wang"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "math.OC"
      ],
      "published": "2026-02-11 19:08:25+00:00",
      "link": "https://arxiv.org/pdf/2602.11290v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11135v1",
      "title": "Divided powers on abelian varieties",
      "abstract": "We prove the existence of divided powers in étale Chow groups of abelian varieties over a separably closed field, and hence of an integral lift of the Fourier transform, away from the characteristic and up to $2$-torsion. The method is to lift the Deninger-Murre Chow-Künneth projectors to integral ones, and draw consequences. Several techniques used here are new.",
      "authors": [
        "Bruno Kahn"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "math.NT"
      ],
      "published": "2026-02-11 18:46:50+00:00",
      "link": "https://arxiv.org/pdf/2602.11135v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11131v1",
      "title": "Formalization and inevitability of the Pareto principle",
      "abstract": "We formalize and study a generalized form of the Pareto principle or \"20/80-rule\" as a property of bounded cumulative processes. Modeling such processes by non-negative gain densities, we first show that any such process satisfies a generalized Pareto principle of the form \"fraction $p$ of inputs yields fraction $1-p$ of outputs\". To obtain a non-trivial and unique characterization, we define the generalized Pareto principle via the decreasing rearrangement of the gain density function. Within this framework, we analyze both constructed gain densities that exemplify the framework and its imposed restrictions, as well as distribution families commonly encountered in datasets, including power-law, exponential, and normal distributions. Finally, we predict commonly encountered ranges for the generalized Pareto principle and discuss the implications of elevating a structural property into a prescriptive role.",
      "authors": [
        "Antti Hippeläinen"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph",
        "math.ST"
      ],
      "published": "2026-02-11 18:42:37+00:00",
      "link": "https://arxiv.org/pdf/2602.11131v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11122v2",
      "title": "Acceleration Waves and the K-Condition in Viscoelastic Solids and Non-Newtonian Fluids",
      "abstract": "The K-condition introduced by Shizuta and Kawashima provides a sufficient criterion for the global existence of smooth solutions to dissipative hyperbolic systems. For genuinely nonlinear characteristic fields, a weaker K-condition becomes necessary, although not sufficient. In this paper, we analyze this weaker K-condition through the study of acceleration waves propagating in an equilibrium state. We investigate two classes of hyperbolic models: one describing viscoelasticity with linear dissipation, and the other non-Newtonian fluids asymptotically converging to a power-law behavior. For viscoelastic models, the weaker K-condition is always satisfied and acceleration waves remain bounded. For non-Newtonian fluids, the validity of the condition depends on the power-law index $m$: it holds for Newtonian fluids ($m=1$), is violated for shear-thinning fluids ($m<1$), and leads to an instantaneous regularization of acceleration waves for shear-thickening fluids ($m>1$).",
      "authors": [
        "Tommaso Ruggeri"
      ],
      "primary_category": "math-ph",
      "categories": [
        "math-ph",
        "physics.flu-dyn"
      ],
      "published": "2026-02-11 18:34:05+00:00",
      "link": "https://arxiv.org/pdf/2602.11122v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11248v1",
      "title": "Data-Driven Hull-Fouling Cleaning Schedule Optimization to Reduce Carbon Footprint of Vessels",
      "abstract": "In response to climate change, the International Maritime Organization has introduced regulatory frameworks to reduce greenhouse gas emissions from international shipping. Compliance with these regulations is increasingly expected from individual shipping companies, compelling vessel operators to lower the CO2 emissions of their fleets while maintaining economic viability. An important step towards achieving this is performing regular hull and propeller cleaning; however, this entails significant costs. As a result, assessing whether ship performance has declined sufficiently to warrant cleaning from an environmental and economic standpoint is a critical task to ensure both long-term viability and regulatory compliance. In this paper, we address this challenge by proposing a novel data-driven dynamic programming approach to optimize vessel cleaning schedules by balancing both environmental and economic considerations. In numerical experiments, we demonstrate the usefulness of our proposed methodology based on real-world sensor data from ten tramp trading vessels. The results confirm that over a four-year period, fuel consumption can be reduced by up to 5%, even when accounting for the costs of one or two additional cleaning events.",
      "authors": [
        "Samuel Ward",
        "Marah-Lisanne Thormann",
        "Julian Wharton",
        "Alain Zemkoho"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-11 18:14:20+00:00",
      "link": "https://arxiv.org/pdf/2602.11248v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10936v1",
      "title": "Trajectory-based data-driven predictive control and the state-space predictor",
      "abstract": "We define trajectory predictive control (TPC) as a family of output-feedback indirect data-driven predictive control (DDPC) methods that represent the output trajectory of a discrete-time system as a linear function of the recent input/output history and the planned input trajectory. This paper shows that for different choices of the trajectory predictor, TPC encompasses a wide variety of DDPC methods, including subspace predictive control (SPC), closed-loop SPC, $γ$-DDPC, causal-$γ$-DDPC, transient predictive control, and others. This paper introduces a trajectory predictor that corresponds to a linear state-space model with the recent input/output history as the state. With this state-space predictor, TPC is a special case of linear model predictive control and therefore inherits its mature theory. In numerical experiments, TPC performance approaches the limit of oracle $H_2$-optimal control with perfect knowledge of the underlying system model. For TPC with small training datasets, the state-space predictor outperforms other predictors because it has fewer parameters.",
      "authors": [
        "Levi D. Reyes Premer",
        "Arash J. Khabbazi",
        "Kevin J. Kircher"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "math.OC"
      ],
      "published": "2026-02-11 15:16:35+00:00",
      "link": "https://arxiv.org/pdf/2602.10936v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10920v1",
      "title": "Data assimilation via model reference adaptation for linear and nonlinear dynamical systems",
      "abstract": "We address data assimilation for linear and nonlinear dynamical systems via the so-called \\emph{model reference adaptive system}. Continuing our theoretical developments in \\cite{Tram_Kaltenbacher_2021}, we deliver the first practical implementation of this approach for online parameter identification with time series data. Our semi-implicit scheme couples a modified state equation with a parameter evolution law that is driven by model-data residuals. We demonstrate four benchmark problems of increasing complexity: the Darcy flow, the Fisher-KPP equation, a nonlinear potential equation and finally, an Allen-Cahn type equation. Across all cases, explicit model reference adaptive system construction, verified assumptions and numerically stable reconstructions underline our proposed method as a reliable, versatile tool for data assimilation and real-time inversion.",
      "authors": [
        "Benedikt Kaltenbach",
        "Christian Aarset",
        "Tram Thi Ngoc Nguyen"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "math.AP",
        "math.DS"
      ],
      "published": "2026-02-11 14:55:50+00:00",
      "link": "https://arxiv.org/pdf/2602.10920v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10836v1",
      "title": "Charged particle motion in a strong magnetic field: The first order expansion",
      "abstract": "We provide a mathematically rigorous derivation of the first order expansion of the motion of a charged particle in a strong magnetic field. In contrast to the derivations that can be found in the physics literature we solely assume throughout that the magnetic field is strong. In particular we do not need to make any structural assumptions on the particle motion, such as the gyroradius being small in comparison to the magnetic length scale. Instead, some of the additional assumptions which are usually made in the physics literature turn out to be an a posteriori consequence in our approach. Our approach further justifies the utilisation of the guiding centre approximation at \"bounce points\" within magnetic mirrors, a situation which violates the usual assumptions which are made in the physics literature when deriving the guiding centre approximation.",
      "authors": [
        "Ugo Boscain",
        "Wadim Gerner"
      ],
      "primary_category": "math-ph",
      "categories": [
        "math-ph",
        "math.CA",
        "physics.plasm-ph"
      ],
      "published": "2026-02-11 13:22:08+00:00",
      "link": "https://arxiv.org/pdf/2602.10836v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10822v1",
      "title": "A fluid-solid interaction problem in porous media",
      "abstract": "In this work, we derive asymptotic interface models for an elastic Muskat free boundary problem describing Darcy flow beneath an elastic membrane. In a weakly nonlinear regime of small interface steepness, we obtain nonlocal evolution equations that capture the free-boundary dynamics up to quadratic order. In the long-wave thin-film regime, we rewrite the kinematic condition in flux form, flatten the moving domain, and derive a lubrication-type equation. Moreover, we establish well-posedness for these models in suitable Wiener spaces.",
      "authors": [
        "Diego Alonso-Orán",
        "Rafael Granero-Belinchón"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "physics.flu-dyn"
      ],
      "published": "2026-02-11 13:03:41+00:00",
      "link": "https://arxiv.org/pdf/2602.10822v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10803v2",
      "title": "Bound-Preserving Adaptive Time-Stepping Method with Energy Stability for Simulating Compressible Gas Flow in Poroelastic Media",
      "abstract": "In this paper, we present an efficient numerical method to address a thermodynamically consistent gas flow model in porous media involving compressible gas and deformable rock. The accurate modeling of gas flow in porous media often poses significant challenges due to their inherent nonlinearity, the coupling between gas and rock dynamics, and the need to preserve physical principles such as mass conservation, energy dissipation and molar density boundedness. The system is further complicated by the need to balance computational efficiency with the accuracy and stability of the numerical scheme. To tackle these challenges, we adopt a stabilization approach that is able to preserve the original energy dissipation while achieving linear energy-stable numerical schemes. We also prove the convergence of the adopted linear iterative method. At each time step, the stabilization parameter is adaptively updated using a simple and explicit formula to ensure compliance with the original energy dissipation law. The proposed method uses adaptive time stepping to improve computational efficiency while maintaining solution accuracy and boundedness. The adaptive time step size is calculated explicitly at each iteration, ensuring stability and allowing for efficient handling of highly dynamic scenarios. A mixed finite element method combined with an upwind scheme is employed as spatial discretization to ensure mass conservation and stability. Finally, we conduct a series of numerical experiments to validate the performance and robustness of the proposed numerical method.",
      "authors": [
        "Huangxin Chen",
        "Yuxiang Chen",
        "Jisheng Kou",
        "Shuyu Sun"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-11 12:44:21+00:00",
      "link": "https://arxiv.org/pdf/2602.10803v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10798v1",
      "title": "Trading in CEXs and DEXs with Priority Fees and Stochastic Delays",
      "abstract": "We develop a mixed control framework that combines absolutely continuous controls with impulse interventions subject to stochastic execution delays. The model extends current impulse control formulations by allowing (i) the controller to choose the mean of the stochastic delay of their impulses, and allowing (ii) for multiple pending orders, so that several impulses can be submitted and executed asynchronously at random times. The framework is motivated by an optimal trading problem between centralized (CEX) and decentralized (DEX) exchanges. In DEXs, traders control the distribution of the execution delay through the priority fee paid, introducing a fundamental trade-off between delays, uncertainty, and costs. We study the optimal trading problem of a trader exploiting trading signals in CEXs and DEXs. From a mathematical perspective, we derive the associated dynamic programming principle of this new class of impulse control problems, and establish the viscosity properties of the corresponding quasi-variational inequalities. From a financial perspective, our model provides insights on how to carry out execution across CEXs and DEXs, highlighting how traders manage latency risk optimally through priority fee selection. We show that employing the optimal priority fee has a significant outperformance over non-strategic fee selection.",
      "authors": [
        "Philippe Bergault",
        "Yadh Hafsi",
        "Leandro Sánchez-Betancourt"
      ],
      "primary_category": "q-fin.TR",
      "categories": [
        "q-fin.TR",
        "math.OC"
      ],
      "published": "2026-02-11 12:39:58+00:00",
      "link": "https://arxiv.org/pdf/2602.10798v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10741v1",
      "title": "Wave front set of solutions to Schrödinger equations with time-dependent magnetic fields",
      "abstract": "In this paper, we determine the wave front set of solutions to the Schrödinger equation with time-dependent magnetic fields. We considered time-dependent and `not so small' magnetic fields through the method using the wave packet transform established by K. Kato, M. Kobayashi and S. Ito. Furthermore, we checked that the fundamental solution of the Schrödinger equation in a spatially decaying magnetic field has no singularities as a consequence of our result.",
      "authors": [
        "Fumihito Abe",
        "Ryo Muramatsu"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-11 11:04:54+00:00",
      "link": "https://arxiv.org/pdf/2602.10741v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10689v1",
      "title": "An Efficient Energy Stable Structure Preserving Method for The Landau-Lifshitz Equation",
      "abstract": "One of the main difficulties in micromagnetics simulation is the norm preserving constraints $\\|\\mathbf{m}\\|=1$ at the continuous or the discrete level. Another difficulty is the stability with the time step constraint. Using standard explicit integrators leads to a physical time step of sub-pico seconds, which is often two orders of magnitude smaller than the fastest physical time scales. Direct implicit integrators require solving complicated, coupled systems. Another major difficulty with the projection method in this field is the lack of rigorous theoretical guarantees regarding its stability of the projection step. In this paper, we introduce a first order method. Such a method is structure preserving based on a combination of a Gauss-Seidel iteration, a double diffusion iteration and a Crank-Nicolson iteration to preserve the norm constraints.",
      "authors": [
        "Changjian Xie",
        "Yingxi Miao",
        "Haocheng Yang"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-11 09:44:54+00:00",
      "link": "https://arxiv.org/pdf/2602.10689v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10678v1",
      "title": "Stabilization of nonautonomous Navier-Stokes flows under dynamic slip boundary conditions",
      "abstract": "Exponential stabilizability of the incompressible Navier-Stokes equations under dynamic slip boundary conditions toward arbitrary time-dependent trajectories is proven. The feedback control law is constructed explicitly using oblique projections and realized through a finite number of spatially localized interior actuators, without requiring spectral assumptions. The approach extends to various slip boundary condition types (Navier, vorticity-type, and Neumann) and applies to multi-connected domains. Weak solution existence and exponential decay estimates are established, with the stabilization rate depending on the boundary dynamics parameters.",
      "authors": [
        "Buddhika Priyasad",
        "Sérgio S. Rodrigues"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "math.OC"
      ],
      "published": "2026-02-11 09:21:30+00:00",
      "link": "https://arxiv.org/pdf/2602.10678v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10509v1",
      "title": "Stationary periodic solutions to Nonlinear Dirac equations with non-coercive potentials",
      "abstract": "We obtain periodic solutions for nonlinear Dirac equations with a nonlinear term that is not necessarily coercive.   This amounts to study the equation on a three-dimensional torus.   The Palais-Smale condition is enhanced by involving a coercive perturbation.   Uniform estimates for the critical levels as well as the Sobolev norms for the perturbed solutions are obtained, making it possible to pass to a limit which gives a nontrivial solution.",
      "authors": [
        "Fuping Zhang",
        "Ruijun Wu"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-11 04:16:16+00:00",
      "link": "https://arxiv.org/pdf/2602.10509v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10464v1",
      "title": "Do More Predictions Improve Statistical Inference? Filtered Prediction-Powered Inference",
      "abstract": "Recent advances in artificial intelligence have enabled the generation of large-scale, low-cost predictions with increasingly high fidelity. As a result, the primary challenge in statistical inference has shifted from data scarcity to data reliability. Prediction-powered inference methods seek to exploit such predictions to improve efficiency when labeled data are limited. However, existing approaches implicitly adopt a use-all philosophy, under which incorporating more predictions is presumed to improve inference. When prediction quality is heterogeneous, this assumption can fail, and indiscriminate use of unlabeled data may dilute informative signals and degrade inferential accuracy. In this paper, we propose Filtered Prediction-Powered Inference (FPPI), a framework that selectively incorporates predictions by identifying a data-adaptive filtered region in which predictions are informative for inference. We show that this region can be consistently estimated under a margin condition, achieving fast rates of convergence. By restricting the prediction-powered correction to the estimated filtered region, FPPI adaptively mitigates the impact of biased or noisy predictions. We establish that FPPI attains strictly improved asymptotic efficiency compared with existing prediction-powered inference methods. Numerical studies and a real-data application to large language model evaluation demonstrate that FPPI substantially reduces reliance on expensive labels by selectively leveraging reliable predictions, yielding accurate inference even in the presence of heterogeneous prediction quality.",
      "authors": [
        "Shirong Xu",
        "Will Wei Sun"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "stat.ML"
      ],
      "published": "2026-02-11 03:02:24+00:00",
      "link": "https://arxiv.org/pdf/2602.10464v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10463v1",
      "title": "Fractional Hardy inequalities on $C^{1,1}$ open sets",
      "abstract": "Let $Ω$ be a bounded open set of class $C^{1,1}$ in $\\mathbb{R}^N$ and $s\\in(\\frac{1}{2}, 1)$. We study a family of fractional Hardy-type inequalities \\begin{equation} \\frac{c_{N,s}}{2}\\displaystyle\\iint_{Ω\\timesΩ}\\frac{(u(x)-u(y))^2}{|x-y|^{N+2s}}\\ dxdy-\\displaystyleλ\\int_Ωu^2\\ dx\\geq C\\displaystyle\\int_Ω\\frac{u^2}{δ^{2s}}\\ dx,~~~\\quad\\forallλ\\in\\mathbb{R},~~~~~~~(0.1) \\end{equation} with $u\\in C_c^\\infty(Ω)$ and $C=C(Ω,s,N,λ)>0$. We show that the best constant in $(0.1)$ is achieved if and only if $λ>λ^*(s,Ω)$, for some $λ^*(s,Ω)\\in\\mathbb{R}$. As a by-product, we derive in particular that the best constant in Hardy inequality $μ_{N,s}(Ω)$ is achieved if and only if $μ_{N,s}(Ω)<\\mathfrak{h}_{N,s}$, with $\\mathfrak{h}_{N,s}$ being the best constant for the fractional Hardy inequality in the half space. Moreover, if $Ω$ is a convex open set, we obtain a lower bound for $λ^*(s,Ω)$ in terms of the volume of $Ω$. Specifically, we prove that $λ^*(s,Ω)\\geq a(N,s)|Ω|^{-\\frac{2s}{N}}$ with an explicit constant $a(N,s)>0$. For general bounded $C^{1,1}$ open sets, we prove instead that $λ^*(s,Ω)\\geq0$ when $s$ is close to $\\frac{1}{2}$. The aforementioned result is proved after showing that $μ_{N,s}(Ω)=\\mathfrak{h}_{N,s}$ for $s$ close to $\\frac{1}{2}$. In particular, we deduce that, whenever $s$ is sufficiently close to $\\frac{1}{2}$, the Hardy constant $μ_{N,s}(Ω)$ is never achieved, hence, behaves differently from that in the local case. This result is completely new in the fractional setting, and was known only for convex open sets for the full range $s\\in(\\frac{1}{2}, 1)$.",
      "authors": [
        "Abdelrazek Dieb",
        "Remi Yvant Temgoua"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-11 03:01:37+00:00",
      "link": "https://arxiv.org/pdf/2602.10463v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10373v1",
      "title": "Convolution comparison measures",
      "abstract": "We give a precise functional comparison between classical and free convolutions. If $μ$ and $ν$ are compactly supported probability measures, we show that the expectation of $f$ over the classical convolution $μ* ν$ is at least the expectation of $f$ over the free convolution $μ\\boxplus ν$, as long as the fourth derivative of $f$ is non-negative. Conversely, the non-negativity of the fourth derivative is necessary for such a comparison.   This comparison is based on the positivity of a related measure on $\\mathbb{R}^{2}$, which we dub the convolution comparison measure. We give an expression for this measure using a curious identity involving Hermitian matrices.",
      "authors": [
        "Otte Heinävaara"
      ],
      "primary_category": "math.FA",
      "categories": [
        "math.FA",
        "math.OA",
        "math.PR"
      ],
      "published": "2026-02-10 23:46:54+00:00",
      "link": "https://arxiv.org/pdf/2602.10373v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10363v1",
      "title": "Transonic Buffet Modeling via Invariant Manifolds",
      "abstract": "In transonic flow over aircraft wings, shock-boundary-layer interactions can give rise to transonic buffet, which degrades maneuverability through unsteady aerodynamic loads. Beyond its practical importance, two-dimensional transonic buffet represents a canonical example of a global instability for which reduced-order modeling remains challenging due to nonlinearity, sharp spatial gradients, and the coexistence of an unstable equilibrium with an attracting limit cycle. Commonly, reduced-order models of such phenomena capture nonlinear dynamics only in aerodynamic observables, while prediction of the full flow state is achieved through linear representations valid only near the unstable equilibrium or on the limit cycle.   In this work, we present a reduced-order model that predicts the nonlinear evolution of the full flow field by exploiting the existence of an attracting two-dimensional invariant manifold. We adapt an existing data-driven framework for identifying invariant manifolds and the associated reduced dynamics, making it suitable for scaling to large-scale CFD applications. The invariant manifold is identified as a graph over its tangent space using an iterative encoder-update and the reduced dynamics are obtained via least-squares regression. A subsequent extended normal-form transformation enables physical interpretability of the model through a modal decomposition of the flow.   The reduced-order model is identified for transonic buffet over the OAT15A supercritical airfoil, showing that it is possible to achieve this accurately using just a single training trajectory. Validation against independent simulations demonstrates accurate prediction of nonlinear behavior, together with reliable reconstruction of the full flow field, particularly in the late-transient and limit-cycle regimes.",
      "authors": [
        "Tea Vojković",
        "David Quero",
        "Rahul Jayaraj",
        "Christoph Kaiser",
        "Dimitris Boskos",
        "Abel-John Buchner"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "math.DS"
      ],
      "published": "2026-02-10 23:29:18+00:00",
      "link": "https://arxiv.org/pdf/2602.10363v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10274v1",
      "title": "Asymptotic equivalence for nonparametric additive regression",
      "abstract": "We prove asymptotic equivalence of nonparametric additive regression and an appropriate Gaussian white noise experiment in which a multidimensional shifted Wiener process is observed, whose dimension equals the number of additive components. The shift depends on the additive components of the regression function and solely the one- and two-dimensional marginal distributions of the covariates via an explicitly specified bounded but non-compact linear operator~$Γ$. The number of additive components $d$ is allowed to increase moderately with respect to the sample size. In the special case of pairwise independent components of the covariates, the white noise model decomposes into $d$ independent univariate processes. Moreover, we study approximation in some semiparametric setting where $Γ$ splits into a multiplication operator and an asymptotically negligible Hilbert-Schmidt operator.",
      "authors": [
        "Moritz Jirak",
        "Alexander Meister",
        "Angelika Rohde"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST"
      ],
      "published": "2026-02-10 20:35:34+00:00",
      "link": "https://arxiv.org/pdf/2602.10274v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10263v1",
      "title": "New logarithmic power nonlinear Schrödinger equations with super-Gaussons",
      "abstract": "We introduce a new class of nonlinear Schrödinger equations with a logarithmic-power nonlinearity that admits exact localized solutions of super-Gaussian form. The resulting stationary states possess flat-top profiles with sharp edges and are referred to as super-Gaussons, in analogy with the Gaussian Gaussons of the classical logarithmic NLS (log-NLS). The model, which we call the logarithmic-power NLS (logp-NLS), is parameterized by an exponent $p\\geq1$ that controls the degree of flatness of the soliton core and the sharpness of its decay. Mathematically, $p$ interpolates between the standard log-NLS ($p=1$) and increasingly flat-top profiles as $p$ increases, while physically it governs the stiffness of an underlying logarithmic-power compressibility law. The proposed equation is constructed so as to admit super-Gaussian stationary states and can be interpreted a posteriori within a generalized pressure-law framework, thereby extending the log-NLS. We investigate the dynamics of super-Gaussons in one spatial dimension through numerical simulations for various values of $p$, demonstrating how this parameter regulates both the internal structure of the soliton and its collision dynamics. The logp-NLS thus generalizes the standard log-NLS by admitting a broader family of localized states with distinctive structural and dynamical properties, suggesting its relevance for flat-top solitons in nonlinear optics, Bose-Einstein condensates, and related nonlinear media.",
      "authors": [
        "Hadi Susanto"
      ],
      "primary_category": "nlin.PS",
      "categories": [
        "nlin.PS",
        "math.AP"
      ],
      "published": "2026-02-10 20:14:40+00:00",
      "link": "https://arxiv.org/pdf/2602.10263v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10240v1",
      "title": "New Types of Sturm bounds via $p$-adic transfer methods",
      "abstract": "Sturm's theorem states that a modular form with coefficients in $\\mathbb{Z}$ or $\\mathbb{Z}/m\\mathbb{Z}$ can only have an explicitly bounded order of vanishing at infinity. This result is one of the most powerful computational tools in the study of modular forms, and has widespread applications to congruences and other kinds of explicit calculations in mathematics and physics. In this paper, we formulate a new ``$p$-adic transfer method\" that lifts Sturm-type bounds from one space to another using exclusively non-geometric inputs. As an application, we transfer the Sturm bounds for classical modular forms to the space of quasimodular forms of level one. These bounds are applicable uniformly for quasimodular forms with coefficients in $\\mathbb{Z}$ or $\\mathbb{Z}/m\\mathbb{Z}$, which extends the non-uniform results for $\\mathbb{Z}/m\\mathbb{Z}$ only which can be derived from classical theories. We also discuss the potential for future applications to other quasi- and mixed-weight modular objects, and perhaps even entirely non-modular objects.",
      "authors": [
        "William Craig"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-02-10 19:35:46+00:00",
      "link": "https://arxiv.org/pdf/2602.10240v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10061v1",
      "title": "Confinement results near point vortices on the rotating sphere",
      "abstract": "We study the Euler equation on the rotating sphere in the case where the absolute vorticity is initially sharply concentrated around several points. We follow the literature already concerning vorticity confinement for the planar Euler equations, and obtain similar results on the rotating sphere, with new challenges due to the geometry. More precisely, we show the improbability of collisions for point-vortices, logarithmic in time absolute vorticity confinement for general configurations, the optimality of this last result in general, and the existence of configurations with power-law long confinement. We take this opportunity to write a unified, self-contained, and improved version of all the proofs, previously scattered across multiple papers on the planar case, with detailed exposition for pedagogical clarity.",
      "authors": [
        "Martin Donati",
        "Emeric Roulley"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "physics.ao-ph"
      ],
      "published": "2026-02-10 18:29:35+00:00",
      "link": "https://arxiv.org/pdf/2602.10061v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10055v1",
      "title": "The weak law of large numbers for the friendship paradox index",
      "abstract": "The friendship paradox index is a network summary statistic used to quantify the friendship paradox, which describes the tendency for an individual's friends to have more friends than the individual. In this paper, we utilize Markov's inequality to derive the weak law of large numbers for the friendship paradox index in a random geometric graph, a widely-used model for networks with spatial dependence and geometry. For uniform random geometric graph, where the nodes are uniformly distributed in a space, the friendship paradox index is asymptotically equal to $1/4$. On the contrary, in nonuniform random geometric graphs, the nonuniform node distribution leads to distinct limiting properties for the index. In the relatively sparse regime, the friendship paradox index is still asymptotically equal to $1/4$, the same as in the uniform case. In the intermediate sparse regime, however, the index converges in probability to $1/4$ plus a constant that is explicitly dependent on the node distribution. Finally, in the relatively dense case, the index diverges to infinity as the graph size increases. Our results highlight the sharp contrast between the uniform case and its nonuniform counterpart.",
      "authors": [
        "Mingao Yuan"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST"
      ],
      "published": "2026-02-10 18:22:14+00:00",
      "link": "https://arxiv.org/pdf/2602.10055v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09996v2",
      "title": "Learning to Choose Branching Rules for Nonconvex MINLPs",
      "abstract": "Outer-approximation-based branch-and-bound is a common algorithmic framework for solving MINLPs (mixed-integer nonlinear programs) to global optimality, with branching variable selection critically influencing overall performance. In modern global MINLP solvers, it is unclear whether branching on fractional integer variables should be prioritized over spatial branching on variables, potentially continuous, that show constraint violations, with different solvers following different defaults. We address this question using a data-driven approach. Based on a test set of hundreds of heterogeneous public and industrial MINLP instances, we train linear and random forest regression models to predict the relative speedup of the FICO(R) Xpress Global solver when using a branching rule that always prioritizes variables with violated integralities versus a mixed rule, allowing for early spatial branches.   We introduce a practical evaluation methodology that measures the effect of the learned model directly in terms of the shifted geometric mean runtime. Using only four features derived from strong branching and the nonlinear structure, our linear regression model achieves an 8-9% reduction in geometric-mean solving time for the Xpress solver, with over 10% improvement on hard instances. We also analyze a random regression forest model. Experiments across solver versions show that a model trained on Xpress 9.6 still yields significant improvements on Xpress 9.8 without retraining.   Our results demonstrate how regression models can successfully guide the branching-rule selection and improve the performance of a state-of-the-art commercial MINLP solver.",
      "authors": [
        "Timo Berthold",
        "Fritz Geis"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-10 17:20:38+00:00",
      "link": "https://arxiv.org/pdf/2602.09996v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09966v1",
      "title": "Graded Betti numbers of the Jacobian algebra of surfaces in $\\mathbb P^3$",
      "abstract": "We compute an explicit closed formula for the Hilbert polynomial of the Jacobian algebra $M(f)$ of a reduced surface $X:f=0$ in $\\mathbb P^3$ in terms of the graded Betti numbers of the algebra $M(f)$. When $X$ has only isolated singularities, a result by A. du Plessis and C. T. C. Wall yields new necessary condition for a set of positive integers to be the graded Betti numbers of the Jacobian algebra of such a surface. The comparison with the plane curve case is discussed in detail and additional information is given in the case of nodal surfaces.",
      "authors": [
        "Alexandru Dimca",
        "Gabriel Sticlaru"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "math.AC"
      ],
      "published": "2026-02-10 16:54:14+00:00",
      "link": "https://arxiv.org/pdf/2602.09966v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09946v1",
      "title": "A Viscosity Framework for Dynamic Programming Principles and Applications",
      "abstract": "In this work we introduce a viscosity-based notion of solution for general approximation schemes associated with partial differential equations, such as dynamic programming principles~(DPPs). A key feature of our approach is that it bypasses any measurability requirement on solutions of the DPP, an assumption that is often difficult to verify and may even fail in relevant examples. We establish a comparison principle between classical strict supersolutions and viscosity subsolutions of the DPP, which yields stability results under minimal and natural hypotheses. As a consequence, we prove existence of viscosity solutions of the DPP and their convergence to viscosity solutions of a PDE that is consistent with the underlying approximation scheme. Moreover, we show that solutions of the limiting PDE admit an asymptotic expansion encoded by the approximation operator. Finally, we demonstrate that a broad class of local, nonlocal, and nonlinear partial differential equations fits into our framework, recovering known examples in the literature and completing gaps in the existing literature.",
      "authors": [
        "Félix del Teso",
        "Julio D. Rossi",
        "Jorge Ruiz-Cases"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-10 16:30:13+00:00",
      "link": "https://arxiv.org/pdf/2602.09946v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09906v1",
      "title": "Regularity for Doubly Nonlinear Equations in the Mixed Regime",
      "abstract": "We study the local Hölder continuity of nonnegative solutions to doubly nonlinear equations by introducing a new technique that allows us to treat the cases where the equation is both singular and degenerate, up to specific Barenblatt numbers. Our argument relies on a new integral $L^1$-$L^1$ Harnack estimate, of independent interest.",
      "authors": [
        "Simone Ciani",
        "Eurica Henriques",
        "Mariia Savchenko",
        "Igor I. Skrypnik",
        "Yevgeniia Yevgenieva"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-10 15:40:47+00:00",
      "link": "https://arxiv.org/pdf/2602.09906v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09875v1",
      "title": "Multi-species kinetic models: GENERIC formulation and Fisher information",
      "abstract": "In this paper, we study the GENERIC structures of multi-species spatially inhomogeneous Boltzmann and Landau equations with Bose-Einstein, Maxwell-Boltzmann, and Fermi-Dirac statistics. In addition, under suitable assumptions on the collision kernels, we show that the Fisher information for the multi-species spatially homogeneous Boltzmann equation is non-increasing in time.",
      "authors": [
        "Manh Hong Duong",
        "Zihui He"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-10 15:17:53+00:00",
      "link": "https://arxiv.org/pdf/2602.09875v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09831v1",
      "title": "First explicit reciprocity law for unitary Friedberg--Jacquet periods",
      "abstract": "Consider a unitary group $G(\\mathbb{A}_{F^+})=U_{2r}(\\mathbb{A}_{F^+})$ over a CM extension $F/F^+$ with $G(\\mathbb{A}_\\infty)$ compact. In this article, we study the Beilinson--Bloch--Kato conjecture for motives associated to irreducible cuspidal automorphic representations $π$ of $G(\\mathbb{A}_{F^+}).$ We prove that if $π$ is distinguished by the unitary Friedberg--Jacquet period, then the Bloch--Kato Selmer group (with coefficients in a favorable field) of the motive of $Π=\\mathrm{BC}(π)$ vanishes.",
      "authors": [
        "Murilo Corato-Zanarella"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-02-10 14:37:37+00:00",
      "link": "https://arxiv.org/pdf/2602.09831v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09806v1",
      "title": "Convergence to pushed fronts and the behavior of level sets in monostable reaction-diffusion equations",
      "abstract": "We study the behavior of solutions of a monostable reaction-diffusion equation $u_t=Δ_x u +u_{yy} +f(u)$ ($x \\in \\mathbb{R}^{n-1}$, $y \\in \\mathbb{R}$, $t>0$), with the unstable equilibrium point $0$ and the stable equilibrium point $1$. Under the condition that the corresponding one-dimensional equation has a pushed front $Φ_{c^*}(z)$ with $Φ_{c^*}(-\\infty)=1$, $Φ_{c^*}(\\infty)=0$, we show that the solution $u(x,y,t)$ approaches $Φ_{c^*}(y-γ(x,t))$ for some $γ(x,t)$ as $t \\to \\infty$, if initially $u(x,y,0)$ decays sufficiently fast as $y \\to \\infty$ and is bounded below by some positive constant near $y=-\\infty$. It is also shown that $γ(x,t)$ is approximated by the mean curvature flow with a drift term.",
      "authors": [
        "Ryo Kiyono"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-10 14:12:14+00:00",
      "link": "https://arxiv.org/pdf/2602.09806v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09799v1",
      "title": "Time-marching representation based quantum algorithms for the Lattice Boltzmann model of the advection-diffusion equation",
      "abstract": "This article introduces a novel framework for developing quantum algorithms for the Lattice Boltzmann Method (LBM) applied to the advection-diffusion equation. We formulate the collision-streaming evolution of the LBM as a compact time-marching scheme and rigorously establish its stability under low Mach number conditions. This unified formulation eliminates the need for classical measurement at each time step, enabling a systematic and fully quantum implementation. Building upon this representation, we investigate two distinct quantum algorithmic approaches. The first is a time-marching quantum algorithm realized through sequential evolution operators, for which we provide a detailed implementation-including block-encoding and dilating unitarization-along with a full complexity analysis. The second employs a quantum linear systems algorithm, which encodes the entire time evolution into a single global linear system. We demonstrate that both methods achieve comparable asymptotic time complexities. The proposed algorithms are validated through numerical simulations of benchmark problems in one and two dimensions. This work provides a systematic, measurement-free pathway for the quantum simulation of advection-diffusion processes via the lattice Boltzmann paradigm.",
      "authors": [
        "Yuan He",
        "Yuan Yu",
        "Yue Yu"
      ],
      "primary_category": "math-ph",
      "categories": [
        "math-ph"
      ],
      "published": "2026-02-10 14:03:53+00:00",
      "link": "https://arxiv.org/pdf/2602.09799v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09778v1",
      "title": "Phase Transition With Rapini-Papoular Surface Anchoring",
      "abstract": "We analyze the dynamical (in)stability of nematic liquid crystals in the presence of external magnetic fields and Rapini-Papoular surface potential. The P-HAN transition is investigated using a simplified 3D Ericksen-Leslie system. We find the thickness threshold of the P-HAN transition. If the thickness of the nematic layer exceeds this threshold, there is a global-in-time suitable weak solution converging exponentially to a nontrivial equilibrium state as time tends to infinity. If the thickness is no more than the threshold, the global-in-time suitable weak solution has a trivial long-time asymptotic limit. Our results rigorously justify the P-HAN transition discussed in the physics literature.",
      "authors": [
        "Shun Li",
        "Yong Yu"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-10 13:38:02+00:00",
      "link": "https://arxiv.org/pdf/2602.09778v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09756v1",
      "title": "Discrete equations from Bäcklund transformations of the fifth Painlevé equation",
      "abstract": "In this paper discrete equations are derived from Bäcklund transformations of the fifth Painlevé equation, including a new discrete equation which has ternary symmetry. There are two classes of rational solutions of the fifth Painlevé equation, one expressed in terms of the generalised Laguerre polynomials and the other in terms of the generalised Umemura polynomials, both of which can be expressed as Wronskians of Laguerre polynomials. Hierarchies of rational solutions of the discrete equations are derived in terms of the generalised Laguerre and generalised Umemura polynomials. It is known that there is nonuniqueness of some rational solutions of the fifth Painlevé equation. Pairs of nonunique rational solutions are used to derive distinct hierarchies of rational solutions which satisfy the same discrete equation.",
      "authors": [
        "Peter A. Clarkson",
        "Clare Dunning",
        "Ben Mitchell"
      ],
      "primary_category": "nlin.SI",
      "categories": [
        "nlin.SI",
        "math-ph",
        "math.CA"
      ],
      "published": "2026-02-10 13:09:24+00:00",
      "link": "https://arxiv.org/pdf/2602.09756v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09734v1",
      "title": "Mathematical Foundation for the Generalised Brillouin zone of m-banded Toeplitz operators",
      "abstract": "We show that the spectrum of the open-boundary limit of banded Toeplitz matrices is real whenever the associated symbol function is real-valued along a closed polar curve. Building on this result, we develop both analytical and numerical methods to symmetrise a class of banded non-Hermitian Toeplitz matrices whose asymptotic spectra are real. Finally, we provide a rigorous mathematical foundation for the generalised Brillouin zone, a concept widely used in non-Hermitian physics, by proving that it coincides with the polar curve on which the symbol function takes real values.",
      "authors": [
        "Yannick de Bruijn",
        "Erik Orvehed Hiltunen"
      ],
      "primary_category": "math.SP",
      "categories": [
        "math.SP"
      ],
      "published": "2026-02-10 12:44:09+00:00",
      "link": "https://arxiv.org/pdf/2602.09734v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09729v1",
      "title": "Beyond Free-Stream Preservation: Transport Polynomial Exactness for Moving-Mesh Methods under Arbitrary Mesh Motion",
      "abstract": "High-order moving-mesh methods can effectively reduce numerical diffusion, but their formal accuracy typically relies on the regularity of the mesh velocity. This dependency creates a fundamental conflict in the numerical solution of hyperbolic conservation laws, where solution-driven adaptation may induce nonsmooth mesh motion, thereby degrading convergence order. We introduce \\emph{transport polynomial exactness} (TPE($k$)), a mesh-motion-independent criterion that generalizes classical free-stream preservation (TPE(0)) to the exact advection of degree-$k$ polynomials. We show that the classical geometric conservation law (GCL) is insufficient to ensure TPE($k$) for $k \\ge 1$ due to mismatches in higher-order geometric moments. To resolve this, we propose \\emph{evolved geometric moments} (EGMs), obtained by solving auxiliary transport equations discretized compatibly with the physical variables. We rigorously prove that second-degree EGMs evolved via the third-order strong stability preserving Runge--Kutta (SSPRK3) method coincide with the exact geometric moments. This exactness arises from a \\emph{superconvergence} mechanism wherein SSPRK3 reduces to Simpson's rule for EGM evolution. Leveraging this result, we construct a third-order conservative finite-volume rezoning moving-mesh scheme. The scheme satisfies the TPE(2) property for \\emph{arbitrary mesh motion} and \\emph{any pseudo-time step size}, thereby naturally accommodating spatiotemporally discontinuous mesh velocity. Crucially, this \\emph{breaks the efficiency bottleneck} in the conventional advection-based remapping step and reduces the required pseudo-time levels from $\\mathcal{O}(h^{-1})$ to $\\mathcal{O}(1)$ under bounded but discontinuous mesh velocity. Numerical experiments verify exact quadratic transport and stable third-order convergence under extreme mesh deformation, demonstrating substantial efficiency gains.",
      "authors": [
        "Chaoyi Cai",
        "Qiqin Cheng",
        "Di Wu",
        "Jianxian Qiu"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-10 12:33:46+00:00",
      "link": "https://arxiv.org/pdf/2602.09729v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09687v1",
      "title": "On a generalization of the Brocard--Ramanujan Diophantine equation",
      "abstract": "Let $Q_1,...,Q_r\\in \\mathbb{Z}[x]$ be polynomials having $0$ as a root. Let $f(x,y)\\in\\mathbb{Z}[x,y]$ be a homogeneous polynomial with factorization $f(x,y)=f_1(x,y)^{e_1}\\cdots f_u(x,y)^{e_u}$, where $f_i(x,y)$ are irreducible homogeneous polynomials of degree $d_i\\geq 2$. Fix some positive integers $A_1,...,A_r$. We show that under certain conditions, the diophantine equation $\\prod_{i=1}^rQ_i(A_i^{n_i}n_i!)=f(x,y)$ has finitely many integer solutions.",
      "authors": [
        "Saša Novaković"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-02-10 11:41:35+00:00",
      "link": "https://arxiv.org/pdf/2602.09687v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09679v1",
      "title": "Real time filtering algorithms",
      "abstract": "This paper presents a systematic review of recent advances in nonlinear filtering algorithms, structured into three principal categories: Kalman-type methods, Monte Carlo methods, and the Yau-Yau algorithm. For each category, we provide a comprehensive synthesis of theoretical developments, algorithmic variants, and practical applications that have emerged in recent years. Importantly, this review addresses both continuous-time and discrete-time system formulations, offering a unified review of filtering methodologies across different frameworks. Furthermore, our analysis reveals the transformative influence of artificial intelligence breakthroughs on the entire nonlinear filtering field, particularly in areas such as learning-based filters, neural network-augmented algorithms, and data-driven approaches.",
      "authors": [
        "Chang Qin",
        "Yikun Li",
        "Ru Qian",
        "Jiayi Kang",
        "Yao Mao"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-10 11:36:10+00:00",
      "link": "https://arxiv.org/pdf/2602.09679v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09671v1",
      "title": "Input-to-state stabilization of an ODE cascaded with a parabolic equation involving Dirichlet-Robin boundary disturbances",
      "abstract": "This paper focuses on the input-to-state stabilization problem for an ordinary differential equation (ODE) cascaded by parabolic partial differential equation (PDE) in the presence of Dirichlet-Robin boundary disturbances, as well as in-domain disturbances. For the cascaded system with a Dirichlet pointwise interconnection, the ODE takes the value of a Robin boundary condition at the ODE-PDE interface as its direct input, and the PDE is driven by a Dirichlet boundary input at the opposite end. We first employ the backstepping method to design a boundary controller and to decouple the cascaded system. This decoupling facilitates independent stability analysis of the PDE and ODE systems sequentially. Then, to address the challenges posed by Dirichlet boundary disturbances to the application of the classical Lyapunov method, we utilize the generalized Lyapunov method to establish the ISS in the max-norm for the cascaded system involving Dirichlet boundary disturbances and two other types of disturbances. The obtained result indicates that even in the presence of different types of disturbances, ISS analysis can still be conducted within the framework of Lyapunov stability theory. For the well-posedness of the target system, it is conducted by using the technique of lifting and the semigroup method. Finally, numerical simulations are conducted to illustrate the effectiveness of the proposed control scheme and ISS properties for a cascaded system with different disturbances.",
      "authors": [
        "Yongchun Bi",
        "Jun Zheng",
        "Guchuan Zhu"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-10 11:27:30+00:00",
      "link": "https://arxiv.org/pdf/2602.09671v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09650v1",
      "title": "LDG method for solving spatial and temporal fractional nonlinear convection-diffusion equations",
      "abstract": "This paper focuses on a nonlinear convection-diffusion equation with space and time-fractional Laplacian operators of orders $1<β<2$ and $0<α\\leq1$, respectively. We develop local discontinuous Galerkin methods, including Legendre basis functions, for a solution to this class of fractional diffusion problem, and prove stability and optimal order of convergence $O(h^{k+1}+(Δt)^{1+\\frac{p}{2}}+p^2)$. This technique turns the equation into a system of first-order equations and approximates the solution by selecting the appropriate basis functions. Regarding accuracy and stability, the basis functions greatly improve the method. According to the numerical results, the proposed scheme performs efficiently and accurately in various conditions and meets the optimal order of convergence.",
      "authors": [
        "Majid Rajabzadeh",
        "Moein Khalighi"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-10 10:56:07+00:00",
      "link": "https://arxiv.org/pdf/2602.09650v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09584v1",
      "title": "Homogenization of nonlocal equations in randomly evolving media. Diffusion approximation",
      "abstract": "The paper deals with homogenization and higher order approximations of solutions to nonlocal evolution equations of convolution type whose coefficients are periodic in the spatial variables and random stationary in time. We assume that the convolution kernel has finite moments up to order three. Under proper mixing assumptions, we study the limit behavior of the normalized difference between solutions of the original and the homogenized problems and show that this difference converges to the solution of a linear stochastic partial differential equation.",
      "authors": [
        "Marina Kleptsyna",
        "Andrey Piatnitski",
        "Alexandre Popier"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "math.PR"
      ],
      "published": "2026-02-10 09:35:47+00:00",
      "link": "https://arxiv.org/pdf/2602.09584v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09547v1",
      "title": "The Porous Medium Equation: Multiscale Integrability in Large Deviations",
      "abstract": "We consider a zero-range process $η^N_t(x)$ with superlinear local jump rate, which in a hydrodynamic-small particle rescaling converges to the porous medium equation $\\partial_t u=\\frac12Δu^α, α>1$. As a main result we obtain a large deviation principle in any scaling regime of vanishing particle size $χ_N\\to 0$. The key challenge is to develop uniform integrability estimate on the nonlinearity $(η^N(x))^α$ in a situation where neither pathwise regularity nor Dirichlet-form based regularity is readily available. We resolve this by introducing a novel multiscale argument exploiting the appearance of pathwise regularity across scales.",
      "authors": [
        "Benjamin Gess",
        "Daniel Heydecker"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-02-10 08:57:41+00:00",
      "link": "https://arxiv.org/pdf/2602.09547v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09505v1",
      "title": "Interpolating between Tikhonov regularization and spectral cutoff",
      "abstract": "Regularizing a linear ill-posed operator equation can be achieved by manipulating the spectrum of the operator's pseudo-inverse. Tikhonov regularization and spectral cutoff are well-known techniques within this category. This paper introduces an interpolating formula that defines a one-parameter family of regularizations, where Tikhonov and spectral cutoff methods are represented as limiting cases. By adjusting the interpolating parameter taking into account the specific operator equation under consideration, it is possible to mitigate the limitations associated with both Tikhonov and spectral cutoff regularizations. The proposed approach is demonstrated through numerical simulations in the fields of signal and image processing.",
      "authors": [
        "Martin Sæbye Carøe",
        "Mirza Karamehmedović",
        "Pierre Maréchal"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-10 08:05:27+00:00",
      "link": "https://arxiv.org/pdf/2602.09505v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09298v1",
      "title": "On integrals of non-autonomous dynamical systems in finite characteristic",
      "abstract": "We use a difference Lax form to construct simultaneous integrals of motion of the fourth Painlevé equation and the difference second Painlevé equation over fields with finite characteristic $p>0$. For $p\\neq 3$, we show that the integrals can be normalised to be completely invariant under the corresponding extended affine Weyl group action. We show that components of reducible fibres of integrals correspond to reductions to Riccatti equations. We further describe a method to construct non-rational algebraic solutions in a given positive characteristic. We also discuss a projective reduction of the integrals.",
      "authors": [
        "Nalini Joshi",
        "Pieter Roffelsen"
      ],
      "primary_category": "nlin.SI",
      "categories": [
        "nlin.SI",
        "math-ph"
      ],
      "published": "2026-02-10 00:31:10+00:00",
      "link": "https://arxiv.org/pdf/2602.09298v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09293v1",
      "title": "Ions-electrons-states for the two-component Vlasov-Poisson equation",
      "abstract": "We establish both local and global bifurcation results for traveling periodic solutions of the one-dimensional two-species Vlasov-Poisson equation. These solutions consist of strip-like regions of ions and electrons in phase space that propagate coherently and emerge from spatially homogeneous, velocity-dependent equilibrium layers. Depending on the geometry of the underlying equilibrium and on the selected Fourier mode, the bifurcation diagram exhibits either two or four solution branches. In all cases, the bifurcation is of pitchfork type; in symmetric configurations, the local structure near the equilibrium has a hyperbolic geometry. We further show that these locally constructed branches extend globally. This work extends the previous study by the same author of the purely electronic case, where the ions were modeled as an immobile neutralizing background. Allowing both species to evolve dynamically leads to a more intricate, higher-dimensional analysis. Finally, by means of an affine change of variables, we reveal a connection with the one-dimensional two-component Euler-Poisson system, which in turn enables the construction of traveling periodic waves of both small and large amplitude for that model as well.",
      "authors": [
        "Emeric Roulley"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "physics.plasm-ph"
      ],
      "published": "2026-02-10 00:23:18+00:00",
      "link": "https://arxiv.org/pdf/2602.09293v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09279v1",
      "title": "Stochastic EM Estimation and Inference for Zero-Inflated Beta-Binomial Mixed Models for Longitudinal Count Data",
      "abstract": "Analyzing overdispersed, zero-inflated, longitudinal count data poses significant modeling and computational challenges, which standard count models (e.g., Poisson or negative binomial mixed effects models) fail to adequately address. We propose a Zero-Inflated Beta-Binomial Mixed Effects Regression (ZIBBMR) model that augments a beta-binomial count model with a zero-inflation component, fixed effects for covariates, and subject-specific random effects, accommodating excessive zeros, overdispersion, and within-subject correlation. Maximum likelihood estimation is performed via a Stochastic Approximation EM (SAEM) algorithm with latent variable augmentation, which circumvents the model's intractable likelihood and enables efficient computation. Simulation studies show that ZIBBMR achieves accuracy comparable to leading mixed-model approaches in the literature and surpasses simpler zero-inflated count formulations, particularly in small-sample scenarios. As a case study, we analyze longitudinal microbiome data, comparing ZIBBMR with an external Zero-Inflated Beta Regression (ZIBR) benchmark; the results indicate that applying both count- and proportion-based models in parallel can enhance inference robustness when both data types are available.",
      "authors": [
        "John Barrera",
        "Ana Arribas-Gil",
        "Dae-Jin Lee",
        "Cristian Meza"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "math.ST"
      ],
      "published": "2026-02-09 23:45:13+00:00",
      "link": "https://arxiv.org/pdf/2602.09279v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09215v1",
      "title": "Weil restriction and the motivic cycle class map",
      "abstract": "The etale cycle class map links Chow groups with etale cohomology. Within the framework of motivic cohomology, the motivic cycle class map appears as a comparison morphism relating motivic and Lichtenbaum cohomology. By examining the comparison morphism constructed by Geisser and Levine, we show that the motivic cycle class map is induced by the etale cycle class map. We then study the behavior of cycle class maps under Weil restriction. Extending Karpenko's construction of the Weil restriction for algebraic cycles and Chow groups, we introduce a corresponding Weil restriction for l-adic cohomology and prove its compatibility with the motivic cycle class map. This provides a conceptual explanation for the descent of cycle classes under finite Galois extensions.",
      "authors": [
        "Qi Ge",
        "Guangzhao Zhu"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG"
      ],
      "published": "2026-02-09 21:38:07+00:00",
      "link": "https://arxiv.org/pdf/2602.09215v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09151v1",
      "title": "Non-absolute integration and application to Young geometric integration",
      "abstract": "We survey several non-absolutely convergent integrals, including the Henstock-Kurzweil and Pfeffer integrals, and use ideas from these theories to investigate the problem of multidimensional Young integration. We further present results on Young geometric integration, namely the integration of certain generalized differential forms over $m$-dimensional subsets of $\\mathbb{R}^d$. This is achieved by introducing appropriate notions of chains and cochains, in the spirit of Whitney's geometric integration theory.",
      "authors": [
        "Philippe Bouafia"
      ],
      "primary_category": "math.FA",
      "categories": [
        "math.FA"
      ],
      "published": "2026-02-09 19:53:12+00:00",
      "link": "https://arxiv.org/pdf/2602.09151v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09133v1",
      "title": "Uniting Iteration Limits for Mixed-Integer Quadratic MPC",
      "abstract": "Iteration limited model predictive control (MPC) can stabilize a feedback control system under sufficient conditions; this work explores combining a low iteration limit MPC with a high iteration limit MPC for mixed-integer quadratic programs (MIQPs) where the suboptimality is due to solver iteration limits. To combine the two MPCs a hybrid systems controller is developed that ``unites'' two MIQP-MPC solvers where the iteration limits of interest are the branch-and-bound and quadratic programming iteration limits. Asymptotic stability and robustness of the hybrid feedback control system are theoretically derived. Then an interpretable branch-and-bound algorithm and implementable uniting controller algorithm are developed. Finally, the developed algorithms and varying iteration limits are empirically evaluated in simulation for the switching thruster and minimum thrust spacecraft rendezvous problems.",
      "authors": [
        "Luke Fina",
        "Christopher Petersen"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-09 19:23:43+00:00",
      "link": "https://arxiv.org/pdf/2602.09133v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.08967v1",
      "title": "Convergence Analysis for the Recovery of the Friction Threshold in a Scalar Tresca Model",
      "abstract": "We consider a scalar valued elliptic partial differential equation on a sufficiently smooth domain $Ω$, subject to a regularized Tresca friction-type boundary condition on a subset $Γ$ of $\\partial Ω$. The friction threshold, a positive function appearing in this boundary condition, is assumed to be unknown and serves as the coefficient to be recovered in our inverse problem. Assuming that (i) the friction threshold lies in a finite dimensional space with known basis functions, (ii) the right hand sides of the partial differential equation are known, and (iii) the solution to the partial differential equation on some small open subset $ω\\subset Ω$ is available, we develop an iterative computational method for the recovery of the friction threshold. This algorithm is simple to implement and is based on piecewise linear finite elements. We show that the proposed algorithm converges in second order to a function $a_h$ and, moreover, that $a_h$ converges in second order in the finite element's mesh size $h$ to the true (unknown) friction threshold. We highlight our theoretical results by simulations that confirm our rates numerically.",
      "authors": [
        "Erik Burman",
        "Marvin Knöller",
        "Lauri Oksanen",
        "Andreas Rupp"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-09 18:04:03+00:00",
      "link": "https://arxiv.org/pdf/2602.08967v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16693v1",
      "title": "Numerical study of non-relativistic quantum systems and small oscillations induced in a helically twisted geometry",
      "abstract": "We investigate bound states of a non-relativistic scalar particle in a three-dimensional helically twisted (torsional) geometry, considering both the free case and the presence of external radial interactions. The dynamics is described by the Schrödinger equation on a curved spatial background and, when included, by minimal coupling to a magnetic vector potential incorporating an Aharonov--Bohm flux. After separation of variables, the problem reduces to a one-dimensional radial eigenvalue equation governed by an effective potential that combines torsion-induced Coulomb-like and centrifugal-like structures with magnetic/flux-dependent terms and optional model interactions. Because closed-form analytic solutions are not reliable over the parameter ranges required for systematic scans, we compute spectra and eigenfunctions numerically by formulating the radial equation as a self-adjoint Sturm--Liouville problem and solving it with a finite-difference discretization on a truncated radial domain, with explicit convergence control. We analyze four representative scenarios: (i) no external potential, (ii) Cornell-type confinement, (iii) Kratzer-type interaction, and (iv) the small-oscillation regime around the minimum of a Morse potential. We present systematic trends of the low-lying levels as functions of the torsion parameter, magnetic field, and azimuthal sector, and we show that geometric couplings alone can produce effective confinement even in the absence of an external interaction.",
      "authors": [
        "C. F. S. Pereira",
        "R. L. L. Vitória",
        "A. R. Soares",
        "B. B. Silva",
        "H. Belich",
        "Edilberto O. Silva"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "math-ph"
      ],
      "published": "2026-02-18 18:39:54+00:00",
      "link": "https://arxiv.org/pdf/2602.16693v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16630v1",
      "title": "Symmetry properties for positive solutions of mixed boundary value problems in a sub-spherical sector",
      "abstract": "In this paper, we investigate the symmetry properties of positive solutions $u$ to a semilinear elliptic equation under mixed Dirichlet-Neumann boundary conditions in symmetric domains. First, we establish a maximum principle tailored to mixed-boundary problems in domains of either small volume or narrow width, thereby enabling the application of the moving plane method. Secondly, in contrast to the purely Dirichlet case, a key challenge is to establish the non-vanishing of the tangential derivative of $u$ along the Neumann boundary. To address this, we employ local analysis techniques of angular derivatives, as introduced by Hartman and Wintner [Amer. J. Math., 1953]. Thirdly, we identify the signs of directional derivatives of $u$ along sections of the moving line. Using a planar sub-spherical sector as an example, we illustrate how these new innovative techniques and the moving plane method can be combined to derive symmetry and monotonicity results, particularly when the amplitude is less than or equal to $2π/3$.",
      "authors": [
        "Ruofei Yao"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-18 17:25:29+00:00",
      "link": "https://arxiv.org/pdf/2602.16630v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16606v1",
      "title": "On Sharpened Convergence Rate of Generalized Sliced Inverse Regression for Nonlinear Sufficient Dimension Reduction",
      "abstract": "Generalized Sliced Inverse Regression (GSIR) is one of the most important methods for nonlinear sufficient dimension reduction. As shown in Li and Song (2017), it enjoys a convergence rate that is independent of the dimension of the predictor, thus avoiding the curse of dimensionality. In this paper we establish an improved convergence rate of GSIR under additional mild eigenvalue decay rate and smoothness conditions. Our convergence rate can be made arbitrarily close to $n^{-1/3}$ under appropriate decay rate and smoothness parameters. As a comparison, the rate of Li and Song (2017) is $n^{-1/4}$ under the best conditions. This improvement is significant because, for example, in a semiparametric estimation problem involving an infinite-dimensional nuisance parameter, the convergence rate of the estimator of the nuisance parameter is often required to be faster than $n^{-1/4}$ to guarantee desired semiparametric properties such as asymptotic efficiency. This can be achieved by the improved convergence rate, but not by the original rate. The sharpened convergence rate can also be established for GSIR in more general settings, such as functional sufficient dimension reduction.",
      "authors": [
        "Chak Fung Choi",
        "Yin Tang",
        "Bing Li"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "stat.ME"
      ],
      "published": "2026-02-18 17:01:53+00:00",
      "link": "https://arxiv.org/pdf/2602.16606v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16604v1",
      "title": "ERGMs on block models",
      "abstract": "We extend the classical edge-triangle Exponential Random Graph Model (ERGM) to an inhomogeneous setting in which vertices carry types determined by an underlying partition. This leads to a block-structured ERGM where interaction parameters depend on vertex types. We establish a large deviation principle for the associated sequence of measures and derive the corresponding variational formula for the limiting free energy. In the ferromagnetic regime, where the parameters governing triangle densities are nonnegative, we reduce the variational problem to a scalar optimization problem, thereby identifying the natural block counterpart of the replica symmetric regime. Under additional restrictions on the parameters, comparable to the classical Dobrushin's uniqueness region, we prove uniqueness of the maximizer and derive a law of large numbers for the edge density.",
      "authors": [
        "Elena Magnanini"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "math-ph"
      ],
      "published": "2026-02-18 16:59:31+00:00",
      "link": "https://arxiv.org/pdf/2602.16604v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16586v1",
      "title": "Nonparametric Kernel Regression for Coordinated Energy Storage Peak Shaving with Stacked Services",
      "abstract": "Developing effective control strategies for behind-the-meter energy storage to coordinate peak shaving and stacked services is essential for reducing electricity costs and extending battery lifetime in commercial buildings. This work proposes an end-to-end, two-stage framework for coordinating peak shaving and energy arbitrage with a theoretical decomposition guarantee. In the first stage, a non-parametric kernel regression model constructs state-of-charge trajectory bounds from historical data that satisfy peak-shaving requirements. The second stage utilizes the remaining capacity for energy arbitrage via a transfer learning method. Case studies using New York City commercial building demand data show that our method achieves a 1.3 times improvement in performance over the state-of-the-art forecast-based method, achieving cost savings and effective peak management without relying on predictions.",
      "authors": [
        "Emily Logan",
        "Ning Qi",
        "Bolun Xu"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "eess.SY"
      ],
      "published": "2026-02-18 16:37:31+00:00",
      "link": "https://arxiv.org/pdf/2602.16586v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16574v1",
      "title": "Optimal bounds for numerical approximations of finite horizon problems based on dynamic programming approach",
      "abstract": "In this paper we provide optimal bounds for fully discrete approximations to finite horizon problems via dynamic programming. We adapt the error analysis in \\cite{nos} for the infinite horizon case to the   finite horizon case. We prove an a priori bound of size $O(h+k)$ for the method, $h$ being the time discretization step and $k$ the spatial mesh size. Arguing with piecewise constants controls we are able to obtain first order of convergence in time and space under standard regularity assumptions, avoiding the more restrictive regularity assumptions on the controls required in \\cite{nos}.   We show that the loss in the rate of convergence in time of the   infinite case (obtained arguing with piece-wise controls)   can be avoided in the finite horizon case",
      "authors": [
        "Javier de Frutos",
        "Julia Novo"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-18 16:18:15+00:00",
      "link": "https://arxiv.org/pdf/2602.16574v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16549v1",
      "title": "Well-posedness and stability of the self-similar profile for a thin-film equation with gravity",
      "abstract": "We consider the thin-film equation with linear mobility and a stabilizing second-order porous-medium type term modeling gravity. The model admits self-similar solutions, and our goal is to analyze their stability. We reformulate the problem in mass-Lagrangian coordinates and exploit the underlying gradient-flow structure of the equation with respect to a weighted $L^2$ inner product, where the weight is given by the self-similar source-type profile. This framework allows us to establish a coercivity result for the Hessian (the linearization around the self-similar solution) in a suitably weighted inner product. As a consequence, we prove the convergence of perturbations toward the self-similar profile at an algebraic rate of order $t^{-\\frac 1 5}$, in arbitrary scales of weighted Sobolev norms. The analysis relies on maximal-regularity estimates for the linearized evolution, combined with appropriate estimates for the nonlinear terms.   Notably, beyond perturbative regimes and in contrast to previous results for the thin-film equation (convergence to the Smyth-Hill profile) or the porous-medium equation (convergence to the Barenblatt-Pattle solution), our analysis does not rely on an explicit (algebraic) representation of the self-similar profile. Instead, it is based solely on a systematic use of the ordinary differential equation satisfied by the self-similar solution, together with a careful analysis of its boundary asymptotics. As a result, we expect that the approach developed here can serve as a flexible toolbox for the study of more general classes of equations and for the stability analysis of special solutions in future work.",
      "authors": [
        "Manuel V. Gnann",
        "Slim Ibrahim"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "math-ph"
      ],
      "published": "2026-02-18 15:52:55+00:00",
      "link": "https://arxiv.org/pdf/2602.16549v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16538v1",
      "title": "A higher order pressure-stabilized virtual element formulation for the Stokes-Poisson-Boltzmann equations",
      "abstract": "Electrokinetic phenomena in nanopore sensors and microfluidic devices require accurate simulation of coupled fluid-electrostatic interactions in geometrically complex domains with irregular boundaries and adaptive mesh refinement. We develop an equal-order virtual element method for the Stokes--Poisson--Boltzmann equations that naturally handles general polygonal meshes, including meshes with hanging nodes, without requiring special treatment or remeshing. The key innovation is a residual-based pressure stabilization scheme derived by reformulating the Laplacian drag force in the momentum equation as a weighted advection term involving the nonlinear Poisson--Boltzmann equation, thereby eliminating second-order derivative terms while maintaining theoretical rigor. Well-posedness of the coupled stabilized problem is established using the Banach and Brouwer fixed-point theorems under sufficiently small data assumptions, and optimal a priori error estimates are derived in the energy norm with convergence rates of order $\\mathcal{O}(h^k)$ for approximation degree $k \\geq 1$. Numerical experiments on diverse polygonal meshes -- including distorted elements, non-convex polygons, Voronoi tessellations, and configurations with hanging nodes -- confirm optimal convergence rates, validating theoretical predictions. Applications to electro-osmotic flows in nanopore sensors with complex obstacle geometries illustrate the method's practical utility for engineering simulations. Compared to Taylor--Hood finite element formulations, the equal-order approach simplifies implementation through uniform polynomial treatment of all fields and offers native support for general polygonal elements.",
      "authors": [
        "Sudheer Mishra",
        "Sundararajan Natarajan",
        "E. Natarajan",
        "Gianmarco Manzini"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-18 15:32:34+00:00",
      "link": "https://arxiv.org/pdf/2602.16538v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16524v1",
      "title": "Nonlinear Schrödinger equations with a critical, inverse-square potential",
      "abstract": "We study the existence of solutions of the following nonlinear Schrödinger equation $$ -Δu+V(x)u-\\frac{(N-2)^2}{4|x|^2}u=f(x,u) $$ where $V:\\mathbb{R}^N\\to\\mathbb{R}$ and $f:\\mathbb{R}^N\\times \\mathbb{R}\\to \\mathbb{R}$ are periodic with respect to $x\\in\\mathbb{R}^N.$ We assume that $V$ has positive essential infimum, $f$ satisfies weak growth conditions and $N\\geq 3$. The approach to the problem uses variational methods with nonstandard functional setting. We obtain the existence of the ground state solution using the new profile decomposition.",
      "authors": [
        "Bartosz Bieganowski",
        "Adam Konysz",
        "Simone Secchi"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-18 15:11:37+00:00",
      "link": "https://arxiv.org/pdf/2602.16524v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16508v1",
      "title": "A Fully Discrete Nonnegativity-Preserving FEM for a Stochastic Heat Equation",
      "abstract": "We consider a stochastic heat equation with nonlinear multiplicative finite-dimensional noise that admits a unique nonnegative solution when given nonnegative initial data. Inspired by existing results for fully discrete finite difference schemes and building on the convergence analysis of semi-discrete mass-lumped finite element approximations, a fully discrete numerical method is introduced that combines mass-lumped finite elements with a Lie-Trotter splitting strategy. This discretization preserves nonnegativity at the discrete level and is shown to be convergent under suitable regularity conditions. A rigorous convergence analysis is provided, highlighting the role of mass lumping in ensuring nonnegativity and of operator splitting in decoupling the deterministic and stochastic dynamics. Numerical experiments are presented to confirm the convergence rates and the preservation of nonnegativity. In addition, we examine several numerical examples outside the scope of the established theory, aiming to explore the range of applicability and potential limitations of the proposed method.",
      "authors": [
        "Owen Hearder",
        "Claude Le Bris",
        "Ana Djurdjevac"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-18 14:53:14+00:00",
      "link": "https://arxiv.org/pdf/2602.16508v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16440v1",
      "title": "Linear Landau equation as a limit of a tagged particle in mean field interaction with a free gas",
      "abstract": "We consider a tagged particle in mean field interaction with a free gas of density N at equilibrium. In dimensions $d\\geq4$, we prove the convergence of its trajectory, as N goes to infinity, to the one of a diffusion process associated with the linear Landau equation. The proof of the convergence of the martingale problem relies on two key ingredients: long time stability results of the microscopic dynamics, and controls on the probability of particle recollisions.",
      "authors": [
        "Thierry Bodineau",
        "Pierre Le Bris"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "math-ph"
      ],
      "published": "2026-02-18 13:20:14+00:00",
      "link": "https://arxiv.org/pdf/2602.16440v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16392v1",
      "title": "Partially observed controlled Markov chains and optimal control of the Wonham filter",
      "abstract": "We consider a class of optimal control problems, with finite or infinite horizon, for a continuous-time Markov chain with finite state space. In this case, the control process affects the transition rates. We suppose that the controlled process can not be observed, and at any time the control actions are chosen based on the observation of a related stochastic process perturbed by an exogenous Brownian motion. We describe a construction of the controlled Markov chain, having stochastic transition rates adapted to the observation filtration. By a change of probability measure of Girsanov type, we introduce the so-called separated optimal control problem, where the state is the conditional (unnormalized) distribution of the controlled Markov chain and the observation process becomes a driving Brownian motion, and we prove the equivalence with the original control problem. The controlled equations for the separated problem are an instance of the Wonham filtering equations. Next we present an analysis of the separated problem: we characterize the value function as the unique viscosity solution to the dynamic programming equations (both in the parabolic and the elliptic case) we prove verifications theorems and a version of the stochastic maximum principle in the form of a necessary conditions for optimality.",
      "authors": [
        "Fulvia Confortola",
        "Marco Fuhrman"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "math.PR"
      ],
      "published": "2026-02-18 12:02:23+00:00",
      "link": "https://arxiv.org/pdf/2602.16392v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16348v1",
      "title": "Heat Equation driven by mixed local-nonlocal operators with non-regular space-dependent coefficients",
      "abstract": "In this paper, we study the Cauchy problem for a heat equation governed by a mixed local--nonlocal diffusion operator with spatially irregular coefficients. We first establish classical well-posedness in an energy framework for bounded, measurable coefficients that satisfy uniform positivity, and we derive an a priori estimate ensuring uniqueness and continuous dependence on the initial data. We then extend the notion of solution to distributional coefficients and initial data by a Friedrichs-type regularisation procedure. Within this very weak framework, we establish the existence and uniqueness of solution nets and prove consistency with the classical weak solution whenever the coefficients are regular.",
      "authors": [
        "Arshyn Altybay",
        "Michael Ruzhansky"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-18 10:33:03+00:00",
      "link": "https://arxiv.org/pdf/2602.16348v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16342v1",
      "title": "Markov processes forced on a subspace by a large drift, with applications to population genetics",
      "abstract": "Consider a sequence of Markov processes $X^1, X^2,...$ with state space $E$, where $X^N$ has a strong drift to $D \\subseteq E$, such that $Φ(X^N)$ is slow for some appropriate $Φ: E\\to D$. Using the method of martingale problems, we give a limit result, such that $Φ(X^N) \\xRightarrow{N\\to\\infty} Z$ in the space of càdlàg paths, and $X^N \\xRightarrow{N\\to\\infty} X$ in measure. \\\\ We apply the general limit result to models for copy number variation of genetic elements in a diploid Moran model of size $N$. The population by time $t$ is described by $X^N \\in \\mathcal P(\\mathbb N_0)$, where $X^N_k$ is the frequency of individuals with copy number $k$, and $Φ: \\mathcal P(\\mathbb",
      "authors": [
        "Samuel Ayomide Adeosun",
        "Peter Pfaffelhuber"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-02-18 10:27:09+00:00",
      "link": "https://arxiv.org/pdf/2602.16342v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16303v1",
      "title": "Finite elements for the space approximation of a differential model for salts crystallization",
      "abstract": "This article investigates a space-time differential model related to the degradation of stone artifacts caused by exposure to air and atmospheric agents, which specifically lead to the accumulation of salt crystals in the material. A numerical method based on finite-element space discretization and implicit-explicit time marching is proposed as an extension of a one-dimensional finite-difference framework introduced in the literature. Within the same one-dimensional setting, a sensitivity analysis is performed, based on the techniques developed therein. They are also used as a comparison tool for the finite-element formulation, here introduced for more realistic simulations in higher space dimensions. Considerations about stability will be provided, together with an experimental convergence analysis highlighting the performance of the proposed approach. Numerical results in two and three space dimensions, obtained by an efficient code implementation, will be presented and discussed.",
      "authors": [
        "Alessandra Aimi",
        "Gabriella Bretti",
        "Giulia Di Credico",
        "Francesco Freddi",
        "Chiara Guardasoni",
        "Mario Pezzella"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "math-ph"
      ],
      "published": "2026-02-18 09:34:10+00:00",
      "link": "https://arxiv.org/pdf/2602.16303v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16293v1",
      "title": "Critical thresholds for semilinear damped wave equations with Riesz potential power nonlinearity and initial data in pseudo-measure spaces",
      "abstract": "In this paper, our primary objective is to establish the time decay properties of solutions $u(t, x)$ with initial data $u_0, u_1 \\in \\mathcal{Y}^q$ (pseudo-measure spaces) to the linear damped wave equation in the spaces $L^2\\left(\\mathbb{R}^n\\right)$ and $\\dot{H}^s\\left(\\mathbb{R}^n\\right)$ (for $s \\leq 0$ or $s \\geq 0$). Our subsequent aim is to investigate the semilinear damped wave equation with a Riesz potential-type power nonlinearity $\\mathcal{I}_γ\\left(|u|^p\\right)$, where $γ\\in [0, n)$, and initial data belonging to pseudo-measure spaces $\\mathcal{Y}^q$. In addition, we derive a new critical exponent $p=p_{\\mathrm{crit}}(n, q, γ):=1+\\frac{2+γ}{n-q}$ for some $q \\in\\left(0, \\frac{n}{2}\\right)$ and in low spatial dimensions, within the framework of pseudo-measure spaces $\\mathcal{Y}^q$. Specifically, we prove the global (in time) existence of small-data Sobolev solutions with low regularity when $p \\geq p_{\\mathrm{crit}}(n, q, γ)$, and the finite-time blow-up of weak solutions, even for small initial data, whenever $1< p<p_{\\mathrm{crit}}(n, q, γ)$. Moreover, in order to characterize the blow-up time more precisely, we establish sharp upper and lower bound estimates for the lifespan of solutions in the subcritical regime.",
      "authors": [
        "Tang Trung Loc",
        "Duong Dinh Van",
        "Phan Duc An"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-18 09:20:37+00:00",
      "link": "https://arxiv.org/pdf/2602.16293v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16263v1",
      "title": "Existence and nonexistence of normalized solutions for nonlinear Schrödinger equation involving combined nonlinearities in bounded domain",
      "abstract": "In this paper, we consider the existence, multiplicity and nonexistence of solutions for the following equation \\begin{equation*} \\begin{cases} \\begin{aligned} &-Δu+ωu=μu^{p-1}+u^{q-1},~ u>0 \\quad &&\\text { in } Ω, \\\\ &u=0 &&\\text { on } \\partialΩ, \\\\ \\end{aligned} \\end{cases} \\end{equation*} with prescribed $L^2$-norm $\\|u\\|_2^2=ρ$, where $N\\ge 1$, $ρ>0$, $μ\\in \\mathbb{R}$, $1<p\\le q$, and $Ω\\subset\\mathbb{R}^N$ is a bounded smooth domain. The parameter $ω\\in\\mathbb{R}$ arises as a Lagrange multiplier. Firstly, when $2<p\\le q\\le \\frac{2N}{(N-2)^+}$ and $ρ$ is small, we establish the existence of a local minimizer of energy. Furthermore, when $μ\\ge 0$ and $Ω$ is a star-shaped domain, using the monotonicity trick and the Pohozaev identity, we show that there exists a second solution which is of mountain pass type. Secondly, when $μ\\ge 0$, $N\\ge 3$, $1<p\\le 2$, $q\\ge \\max\\left\\{\\frac{2N}{N-2}, 3\\right\\}$ and $Ω$ is a convex domain, using the moving-plane method, we prove the nonexistence of normalized solutions for large $ρ$. Finally, when $μ=0$, $N\\ge 3$, $q=\\frac{2N}{N-2}$ and $Ω$ is a ball, we give a dichotomy result of normalized solutions for the Brézis-Nirenberg problem by continuation arguments.",
      "authors": [
        "Zhen-Feng Jin",
        "Weimin Zhang"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-18 08:23:34+00:00",
      "link": "https://arxiv.org/pdf/2602.16263v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16258v1",
      "title": "A zero-one law for improvements to Dirichlet's theorem in arbitrary dimension",
      "abstract": "Let $ψ$ be a continuous decreasing function defined on all large positive real numbers. We say that a real $m\\times n$ matrix $A$ is $ψ$-Dirichlet if for every sufficiently large real number $t$ one can find $\\mathbf{p} \\in \\mathbb{Z}^m$, $\\mathbf{q} \\in \\mathbb{Z}^n\\setminus\\{\\mathbf{0}\\}$ satisfying $\\|A\\mathbf{q}-\\mathbf{p}\\|^m< ψ(t)$ and $\\|\\mathbf{q}\\|^n<t$. By removing a technical condition from a partial zero-one law proved by Kleinbock-Strömbergsson-Yu, we prove a zero-one law for the Lebesgue measure of the set of $ψ$-Dirichlet matrices provided that $ψ(t)<1/t$ and $tψ(t)$ is increasing. In fact, we prove the zero-one law in a more general situation with the monotonicity assumption on $tψ(t)$ replaced by a weaker condition. Our proof follows the dynamical approach of Kleinbock-Strömbergsson-Yu in reducing the question to a shrinking target problem in the space of lattices. The key new ingredient is a family of carefully chosen subsets of the shrinking targets studied by Kleinbock-Strömbergsson-Yu, together with a short-range mixing estimate for the associated hitting events. Our method also works for the analogous weighted problem where the relevant supremum norms are replaced by certain weighted quasi-norms.",
      "authors": [
        "Andreas Strömbergsson",
        "Shucheng Yu"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-02-18 08:15:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16258v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16254v1",
      "title": "Concentration Phenomena for $(p,N)$-Laplace Equation Under Discontinuous Nonlinearities and Penalization Method",
      "abstract": "In this paper, we investigate the existence and concentration of solutions to a $(p,N)$-Laplace equation in $\\mathbb{R}^N$ involving a discontinuous nonlinearity and critical exponential growth. To establish the existence of solutions, we employ a penalization technique in the sense of Del Pino and Felmer adapted to a locally Lipschitz functional. Furthermore, by combining variational methods with Moser-type iteration techniques, we obtain the concentration behavior of the solutions. Our results contribute to the study of nonlinear elliptic problems with irregular nonlinearities and critical growth phenomena.",
      "authors": [
        "Ankit",
        "Giovany M. Figueiredo",
        "Abhishek Sarkar"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-18 08:08:13+00:00",
      "link": "https://arxiv.org/pdf/2602.16254v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16208v1",
      "title": "Coefficient problems of Starlike Functions Related to a Balloon-Shaped Domain",
      "abstract": "Recent advances in image and signal processing have drawn on geometric function theory, particularly coefficient estimate problems. Motivated by their significance, we introduce a class of starlike functions related to a balloon-shaped domain \\[ \\mathcal{S}^*_{\\mathcal{B}}= \\left\\{ f \\in \\mathcal{A} : \\frac{z f'(z)}{f(z)} \\prec \\frac{1}{1-\\log(1+z)} := B(z); \\; z \\in \\mathbb{D} \\right\\}, \\] where $B(z)$ maps the unit disk $\\mathbb{D}$ onto a balloon-shaped domain. This work establishes bounds for the second order Hankel determinants and second order Toeplitz determinants involving the initial coefficients, the logarithmic coefficients and the logarithmic coefficients of the inverse function for $f \\in \\mathcal{S}^*_{\\mathcal{B}}$",
      "authors": [
        "S. Sivaprasad Kumar",
        "A. Tripathi"
      ],
      "primary_category": "math.CV",
      "categories": [
        "math.CV"
      ],
      "published": "2026-02-18 06:10:28+00:00",
      "link": "https://arxiv.org/pdf/2602.16208v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16170v1",
      "title": "Metaheuristic algorithms for the induced P-median problem with upgrades",
      "abstract": "Facility location problems (FLPs) are a family of optimisation problems with significant social impact. This class of problems has been the subject of study since the 1960s, with classical approaches including the Weber problem and the p-Median problem. Currently, more complex variations of these problems are being investigated. In particular, the Induced p-Median Problem with Upgrades (IpMU) represents a variation of the classical p-Median problem, where the concepts of transport cost and time are separated as distinct metrics in the input graph of the problem. Furthermore, the problem includes a budget which allows one to relax the graph costs, reducing the cost of the edges, thus improving the associated routes between the designated medians and the customers. In this study, a metaheuristic algorithm, based on the Greedy Randomized Adaptive Search Procedure (GRASP), is proposed. A two-phase resolution scheme is defined, studying the median problem and the upgrading problem independently. In this approach, a larger set of state-of-the-art instances was analysed to ensure a fair comparison with previous proposals. In addition, the characteristics of the instances were studied to assess their complexity. The results obtained are promising when compared to the state-of-the-art, which is based entirely on mathematical programming models. The execution time was improved on average by two orders of magnitude for the harder instances, and the best known result was obtained in more than 99% of the tested instances.",
      "authors": [
        "Sergio Salazar",
        "Abraham Duarte",
        "Mauricio G. C. Resende",
        "J. Manuel Colmenar"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-18 04:13:28+00:00",
      "link": "https://arxiv.org/pdf/2602.16170v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16126v1",
      "title": "Martin Boundary and the Nonlinear Multiplicative Heat Equation in Weak disorder",
      "abstract": "We study the nonlinear multiplicative heat equation on Dirichlet spaces with white in time noise under weak disorder. We show that positive invariant random fields with uniformly bounded second moments are in one-to-one correspondence with bounded positive harmonic functions. The proof combines a remote past pullback construction with a uniqueness argument that applies a contraction inspired by chaos expansion. As a consequence, the space of invariant measures inherits geometric structure from the Martin Boundary. We further establish a small-noise Gaussian fluctuation result within each harmonic sector and show that the long-time behavior of solutions is completely determined by the Martin boundary data of the initial condition. These results reveal a direct connection between stochastic PDE dynamics and boundary theory in potential analysis.",
      "authors": [
        "Hongyi Chen"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "math.DS"
      ],
      "published": "2026-02-18 01:33:12+00:00",
      "link": "https://arxiv.org/pdf/2602.16126v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16122v1",
      "title": "The nonlinear Schrödinger equation with combined nonlinearities in 1D",
      "abstract": "We consider the one-dimensional nonlinear Schrödinger equation $$ iu_t + u_{xx} + \\mathcal{N}(u)u=0, \\quad x,t \\in \\mathbb R, $$ with the nonlinearity term that is expressed as a sum of powers, possibly infinite: $$ \\mathcal{N}(u) = \\sum d_k |u|^{α_k}, \\quad α_k > 0. $$   We first investigate the local well-posedness of this equation for any positive powers of $α_k$ in a certain weighted class of initial data, subset of $H^1 (\\mathbb R)$. For that we use an approach of Cazenave-Naumkin [19], thus, avoiding any Strichartz estimates. Then, using the pseudo-conformal transformation, we extend the local result to the global one for the initial data with a quadratic phase. Furthermore, we investigate the asymptotic behavior of such global solutions and prove scattering for data with the quadratic phase $e^{ib|x|^2}$ with sufficiently large positive $b$, in $H^1(\\mathbb R)$. One of the advantages of considering an infinite sum in the nonlinearity term is being able to consider exponential nonlinearities, such as $e^{γ|u|^{k}} u$, as well as sine or cosine nonlinearities, and obtain well-posedness in those cases, the first such result for most of those nonlinearities.   To conclude, we show numerical simulations for various examples of combined nonlinearities, including the double nonlinearity and an exponential one, then investigate the behavior of solutions with positive or negative initial $b$ in a quadratic phase data. Furthermore, we also show that a ground state in the NLS equation with combined nonlinearities no longer provides a sharp threshold for global behavior such as scattering vs. finite time blow-up, instead the equation has a much richer dynamics.",
      "authors": [
        "Oscar Riaño",
        "Alex D Rodriguez",
        "Svetlana Roudenko"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "math.NA"
      ],
      "published": "2026-02-18 01:27:29+00:00",
      "link": "https://arxiv.org/pdf/2602.16122v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16103v1",
      "title": "Topology of the Vakil--Zinger moduli space",
      "abstract": "We derive a set of generators for the rational homology of the desingularised genus one mapping space $\\widetilde{\\mathcal{M}}_{1,n}(\\mathbb{P}^r,d)$ constructed by Vakil--Zinger and qualitatively describe the relations among the generators. The results build on a detailed study of the stratifications of the moduli spaces coming from tropical geometry and the constraints coming from the weight filtration on the Borel--Moore homology groups of strata, extending the techniques from the previous study on $\\overline{\\mathcal{M}}_{g,n}.$ Our results imply that the even homology of $\\widetilde{\\mathcal{M}}_{1,n}(\\mathbb{P}^r,d)$ is tautological and controlled by genus-zero and reduced genus-one Gromov--Witten theory. We verify the Hodge and Tate conjectures for $\\widetilde{\\mathcal{M}}_{1,n}(\\mathbb{P}^r,d),$ completely describe its rational Picard group, and recover known results on the vanishing of odd cohomology. Our techniques also apply to the pure weight homology groups of genus one stable maps $\\overline{\\mathcal{M}}_{1,n}(\\mathbb{P}^r,d).$",
      "authors": [
        "Terry Dekun Song"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "math.AT"
      ],
      "published": "2026-02-18 00:31:07+00:00",
      "link": "https://arxiv.org/pdf/2602.16103v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15800v1",
      "title": "Entanglement in the Dicke subspace",
      "abstract": "In this paper, we provide a complete mathematical theory for the entanglement of mixtures of Dicke states. These quantum states form an important subclass of bosonic states arising in the study of indistinguishable particles. We introduce a tensor-based parametrization where the diagonal entries of these states are encoded as a symmetric tensor, enabling a direct translation between entanglement properties and well-studied convex cones of tensors. Our results bridge multipartite entanglement theory with semialgebraic geometry and the theory of completely positive and copositive tensors. This dictionary maps separability to completely positive tensors, the PPT property to moment tensors, entanglement witnesses to copositive tensors, and decomposable witnesses to sum of squares tensors. Using this framework, we construct explicit PPT entangled states in three or more qutrits. In this class of states, we establish that PPT entanglement exists for all multipartite systems with three qutrits or more, disproving a recent conjecture in [J. Math. Phys. 66, 022203 (2025)]. We also show that, for mixtures of Dicke states, the PPT condition with respect to the most balanced bipartition implies PPT with respect to any other bipartition. We further connect bosonic extendibility of mixtures of Dicke states to the duals of known hierarchies for non-negative polynomials, such as the ones by Reznick and Polya. We thus provide semidefinite programming relaxations for separability and entanglement testing in the Dicke subspace.",
      "authors": [
        "Aabhas Gulati",
        "Ion Nechita",
        "Clément Pellegrini"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "math-ph"
      ],
      "published": "2026-02-17 18:39:30+00:00",
      "link": "https://arxiv.org/pdf/2602.15800v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15754v1",
      "title": "Power monoids and their arithmetic: a survey",
      "abstract": "The non-empty finite subsets of a multiplicatively written monoid form a monoid in their own right, and so do the finite subsets that contain the identity element. Partly due to their unusual arithmetic properties, these structures, known as power monoids, have attracted increasing attention in recent years and have in turn stimulated growing interest in new perspectives in factorization theory, better suited to non-cancellative settings. We survey these developments and briefly review some related aspects.",
      "authors": [
        "Salvatore Tringali"
      ],
      "primary_category": "math.RA",
      "categories": [
        "math.RA",
        "math.CO",
        "math.NT"
      ],
      "published": "2026-02-17 17:38:38+00:00",
      "link": "https://arxiv.org/pdf/2602.15754v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15722v1",
      "title": "Pricing Discrete and Nonlinear Markets With Semidefinite Relaxations",
      "abstract": "Nonconvexities in markets with discrete decisions and nonlinear constraints make efficient pricing challenging, often necessitating subsidies. A prime example is the unit commitment (UC) problem in electricity markets, where costly subsidies are commonly required. We propose a new pricing scheme for nonconvex markets with both discreteness and nonlinearity, by convexifying nonconvex structures through a semidefinite programming (SDP) relaxation and deriving prices from the relaxation's dual variables. When the choice set is bounded, we establish strong duality for the SDP, which allows us to extend the envelope theorem to the value function of the relaxation. This extension yields a marginal price signal for demand, which we use as our pricing mechanism. We demonstrate that under certain conditions-for instance, when the relaxation's right hand sides are linear in demand-the resulting lost opportunity cost is bounded by the relaxation's optimality gap. This result highlights the importance of achieving tight relaxations. The proposed framework applies to nonconvex electricity market problems, including for both direct current and alternating current UC. Our numerical experiments indicate that the SDP relaxations are often tight, reinforcing the effectiveness of the proposed pricing scheme. Across a suite of IEEE benchmark instances, the lost opportunity cost under our pricing scheme is, on average, 46% lower than that of the commonly used fixed-binary pricing scheme.",
      "authors": [
        "Cheng Guo",
        "Lauren Henderson",
        "Ryan Cory-Wright",
        "Boshi Yang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "econ.GN"
      ],
      "published": "2026-02-17 16:55:48+00:00",
      "link": "https://arxiv.org/pdf/2602.15722v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15647v1",
      "title": "On the Robin problem for the Laplace equation in multiply connected domains",
      "abstract": "This paper complements the existing theory developed in [5] for the Dirichlet and Neumann problems for the Laplace equation, in multiply connected domains. Within the framework of layer potential methods, we study the Laplace equation under Robin boundary conditions, representing the solutions by means of a double layer potential. We observe that the classical approach searches the solutions in terms of a single layer potential.",
      "authors": [
        "Alberto Cialdea",
        "Vita Leonessa"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-17 15:15:17+00:00",
      "link": "https://arxiv.org/pdf/2602.15647v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15643v1",
      "title": "Reinforcement Learning in Real Option Models",
      "abstract": "We investigate an entropy-regularized reinforcement learning (RL) approach to optimal stopping problems motivated by real option models. Classical stopping rules are strict and non-randomized, limiting natural exploration in RL settings. To address this, we introduce entropy regularization, allowing randomized stopping policies that balance exploitation and exploration. We derive an explicit analytical solution to the regularized problem and prove convergence of the associated free boundary to the classical stopping threshold as the entropy vanishes. The regularized problem admits a natural formulation as a singular stochastic control problem. Building on this structure, we propose both model-based and model-free policy iteration algorithms to learn the optimal boundary. The model-free method operates without knowledge of system dynamics, using only trajectories from the stochastic environment. We establish convergence guarantees and illustrate strong numerical performance. This framework provides a principled and tractable approach for data-driven stopping problems under uncertainty.",
      "authors": [
        "Jodi Dianetti",
        "Giorgio Ferrari",
        "Renyuan Xu"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-17 15:10:51+00:00",
      "link": "https://arxiv.org/pdf/2602.15643v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15621v1",
      "title": "Completeness theorems on the boundary for a parabolic equation",
      "abstract": "Let $\\{v_α\\}$ be a system of polynomial solutions of the parabolic equation $a_{hk}\\partial_{x_{h}x_{k}}u - \\partial_t u =0$ in a bounded $C^1$-cylinder $Ω_{T}$ contained in $\\mathbb{R}^{n+1}$. Here $a_{hk}\\partial_{x_{h}x_{k}}$ is an elliptic operator with real constant coefficients. We prove that $\\{v_α\\}$ is complete in $L^{p}(Σ')$, where $Σ'$ is the parabolic boundary of $Ω_{T}$. Similar results are proved for the adjoint equation $a_{hk}\\partial_{x_{h}x_{k}} u+ \\partial_t u =0$.",
      "authors": [
        "Alberto Cialdea",
        "Carmine Sebastiano Mare"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-17 14:48:07+00:00",
      "link": "https://arxiv.org/pdf/2602.15621v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15601v1",
      "title": "Uniqueness and Zeroth-Order Analysis of Weak Solutions to the Non-cutoff Boltzmann equation",
      "abstract": "We establish the uniqueness of large solutions to the non-cutoff Boltzmann equation with moderate soft potentials. Specifically, the weak solution $F=μ+μ^{\\frac{1}{2}}f$ is unique as long as it has finite energy, in the sense that the norm $\\|f\\|_{L^\\infty_t L^{r}_{x,v}}+\\|f\\|_{L^\\infty_t L^2_{x,v}}$ remains bounded (arbitrary large) for some sufficiently large $r>0$. Our approach applies dilated dyadic decompositions in phase space $(v,ξ,η)$ to capture hypoellipticity and to reduce the fractional derivative structure $(-Δ_v)^{s}$ of the Boltzmann collision operator to zeroth order. The difficulties posed by the large solution are overcome through the negative-order hypoelliptic estimate that gains integrability in $(t,x)$.",
      "authors": [
        "Dingqun Deng",
        "Shota Sakamoto"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-02-17 14:12:51+00:00",
      "link": "https://arxiv.org/pdf/2602.15601v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15548v1",
      "title": "A Counterexample to Matkowski's Conjecture for Quasi Graph-Additive Functions",
      "abstract": "In this paper we investigate a conjecture of Janusz Matkowski concerning the continuous solutions of the functional equation \\[ f\\big(f(-x)+x\\big)=f\\big(-f(x)\\big)+f(x),\\qquad x\\in\\mathbb{R}. \\]   Matkowski conjectured that all continuous solutions must necessarily be linear on both the negative and the positive half-line. We show, however, that the family of continuous solutions to the equation in question is far richer than anticipated: there exist continuous solutions that admit an arbitrary part.   In addition, we provide a sufficient condition which, in the continuous setting, enforces the conclusion predicted by Matkowski's Conjecture.",
      "authors": [
        "Tibor Kiss"
      ],
      "primary_category": "math.CA",
      "categories": [
        "math.CA"
      ],
      "published": "2026-02-17 12:54:06+00:00",
      "link": "https://arxiv.org/pdf/2602.15548v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15541v1",
      "title": "Improved regularity for a composite functional equation stemming from the theory of means",
      "abstract": "In this paper we describe the solutions of the functional equation \\begin{equation*} F\\Big(\\frac{x+y}2\\Big)+f_1(x)+f_2(y)=G \\big(g_1(x)+g_2(y)) \\end{equation*} defined on an open subinterval of $ \\mathbb{R} $. Improving previous results we assume differentiability on each involved function, eliminate a former condition on $ g'_1 $ and $ g'_2$, moreover we determine a brand new family of solutions. We also present a particular member of this class as an example. In order to achieve this, we strengthen known results about certain auxiliary functional equations as well.",
      "authors": [
        "Tibor Kiss",
        "Péter Tóth"
      ],
      "primary_category": "math.CA",
      "categories": [
        "math.CA"
      ],
      "published": "2026-02-17 12:44:51+00:00",
      "link": "https://arxiv.org/pdf/2602.15541v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15522v1",
      "title": "Universality of the Hall conductivity for a weakly interacting magnetic fermionic gas in the Hartree-Fock approximation",
      "abstract": "We consider a two-dimensional gas of interacting fermions in presence of an external constant magnetic field: the system is extended and homogeneous, and thus assumed to be invariant under magnetic translations. Working within the Hartree-Fock approximation, we analyze the system directly in the thermodynamic limit by solving a self-consistent fixed-point equation for the one-particle density matrix. We prove that, provided that the interactions among fermions are sufficiently weak, there exists a unique one-particle density matrix that solves the self-consistency condition. By choosing the Fermi-Dirac distribution as the function in the fixed-point equation, this approach can describe both positive and zero-temperature cases.   At zero temperature and when the chemical potential of the non-interacting system lies in a spectral gap of the free Landau operator, our self-consistent solution is an orthogonal projection (an \"interacting\" effective Fermi projection). We prove that its integrated density of states varies linearly with the external magnetic field, provided the interaction is weak enough: the slope of this variation is quantized and independent of the interaction. According to the Středa formula, this can be seen as yet another expression of the universality of the quantum Hall effect in weakly interacting systems, at least within the Hartree-Fock approximation.",
      "authors": [
        "Horia D. Cornean",
        "Emanuela Laura Giacomelli",
        "Domenico Monaco",
        "Mikkel Hviid Thorn"
      ],
      "primary_category": "math-ph",
      "categories": [
        "math-ph"
      ],
      "published": "2026-02-17 11:51:02+00:00",
      "link": "https://arxiv.org/pdf/2602.15522v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15415v1",
      "title": "Framed null curves and timelike surfaces via Lorentzian harmonic maps into de-Sitter 2-space",
      "abstract": "We construct a class of Lorentzian harmonic maps into the de-Sitter $2$-space satisfying the eigenvalue equation $\\Box N=2H^2N$ for the d'Alambert operator $\\Box$ and a non-zero constant $H$ from framed null curves. We also investigate two classes of timelike surfaces associated with these Lorentzian harmonic maps: the first one is timelike surfaces with constant mean curvature $H$ in Lorentz-Minkowski $3$-space and the second one is timelike minimal surfaces in the three-dimensional Lorentzian Heisenberg group $\\operatorname{Nil}_3(H)$. In particular, we characterize some properties of singularities on timelike minimal surfaces in $\\operatorname{Nil}_3(H)$ via an invariant of framed null curves.",
      "authors": [
        "Shintaro Akamine",
        "Hirotaka Kiyohara"
      ],
      "primary_category": "math.DG",
      "categories": [
        "math.DG"
      ],
      "published": "2026-02-17 08:15:11+00:00",
      "link": "https://arxiv.org/pdf/2602.15415v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15370v1",
      "title": "A Geometric Approach to Feedback Stabilization of Nonlinear Systems with Drift",
      "abstract": "The paper presents an approach to the construction of stabilizing feedback for strongly nonlinear systems. The class of systems of interest includes systems with drift which are affine in control and which cannot be stabilized by continuous state feedback. The approach is independent of the selection of a Lyapunov type function, but requires the solution of a nonlinear programming 'satisficing problem' stated in terms of the logarithmic coordinates of flows. As opposed to other approaches, point-to-point steering is not required to achieve asymptotic stability. Instead, the flow of the controlled system is required to intersect periodically a certain reachable set in the space of the logarithmic coordinates.",
      "authors": [
        "Hannah Michalska",
        "Miguel Torres-Torriti"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "eess.SY"
      ],
      "published": "2026-02-17 05:42:53+00:00",
      "link": "https://arxiv.org/pdf/2602.15370v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15300v1",
      "title": "Carleman Inequalities for the Heat Equation with Fourier Boundary Conditions: Applications to Null Controllability Problems",
      "abstract": "In this work, we establish a Carleman inequality for the heat equation with Fourier boundary conditions of the form $\\partial_νy+by=f1_γ$, where the control acts on a small portion $γ$ of the boundary. We apply this inequality to address the null controllability problem with boundary control supported on this small region. An explicit solution to this problem is obtained via a system of coupled parabolic equations. Based on these results, we propose an iterative numerical method to solve the coupled system.",
      "authors": [
        "Jose Antonio Villa"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "math.AP"
      ],
      "published": "2026-02-17 01:50:19+00:00",
      "link": "https://arxiv.org/pdf/2602.15300v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15279v1",
      "title": "On the efficiency of pairwise Hamiltonian control to desynchronize the higher-order Kuramoto model",
      "abstract": "Synchronization of coupled oscillators is observed in many natural and engineered systems and emerges due to the interactions within the system. It can be both beneficial, e.g., in power grids, and harmful, e.g., in epileptic seizures. In the latter case, efficient control methods to desynchronize the systems are crucial. Recent studies have shown that interactions are not always pairwise, but higher-order, i.e., many-body, and this greatly affects the dynamics. For instance, higher-order interactions increase the linear stability of synchronized states but simultaneously shrink their attraction basin, with potentially opposite effects on control methods. Here, we use a minimally invasive pairwise control based on Hamiltonian control theory, and investigate its efficiency on phase oscillators with higher-order interactions. We show that, if the initial phases are close to the synchronized state, higher-order interactions make desynchronization more difficult to achieve. Otherwise, a non-monotonic effect appears: intermediate strengths of higher-order interactions impede desynchronization while larger ones facilitate it. In all cases, the control can desynchronize the system with a sufficient number of controlled nodes and intensity.",
      "authors": [
        "Martin Moriamé",
        "Riccardo Muolo",
        "Timoteo Carletti",
        "Maxime Lucas"
      ],
      "primary_category": "nlin.AO",
      "categories": [
        "nlin.AO",
        "math-ph",
        "math.DS",
        "math.OC",
        "nlin.PS"
      ],
      "published": "2026-02-17 00:34:38+00:00",
      "link": "https://arxiv.org/pdf/2602.15279v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15269v1",
      "title": "Operating room planning with pooling downstream beds among specialties: A stochastic programming approach",
      "abstract": "In this paper, we study pooling downstream beds across specialties in a stochastic operating room planning problem. The main sources of uncertainty are stochastic surgical durations and patients' lengths of stay. We developed a two-stage stochastic programming model where in the first stage we decide on 1) the number of non-shared ICU and ward beds to be allocated to each specialty, and 2) the allocation of surgeries to operating rooms during the planning horizon. In the second stage, we decide on 1) the number of shared beds in ICU and wards to be allocated to different specialties on each day during the planning horizon, 2) the surge capacity required to satisfy downstream service to patients, and 3) the overtime incurred in operating rooms. The proposed model aims at minimizing the total cost including the patients' waiting cost, postponement cost, overtime and fixed cost of operating rooms, and the cost of downstream surge capacity. We have implemented the proposed stochastic programming model in a sample average approximation framework. To enhance the efficiency of sample average approximation, we have developed a specialized algorithm that quickly solves the second-stage model for any given first-stage solution for a large number of scenarios. We have carried out extensive computational experiments to evaluate the effectiveness of several pooling policies for downstream beds and also the efficiency of the proposed sample average approximation algorithm. Moreover, we have performed an extensive sensitivity analysis of cost and stochastic parameters. Our results demonstrated that a full-sharing policy among different specialties in the downstream units enhance the functionality of the system by up to 19.53%. Moreover, the results indicated that the solutions obtained by the proposed stochastic model outperform those from the corresponding deterministic problem by 17.43% on average.",
      "authors": [
        "Arian Andam",
        "Hossein Hashemi Doulabi"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-16 23:54:07+00:00",
      "link": "https://arxiv.org/pdf/2602.15269v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15264v1",
      "title": "Automorphisms of Kimura Hadamard Matrices",
      "abstract": "We investigate the structure of the automorphism groups of Kimura Hadamard matrices (KHMs) constructed from dihedral groups. We identify several different types of automorphisms, and show that the automorphism group of a KHM always has a subgroup isomorphic to $D_{2k}\\times Q_8$, or $C_2\\times D_{2k}\\times Q_8$ if it is $y$-invariant. We exhibit additional automorphisms arising from the holomorph of the dihedral group under suitable structural conditions. A comparison with known examples, including those of Kimura, Niwasaki, and matrices arising from the Shinoda--Yamada construction, reveals counterexamples to a conjecture of Ó Cathaín and suggests that no further automorphisms occur beyond those predicted by our framework.",
      "authors": [
        "Santiago Barrera Acevedo",
        "Melissa Lee"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "math.GR"
      ],
      "published": "2026-02-16 23:39:53+00:00",
      "link": "https://arxiv.org/pdf/2602.15264v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15188v1",
      "title": "Quantization as a Categorical Equivalence for Hilbert Bimodules and Lagrangian Relations",
      "abstract": "It is well known that classical and quantum theories carry distinct types of representations, each type of representation corresponding to possible values of generalized charges in the classical or quantum context. This paper demonstrates a sense in the structure of these representation theories is preserved from classical to quantum physics. To show this, I discuss distinct representation-theory preserving morphisms in the classical and quantum contexts. Specifically, I consider categories whose morphisms are Lagrangian relations in the classical context and Hilbert bimodules in the quantum context. These morphisms are significant because they give rise to induced representations of classical and quantum theories, respectively. I consider quantization and the classical limit as determining functors between these categories. I treat quantization via the strict deformation quantization of a Poisson algebra and the classical limit via the extension of a uniformly continuous bundle of C*-algebras. With these tools, I prove that the quantization and classical limit functors are \"almost-inverse\" to each other, thus establishing a categorical equivalence.",
      "authors": [
        "Benjamin H. Feintzeig"
      ],
      "primary_category": "math-ph",
      "categories": [
        "math-ph",
        "math.OA",
        "quant-ph"
      ],
      "published": "2026-02-16 20:56:24+00:00",
      "link": "https://arxiv.org/pdf/2602.15188v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15000v1",
      "title": "ALiA: Adaptive Linearized ADMM",
      "abstract": "We propose ALiA, a novel adaptive variant of the alternating direction method of multipliers (ADMM). Specifically, ALiA is a variant of function-linearized proximal ADMM (FLiP ADMM), which generalizes the classical ADMM by leveraging the differentiable structure of the objective function, making it highly versatile. Notably, ALiA features an adaptive stepsize selection scheme that eliminates the need for backtracking linesearch. Motivated by recent advances in adaptive gradient and proximal methods, we establish point convergence of ALiA for convex and differentiable objectives. Furthermore, by introducing negligible computational overhead, we develop an alternative stepsize selection scheme for ALiA that improves the convergence speed both theoretically and empirically. Extensive numerical experiments on practical datasets confirm the accelerated performance of ALiA compared to standard FLiP ADMM. Additionally, we demonstrate that ALiA either outperforms or matches the practical performance of existing adaptive methods across problem classes where it is applicable.",
      "authors": [
        "Uijeong Jang",
        "Kaizhao Sun",
        "Wotao Yin",
        "Ernest K Ryu"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-16 18:28:56+00:00",
      "link": "https://arxiv.org/pdf/2602.15000v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14969v1",
      "title": "Topological trivialization in non-convex empirical risk minimization",
      "abstract": "Given data $\\{({\\boldsymbol x}_i,y_i): i\\le n\\}$, with ${\\boldsymbol x}_i$ standard $d$-dimensional Gaussian feature vectors, and $y_i\\in{\\mathbb R}$ response variables, we study the general problem of learning a model parametrized by ${\\boldsymbol θ}\\in{\\mathbb R}^d$, by minimizing a loss function that depends on ${\\boldsymbol θ}$ via the one-dimensional projections ${\\boldsymbol θ}^{\\sf T}{\\boldsymbol x}_i$. While previous work mostly dealt with convex losses, our approach assumes general (non-convex) losses hence covering classical, yet poorly understood examples such as the perceptron and non-convex robust regression. We use the Kac-Rice formula to control the asymptotics of the expected number of local minima of the empirical risk, under the proportional asymptotics $n,d\\to\\infty$, $n/d\\toα>1$. Specifically, we prove a finite dimensional variational formula for the exponential growth rate of the expected number of local minima. Further we provide sufficient conditions under which the exponential growth rate vanishes and all empirical risk minimizers have the same asymptotic properties (in fact, we expect the minimizer to be unique in these circumstances). We refer to this phenomenon as `rate trivialization.' If the population risk has a unique minimizer, our sufficient condition for rate trivialization is typically verified when the samples/parameters ratio $α$ is larger than a suitable constant $α_{\\star}$. Previous general results of this type required $n\\ge Cd \\log d$. We illustrate our results in the case of non-convex robust regression. Based on heuristic arguments and numerical simulations, we present a conjecture for the exact location of the trivialization phase transition $α_{\\text{tr}}$.",
      "authors": [
        "Andrea Montanari",
        "Basil Saeed"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST"
      ],
      "published": "2026-02-16 17:55:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14969v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14630v1",
      "title": "Bayesian Cosmic Void Finding with Graph Flows",
      "abstract": "Cosmic voids contain higher-order cosmological information and are of interest for astroparticle physics. Finding genuine matter underdensities in sparse galaxy surveys is, however, an underconstrained problem. Traditional void finding algorithms produce deterministic void catalogs, neglecting the probabilistic nature of the problem. We present a method to sample from the stochastic mapping from galaxy catalogs to arbitrary void definitions. Our algorithm uses a deep graph neural network to evolve \"test particles\" according to a flow-matching objective. We demonstrate the method in a simplified example setting but outline steps to generalize it towards practically usable void finders. Trained on a deterministic teacher, the model performs well but has considerable stochasticity which we interpret as regularization. Cosmological information in the predicted void catalogs outperforms the teacher. On the one hand, our method can cheaply emulate existing void finders with apparently useful regularization. More importantly, it also allows us to find the Bayes-optimal mapping between observed galaxies and any void definition. This includes definitions operating at the level of simulated matter density and velocity fields.",
      "authors": [
        "Leander Thiele"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "stat.ML"
      ],
      "published": "2026-02-16 10:37:53+00:00",
      "link": "https://arxiv.org/pdf/2602.14630v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14414v1",
      "title": "The Role of Measured Covariates in Assessing Sensitivity to Unmeasured Confounding",
      "abstract": "Sensitivity analysis is widely used to assess the robustness of causal conclusions in observational studies, yet its interaction with the structure of measured covariates is often overlooked. When latent confounders cannot be directly adjusted for and are instead controlled using proxy variables, strong associations between exposure and measured proxies can amplify sensitivity to residual confounding. We formalize this phenomenon in linear regression settings by showing that a simple ratio involving the exposure model coefficient and residual exposure variance provides an observable measure of this increased sensitivity. Applying our framework to smoking and lung cancer, we document how growing socioeconomic stratification in smoking behavior over time leads to heightened sensitivity to unmeasured confounding in more recent data. These results highlight the importance of multicollinearity when interpreting sensitivity analyses based on proxy adjustment.",
      "authors": [
        "Abhinandan Dalal",
        "Iris Horng",
        "Yang Feng",
        "Dylan S. Small"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "econ.EM",
        "stat.AP"
      ],
      "published": "2026-02-16 02:45:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14414v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14387v1",
      "title": "Automatic Variance Adjustment for Small Area Estimation",
      "abstract": "Small area estimation (SAE) is a common endeavor and is used in a variety of disciplines. In low- and middle-income countries (LMICs), in which household surveys provide the most reliable and timely source of data, SAE is vital for highlighting disparities in health and demographic indicators. Weighted estimators are ideal for inference, but for fine geographical partitions in which there are insufficient data, SAE models are required. The most common approach is Fay-Herriot area-level modeling in which the data requirements are a weighted estimate and an associated variance estimate. The latter can be undefined or unstable when data are sparse and so we propose a principled modification which is based on augmenting the available data with a prior sample from a hypothetical survey. This adjustment is generally available, respects the design and is simple to implement. We examine the empirical properties of the adjustment through simulation and illustrate its use with wasting data from a 2018 Zambian Demographic and Health Survey. The modification is implemented as an automatic remedy in the R package surveyPrev, which provides a comprehensive suite of tools for conducing SAE in LMICs.",
      "authors": [
        "Jon Wakefield",
        "Jitong Jiang",
        "Yunhan Wu"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-16 01:29:59+00:00",
      "link": "https://arxiv.org/pdf/2602.14387v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14198v1",
      "title": "Zipf-Mandelbrot Scaling in Korean Court Music: Universal Patterns in Music",
      "abstract": "Zipf's law, originally discovered in natural language and later generalized to the Zipf-Mandelbrot law, describes a power-law relationship between the frequency of a Zipfian element and its rank. Due to the semantic characteristics of this law, it has also been observed in musical data. However, most such studies have focused on Western music, and its applicability to non-Western music remains not well investigated. We analyzed 43 Korean court music pieces called Jeong-ak, spanning several centuries and written in the traditional Korean musical notation Jeongganbo. These pieces were transcribed into Western staff notation, and musical data such as pitch and duration were extracted. Using pitch, duration, and their paired combinations as Zipfian units, we found that Korean music also fits the Zipf-Mandelbrot law to a high degree, particularly for the paired pitch-duration unit. Korean music has evolved collectively over long periods, smoothing idiosyncratic variations and producing forms that are widely understandable among people. This collective evolution appears to have played a significant role in shaping the characteristics that lead to the satisfaction of Zipf-Mandelbrot law. Our findings provide additional evidence that Zipf-Mandelbrot scaling in musical data is universal across cultures. We further show that the joint distribution of two independent Zipfian data sets follows the Zipf-Mandelbrot law; in this sense, our result does not merely extend Zipf's law but deepens our understanding of how scaling laws behave under composition and interaction, offering a more unified perspective on rank-based statistical regularities.",
      "authors": [
        "Byeongchan Choi",
        "Junwon You",
        "Myung Ock Kim",
        "Jae-Hun Jung"
      ],
      "primary_category": "stat.AP",
      "categories": [
        "stat.AP"
      ],
      "published": "2026-02-15 15:47:39+00:00",
      "link": "https://arxiv.org/pdf/2602.14198v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13442v1",
      "title": "Measuring Neural Network Complexity via Effective Degrees of Freedom",
      "abstract": "Quantifying the complexity of feed-forward neural networks (FFNNs) remains challenging due to their nonlinear, hierarchical structure and numerous parameters. We apply generalized degrees of freedom (GDF) to measure model complexity in FFNNs with binary outcomes, adapting the algorithm for discrete responses. We compare GDF with both the effective number of parameters derived via log-likelihood cross-validation and the null degrees of freedom of Landsittel et al. Through simulation studies and a real data analysis, we demonstrate that GDF provides a robust assessment of model complexity for neural network models, as it depends only on the sensitivity of fitted values to perturbations in the observed responses rather than on assumptions about the likelihood. In contrast, cross-validation-based estimates of model complexity and the null degrees of freedom rely on the correctness of the assumed likelihood and may exhibit substantial variability. We find that GDF, cross-validation-based measures, and null degrees of freedom yield similar assessments of model complexity only when the fitted model adequately represents the data-generating mechanism. These findings highlight GDF as a stable and broadly applicable measure of model complexity for neural networks in statistical modeling.",
      "authors": [
        "Jia Zhou",
        "Douglas Landsittel"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "stat.ML"
      ],
      "published": "2026-02-13 20:37:12+00:00",
      "link": "https://arxiv.org/pdf/2602.13442v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13184v1",
      "title": "Profiling systematic uncertainties in Simulation-Based Inference with Factorizable Normalizing Flows",
      "abstract": "Unbinned likelihood fits aim at maximizing the information one can extract from experimental data, yet their application in realistic statistical analyses is often hindered by the computational cost of profiling systematic uncertainties. Additionally, current machine learning-based inference methods are typically limited to estimating scalar parameters in a multidimensional space rather than full differential distributions. We propose a general framework for Simulation-Based Inference (SBI) that efficiently profiles nuisance parameters while measuring multivariate Distributions of Interest (DoI), defined as learnable invertible transformations of the feature space. We introduce Factorizable Normalizing Flows to model systematic variations as parametric deformations of a nominal density, preserving tractability without combinatorial explosion. Crucially, we develop an amortized training strategy that learns the conditional dependence of the DoI on nuisance parameters in a single optimization process, bypassing the need for repetitive training during the likelihood scan. This allows for the simultaneous extraction of the underlying distribution and the robust profiling of nuisances. The method is validated on a synthetic dataset emulating a high-energy physics measurement with multiple systematic sources, demonstrating its potential for unbinned, functional measurements in complex analyses.",
      "authors": [
        "Davide Valsecchi",
        "Mauro Donegà",
        "Rainer Wallny"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "physics.data-an",
        "stat.ML"
      ],
      "published": "2026-02-13 18:48:12+00:00",
      "link": "https://arxiv.org/pdf/2602.13184v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13158v2",
      "title": "A new mixture model for spatiotemporal exceedances with flexible tail dependence",
      "abstract": "We propose a new model and estimation framework for spatiotemporal streamflow exceedances above a threshold that flexibly captures asymptotic dependence and independence in the tail of the distribution. We model streamflow using a mixture of processes with spatial, temporal and spatiotemporal asymptotic dependence regimes. A censoring mechanism allows us to use only observations above a threshold to estimate marginal and joint probabilities of extreme events. As the likelihood is intractable, we use simulation-based inference powered by random forests to estimate model parameters from summary statistics of the data. Simulations and modeling of streamflow data from the U.S. Geological Survey illustrate the feasibility and practicality of our approach.",
      "authors": [
        "Ryan Li",
        "Emily C. Hector",
        "Brian J. Reich",
        "Reetam Majumder"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-13 18:12:01+00:00",
      "link": "https://arxiv.org/pdf/2602.13158v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12845v1",
      "title": "Small area estimation using incomplete auxiliary information",
      "abstract": "Auxiliary information is increasingly available from administrative and other data sources, but it is often incomplete and of non-probability origin. We propose a two-step small area estimation approach in which the first step relies on design-based model calibration and exploits a large non-probability source providing a noisy proxy of the study variable for only part of the population. A unit-level measurement-error working model is fitted on the linked overlap between the probability survey and the external source, and its predictions are incorporated through domain-specific model-calibration constraints to obtain approximately design-unbiased domain totals. These totals and their variance estimates are then used in a Fay-Herriot area-level model with exactly known covariates to produce empirical best linear unbiased predictors. The approach is demonstrated in three enterprise survey settings from official statistics by integrating probability sample data with (i) administrative records, (ii) a cut-off data source, and (iii) web-scraped online information. Empirical comparisons show consistent improvements in domain-level precision over direct estimation and over a Fay-Herriot benchmark that directly incorporates the proxy information as an error-prone covariate. These gains are achieved without modeling the selection mechanism of the non-probability sample.",
      "authors": [
        "Donatas Šlevinskas",
        "Ieva Burakauskaitė",
        "Andrius Čiginas"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-13 11:52:04+00:00",
      "link": "https://arxiv.org/pdf/2602.12845v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12490v1",
      "title": "Transformer-based CoVaR: Systemic Risk in Textual Information",
      "abstract": "Conditional Value-at-Risk (CoVaR) quantifies systemic financial risk by measuring the loss quantile of one asset, conditional on another asset experiencing distress. We develop a Transformer-based methodology that integrates financial news articles directly with market data to improve CoVaR estimates. Unlike approaches that use predefined sentiment scores, our method incorporates raw text embeddings generated by a large language model (LLM). We prove explicit error bounds for our Transformer CoVaR estimator, showing that accurate CoVaR learning is possible even with small datasets. Using U.S. market returns and Reuters news items from 2006--2013, our out-of-sample results show that textual information impacts the CoVaR forecasts. With better predictive performance, we identify a pronounced negative dip during market stress periods across several equity assets when comparing the Transformer-based CoVaR to both the CoVaR without text and the CoVaR using traditional sentiment measures. Our results show that textual data can be used to effectively model systemic risk without requiring prohibitively large data sets.",
      "authors": [
        "Junyu Chen",
        "Tom Boot",
        "Lingwei Kong",
        "Weining Wang"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM",
        "q-fin.RM",
        "stat.ML"
      ],
      "published": "2026-02-13 00:10:30+00:00",
      "link": "https://arxiv.org/pdf/2602.12490v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12072v1",
      "title": "Enhanced Forest Inventories for Habitat Mapping: A Case Study in the Sierra Nevada Mountains of California",
      "abstract": "Traditional forest inventory systems, originally designed to quantify merchantable timber volume, often lack the spatial resolution and structural detail required for modern multi-resource ecosystem management. In this manuscript, we present an Enhanced Forest Inventory (EFI) and demonstrate its utility for high-resolution wildlife habitat mapping. The project area covers 270,000 acres of the Eldorado National Forest in California's Sierra Nevada. By integrating 118 ground-truth Forest Inventory and Analysis (FIA) plots with multi-modal remote sensing data (LiDAR, aerial photography, and Sentinel-2 satellite imagery), we developed predictive models for key forest attributes. Our methodology employed a two-tier segmentation approach, partitioning the landscape into approximately 575,000 reporting units with an average size of 0.5 acre to capture forest heterogeneity. We utilized an Elastic-Net Regression framework and automated feature selection to relate remote sensing metrics to ground-measured variables such as basal area, stems per acre, and canopy cover. These physical metrics were translated into functional habitat attributes to evaluate suitability for two focal species: the California Spotted Owl (Strix occidentalis occidentalis) and the Pacific Fisher (Pekania pennanti). Our analysis identified 25,630 acres of nesting and 26,622 acres of foraging habitat for the owl, and 25,636 acres of likely habitat for the fisher based on structural requirements like large-diameter trees and high canopy closure. The results demonstrate that EFIs provide a critical bridge between forestry and conservation ecology, offering forest managers a spatially explicit tool to monitor ecosystem health and manage vulnerable species in complex environments.",
      "authors": [
        "Maxime Turgeon",
        "Michael Kieser",
        "Dwight Wolfe",
        "Bruce MacArthur"
      ],
      "primary_category": "stat.AP",
      "categories": [
        "stat.AP"
      ],
      "published": "2026-02-12 15:32:02+00:00",
      "link": "https://arxiv.org/pdf/2602.12072v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11118v1",
      "title": "A Doubly Robust Machine Learning Approach for Disentangling Treatment Effect Heterogeneity with Functional Outcomes",
      "abstract": "Causal inference is paramount for understanding the effects of interventions, yet extracting personalized insights from increasingly complex data remains a significant challenge for modern machine learning. This is the case, in particular, when considering functional outcomes observed over a continuous domain (e.g., time, or space). Estimation of heterogeneous treatment effects, known as CATE, has emerged as a crucial tool for personalized decision-making, but existing meta-learning frameworks are largely limited to scalar outcomes, failing to provide satisfying results in scientific applications that leverage the rich, continuous information encoded in functional data. Here, we introduce FOCaL (Functional Outcome Causal Learning), a novel, doubly robust meta-learner specifically engineered to estimate a functional heterogeneous treatment effect (F-CATE). FOCaL integrates advanced functional regression techniques for both outcome modeling and functional pseudo-outcome reconstruction, thereby enabling the direct and robust estimation of F-CATE. We provide a rigorous theoretical derivation of FOCaL, demonstrate its performance and robustness compared to existing non-robust functional methods through comprehensive simulation studies, and illustrate its practical utility on diverse real-world functional datasets. FOCaL advances the capabilities of machine intelligence to infer nuanced, individualized causal effects from complex data, paving the way for more precise and trustworthy AI systems in personalized medicine, adaptive policy design, and fundamental scientific discovery.",
      "authors": [
        "Filippo Salmaso",
        "Lorenzo Testa",
        "Francesca Chiaromonte"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "stat.ML"
      ],
      "published": "2026-02-11 18:31:59+00:00",
      "link": "https://arxiv.org/pdf/2602.11118v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10924v1",
      "title": "Non-centred Bayesian inference for discrete-valued state-transition models: the Rippler algorithm",
      "abstract": "Stochastic state-transition models of infectious disease transmission can be used to deduce relevant drivers of transmission when fitted to data using statistically principled methods. Fitting this individual-level data requires inference on individuals' unobserved disease statuses over time, which form a high-dimensional and highly correlated state space. We introduce a novel Bayesian (data-augmentation Markov chain Monte Carlo) algorithm for jointly estimating the model parameters and unobserved disease statuses, which we call the Rippler algorithm. This is a non-centred method that can be applied to any individual-based state-transition model. We compare the Rippler algorithm to the state-of-the-art inference methods for individual-based stochastic epidemic models and find that it performs better than these methods as the number of disease states in the model increases.",
      "authors": [
        "James Neill",
        "Lloyd A. C. Chapman",
        "Chris Jewell"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-11 15:01:55+00:00",
      "link": "https://arxiv.org/pdf/2602.10924v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10784v1",
      "title": "Integrating Unsupervised and Supervised Learning for the Prediction of Defensive Schemes in American football",
      "abstract": "Anticipating defensive coverage schemes is a crucial yet challenging task for offenses in American football. Because defenders' assignments are intentionally disguised before the snap, they remain difficult to recognize in real time. To address this challenge, we develop a statistical framework that integrates supervised and unsupervised learning using player tracking data. Our goal is to forecast the defensive coverage scheme -- man or zone -- through elastic net logistic regression and gradient-boosted decision trees with incrementally derived features. We first use features from the pre-motion situation, then incorporate players' trajectories during motion in a naive way, and finally include features derived from a hidden Markov model (HMM). Based on player movements, the non-homogeneous HMM infers latent defensive assignments between offensive and defensive players during motion and transforms decoded state sequences into informative features for the supervised models. These HMM-based features enhance predictive performance and are significantly associated with coverage outcomes. Moreover, estimated random effects offer interpretable insights into how different defenses and positions adjust their coverage responsibilities.",
      "authors": [
        "Rouven Michels",
        "Robert Bajons",
        "Jan-Ole Fischer"
      ],
      "primary_category": "stat.AP",
      "categories": [
        "stat.AP"
      ],
      "published": "2026-02-11 12:19:10+00:00",
      "link": "https://arxiv.org/pdf/2602.10784v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10012v1",
      "title": "Doubly Robust Estimation of Desirability of Outcome Ranking (DOOR) Probability with Application to MDRO Studies",
      "abstract": "In observational studies, adjusting for confounders is required if a treatment comparison is planned. A crude comparison of the primary endpoint without covariate adjustment will suffer from biases, and the addition of regression models could improve precision by incorporating imbalanced covariates and thus help make correct inference. Desirability of outcome ranking (DOOR) is a patient-centric benefit-risk evaluation methodology designed for randomized clinical trials. Still, robust covariate adjustment methods could further expand the compatibility of this method in observational studies. In DOOR analysis, each participant's outcome is ranked based on pre-specified clinical criteria, where the most desirable rank represents a good outcome with no side effects and the least desirable rank is the worst possible clinical outcome. We develop a causal framework for estimating the population-level DOOR probability, via the inverse probability of treatment weighting method, G-Computation method, and a Doubly Robust method that combines both. The performance of the proposed methodologies is examined through simulations. We also perform a causal analysis of the Multi-Drug Resistant Organism (MDRO) network within the Antibacterial Resistant Leadership Group (ARLG), comparing the benefit:risk between Mono-drug therapy and Combination-drug therapy.",
      "authors": [
        "Shiyu Shu",
        "Toshimitsu Hamasaki",
        "Scott Evans",
        "Lauren Komarow",
        "David van Duin",
        "Guoqing Diao"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-10 17:35:29+00:00",
      "link": "https://arxiv.org/pdf/2602.10012v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09351v1",
      "title": "Supervised Learning of Functional Outcomes with Predictors at Different Scales: A Functional Gaussian Process Approach",
      "abstract": "The analysis of complex computer simulations, often involving functional data, presents unique statistical challenges. Conventional regression methods, such as function-on-function regression, typically associate functional outcomes with both scalar and functional predictors on a per-realization basis. However, simulation studies often demand a more nuanced approach to disentangle nonlinear relationships of functional outcome with predictors observed at multiple scales: domain-specific functional predictors that are fixed across simulation runs, and realization-specific global predictors that vary between runs. In this article, we develop a novel supervised learning framework tailored to this setting. We propose an additive nonlinear regression model that flexibly captures the influence of both predictor types. The effects of functional predictors are modeled through spatially-varying coefficients governed by a Gaussian process prior. Crucially, to capture the impact of global predictors on the functional outcome, we introduce a functional Gaussian process (fGP) prior. This new prior jointly models the entire collection of unknown, spatially-indexed nonlinear functions that encode the effects of the global predictors over the entire domain, explicitly accounting for their spatial dependence. This integrated architecture enables simultaneous learning from both predictor types, provides a principled strategies to quantify their respective contributions in predicting the functional outcome, and delivers rigorous uncertainty estimates for both model parameters and predictions. The utility and robustness of our approach are demonstrated through multiple synthetic datasets and a real-world application involving outputs from the Sea, Lake, and Overland Surges from Hurricanes (SLOSH) model.",
      "authors": [
        "R. Jacob Andros",
        "Rajarshi Guhaniyogi",
        "Devin Francom",
        "Donatella Pasqualini"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-10 02:56:03+00:00",
      "link": "https://arxiv.org/pdf/2602.09351v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09167v1",
      "title": "Mean regression for (0,1) responses via beta scale mixtures",
      "abstract": "To achieve a greater general flexibility for modeling heavy-tailed bounded responses, a beta scale mixture model is proposed. Each member of the family is obtained by multiplying the scale parameter of the conditional beta distribution by a mixing random variable taking values on all or part of the positive real line and whose distribution depends on a single parameter governing the tail behavior of the resulting compound distribution. These family members allow for a wider range of values for skewness and kurtosis. To validate the effectiveness of the proposed model, we conduct experiments on both simulated data and real datasets. The results indicate that the beta scale mixture model demonstrates superior performance relative to the classical beta regression model and alternative competing methods for modeling responses on the bounded unit domain.",
      "authors": [
        "Arno Otto",
        "Andriëtte Bekker",
        "Johan Ferreira",
        "Lebogang Rathebe"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-09 20:18:37+00:00",
      "link": "https://arxiv.org/pdf/2602.09167v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09145v1",
      "title": "Estimating causal effects of functional treatments with modified functional treatment policies",
      "abstract": "Functional data are increasingly prevalent in biomedical research. While functional data analysis has been established for decades, causal inference with functional treatments remains largely unexplored. Existing methods typically focus on estimating the causal average dose response functional (ADRF), which requires strong positivity assumptions and offers limited interpretability. In this work, we target a new causal estimand, the modified functional treatment policy (MFTP), which focuses on estimating the average potential outcome when each individual slightly modifies their treatment trajectory from the observed one. A major challenge for this new estimand is the need to define an average over an infinite-dimensional object with no density. By proposing a novel definition of the population average over a functional variable using a functional principal component analysis (FPCA) decomposition, we establish the causal identifiability of the MFTP estimand. We further derive outcome regression, inverse probability weighting, and doubly robust estimators for the MFTP, and provide theoretical guarantees under mild regularity conditions. The proposed estimators are validated through extensive simulation studies. Applying our MFTP framework to the National Health and Nutrition Examination Survey (NHANES) accelerometer data, we estimate the causal effects of reducing disruptive nighttime activity and low-activity duration on all-cause mortality.",
      "authors": [
        "Ziren Jiang",
        "Erjia Cui",
        "Jared D. Huling"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-09 19:42:23+00:00",
      "link": "https://arxiv.org/pdf/2602.09145v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16616v1",
      "title": "Design and Analysis Strategies for Pooling in High Throughput Screening: Application to the Search for a New Anti-Microbial",
      "abstract": "A major public health issue is the growing resistance of bacteria to antibiotics. An important part of the needed response is the discovery and development of new antimicrobial strategies. These require the screening of potential new drugs, typically accomplished using high-throughput screening (HTS). Traditionally, HTS is performed by examining one compound per well, but a more efficient strategy pools multiple compounds per well. In this work, we study several recently proposed pooling construction methods, as well as a variety of pooled high-throughput screening analysis methods, in order to provide guidance to practitioners on which methods to use. This is done in the context of an application of the methods to the search for new drugs to combat bacterial infection. We discuss both an extensive pilot study as well as a small screening campaign, and highlight both the successes and challenges of the pooling approach.",
      "authors": [
        "Byran Smucker",
        "Benjamin Brennan",
        "Emily Rego",
        "Meng Wu",
        "Zhihong Lin",
        "Brian Ahmer",
        "Blake Peterson"
      ],
      "primary_category": "stat.AP",
      "categories": [
        "stat.AP"
      ],
      "published": "2026-02-18 17:09:34+00:00",
      "link": "https://arxiv.org/pdf/2602.16616v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16583v1",
      "title": "Physical Activity Trajectories Preceding Incident Major Depressive Disorder Diagnosis Using Consumer Wearable Devices in the All of Us Research Program: Case-Control Study",
      "abstract": "Low physical activity is a known risk factor for major depressive disorder (MDD), but changes in activity before a first clinical diagnosis remain unclear, especially using long-term objective measurements. This study characterized trajectories of wearable-measured physical activity during the year preceding incident MDD diagnosis.   We conducted a retrospective nested case-control study using linked electronic health record and Fitbit data from the All of Us Research Program. Adults with at least 6 months of valid wearable data in the year before diagnosis were eligible. Incident MDD cases were matched to controls on age, sex, body mass index, and index time (up to four controls per case). Daily step counts and moderate-to-vigorous physical activity (MVPA) were aggregated into monthly averages. Linear mixed-effects models compared trajectories from 12 months before diagnosis to diagnosis. Within cases, contrasts identified when activity first significantly deviated from levels 12 months prior.   The cohort included 4,104 participants (829 cases and 3,275 controls; 81.7% women; median age 48.4 years). Compared with controls, cases showed consistently lower activity and significant downward trajectories in both step counts and MVPA during the year before diagnosis (P < 0.001). Significant declines appeared about 4 months before diagnosis for step counts and 5 months for MVPA. Exploratory analyses suggested subgroup differences, including steeper declines in men, greater intensity reductions at older ages, and persistently low activity among individuals with obesity.   Sustained within-person declines in physical activity emerged months before incident MDD diagnosis. Longitudinal wearable monitoring may provide early signals to support risk stratification and earlier intervention.",
      "authors": [
        "Yuezhou Zhang",
        "Amos Folarin",
        "Hugh Logan Ellis",
        "Rongrong Zhong",
        "Callum Stewart",
        "Heet Sankesara",
        "Hyunju Kim",
        "Shaoxiong Sun",
        "Abhishek Pratap",
        "Richard JB Dobson"
      ],
      "primary_category": "stat.AP",
      "categories": [
        "stat.AP"
      ],
      "published": "2026-02-18 16:29:12+00:00",
      "link": "https://arxiv.org/pdf/2602.16583v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16497v1",
      "title": "Factor-Adjusted Multiple Testing for High-Dimensional Individual Mediation Effects",
      "abstract": "Identifying individual mediators is a central goal of high-dimensional mediation analysis, yet pervasive dependence among mediators can invalidate standard debiased inference and lead to substantial false discovery rate (FDR) inflation. We propose a Factor-Adjusted Debiased Mediation Testing (FADMT) framework that enables large-scale inference for individual mediation effects with FDR control under complex dependence structures. Our approach posits an approximate factor structure on the unobserved errors of the mediator model, extracts common latent factors, and constructs decorrelated pseudo-mediators for the subsequent inferential procedure. We establish the asymptotic normality of the debiased estimator and develop a multiple testing procedure with theoretical FDR control under mild high-dimensional conditions. By adjusting for latent factor induced dependence, FADMT also improves robustness to spurious associations driven by shared latent variation in observational studies. Extensive simulations demonstrate the superior finite-sample performance across a wide range of correlation structures. Applications to TCGA-BRCA multi-omics data and to China's stock connect study further illustrate the practical utility of the proposed method.",
      "authors": [
        "Chen Shi",
        "Zhao Chen",
        "Christina Dan Wang"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-18 14:40:42+00:00",
      "link": "https://arxiv.org/pdf/2602.16497v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16463v1",
      "title": "Focused Relative Risk Information Criterion for Variable Selection in Linear Regression",
      "abstract": "This paper motivates and develops a novel and focused approach to variable selection in linear regression models. For estimating the regression mean $μ=\\E\\,(Y\\midd x_0)$, for the covariate vector of a given individual, there is a list of competing estimators, say $\\hattμ_S$ for each submodel $S$. Exact expressions are found for the relative mean squared error risks, when compared to the widest model available, say $\\mse_S/\\mse_\\wide$. The theory of confidence distributions is used for accurate assessments of these relative risks. This leads to certain Focused Relative Risk Information Criterion scores, and associated FRIC plots and FRIC tables, as well as to Confidence plots to exhibit the confidence the data give in the submodels. The machinery is extended to handle many focus parameters at the same time, with appropriate averaged FRIC scores. The particular case where all available covariate vectors have equal importance yields a new overall criterion for variable selection, balancing complexity and fit in a natural fashion. A connection to the Mallows criterion is demonstrated, leading also to natural modifications of the latter. The FRIC and AFRIC strategies are illustrated for real data.",
      "authors": [
        "Nils Lid Hjort"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-18 13:49:23+00:00",
      "link": "https://arxiv.org/pdf/2602.16463v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16376v1",
      "title": "Two-way Clustering Robust Variance Estimator in Quantile Regression Models",
      "abstract": "We study inference for linear quantile regression with two-way clustered data. Using a separately exchangeable array framework and a projection decomposition of the quantile score, we characterize regime-dependent convergence rates and establish a self-normalized Gaussian approximation. We propose a two-way cluster-robust sandwich variance estimator with a kernel-based density ``bread'' and a projection-matched ``meat'', and prove consistency and validity of inference in Gaussian regimes. We also show an impossibility result for uniform inference in a non-Gaussian interaction regime.",
      "authors": [
        "Ulrich Hounyo",
        "Jiahao Lin"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM",
        "stat.AP"
      ],
      "published": "2026-02-18 11:35:18+00:00",
      "link": "https://arxiv.org/pdf/2602.16376v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16146v1",
      "title": "Uncertainty-Aware Neural Multivariate Geostatistics",
      "abstract": "We propose Deep Neural Coregionalization, a scalable framework for uncertainty-aware multivariate geostatistics. DNC models multivariate spatial effects through spatially varying latent factors and loadings, assigning deep Gaussian process (DGP) priors to both the factors and the entries of the loading matrix. This joint construction learns shared latent spatial structure together with response-specific, location-dependent mixing weights, enabling flexible nonlinear and space-dependent associations within and across variables. A key contribution is a variational formulation that makes the DGP to deep neural network (DNN) correspondence explicit: maximizing the DGP evidence lower bound (ELBO) is equivalent to training DNNs with weight decay and Monte Carlo (MC) dropout. This yields fast mini-batch stochastic optimization without Markov Chain Monte Carlo (MCMC), while providing principled uncertainty quantification through MC-dropout forward passes as approximate posterior draws, producing calibrated credible surfaces for prediction and spatial effect estimation. Across simulations, DNC is competitive with existing spatial factor models, particularly under strong nonstationarity and complex cross-dependence, while delivering substantial computational gains. In a multivariate environmental case study, DNC captures spatially varying cross-variable interactions, produces interpretable maps of multivariate outcomes, and scales uncertainty quantification to large datasets with orders-of-magnitude reductions in runtime.",
      "authors": [
        "Yeseul Jeon",
        "Aaron Scheffler",
        "Rajarshi Guhaniyogi"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-18 02:38:22+00:00",
      "link": "https://arxiv.org/pdf/2602.16146v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16041v1",
      "title": "Predictive Subsampling for Scalable Inference in Networks",
      "abstract": "Network datasets appear across a wide range of scientific fields, including biology, physics, and the social sciences. To enable data-driven discoveries from these networks, statistical inference techniques like estimation and hypothesis testing are crucial. However, the size of modern networks often exceeds the storage and computational capacities of existing methods, making timely, statistically rigorous inference difficult. In this work, we introduce a subsampling-based approach aimed at reducing the computational burden associated with estimation and two-sample hypothesis testing. Our strategy involves selecting a small random subset of nodes from the network, conducting inference on the resulting subgraph, and then using interpolation based on the observed connections between the subsample and the rest of the nodes to estimate the entire graph. We develop the methodology under the generalized random dot product graph framework, which affords broad applicability and permits rigorous analysis. Within this setting, we establish consistency guarantees and corroborate the practical effectiveness of the approach through comprehensive simulation studies.",
      "authors": [
        "Arpan Kumar",
        "Minh Tang",
        "Srijan Sengupta"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-17 21:48:57+00:00",
      "link": "https://arxiv.org/pdf/2602.16041v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15697v1",
      "title": "Reproducibility and Statistical Methodology",
      "abstract": "In 2015 the Open Science Collaboration (OSC) (Nosek et al 2015) published a highly influential paper which claimed that a large fraction of published results in the psychological sciences were not reproducible. In this article we review this claim from several points of view. We first offer an extended analysis of the methods used in that study. We show that the OSC methodology induces a bias that is able by itself to explain the discrepancy between the OSC estimates of reproducibility and other more optimistic estimates made by similar studies.   The article also offers a more general literature review and discussion of reproducibility in experimental science. We argue, for both scientific and ethical reasons, that a considered balance of false positive and false negative rates is preferable to a single-minded concentration on false positive rates alone.",
      "authors": [
        "Anthony Almudevar",
        "Jacob Almudevar"
      ],
      "primary_category": "stat.AP",
      "categories": [
        "stat.AP"
      ],
      "published": "2026-02-17 16:25:00+00:00",
      "link": "https://arxiv.org/pdf/2602.15697v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15387v1",
      "title": "Bayesian Nonparametrics for Gene-Gene and Gene-Environment Interactions in Case-Control Studies: A Synthesis and Extension",
      "abstract": "Gene-gene and gene-environment interactions are widely believed to play significant roles in explaining the variability of complex traits. While substantial research exists in this area, a comprehensive statistical framework that addresses multiple sources of uncertainty simultaneously remains lacking. In this article, we synthesize and propose extension of a novel class of Bayesian nonparametric approaches that account for interactions among genes, loci, and environmental factors while accommodating uncertainty about population substructure. Our contribution is threefold: (1) We provide a unified exposition of hierarchical Bayesian models driven by Dirichlet processes for genetic interactions, clarifying their conceptual advantages over traditional regression approaches; (2) We shed light on new computational strategies that combine transformation-based MCMC with parallel processing for scalable inference; and (3) We present enhanced hypothesis testing procedures for identifying disease-predisposing loci.Through applications to myocardial infarction data, we demonstrate how these methods offer biological insights not readily obtainable from standard approaches. Our synthesis highlights the advantages of Bayesian nonparametric thinking in genetic epidemiology while providing practical guidance for implementation.",
      "authors": [
        "Durba Bhattacharya",
        "Sourabh Bhattacharya"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "stat.AP"
      ],
      "published": "2026-02-17 06:48:31+00:00",
      "link": "https://arxiv.org/pdf/2602.15387v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15385v2",
      "title": "From Chain-Ladder to Individual Claims Reserving",
      "abstract": "The chain-ladder (CL) method is the most widely used claims reserving technique in non-life insurance. This manuscript introduces a novel approach to computing the CL reserves based on a fundamental restructuring of the data utilization for the CL prediction procedure. Instead of rolling forward the cumulative claims with estimated CL factors, we estimate multi-period factors that project the latest observations directly to the ultimate claims. This alternative perspective on CL reserving creates a natural pathway for the application of machine learning techniques to individual claims reserving. As a proof of concept, we present a small-scale real data application employing neural networks for individual claims reserving.",
      "authors": [
        "Ronald Richman",
        "Mario V. Wüthrich"
      ],
      "primary_category": "stat.AP",
      "categories": [
        "stat.AP",
        "q-fin.RM",
        "stat.ML"
      ],
      "published": "2026-02-17 06:46:17+00:00",
      "link": "https://arxiv.org/pdf/2602.15385v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15247v1",
      "title": "Sample size and power determination for assessing overall SNP effects in joint modeling of longitudinal and time-to-event data",
      "abstract": "Longitudinal biomarkers are frequently collected in clinical studies due to their strong association with time-to-event outcomes. While considerable progress has been made in methods for jointly modeling longitudinal and survival data, comparatively little attention has been paid to statistical design considerations, particularly sample size and power calculations, in genetic studies. Yet, appropriate sample size estimation is essential for ensuring adequate power and valid inference. Genetic variants may influence event risk through both direct effects and indirect effects mediated by longitudinal biomarkers. In this paper, we derive a closed-form sample size formula for testing the overall effect of a single nucleotide polymorphism within a joint modeling framework. Simulation studies demonstrate that the proposed formula yields accurate and robust performance in finite samples. We illustrate the practical utility of our method using data from the Diabetes Control and Complications Trial.",
      "authors": [
        "Yuan Bian",
        "Shelley B. Bull"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "stat.AP"
      ],
      "published": "2026-02-16 22:57:15+00:00",
      "link": "https://arxiv.org/pdf/2602.15247v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13630v1",
      "title": "Bistability to Quad-stability: Emergence of Hybrid Phenotypes & Enhanced Spatio-temporal Plasticity in Presence of Host-Circuit Coupling",
      "abstract": "In the context of multistability driven diseases, like cancer, spatiotemporal plasticity plays a significant role to achieve a spectrum of phenotypic variations. The interplay between gene regulatory networks and environmental factors, such as resource competition and spatial diffusion, plays a crucial role in determining cellular behaviour and phenotypic heterogeneity. Though reaction diffusion frameworks have been widely applied in developmental biology, less attention has been paid to the simultaneous effects of resource competition and growth feedback on spatial organization. In this paper, we observed that a bistable genetic circuit under high resource competition due to growth feedback gives rise to multiple emergent phenotypes, as observed in cancer systems. Furthermore, we observed how spatial diffusion coupled with intrinsic nonlinearity can drive the emergence of distinct spatial dynamics over time. The observed spatiotemporal plasticity can also be driven by the comparative stability of the fixed points, diffusivity, and asymmetry of diffusion. Our findings highlight that growth-induced resource competition combined with diffusion can provide deeper insights into metastasis and cancer progression.",
      "authors": [
        "Ranu Kundu",
        "Priya Chakraborty",
        "Sohini Guin",
        "Shyam Sundar Poriah",
        "Sayantari Ghosh"
      ],
      "primary_category": "q-bio.PE",
      "categories": [
        "q-bio.PE"
      ],
      "published": "2026-02-14 06:39:49+00:00",
      "link": "https://arxiv.org/pdf/2602.13630v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13121v1",
      "title": "LinkedNN: a neural model of linkage disequilibrium decay for recent effective population size inference",
      "abstract": "Summary: A bioinformatics tool is presented for estimating recent effective population size by using a neural network to automatically compute linkage disequilibrium-related features as a function of genomic distance between polymorphisms. The new method outperforms existing deep learning and summary statistic-based approaches using relatively few sequenced individuals and variant sites, making it particularly valuable for molecular ecology applications with sparse, unphased data. Availability and implementation: The program is available as an easily installable Python package with documentation here: https://pypi.org/project/linkedNN/. The open source code is available from: https://github.com/the-smith-lab/LinkedNN.",
      "authors": [
        "Chris C R Smith"
      ],
      "primary_category": "q-bio.PE",
      "categories": [
        "q-bio.PE",
        "q-bio.QM"
      ],
      "published": "2026-02-13 17:18:21+00:00",
      "link": "https://arxiv.org/pdf/2602.13121v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12310v1",
      "title": "ChemRecon: a Consolidated Meta-Database Platform for Biochemical Data Integration",
      "abstract": "In this paper, we present ChemRecon, a meta-database and Python interface for integrating and exploring biochemical data across multiple heterogeneous resources by consolidating compounds, reactions, enzymes, molecular structures, and atom-to-atom maps from several major databases into a single, consistent ontology. ChemRecon enables unified querying, cross-database analysis, and the construction of graph-based representations of sets of related database entries by the traversal of inter-database connections. This facilitates information extraction which is impossible within any single database, including deriving consensus information from conflicting sources, of which identifying the most probable molecular structure associated with a given compound is just one example. The Python interface is available via pip from the Python Package Index (https://pypi.org/project/chemrecon/). ChemRecon is open-source and the source code is hosted at GitLab (https://gitlab.com/casbjorn/chemrecon). Documentation and additional information is available at https://chemrecon.org.",
      "authors": [
        "Casper Asbjørn Eriksen",
        "Jakob Lykke Andersen",
        "Rolf Fagerberg",
        "Daniel Merkle"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM"
      ],
      "published": "2026-02-12 15:06:58+00:00",
      "link": "https://arxiv.org/pdf/2602.12310v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10644v1",
      "title": "Towards Universal Spatial Transcriptomics Super-Resolution: A Generalist Physically Consistent Flow Matching Framework",
      "abstract": "Spatial transcriptomics provides an unprecedented perspective for deciphering tissue spatial heterogeneity. However, high-resolution spatial transcriptomic technology remains constrained by limited gene coverage, technical complexity, and high cost. Existing spatial transcriptomics super-resolution methods from low resolution data suffer from two fundamental limitations: poor out-of-distribution generalization stemming from a neglect of inherent biological heterogeneity, and a lack of physical consistency. To address these challenges, we propose SRast, a novel physically constrained generalist framework designed for robust spatial transcriptomics super-resolution. To tackle heterogeneity, SRast employs a strategic decoupling architecture that explicitly decouples gene semantics representation from spatial geometry deconvolution, utilizing self-supervised learning to align latent distributions and mitigate cross-sample shifts. Regarding physical priors, SRast reformulates the task as ratio prediction on the simplex, performing a flow matching model to learn optimal transport-based geometric transformations that strictly enforce local mass conservation. Extensive experiments across diverse species, tissues, and platforms demonstrate that SRast achieves state-of-the-art performance, exhibiting superior zero-shot generalization capabilities and ensuring physical consistency in recovering fine-grained biological structures.",
      "authors": [
        "Xinlei Huang",
        "Weihao Dai",
        "Zijun Qin",
        "Xin Yu",
        "Di Wang",
        "Yanran Liu",
        "Lixin Cheng",
        "Xubin Zheng"
      ],
      "primary_category": "q-bio.BM",
      "categories": [
        "q-bio.BM"
      ],
      "published": "2026-02-11 08:44:40+00:00",
      "link": "https://arxiv.org/pdf/2602.10644v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09867v2",
      "title": "A dialog between cell adhesion and topology at the core of morphogenesis",
      "abstract": "During the development of an organism, cells must coordinate and organize to generate the correct shape, structure, and spatial patterns of tissues and organs, a process known as morphogenesis. The morphogenesis of embryonic tissues is supported by multiple processes that induce the precise physical deformations required for tissues to ultimately form organs with complex geometries. Among the most active players shaping the morphogenetic path are fine-tuned changes in cell adhesion. We review here recent advances showing that changes of a local, pair-wise property defined at the cell-cell contact level has important global consequences for embryonic tissue topology, being determinant in defining both the geometric and material properties of early embryo tissues.",
      "authors": [
        "Adrian Aguirre-Tamaral",
        "Elisa Floris",
        "Bernat Corominas-Murtra"
      ],
      "primary_category": "q-bio.TO",
      "categories": [
        "q-bio.TO",
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-10 15:10:15+00:00",
      "link": "https://arxiv.org/pdf/2602.09867v2",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16584v1",
      "title": "The Representational Alignment Hypothesis: Evidence for and Consequences of Invariant Semantic Structure Across Embedding Modalities",
      "abstract": "There is growing evidence that independently trained AI systems come to represent the world in the same way. In other words, independently trained embeddings from text, vision, audio, and neural signals share an underlying geometry. We call this the Representational Alignment Hypothesis (RAH) and investigate evidence for and consequences of this claim. The evidence is of two kinds: (i) internal structure comparison techniques, such as representational similarity analysis and topological data analysis, reveal matching relational patterns across modalities without explicit mapping; and (ii) methods based on cross-modal embedding alignment, which learn mappings between representation spaces, show that simple linear transformations can bring different embedding spaces into close correspondence, suggesting near-isomorphism. Taken together, the evidence suggests that, even after controlling for trivial commonalities inherent in standard data preprocessing and embedding procedures, a robust structural correspondence persists, hinting at an underlying organizational principle. Some have argued that this result shows that the shared structure is getting at a fundamental, Platonic level of reality. We argue that this conclusion is unjustified. Moreover, we aim to give the idea an alternative philosophical home, rooted in contemporary metasemantics (i.e., theories of what makes a representation and what makes something meaningful) and responses to the symbol grounding problem. We conclude by considering the scope of the RAH and proposing new ways of distinguishing semantic structures that are genuinely invariant from those that inevitably arise due to the fact that all our data is generated under human-specific conditions on Earth.",
      "authors": [
        "Akhil Ramidi",
        "Kevin Scharp"
      ],
      "primary_category": "q-bio.NC",
      "categories": [
        "q-bio.NC"
      ],
      "published": "2026-02-18 16:29:27+00:00",
      "link": "https://arxiv.org/pdf/2602.16584v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16504v1",
      "title": "GRIMM: Genetic stRatification for Inference in Molecular Modeling",
      "abstract": "The vast majority of biological sequences encode unknown functions and bear little resemblance to experimentally characterized proteins, limiting both our understanding of biology and our ability to harness functional potential for the bioeconomy. Predicting enzyme function from sequence remains a central challenge in computational biology, complicated by low sequence diversity and imbalanced label support in publicly available datasets. Models trained on these data can overestimate performance and fail to generalize. To address this, we introduce GRIMM (Genetic stRatification for Inference in Molecular Modeling), a benchmark for enzyme function prediction that employs genetic stratification: sequences are clustered by similarity and clusters are assigned exclusively to training, validation, or test sets. This ensures that sequences from the same cluster do not appear in multiple partitions. GRIMM produces multiple test sets: a closed-set test with the same label distribution as training (Test-1) and an open-set test containing novel labels (Test-2), serving as a realistic out-of-distribution proxy for discovering novel enzyme functions. While demonstrated on enzymes, this approach is generalizable to any sequence-based classification task where inputs can be clustered by similarity. By formalizing a splitting strategy often used implicitly, GRIMM provides a unified and reproducible framework for closed- and open-set evaluation. The method is lightweight, requiring only sequence clustering and label annotations, and can be adapted to different similarity thresholds, data scales, and biological tasks. GRIMM enables more realistic evaluation of functional prediction models on both familiar and unseen classes and establishes a benchmark that more faithfully assesses model performance and generalizability.",
      "authors": [
        "Ashley Babjac",
        "Adrienne Hoarfrost"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM"
      ],
      "published": "2026-02-18 14:46:18+00:00",
      "link": "https://arxiv.org/pdf/2602.16504v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12030v1",
      "title": "Time-Inhomogeneous Volatility Aversion for Financial Applications of Reinforcement Learning",
      "abstract": "In finance, sequential decision problems are often faced, for which reinforcement learning (RL) emerges as a promising tool for optimisation without the need of analytical tractability. However, the objective of classical RL is the expected cumulated reward, while financial applications typically require a trade-off between return and risk. In this work, we focus on settings where one cares about the time split of the total return, ruling out most risk-aware generalisations of RL which optimise a risk measure defined on the latter. We notice that a preference for homogeneous splits, which we found satisfactory for hedging, can be unfit for other problems, and therefore propose a new risk metric which still penalises uncertainty of the single rewards, but allows for an arbitrary planning of their target levels. We study the properties of the resulting objective and the generalisation of learning algorithms to optimise it. Finally, we show numerical results on toy examples.",
      "authors": [
        "Federico Cacciamani",
        "Roberto Daluiso",
        "Marco Pinciroli",
        "Michele Trapletti",
        "Edoardo Vittori"
      ],
      "primary_category": "q-fin.CP",
      "categories": [
        "q-fin.CP",
        "q-fin.TR"
      ],
      "published": "2026-02-12 15:00:28+00:00",
      "link": "https://arxiv.org/pdf/2602.12030v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10071v1",
      "title": "Deep Learning for Electricity Price Forecasting: A Review of Day-Ahead, Intraday, and Balancing Electricity Markets",
      "abstract": "Electricity price forecasting (EPF) plays a critical role in power system operation and market decision making. While existing review studies have provided valuable insights into forecasting horizons, market mechanisms, and evaluation practices, the rapid adoption of deep learning has introduced increasingly diverse model architectures, output structures, and training objectives that remain insufficiently analyzed in depth. This paper presents a structured review of deep learning methods for EPF in day-ahead, intraday, and balancing markets. Specifically, We introduce a unified taxonomy that decomposes deep learning models into backbone, head, and loss components, providing a consistent evaluation perspective across studies. Using this framework, we analyze recent trends in deep learning components across markets. Our study highlights the shift toward probabilistic, microstructure-centric, and market-aware designs. We further identify key gaps in the literature, including limited attention to intraday and balancing markets and the need for market-specific modeling strategies, thereby helping to consolidate and advance existing review studies.",
      "authors": [
        "Runyao Yu",
        "Derek W. Bunn",
        "Julia Lin",
        "Jochen Stiasny",
        "Fabian Leimgruber",
        "Tara Esterl",
        "Yuchen Tao",
        "Lianlian Qi",
        "Yujie Chen",
        "Wentao Wang",
        "Jochen L. Cremer"
      ],
      "primary_category": "q-fin.CP",
      "categories": [
        "q-fin.CP"
      ],
      "published": "2026-02-10 18:36:36+00:00",
      "link": "https://arxiv.org/pdf/2602.10071v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14709v1",
      "title": "Deep Image Prior for Computed Tomography Reconstruction",
      "abstract": "We present a comprehensive overview of the Deep Image Prior (DIP) framework and its applications to image reconstruction in computed tomography. Unlike conventional deep learning methods that rely on large, supervised datasets, the DIP exploits the implicit bias of convolutional neural networks and operates in a fully unsupervised setting, requiring only a single measurement, even in the presence of noise. We describe the standard DIP formulation, outline key algorithmic design choices, and review several strategies to mitigate overfitting, including early stopping, explicit regularisation, and self-guided methods that adapt the network input. In addition, we examine computational improvements such as warm-start and stochastic optimisation methods to reduce the reconstruction time. The discussed methods are tested on real $μ$CT measurements, which allows examination of trade-offs among the different modifications and extensions.",
      "authors": [
        "Simon Arridge",
        "Riccardo Barbano",
        "Alexander Denker",
        "Zeljko Kereta"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV"
      ],
      "published": "2026-02-16 12:56:55+00:00",
      "link": "https://arxiv.org/pdf/2602.14709v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14339v1",
      "title": "Data-Driven Network LQG Mean Field Games with Heterogeneous Populations via Integral Reinforcement Learning",
      "abstract": "This paper establishes a data-driven solution for infinite horizon linear quadratic Gaussian Mean Field Games with network-coupled heterogeneous agent populations where the dynamics of the agents are unknown. The solution technique relies on Integral Reinforcement Learning and Kleinman's iteration for solving algebraic Riccati equations (ARE). The resulting algorithm uses trajectory data to generate network-coupled MFG strategies for agents and does not require parameters of agents' dynamics. Under technical conditions on the persistency of excitation and on the existence of unique stabilizing solution to the corresponding AREs, the learned network-coupled MFG strategies are shown to converge to their true values.",
      "authors": [
        "Jean Zhu",
        "Shuang Gao"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-15 23:14:36+00:00",
      "link": "https://arxiv.org/pdf/2602.14339v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14191v1",
      "title": "Robust SAC-Enabled UAV-RIS Assisted Secure MISO Systems With Untrusted EH Receivers",
      "abstract": "This paper investigates secure downlink transmission in a UAV-assisted reconfigurable intelligent surface (RIS)-enabled multiuser multiple-input single-output network, where legitimate information-harvesting receivers coexist with untrusted energy-harvesting receivers (UEHRs) capable of eavesdropping. A UAV-mounted RIS provides blockage mitigation and passive beamforming, while the base station employs zero-forcing precoding for multiuser interference suppression. Due to limited feedback from UEHRs, their channel state information (CSI) is imperfect, leading to a worst-case secrecy energy efficiency (WCSEE) maximization problem. We jointly optimize the UAV horizontal position, RIS phase shifts, and transmit power allocation under both perfect and imperfect CSI, considering discrete RIS phases, UAV mobility, and energy-harvesting constraints. The resulting problem is highly nonconvex due to coupled channel geometry, robustness requirements, and discrete variables. To address this challenge, we propose a soft actor-critic (SAC)-based deep reinforcement learning framework that learns WCSEE-maximizing policies through interaction with the wireless environment. As a structured benchmark, a successive convex approximation (SCA) approach is developed for the perfect CSI case with continuous RIS phases. Simulation results show that the proposed SAC method achieves up to 28% and 16% secrecy energy efficiency gains over SCA and deep deterministic policy gradient baselines, respectively, while demonstrating superior robustness to CSI uncertainty and stable performance across varying transmit power levels and RIS sizes.",
      "authors": [
        "Hamid Reza Hashempour",
        "Le-Nam Tran",
        "Duy H. N. Nguyen",
        "Hien Quoc Ngo"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-15 15:37:10+00:00",
      "link": "https://arxiv.org/pdf/2602.14191v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14094v1",
      "title": "Wireless Physical Neural Networks (WPNNs): Opportunities and Challenges",
      "abstract": "Wireless communication systems exhibit structural and functional similarities to neural networks: signals propagate through cascaded elements, interact with the environment, and undergo transformations. Building upon this perspective, we introduce a unified paradigm, termed \\textit{wireless physical neural networks (WPNNs)}, in which components of a wireless network, such as transceivers, relays, backscatter, and intelligent surfaces, are interpreted as computational layers within a learning architecture. By treating the wireless propagation environment and network elements as differentiable operators, new opportunities arise for joint communication-computation designs, where system optimization can be achieved through learning-based methods applied directly to the physical network. This approach may operate independently of, or in conjunction with, conventional digital neural layers, enabling hybrid communication learning pipelines. In the article, we outline representative architectures that embody this viewpoint and discuss the algorithmic and training considerations required to leverage the wireless medium as a computational resource. Through numerical examples, we highlight the potential performance gains in processing, adaptability, efficiency, and end-to-end optimization, demonstrating the promise of reconfiguring wireless systems as learning networks in next-generation communication frameworks.",
      "authors": [
        "Meng Hua",
        "Itsik Bergel",
        "Tolga Girici",
        "Marco Di Renzo",
        "Deniz Gunduz"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-15 10:58:44+00:00",
      "link": "https://arxiv.org/pdf/2602.14094v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14018v1",
      "title": "Extended Universal Joint Source-Channel Coding for Digital Semantic Communications: Improving Channel-Adaptability",
      "abstract": "Recent advances in deep learning (DL)-based joint source-channel coding (JSCC) have enabled efficient semantic communication in dynamic wireless environments. Among these approaches, vector quantization (VQ)-based JSCC effectively maps high-dimensional semantic feature vectors into compact codeword indices for digital modulation. However, existing methods, including universal JSCC (uJSCC), rely on fixed, modulation-specific encoders, decoders, and codebooks, limiting adaptability to fine-grained SNR variations. We propose an extended universal JSCC (euJSCC) framework that achieves SNR- and modulation-adaptive transmission within a single model. euJSCC employs a hypernetwork-based normalization layer for fine-grained feature vector normalization and a dynamic codebook generation (DCG) network that refines modulation-specific base codebooks according to block-wise SNR. To handle block fading channels, which consist of multiple coherence blocks, an inner-outer encoder-decoder architecture is adopted, where the outer encoder and decoder capture long-term channel statistics, and the inner encoder and decoder refine feature vectors to align with block-wise codebooks. A two-phase training strategy, i.e., pretraining on AWGN channels followed by finetuning on block fading channels, ensures stable convergence. Experiments on image transmission demonstrate that euJSCC consistently outperforms state-of-the-art channel-adaptive digital JSCC schemes under both block fading and AWGN channels.",
      "authors": [
        "Eunsoo Kim",
        "Yoon Huh",
        "Wan Choi"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-15 06:46:29+00:00",
      "link": "https://arxiv.org/pdf/2602.14018v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13896v1",
      "title": "Probabilistic Reachability Analysis of Multi-scale Voltage Dynamics Using Reinforcement Learning",
      "abstract": "Voltage stability in modern power systems involves coupled dynamics across multiple time scales. Conventional methods based on time-scale separation or static stability margins may overlook instabilities caused by the coupling of slow and fast transients. Uncertainty in operating conditions further complicates stability assessment, and high computational cost of Monte Carlo simulations limit its applicability to multi-scale dynamics. This paper presents a deep reinforcement learning-based framework for probabilistic reachability analysis of multi-scale voltage dynamics. By formulating each instability mechanism as a distinct absorbing state and introducing a multi-critic architecture for mechanism-specific learning, the proposed method enables consistent learning of risk probabilities associated with multiple instability types within a unified framework. The approach is demonstrated on a four-bus system with load tap changers and over-excitation limiters, illustrating effectiveness of the proposed learning-based reachability analysis in identifying and quantifying the mechanisms leading to voltage collapse.",
      "authors": [
        "Naoki Hashima",
        "Hikaru Hoshino",
        "Luis David Pabón Ospina",
        "Eiko Furutani"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-14 21:36:33+00:00",
      "link": "https://arxiv.org/pdf/2602.13896v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13814v1",
      "title": "A Deep Convolutional Network to Extract Real-Time Landmarks for UAV Navigation",
      "abstract": "Recent advances in satellite and communication technologies have significantly improved geographical information and monitoring systems. Global System for Mobile Communications (GSM) and Global Navigation Satellite System (GNSS) technologies, which rely on electromagnetic signals transmitted from satellites and base stations, have long been utilized for geolocation applications. However, signal attenuation due to environmental conditions or intentional interference such as jamming may lead to severe degradation or complete loss of positioning capability. In such GNSS-denied environments, landmark extraction becomes critical for the navigation of unmanned aerial vehicles (UAVs) used in monitoring applications. By processing images captured from onboard UAV cameras, reliable visual landmarks can be identified to enable navigation without GNSS support. In this study, a convolution-based deep learning approach is proposed for the extraction of appropriate landmarks, and its effectiveness is examined.",
      "authors": [
        "Osman Tokluoglu",
        "Mustafa Ozturk"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "eess.SP"
      ],
      "published": "2026-02-14 15:09:55+00:00",
      "link": "https://arxiv.org/pdf/2602.13814v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13520v2",
      "title": "Sub Specie Aeternitatis: Fourier Transforms from the Theory of Heat to Musical Signals",
      "abstract": "J. B. Fourier in his \\emph{Théorie Analytique de la Chaleur} of 1822 introduced, amongst other things, two ideas that have made a fundamental impact in fields as diverse as Mathematical Physics, Electrical Engineering, Computer Science, and Music. The first one of these, a method to find the coefficients for a trigonometric series describing an arbitrary function, was very early on picked up by G. Ohm and H. Helmholtz as the foundation for a theory of \\emph{musical tones}. The second one, which is described by Fourier's double integral, became the basis for treating certain kinds of infinity in discontinuous functions, as shown by A. De Morgan in his 1842 \\emph{The Differential and Integral Calculus}. Both make up the fundamental basis for what is now commonly known as the \\emph{Fourier theorem}. With the help of P. A. M. Dirac's insights into the nature of these infinities, we can have a compact description of the frequency spectrum of a function of time, or conversely of a waveform corresponding to a given function of frequency. This paper, using solely primary sources, takes us from the physics of heat propagation to the modern theory of musical signals. It concludes with some considerations on the inherent duality of time and frequency emerging from Fourier's theorem.",
      "authors": [
        "Victor Lazzarini"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "physics.hist-ph"
      ],
      "published": "2026-02-13 23:18:28+00:00",
      "link": "https://arxiv.org/pdf/2602.13520v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13447v1",
      "title": "Sample-level EEG-based Selective Auditory Attention Decoding with Markov Switching Models",
      "abstract": "Selective auditory attention decoding aims to identify the speaker of interest from listeners' neural signals, such as electroencephalography (EEG), in the presence of multiple concurrent speakers. Most existing methods operate at the window level, facing a trade-off between temporal resolution and decoding accuracy. Recent work has shown that hidden Markov model (HMM)-based post-processing can smooth window-level decoder outputs to improve this trade-off. Instead of using a separate smoothing step, we propose to integrate the decoding and smoothing components into a single probabilistic framework using a Markov switching model (MSM). It directly models the relationship between the EEG and speech envelopes under each attention state while incorporating the temporal dynamics of attention. This formulation enables sample-level attention decoding, with model parameters and attention states jointly estimated via the expectation-maximization algorithm. Experimental results demonstrate that this integrated MSM formulation achieves comparable decoding accuracy to HMM post-processing while providing faster attention switch detection. The code for the proposed method is available at https://github.com/YYao-42/MSM.",
      "authors": [
        "Yuanyuan Yao",
        "Simon Geirnaert",
        "Tinne Tuytelaars",
        "Alexander Bertrand"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-13 20:50:13+00:00",
      "link": "https://arxiv.org/pdf/2602.13447v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13108v1",
      "title": "Encoder initialisation methods in the model augmentation setting",
      "abstract": "Nonlinear system identification (NL-SI) has proven to be effective in obtaining accurate models for highly complex systems. Recent encoder-based methods for artificial neural network state-space (ANN-SS) models have shown state-of-the-art performance with improved computational efficiency, where the encoder is used to estimate the initial state allowing for batch optimisation methods. To address the lack of interpretability of these black-box ANN models, model augmentation approaches can be used. These combine prior available baseline models with the ANN learning components, resulting in faster convergence and more interpretable models. The combination of the encoder-based method with model augmentation has shown potential. Thus far, however, the encoder has still been treated as a black-box function in the overall estimation process, while additional information in the form of the baseline model is available to predict the model state from past input-output data. In this paper, we propose novel encoder initialisation approaches based on the available baseline model, resulting in improved noise robustness and faster convergence compared to black-box initialisation. The performance of these initialisation methods is demonstrated on a mass-spring-damper system.",
      "authors": [
        "J. H. Hoekstra",
        "B. Györök",
        "R. Töth",
        "M. Schoukens"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-13 17:10:26+00:00",
      "link": "https://arxiv.org/pdf/2602.13108v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13043v1",
      "title": "Efficient Plug-and-Play method for Dynamic Imaging Via Kalman Smoothing",
      "abstract": "State-space models (SSM) are common in signal processing, where Kalman smoothing (KS) methods are state-of-the-art. However, traditional KS techniques lack expressivity as they do not incorporate spatial prior information. Recently, [1] proposed an ADMM algorithm that handles the state-space fidelity term with KS while regularizing the object via a sparsity-based prior with proximity operators. Plug-and-Play (PnP) methods are a popular type of iterative algorithms that replace proximal operators encoding prior knowledge with powerful denoisers such as deep neural networks. These methods are widely used in image processing, achieving state-of-the-art results. In this work, we build on the KS-ADMM method, combining it with deep learning to achieve higher expressivity. We propose a PnP algorithm based on KS-ADMM iterations, efficiently handling the SSM through KS, while enabling the use of powerful denoising networks. Simulations on a 2D+t imaging problem show that the proposed PnP-KS-ADMM algorithm improves the computational efficiency over standard PnP-ADMM for large numbers of timesteps.",
      "authors": [
        "Benjamin Hawkes",
        "Mike Davies",
        "Victor Elvira",
        "Audrey Repetti"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV"
      ],
      "published": "2026-02-13 15:54:15+00:00",
      "link": "https://arxiv.org/pdf/2602.13043v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12954v1",
      "title": "Data Augmentation and Attention for massive MIMO-based Indoor Localization in Changing Environments",
      "abstract": "The demand for high-precision indoor localization has grown significantly with the rise of smart environments, industrial automation, and location-aware applications. While massive Multiple-Input and Multiple-Output (MIMO) systems enable millimeter-level accuracy by leveraging rich Channel State Information (CSI), most existing solutions are optimized for static environments, where users or devices remain fixed during data collection and inference. Real-world applications, however, often require real-time localization in changing environments, where rapid movement, unpredictable blockages, and dynamic channel conditions pose significant challenges. To address these challenges, we introduce two data augmentation techniques designed to resemble blocked antennas, enhancing the generalizability of localization models to dynamic scenarios. Additionally, we enhance an existing Deep Learning (DL) model by incorporating attention modules, improving its ability to focus on relevant channel features and antennas. We train our model on data from a static scenario, augmented with the proposed techniques, and evaluate it on a dataset collected in changing scenarios. We investigate the performance enhancements achieved by the data augmentation techniques and the Attention modules, and observe a localization accuracy improvement from a mean error of 286 mm, when trained without Attention and without data augmentations, to 66 mm, when trained with Attention and data augmentation. This shows that high localization accuracy can be maintained in changing environments, even without training data from those scenarios.",
      "authors": [
        "Luisa Schuhmacher",
        "Hazem Sallouha",
        "Ihsane Gryech",
        "Sofie Pollin"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-13 14:18:30+00:00",
      "link": "https://arxiv.org/pdf/2602.12954v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12757v1",
      "title": "Flexible RISs: Learning-based Array Manifold Estimation and Phase-shift Optimization",
      "abstract": "Reconfigurable intelligent surfaces (RISs) are envisioned as a key enabler for next-generation wireless networks, offering programmable control over propagation environments. While extensive research focuses on planar RIS architectures, practical deployments often involve non-planar surfaces, such as structural columns or curved facades, where standard planar beamforming models fail. Moreover, existing analytical solutions for curved RISs are often restricted to specific, pre-defined array manifold geometries. To address this limitation, this paper proposes a novel deep learning (DL) framework for optimizing the phase shifts of non-planar RISs. We first introduce a low-dimensional parametric model to capture arbitrary surface curvature effectively. Based on this, we design a neural network (NN) that utilizes a sparse set of received power measurements to estimate the surface geometry and derive the optimal phase configuration. Simulation results demonstrate that the proposed algorithm converges fast and significantly outperforms conventional planar beamforming designs, validating its robustness against arbitrary surface curvature. We also analyze the impact of the measurement location error on the algorithm's performance.",
      "authors": [
        "Mohamadreza Delbari",
        "Ehsan Mohammadi",
        "Mostafa Darabi",
        "Arash Asadi",
        "Alejandro Jiménez-Sáez",
        "Vahid Jamali"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-13 09:36:05+00:00",
      "link": "https://arxiv.org/pdf/2602.12757v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11701v1",
      "title": "BSoNet: Deep Learning Solution for Optimizing Image Quality of Portable Backscatter Imaging Systems",
      "abstract": "Portable backscatter imaging systems (PBI) integrate an X-ray source and detector in a single unit, utilizing Compton scattering photons to rapidly acquire superficial or shallow structural information of an inspected object through single-sided imaging. The application of this technology overcomes the limitations of traditional transmission X-ray detection, offering greater flexibility and portability, making it the preferred tool for the rapid and accurate identification of potential threats in scenarios such as borders, ports, and industrial nondestructive security inspections. However, the image quality is significantly compromised due to the limited number of Compton backscattered photons. The insufficient photon counts result primarily from photon absorption in materials, the pencil-beam scanning design, and short signal sampling times. It therefore yields severe image noise and an extremely low signal-to-noise ratio, greatly reducing the accuracy and reliability of PBI systems. To address these challenges, this paper introduces BSoNet, a novel deep learning-based approach specifically designed to optimize the image quality of PBI systems. The approach significantly enhances image clarity, recognition, and contrast while meeting practical application requirements. It transforms PBI systems into more effective and reliable inspection tools, contributing significantly to strengthening security protection.",
      "authors": [
        "Linxuan Li",
        "Wenjia Wei",
        "Yunfei Lu",
        "Wenwen Zhang",
        "Yanlong Zhang",
        "Wei Zhao"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "physics.med-ph"
      ],
      "published": "2026-02-12 08:29:08+00:00",
      "link": "https://arxiv.org/pdf/2602.11701v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11670v1",
      "title": "Exploring Frequency-Domain Feature Modeling for HRTF Magnitude Upsampling",
      "abstract": "Accurate upsampling of Head-Related Transfer Functions (HRTFs) from sparse measurements is crucial for personalized spatial audio rendering. Traditional interpolation methods, such as kernel-based weighting or basis function expansions, rely on measurements from a single subject and are limited by the spatial sampling theorem, resulting in significant performance degradation under sparse sampling. Recent learning-based methods alleviate this limitation by leveraging cross-subject information, yet most existing neural architectures primarily focus on modeling spatial relationships across directions, while spectral dependencies along the frequency dimension are often modeled implicitly or treated independently. However, HRTF magnitude responses exhibit strong local continuity and long-range structure in the frequency domain, which are not fully exploited. This work investigates frequency-domain feature modeling by examining how different architectural choices, ranging from per-frequency multilayer perceptrons to convolutional, dilated convolutional, and attention-based models, affect performance under varying sparsity levels, showing that explicit spectral modeling consistently improves reconstruction accuracy, particularly under severe sparsity. Motivated by this observation, a frequency-domain Conformer-based architecture is adopted to jointly capture local spectral continuity and long-range frequency correlations. Experimental results on the SONICOM and HUTUBS datasets demonstrate that the proposed method achieves state-of-the-art performance in terms of interaural level difference and log-spectral distortion.",
      "authors": [
        "Xingyu Chen",
        "Hanwen Bi",
        "Fei Ma",
        "Sipei Zhao",
        "Eva Cheng",
        "Ian S. Burnett"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS"
      ],
      "published": "2026-02-12 07:43:26+00:00",
      "link": "https://arxiv.org/pdf/2602.11670v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11463v1",
      "title": "Estimation of Electrical Characteristics of Complex Walls Using Deep Neural Networks",
      "abstract": "Electromagnetic wave propagation through complex inhomogeneous walls introduces significant distortions to through-wall radar signatures. Estimation of wall thickness, dielectric, and conductivity profiles may enable wall effects to be deconvolved from target scattering. We propose to use deep neural networks (DNNs) to estimate wall characteristics from broadband scattered electric fields on the same side of the wall as the transmitter. We demonstrate that both single deep artificial and convolutional neural networks and dual networks involving generative adversarial networks are capable of performing the highly nonlinear regression operation of electromagnetic inverse scattering for wall characterization. These networks are trained with simulation data generated from full wave solvers and validated on both simulated and real wall data with approximately 95% accuracy.",
      "authors": [
        "Kainat Yasmeen",
        "Shobha Sundar Ram"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-12 00:39:23+00:00",
      "link": "https://arxiv.org/pdf/2602.11463v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11373v1",
      "title": "A Unified Estimation--Guidance Framework Based on Bayesian Decision Theory",
      "abstract": "Using Bayesian decision theory, we modify the perfect-information, differential game-based guidance law (DGL1) to address the inevitable estimation error occurring when driving this guidance law with a separately-designed state estimator. This yields a stochastic guidance law complying with the generalized separation theorem, as opposed to the common approach, that implicitly, but unjustifiably, assumes the validity of the regular separation theorem. The required posterior probability density function of the game's state is derived from the available noisy measurements using an interacting multiple model particle filter. When the resulting optimal decision turns out to be nonunique, this feature is harnessed to appropriately shape the trajectory of the pursuer so as to enhance its estimator's performance. In addition, certain properties of the particle-based computation of the Bayesian cost are exploited to render the algorithm amenable to real-time implementation. The performance of the entire estimation-decision-guidance scheme is demonstrated using an extensive Monte Carlo simulation study.",
      "authors": [
        "Liraz Mudrik",
        "Yaakov Oshman"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-11 21:04:07+00:00",
      "link": "https://arxiv.org/pdf/2602.11373v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11077v1",
      "title": "Credit-Based vs. Discount-Based Congestion Pricing: A Comparison Study",
      "abstract": "Credit-based congestion pricing (CBCP) and discount-based congestion pricing (DBCP), which respectively allot travel credits and toll discounts to subsidize low-income users' access to tolled roads, have emerged as promising policies for alleviating the societal inequity concerns of congestion pricing. However, since real-world implementations of CBCP and DBCP are nascent, their relative merits remain unclear. In this work, we compare the efficacy of deploying CBCP and DBCP in reducing user costs and increasing toll revenues. We first formulate a non-atomic congestion game in which low-income users receive a travel credit or toll discount for accessing tolled lanes. We establish that, in our formulation, Nash equilibrium flows always exist and can be computed or well approximated via convex programming. Our main result establishes a set of practically relevant conditions under which DBCP provably outperforms CBCP in inducing equilibrium outcomes that minimize a given societal cost, which encodes user cost reduction and toll revenue maximization. Finally, we validate our theoretical contributions via a case study of the 101 Express Lanes Project, a CBCP program implemented in the San Francisco Bay Area.",
      "authors": [
        "Chih-Yuan Chiu",
        "Devansh Jalota",
        "Marco Pavone"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-11 17:44:52+00:00",
      "link": "https://arxiv.org/pdf/2602.11077v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11063v2",
      "title": "Deep Neural Network-Enhanced Frequency-Constrained Optimal Power Flow with Multi-Governor Dynamics",
      "abstract": "To ensure frequency security in power systems, both the rate of change of frequency (RoCoF) and the frequency nadir (FN) must be explicitly accounted for in real-time frequency-constrained optimal power flow (FCOPF). However, accurately modeling sys-tem frequency dynamics through analytical formulations is chal-lenging due to their inherent nonlinearity and complexity. To address this issue, deep neural networks (DNNs) are utilized to capture the nonlinear mapping between system operating condi-tions and key frequency performance metrics. In this paper, a DNN-based frequency prediction model is developed and trained using the high-fidelity time-domain simulation data generated in PSCAD/EMTDC. The trained DNN is subsequently transformed into an equivalent mixed-integer linear programming (MILP) form and embedded into the FCOPF problem as additional con-straints to explicitly enforce frequency security, leading to the proposed DNN-FCOPF formulation. For benchmarking, two alternative models are considered: a conventional optimal power flow without frequency constraints and a linearized FCOPF in-corporating system-level RoCoF and FN constraints. The effec-tiveness of the proposed method is demonstrated by comparing the solutions of these three models through extensive PSCAD/EMTDC time-domain simulations under various loading scenarios.",
      "authors": [
        "Fan Jiang",
        "Xingpeng Li",
        "Pascal Van Hentenryck"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-11 17:32:07+00:00",
      "link": "https://arxiv.org/pdf/2602.11063v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10736v1",
      "title": "Transfer to Sky: Unveil Low-Altitude Route-Level Radio Maps via Ground Crowdsourced Data",
      "abstract": "The expansion of the low-altitude economy is contingent on reliable cellular connectivity for unmanned aerial vehicles (UAVs). A key challenge in pre-flight planning is predicting communication link quality along proposed and pre-defined routes, a task hampered by sparse measurements that render existing radio map methods ineffective. This paper introduces a transfer learning framework for high-fidelity route-level radio map prediction. Our key insight is to leverage abundant crowdsourced ground signals as auxiliary supervision. To bridge the significant domain gap between ground and aerial data and address spatial sparsity, our framework learns general propagation priors from simulation, performs adversarial alignment of the feature spaces, and is fine-tuned on limited real UAV measurements. Extensive experiments on a real-world dataset from Meituan show that our method achieves over 50% higher accuracy in predicting Route RSRP compared to state-of-the-art baselines.",
      "authors": [
        "Wenlihan Lu",
        "Huacong Chen",
        "Ruiyang Duan",
        "Weijie Yuan",
        "Shijian Gao"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-11 10:56:40+00:00",
      "link": "https://arxiv.org/pdf/2602.10736v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10397v1",
      "title": "Resilient Voltage Estimation for Battery Packs Using Self-Learning Koopman Operator",
      "abstract": "Cloud-based battery management systems (BMSs) rely on real-time voltage measurement data to ensure coordinated bi-directional charging of electric vehicles (EVs) with vehicle-to-grid technology. Unfortunately, an adversary can corrupt the measurement data during transmission from the local-BMS to the cloud-BMS, leading to disrupted EV charging. Therefore, to ensure reliable voltage data under such sensor attacks, this paper proposes a two-stage error-corrected self-learning Koopman operator-based secure voltage estimation scheme for large-format battery packs. The first stage of correction compensates for the Koopman approximation error. The second stage aims to recover the error amassing from the lack of higher-order battery dynamics information in the self-learning feedback, using two alternative methods: an adaptable empirical strategy that uses cell-level knowledge of open circuit voltage to state-of-charge mapping for pack-level estimation, and a Gaussian process regression-based data-driven method that leverages minimal data-training. During our comprehensive case studies using the high-fidelity battery simulation package 'PyBaMM-liionpack', our proposed secure estimator reliably generated real-time voltage estimation with high accuracy under varying pack topologies, charging settings, battery age-levels, and attack policies. Thus, the scalable and adaptable algorithm can be easily employed to diverse battery configurations and operating conditions, without requiring significant modifications, excessive data or sensor redundancy, to ensure optimum charging of EVs under compromised sensing.",
      "authors": [
        "Sanchita Ghosh",
        "Tanushree Roy"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-11 00:53:48+00:00",
      "link": "https://arxiv.org/pdf/2602.10397v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10355v1",
      "title": "Efficient Policy Adaptation for Voltage Control Under Unknown Topology Changes",
      "abstract": "Reinforcement learning (RL) has shown great potential for designing voltage control policies, but their performance often degrades under changing system conditions such as topology reconfigurations and load variations. We introduce a topology-aware online policy optimization framework that leverages data-driven estimation of voltage-reactive power sensitivities to achieve efficient policy adaptation. Exploiting the sparsity of topology-switching events, where only a few lines change at a time, our method efficiently detects topology changes and identifies the affected lines and parameters, enabling fast and accurate sensitivity updates without recomputing the full sensitivity matrix. The estimated sensitivity is subsequently used for online policy optimization of a pre-trained neural-network-based RL controller. Simulations on both the IEEE 13-bus and SCE 56-bus systems demonstrate over 90 percent line identification accuracy, using only 15 data points. The proposed method also significantly improves voltage regulation performance compared with non-adaptive policies and adaptive policies that rely on regression-based online optimization methods for sensitivity estimation.",
      "authors": [
        "Jie Feng",
        "Yuanyuan Shi",
        "Deepjyoti Deka"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-10 23:04:45+00:00",
      "link": "https://arxiv.org/pdf/2602.10355v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09695v1",
      "title": "Robust Macroscopic Density Control of Heterogeneous Multi-Agent Systems",
      "abstract": "Modern applications, such as orchestrating the collective behavior of robotic swarms or traffic flows, require the coordination of large groups of agents evolving in unstructured environments, where disturbances and unmodeled dynamics are unavoidable. In this work, we develop a scalable macroscopic density control framework in which a feedback law is designed directly at the level of an advection--diffusion partial differential equation. We formulate the control problem in the density space and prove global exponential convergence towards the desired behavior in $\\mathcal{L}^2$ with guaranteed asymptotic rejection of bounded unknown drift terms, explicitly accounting for heterogeneous agent dynamics, unmodeled behaviors, and environmental perturbations. Our theoretical findings are corroborated by numerical experiments spanning heterogeneous oscillators, traffic systems, and swarm robotics in partially unknown environments.",
      "authors": [
        "Gian Carlo Maffettone",
        "Davide Salzano",
        "Mario di Bernardo"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-10 11:50:34+00:00",
      "link": "https://arxiv.org/pdf/2602.09695v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09685v1",
      "title": "Generalizable and Robust Beam Prediction for 6G Networks: An Deep-Learning Framework with Positioning Feature Fusion",
      "abstract": "Beamforming (BF) is essential for enhancing system capacity in fifth generation (5G) and beyond wireless networks, yet exhaustive beam training in ultra-massive multiple-input multiple-output (MIMO) systems incurs substantial overhead. To address this challenge, we propose a deep learning based framework that leverages position-aware features to improve beam prediction accuracy while reducing training costs. The proposed approach uses spatial coordinate labels to supervise a position extraction branch and integrates the resulting representations with beam-domain features through a feature fusion module. A dual-branch RegNet architecture is adopted to jointly learn location related and communication features for beam prediction. Two fusion strategies, namely adaptive fusion and adversarial fusion, are introduced to enable efficient feature integration. The proposed framework is evaluated on datasets generated by the DeepMIMO simulator across four urban scenarios at 3.5 GHz following 3GPP specifications, where both reference signal received power and user equipment location information are available. Simulation results under both in-distribution and out-of-distribution settings demonstrate that the proposed approach consistently outperforms traditional baselines and achieves more accurate and robust beam prediction by effectively incorporating positioning information.",
      "authors": [
        "Yanliang Jin",
        "Yunfan Li",
        "Jiang Jun",
        "Yuan Gao",
        "Shengli Liu",
        "Jianbo Du",
        "Zhaohui Yang",
        "Shugong Xu"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-10 11:39:43+00:00",
      "link": "https://arxiv.org/pdf/2602.09685v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09615v1",
      "title": "Collaborative Spectrum Sensing in Cognitive and Intelligent Wireless Networks: An Artificial Intelligence Perspective",
      "abstract": "Artificial intelligence (AI) has become a key enabler for next-generation wireless communication systems, offering powerful tools to cope with the increasing complexity, dynamics, and heterogeneity of modern wireless environments. To illustrate the role and impact of AI in wireless communications, this paper takes collaborative spectrum sensing (CSS) in cognitive and intelligent wireless networks as a representative application and surveys recent advances from an AI perspective. We first introduce the fundamentals of CSS, including the general framework, classical detector design, and fusion strategies. Then, we present an overview of the state-of-the-art research on AI-driven CSS, classified into three categories: discriminative deep learning (DL) models, generative DL models, and deep reinforcement learning (DRL). Furthermore, we explore semantic communication (SemCom) as a promising solution for CSS, in which task-oriented representations are exchanged to reduce reporting overhead while preserving decision-critical information. Finally, we discuss limitations, open challenges, and future research directions at the intersection of AI and wireless communication.",
      "authors": [
        "Peng Yi",
        "Ying-Chang Liang"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-10 10:04:37+00:00",
      "link": "https://arxiv.org/pdf/2602.09615v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09589v1",
      "title": "A Survey on STAR-RIS Enabled Joint Communications and Sensing: Fundamentals, Recent Advances and Research Challenges",
      "abstract": "The joint communications and sensing (JCAS) paradigm is envisioned as a core capability of sixth-generation (6G) wireless networks, enabling the integration of data communication and environmental sensing within a unified system. By reusing spectrum, waveforms, and hardware resources, JCAS improves spectral efficiency, reduces system complexity, and hardware cost, while enabling new use cases. Nevertheless, the realization of JCAS is hindered by inherent trade-offs between communication and sensing objectives, limited controllability of wireless propagation, and stringent hardware and design constraints. Simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS) have recently emerged as a promising technology to address these challenges by enabling full-space programmable manipulation of electromagnetic waves. This survey provides a systematic and in-depth review of STAR-RIS-enabled JCAS systems. Specifically, we first introduce the fundamental principles of JCAS and STAR-RIS. We then classify and review the state-of-the-art research on STAR-RIS-assisted JCAS from multiple perspectives, encompassing system architectures, waveform and beamforming design, resource allocation, optimization frameworks, and learning-based control. Finally, we identify key open challenges that remain unsolved and outline promising future research directions toward intelligent, flexible, and perceptive 6G wireless networks.",
      "authors": [
        "Wali Ullah Khan",
        "Chandan Kumar Sheemar",
        "Syed Tariq Shah",
        "Manzoor Ahmed",
        "Symeon Chatzinotas"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-10 09:42:41+00:00",
      "link": "https://arxiv.org/pdf/2602.09589v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09536v1",
      "title": "UAV-Assisted 6G Communication Networks for Railways: Technologies, Applications, and Challenges",
      "abstract": "Unmanned Aerial Vehicles (UAVs) are crucial for advancing railway communication by offering reliable connectivity, adaptive coverage, and mobile edge services . This survey examines UAV-assisted approaches for 6G railway needs including ultra-reliable low-latency communication (URLLC) and integrated sensing and communication (ISAC). We cover railway channel models, reconfigurable intelligent surfaces (RIS), and UAV-assisted mobile edge computing (MEC). Key challenges include coexistence with existing systems, handover management, Doppler effect, and security. The roadmap suggests work on integrated communication-control systems and AI-driven optimization for intelligent railway networks.",
      "authors": [
        "Aamer Mohamed Huroon",
        "Li-Chun Wang"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-10 08:48:11+00:00",
      "link": "https://arxiv.org/pdf/2602.09536v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09419v1",
      "title": "When Movable Antennas Meet RSMA and RIS: Robust Beamforming Design With Channel Uncertainty",
      "abstract": "In this work, we propose an intelligent optimization framework for a multi-user communication system integrating movable antennas (MAs) and a reconfigurable intelligent surface (RIS) under the rate-splitting multiple access (RSMA) protocol. The system sum-rate is maximized through joint optimization of transmit precoding vectors, RIS reflection matrix, common-rate allocation, and MA positions, subject to quality-of-service (QoS), power-budget, common-rate decoding, and mutual coupling constraints. Imperfect channel state information (CSI) is considered for all links, where robustness is ensured by modeling channel estimation errors within a bounded uncertainty region, guaranteeing worst-case performance reliability. The resulting non-convex problem is solved using an alternating optimization framework. The precoding subproblem is reformulated as a semidefinite programming (SDP) problem via linear matrix inequalities derived using the S-procedure. The RIS reflection matrix is optimized using successive convex approximation (SCA), yielding an equivalent SDP formulation. The MA position optimization is addressed through SCA combined with block coordinate descent (BCD) method. Numerical results validate the effectiveness of the proposed framework and demonstrate fast convergence.",
      "authors": [
        "Muhammad Asif",
        "Asim Ihsan",
        "Zhongliang Wang",
        "Manzoor Ahmed",
        "Xingwang Li",
        "Arumugam Nallanathan",
        "Symeon Chatzinotas"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-10 05:24:34+00:00",
      "link": "https://arxiv.org/pdf/2602.09419v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09157v1",
      "title": "Foundation Model-Aided Hierarchical Deep Reinforcement Learning for Blockage-Aware Link in RIS-Assisted Networks",
      "abstract": "Reconfigurable intelligent surface (RIS) technology has the potential to significantly enhance the spectral efficiency (SE) of 6G wireless networks. However, practical deployment remains constrained by challenges in accurate channel estimation and control optimization under dynamic conditions. This paper presents a foundation model-aided hierarchical deep reinforcement learning (FM-HDRL) framework designed for joint beamforming and phase-shift optimization in RIS-assisted wireless networks. To implement this, we first fine-tune a pre-trained large wireless model (LWM) to translate raw channel data into low-dimensional, context-aware channel state information (CSI) embeddings. Next, these embeddings are combined with user location information and blockage status to select the optimal communication path. The resulting features are then fed into an HDRL model, assumed to be implemented at a centralized controller, which jointly optimizes the base station (BS) beamforming vectors and the RIS phase-shift configurations to maximize SE. Simulation results demonstrate that the proposed FM-HDRL framework consistently outperforms baseline methods in terms of convergence speed, spectral efficiency, and scalability. According to the simulation results, our proposed method improves 7.82% SE compared to the FM-aided deep reinforcement learning (FM-DRL) approach and a substantial enhancement of about 48.66% relative to the beam sweeping approach.",
      "authors": [
        "Mohammad Ghassemi",
        "Han Zhang",
        "Ali Afana",
        "Akram Bin Sediq",
        "Melike Erol-Kantarci"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-09 20:01:38+00:00",
      "link": "https://arxiv.org/pdf/2602.09157v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.08977v1",
      "title": "Contraction Metric Based Safe Reinforcement Learning Force Control for a Hydraulic Actuator with Real-World Training",
      "abstract": "Force control in hydraulic actuators is notoriously difficult due to strong nonlinearities, uncertainties, and the high risks associated with unsafe exploration during learning. This paper investigates safe reinforcement learning (RL) for hy draulic force control with real-world training using contraction metric certificates. A data-driven model of a hydraulic actuator, identified from experimental data, is employed for simulation based pretraining of a Soft Actor-Critic (SAC) policy that adapts the PI gains of a feedback-linearization (FL) controller. To reduce instability during online training, we propose a quadratic-programming (QP) contraction filter that leverages a learned contraction metric to enforce approximate exponential convergence of trajectories, applying minimal corrections to the policy output. The approach is validated on a hydraulic test bench, where the RL controller is trained directly on hardware and benchmarked against a simulation-trained agent and a fixed-gain baseline. Experimental results show that real-hardware training improves force-tracking performance compared to both alternatives, while the contraction filter mitigates chattering and instabilities. These findings suggest that contraction-based certificates can enable safe RL in high force hydraulic systems, though robustness at extreme operating conditions remains a challenge.",
      "authors": [
        "Lucca Maitan",
        "Lucas Toschi",
        "Cícero Zanette",
        "Elisa G. Vergamini",
        "Leonardo F. Santos",
        "Thiago Boaventura"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-09 18:21:15+00:00",
      "link": "https://arxiv.org/pdf/2602.08977v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16637v1",
      "title": "Active RIS-Assisted MIMO System for Vital Signs Extraction: ISAC Modeling, Deep Learning, and Prototype Measurements",
      "abstract": "We present the RIS-VSign system, an active reconfigurable intelligent surface (RIS)-assisted multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) framework for vital signs extraction under an integrated sensing and communication (ISAC) model. The system consists of two stages: the phase selector of RIS and the extraction of respiration rate. To mitigate synchronization-induced common phase drifts, the difference of Möbius transformation (DMT) is integrated into the deep learning framework, named DMTNet, to jointly configure multiple active RIS elements. Notably, the training data are generated in simulation without collecting real-world measurements, and the resulting phase selector is validated experimentally. For sensing, multi-antenna measurements are fused by the DC-offset calibration and the DeepMining-MMV processing with CA-CFAR detection and Newton's refinements. Prototype experiments indicate that active RIS deployment improves respiration detectability while simultaneously enabling higher-order modulation; without RIS, respiration detection is unreliable and only lower-order modulation is supported.",
      "authors": [
        "De-Ming Chian",
        "Chao-Kai Wen",
        "Feng-Ji Chen",
        "Yi-Jie Sun",
        "Fu-Kang Wang"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-18 17:27:48+00:00",
      "link": "https://arxiv.org/pdf/2602.16637v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16475v1",
      "title": "Certifying Hamilton-Jacobi Reachability Learned via Reinforcement Learning",
      "abstract": "We present a framework to \\emph{certify} Hamilton--Jacobi (HJ) reachability learned by reinforcement learning (RL). Building on a discounted initial time \\emph{travel-cost} formulation that makes small-step RL value iteration provably equivalent to a forward Hamilton--Jacobi (HJ) equation with damping, we convert certified learning errors into calibrated inner/outer enclosures of strict backward reachable tube. The core device is an additive-offset identity: if $W_λ$ solves the discounted travel-cost Hamilton--Jacobi--Bellman (HJB) equation, then $W_\\varepsilon:=W_λ+ \\varepsilon$ solves the same PDE with a constant offset $λ\\varepsilon$. This means that a uniform value error is \\emph{exactly} equal to a constant HJB offset. We establish this uniform value error via two routes: (A) a Bellman operator-residual bound, and (B) a HJB PDE-slack bound. Our framework preserves HJ-level safety semantics and is compatible with deep RL. We demonstrate the approach on a double-integrator system by formally certifying, via satisfiability modulo theories (SMT), a value function learned through reinforcement learning to induce provably correct inner and outer backward-reachable set enclosures over a compact region of interest.",
      "authors": [
        "Prashant Solanki",
        "Isabelle El-Hajj",
        "Jasper J. van Beers",
        "Erik-Jan van Kampen",
        "Coen C. de Visser"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-18 14:05:17+00:00",
      "link": "https://arxiv.org/pdf/2602.16475v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16271v1",
      "title": "Impact of Preprocessing on Neural Network-Based RSS/AoA Positioning",
      "abstract": "Hybrid received signal strength (RSS)-angle of arrival (AoA)-based positioning offers low-cost distance estimation and high-resolution angular measurements. Still, it comes at a cost of inherent nonlinearities, geometry-dependent noise, and suboptimal weighting in conventional linear estimators that might limit accuracy. In this paper, we propose a neural network-based approach using a multilayer perceptron (MLP) to directly map RSS-AoA measurements to 3D positions, capturing nonlinear relationships that are difficult to model with traditional methods. We evaluate the impact of input representation by comparing networks trained on raw measurements versus preprocessed features derived from a linearization method. Simulation results show that the learning-based approach consistently outperforms existing linear methods under RSS noise across all noise levels, and matches or surpasses state-of-the-art performance under increasing AoA noise. Furthermore, preprocessing measurements using the linearization method provides a clear advantage over raw data, demonstrating the benefit of geometry-aware feature extraction.",
      "authors": [
        "Omid Abbassi Aghda",
        "Slavisa Tomic",
        "Oussama Ben Haj Belkacem",
        "Joao Guerreiro",
        "Nuno Souto",
        "Michal Szczachor",
        "Rui Dinis"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-18 08:44:31+00:00",
      "link": "https://arxiv.org/pdf/2602.16271v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16166v1",
      "title": "Discovering Unknown Inverter Governing Equations via Physics-Informed Sparse Machine Learning",
      "abstract": "Discovering the unknown governing equations of grid-connected inverters from external measurements holds significant attraction for analyzing modern inverter-intensive power systems. However, existing methods struggle to balance the identification of unmodeled nonlinearities with the preservation of physical consistency. To address this, this paper proposes a Physics-Informed Sparse Machine Learning (PISML) framework. The architecture integrates a sparse symbolic backbone to capture dominant model skeletons with a neural residual branch that compensates for complex nonlinear control logic. Meanwhile, a Jacobian-regularized physics-informed training mechanism is introduced to enforce multi-scale consistency including large/small-scale behaviors. Furthermore, by performing symbolic regression on the neural residual branch, PISML achieves a tractable mapping from black-box data to explicit control equations. Experimental results on a high-fidelity Hardware-in-the-Loop platform demonstrate the framework's superior performance. It not only achieves high-resolution identification by reducing error by over 340 times compared to baselines but also realizes the compression of heavy neural networks into compact explicit forms. This restores analytical tractability for rigorous stability analysis and reduces computational complexity by orders of magnitude. It also provides a unified pathway to convert structurally inaccessible devices into explicit mathematical models, enabling stability analysis of power systems with unknown inverter governing equations.",
      "authors": [
        "Jialin Zheng",
        "Ruhaan Batta",
        "Zhong Liu",
        "Xiaonan Lu"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-18 03:46:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16166v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15618v1",
      "title": "Physics-Informed Anomaly Detection of Terrain Material Change in Radar Imagery",
      "abstract": "In this paper we consider physics-informed detection of terrain material change in radar imagery (e.g., shifts in permittivity, roughness or moisture). We propose a lightweight electromagnetic (EM) forward model to simulate bi-temporal single-look complex (SLC) images from labelled material maps. On these data, we derive physics-aware feature stacks that include interferometric coherence, and evaluate unsupervised detectors: Reed-Xiaoli (RX)/Local-RX with robust scatter (Tyler's M-estimator), Coherent Change Detection (CCD), and a compact convolutional auto-encoder. Monte Carlo experiments sweep dielectric/roughness/moisture changes, number of looks and clutter regimes (gamma vs K-family) at fixed probability of false alarm. Results on synthetic but physically grounded scenes show that coherence and robust covariance markedly improve anomaly detection of material changes; a simple score-level fusion achieves the best F1 in heavy-tailed clutter.",
      "authors": [
        "Abdel Hakiem Mohamed Abbas Mohamed Ahmed",
        "Beth Jelfs",
        "Airlie Chapman",
        "Eric Schoof",
        "Christopher Gilliam"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-17 14:46:25+00:00",
      "link": "https://arxiv.org/pdf/2602.15618v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15282v1",
      "title": "State Feedback Control of State-Delayed LPV Systems using Dynamics IQCs",
      "abstract": "This paper develops a new control framework for linear parameter-varying (LPV) systems with time-varying state delays by integrating parameter-dependent Lyapunov functions with integral quadratic constraints (IQCs). A novel delay-dependent state-feedback controller structure is proposed, consisting of a linear state-feedback law augmented with an additional term that captures the delay-dependent dynamics of the plant. Closed-loop stability and $\\mathcal{L}_2$-gain performance are analyzed using dynamic IQCs and parameter-dependent quadratic Lyapunov functions, leading to convex synthesis conditions that guarantee performance in terms of parameter-dependent linear matrix inequalities (LMIs). Unlike traditional delay control approaches, the proposed IQC-based framework provides a flexible and systematic methodology for handling delay effects, enabling enhanced control capability, reduced conservatism, and improved closed-loop performance.",
      "authors": [
        "Fen Wu"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-17 00:45:15+00:00",
      "link": "https://arxiv.org/pdf/2602.15282v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13537v2",
      "title": "Cluster-Robust Inference for Quadratic Forms",
      "abstract": "This paper studies inference for quadratic forms of linear regression coefficients with clustered data and many covariates. Our framework covers three important special cases: instrumental variables regression with many instruments and controls, inference on variance components, and testing multiple restrictions in a linear regression. Naïve plug-in estimators are known to be biased. We study a leave-one-cluster-out estimator that is unbiased, and provide sufficient conditions for its asymptotic normality. For inference, we establish the consistency of a leave-three-cluster-out variance estimator under primitive conditions. In addition, we develop a novel leave-two-cluster-out variance estimator that is computationally simpler and guaranteed to be conservative under weaker conditions. Our analysis allows cluster sizes to diverge with the sample size, accommodates strong within-cluster dependence, and permits the dimension of the covariates to diverge with the sample size, potentially at the same rate.",
      "authors": [
        "Michal Kolesár",
        "Pengjin Min",
        "Wenjie Wang",
        "Yichong Zhang"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM"
      ],
      "published": "2026-02-14 00:33:20+00:00",
      "link": "https://arxiv.org/pdf/2602.13537v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12695v1",
      "title": "Generative AI and the Reallocation of Time: Productivity, Leisure, and Fulfilling Work",
      "abstract": "Using a representative survey of Korean workers, we provide evidence on the adoption of Generative AI (GenAI) and how GenAI reallocates time at work. We find that 51.8\\% of workers use GenAI for work and GenAI reduces working time by 3.8\\%. However, these gains may not materialize in aggregate productivity statistics yet: the correlation between time savings and output changes is near zero. We show this disconnect arises because workers capture efficiency gains primarily as on-the-job leisure, rather than increasing their output. These findings suggest that standard productivity measures may understate AI's impact by missing non-pecuniary welfare channels.",
      "authors": [
        "Donghyun Suh",
        "Samil Oh"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN"
      ],
      "published": "2026-02-13 08:00:12+00:00",
      "link": "https://arxiv.org/pdf/2602.12695v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12035v1",
      "title": "The Algorithmic Advantage: How Reinforcement Learning Generates Rich Communication",
      "abstract": "We analyze strategic communication when advice is generated by a reinforcement-learning algorithm rather than by a fully rational sender. Building on the cheap-talk framework of Crawford and Sobel (1982), an advisor adapts its messages based on payoff feedback, while a decision maker best-responds. We provide a theoretical analysis of the long-run communication outcomes induced by such reward-driven adaptation. With aligned preferences, we establish that learning robustly leads to informative communication even from uninformative initial policies. With misaligned preferences, no stable outcome exists; instead, learning generates cycles that sustain highly informative communication and payoffs exceeding those of any static equilibrium.",
      "authors": [
        "Emilio Calvano",
        "Clemens Possnig",
        "Juha Tolvanen"
      ],
      "primary_category": "econ.TH",
      "categories": [
        "econ.TH"
      ],
      "published": "2026-02-12 15:03:26+00:00",
      "link": "https://arxiv.org/pdf/2602.12035v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16631v1",
      "title": "Can Wearable Exoskeletons Reduce Gender and Disability Gaps in the Construction Industry?",
      "abstract": "The share of construction trade jobs held by women and people with disabilities has remained stubbornly low in the face of chronic shortages of skilled labor. This study explores the potential of wearable assistive technologies to reduce these disparities. We use U.S. worker-level data to estimate employment and wage differences by gender and by mobility/strength impairments in construction and non-construction jobs. We also use occupational-level data to examine variations in workforce composition, physical skill requirements, and earnings across detailed construction occupations. Regression estimates indicate that being a woman and having strength and mobility impairments are associated with substantial employment and pay gaps in construction compared to non-construction jobs. Further analysis shows a high negative correlation between the representation of women and the ability levels required in those occupations. Finally, we discuss several wearable exoskeletons under development for people with upper-body and lower-body impairments, focusing on how these innovations could be integrated into construction jobs. These findings suggest that wearable exoskeletons that enhance manual dexterity, balance, and strength may improve the representation of women and people with disabilities in some of the higher-paying occupations in construction.",
      "authors": [
        "Yana Rodgers",
        "Xiangmin Liu",
        "Jingang Yi",
        "Liang Zhang"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN"
      ],
      "published": "2026-02-18 17:25:59+00:00",
      "link": "https://arxiv.org/pdf/2602.16631v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15980v1",
      "title": "Dutch Disease and the Resource Curse: The Progression of Views from Exchange Rates to Women's Agency and Well-Being",
      "abstract": "This article provides an overview of the history of economic thought on natural resource extraction, which has long been considered an enclave industry with few benefits for areas beyond the local economy. We focus on more recent scholarship examining the social impacts of natural resource extraction, emphasizing gender-related outcomes and determinants. An important lesson from this scholarship is that it is difficult to discuss sustainable development in its contemporary sense without paying due diligence to the gender dimensions of natural resource extraction. A lesson highlighted is that the \"resource curse\" view of natural capital may not be as pervasive as previously thought.",
      "authors": [
        "Nidhiya Menon",
        "Yana Rodgers"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN"
      ],
      "published": "2026-02-17 20:13:32+00:00",
      "link": "https://arxiv.org/pdf/2602.15980v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14918v1",
      "title": "Data-driven modeling of shock physics by physics-informed MeshGraphNets",
      "abstract": "High-resolution fluid simulations for plasma physics and astrophysics rely on Particle in cell (PIC) and hydrodynamic solvers (e.g., FLASH) to resolve shock dominated, multiscale phenomena, but their high computational cost severely limits scalability. This motivates the development of learning based surrogate models, which offer a promising route to accelerate these simulations while preserving physical fidelity. In this work, we study the Sedov Taylor shock propagation problem using a physics informed graph based surrogate model, Physics Informed MeshGraphNet (PhyMGN), designed for grid-based hydrodynamics. By incorporating weak physics constraints derived from the Euler equations using finite difference method, the model captures the self similar shock evolution and associated flow structures without explicitly solving the full hydrodynamic equations at each timestep. Comparing to the baseline MeshGraphNet model, PhyMGN is able to generalize beyond the training regime with a higher accuracy and preserves differentiability in parameter space while achieving a substantial reduction in computational cost relative to conventional numerical solvers.",
      "authors": [
        "S. Zhang",
        "M. Mallon",
        "M. Luo",
        "J. Thiyagalingam",
        "P. Tzeferacos",
        "R. Bingham",
        "G. Gregori"
      ],
      "primary_category": "physics.plasm-ph",
      "categories": [
        "physics.plasm-ph"
      ],
      "published": "2026-02-16 16:53:51+00:00",
      "link": "https://arxiv.org/pdf/2602.14918v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14803v2",
      "title": "A physics inspired and efficient transform for optoacoustic systems",
      "abstract": "Optoacoustic imaging technologies require fast and accurate signal pre-processing algorithms to enable widespread deployment in clinical and home-care settings. However, they still rely on the Discrete Fourier Transform (DFT) as the default tool for essential signal-conditioning operations, which imposes hard limits on both execution speed and signal-retrieval accuracy. Here, we present a new transform whose building blocks are directly inspired by the physics of optoacoustic signal generation. We compared its performance with the DFT and other classical transforms on common signal-processing tasks using both simulations and experimental datasets. Our results indicate that the proposed transform not only sets a new lower bound on computational complexity relative to the DFT, but also substantially outperforms classical transforms on basic signal-processing operations in terms of accuracy. We expect this transform to catalyze broader adoption of optoacoustic methods.",
      "authors": [
        "Maria Rodriguez Saenz de Tejada",
        "Alvaro Jimenez",
        "Rodrigo Rojo",
        "Sergio Contador",
        "Juan Aguirre"
      ],
      "primary_category": "physics.med-ph",
      "categories": [
        "physics.med-ph"
      ],
      "published": "2026-02-16 14:54:00+00:00",
      "link": "https://arxiv.org/pdf/2602.14803v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15085v1",
      "title": "Well-being and career instability across genders in the Spanish Astronomical Society",
      "abstract": "We present the results of a comprehensive survey conducted among members of the Spanish Astronomical Society (Sociedad Espanola de Astronomia, SEA) to assess well-being, professional satisfaction, and family-work balance of researchers in astronomy. The survey addressed multiple aspects of professional life, including happiness, career stability, publication pressure, and access to childcare services during scientific meetings. Responses were examined across gender and career stages to identify trends and sources of dissatisfaction.",
      "authors": [
        "Maritza A. Lara-Lopez",
        "I. Rebollido",
        "A. Vidal-Garcia",
        "A. Rouco Escorial",
        "S. Berlanas",
        "I. Garcia-Bernete",
        "B. Agis-Gonzalez",
        "M. Rodriguez-Baras",
        "N. Barrado-Izagirre",
        "I. Pintos Castro",
        "N. Ospina",
        "S. Bonoli"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.GA",
        "physics.soc-ph"
      ],
      "published": "2026-02-16 12:58:41+00:00",
      "link": "https://arxiv.org/pdf/2602.15085v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14669v1",
      "title": "Conductive Scaffolding for Neural Tissue Regeneration: 3D Bridging with Two-Photon Fabrication",
      "abstract": "We report on a novel dual-structure scaffold fabricated using two-photon polymerisation (2PP), integrating electrically conductive and non-conductive regions within a single architecture, targeting neural tissue regeneration. Poly(ethylene glycol) diacrylate (PEGDA) was combined with 20 nm gold nanoparticles to create a conductive microstructure, encapsulated within a biocompatible PEGDA lattice designed to support neuronal growth possibility after neural injuries. Electrical resistance measurements confirmed the feasibility of integrating conductive pathways into precision-fabricated microarchitectures.",
      "authors": [
        "Vladimir Osipov",
        "Aminah Jawed",
        "Petro Lutsyk",
        "David J. Webb",
        "Antonio Fratini"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-02-16 11:48:18+00:00",
      "link": "https://arxiv.org/pdf/2602.14669v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14654v1",
      "title": "Boundary conditions for the Schrödinger equation in the numerical simulation of quantum systems",
      "abstract": "We study the problem of the boundary conditions in the numerical simulation of closed and open quantum systems, described by a Schrödinger equation. On one hand, we show that a closed quantum system is defined by local boundary conditions. On the other hand, we argue that, because of the uncertainty principle, no local boundary condition can be defined for open quantum systems. For this reason plane waves or wave packet trains cannot be simulated on a finite numerical lattice with the usual procedures. We suggest a method that avoids these difficulties by using only a small numerical lattice and maintains the correspondence with the physical picture, in which the incident and scattered waves may be infinitely extended.",
      "authors": [
        "Marco Patriarca"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.mes-hall",
        "physics.comp-ph"
      ],
      "published": "2026-02-16 11:26:03+00:00",
      "link": "https://arxiv.org/pdf/2602.14654v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14601v1",
      "title": "The road of quantum entanglement: from Einstein to 2022 Nobel Prize in Physics",
      "abstract": "We explain the achievements that were awarded 2022 Nobel Prize in Physics, as well as the preceding and the later developments. The main notions and historic cornerstones of Bell inequalities, the related researches on quantum entanglement are reviewed, and the key physical ideas are emphasized. Among the early work, C. S. Wu's contributions using polarization-entangled photons from electron-positron annihilation are introduced.",
      "authors": [
        "Yu Shi"
      ],
      "primary_category": "physics.hist-ph",
      "categories": [
        "physics.hist-ph",
        "hep-ph",
        "quant-ph"
      ],
      "published": "2026-02-16 10:02:28+00:00",
      "link": "https://arxiv.org/pdf/2602.14601v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14567v1",
      "title": "Human versus Artificial Intelligence; various significant examples in astrophysics",
      "abstract": "In a recent arXiv posting [1] I reported the result of an experiment: asking Perplexity.ai to compare three items concerning (ordinary) Gamma Ray Burts (GRBs): the data, the standard paradigm(s) and the \"Cannonball\" (CB) model. Here I ask the same URL to extend this comparison to long--lasting GRBs, binary Neutron-Star mergers and their associated short--hard GRBs, low--luminosity GRBs, X--ray flashes, X--ray transients, and non--solar cosmic rays. The results of this experiment are enlightening but worrisome. Except for this abstract, two footnotes and two other references to standard [2] and CB-model [3] articles and talks, all of what follows is, verbatim, what the cited AI \"opines\".",
      "authors": [
        "A. De Rújula"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "hep-ph",
        "physics.soc-ph"
      ],
      "published": "2026-02-16 08:59:56+00:00",
      "link": "https://arxiv.org/pdf/2602.14567v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14565v1",
      "title": "Compositional Metrology of Atom Probe Applied to non-Metallic Materials",
      "abstract": "Two decades after its introduction, laser-assisted Atom Probe Tomography (La-APT) has demonstrated a unique potential for the study of the 3D distribution of atomic species in semiconductor materials and devices, and in a growing list of inorganic non-metallic solids. A crucial and often underestimated issue with APT is its accuracy in compositional measurements of non-metallic systems. This work introduces the principles of APT as an experimental technique, recalling the aspects potentially leading to compositional biases and underlining in particular the role of the surface electric field in governing the different physical-chemical phenomena that enable the measurement. It reviews the possible mechanisms of specific losses, as well as the methods for assessing a compositional bias and proposing possible correction methods. Finally, it establishes a state of the art on compositional biases in APT of non-metallic materials, on the basis of which it will be possible to conclude on specific recommendations for best practices, and the perspective of application of APT to new materials.",
      "authors": [
        "Enrico Di Russo",
        "François Vurpillot",
        "Lorenzo Rigutti"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.ins-det"
      ],
      "published": "2026-02-16 08:59:03+00:00",
      "link": "https://arxiv.org/pdf/2602.14565v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14555v1",
      "title": "Effective Caldirola-Kanai Model for Accelerating Twisted Dirac States in Nonuniform Axial Fields",
      "abstract": "We study relativistic twisted (orbital-angular-momentum) states of a massive charged particle propagating through an axially symmetric, longitudinally inhomogeneous solenoid field and a co-directed accelerating or decelerating electric field. Starting from the Dirac equation and using controlled spinless and paraxial approximations, we show that the transverse envelope obeys an effective nonstationary Schrödinger equation governed by a Caldirola--Kanai Hamiltonian. The longitudinal energy gain or loss encoded in $f(z)=[E_0-V(z)]^2-m^2$ generates an effective gain or damping rate $\\widetildeγ(z)=\\partial_z f(z)/[2f(z)]$ and a $z$-dependent oscillator frequency $\\widetildeω(z)=p_0Ω(z)/\\sqrt{f(z)}$. Exploiting the Ermakov mapping (unitary equivalence of Caldirola--Kanai systems), we obtain a closed-form propagated twisted wave function by transforming the stationary Landau basis. The transverse evolution is controlled by a single scaling function $b(z)$ that satisfies a generalized Ermakov--Pinney equation with coefficients determined by $E_z(z)$ and $B_z(z)$. In the limiting cases of uniform acceleration with $B_z=0$ and of solenoid focusing with negligible acceleration, our solution reduces to previously known analytic results, providing a direct bridge to established models.",
      "authors": [
        "N. V. Filina",
        "S. S. Baturin"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "physics.acc-ph",
        "physics.optics"
      ],
      "published": "2026-02-16 08:35:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14555v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14548v1",
      "title": "Potential Energy Curves of Hydrogenic Halides HX(Cl,Br) and i.DMFT Method",
      "abstract": "Comparison of {\\it ab initio} calculations in i.DMFT Method by Di Liu et al. (2025) with benchmark potential curves for HX(Cl,Br) halides shows their inaccuracy in domain around equilibrium and wrong behavior in Van der Waals region of large distances.",
      "authors": [
        "H Olivares Pilon",
        "A V Turbiner"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-16 08:09:31+00:00",
      "link": "https://arxiv.org/pdf/2602.14548v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14494v1",
      "title": "Design of Robust Raman Pulses for Cold Atom Interferometers Based on the Krotov Algorithm",
      "abstract": "The performance of high-precision cold-atom interferometers, which are important for applications in gravimetry and fundamental physics, is often limited by noise and imperfections in the driving laser system. To address this, we propose and numerically demonstrate a method for designing robust Raman pulses using the Krotov quantum optimal control algorithm. We establish a theoretical model for the atom-laser interaction and detail the implementation of the Krotov method to optimize the temporal shape of the pulse's amplitude and phase. Numerical simulations indicate that, compared to standard pulses, the optimized pulses maintain high atomic manipulation fidelity over an extended range of laser frequency detunings and intensity fluctuations. Furthermore, in simulations of a full interferometer sequence, this robustness translates to a significant enhancement in the final fringe contrast under a systematic detuning. This work demonstrates that quantum optimal control is a promising pathway for suppressing experimental noise and improving the signal-to-noise ratio and precision of next-generation atomic sensors.",
      "authors": [
        "Ziwen Song"
      ],
      "primary_category": "physics.atom-ph",
      "categories": [
        "physics.atom-ph"
      ],
      "published": "2026-02-16 06:16:56+00:00",
      "link": "https://arxiv.org/pdf/2602.14494v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14475v1",
      "title": "Self-Viscophoresis: Autonomous Motion by Biasing Thermal Fluctuations via Self-Generated Viscosity Asymmetry",
      "abstract": "Microscale transport often relies on ubiquitous yet intrinsically random thermal fluctuations. Understanding how such fluctuations can be biased into directed motion has long been a central theme of nonequilibrium physics. Here, we introduce self-viscophoresis, a mechanism of autonomous motion based on the rectification of thermal fluctuations in a self-generated nonequilibrium viscosity field. Asymmetric colloidal particles dispersed in a thermoresponsive polymer solution induce local heating under uniform illumination, producing a spatially asymmetric viscosity profile around the particle and resulting in persistent directed motion. To elucidate the physical origin of this behavior, we develop a minimal Langevin model coupling isotropic thermal fluctuations to a dynamically updating temperature-viscosity field. The model shows that viscosity asymmetry anisotropically damps stochastic dynamics, effectively biasing thermal fluctuations into a net drift. It thus reproduces the observed directed motion without invoking deterministic propulsion terms associated with effective potentials or environmental fluid flows. Our results distinguish self-viscophoresis from conventional self-propulsion mechanisms and establish it as a general framework enabling reversible control of both the direction and dimensionality of motion.",
      "authors": [
        "Bokusui Nakayama",
        "Yusuke Takagi",
        "Ryoya Hirose",
        "Masatoshi Ichikawa",
        "Marie Tani",
        "Ibuki Kawamata",
        "Eiji Yamamoto",
        "Akira Kakugo"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft",
        "physics.app-ph"
      ],
      "published": "2026-02-16 05:25:57+00:00",
      "link": "https://arxiv.org/pdf/2602.14475v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14205v1",
      "title": "Neural Network Based Molecular Structure Retrieval from Coulomb Explosion Imaging Data",
      "abstract": "Determining the structure and following the structural evolution of molecules undergoing chemical reactions is one of the key goals of ultrafast molecular physics and chemistry. Recently, Coulomb explosion imaging has emerged as a promising technique for imaging the evolving structure of individual molecules in the gas phase. However, its practical application for structure determination is hampered by the lack of suitable algorithms to directly retrieve the molecular structure from the measured fragment-ion momentum data. Here, we propose a scheme to solve the underlying inverse problem by employing neural networks to infer the initial atomic positions from the final ion momenta on an event-by-event basis. Using this scheme, we retrieve the structure of several polyhalomethane isomers from simulated Coulomb explosion imaging data with an average per-atom position error of approximately 0.1 atomic units, i.e., to within 5% of the typical bond lengths. This development paves the way for an automated structure retrieval from Coulomb explosion data one molecule at a time, making it ideally suitable for analyzing pump-probe experiments where several products are formed that need to be distinguished.",
      "authors": [
        "Amirhossein Ghanaatian",
        "Aravinth K. Ravi",
        "Joshua Stallbaumer",
        "Huynh V. S. Lam",
        "Artem Rudenko",
        "Loren Greenman",
        "Nathan Albin",
        "Doina Caragea",
        "Daniel Rolles"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph"
      ],
      "published": "2026-02-15 15:59:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14205v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14141v1",
      "title": "Ice-free geomorphometry of Queen Maud Land, East Antarctica: 3. Belgica and Yamato (Queen Fabiola) Mountains",
      "abstract": "Geomorphometric modeling and mapping of ice-free Antarctic areas can be applied for obtaining new quantitative knowledge about the topography of these unique landscapes and for the further use of morphometric information in Antarctic research. Within the framework of a project of creating a physical geographical thematic scientific reference geomorphometric atlas of ice-free areas of Antarctica, we performed geomorphometric modeling and mapping of two, partly ice-free mountainous areas of the eastern Queen Maud Land, East Antarctica. These include the Belgica Mountains and Yamato (Queen Fabiola) Mountains. As input data, we used two fragments of the Reference Elevation Model of Antarctica (REMA). For the two ice-free areas and adjacent glaciers, we derived models and maps of eleven, most scientifically important morphometric variables (i.e., slope, aspect, horizontal curvature, vertical curvature, minimal curvature, maximal curvature, catchment area, topographic wetness index, stream power index, total insolation, and wind exposition index). The obtained models and maps describe the ice-free topography of the Belgica Mountains and Yamato (Queen Fabiola) Mountains in a rigorous, quantitative, and reproducible manner. New morphometric data can be useful for further geological, geomorphological, glaciological, ecological, and hydrological studies of these areas.",
      "authors": [
        "I. V. Florinsky",
        "S. O. Zharnova"
      ],
      "primary_category": "physics.geo-ph",
      "categories": [
        "physics.geo-ph"
      ],
      "published": "2026-02-15 13:29:10+00:00",
      "link": "https://arxiv.org/pdf/2602.14141v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13884v1",
      "title": "Predicting the energies of Cf17+ for an optical clock",
      "abstract": "Highly charged ions (HCIs) combine compact electronic structure with strong relativistic effects, offering both robustness against external perturbations and enhanced sensitivity to variations of the fine-structure constant. Recent advances in sympathetic cooling and trapping enable precision measurements of highly charged ions; however, fully exploiting their potential requires accurate theoretical predictions. In particular, reliable calculations of clock wavelengths are essential for experimentally locating HCI clock transitions. Here, we treat Cf17+ as a univalent ion and perform calculations within the relativistic coupled-cluster framework, iteratively including nonlinear single-double contributions and valence and core triple excitations. We also assess quantum-electrodynamic corrections and basis-set and partial-wave truncation effects. Our results establish the impact of different correlation contributions on the low-lying energy spectrum and provide a quantitatively reliable prediction of the 5f_5/2 - 6p_1/2 clock transition, highlighting the critical role of core-valence correlations and iterative triples for precision spectroscopy and optical clock development.",
      "authors": [
        "S. G. Porsev",
        "M. S. Safronova"
      ],
      "primary_category": "physics.atom-ph",
      "categories": [
        "physics.atom-ph"
      ],
      "published": "2026-02-14 20:50:40+00:00",
      "link": "https://arxiv.org/pdf/2602.13884v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13862v1",
      "title": "Measuring Self-Rating Bias in LLM-Generated Survey Data: A Semantic Similarity Framework for Independent Scale Mapping",
      "abstract": "Synthetic survey data generated by large language models (LLMs) suffers from a fundamental circularity: the same model family that generates text responses also maps them to numerical scales. We calibrate and validate Semantic Similarity Rating (SSR; Maier et al., 2024), which decouples generation from scale mapping via embedding-based cosine similarity against predefined anchor statements. Configuration experiments (N=17 pilot, N=69 cross-validation across 8 domains) show that naturalistic behavioral anchors outperform formal jargon by 29 percentage points (pp), and that SSR achieves 65-67% exact match and 91% within plus/minus 1; a cross-model test with OpenAI text-embedding-3-small reaches 77% exact, confirming cross-provider generalization. Direct LLM baselines (Claude 87%, GPT-4o 83%) establish that SSR's contribution is methodological independence, not accuracy superiority. A control condition removing question text from the LLM prompt actually improves LLM accuracy, ruling out information asymmetry as the explanation for SSR's lower accuracy. A pre-registered circularity experiment (N=345) reveals 4x compressed error variance in LLM rating (sigma^2 = 0.21 vs 0.87 for SSR) and systematic directional bias. A cross-model control (GPT-4o rating Claude-generated text) shows nearly identical compression (within/cross ratio = 0.93), indicating variance compression is a general LLM property rather than a within-model artifact. The calibration dataset, anchor library, and source code are publicly available (see Data Availability).",
      "authors": [
        "Eduardo Vera Pichardo"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph"
      ],
      "published": "2026-02-14 19:51:33+00:00",
      "link": "https://arxiv.org/pdf/2602.13862v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13775v1",
      "title": "The gold-rush effect: how innovation speeds up",
      "abstract": "Innovation records often exhibit \"hockey-stick\" patterns of abrupt, near-singular growth at the collective level. However, this macroscopic explosiveness stands in stark contrast to individual discovery, which remains bounded by cognitive and temporal constraints and follows slow, sublinear accumulation laws. Here, we resolve this micro-macro discrepancy by introducing a minimal multi-scale model that identifies the growth of the explorer population as the primary driver of aggregate acceleration. Building on the Theory of the Adjacent Possible and the Urn Model with Triggering (UMT), we demonstrate that as discoveries expand the space of possibilities, they attract new explorers through a self-reinforcing branching process. This expansion induces a nonlinear mapping between intrinsic time (individual discovery events) and natural time (calendar years), effectively reparameterizing steady individual trajectories into accelerating system-level dynamics. We validate the framework using large-scale patent (EPO) and scientific publication (OpenAlex) datasets, showing that the model accurately reproduces stable per-capita productivity alongside exponential aggregate growth. By providing a quantitative link between individual behavior and collective takeoffs, this work offers a unified foundation for understanding the statistical structure and temporal evolution of innovation ecosystems.",
      "authors": [
        "Alessandro Bellina",
        "Gabriele Di Bona",
        "Giordano De Marzo",
        "Vittorio Loreto"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph"
      ],
      "published": "2026-02-14 13:38:16+00:00",
      "link": "https://arxiv.org/pdf/2602.13775v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13708v1",
      "title": "Making Symmetry Explicit: The Limits of Sophistication",
      "abstract": "Symmetry is often treated in philosophy of physics as an interpretive problem. A particularly lively dispute concerns local symmetries: do they indicate surplus structure that ought to be expunged, or are they merely a harmless redundancy? One influential response favours the second option for certain theories -- those dubbed internally sophisticated. And indeed, in much of physics practice, local symmetries are left implicit: one simply works \"up to isomorphism'' without pausing over invariance. But not always. In some settings, local symmetry and invariance become pressing practical concerns for physicists. Yet philosophical discussions of sophistication have paid little sustained attention to when, and why, this happens.   Surveying textbook general relativity (GR) and gauge theory, I identify the settings in which diffeomorphism invariance or gauge invariance must be handled explicitly. (Here a setting is a choice of representational framework or background assumptions within which one formulates and uses the theory -- for instance, linearisation, an initial-value formulation, or a Hamiltonian $3+1$ formalism.) I propose an operational criterion -- background-relative sophistication (BRS) -- and argue that it accounts well for the pattern: it marks just where symmetry can stay implicit and where it must be made explicit. Quantum and subsystem settings raise a further difficulty: there, certain tasks (superposition and gluing) force symmetry into view even for theories that are BRS.",
      "authors": [
        "Henrique Gomes"
      ],
      "primary_category": "physics.hist-ph",
      "categories": [
        "physics.hist-ph",
        "gr-qc"
      ],
      "published": "2026-02-14 10:21:05+00:00",
      "link": "https://arxiv.org/pdf/2602.13708v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13601v1",
      "title": "Resolving Cryogenic and Hypersonic Rarefied Flows via Deep Learning-Accelerated Lennard-Jones DSMC",
      "abstract": "Integrating a physically realistic Lennard Jones LJ potential into Direct Simulation Monte Carlo DSMC has long been hindered by the high cost of evaluating detailed scattering dynamics. We present a high-fidelity, machine-learning-accelerated framework that bridges rigorous molecular physics and large-scale kinetic simulation, implemented within Bird standard DSMC algorithm suite. Two challenges are solved incorporating LJ consistent properties into DSMC total cross-section formulation, and replacing the expensive particle scattering step with a surrogate model. First, we develop a universal Variable Effective Diameter model via local viscosity matching, capturing attractive repulsive interactions over a wide temperature range an advance over traditional models restricted to narrow thermal bands. Second, we employ a Deep Operator Network as a fast, accurate substitute for the LJ scattering integral, enabling efficient high-precision collisions. The resulting framework exposes physical effects often missed by standard models and is validated on three canonical problems: shock waves in helium and argon, supersonic Couette flow with cryogenic walls, and hypersonic cylinder flow at two Mach numbers. In the argon shock case, we show that while the Variable Hard Sphere VHS model fails to match the experimental density profile, its velocity distribution function closely follows the LJ prediction. In low temperature supersonic Couette flow, the LJ model predicts smaller shear stress than VHS, underscoring the dominant influence of long-range attractive forces in cryogenic shear layers.",
      "authors": [
        "Ahmad Shoja Sani",
        "Ehsan Roohi",
        "Stefan Stefanov"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-02-14 04:47:28+00:00",
      "link": "https://arxiv.org/pdf/2602.13601v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13512v1",
      "title": "Higher-order mean velocity profile in the convective atmospheric boundary layer",
      "abstract": "The higher-order mean velocity profile in the convective atmospheric boundary layer (CBL) is derived using the method of matched asymptotic expansions. The universal expansion coefficients are obtained using field measurement data. The profile accounts for the departures from the (leading-order) log law and local-free-convection scaling as well as the deviations from the Monin-Obukhov Similarity theory (MOST). Invoking MOST and the Multipoint Monin-Obukhov similarity theory, the perturbation equations are obtained from the Reynolds-stress, potential-temperature flux and potential temperature-variance budget equations and the mean momentum and mean potential temperature equations. The small parameters with the most impact in the equations are $(-z_i/L)^{-4/3}$, $(-z_i/L)^{-2/3}$ and $-h_0/L$, where $z_i$, $L$ and $h_0$ are the inversion height, the Obukhov length and the roughness height, respectively. Tong and Ding ({\\it J.~Fluid Mech.} 2020) have identified the three-layer structure of the CBL In the present work, asymptotic matching between the outer and inner-outer layers also results in higher-order expansion terms. The expansion coefficients are obtained using measurement data from the recent M$^2$HATS field campaign. Comparisons between the expansions and the measurement show excellent agreement. The higher-order asymptotic expansions show that the convective logarithmic friction law derived by Tong and Ding (2020) is valid to at least the second order. The predicted friction law also agrees well with measurements. The higher-order mean velocity profile can provide improved accuracy over empirical profiles.",
      "authors": [
        "Chenning Tong",
        "Davoud Pourabdollah",
        "Kirill Barskov",
        "Mengjie Ding"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-02-13 22:43:13+00:00",
      "link": "https://arxiv.org/pdf/2602.13512v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13438v1",
      "title": "Quantum Algorithm Framework for Phase-Contrast Transmission Electron Microscopy Image Simulation",
      "abstract": "We present a quantum algorithmic framework for simulating phase-contrast transmission electron microscopy (CTEM) image formation using a fault-tolerant, gate-based quantum circuit model. The electron wavefield on an $N\\times N$ grid is amplitude-encoded into a $2\\log_2 N$-qubit register. Free-space propagation and objective-lens aberrations are implemented via two-dimensional quantum Fourier transforms (QFTs) and diagonal phase operators in reciprocal space, while specimen interaction is modeled under the weak phase object approximation (WPOA) as a position-dependent phase grating. We validate projected potentials, contrast transfer function (CTF) behavior, and image contrast trends against classical multislice simulations for MoS$_2$ over experimentally relevant parameters, and provide resource estimates and key assumptions that determine end-to-end runtime. While extracting complete $N\\times N$ intensity images requires $O(N^2/ε^2)$ measurements that preclude advantage for full-image reconstruction, the framework enables quantum advantage for tasks requiring Fourier-space queries, global image statistics, or phase-coherent observables inaccessible to classical intensity-only detection. This framework provides a physics-grounded mapping from CTEM theory to quantum circuits and establishes a baseline for extending toward full multislice and inelastic scattering models.",
      "authors": [
        "Sean D. Lam",
        "Roberto dos Reis"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ],
      "published": "2026-02-13 20:26:27+00:00",
      "link": "https://arxiv.org/pdf/2602.13438v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13180v1",
      "title": "Exact moment models for conservation laws in phase space",
      "abstract": "Moment equations offer a compelling alternative to the kinetic description of plasmas, gases, and liquids. Their simulation requires fewer degrees of freedom than phase space models, yet it can still incorporate kinetic effects to a certain extent. To derive moment equations, we use a parameterization of the distribution function using centered moments, as proposed by Burby. This yields moment equations for which the parameterized distribution function exactly solves the hyperbolic conservation law. Similarly, a particle model is derived based on a parametrization of the distribution function using phase space moments. Finally, we present the application of the method to the non-relativistic and relativistic Vlasov--Maxwell equations.",
      "authors": [
        "Tileuzhan Mukhamet",
        "Katharina Kormann"
      ],
      "primary_category": "physics.plasm-ph",
      "categories": [
        "physics.plasm-ph"
      ],
      "published": "2026-02-13 18:40:05+00:00",
      "link": "https://arxiv.org/pdf/2602.13180v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13161v1",
      "title": "Optical Thermodynamics Beyond the Weak Nonlinearity Limit",
      "abstract": "Optical thermodynamics has recently emerged as a theoretical framework describing a Rayleigh-Jeans (RJ) modal power distribution of multimoded nonlinear photonic circuits. However, its applicability is constrained to systems exhibiting weak nonlinear mode-mode interactions. Here, by employing a Transfer Integral Operator, we circumvent this limitation and establish a steady-state interacting RJ modal distribution -- referred to as non-ideal RJ (NIRJ) -- with renormalized temperature and optical chemical potential. This also builds a natural bridge with earlier work on grand-canonical statistical-mechanical formulations of discrete nonlinear systems. The theory derives the optical analogue of the compressibility factor, which controls the transition from an ideal, non-interacting equation of state (EoS) to a van der Waals-like interacting EoS.",
      "authors": [
        "Emily Kabat",
        "Shrohan Mohapatra",
        "P. G. Kevrekidis",
        "Tsampikos Kottos"
      ],
      "primary_category": "nlin.PS",
      "categories": [
        "nlin.PS",
        "physics.optics"
      ],
      "published": "2026-02-13 18:18:16+00:00",
      "link": "https://arxiv.org/pdf/2602.13161v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13054v1",
      "title": "Polariton-mediated binding of anti-aligned dipolar excitons",
      "abstract": "Interacting bosonic quasiparticles are the cornerstone for exploring many-body physics and nonlinear quantum phenomena in correlated light-matter systems. Strongly interacting dipolar excitons in van der Waals heterostructures have attracted significant interest due to their out-of-plane electric dipole moments and high tunability via the quantum-confined Stark effect (QCSE). However, leveraging these tunable dipolar excitons in strongly coupled exciton-photon systems to explore exotic many-body physics and macroscopic quantum phenomena remains experimentally elusive. Here, we report the strong coupling of dipolar excitons in a gated bilayer MoS2 device integrated with a one-dimensional photonic crystal hosting bound-states-in-continuum (BIC). The resulting polaritons hybridize cavity photons with a coherent superposition of two electrically tunable anti-aligned dipolar excitons, effectively binding them into composite quasiparticle states. By tuning the dipolar excitons into non-degenerate states via the QCSE, we realize in situ reconfiguration of the polariton wavefunction and observe an emergent polariton branch exhibiting non-monotonic Stark shifts. Notably, these tunable polaritons allow for customized control over nonlinear interactions through distinct excitonic hybridization and dipolar configurations. This in situ tunability offers a scalable pathway toward electrically programmable quantum fluids of light and correlated polariton phases in on-chip photonic integrated circuits.",
      "authors": [
        "Haifeng Kang",
        "Quanbing Guo",
        "Tianyi Zhou",
        "Shun Feng",
        "Wei Dai",
        "Kenji Watanabe",
        "Takashi Taniguchi",
        "Hongxing Xu",
        "Ting Yu",
        "Xiaoze Liu"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-02-13 16:08:45+00:00",
      "link": "https://arxiv.org/pdf/2602.13054v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12993v1",
      "title": "Neural Quantum States Based on Selected Configurations",
      "abstract": "Neural quantum states (NQS) provide a flexible and highly expressive parameterization of wave functions for strongly correlated problems in quantum chemistry. Despite rapid advances in network architectures, the evaluation of electronic energies remains almost exclusively based on variational Monte Carlo (VMC). While VMC is effective for structured systems such as spin chains, its accuracy and efficiency for electronic Hamiltonians are hindered by sharply peaked distributions, stochastic gradient noise, and slow convergence with sample size. In this letter, we assess the capability of NQS-VMC to efficiently capture correlation in electronic ground states by comparing it to a recently developed NQS-based selected configuration (NQS-SC) approach. We set up a systematic comparison of the ground-state optimizations obtained with NQS-VMC and NQS-SC for molecular systems dominated by either static or dynamical correlation. The comparison demonstrates a clear advantage of NQS-SC over NQS-VMC in both energy accuracy and wave-function coefficients, particularly for statically correlated molecules. Moreover, NQS-SC exhibits robust systematic improvability, whereas NQS-VMC does not. These findings position NQS-SC as the new default approach over NQS-VMC for electronic structure calculations. We further observe that neither NQS-SC nor NQS-VMC can efficiently capture dynamical correlation, highlighting the need for future hybrid methods, such as multiconfigurational perturbation theories built on top of NQS solutions.",
      "authors": [
        "Marco Julian Solanki",
        "Lexin Ding",
        "Markus Reiher"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph",
        "cond-mat.str-el",
        "physics.comp-ph"
      ],
      "published": "2026-02-13 15:04:07+00:00",
      "link": "https://arxiv.org/pdf/2602.12993v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12938v1",
      "title": "All-Optically Controlled Memristive Reservoir Computing Capable of Bipolar and Parallel Coding",
      "abstract": "Physical reservoir computing (RC) utilizes the intrinsic dynamical evolution of physical systems for efficient data processing. Emerging optoelectronic RC platforms,such as light-driven memristors, merge the benefits of electronic and photonic computation. However, conventional designs are often limited by the unipolar photoresponse of optoelectronic devices, which restricts reservoir state diversity and reduces computational accuracy. To overcome these limitations, we introduce an all-optically controlled RC system employing an oxide memristor array that demonstrates exceptional uniformity and stability. The memristive devices exhibit wavelength-dependent bipolar photoresponse, originating from light-induced dynamic evolution of oxygen vacancies. Tuning the power density and irradiation mode of dual-wavelength light pulses enables dynamic control of photocurrent relaxation and nonlinearity. By leveraging these unique device properties, we develop bipolar and parallel coding strategies to significantly enrich reservoir dynamics and enhance nonlinear mapping capability. In word recognition and time-series prediction tasks, the bipolar coding demonstrates markedly improved accuracy compared to unipolar coding. The parallel coding supports multi-source signal fusion within a single reservoir, maintaining high computational accuracy while significantly reducing hardware consumption. This work provides a high-performance approach to physical RC, paving the way for intelligent edge computing.",
      "authors": [
        "Lingxiang Hu",
        "Dian Jiao",
        "Kexuan Wang",
        "Peihong Cheng",
        "Jingrui Wang",
        "Li Zhang",
        "Athanasios V. Vasilakos",
        "Yang Chai",
        "Zhizhen Ye",
        "Fei Zhuge"
      ],
      "primary_category": "physics.app-ph",
      "categories": [
        "physics.app-ph"
      ],
      "published": "2026-02-13 13:50:30+00:00",
      "link": "https://arxiv.org/pdf/2602.12938v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12898v1",
      "title": "Sympathetic cooling of charged particles in Penning traps using electron cyclotron radiation",
      "abstract": "We present a new technique for cooling arbitrary charged particles in a Penning trap by utilizing self-cooled electrons stored in a separate, macroscopically distant Penning trap as the cooling medium. The electrons decay predominantly to their motional ground state by emission of cyclotron radiation, which results in extremely low temperatures in the realm of single-digit quantum numbers in the motional degrees of freedom of the sympathetically cooled particle species. This opens up an exciting new frontier of tests of fundamental physics in Penning traps. This article provides a conceptual overview as well as a quantum-mechanical description of the involved cooling dynamics. The first implementation of this technique is currently being realized at the dedicated ELCOTRAP experiment at the Max Planck Institute for Nuclear Physics, which introduces special features for a quick iterative technical development cycle. Its current status, first results from commissioning, and future prospects will be presented.",
      "authors": [
        "Jost Herkenhoff",
        "Jonathan Notter",
        "Klaus Blaum"
      ],
      "primary_category": "physics.atom-ph",
      "categories": [
        "physics.atom-ph"
      ],
      "published": "2026-02-13 12:59:50+00:00",
      "link": "https://arxiv.org/pdf/2602.12898v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12865v1",
      "title": "On the rheoscopic measurement of turbulent decay in wall-bounded flows",
      "abstract": "Quench experiments where the flow passes from a fully turbulent state to a laminar state by an abrupt decrease in the flow Reynolds number ($Re$) have been extensively studied in the literature to quantify the turbulent-laminar transition process in wall-bounded flows. Measurements have been classically made using rheoscopic fluid visualisations, which make turbulent coherent structures easily identifiable, allowing for quantification of the evolution of a turbulent fraction -- the percentage of a given observation window where turbulence is deemed active by the presence of coherent structures, such as streamwise vortices called rolls, and modulations of the streamwise velocity fluctuations called streaks. Decay characteristic times of these structures have therefore been extensively measured. However, owing to the nature of visualization based techniques, only a single decay time is typically extracted, whereas measurements of the velocity field can reveal distinct decay times associated with different velocity or kinetic energy components. As a result, the physical meaning of the decay time inferred from visualization alone is not straightforward. The goal of the present paper is to perform such a comparison quantitatively, using particle image velocimetry (PIV) measurements and rheoscopic fluid visualisations in the same setup: a Couette-Poiseuille experiment. We observe via PIV different characteristic times of decay for streamwise (streaks) and spanwise (rolls) velocity fluctuations. We show that the characteristic time of decay of the turbulent fraction observed by visualisation is close to the decay of the streaks.",
      "authors": [
        "Tao Liu",
        "Victoria Nicolazo-Crach",
        "Ramiro Godoy-Diana",
        "José Eduardo Wesfreid",
        "Benoît Semin"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-02-13 12:15:44+00:00",
      "link": "https://arxiv.org/pdf/2602.12865v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12853v1",
      "title": "R&D Efforts in Cherenkov Imaging Technologies for Particle Identification in Future Experiments",
      "abstract": "Cherenkov imaging detectors will continue to play a central role for particle identification in future particle and nuclear physics experiments. Growing demands on momentum coverage, timing precision, radiation tolerance, and sustainability have driven extensive R&D in detector concepts, radiator materials, and photon sensors. This article reviews recent efforts, focusing on experiments leading advances in sensor technology, radiator materials, and the exploitation of Cherenkov photon timing to push PID limits, while highlighting synergies across experiments in addressing common challenges.",
      "authors": [
        "Chandradoy Chatterjee"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det",
        "hep-ex",
        "nucl-ex"
      ],
      "published": "2026-02-13 11:58:17+00:00",
      "link": "https://arxiv.org/pdf/2602.12853v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12808v1",
      "title": "Forecasting emergency department visits in the reference hospital of the Balearic Islands: the role of tourist and weather data",
      "abstract": "Accurate forecasting of patient arrivals at emergency departments (EDs) is vital for efficient resource allocation and high-quality patient care. In this study we investigate the relevance of exogenous variables, namely tourism, weather, calendar and demographic variables, in forecasting ED visits in the reference hospital in Palma de Mallorca, a city with significant seasonal population fluctuations due to tourism. Using a machine learning approach, we develop a model that predicts ED visits based solely on these exogenous variables. We test different machine learning algorithms (random forests, support vector machines, and feedforward neural networks) with different combinations of input variables and compare their symmetric mean average percentage errors (SMAPEs). Our findings reveal that calendar information, resident, and tourist population data are statistically significant for the accuracy of the predictions, while the addition of weather data does not provide any further improvement. Comparison of non-time-series with time-series prediction models reveals that the latter provide better accuracy for short prediction horizons (e.g. shorter than a week). Furthermore, time-series models become less or equally accurate to models relying only on exogenous variables for long prediction horizons (e.g. fortnight or month). Our study highlights the importance of carefully selecting predictive variables to ensure short- and long-term, robust and reliable forecasts. This demonstrates that, despite their lower complexity, non-time-series models with well-chosen input variables can be as effective as time-series models when predicting for long time horizons.",
      "authors": [
        "Paride Crisafulli",
        "Angel del Río Mangada",
        "Juan José Segura Sampedro",
        "Claudio R. Mirasso",
        "Raúl Toral",
        "Tobias Galla"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph"
      ],
      "published": "2026-02-13 10:42:54+00:00",
      "link": "https://arxiv.org/pdf/2602.12808v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12743v1",
      "title": "A T-matrix scattering formalism for electron-beam spectroscopy",
      "abstract": "Advanced computational tools that describe the interaction of electrons with structured nanophotonic materials are crucial for theoretical predictions, specific design tasks, and the interpretation of experimental results. These tools open the door to systematic exploration of free-electron-driven nanophotonic light sources, among others. Here, we report on the implementation of electron-beam spectroscopy in a T-matrix-based scattering formulation. Such a framework is quite versatile in predicting the electromagnetic response of complex photonic materials composed of periodically or aperiodically arranged individual scatterers. By extending this formalism to describe interactions with fast electrons, we provide a fast and accurate numerical tool for simulating cathodoluminescence (CL) and electron energy-loss spectroscopy (EELS) measurements. The desired functionalities are implemented into the existing software suite treams for electromagnetic scattering computations, and the extended code treams_ebeam is available online at https://github.com/tfp-photonics/treams_ebeam. We demonstrate the implementation details on a carefully selected set of problems, including single scatterers of various shapes and materials, a periodic chain of elliptical nanodisks, and a finite cluster of nanospheres arranged in a two-dimensional (2D) lattice. By uniting fast-electron physics with advanced scattering theory, our framework unlocks new possibilities for designing, understanding, and engineering next-generation nanoscale light-matter interactions.",
      "authors": [
        "P. Elli Stamatopoulou",
        "Carsten Rockstuhl"
      ],
      "primary_category": "physics.comp-ph",
      "categories": [
        "physics.comp-ph"
      ],
      "published": "2026-02-13 09:15:02+00:00",
      "link": "https://arxiv.org/pdf/2602.12743v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12497v1",
      "title": "Winter forecasting of September/October rainfall",
      "abstract": "We formulate seasonal rainfall prediction as a reduced-order nonlinear forecasting problem, embedding coupled Indian-Pacific Ocean variability into a low-dimensional state space and projecting it forward using deep neural networks. Variables include Nino 3.4, the Indian Ocean Dipole (IOD), the Indian Ocean meridional SST gradient, and selected empirical orthogonal functions. Monthly time series of the variables then form the input into deep neural networks which project rainfall further into the future. Forecasts for the 2025 austral spring were generated and archived in the Mendeley database during the winter. Subsequent rainfall data demonstrated a high level of agreement with the forecasts, providing a validation of the method and supporting the hypothesis that chaotic yet conditionally predictable dynamics underpin spring rainfall variability in southeastern Australia.",
      "authors": [
        "Stjepan Marcelja"
      ],
      "primary_category": "physics.ao-ph",
      "categories": [
        "physics.ao-ph",
        "nlin.CD"
      ],
      "published": "2026-02-13 00:41:59+00:00",
      "link": "https://arxiv.org/pdf/2602.12497v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12420v1",
      "title": "A Transformer-based Model for Rapid Microstructure Inference from Four-Dimensional Scanning Transmission Electron Microscopy Data",
      "abstract": "Properties of crystalline materials are closely linked to microstructure arising from the spatial arrangement, orientation, and phase of nanocrystals. Rapid characterization of crystalline microstructure can accelerate the identification of these links and the development of materials with desired properties. Here, we combine a machine learning framework with four-dimensional scanning transmission electron microscopy (4D-STEM) to enable fast inference of crystalline microstructure over large fields of view. The framework employs a transformer-based architecture to predict crystallographic orientations and phases from 4D-STEM diffraction patterns, yielding spatially resolved maps of microstructural features at the nanoscale. With this framework, crystallographic orientations are inferred up to two orders of magnitude faster than widely used correlative template-matching approaches. This capability enables high-throughput characterization of complex crystalline materials and facilitates the establishment of structure-property relationships central to materials design and optimization.",
      "authors": [
        "Kwanghwi Je",
        "Ellis R. Kennedy",
        "Sungin Kim",
        "Yao Yang",
        "Erik H. Thiede"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.ins-det"
      ],
      "published": "2026-02-12 21:17:58+00:00",
      "link": "https://arxiv.org/pdf/2602.12420v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12408v1",
      "title": "Detecting Spatiotemporal b-Value Anomalies with a Progressive Deep Learning Architecture",
      "abstract": "Identifying systematic patterns in seismicity that precede large earthquakes remains a central challenge in statistical seismology. In this work, we present a methodological framework for detecting spatiotemporal anomalies in seismicity using the evolution of gridded b-values. Focusing on the Japanese subduction zone, we construct daily b-value fields on a fine spatial grid by aggregating local seismicity over moving time windows, yielding a continuous 2+1D representation of seismic-state evolution.   We formulate the problem as a binary classification task in which spatiotemporal blocks extracted from these $b$-value fields are labeled according to the occurrence of a target earthquake with \\Mw $\\geq 5$ in the central region within the next day. To model this data, we introduce a hybrid deep-learning architecture that combines a spatial convolutional encoder with a temporal convolutional network, enabling joint learning of spatial structure and temporal dynamics. A progressive meta-epoch training scheme is employed, in which the model is iteratively updated using a time-forward strategy that mirrors operational deployment and mitigates issues related to nonstationarity.   This paper is strictly methodological in scope. It describes the construction of b-value fields, the spatiotemporal sampling strategy, the network architecture, and the progressive training and internal validation framework used for model development and parameter selection.",
      "authors": [
        "Jonas Köhler",
        "Wei Li",
        "Johannes Faber",
        "Georg Rümpker",
        "Nishtha Srivastava"
      ],
      "primary_category": "physics.geo-ph",
      "categories": [
        "physics.geo-ph"
      ],
      "published": "2026-02-12 20:57:02+00:00",
      "link": "https://arxiv.org/pdf/2602.12408v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12227v1",
      "title": "Phase Estimation from Amplitude Collapse in Correlated Matter-Wave Interference",
      "abstract": "Operating matter-wave interferometers as quantum detectors for fundamental physics or inertial sensors in real-world applications with unprecedented accuracies relies on noise rejection, often implemented by correlating two sensors. Such sensors can be spatially separated (gradiometry or gravitational-wave detection) or consist of different internal states (magnetometry or quantum clock interferometry), in which case a signal-amplitude modulation may serve as a signature of a differential phase. In this work, we introduce Phase Estimation from Amplitude Collapse (PEAC) by applying targeted fitting methods for different magnetically sensitive substates of an atom interferometer. We demonstrate that PEAC provides higher trueness (up to 80% bias reduction) than standard tools for perfectly correlated signals. At its working point near, but not exactly at phase settings resulting in vanishing amplitude, it achieves precision competitive with standard methods, contrasting prior claims of optimal operation at vanishing amplitude. PEAC presents a generally applicable complementary evaluation method for correlated interferometers without phase stability, increasing the overall accuracy and enabling applications beyond atom interferometry.",
      "authors": [
        "Daniel Derr",
        "Dominik Pfeiffer",
        "Ludwig Lind",
        "Gerhard Birkl",
        "Enno Giese"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "physics.atom-ph"
      ],
      "published": "2026-02-12 18:05:21+00:00",
      "link": "https://arxiv.org/pdf/2602.12227v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12140v1",
      "title": "Spreading viscous fluids on a horizontal surface: project-based learning in fluid mechanics",
      "abstract": "The spreading of a thin viscous fluid film on a horizontal surface is an interesting problem in fluid mechanics with many practical applications ranging from coating processes to biological systems and environmental flows. It can even be observed in everyday situations, such as syrup spreading on a pancake. We present a project-based learning approach to this problem, in which engineering or physics undergraduates apply classroom knowledge to understand and solve it, using dimensional analysis, experiments, and theoretical modeling. First, a dimensional analysis is conducted to guide the design of the experiment suitable for an undergraduate laboratory or even at home. The problem is then simplified to obtain a mathematical model that accounts for the experimental results. Through this process, students are able to obtain a solution compatible with those published in fluid mechanics journals with minimal supervision from the instructor. This project not only develops important skills but also motivates students by showing that they have the ability to solve complex problems.",
      "authors": [
        "R. Bolaños-Jimenez",
        "P. L. Luque-Escamilla"
      ],
      "primary_category": "physics.ed-ph",
      "categories": [
        "physics.ed-ph"
      ],
      "published": "2026-02-12 16:28:20+00:00",
      "link": "https://arxiv.org/pdf/2602.12140v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12109v1",
      "title": "A critical assessment of bonding descriptors for predicting materials properties",
      "abstract": "Most machine learning models for materials science rely on descriptors based on materials compositions and structures, even though the chemical bond has been proven to be a valuable concept for predicting materials properties. Over the years, various theoretical frameworks have been developed to characterize bonding in solid-state materials. However, integrating bonding information from these frameworks into machine learning pipelines at scale has been limited by the lack of a systematically generated and validated database. Recent advances in high-throughput bonding analysis workflows have addressed this issue, and our previously computed Quantum-Chemical Bonding Database for Solid-State Materials was extended to include approximately 13,000 materials. This database is then used to derive a new set of quantum-chemical bonding descriptors. A systematic assessment is performed using statistical significance tests to evaluate how the inclusion of these descriptors influences the performance of machine-learning models that otherwise rely solely on structure- and composition-derived features. Models are built to predict elastic, vibrational, and thermodynamic properties typically associated with chemical bonding in materials. The results demonstrate that incorporating quantum-chemical bonding descriptors not only improves predictive performance but also helps identify intuitive expressions for properties such as the projected force constant and lattice thermal conductivity via symbolic regression.",
      "authors": [
        "Aakash Ashok Naik",
        "Nidal Dhamrait",
        "Katharina Ueltzen",
        "Christina Ertural",
        "Philipp Benner",
        "Gian-Marco Rignanese",
        "Janine George"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.chem-ph",
        "physics.comp-ph"
      ],
      "published": "2026-02-12 16:00:12+00:00",
      "link": "https://arxiv.org/pdf/2602.12109v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12093v2",
      "title": "Covariant Chu-Kovasznay Decomposition: Resolving Thermodynamic Ambiguity in Compressible Flows",
      "abstract": "We establish the Covariant Chu--Kovasznay Decomposition (CCKD), a geometric framework that resolves thermodynamic ambiguity in compressible mode content by formulating the decomposition on the effective acoustic spacetime. Enforcing orthogonality in the covariant Chu energy norm, we show that shock--turbulence interaction, often treated as a scattering source, is, in the idealized linear, inviscid setting, a near-unitary (Chu-isometric) scattering map constrained by conservation of covariant Chu-energy flux. In the canonical Shu-Osher problem, CCKD characterizes the shock as a thermo-acoustic lens, mathematically demonstrating that the transfer of entropy fluctuations into sound follows a geometric blue-shift ($k_{\\mathrm{out}}=Λk_{\\mathrm{in}}$) analogous to gravitational blue-shift. Thus, while the mean flow produces entropy across the shock, the fluctuation mapping is information-preserving on the retained subspace; practical information loss arises from noise, truncation, and model mismatch, not shock physics.",
      "authors": [
        "Chanho Park",
        "Gyeongho Gong",
        "Yeachan Kwak",
        "Seongim Choi"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-02-12 15:45:12+00:00",
      "link": "https://arxiv.org/pdf/2602.12093v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11928v2",
      "title": "Topology-Enabled Switchable Unidirectional Radiative Band in a Bilayer Photonic Crystal",
      "abstract": "Controlling how an open photonic system exchanges energy with its environment-and in particular how it radiates into the far field-is a cornerstone of non-Hermitian wave physics and a key enabler for directional photonic functionalities. Here, we propose a new route to robust unidirectional emission based on the non-Hermitian hybridization of resonances localized in spatially separated layers of a hetero-bilayer photonic crystal. By tailoring the interlayer coupling, we engineer hybrid photonc bands that exhibit strong unidirectional radiation across a broad spectral and momentum range while maintaining theoretically high quality factors. This asymmetric emission is organized by a topological vortex in a pseudo-polarization field defined from the front/back intensity imbalance, which endows the directionality with robustness against perturbations. We further show that, by tuning the surrounding refractive index, this singularity can be displaced in parameter space, enabling reversible switching of the emission direction and a reconfigurable far-field response. This framework opens perspectives for topological photonic sensing and for directional and switchable light sources, including unidirectional lasing supported by high-quality-factor modes.",
      "authors": [
        "Zhiyi Yuan",
        "Vytautas Valuckas",
        "Yuhao Wang",
        "Thi Thu Ha Do",
        "Ningyuan Nie",
        "Yu-Cheng Chen",
        "Hai Son Nguyen",
        "Cuong Dang",
        "Son Tung Ha"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-02-12 13:25:35+00:00",
      "link": "https://arxiv.org/pdf/2602.11928v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11734v1",
      "title": "Ultra-Fast 3D Porous Media Generation: a GPU- Accelerated List-Indexed Explicit Time-Stepping QSGS Algorithm",
      "abstract": "Efficient generation of high-resolution synthetic microstructures is essential in digital rock physics, yet classical Quartet Structure Generation Set (QSGS) algorithms become prohibitively expensive on large three-dimensional grids. We develop a list-indexed explicit time-stepping (LIETS) formulation of QSGS that restricts stochastic growth operations to an explicit active front instead of the entire voxel grid. The method is implemented in Python using NumPy on CPUs and CuPy on GPUs, and incorporates seed-spacing control via diamond dilation together with a volume-fraction-dependent directional growth probability. For a 400^3 domain, LIETS reduces generation time from tens of minutes for a serial CPU implementation and several minutes for vectorized CPU and GPU QSGS to about 24 s on a consumer-grade RTX 4060, achieving peak throughputs up to 2.7x10^7 nodes/s. A Fontainebleau sandstone benchmark at 500^3 resolution shows that LIETS reproduces the dependence of pore and grain size distributions on seed spacing (optimal s=30 voxels) and yields permeability-porosity trends within the experimental envelope and consistent with previously published Fast-QSGS results.",
      "authors": [
        "Ruofan Wang",
        "Mohammed Al-Kobaisi"
      ],
      "primary_category": "physics.comp-ph",
      "categories": [
        "physics.comp-ph"
      ],
      "published": "2026-02-12 09:01:18+00:00",
      "link": "https://arxiv.org/pdf/2602.11734v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11702v1",
      "title": "A Hardware-Native Realisation of Semi-Empirical Electronic Structure Theory on Field-Programmable Gate Arrays",
      "abstract": "High-throughput quantum-chemical calculations underpin modern molecular modelling, materials discovery, and machine-learning workflows, yet even semi-empirical methods become restrictive when many molecules must be evaluated. Here we report the first hardware-native realisation of semi-empirical electronic structure theory on a field-programmable gate array (FPGA), implementing as a proof of principle Extended Hückel Theory (EHT) and non-self-consistent Density Functional Tight Binding (DFTB0). Our design performs Hamiltonian construction and diagonalisation on the FPGA device through a streaming dataflow, enabling deterministic execution without host intervention. On a mid-range Artix-7 FPGA, the DFTB0 Hamiltonian generator delivers a throughput over fourfold higher than that of a contemporary server-class CPU. Improvements in eigensolver design, memory capacity, and extensions to nuclear gradients and excited states could further expand capability. Combined with the inherent energy efficiency of FPGA dataflow, this work opens a pathway towards sustainable, hardware-native acceleration of electronic-structure simulation and direct hardware implementations of a broad class of methods.",
      "authors": [
        "Xincheng Miao",
        "Roland Mitrić"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph"
      ],
      "published": "2026-02-12 08:29:12+00:00",
      "link": "https://arxiv.org/pdf/2602.11702v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11682v1",
      "title": "Synthetic Gauge Phase in Rydberg Electromagnetically Induced Transparency",
      "abstract": "We demonstrate a synthetic gauge phase in Rydberg electromagnetically induced transparency (EIT) using room-temperature rubidium vapor. By exploiting polarization selection rules in a ladder-type system involving ground, intermediate, and Rydberg states, multiple Zeeman sublevels form closed-loop transitions that acquire a gauge phase. We show that the relative polarization angle between the linearly polarized probe and coupling lasers directly controls this gauge phase, which modulates the EIT transmission and Rydberg state population, consequently controlling the linewidth of EIT due to Rydberg dipole-dipole interactions between atoms. Our approach provides a simple polarization-based method for realizing synthetic gauge physics and manipulating many-body interactions in atomic ensembles without requiring laser cooling and dipole traps.",
      "authors": [
        "Ya-Dong Hu",
        "Yi-Chen Zhang",
        "Qing-Xuan Jie",
        "Hong-Jie Fan",
        "Xiao-Kang Zhong",
        "Dong-Qi Ma",
        "Ya-Nan Lv",
        "Yan-Lei Zhang",
        "Xu-Bo Zou",
        "Song-Bai Kang",
        "Guang-Can Guo",
        "Zhu-Bo Wang",
        "Chang-Ling Zou"
      ],
      "primary_category": "physics.atom-ph",
      "categories": [
        "physics.atom-ph"
      ],
      "published": "2026-02-12 07:56:28+00:00",
      "link": "https://arxiv.org/pdf/2602.11682v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11621v1",
      "title": "Differentiable Graph Neural Network Simulator for the Back-Analysis of Post-Liquefaction Residual Strength from Flow Failure Runout",
      "abstract": "This study introduces Differentiable Graph Neural Network Simulators (Diff-GNS) as a physics-informed and automated framework for estimating post-liquefaction residual strengths ($S_r$). Traditional approaches to estimate $S_r$ rely on simplified physics, manual iterations, and assumptions about runout development. Diff-GNS overcomes these limitations by integrating a Graph Neural Network Simulator (GNS) that simulates granular flows, with gradient-based optimization through automatic differentiation. GNS accelerates forward runout simulations that are otherwise computationally intensive with conventional numerical methods, while gradient-based optimization automates the inversion to back-calculate $S_r$. The GNS is trained on simulations with the material point method on geometries informed by case-history runout failures, enabling focused learning of realistic runout mechanisms and the ability to simulate slopes across small and large scales. The Diff-GNS framework is validated using two well-documented liquefaction-induced flow failure case histories: the Lower San Fernando dam and La Marquesa dam. In the two cases, the inferred $S_r$ agrees closely with published estimates and reproduces physically consistent runout behaviors. The framework also has the ability to jointly infer multiple interacting parameters, extending beyond single-parameter back-analyses. By embedding the physics of runout processes, minimizing manual intervention, and accelerating the inversion process to estimate $S_r$, Diff-GNS provides an efficient, reproducible, and physically grounded approach for geotechnical analysis of liquefaction-induced flow failures.",
      "authors": [
        "Yongjin Choi",
        "Jorge Macedo"
      ],
      "primary_category": "physics.geo-ph",
      "categories": [
        "physics.geo-ph"
      ],
      "published": "2026-02-12 06:15:29+00:00",
      "link": "https://arxiv.org/pdf/2602.11621v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11563v1",
      "title": "Nonlinear optical spectra from Rydberg-mediated photon-photon interactions",
      "abstract": "While Rydberg-Rydberg interactions are essential for quantum nonlinear optics and quantum information processing, their role in microwave and radio-frequency sensing remains poorly understood. Here we experimentally investigate Rydberg interaction-induced nonlinearity in cold-atom Rydberg electromagnetically induced transparency (EIT). In a three-level EIT system, increasing photon-photon interactions produces nonlinear spectral broadening accompanied by resonance shifts, while a microwave-dressed four-level system exhibits pronounced nonlinear broadening without detectable spectral shifts. Our three-level data can be explained by a conditional superatom model, whereas our four-level observations are surprisingly captured by a simple dephasing model. Comparisons with three representative models provide key insights to the role of many-body interactions in Rydberg EIT spectroscopy. Furthermore, our results clarify the conditions under which microwave field characterization can be performed in the nonlinear regime without introducing systematic bias. Our study advances both fundamental understanding of many-body physics and practical development of atomic sensors.",
      "authors": [
        "Xinghan Wang",
        "Yupeng Wang",
        "Aishik Panja",
        "Qi-Yu Liang"
      ],
      "primary_category": "physics.atom-ph",
      "categories": [
        "physics.atom-ph"
      ],
      "published": "2026-02-12 04:34:43+00:00",
      "link": "https://arxiv.org/pdf/2602.11563v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11535v1",
      "title": "Switchable high-Q light absorbers based on phase-change resonant metasurfaces",
      "abstract": "In this paper, we propose a switchable high-Q light absorber based on a reconfigurable metasurface enabled by a lowloss phase-change material (PCM). By leveraging the coupling between guided-mode resonance and Fabry-Perot modes, mediated by the phase-transition dynamics of the embedded PCM, the resonance Q factor can be actively tuned. This allows the system to switch from a perfect dark state, governed by the physics of bound states in the continuum, to a critically coupled resonance with a finite Q factor. Consequently, the metasurface exhibits perfect absorption in the amorphous state and a reflection-dominated response in the crystalline state. The proposed metasurface holds significant potential for diverse nanophotonic applications, including photodetection and thermal emission control.",
      "authors": [
        "Kai Qi",
        "Guoxiang Wang",
        "Xiang Shen",
        "Yixiao Gao"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-02-12 03:51:30+00:00",
      "link": "https://arxiv.org/pdf/2602.11535v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11526v1",
      "title": "Nonmonotonic Magnetic Friction from Collective Rotor Dynamics",
      "abstract": "Amontons' law postulates a monotonic relationship between frictional force and the normal load applied to a sliding contact. This empirical rule, however, fails in systems where internal degrees of freedom - such as structural or electronic order - play a central role. Here, we demonstrate that friction can emerge entirely from magnetically driven configurational dynamics in the absence of physical contact. Using a two-dimensional array of rotatable magnetic dipoles sliding over a commensurate magnetic substrate, we observe a pronounced non-monotonic dependence of friction on the interlayer separation, and thus on the effective load. The friction peaks at an intermediate distance where competing ferromagnetic and antiferromagnetic interactions induce dynamical frustration and hysteretic torque cycles during sliding. Molecular dynamics simulations and a simplified two-sublattice model confirm that energy dissipation is governed by collective magnetic reorientations and their hysteresis. Our results establish the occurrence of sliding-induced changes in collective magnetic order, which has a strong impact on friction, and thus open new possibilities for contactless friction control, magnetic sensing, and the design of reconfigurable, wear-free frictional interfaces and metamaterials.",
      "authors": [
        "Hongri Gu",
        "Anton Lüders",
        "Clemens Bechinger"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.soft",
        "physics.app-ph"
      ],
      "published": "2026-02-12 03:34:18+00:00",
      "link": "https://arxiv.org/pdf/2602.11526v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11489v1",
      "title": "Intermediate Thermal Equilibrium Stages in Molecular Dynamics Simulations of two Bodies in Contact",
      "abstract": "The Zeroth Law of Thermodynamics states that if two systems are in thermal equilibrium with a third one, then they are also in equilibrium with each other. This study explores not only the final state of thermal equilibrium between ideal gases separated by heat-conducting walls, but also the intermediate stages leading up to equilibrium, using classical molecular dynamics simulations. Two- and three-region models with argon atoms are analyzed. Fluctuations, correlations, and temperature distributions are observed, highlighting how heat conduction between regions influences the time to reach equilibrium. This work is distinguished by its detailed analysis of the intermediate stages that occur until the system reaches thermal equilibrium, in accordance with the Zeroth Law of Thermodynamics.",
      "authors": [
        "Jonathas N. da Silva",
        "Octavio D. Rodriguez Salmon",
        "Minos A. Neto"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "physics.comp-ph"
      ],
      "published": "2026-02-12 02:20:18+00:00",
      "link": "https://arxiv.org/pdf/2602.11489v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11421v1",
      "title": "Nonlinear integrated quantum photonics with AlGaAs",
      "abstract": "Integrated photonics provides a powerful approach for developing compact, stable and scalable architectures for the generation, manipulation and detection of quantum states of light. To this end, several material platforms are being developed in parallel, each providing its specific assets, and hybridization techniques to combine their strengths are now possible. This review focuses on AlGaAs, a III-V semiconductor platform combining a mature fabrication technology, direct band-gap compliant with electrical injection, low-loss operation, large electro-optic effect, and compatibility with superconducting detectors for on-chip detection. We detail recent implementations of room-temperature sources of quantum light based on the high second- and third-order optical nonlinearities of the material, as well as photonic circuits embedding various functionalities ranging from polarizing beamsplitters to Mach-Zehnder interferometers, modulators and tunable filters. We then present several realizations of quantum state engineering enabled by these recent advances and discuss open perspectives and remaining challenges in the field of integrated quantum photonics with AlGaAs.",
      "authors": [
        "F. Baboux",
        "G. Moody",
        "S. Ducci"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.mes-hall",
        "physics.optics"
      ],
      "published": "2026-02-11 22:44:56+00:00",
      "link": "https://arxiv.org/pdf/2602.11421v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11370v1",
      "title": "How cross-disciplinary science can describe living matter",
      "abstract": "Experience shows that disciplinary science cannot describe life without contradictions. We show that one of the fundamental reasons is the disciplinarity itself: the disciplines deal with a limited set of quantities. This way some 'outlaw' quantities are not measured and the discipline does not have laws about them. All laws of science are based on approximations and the approximations must be different for inanimate and life sciences. Studying ions is special because ions belong simultaneously to thermodynamics and electricity, but neither of those disciplines alone can describe biological processes. One needs a cross-disciplinary discussion and maybe a new scientific discipline. We provide a method for handling the different interaction speeds characterizing the ion transport. Electrolytes in living matter introduce further peculiarities with their closed volumes, internal structure, and slow processes. Their meticulous analysis led to the appropriate approximations, leading to the correct scientific description. As a success story, the cross-disciplinary theory of neuronal operation has been developed.",
      "authors": [
        "János Végh"
      ],
      "primary_category": "physics.bio-ph",
      "categories": [
        "physics.bio-ph"
      ],
      "published": "2026-02-11 21:01:20+00:00",
      "link": "https://arxiv.org/pdf/2602.11370v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11359v1",
      "title": "High-level hadronic tau lepton triggers of the CMS experiment in proton-proton collisions at $\\sqrt{s}$ = 13.6 TeV",
      "abstract": "The trigger system of the CMS detector is pivotal in the acquisition of data for physics measurements and searches. Studies of final states characterized by hadronic decays of tau leptons require the reconstruction and the identification of genuine tau leptons against quark- and gluon-initiated jets at the trigger level. This is a difficult task, particularly as improvements to the LHC have resulted in an increased number of interactions per bunch crossing in recent years. To address this challenge, a series of machine-learning algorithms with high identification efficiency and low computational cost have been incorporated into the high-level trigger for hadronically decaying tau leptons. In this paper, these developments and the trigger performance are summarized using data collected by the CMS experiment in proton-proton collisions at $\\sqrt{s}$ = 13.6 TeV in 2022$-$2023, corresponding to an integrated luminosity of 62 fb$^{-1}$.",
      "authors": [
        "CMS Collaboration"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det",
        "hep-ex"
      ],
      "published": "2026-02-11 20:46:53+00:00",
      "link": "https://arxiv.org/pdf/2602.11359v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11335v1",
      "title": "Initialization with a Fock State Cavity Mode in Real-Time Nuclear--Electronic Orbital Polariton Dynamics",
      "abstract": "Molecular polaritons have drawn great interest in recent years as a possible avenue for providing optical control over chemical dynamics. A central challenge in the field is to identify physical phenomena that require a quantum rather than a classical treatment of electrodynamics. In this work, we use our recently developed mean-field quantum (mfq) and full-quantum (fq) real-time nuclear--electronic orbital (RT-NEO) time-dependent density functional theory methods to simulate polaritonic dynamics for a molecule under vibrational strong coupling when a quantized cavity mode is initialized in a Fock state rather than a coherent state. Our previous work showed that a coherent state initial condition for the cavity mode leads to polariton formation for both the mfq-RT-NEO and fq-RT-NEO methods. Herein, we show that the mfq-RT-NEO method, which does not allow light--matter entanglement, does not predict polariton formation for a Fock state initial condition. Similar to the mfq-RT-NEO method, the fq-RT-NEO method does not predict oscillations of the cavity mode coordinate and molecular dipole operator expectation values for a Fock state initial condition. However, the fq-RT-NEO method does predict oscillations of the expectation values of even powers of these operators as well as light--matter entanglement, implicating polariton formation with a Fock state initial condition. All these observations can be explained with model systems. These results suggest that using a quantized cavity mode initial condition that does not have a direct analogy to an initial condition in classical electrodynamics can lead to physical phenomena that can only be described by a quantum treatment of the cavity mode.",
      "authors": [
        "Milan F. Welman",
        "Sharon Hammes-Schiffer"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph"
      ],
      "published": "2026-02-11 20:12:23+00:00",
      "link": "https://arxiv.org/pdf/2602.11335v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11098v1",
      "title": "Data-Efficient Multidimensional Free Energy Estimation via Physics-Informed Score Learning",
      "abstract": "Many biological processes involve numerous coupled degrees of freedom, yet free-energy estimation is often restricted to one-dimensional profiles to mitigate the high computational cost of multidimensional sampling. In this work, we extend Fokker--Planck Score Learning (FPSL) to efficiently reconstruct two-dimensional free-energy landscapes from non-equilibrium molecular dynamics simulations using different types of collective variables. We show that explicitly modeling orthogonal degrees of freedom reveals insights hidden in one-dimensional projections at negligible computational overhead. Additionally, exploiting symmetries in the underlying landscape enhances reconstruction accuracy, while regularization techniques ensure numerical robustness in sparsely sampled regions. We validate our approach on three distinct systems: the conformational dynamics of alanine dipeptide, as well as coarse-grained and all-atom models of solute permeation through lipid bilayers. We demonstrate that, because FPSL learns a smooth score function rather than histogram-based densities, it overcomes the exponential scaling of grid-based methods, establishing it as a data-efficient and scalable tool for multidimensional free-energy estimation.",
      "authors": [
        "Daniel Nagel",
        "Tristan Bereau"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "physics.chem-ph"
      ],
      "published": "2026-02-11 18:11:49+00:00",
      "link": "https://arxiv.org/pdf/2602.11098v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10968v2",
      "title": "The search for the gust-wing interaction \"textbook\"",
      "abstract": "We address whether complex physical relations can be investigated through the synergy of automated high-volume experiments and the reduction of large datasets to a concise, representative subset of canonical examples -- a \"textbook\". To this end, we consider the unsteady aerodynamics of wing-gust interactions, which is characterized by its rich, high-dimensional physics. We take advantage of a purpose-built gust generator to systematically produce over 1,000 distinct random gust events and to measure the unsteady loads induced on a delta wing. We then employ a data summarization procedure to identify representative subsets of increasing size from the large-scale database, which then serve as training data for a machine-learning model of the aerodynamic loads from sparse pressure measurements. An appropriately selected \"textbook\" of a few events can achieve predictive accuracy comparable to random training sets up to two orders of magnitude larger, capturing the intrinsic diversity of the full-scale data and enhancing modeling efficiency and interpretability. Our methodology evidences the potential of distilling the essential information contained in large amounts of experimental observations.",
      "authors": [
        "Paolo Olivucci",
        "David E. Rival"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "physics.data-an"
      ],
      "published": "2026-02-11 15:59:50+00:00",
      "link": "https://arxiv.org/pdf/2602.10968v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10937v2",
      "title": "Non-Hermitian curved space via inverted wave equation",
      "abstract": "Inverting design method of solving passive graded materials from predefined amplitude and phase was developed along the line of transformation optics (TO), which however precluded the presence of source and sink in the pragmatic world. So in this Letter we extend such an inverse method to non-Hermitian media, offering more freedom to manipulate the wave flows. Our principle of a curved-space analogue picture powered with gain and loss, is exemplified by three types: amplitude controlling, phase conversion, and direction shunting. These examples showcase precise wave manipulation in a surprisingly simple manner, which goes beyond convectional paradigms of TO and is readily implementable in realistic photonic platform.",
      "authors": [
        "C. Zhang",
        "Y. Liu",
        "H. Lin",
        "B. Zhou"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics",
        "physics.app-ph"
      ],
      "published": "2026-02-11 15:18:54+00:00",
      "link": "https://arxiv.org/pdf/2602.10937v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11225v1",
      "title": "Scale Invariance, Variety and Central Configurations",
      "abstract": "Scale invariance has received very little attention in physics. Nevertheless, it provides a natural conceptual foundation for a relational understanding of the universe, where absolute size loses meaning and only dimensionless ratios retain physical significance. We formalize this idea through the $N$-body problem, introducing a scale-invariant function--the variety, $V$--built from the square root of the center-of-mass moment of inertia and the Newtonian potential. Critical points of $V$, known as central configurations, correspond to special particle arrangements that preserve their shape under homothetic collapse or expansion. Numerical exploration of these critical points reveals that even slight deviations from the absolute minimum of $V$, which corresponds to a remarkably uniform configuration, lead to the spontaneous formation of filaments, loops, voids and other patterns reminiscent of the cosmic web. This behavior is a consequence of the intrinsic structure of shape space--the space of configurations modulo translations, rotations and dilatations--in which regions of higher variety act as attractors. Our results suggest that scale-invariant dynamics not only captures the relational nature of physical laws but also naturally generates organized patterns, offering a novel perspective on the formation of cosmic structures and on the emergence of a gravitational arrow of time from scale-invariant, relational dynamics.",
      "authors": [
        "Maria I. R. Lourenço",
        "Julian Barbour",
        "Francisco S. N. Lobo"
      ],
      "primary_category": "physics.hist-ph",
      "categories": [
        "physics.hist-ph",
        "gr-qc"
      ],
      "published": "2026-02-11 13:43:44+00:00",
      "link": "https://arxiv.org/pdf/2602.11225v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10817v1",
      "title": "Detecting and forecasting tipping points from sample variance alone",
      "abstract": "Anticipating tipping points in complex systems is a fundamental challenge across domains. Traditional early warning signals (EWSs) based on critical slowing down, such as increasing sample variance, are widely used, but their ability to reliably indicate imminent bifurcations and forecast their timing remains limited. Here, we introduce TIPMOC (TIpping via Power-law fits and MOdel Comparison), a parametric framework designed to statistically detect the approach of a bifurcation and estimate its future location using only the sample variance. TIPMOC exploits the mathematical property that variance diverges with a characteristic power-law form near codimension-one bifurcations. By sequentially monitoring system variance as a control parameter changes, TIPMOC statistically adjudicates between linear and power-law divergence at each step. When evidence favors power-law divergence, TIPMOC forecasts the impending tipping point and estimates its position; otherwise, it avoids false positives. Through numerical simulations, we demonstrate TIPMOC's robustness and accuracy in both detection and timing prediction across different types of dynamics and bifurcation. TIPMOC shows low false positive rates and performs well even with uneven sampling and colored noise. This method thus enhances the interpretability and practical utility of classical EWSs, serving as both a transparent add-on and a stand-alone statistical tool for forecasting regime shifts in diverse complex systems.",
      "authors": [
        "Naoki Masuda"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph"
      ],
      "published": "2026-02-11 12:59:08+00:00",
      "link": "https://arxiv.org/pdf/2602.10817v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10738v1",
      "title": "Between equilibrium and fluctuation: Einstein's heuristic argument and Boltzmann's principle",
      "abstract": "We critically revisit Einstein's 1905 heuristic argument for lightquanta, considering its internal coherence and the scope of its applicability. We argue that Einstein's reasoning, often celebrated for its originality, is ambiguous because it can be understood as a fluctuation or as a comparison between equilibrium states. A historical and conceptual analysis of Einstein's use of Boltzmann's principle in those years reveals his evolving stance on its meaning and the role of probability, as well as his persistent doubts about the nature of radiation. We use our analysis to examine the limitations of extending the notion of Einstein's lightquanta across the electromagnetic spectrum: the relevant parameter is not the frequency, but the occupancy number.",
      "authors": [
        "Enric Pérez",
        "Antonio Gil"
      ],
      "primary_category": "physics.hist-ph",
      "categories": [
        "physics.hist-ph",
        "cond-mat.stat-mech",
        "quant-ph"
      ],
      "published": "2026-02-11 10:59:19+00:00",
      "link": "https://arxiv.org/pdf/2602.10738v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10681v1",
      "title": "High-voltage generation system for a traveling-wave Stark decelerator",
      "abstract": "In this paper we describe the high-voltage generation system we have developed for a traveling-wave Stark decelerator (TWSD). The TWSD can reduce the forward velocity of a molecular beam of heavy neutral polar molecules such as strontium monofluoride (SrF) and barium monofluoride (BaF) from $\\sim$ 200 m/s down to $\\sim$ 6 m/s. The main motivation for the development of this device is the increased sensitivity from precision spectroscopy of the decelerated molecules to test fundamental physics. The high-voltage generation system can produce eight pulsed sinusoidal waveforms with a maximum amplitude of 10 kV and a linear frequency sweep from 16.7 kHz down to 500 Hz over the span of 40 ms at a repetition rate of 10 Hz. The eight waveforms are phase-offset to each other by 45 degrees. To slow down the heavy molecules, the decelerator is required to have a length of $\\sim$ 4 m, which results in a significant capacitive coupling between adjacent channels of $\\sim$ 160 pF. As a consequence, the control and stability of the waveforms is extra challenging. We designed a method that compensates for the frequency-dependent coupling between the eight channels. Allowing for amplitude and phase-offsets that do not deviate more than 1% and 2 degrees, respectively, from their design values during the frequency sweep. The system outperforms commercially available options in terms of stability, output voltage amplitude, cost and ease of maintenance. This approach is also relevant for other fields where precise control of high-voltage waveforms is required, such as particle accelerator physics, plasma physics and mass spectroscopy.",
      "authors": [
        "Lucas van Sloten",
        "Leo Huisman",
        "Steven Hoekstra"
      ],
      "primary_category": "physics.atom-ph",
      "categories": [
        "physics.atom-ph",
        "physics.ins-det"
      ],
      "published": "2026-02-11 09:32:47+00:00",
      "link": "https://arxiv.org/pdf/2602.10681v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10557v1",
      "title": "Field-Deployable Hybrid Gravimetry: Projecting Absolute Accuracy Across a Remote 24km$^2$ Survey via Daily Quantum Calibration",
      "abstract": "Absolute gravimeters deliver drift-free, high-precision measurements but are typically bulky and difficult to deploy, whereas relative gravimeters are lightweight and mobile but intrinsically limited by time-dependent drift. We demonstrate a hybrid quantum-enabled gravimetry approach in which an on-site atomic gravimeter provides routine, $μ$Gal-level calibration of two mobile spring gravimeters during a field survey spanning 24 km$^2$ of dense tropical terrain. The atomic reference enables high-precision, asynchronous cross-comparison of relative measurements acquired over seven days, effectively suppressing instrumental drift to a level required for demanding geophysical applications. This deployment captures regional gravity gradients with high fidelity under challenging environmental conditions, illustrating how field-operable quantum sensors can extend quantum-grade gravimetry beyond laboratory settings and serve as scalable calibration backbones for large-area, high-precision geophysical surveys in remote or logistically constrained environments.",
      "authors": [
        "Nathan Shettell",
        "Kai Sheng Lee",
        "Fong En Oon",
        "Elizaveta Maksimova",
        "Hong Hui Chen",
        "Rainer Dumke"
      ],
      "primary_category": "physics.geo-ph",
      "categories": [
        "physics.geo-ph",
        "physics.atom-ph"
      ],
      "published": "2026-02-11 06:11:03+00:00",
      "link": "https://arxiv.org/pdf/2602.10557v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10475v1",
      "title": "Accurate simulation of pulled and pushed fronts in the nonautonomous Fisher-KPP equation",
      "abstract": "We introduce a novel numerical method for direct simulation of front propagation in the Fisher-KPP equation with a time-dependent parameter on an infinite domain. The method computes a time-dependent boundary condition that accurately captures the leading-edge dynamics by coupling the nonlinear simulation region to a linear approximation region in which the dynamics can be solved exactly via the Green's function of the linearized equation. This approach enables precise front velocity measurements on relatively small computational domains for a variety of nonautonomous regimes and initial conditions for which existing numerical methods break down. We apply the method to pulled and pushed fronts in the Fisher-KPP equation with quadratic and quadratic-cubic nonlinearities, finding that it improves the accuracy of the simulated front velocity even for constant parameters and a fixed domain size. For pulled fronts with a diffusion coefficient that increases algebraically in time, our results reveal a deviation from the natural asymptotic velocity predicted by linear theory, whose explanation requires nonlinear theory. For pushed fronts with constant parameters, the method reproduces the exponential convergence to the theoretical asymptotic front speed and profile with improved precision. For a slowly time-varying linear growth parameter, we find that the pushed front velocity follows the changing parameter adiabatically if the asymptotic pushed velocity remains faster than the natural asymptotic pulled velocity. As the growth parameter moves toward the pushed--pulled transition point, the competition between the pushed and pulled fronts can result in both delayed and even premature onset of the pushed--pulled transition, depending on the form of parameter growth. The numerical method presented here proves to be an effective tool for analyzing front propagation in nonautonomous systems.",
      "authors": [
        "Troy Tsubota",
        "Smridhi Mahajan",
        "Adrian van Kan",
        "Edgar Knobloch"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "nlin.PS"
      ],
      "published": "2026-02-11 03:27:58+00:00",
      "link": "https://arxiv.org/pdf/2602.10475v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10447v1",
      "title": "Bridging the Kinetic-Fluid Gap: Ion-Driven Magnetogenesis to Prime Cosmic Dynamos",
      "abstract": "The origin of cosmic magnetic fields is widely attributed to the amplification of weak seed fields by turbulent dynamos. However, a critical understanding gap remains between the microscopic generation of these seeds and the macroscopic onset of the dynamo. Current kinetic models, often constrained to electron scales, predict premature saturation via magnetic trapping, leaving the generated fields potentially too weak and small-scale to effectively prime magnetohydrodynamic (MHD) processes. Here, using high-resolution kinetic simulations with a realistic mass ratio, we reveal the physics of this unexplored ion-kinetic regime. Under generalized continuous shear driving, used to simulate ubiquitous macroscopic flows, we demonstrate that the saturation of electron instabilities is not the endpoint but a precursor to a distinct, ion-dominated evolution. Massive ions, sustaining the velocity shear, trigger a subsequent filamentation instability that accesses the vast ion kinetic energy reservoir. This mechanism amplifies the magnetic energy by orders of magnitude beyond the electron-saturation limit, expanding the field coherence to ion scales. Our results establish ion kinetics as the essential ''missing link'' that bridges the divide between microscopic plasma instabilities and macroscopic cosmic dynamos.",
      "authors": [
        "X. Liu",
        "D. Wu",
        "J. Zhang"
      ],
      "primary_category": "physics.plasm-ph",
      "categories": [
        "physics.plasm-ph",
        "astro-ph.GA"
      ],
      "published": "2026-02-11 02:39:24+00:00",
      "link": "https://arxiv.org/pdf/2602.10447v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10427v1",
      "title": "The selective use of physics knowledge in policy: how interdisciplinary physics bridges subfields and shapes policy influence",
      "abstract": "Scientific knowledge has become central to policymaking as societies face challenges related to technological change, climate risk, and public health. Despite the growing emphasis on evidence-based policy, a systematic understanding of how science is selectively used in policy, specifically which forms of knowledge are preferred and which scientific citations translate into influence, remains limited. We address these questions by constructing a novel dataset that links policy documents from the Overton database with publications from the American Physical Society, enabling an analysis of how physics knowledge enters and circulates in policy discourse. Using subfield classifications, we provide quantitative evidence for a gap between scientific communities and policymakers. First, we find that policy documents draw on broad and interdisciplinary areas of physics, such as General Physics and Interdisciplinary Physics, rather than mirroring the structure of physics research production. Second, we identify substantial institutional heterogeneity with systematic differences in subfield preferences across policy producing organizations and topics. Third, network analysis reveals that interdisciplinary areas of physics act as a central bridge connecting specialized subfields. Finally, regression analysis reveals a clear separation between policy visibility and policy influence. While interdisciplinary areas facilitate entry into policy discourse, it does not necessarily increase downstream policy influence. Conversely, documents citing geophysics are associated with approximately 24 percent higher policy influence, likely driven by the political salience of climate change policy. Our findings underscore the distinction between scientific visibility and policy influence, contributing to a deeper understanding of the complex relationship between scientific communities and policy system.",
      "authors": [
        "Jeongmin Lee",
        "Jisung Yoon"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph"
      ],
      "published": "2026-02-11 02:15:24+00:00",
      "link": "https://arxiv.org/pdf/2602.10427v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10283v1",
      "title": "Nonstationary polarization optical forces, considering the influence of dispersion and diffraction",
      "abstract": "In the present work, the dynamic properties of an attractive longitudinal optical force and the applied potential, due to diffraction and dispersion of ultrashort laser pulses, propagating in air at distances of several diffraction and dispersion lengths, are presented. The results are based on an analytical solution of the linear 3D+1 paraxial amplitude equation and its application to the evolution in time of the longitudinal optical force. The current research provides valuable guidance for the development and creation of neutral particle laser accelerators with potential applications in the field of laser driven nuclear fusion.",
      "authors": [
        "Maria-Gabriela Zheleva",
        "A. Dakova",
        "V. Slavchev",
        "L. Kovachev.",
        "D. Dakova"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-02-10 20:52:36+00:00",
      "link": "https://arxiv.org/pdf/2602.10283v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10064v1",
      "title": "PySlice: Routine Vibrational Electron Energy Loss Spectroscopy Prediction with Universal Interatomic Potentials",
      "abstract": "Vibrational spectroscopy in the electron microscope can reveal phonon excitations with nanometer spatial resolution, yet routine prediction remains out of reach due to fragmented workflows requiring specialized expertise. Here we introduce PySlice, the first publicly available implementation of the Time Autocorrelation of Auxiliary Wavefunction (TACAW) method, providing an automated framework that produces momentum- and energy-resolved vibrational electron energy-loss spectra directly from atomic structures. By integrating universal machine learning interatomic potentials with TACAW, PySlice eliminates the bottleneck of per-system potential development. Users input atomic structures and obtain phonon dispersions, spectral diffraction patterns, and spectrum images through a unified workflow spanning molecular dynamics, GPU-accelerated electron scattering, and frequency-domain analysis. We outline the formulation behind the code, demonstrate its application to canonical systems in materials science, and discuss its use for advanced analysis and materials exploration. The modular Python architecture additionally supports conventional electron microscopy simulations, providing a general-purpose platform for imaging and diffraction calculations. PySlice makes vibrational spectroscopy prediction routine rather than specialized, enabling computational screening for experimental design, systematic exploration of phonon physics across materials families, and high-throughput generation of simulated data for training of future machine learning models.",
      "authors": [
        "Harrison A. Walker",
        "Thomas W. Pfeifer",
        "Paul M. Zeiger",
        "Jordan A. Hachtel",
        "Sokrates T. Pantelides",
        "Eric R. Hoglund"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ],
      "published": "2026-02-10 18:32:25+00:00",
      "link": "https://arxiv.org/pdf/2602.10064v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10041v1",
      "title": "Design of experiments characterising heat conduction in magnetised, weakly collisional plasma",
      "abstract": "Heat conduction in weakly collisional, magnetised plasma is challenging to model accurately due to multifaceted physics governing heat-carrying electrons, including microinstabilities that scatter electrons and modify heat transport. Capturing these effects requires multidimensional kinetic theory simulations, which are computationally expensive. Experimental constraints overcome this issue, resulting in improved understanding of thermal transport in systems such as the intra-cluster medium of galaxy clusters, and the hot-spot in inertial confinement fusion. In this paper, we present a new experimental platform that produces a weakly collisional high-\\b{eta} plasma expected to be susceptible to the whistler heat-flux instability. This platform, to be fielded on the Orion laser, enables characterisation of whistler-regulated thermal conductivity. The platform design is assessed using radiation-magnetohydrodynamics simulations with the code FLASH. Simulations using three thermal conduction models predict conductivity suppression by over an order of magnitude relative to the Spitzer value at whistler saturation, demonstrating the efficacy of the platform.",
      "authors": [
        "T. A. Vincent",
        "P. Ariyathilaka",
        "L. Creaser",
        "C. Danson",
        "D. Lamb",
        "J. Meinecke",
        "C. A. J. Palmer",
        "S. Pitt",
        "H. Poole",
        "C. Spindloe",
        "P. Thomas",
        "E. Tubman",
        "L. Wilson",
        "W. J. Garbett",
        "G. Gregori",
        "P. Tzeferacos",
        "T. Hodge",
        "A. F. A. Bott"
      ],
      "primary_category": "physics.plasm-ph",
      "categories": [
        "physics.plasm-ph"
      ],
      "published": "2026-02-10 18:07:15+00:00",
      "link": "https://arxiv.org/pdf/2602.10041v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09986v1",
      "title": "Universal Foundations of Thermodynamics: Entropy and Energy Beyond Equilibrium and Without Extensivity",
      "abstract": "Thermodynamics is commonly presented as a theory of macroscopic systems in stable equilibrium, built upon assumptions of extensivity and scaling with system size. In this paper, we present a universal formulation of the elementary foundations of thermodynamics, in which entropy and energy are defined and employed beyond equilibrium and without assuming extensivity. The formulation applies to all systems -- large and small, with many or few particles -- and to all states, whether equilibrium or nonequilibrium, by relying on carefully stated operational definitions and existence principles rather than macroscopic idealizations. Key thermodynamic concepts, including adiabatic availability and available energy, are developed and illustrated using the energy-entropy diagram representation of nonequilibrium states, which provides geometric insight into irreversibility and the limits of work extraction for systems of any size. A substantial part of the paper is devoted to the analysis of entropy transfer in non-work interactions, leading to precise definitions of heat interactions and heat-and-diffusion interactions of central importance in mesoscopic continuum theories of nonequilibrium behavior in simple and complex solids and fluids. As a direct consequence of this analysis, Clausius inequalities and the Clausius statement of the second law are derived in forms explicitly extended to nonequilibrium processes. The resulting framework presents thermodynamics as a universal theory whose concepts apply uniformly to all systems, large and small, and provides a coherent foundation for both teaching and modern applications.",
      "authors": [
        "Gian Paolo Beretta"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.stat-mech",
        "physics.chem-ph",
        "physics.class-ph"
      ],
      "published": "2026-02-10 17:12:20+00:00",
      "link": "https://arxiv.org/pdf/2602.09986v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09827v1",
      "title": "Scaling laws for the cutoff wavenumber of the short-wavelength ion-temperature-gradient mode in a Z-pinch",
      "abstract": "We use a heuristic fluid model to predict the dependence of the cutoff wave number for the short-wavelength ion temperature gradient (SWITG) mode on ion density gradient, ion temperature gradient (ITG) and ion-electron temperature ratio. In particular, we predict that the cutoff wave number increases linearly with increasing ITG for sufficiently large values of the ITG. Direct numerical solutions of the gyrokinetic dispersion relation using a purpose-built solver confirm the predicted scalings at large ITG values and find a weaker power-law scaling for intermediate ITG values. Combining these wave number scalings with a simple diffusive estimate for turbulent fluxes produces a scaling prediction for the ITG heat flux in SWITG-driven turbulence. Applying the critical balance conjecture additionally provides scalings for the aspect ratio of the SWITG turbulent eddies.",
      "authors": [
        "O. Gupta",
        "M. Barnes",
        "F. I. Parra",
        "L. Podavini",
        "A. Zocco",
        "T. Adkins",
        "P. G. Ivanov"
      ],
      "primary_category": "physics.plasm-ph",
      "categories": [
        "physics.plasm-ph"
      ],
      "published": "2026-02-10 14:34:52+00:00",
      "link": "https://arxiv.org/pdf/2602.09827v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09792v1",
      "title": "Variability in Performance of a Machine-Learning Seismicity Catalog: Central Italy, 2016-2017",
      "abstract": "Machine learning (ML) catalogs contain many more earthquakes than routine catalogs, but their performance in phase picking and earthquake detection has not been fully evaluated. We develop station-level detection probabilities using logistic regression and combine them across a seismic network to compute spatial magnitude-of-completeness fields. We apply this approach to two catalogs from the 2016-2017 Central Italy sequence that were constructed from the same seismic network, one routine and one ML based. At the station level, the ML picker increases detection sensitivity by identifying smaller magnitude events and detecting earthquakes at greater distances. Spatially, the magnitude-of-completeness decreases substantially, with median values shifting from 1.6 to 0.5 for P waves and from 1.7 to 0.5 for S waves. However, the ML catalog also shows greater variability in station-level performance than the routine catalog. These results demonstrate that ML-based improvements in detectability are widespread but spatially non-uniform, highlighting their benefits, their limitations, and the potential for further improvements.",
      "authors": [
        "Jaehong Chung",
        "Yifan Yu",
        "Lauro Chiaraluce",
        "Maddalena Michele",
        "Gregory C. Beroza"
      ],
      "primary_category": "physics.geo-ph",
      "categories": [
        "physics.geo-ph"
      ],
      "published": "2026-02-10 13:57:19+00:00",
      "link": "https://arxiv.org/pdf/2602.09792v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10170v1",
      "title": "Observing solar vortices with existing and future instrumentation. Solar Physics International Network for Swirls (SPINS) white paper (Helio)",
      "abstract": "Solar vortices are fundamental components of solar atmospheric dynamics, serving as natural laboratories for magnetic field twisting, energy concentration and transport, wave guidance, and plasma coupling across atmospheric layers. Numerical and observational studies show that solar vortices are intimately connected to key physical processes including magnetic reconnection, atmospheric heating, turbulence, and wave generation. This white paper, prepared for the UK Space Frontiers 2035 call, outline five high-priority scientific questions addressing vortex generation mechanisms, cross-layer coupling, magnetic restructuring, collective wave-guidance structures, and their role in triggering explosive events and modulating the solar wind. Key observations and capabilities required to make significant advancements over the coming decade are identified. The UK solar physics community has established world-leading expertise in vortex dynamics, combining strengths in high-resolution observations, MHD turbulence theory, numerical modelling, and space instrumentation. UK researchers have made foundational contributions to Solar Orbiter, delivered critical systems for DKIST, and maintain active involvement in MUSE and SOLAR-C EUVST missions. Our technical approach centres on developing next-generation instrumentation: a multi-band, space-qualified system employing four tunable Fabry-Pérot Interferometers providing diffraction-limited, high-cadence spectropolarimetric coverage from the deep photosphere to the low corona. This capability will be validated through a staged mission architecture beginning with balloon-borne demonstrators. Continuing this effort over the coming decade is vital to maintain UK leadership in this field and achieve the goals of roadmap for solar system research.",
      "authors": [
        "Suzana S. A. Silva",
        "Viktor Fedun",
        "Gary Verth",
        "Istvan Ballai",
        "Eamon Scullion",
        "Malcolm Druett",
        "Kostas Tziotziou",
        "Alex Pietrow",
        "Nitin Yadav",
        "Ioannis Dakanalis",
        "Elena Khomenko",
        "Hidetaka Kuniyoshi",
        "Shivdev Turkay",
        "Matias Koll Pistarini",
        "Robertus Erdelyi",
        "Luiz Augusto Camargo Aranha Schiavo"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.SR",
        "physics.space-ph"
      ],
      "published": "2026-02-10 13:55:23+00:00",
      "link": "https://arxiv.org/pdf/2602.10170v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09771v1",
      "title": "A large scale multi-modal workflow for battery characterization: from concept to implementation",
      "abstract": "The development of material acceleration platforms in battery research requires integrating complementary techniques and correlating heterogeneous experimental datasets. Here, this challenge is tackled in a large-scale multimodal program involving fifteen laboratories and facilities across Europe. Coordinated multi-site experiments are performed on state-of-the-art graphite / LiNiO2 Li-ion full cells to address two archetypal scientific questions: is the electrolyte composition impacting electrode properties, and how do electrode materials evolve when cells are cycled to their end-of-life? A fully standardized and centralized workflow is demonstrated, from sample production and delivery, to metadata and data handling, generating seventy-five concatenated datasets shared among all partners. Their integrated analysis shows that scientific conclusions depend critically on both the observable chosen to describe electrode properties, and the measurement technique employed. Individual experiments provide detailed information into specific aspects, such as crystal structures, redox activity, surface processes, morphology, etc., but can also function as binary diagnostic tool. Two-dimensional observable-technique patterns are introduced, in which each pixel encodes a yes, no or uncertain answer to a given scientific question. These patterns serve as multi-property metaviews, e.g. visual genotypes, enabling to classify material behavior and technique suitability according to predefined user demand and criteria, highlighting the interdependencies between measurement choices, extracted parameters and scientific interpretation. This multimodal workflow establishes a proof-of-concept for correlative analysis and underscores challenges toward fully integrated, automated and holistic approaches in energy material science.",
      "authors": [
        "François Cadiou",
        "Cinthya Herrera",
        "Duncan Atkins",
        "Elixabete Ayerbe",
        "Giorgio Baraldi",
        "Stéphanie Belin",
        "Anass Benayad",
        "Didier Blanchard",
        "Federico Capone",
        "Ennio Capria",
        "Isidora Cekic Laskovic",
        "Robert Dominko",
        "Kristina Edström",
        "Ajay Gautam",
        "Lukas Helfen",
        "Antonella Iadecola",
        "Quentin Jacquet",
        "Gregor Kapun",
        "Xinyu Li",
        "Aleksandar Matic",
        "Nataliia Mozhzhukhina",
        "Andrew J Naylor",
        "Poul Norby",
        "Chris O Keefe",
        "Alexandre Ponrouch",
        "Jean Pascal Rueff",
        "Elena Tchernykova",
        "Deyana Tchitchekova",
        "Israel Temprano",
        "Nikita Vostrov",
        "Marnix Wagemaker",
        "Martin Winter",
        "Christian Wölke",
        "Tejs Vegge",
        "Sandrine Lyonnard"
      ],
      "primary_category": "physics.app-ph",
      "categories": [
        "physics.app-ph"
      ],
      "published": "2026-02-10 13:30:11+00:00",
      "link": "https://arxiv.org/pdf/2602.09771v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09743v1",
      "title": "Testing Exotic Electron-Electron Interactions with the Helium Ionization-Energy Anomaly",
      "abstract": "Precision atomic spectroscopy provides a sensitive probe of physics beyond the Standard Model. A recently reported $9σ$ theory-experiment discrepancy in the ionization energy of metastable helium has motivated the hypothesis of a new boson mediating exotic electron-electron interactions. Using a model-independent sign-consistency analysis of the induced energy shifts, we show that the sign requirement alone excludes vector-vector and pseudoscalar-pseudoscalar interactions as possible explanations of the anomaly. Incorporating existing constraints together with improved limits obtained here further excludes axial-vector scenarios. Within the single-boson framework considered in this work, only a narrowly constrained scalar-mediated interaction remains viable. The remaining parameter space could be probed, for example, by modest improvements in the determination of the electron gyromagnetic ratio.",
      "authors": [
        "Lei Cong",
        "Filip Ficek",
        "Rinat Abdullin",
        "Mikhail G. Kozlov",
        "Dmitry Budker"
      ],
      "primary_category": "physics.atom-ph",
      "categories": [
        "physics.atom-ph"
      ],
      "published": "2026-02-10 12:54:33+00:00",
      "link": "https://arxiv.org/pdf/2602.09743v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09663v1",
      "title": "Global statistical entropy and its implications for the main sequences of stars and galaxies",
      "abstract": "In a dissipative system such as star or a galaxy, the emitted photons are decoupled from matter particles and may therefore be considered as part of a closed system to which the Second Law of Thermodynamics applies. In the present paper, we define a global entropy using a statistical approach that accounts for the contributions of both matter particles and photons. The statistical contribution of radiation is described as a photon gas in the definition of this global entropy. The increase in global entropy can foster structure formation -- rather than disorder -- because structures such as stars and galaxies are efficient at dissipating energy in the form of photons, and thus at producing entropy. We show that stars generate a nearly equal amount of specific entropy, and therefore a comparable number of photons per unit mass, over their lifetime on the main sequence of the Hertzsprung-Russell (HR) diagram. This suggests that the main sequence of the HR diagram constitutes a locus of convergence toward a universal specific entropy production by stars. We then examine the implications of this approach for the star-formation main sequence in galaxies, and find a similar result. The emergence of organized structures in cosmic history reflects the second law, as organized matter is efficient at generating entropy through the slicing of energy into lower-frequency photons. This is also reflected in the dominant contribution of low-frequency photons to the extragalactic background light. Finally, we briefly discuss how this perspective may inform us on the possibility of the existence of life elsewhere in the universe.",
      "authors": [
        "David Elbaz"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA",
        "physics.class-ph"
      ],
      "published": "2026-02-10 11:17:50+00:00",
      "link": "https://arxiv.org/pdf/2602.09663v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09647v1",
      "title": "Field-material coupled neural network: A novel prior-free and data-free inverse problem solver for extracting complex dielectric constant in terahertz band",
      "abstract": "Accurate extraction of the complex dielectric constant in the terahertz (THz) band is essential for material characterization and non-destructive evaluation yet remains challenging due to the ill-posed nature of electromagnetic inverse problems and the limited availability of reliable reference data. In this work, a field-material couple neural network (FMCNN) is proposed to retrieve the complex dielectric constant directly from THz measurements. The FMCNN consists of a field neural network and a material neural network that are strongly coupled through the frequency-domain Maxwell equations in the form of a Helmholtz equation, with the governing physics enforced by partial differential equation (PDE) and boundary condition constraints. This formulation enables prior-free and data-free inversion, requiring only measured test data as input. The extracted dielectric constants are validated by comparison with results from a one-dimensional normal-incidence model and the Drude-Lorentz model, showing good agreement over a broad frequency range, particularly above 0.2 THz. These results demonstrate that the FMCNN provides a physics-consistent and data-efficient approach for material parameter extraction in the THz band, offering an alternative to conventional model-based methods.",
      "authors": [
        "Pengfei Zhu",
        "Xavier Maldague"
      ],
      "primary_category": "physics.app-ph",
      "categories": [
        "physics.app-ph"
      ],
      "published": "2026-02-10 10:54:29+00:00",
      "link": "https://arxiv.org/pdf/2602.09647v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15050v1",
      "title": "Condensed Past, Thick Present: Evolutionary Approach to the Conscious Experience",
      "abstract": "This paper examines the conceptual convergence between Lee Smolin's Causal Theory of Views, Karl Friston's Free Energy Principle, and contemporary psychological accounts of the functions of consciousness. Although formulated within different domains -- physics, biology, and psychology -- all three frameworks, in one form or another, appeal to processes of transition from uncertainty to certainty, in which novelty arises through the resolution of surprise. According to the first two approaches, these transitions are realized within particular temporo-spatial gaps, which themselves evolve and become increasingly elaborate as organization grows. By tracing the structural and functional parallels between these frameworks, the paper proposes an account of how the evolution and the gradual elaboration of novelty, surprise, and these temporo-spatial gaps may be linked to the emergence and progressive development of consciousness, up to its highest forms addressed by psychology.",
      "authors": [
        "Anna Sverdlik"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph"
      ],
      "published": "2026-02-10 10:53:34+00:00",
      "link": "https://arxiv.org/pdf/2602.15050v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09550v1",
      "title": "From Search to GenAI Queries: Global Trends in Physics Information-Seeking Across Topics and Regions",
      "abstract": "The emergence of generative artificial intelligence (GenAI) marks a potential inflection point in the way academic information is accessed, raising fundamental questions about the evolving role of search in student learning. This study examines this shift by analyzing longitudinal trends in physics-related search and page-view activity, using declines in traditional search behavior as a quantitative proxy for changes in independent information-seeking practices. We analyze Google Trends data for core concepts in Classical Mechanics and Electromagnetism across three academic years (2022-2025) in more than 20 countries, and complement this analysis with Wikipedia page-view data across seven major languages to establish platform independence. The results reveal a substantial, systematic, and persistent global decline in search and page-view activity across most examined physics topics. The magnitude of this decline is domain-dependent, with Mechanics-related content exhibiting sharper and more consistent reductions than Electromagnetism-related content. Pronounced geographic and linguistic heterogeneity is observed: while English-speaking regions show relative stability or only moderate declines, non-English-speaking regions exhibit substantially larger reductions in traditional, search-based information-seeking activity. Despite the overall decrease in volume, the seasonal structure characteristic of academic activity remains robust. Taken together, these findings indicate a redistribution of physics-related information-seeking behavior in academic contexts where generative tools are increasingly available.",
      "authors": [
        "Yossi Ben-Zion",
        "Omer Michaeli",
        "Noah D. Finkelstein"
      ],
      "primary_category": "physics.ed-ph",
      "categories": [
        "physics.ed-ph"
      ],
      "published": "2026-02-10 08:57:55+00:00",
      "link": "https://arxiv.org/pdf/2602.09550v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09519v1",
      "title": "Multimode fiber laser cavities as nonlinear optical processors",
      "abstract": "Optical computing provides a promising path toward energy-efficient machine learning, yet implementing nonlinear transformations without complex electronics or high-power sources remains challenging. Here, we demonstrate that continuous-wave multimode fiber laser cavities can function as nonlinear optical processors. Input images encoded as phase patterns on a spatial light modulator undergo high-dimensional transformation through the interplay of multimode interference and gain saturation dynamics. The cavity maps input data into spatially stable, class-separable intensity distributions, enabling a simple linear classifier to achieve accuracies of 85--99\\% across diverse benchmarks -- including medical imaging and remote sensing -- with orders of magnitude fewer trainable parameters than deep neural networks. Our results establish multimode fiber lasers as compact, low-power physical processors for scalable optical machine learning.",
      "authors": [
        "Dilem Eşlik",
        "Bahadır Utku Kesgin",
        "Fatma Nur Kılınç",
        "Uğur Teğin"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-02-10 08:23:02+00:00",
      "link": "https://arxiv.org/pdf/2602.09519v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09459v1",
      "title": "Fully programmable slow light based on a spinor representation of generalized coupled-resonator-induced transparency",
      "abstract": "Electromagnetically induced transparency (EIT), arising from quantum interference in coherently driven atomic systems, has inspired a variety of photonic analogues, such as coupled-resonator-induced transparency (CRIT) built on the quantum-state modelling using resonators. Although CRIT serves as a building block for slow light in photonic integrated circuits, recent advances in topological photonics motivate a further generalization of both EIT and CRIT using gauge-field degrees of freedom. Here, we propose generalized CRIT via a spinor representation with dual-channel gauge fields, enabling fully programmable CRIT featuring dynamical spectral engineering. We generalize the traditional EIT framework by introducing a spinor representation of bright- and dark-mode resonances, yielding a unified description of design parameters through universal unitary operations. Implementing a coupled-resonator building block that accesses the entire design space through dual-channel gauge fields, we demonstrate a programmable slow-light band in a one-dimensional CRIT lattice. These results address urgent needs in optical interconnects, such as tunable delay lines, reconfigurable synchronization, and linear frequency conversion.",
      "authors": [
        "Seungkyun Park",
        "Beomjoon Chae",
        "Hyungchul Park",
        "Sunkyu Yu",
        "Xianji Piao",
        "Namkyoo Park"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-02-10 06:52:37+00:00",
      "link": "https://arxiv.org/pdf/2602.09459v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09458v1",
      "title": "Non-Hermitian stealthy hyperuniformity",
      "abstract": "Symmetry-driven wave physics in open systems, exemplified by parity-time (PT) symmetry, has extended the landscape of crystalline phases in materials science to include gain-loss media. Given the growing interest in engineering disorder for wave manipulation, such non-Hermitian crystals motivate the extension of non-Hermitian frameworks into the realm of correlated disorder. Here, we propose hyperuniformity and stealthiness in non-Hermitian systems as a generalization of PT-symmetric crystals to correlated disorder. We extend the scattering-microstructure correspondence to open systems, formulating non-Hermitian hyperuniformity and stealthiness that encompass their Hermitian counterparts. This approach, incorporating a statistical crystallography framework for non-Hermitian materials, demonstrates that real-imaginary cross-correlations of the material potential are irrelevant for achieving hyperuniformity but are essential for characterizing stealthiness, revealing unidirectional scattering phases that are inaccessible in Hermitian materials and in non-Hermitian crystals. By analysing the microstructural statistics of the resulting materials, our results, building on non-Hermitian wave physics, establish a connection to materials science, encompassing conventional descriptors of correlated disorder.",
      "authors": [
        "Gitae Lee",
        "Seungmok Youn",
        "Ikbeom Lee",
        "Kunwoo Park",
        "Duhwan Hwang",
        "Xianji Piao",
        "Namkyoo Park",
        "Sunkyu Yu"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-10 06:46:07+00:00",
      "link": "https://arxiv.org/pdf/2602.09458v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09409v1",
      "title": "A theoretical one-dimensional model for variable-density Rayleigh-Taylor turbulence",
      "abstract": "In an early theoretical work published in 1965, Belen'kii & Fradkin proposed a turbulent diffusivity model for Rayleigh--Taylor (RT) mixing. We review its derivation and present alternative arguments leading to the same final similarity equation. The original work then introduced an approximation that led to a simplified ordinary differential equation (ODE), which was used primarily to derive the important scaling result, $h \\sim (\\ln R)gt^2$. Here, we extend the analysis by examining the solutions to both the full similarity ODE and the simplified ODE in detail. It is shown that the full similarity equation captures many now well-known features of non-Boussinesq RT flows, including asymmetric spike and bubble growth and a systematic shift of velocity statistics toward the light-fluid side. Comparisons of the theoretical model with numerical and experimental studies show reasonable agreement in both spatial profiles and growth trends of mixing layer heights. We further show that a global mass correction applied to the simplified solution closely approximates the full solution, highlighting that, to leading order, RT mixing is governed by the competing dynamics between diffusion of $\\ln \\barρ$ and mass conservation.",
      "authors": [
        "Chian Yeh Goh",
        "Guillaume Blanquart"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-02-10 04:54:39+00:00",
      "link": "https://arxiv.org/pdf/2602.09409v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09397v1",
      "title": "Historical Debates over the Physical Reality of the Wave Function",
      "abstract": "This paper provides a detailed historical account of early debates over wave-function realism, the modern term for the view that the wave function of quantum theory is physically real. As this paper will show, the idea of physical waves associated with particles had its roots in work by Einstein and de Broglie, who both originally thought of these waves as propagating in three-dimensional physical space. De Broglie quickly turned this wave-particle duality into an early pilot-wave theory, on which a particle's associated phase wave piloted or guided the particle along its trajectory. Schrödinger built on de Broglie's phase-wave hypothesis to provide a comprehensive account of the nascent quantum theory. However, Schrödinger's new undulatory mechanics came at the cost of replacing de Broglie's phase waves propagating in physical space with a wave function propagating in a system's abstract configuration space. The present work will argue that this move from three-dimensional physical space to a many-dimensional configuration space was a key reason why the founders of quantum theory uniformly abandoned the physical reality of the wave function. This paper will further clarify that de Broglie introduced two distinct pilot-wave theories, and will then argue that it was Bohm's rediscovery of the second of these two pilot-wave theories over two decades later, as well as Bohm's vociferous defense of wave-function realism, that were responsible for resurrecting the idea of an ontological wave function. This idea ended up playing a central role in Everett's development of the many-worlds interpretation.",
      "authors": [
        "Jacob A. Barandes"
      ],
      "primary_category": "physics.hist-ph",
      "categories": [
        "physics.hist-ph",
        "quant-ph"
      ],
      "published": "2026-02-10 04:06:35+00:00",
      "link": "https://arxiv.org/pdf/2602.09397v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09330v1",
      "title": "Revealing Gauge Constraints in LQG-Inspired Yang-Mills Theory",
      "abstract": "The consistent embedding of Loop Quantum Gravity (LQG) effects within the Standard Model requires a rigorous understanding of how Planck-scale deformations manifest at low energies. While phenomenological approaches often introduce canonical deformations with multiple free parameters to capture these effects, the physical requirement of gauge symmetry in the framework of a covariant Effective Field Theory (EFT) imposes strict conditions on the allowed interaction structure. In this paper, we demonstrate that these conditions act as physical selection rules for admissible quantum gravity models. By applying non-Abelian Ward identities and a covariant operator mapping to the dimension-six operator basis, we derive a fundamental on-shell equivalence between kinetic and cubic interaction terms. As a paradigmatic application, we show that the Levy-Helayel-Neto (LHN) framework, a candidate effective description of LQG, satisfies this physical requirement only when its parameters obey the specific algebraic relation: theta_3 / theta_8 = -1/2 * [ 1 + theta_7 * (ell_P / L)^(2 + 2 Upsilon) ] + O(ell_P). It must be highlighted that this result advances the physical understanding of LQG phenomenology by revealing that the apparent freedom in defining the Hamiltonian is illusory; the parameters are bound by the necessity of preserving the gauge structure of the Standard Model.",
      "authors": [
        "Leonardo P. G. De Assis"
      ],
      "primary_category": "physics.gen-ph",
      "categories": [
        "physics.gen-ph"
      ],
      "published": "2026-02-10 01:53:47+00:00",
      "link": "https://arxiv.org/pdf/2602.09330v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09266v1",
      "title": "Solitary waves of moderate amplitude in the SSGGN equations: the extended KdV-Whitham approximation",
      "abstract": "We consider the extended Korteweg-de Vries (eKdV) equation as a model for long moderately nonlinear surface water waves. In the slow time formulation this equation generates fast propagating resonant radiation due to the non-convexity of its linear dispersion curve, which is not present in the strongly nonlinear Serre-Su-Gardner-Green-Naghdi (SSGGN) parent system. We show that the extended KdV-Whitham approximation and the slow space formulation of the eKdV equation are suitable regularisations of the eKdV equation in several cases of interest, and even for moderate amplitudes. Numerical comparisons are made between the SSGGN system and the respective reduced models, where simulations are initiated with an approximate soliton solution of the eKdV equation, constructed by use of Kodama-Fokas-Liu near-identity transformation to the KdV equation.",
      "authors": [
        "Benjamin Martin",
        "Dmitri Tseluiko",
        "Karima Khusnutdinova"
      ],
      "primary_category": "nlin.PS",
      "categories": [
        "nlin.PS",
        "physics.flu-dyn"
      ],
      "published": "2026-02-09 23:02:33+00:00",
      "link": "https://arxiv.org/pdf/2602.09266v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16668v1",
      "title": "Operator based propagation of Whittaker and Helmholtz Gauss beams",
      "abstract": "We introduce a compact operator-based technique that solves the paraxial wave equation for a broad class of structured light fields. Using the spatial evolution operator to propagate two families of physically apodized inputs, Gaussian apodized Whittaker integrals and Gaussian apodized Helmholtz fields, we derive closed form expressions that retain the Gaussian width and therefore describe finite energy beams. The method unifies and extends the Helmholtz Gauss families and readily generalizes to nonseparable nondiffracting architectures. Experiments on superposed Bessel Gauss beams confirm the predicted transverse rotations, demonstrating that this operator approach is a fast, transparent, and practical alternative to standard diffraction ntegral treatments",
      "authors": [
        "M. A. Jacome Silva",
        "I. Julian Macias",
        "F. Soto Eguibar",
        "U. Ruiz Corona",
        "I. Ramos Prieto",
        "D. Sanchez de la Llave",
        "H. M. Moya Cessa"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-02-18 18:08:25+00:00",
      "link": "https://arxiv.org/pdf/2602.16668v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16665v1",
      "title": "Optimizing p-spin models through hypergraph neural networks and deep reinforcement learning",
      "abstract": "p-spin glasses, characterized by frustrated many-body interactions beyond the conventional pairwise case (p>2), are prototypical disordered systems whose ground-state search is NP-hard and computationally prohibitive for large instances. Solving this problem is not only fundamental for understanding high-order disorder, structural glasses, and topological phases, but also central to a wide spectrum of hard combinatorial optimization tasks. Despite decades of progress, there still lacks an efficient and scalable solver for generic large-scale p-spin models. Here we introduce PLANCK, a physics-inspired deep reinforcement learning framework built on hypergraph neural networks. PLANCK directly optimizes arbitrary high-order interactions, and systematically exploits gauge symmetry throughout both training and inference. Trained exclusively on small synthetic instances, PLANCK exhibits strong zero-shot generalization to systems orders of magnitude larger, and consistently outperforms state-of-the-art thermal annealing methods across all tested structural topologies and coupling distributions. Moreover, without any modification, PLANCK achieves near-optimal solutions for a broad class of NP-hard combinatorial problems, including random k-XORSAT, hypergraph max-cut, and conventional max-cut. The presented framework provides a physics-inspired algorithmic paradigm that bridges statistical mechanics and reinforcement learning. The symmetry-aware design not only advances the tractable frontiers of high-order disordered systems, but also opens a promising avenue for machine-learning-based solvers to tackle previously intractable combinatorial optimization challenges.",
      "authors": [
        "Li Zeng",
        "Mutian Shen",
        "Tianle Pu",
        "Zohar Nussinov",
        "Qing Feng",
        "Chao Chen",
        "Zhong Liu",
        "Changjun Fan"
      ],
      "primary_category": "cond-mat.dis-nn",
      "categories": [
        "cond-mat.dis-nn",
        "physics.comp-ph"
      ],
      "published": "2026-02-18 18:05:19+00:00",
      "link": "https://arxiv.org/pdf/2602.16665v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16645v1",
      "title": "Ultracold atoms in a dipole trap in microgravity",
      "abstract": "Most cold atoms experiments in microgravity platforms or in Space are achieved using atom chips, leading to limitations in terms of optical access and inhomogeneous magnetic fields. Optical dipole traps do not have these drawbacks but have difficulties producing atomic samples with a large number of atoms at ultra low temperature in the absence of gravity. Here, we report on an efficient evaporative cooling in two-crossed laser beams during parabolic flights. Time-averaged potentials combine the advantages of large capture volume and trap compression, increasing the initial phase space density and collision rate to favor the evaporative process. With this technique we demonstrate the production of an ultra cold gas of $2.5\\times 10^4$ rubidium atoms at a temperature below 100 nK in less than 4 seconds. Our experiment paves the way for the development of quantum sensors applied to fundamental physics and geodesy as well as the study of ultracold atomic physics in Space.",
      "authors": [
        "Julien Le Mener",
        "Clement Metayer",
        "Vincent Jarlaud",
        "Celia Pelluet",
        "Baptiste Battelier"
      ],
      "primary_category": "physics.atom-ph",
      "categories": [
        "physics.atom-ph"
      ],
      "published": "2026-02-18 17:35:11+00:00",
      "link": "https://arxiv.org/pdf/2602.16645v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16617v1",
      "title": "Fluctuation-induced acceleration of inter-ligand exciton transfer in bis(dipyrrinato)Zn(II) complex",
      "abstract": "Exciton transfer dynamics between chromophores depends on excitonic coupling, which is governed by relative orientation between the chromophores. While the excitonic coupling is treated as a static parameter in many cases, structural dynamics can introduce time-dependence on the excitonic coupling. However, influence of the dynamics of excitonic coupling on the exciton transfer has been scarcely understood. In the present study, exciton transfer under dynamical fluctuation in excitonic coupling was investigated via combined use of non-adiabatic molecular dynamics simulations, exciton density analysis, and a simple two-state model, for inter-ligand exciton transfer in bis(dipyrrinato)Zn(II) as the example case. The reaction coordinate for the exciton transfer was obtained a posteriori via regression analysis where the target and explanatory variables are diabatic energy gaps and atomic displacements, respectively. The results suggest that dynamical angular fluctuation between the two dipyrrinato ligands incidentally increase the excitonic coupling, accelerating the exciton transfer between the ligands.",
      "authors": [
        "Hiroki Uratani",
        "Hirofumi Sato"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph"
      ],
      "published": "2026-02-18 17:09:36+00:00",
      "link": "https://arxiv.org/pdf/2602.16617v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16515v1",
      "title": "Generative deep learning improves reconstruction of global historical climate records",
      "abstract": "Accurate assessment of anthropogenic climate change relies on historical instrumental data, yet observations from the early 20th century are sparse, fragmented, and uncertain. Conventional reconstructions rely on disparate statistical interpolation, which excessively smooths local features and creates unphysical artifacts, leading to systematic underestimation of intrinsic variability and extremes. Here, we present a unified, probabilistic generative deep learning framework that overcomes these limitations and reveals previously unresolved historical climate variability back to 1850. Leveraging a learned generative prior of Earth system dynamics, our model performs probabilistic inference to recover spatiotemporally consistent historical temperature and precipitation fields from sparse observations. Our approach preserves the higher-order statistics of climate dynamics, transforming reconstruction into a robust uncertainty-aware assessment. We demonstrate that our reconstruction overcomes pronounced biases in widely used historical reference products, including those underlying IPCC assessments, especially regarding extreme weather events. Notably, we uncover higher early 20th-century global warming levels compared to existing reconstructions, primarily driven by more pronounced polar warming, with mean Arctic warming trends exceeding established benchmarks by 0.15--0.29°C per decade for 1900--1980. Conversely, for the modern era, our reconstruction indicates that the broad Arctic warming trend is likely overestimated in recent assessments, yet explicitly resolves previously unrecognized intense, localized hotspots in the Barents Sea and Northeastern Greenland. Furthermore, based on our seamless global reconstruction that recovers precipitation variability across the oceans and under-monitored regions, we uncover an intensification of the global hydrological cycle.",
      "authors": [
        "Zhen Qian",
        "Teng Liu",
        "Sebastian Bathiany",
        "Shangshang Yang",
        "Philipp Hess",
        "Nils Bochow",
        "Christian Burmester",
        "Maximilian Gelbrecht",
        "Brian Groenke",
        "Niklas Boers"
      ],
      "primary_category": "physics.geo-ph",
      "categories": [
        "physics.geo-ph"
      ],
      "published": "2026-02-18 15:03:26+00:00",
      "link": "https://arxiv.org/pdf/2602.16515v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16461v1",
      "title": "An Integrated Ultralow Noise Spiral Interferometric Laser",
      "abstract": "Photonic integration offers the potential to bring complex high-performance optical systems to the form factor of a compact semiconductor chip. However, the range of system functions accessible critically depends on the extent to which free-space and fiber components can be made integrable. The ultralow-expansion cavity-stabilized laser$-$often used in precision metrology, high-resolution sensors, and advanced systems in atomic physics$-$is one component that currently has no direct parallel on chip. Lasers stabilized to photonically-integrated resonators exist, but exhibit considerably higher frequency noise and are accompanied by large levels of frequency drift. We demonstrate here a new architecture for an ultranarrow linewidth integrated laser based on stabilization to a sinusoidal fringe of an interferometer having a long 25-m unbalanced delay line. Our interferometric laser not only advances the state-of-the-art for on-chip lasers, but we in addition introduce an amplitude locking scheme that greatly suppresses the laser's long-term frequency wander. We achieve a record on-chip fractional frequency noise of $5.6 \\times 10^{-14}$, corresponding to a linewidth of 12 Hz centered at 1348 nm. To showcase the utility of this laser, we divide the optical carrier to microwave frequencies, demonstrating the ability to outperform state-of-the-art quartz crystal oscillators by 15 dB or more.",
      "authors": [
        "William Loh",
        "David Reens",
        "Dave Kharas",
        "Alkesh Sumant",
        "Connor Belanger",
        "Eli Briskin",
        "Dodd Gray",
        "Alexander Medeiros",
        "Ryan T. Maxson",
        "William Setzer",
        "Ethan Clements",
        "Wonseok Shin",
        "Paul W. Juodawlkis",
        "Cheryl Sorace-Agaskar",
        "Siva Yegnanarayanan",
        "Danielle Braje",
        "Robert McConnell"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-02-18 13:48:06+00:00",
      "link": "https://arxiv.org/pdf/2602.16461v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16420v1",
      "title": "Combined dynamic-kinematic validation of droplet-wall impact modeling",
      "abstract": "Many numerical studies validate droplet wall impact using only maximum spreading diameter, yet this metric alone cannot ensure correct droplet dynamics. We present a combined dynamic contact angle (DCA) model that merges the geometric accuracy of the generalized Hoffman-Voinov-Tanner law with the kinematic consistency of a Hoffman function-based approach, improving predictions of droplet spreading and receding. We simulate water-glycerol droplet impact on sapphire glass at Weber numbers 20 -- 250 and assess both contact angle formulations. Simulated radial velocity fields are processed in Python using SciPy and compared with Particle Image Velocimetry measurements in the longitudinal section of the spreading droplet. The Hoffman function-based model captures the main droplet kinematic trends and provides more consistent receding dynamics. The generalized Hoffman-Voinov-Tanner law matches the maximum spreading diameter within 7%. However, during receding, it shows a median absolute error in radial velocity up to three times higher than that of the Hoffman function-based solution. Average radial velocity and spreading velocity can differ from experimental trends even when maximum spreading is reproduced. These findings support validation combining geometric and kinematic metrics and motivate the combined model for predicting spreading and receding. Using the maximum spreading factor $β_{max}$ as the ratio of the maximum spreading diameter over the initial droplet diameter and the characteristic capillary number $Ca_{char}$ defined from the mean internal horizontal velocity at 300 micrometer above the substrate, we introduce a $(β_{max},\\,Ca_{char})$ diagram to relate spreading characteristics to internal flow dynamics. We hypothesize that, given sufficient data, the contact-line geometry may be used to estimate internal kinematics.",
      "authors": [
        "Dmitry Zharikov",
        "Maxim Piskunov",
        "Dmitry Kolomenskiy"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "physics.comp-ph"
      ],
      "published": "2026-02-18 12:51:06+00:00",
      "link": "https://arxiv.org/pdf/2602.16420v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16417v1",
      "title": "Network geometry of the Drosophila brain",
      "abstract": "The recent reconstruction of the Drosophila brain provides a neural network of unprecedented size and level of details. In this work, we study the geometrical properties of this system by applying network embedding techniques to the graph of synaptic connections. Since previous analysis have revealed an inhomogeneous degree distribution, we first employ a hyperbolic embedding approach that maps the neural network onto a point cloud in the two-dimensional hyperbolic space. In general, hyperbolic embedding methods exploit the exponentially growing volume of hyperbolic space with increasing distance from the origin, allowing for an approximately uniform spatial distribution of nodes even in scale-free, small-world networks. By evaluating multiple embedding quality metrics, we find that the network structure is well captured by the resulting two-dimensional hyperbolic embedding, and in fact is more congruent with this representation than with the original neuron coordinates in three-dimensional Euclidean space. In order to examine the network geometry in a broader context, we also apply the well-known Euclidean network embedding approach Node2vec, where the dimension of the embedding space, $d$ can be set arbitrarily. In 3 dimensions, the Euclidean embedding of the network yields lower quality scores compared to the original neuron coordinates. However, as a function of the embedding dimension the scores show an improving tendency, surpassing the level of the 2d hyperbolic embedding roughly at $d=16$, and reaching a maximum around $d=64$. Since network embeddings can serve as valuable inputs for a variety of downstream machine learning tasks, our results offer new perspectives on the structure and representation of this recently revealed and biologically significant neural network.",
      "authors": [
        "Bendegúz Sulyok",
        "Sámuel G. Balogh",
        "Gergely Palla"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph"
      ],
      "published": "2026-02-18 12:48:58+00:00",
      "link": "https://arxiv.org/pdf/2602.16417v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16390v1",
      "title": "Hidden universality in dislocation-loops mediated three-dimensional crystal melting",
      "abstract": "Understanding why and how crystalline solids melt remains a central problem in condensed-matter physics. Dislocation loops are fundamental topological excitations that control the thermodynamic stability of crystals, yet their role in setting universal aspects of melting has remained unclear. Here we show, within dislocation-mediated melting theory, that the free-energy condition for loop proliferation leads to a universal ratio between the energy of a minimal dislocation loop and the thermal energy at melting. For minimal dislocation loops that begin to proliferate at the onset of melting, this ratio takes the purely geometric value $\\mathcal{E}_* = E_{\\rm loop}/(k_B T_m) \\approx 25.1$, independent of elastic moduli and chemistry-dependent details. This result provides a microscopic explanation for recent empirical findings by Lunkenheimer \\emph{et al.}, who identified a closely related universal energy scale $\\approx 24.6$ from viscosity data. The same framework also rationalizes the empirical $2/3$ rule relating the glass-transition and melting temperatures.",
      "authors": [
        "Alessio Zaccone",
        "Konrad Samwer"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.dis-nn",
        "cond-mat.soft",
        "cond-mat.stat-mech",
        "physics.chem-ph"
      ],
      "published": "2026-02-18 11:56:45+00:00",
      "link": "https://arxiv.org/pdf/2602.16390v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16297v1",
      "title": "Characterization of an MPPC-Based Scintillator Telescope and Measurement of Cosmic Muon Angular Distribution",
      "abstract": "This report presents the design, characterization, and application of a high-sensitivity optical detection system based on plastic scintillators coupled to Multi-Pixel Photon Counters (MPPCs). The primary objective was to evaluate the performance of MPPCs (Silicon Photomultipliers) as robust, low-voltage alternatives to traditional photomultiplier tubes for detecting faint scintillation light. The optoelectronic properties of the sensors were analyzed, including single-photoelectron gain calibration and dark count rate measurements, to optimize the signal-to-noise ratio. By embedding wavelength-shifting fibers to enhance light collection efficiency, the system was configured into a three-fold coincidence telescope. The angular distribution of the cosmic ray muon flux was measured to validate the detector's stability and geometric acceptance. Fitting the experimental data to a $\\bm{\\cos^n(θ)}$ distribution yielded an angular exponent of $\\bm{n = 1.44 \\pm 0.06}$, consistent with literature values. These results demonstrate the efficacy of the MPPC-scintillator coupling for precise photon counting and timing applications in high-energy physics instrumentation.",
      "authors": [
        "Sahla Manithottathil",
        "Anuj Gupta",
        "Mudit Kumar",
        "Navaneeth Poonthottathil"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det",
        "astro-ph.IM",
        "hep-ex"
      ],
      "published": "2026-02-18 09:27:39+00:00",
      "link": "https://arxiv.org/pdf/2602.16297v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16247v1",
      "title": "Breaking the Moss rule",
      "abstract": "Photonic devices depend critically on the dielectric materials from which they are made, with higher refractive indices and lower absorption losses enabling new functionalities and higher performance. However, these two material properties are intrinsically linked through the empirical Moss rule, which states that the refractive index of a dielectric decreases as its band gap energy increases. Materials that surpass this rule, termed super-Mossian dielectrics, combine large refractive indices with wide optical transparency and are therefore ideal candidates for advanced photonic applications. This Review surveys the expanding landscape of high-index dielectric and semiconductor materials, with a particular focus on those that surpass the Moss rule. We discuss how electronic band structures with a large joint density of states near the band edge give rise to super-Mossian behavior and how first-principles computational screening can accelerate their discovery. Finally, we establish how the refractive index sets the performance limits of nanoresonators, waveguides, and metasurfaces, highlighting super-Mossian dielectrics as a promising route toward the next performance leap in photonic technologies.",
      "authors": [
        "Søren Raza",
        "Kristian Sommer Thygesen",
        "Gururaj Naik"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics",
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-18 07:55:46+00:00",
      "link": "https://arxiv.org/pdf/2602.16247v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16081v1",
      "title": "Non-local physics-informed neural networks for forward and inverse solutions of granular flows",
      "abstract": "Dense granular flows exhibit nonlocal effects due to stress transmission in microplastic events, especially in quasi-static or slowly sheared regions. Hence, traditional local rheological models fail to capture spatial cooperativity effects that are prominent in many granular systems. The nonlocal granular fluidity (NGF) model addresses this limitation by introducing a diffusive-like partial differential equation for a fluidity field, governed by a key material-dependent parameter: the nonlocal amplitude A. However, determining A from experiments or simulations is known to be difficult and typically requires extensive calibration across multiple geometries. In this work, we present a data-driven platform based on Physics-Informed Neural Networks (PINNs) embedded with the NGF model, capable of solving granular flows in a forward or inverse manner. We show that once trained on transient flow fields, these non-local PINNs can readily infer the material parameters, as well as the pressure and stress fields. These data-driven frameworks allow for accurate recovery of small variations in the nonlocal amplitude, A, which lead to sharp bifurcation-like transitions in the flow field. This approach demonstrates the feasibility of data-driven parameter inference in complex nonlocal models and opens up new possibilities for characterizing granular materials from sparse experimental observations.",
      "authors": [
        "Saghar Zolfaghari",
        "Safa Jamali"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft",
        "cond-mat.dis-nn",
        "physics.flu-dyn"
      ],
      "published": "2026-02-17 23:13:54+00:00",
      "link": "https://arxiv.org/pdf/2602.16081v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16044v1",
      "title": "Multi-Objective Evolutionary Design of Molecules with Enhanced Nonlinear Optical Properties",
      "abstract": "Nonlinear optical (NLO) materials are essential for many photonic, telecommunication, and laser technologies, yet discovering better NLO molecules is computationally challenging due to the vast chemical space and competing objectives. We compare evolutionary algorithms for molecular design, targeting four objectives: maximizing the ratio of first-to-second hyperpolarizability $(β/γ)$, optimizing HOMO-LUMO gap and linear polarizability to target ranges, and minimizing energy per atom. We encode molecules as SMILES strings and evaluate their properties using quantum-chemical calculations. We compare NSGA-II, MAP-Elites, MOME, a single-objective $(μ+λ)$ evolutionary algorithm, and simulated annealing. Quality diversity methods maintain archives across a measure space defined by atom and bond count, enabling the discovery of structurally diverse molecules. Our results demonstrate that NSGA-II consistently earns high scores in every objective, leading to high-quality molecules, but MOME does a better job exploring a wide range of possibilities, resulting in higher global hypervolume and MOQD scores. However, each method has strengths and weaknesses, and produced many promising molecules.",
      "authors": [
        "Dominic Mashak",
        "Jacob Schrum",
        "S. A. Alexander"
      ],
      "primary_category": "physics.comp-ph",
      "categories": [
        "physics.comp-ph"
      ],
      "published": "2026-02-17 21:55:24+00:00",
      "link": "https://arxiv.org/pdf/2602.16044v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16002v1",
      "title": "The Beauty of Mathematics in Helfrich's Biomembrane Theory",
      "abstract": "It is with great regret that Prof. Wolfgang Helfrich passed away on 28 September 2025 in Berlin. As the founder of the membrane liquid crystal model, Prof. Helfrich made outstanding contributions to membrane physics and liquid crystal display technology. This review article is written in his memory. Biomembranes, primarily composed of lipid bilayers, are not merely passive barriers but dynamic and complex materials whose shapes are governed by the principles of soft matter physics. This review explores the shape problem in biomembranes through the lens of material science and liquid crystal theory. Beginning with classical analogies to crystals and soap bubbles, it details the application of the Helfrich elastic model to explain the biconcave shape of red blood cells. The discussion extends to multi-layer systems, drawing parallels between the focal conic structures of smectic liquid crystals, the geometries of fullerenes and carbon nanotubes, and the reversible transitions in peptide assemblies. Furthermore, it examines icosahedral self-assemblies and shape formation in two-dimensional lipid monolayers at air/water interfaces. At the end of the paper, we find that the shapes such as cylinders, spheres, tori, bicocave discoids and Delaunay surfaces form a group. This result is merely an intrinsic geometric feature of these shapes and is independent of the biomembrane equation. When the pressure on the membrane, surface tension, and bending modules meet certain conditions, the biomembrane will take on these shapes. The review concludes by highlighting the unifying power of continuum elastic theories in describing a vast array of membrane morphologies across biological and synthetic systems.",
      "authors": [
        "Tao Xu",
        "Zhong-Can Ou-Yang"
      ],
      "primary_category": "physics.comp-ph",
      "categories": [
        "physics.comp-ph",
        "physics.bio-ph"
      ],
      "published": "2026-02-17 20:47:27+00:00",
      "link": "https://arxiv.org/pdf/2602.16002v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15993v1",
      "title": "An Interpretable Physics Informed Multi-Stream Deep Learning Architecture for the Discrimination between Earthquake, Quarry Blast and Noise",
      "abstract": "The reliable discrimination of tectonic earthquakes from anthropogenic quarry blasts and transient noise remains a critical challenge in single station seismic monitoring. In this study, we introduce a novel Physics Informed Convolutional Recurrent Neural Network (PI CRNN) that embeds seismological domain knowledge directly into the feature extraction and learning process. We adapt a multistream architecture with three parallel encoders: (i) Time Domain: SincNet Encoder, (ii) MultiResolution Spectrogram branch, and, (iii) Physics Branch, followed by a fusion and a bidirectionalLSTM module. Evaluated on the Curated Pacific Northwest AI ready Seismic Dataset, the PI CRNN achieves an overall classification accuracy of 97.56 percent on an independent test set. It outperforms a standard CRNN baseline, a classical P to S amplitude ratio method, and a Physics Informed Neural Network (PINN) that enforces physical constraints via the loss function. Furthermore, the model demonstrates perfect precision in noise rejection (100 percent Recall). Interpretability analysis using saliency maps confirms that the architecture successfully learns distinct physical signatures, identifying bimodal P- and S-wave arrivals for earthquakes versus singular impulsive onsets for blasts. This work establishes a scalable, transparent framework for AI-driven seismology, proving that architectural inductive bias provides an alternative reliable approach compared to purely data-driven approaches.",
      "authors": [
        "Nishtha Srivastava",
        "Johannes Faber",
        "Dhruv Aditya Srivastava"
      ],
      "primary_category": "physics.geo-ph",
      "categories": [
        "physics.geo-ph"
      ],
      "published": "2026-02-17 20:30:05+00:00",
      "link": "https://arxiv.org/pdf/2602.15993v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15992v1",
      "title": "Properties of a compact neutron supermirror transmission polarizer with an electromagnetic system",
      "abstract": "The paper will present SVAROG, a compact neutron supermirror transmission multichannel polarizer with an electromagnetic system. The basic properties of this polarizer will be considered. Variants for using this polarizer in experimenrtla facilities of the PIK research reactor (Petersburg Nuclear Physics Institute of National Research Centre «Kurchatov Institute» (NRC «Kurchatov Institute» - PNPI)) will be discussed and a comparison of the considered polarizer with known neutron transmission polarizers will be carried out.",
      "authors": [
        "V. G. Syromyatnikov",
        "S. Yu. Semenikhin",
        "M. V. Lasitsa"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det",
        "nucl-ex",
        "physics.acc-ph"
      ],
      "published": "2026-02-17 20:29:09+00:00",
      "link": "https://arxiv.org/pdf/2602.15992v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15990v1",
      "title": "Memristive tabular variational autoencoder for compression of analog data in high energy physics",
      "abstract": "We present an implementation of edge AI to compress data on an in-memory analog content-addressable memory (ACAM) device. A variational autoencoder is trained on a simulated sample of energy measurements from incident high-energy electrons on a generic three-layer scintillator-based calorimeter. The encoding part is distilled into tabular format by regressing the latent space variables using decision trees, which is then programmed on a memristor-based ACAM. In real-time, the ACAM compresses 48 continuously valued incoming energies measured by the calorimeter sensors into the latent space, achieving a compression factor of 12x, which is transmitted off-detector for decompression. The performance result of the ACAM, obtained using the Structural Simulation Toolkit, the SST open source framework, gives a latency value of 24 ns and a throughput of 330M compressions per second, i.e., 3 ns between successive inputs, and an average energy consumption of 4.1 nJ per compression.",
      "authors": [
        "Rajat Gupta",
        "Yuvaraj Elangovan",
        "Tae Min Hong",
        "James Ignowski",
        "John Moon",
        "Aishwarya Natarajan",
        "Stephen Roche",
        "Luca Buonanno"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det",
        "hep-ex",
        "physics.data-an"
      ],
      "published": "2026-02-17 20:26:56+00:00",
      "link": "https://arxiv.org/pdf/2602.15990v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15946v1",
      "title": "On-chip probabilistic inference for charged-particle tracking at the sensor edge",
      "abstract": "Modern scientific instruments operate under increasingly extreme constraints on bandwidth, latency, and power. Inference at the sensor edge determines experimental data collection efficiency by deciding which information to save for further analysis. Particle tracking detectors at the Large Hadron Collider exemplify this challenge: pixelated silicon sensors generate rich spatiotemporal ionization patterns, yet most of this information is discarded due to data-rate limitations. Concurrently, advancements in co-design tools provide rapid turn-around for incorporating machine learning into application-specific integrated circuits, motivating designs for particle detectors with new integrated technologies. We demonstrate that neural networks embedded in the front-end electronics can infer charged-particle kinematic parameters from a single silicon layer. We regress hit positions and incident angles with calibrated uncertainties, while satisfying stringent constraints on numerical precision, latency, and silicon area. Our results establish a path toward probabilistic inference directly at the edge, opening new opportunities for intelligent sensing in high-rate scientific instruments.",
      "authors": [
        "Arghya Ranjan Das",
        "David Jiang",
        "Rachel Kovach-Fuentes",
        "Shiqi Kuang",
        "Ana Sofía Calle Muñoz",
        "Danush Shekar",
        "Jennet Dickinson",
        "Giuseppe Di Guglielmo",
        "Lindsey Gray",
        "Mia Liu",
        "Corrinne Mills",
        "Mark S. Neubauer",
        "Daniel Abadjiev",
        "Anthony Badea",
        "Doug Berry",
        "Karri DiPetrillo",
        "Farah Fahim",
        "Abhijith Gandrakota",
        "Harshul Gupta",
        "James Hirschauer",
        "Eliza Howard",
        "Ron Lipton",
        "Petar Maksimovic",
        "Nick Manganelli",
        "Benjamin Parpillon",
        "Jannicke Pearkes",
        "Ricardo Silvestre",
        "Morris Swartz",
        "Chinar Syal",
        "Nhan Tran",
        "Amit Trivedi",
        "Keith Ulmer",
        "Mohammad Abrar Wadud",
        "Benjamin Weiss",
        "Eric You"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det",
        "hep-ex"
      ],
      "published": "2026-02-17 19:03:17+00:00",
      "link": "https://arxiv.org/pdf/2602.15946v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15939v1",
      "title": "Particle-in-Cell Methods for Simulations of Sheared, Expanding, or Escaping Astrophysical Plasma",
      "abstract": "Particle-in-Cell (PIC) methods have achieved widespread recognition as simple and flexible approaches to model collisionless plasma physics in fully kinetic simulations of astrophysical environments. However, in many situations the standard PIC algorithm must be extended to include macroscopic effects in microscale simulations. For plasmas subjected to shearing or expansion, shearing-box and expanding-box methods can be incorporated into PIC to account for these global effects. For plasmas subjected to local acceleration in confined regions of space, a leaky-box method can allow closed-box PIC simulations to account for particle escape from the accelerator region. In this work, we review and improve methods to include shearing, expansion, and escape in PIC simulations. We provide the numerical details of how Maxwell's equations and the particle equations of motion are solved in each case, and introduce generalized Boris-like particle pushers to solve the momentum equation in the presence of extra forces. This work is intended to serve as a comprehensive reference for the implementation of shearing-box, expanding-box, and leaky-box algorithms in PIC.",
      "authors": [
        "Fabio Bacchini",
        "Evgeny A. Gorbunov",
        "Maximilien Péters de Bonhome",
        "Paul Els",
        "Konstantinos-Xanthos Argyropoulos",
        "Minh Nhat Ly",
        "Daniel Grošelj"
      ],
      "primary_category": "physics.plasm-ph",
      "categories": [
        "physics.plasm-ph",
        "astro-ph.HE"
      ],
      "published": "2026-02-17 19:00:19+00:00",
      "link": "https://arxiv.org/pdf/2602.15939v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15933v1",
      "title": "KPZ-like transport in long-range interacting spin chains proximate to integrability",
      "abstract": "Isotropic integrable spin chains such as the Heisenberg model feature superdiffusive spin transport belonging to an as-yet-unidentified dynamical universality class closely related to that of Kardar, Parisi, and Zhang (KPZ). To determine whether these results extend to more generic one-dimensional models, particularly those realizable in quantum simulators, we investigate spin and energy transport in non-integrable, long-range Heisenberg models using state-of-the-art tensor network methods. Despite the lack of integrability and the asymptotic expectation of diffusion, for power-law models (with exponent $2 < α< \\infty$) we observe long-lived $z=3/2$ superdiffusive spin transport and two-point correlators consistent with KPZ scaling functions, up to times $t \\sim 10^3/J$. We conjecture that this KPZ-like transport is due to the proximity of such power-law-interacting models to the integrable family of Inozemtsev models, which we show to also exhibit KPZ-like spin transport across all interaction ranges. Finally, we consider anisotropic spin models naturally realized in Rydberg atom arrays and ultracold polar molecules, demonstrating that a wide range of long-lived, non-diffusive transport can be observed in experimental settings.",
      "authors": [
        "Sajant Anand",
        "Jack Kemp",
        "Julia Wei",
        "Christopher David White",
        "Michael P. Zaletel",
        "Norman Y. Yao"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.dis-nn",
        "cond-mat.str-el",
        "physics.atom-ph"
      ],
      "published": "2026-02-17 19:00:02+00:00",
      "link": "https://arxiv.org/pdf/2602.15933v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15780v1",
      "title": "Deep Learning for Point Spread Function Modeling in Cosmology",
      "abstract": "We present the development of a data-driven, AI-based model of the Point Spread Function (PSF) that achieves higher accuracy than the current state-of-the-art approach, \"PSF in the Full Field-of-View'' (PIFF). PIFF is widely used in leading weak-lensing surveys, including the Dark Energy Survey (DES), the Hyper Suprime-Cam (HSC) Survey, and the Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST). The PSF characterizes how a point source, such as a star, is imaged after its light traverses the atmosphere and telescope optics, effectively representing the \"blurred fingerprint'' of the entire imaging system. Accurate PSF modeling is essential for weak gravitational lensing analyses, as biases in its estimation propagate directly into cosmic shear measurements -- one of the primary cosmological probes of the expansion history of the Universe and the growth of large-scale structure for dark energy studies. To address the limitations of PIFF, which constructs PSF models independently for each CCD and therefore loses spatial coherence across the focal plane, we introduce a deep-learning-based framework for PSF reconstruction. In this approach, an autoencoder is trained on stellar images obtained with the Hyper Suprime-Cam (HSC) of the Subaru Telescope and combined with a Gaussian process to interpolate the PSF across the telescope's full field of view. This hybrid model captures systematic variations across the focal plane and achieves a reconstruction error of $3.4 \\times 10^{-6}$ compared to PIFF's $3.7 \\times 10^{-6}$, laying the foundation for integration into the LSST Science Pipelines.",
      "authors": [
        "Dayana Andrea Henao Arbeláez",
        "Pierre-François Léget",
        "Andrés Alejandro Plazas Malagón"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO",
        "physics.data-an"
      ],
      "published": "2026-02-17 18:12:53+00:00",
      "link": "https://arxiv.org/pdf/2602.15780v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15777v1",
      "title": "New Challenges in Plasma Accelerators: Final Focusing for Wakefield Colliders",
      "abstract": "The focusing of particle beams for collider experiments is crucial for maximizing the luminosity and thus the discovery potential of these machines. In recent years, plasma wakefield acceleration has emerged as a leading candidate for achieving higher energy collisions with smaller facility footprints due to the large accelerating gradients in the plasma. This higher beam energy poses significant challenges for the final focusing system of the collider. Here, we discuss the various challenges of final focusing for TeV-scale plasma accelerators and propose possible solutions. Finally, we present the first design of a final focusing system for a 10 TeV linear wakefield collider, evaluate its performance, and discuss its shortcomings as well as improvements for future designs.",
      "authors": [
        "Keegan Downham",
        "Spencer Gessner",
        "Lewis Kennedy",
        "Rogelio Tomás",
        "Andrei Seryi"
      ],
      "primary_category": "physics.acc-ph",
      "categories": [
        "physics.acc-ph"
      ],
      "published": "2026-02-17 18:06:54+00:00",
      "link": "https://arxiv.org/pdf/2602.15777v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15743v1",
      "title": "Physics-informed data-driven inference of an interpretable equivariant LES model of incompressible fluid turbulence",
      "abstract": "Restrictive phenomenological assumptions represent a major roadblock for the development of accurate subgrid-scale models of fluid turbulence. Specifically, these assumptions limit a model's ability to describe key quantities of interest, such as local fluxes of energy and enstrophy, in the presence of diverse coherent structures. This paper introduces a symbolic data-driven subgrid-scale model that requires no phenomenological assumptions and has no adjustable parameters, yet it outperforms leading LES models. A combination of a priori and a posteriori benchmarks shows that the model produces accurate predictions of various quantities including local fluxes across a broad range of two-dimensional turbulent flows. While the model is inferred using LES-style spatial coarse-graining, its structure is more similar to RANS models, as it employs an additional field to describe subgrid scales. We find that this field must have a rank-two tensor structure in order to correctly represent both the components of the subgrid-scale stress tensor and the various fluxes.",
      "authors": [
        "Matteo Ugliotti",
        "Brandon Choi",
        "Mateo Reynoso",
        "Daniel R. Gurevich",
        "Roman O. Grigoriev"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "physics.comp-ph"
      ],
      "published": "2026-02-17 17:17:09+00:00",
      "link": "https://arxiv.org/pdf/2602.15743v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15652v1",
      "title": "The COHERENT Experiment: 2026 Update",
      "abstract": "The COHERENT experiment measures neutrino-induced recoils from coherent elastic neutrino-nucleus scattering (CEvNS) with multiple nuclear targets at the Spallation Neutron Source (SNS) at the Oak Ridge National Laboratory (ORNL), USA. Several successful CEvNS measurements have been achieved in recent years with tens-of-kg detector masses, with a CsI scintillating crystal, a liquid argon single-phase detector, and high-purity germanium spectrometers. For the next phase, COHERENT aims at high-statistics detection of CEvNS events for precision tests of the standard model of particle physics, and to probe new physics beyond-the-standard model. Percent-level precision can be achieved by lowering thresholds, reducing backgrounds, and by scaling up the detector masses. It goes hand in hand with benchmarking the neutrino flux from the SNS. Further detectors will measure CEvNS in additional nuclei, including lighter target nuclei such as sodium and neon, to continue to test the expected neutron-number-squared dependence of the cross section. COHERENT can furthermore study charged-current and neutral-current inelastic neutrino-nucleus cross sections on various nuclei at neutrino energies below $\\sim$50 MeV. Many of these cross sections have never been measured before, but are critical input for the interpretation of core-collapse supernova detection in large-scale neutrino experiments such as DUNE, Super-K, Hyper-K, and HALO.",
      "authors": [
        "M. Adhikari",
        "M. Ahn",
        "D. Amaya Matamoros",
        "P. S. Barbeau",
        "V. Belov",
        "I. Bernardi",
        "C. Bock",
        "A. Bolozdynya",
        "R. Bouabid",
        "J. Browning",
        "B. Cabrera-Palmer",
        "N. Cedarblade-Jones",
        "S. Chen",
        "A. I. Colón Rivera",
        "V. da Silva",
        "J. Daughhetee",
        "Y. Efremenko",
        "S. R. Elliott",
        "A. Erlandson",
        "L. Fabris",
        "M. L. Fischer",
        "S. Foster",
        "A. Galindo-Uribarri",
        "E. Granados Vazquez",
        "M. P. Green",
        "B. Hackett",
        "J. Hakenmüller",
        "M. Harada",
        "M. R. Heath",
        "S. Hedges",
        "Y. Hino",
        "H. Huang",
        "W. Huang",
        "H. Jeong",
        "B. A. Johnson",
        "T. Johnson",
        "A. Khromov",
        "D. Kim",
        "L. Kong",
        "A. Konovalov",
        "Y. Koshio",
        "E. Kozlova",
        "A. Kumpan",
        "O. Kyzylova",
        "Y. Lee",
        "S. M. Lee",
        "G. Li",
        "L. Li",
        "Z. Li",
        "J. M. Link",
        "J. Liu",
        "Q. Liu",
        "X. Lu",
        "M. Luxnat",
        "D. M. Markoff",
        "J. Mattingly",
        "H. McLaurin",
        "K. McMichael",
        "N. Meredith",
        "Y. Nakajima",
        "F. Nakanishi",
        "J. Newby",
        "B. Nolan",
        "J. O'Reilly",
        "A. Orvedahl",
        "D. S. Parno",
        "D. Pérez-Loureiro",
        "D. Pershey",
        "C. G. Prior",
        "J. Queen",
        "R. Rapp",
        "H. Ray",
        "O. Razuvaeva",
        "D. Reyna",
        "D. Rudik",
        "J. Runge",
        "D. J. Salvat",
        "J. Sander",
        "K. Scholberg",
        "H. Sekiya",
        "J. Seligman",
        "A. Shakirov",
        "G. Simakov",
        "J. Skweres",
        "W. M. Snow",
        "V. Sosnovtsev",
        "Q. Stefan",
        "M. Stringer",
        "C. Su",
        "T. Subedi",
        "B. Suh",
        "B. Sur",
        "R. Tayloe",
        "Y. -T. Tsai",
        "J. Vaccaro",
        "E. E. van Nieuwenhuizen",
        "C. J. Virtue",
        "G. Visser",
        "K. Walkup",
        "E. M. Ward",
        "R. Wendell",
        "T. Wongjirad",
        "C. Yang",
        "Y. Yang",
        "J. Yoo",
        "C. -H. Yu",
        "Y. Yu",
        "A. Zaalishvili",
        "J. Zettlemoyer",
        "Y. Zheng"
      ],
      "primary_category": "hep-ex",
      "categories": [
        "hep-ex",
        "hep-ph",
        "nucl-ex",
        "physics.ins-det"
      ],
      "published": "2026-02-17 15:24:29+00:00",
      "link": "https://arxiv.org/pdf/2602.15652v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15627v1",
      "title": "Fastest first-passage time for multiple searchers with finite speed",
      "abstract": "We study analytically and numerically the mean fastest first-passage time (fFPT) to an immobile target for an ensemble of $N$ independent finite-speed random searchers driven by dichotomous noise and described by the telegrapher's equation. In stark contrast to the well-studied case of Brownian particles -- for which the mean fFPT vanishes logarithmically with $N$ -- we uncover that the mean fFPT is bounded from below by the minimal ballistic travel time, with an exponentially fast convergence to this bound as $N \\to \\infty$. This behavior reveals a dramatic efficiency advantage of physically realistic, finite-speed searchers over Brownian ones and illustrates how diffusive macroscopic models may be conceptually misleading in predicting the short-time behavior of a physical system. We extend our analysis to anomalous diffusion generated by Riemann-Liouville-type dichotomous noises and find that target detection is more efficient in the superdiffusive regime, followed by normal and then subdiffusive regimes, in agreement with physical intuition and contrary to earlier predictions.",
      "authors": [
        "Denis S. Grebenkov",
        "Ralf Metzler",
        "Gleb Oshanin"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "physics.bio-ph",
        "physics.chem-ph"
      ],
      "published": "2026-02-17 14:52:55+00:00",
      "link": "https://arxiv.org/pdf/2602.15627v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15626v1",
      "title": "Deformation and orientation of a capsule with viscosity contrast in linear flows: a theoretical study",
      "abstract": "We develop a perturbation theory to study the shape and the orientation of an initially spherical capsule of radius R with a viscosity contrast, a surface tension σ and a bending rigidity $κ$ in linear flows. The elastic mechanical response of membrane to deformations is described by three elastic constitutive law which are either Hookean, Neohookean or Skalak type leading to the introduction of a surface shear elastic modulus $G_s$ and the Poisson ratio (or analog quantities). At the leading order, the deformation, i.e. the so-called Taylor parameter is proportional to the elastic capillary number Ca which evaluates the ratio between the external viscous stress and the elastic membrane response. In this linear regime, the results do not depend on the elastic constitutive law as expected. Without surface tension and bending rigidity, we recover the results of Barthes-Biesel & Rallison (1981) and notably the fact that the Taylor parameter does not depend on the viscosity contrast $λ$ contrary to the case of a viscous droplet. In our more general model, the deformation does no longer depend on $λ$ at the upper order. Now, the Taylor parameter also depends on two other dimensionless numbers: the surface elastocapillary ratio $σ/G_s$ and the dimensionless bending rigidity $B= κ/G_sR^2$. At the further order, the angle of inclination of the capsule with the direction of the shear flow, the analog of the Chaffey and Brenner equation for droplets is determined in each case. The results are in excellent agreement with the numerical ones performed with a code based on the boundary integral method providing an useful method to valid numerical developments.",
      "authors": [
        "Paul Regazzi",
        "Marc Leonetti"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft",
        "physics.flu-dyn"
      ],
      "published": "2026-02-17 14:51:31+00:00",
      "link": "https://arxiv.org/pdf/2602.15626v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15616v1",
      "title": "Relativistic nuclear recoil effects in hyperfine splitting of hydrogenic systems",
      "abstract": "The finite nuclear mass $(Z\\,α)^2\\,m/M\\,E_F$ correction to the hyperfine splitting in hydrogenic systems is calculated using a combined relativistic heavy particle and nonrelativistic quantum electrodynamics. The obtained results are in disagreement with previous calculations by Bodwin and Yennie [Phys. Rev. D {\\bf 37}, 498 (1988)]. The comparison of improved theoretical predictions with the corresponding measurements in hydrogen reveals $5σ$ discrepancy, which indicates problems with the proton structure corrections.",
      "authors": [
        "Jakub Hevler",
        "Andrzej Maroń",
        "Krzysztof Pachucki"
      ],
      "primary_category": "physics.atom-ph",
      "categories": [
        "physics.atom-ph"
      ],
      "published": "2026-02-17 14:44:41+00:00",
      "link": "https://arxiv.org/pdf/2602.15616v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15468v1",
      "title": "Students' understanding of the 2D Heat Equation: An APOS approach",
      "abstract": "In this paper, we use the APOS theoretical framework to validate a hypothetical learning trajectory of the 2D heat equation, a preliminary genetic decomposition that stresses the conceptual understanding of its mathematical formulation. We design questions to probe specific mental constructions of the preliminary genetic decomposition. We interview 8 students in the second year of the B.Sc. enrolled in either engineering, physics or twin (mathematics and physics) majors. Our findings indicate that students engage with many predicted mental constructions. In particular, coordination and encapsulation of two process conceptions of the Laplacian of the temperature improve understanding although it is challenging. Other parts of the genetic decomposition require refinements. These include mental constructions related to the temperature distribution function, heat flow, and the temperature gradient.",
      "authors": [
        "Maria Al Dehaybes",
        "Johan Deprez",
        "Paul van Kampen",
        "Mieke De Cock"
      ],
      "primary_category": "physics.ed-ph",
      "categories": [
        "physics.ed-ph"
      ],
      "published": "2026-02-17 10:15:02+00:00",
      "link": "https://arxiv.org/pdf/2602.15468v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15437v1",
      "title": "Isotope effect in the work function of lithium",
      "abstract": "The work functions of 7Li and 6Li metals have been measured as a function of temperature, by using photoionization of pure isolated metal nanoparticles in a beam. These data reveal a marked isotope effect in the temperature variation of these work functions. Furthermore, for both isotopes the curvature of this temperature variation is found to be significantly larger than may be ascribed purely to a change in the electron gas density. These findings enhance the characterization of lithium as a quantum material in which the interplay between electronic and ionic degrees of freedom is nontrivial, and call for a microscopic understanding beyond simple models. Additionally, the slope of the work function curves was observed to vanish in the low temperature limit, as had been predicted on the basis of the Third Law of thermodynamics.",
      "authors": [
        "Atef A. Sheekhoon",
        "Abdelrahman O. Haridy",
        "Vitaly V. Kresin"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "physics.atm-clus",
        "physics.chem-ph"
      ],
      "published": "2026-02-17 09:00:06+00:00",
      "link": "https://arxiv.org/pdf/2602.15437v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15343v1",
      "title": "Transition radiation in helical metamaterials with strong spatial dispersion",
      "abstract": "The theory of transition radiation in helical metamaterials with strong spatial dispersion is developed in the framework of an effective field theory approach. The average number of photons radiated by a charged particle passing through a plate made of this metamaterial is obtained. Given the positions of the transition radiation maxima in momentum space for different velocities of a charged particle, the method for reconstruction of the dispersion law of plasmon-polaritons in metamaterials is proposed. Applying this method conversely, one can predict the radiation spectrum and polarization properties of transition radiation by means of the dispersion law of plasmon-polaritons in the metamaterial known, for example, from the effective model. It is shown that the strong spatial dispersion alters qualitatively the properties of transition radiation from a charged particle traversing normally a plate made of the helical metamaterial along its symmetry axis in the paraxial regime, viz., there is a nonzero forward radiation in contrast to transition radiation in media without strong spatial dispersion. Vavilov-Cherenkov radiation and the anomalous Doppler effect in helical metamaterials with strong spatial dispersion are described.",
      "authors": [
        "P. O. Kazinski",
        "P. S. Korolev"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall",
        "physics.optics"
      ],
      "published": "2026-02-17 04:17:53+00:00",
      "link": "https://arxiv.org/pdf/2602.15343v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15296v1",
      "title": "GPS constellation search for exotic physics messengers coincident with the binary neutron star merger GW170817",
      "abstract": "The Global Positioning System (GPS) includes a continuously operating, planet-scale network of atomic clocks that, beyond navigation and time dissemination, enables precision tests of fundamental physics. Here we use GPS carrier phase archival data to perform a retrospective search for exotic low-mass fields (ELFs) that might be emitted by the binary neutron-star merger GW170817, complementing gravitational wave and electromagnetic modalitiesnin multi-messenger astronomy. Such ultra-relativistic fields would imprint a dispersive, anti-chirp signature in clock-frequency time series, delayed with respect to the LIGO-Virgo gravitational wave detection. We construct network-median pseudo-frequency data from eighteen Rb satellite clocks referenced to a terrestrial hydrogen maser and conduct a template-bank search spanning ELF pulse duration, arrival delay, and characteristic frequency. No statistically significant signal is observed after accounting for noise statistics and template-bank trials. We derive 95\\% confidence-level lower bounds on the interaction energy scale $Λ_α$ of quadratic couplings driving variations in electromagnetic fine-structure constant. These limits improve upon existing astrophysical and gravity-test constraints across the ELF-energy range $\\approx10^{-18}$--$10^{-14}\\,\\mathrm{eV}$. This demonstrates that mature global satellite-clock networks provide an observational capability for retrospective, multi-messenger searches for new physics using decades of archival timing data.",
      "authors": [
        "Arko P. Sen",
        "Geoffrey Blewitt",
        "Andrey Sarantsev",
        "Paul Ries",
        "Andrei Derevianko"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.HE",
        "physics.atom-ph",
        "physics.data-an",
        "physics.ins-det"
      ],
      "published": "2026-02-17 01:40:17+00:00",
      "link": "https://arxiv.org/pdf/2602.15296v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15262v1",
      "title": "Multi-Arrival Infrasound from Meteoroids: Fragmentation Signatures versus Propagation Effects in a Fine-Scale Layered Atmosphere",
      "abstract": "Infrasonic signatures of meteoroid fragmentation are frequently ambiguous: do multiple arrivals signify a complex breakup or merely the distorting effects of a layered atmosphere? Resolving this ambiguity is critical for accurate energy estimates and source reconstruction. In this study, we address this challenge by analyzing a unique regional dataset of well-constrained meteoroid events observed by the Southern Ontario Meteor Network and the co-located Elginfield Infrasound Array. We employ pseudo-differential parabolic equation (PPE) simulations to quantify how fine-scale gravity-wave structures in the stratosphere and lower thermosphere modify acoustic waveforms at ranges <300 km. Our modeling reveals that while fine-scale layering can stretch signals and generate diffuse oscillatory tails, it does not produce discrete, high-amplitude pulse splitting at ranges below ~140 km. By applying these results to the rare multi-arrival event 20060305, we demonstrate that its distinct double arrival at 100 km range is inconsistent with atmospheric multipathing and provides definitive evidence of separate fragmentation episodes. These findings establish new diagnostic criteria for separating source physics from propagation artifacts, improving the reliability of infrasound as a monitoring tool for natural bolides, space debris re-entries, and catastrophic launch failures.",
      "authors": [
        "Igor P. Chunchuzov",
        "Oleg E. Popov",
        "Elizabeth A. Silber",
        "Sergey N. Kulichkov"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP",
        "physics.ao-ph",
        "physics.geo-ph"
      ],
      "published": "2026-02-16 23:39:45+00:00",
      "link": "https://arxiv.org/pdf/2602.15262v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15223v1",
      "title": "Systematic study of high performance GeSn photodiodes with thick absorber for SWIR and extended SWIR detection",
      "abstract": "Germanium-tin (GeSn) photodiodes potentiate a viable solution to integrate SWIR and extended SWIR detection technology into CMOS processing line. However, challenges in the growth of thick, high quality GeSn limit the device absorber thickness, making it impossible to ascertain the performance limit of GeSn photodiodes. An in-depth understanding of their device physics and a clear optimization pathway towards commercial-grade devices remain elusive. This work presents a systematic empirical study of GeSn photodiodes with thick absorber (2 to 8% Sn content, up to 2630 nm thick), showing high responsivity up to 0.59 A.W-1 at 1.55 μm and 0.43 A.W-1 at 2 μm wavelengths, low dark current density down to 2 x 10-2 A.cm-2, and high detection cutoff wavelengths up to 2.1 and 2.5 μm at 5% and 8% Sn, respectively. Using specific doping design (P-i-N and N-i-P), an in-depth analysis is presented on the impact of junction position, p-type background carrier concentration, bulk/ surface defects and photocarrier diffusion length - on photodetection performance. Different optimization strategies for GeSn photodiodes, in particular at high Sn content, are proposed.",
      "authors": [
        "Quang Minh Thai",
        "Rajesh Kumar",
        "Abdulla Said Ali",
        "Justin Rudie",
        "Steven Akwabli",
        "Yunsheng Qiu",
        "Mourad Benamara",
        "Hryhorii Stanchu",
        "Kushal Dahal",
        "Xuehuan Ma",
        "Sudip Acharya",
        "Chun-Chieh Chang",
        "Gregory T. Forcherio",
        "Bruce Claflin",
        "Wei Du",
        "Shui-Qing Yu"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det",
        "physics.app-ph"
      ],
      "published": "2026-02-16 22:06:10+00:00",
      "link": "https://arxiv.org/pdf/2602.15223v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15118v1",
      "title": "Real-time graph neural networks on FPGAs for the Belle II electromagnetic calorimeter",
      "abstract": "We present the development and evaluation of a real-time Graph Neural Network-based trigger for the electromagnetic calorimeter of the Belle II experiment at the SuperKEKB collider. The algorithm processes calorimeter trigger cells as graph nodes to perform clustering, feature extraction, and per-cluster signal classification with deterministic latency compatible with the first-level trigger readout system. The model predicts cluster positions and energies and provides a signal classification score, enabling a more flexible clustering strategy than the baseline trigger algorithm. Implemented on an FPGA and integrated into the Belle II trigger chain for synchronous operation, the system sustains the 8 MHz trigger throughput with an end-to-end latency of 3.168 $μ$s. The performance is evaluated using simulated events and collision data. The energy resolution is comparable to the baseline trigger, while the position resolution for high-energy clusters improves by up to 18 percent in the central detector region. Cluster purity increases by up to 20 percent at low energies for isolated clusters, and cluster efficiency improves by up to 20 percent for overlapping clusters. The signal classifier enables additional background suppression at fixed signal retention. These results demonstrate the first operation of a Graph Neural Network-based reconstruction system implemented on FPGAs within the real-time trigger readout path of a collider experiment.",
      "authors": [
        "I. Haide",
        "M. Neu",
        "Y. Unno",
        "T. Justinger",
        "V. Dajaku",
        "F. Baptist",
        "T. Lobmaier",
        "J. Becker",
        "T. Ferber",
        "H. Bae",
        "A. Beaubien",
        "J. Eppelt",
        "R. Giordano",
        "G. Heine",
        "T. Koga",
        "Y. -T. Lai",
        "K. Miyabayashi",
        "H. Nakazawa",
        "M. Remnev",
        "L. Reuter",
        "K. Unger",
        "R. van Tonder"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det",
        "hep-ex"
      ],
      "published": "2026-02-16 19:00:16+00:00",
      "link": "https://arxiv.org/pdf/2602.15118v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14711v1",
      "title": "The distinction of time-reversal-like degeneracy by electronic transport in a new compound",
      "abstract": "We report the discovery of a new compound, Ce$_3$MgBi$_5$, and reveal the hidden time-reversal-like degenerate states within it. Ce$_3$MgBi$_5$ is an antiferromagnet with the distorted kagome lattice of Ce atoms, in which several fractional magnetization plateaus emerge with the increase of magnetic field. At the 1/2 magnetization plateau, obvious hysteresis has been observed in the magnetoresistance and Hall resistivity during the rise and fall of the magnetic field. However, hysteresis vanishes in the corresponding measurements of magnetization, indicating the existence of degenerate states with the same net magnetization but different electronic transport properties. The degenerate states can be connected by the time-reversal-like operation. In addition, by comparing with HoAgGe, it is suggested that the special crystal structure in Ce$_3$MgBi$_5$ may have a shielding effect on the time-reversal-like operation, thereby affecting the distinction of degenerate states. Our work establishes Ce$_3$MgBi$_5$ as an example of utilizing electronic transport properties to identify and distinguish hidden symmetries in frustrated magnetic systems.",
      "authors": [
        "Yi-Yan Wang",
        "Ping Su",
        "Kai-Yuan Hu",
        "Yi-Ran Li",
        "Na Li",
        "Ying Zhou",
        "Dan-Dan Wu",
        "Yan Sun",
        "Qiu-Ju Li",
        "Xia Zhao",
        "Hui Liang",
        "Xue-Feng Sun"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-02-16 12:57:51+00:00",
      "link": "https://arxiv.org/pdf/2602.14711v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14599v1",
      "title": "Non-commutative Dynamic Approaches to the Kibble-Zurek Scaling Limit with an Initial Gapless Order",
      "abstract": "Nonequilibrium many-body physics is one of the core problems in modern physics, while the dynamical scaling from a gapless phase to the critical point is a most important challenge with very few knowledge so far. In the driven dynamics with a tuning rate $R$ across the quantum critical point (QCP) of a system with size $L$, the finite-time scaling shows that the square of the order parameter $m^2$ obeys a simple scaling relation $m^2\\propto R^{2β/νr}$ in the Kibble-Zurek (KZ) scaling limit with $RL^r\\gg1$. Here, by studying the driven critical dynamics from a gapless ordered phase in the bilayer Heisenberg model, we unveil that the approaches to the scaling region dominated by the KZ scaling limit with $RL^r\\gg1$ are {\\it non-commutative}: this scaling region is inaccessible for large $R$ and finite medium $L$, while merely accessible for large $L$ and moderately finite $R$. We attribute this to the memory effect induced by the finite-size correction in the gapless ordered phase. This non-commutative property makes $m^2$ still strongly depends on the system size and deviates from $m^2\\propto R^{2β/νr}$ even for large $R$. We further show that a similar correction applies to the imaginary-time relaxation dynamics. Our results establish an essential extension of nonequilibrium scaling theory with a gapless ordered initial state.",
      "authors": [
        "Zhe Wang",
        "Chengxiang Ding",
        "Dongxu Liu",
        "Fuxiang Li",
        "Zheng Yan",
        "Shuai Yin"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-02-16 10:01:31+00:00",
      "link": "https://arxiv.org/pdf/2602.14599v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14563v1",
      "title": "Magnetic excitations in the Kitaev material Na$_2$IrO$_3$ studied by neutron scattering",
      "abstract": "Inelastic neutron scattering experiments with a large set of comounted Na$_2$IrO$_3$ crystals reveal the low-energy magnon dispersion in this candidate material for Kitaev physics. The magnon gap amounts to 1.7(1) meV and can be interpreted similarly to the sister compound $α$-RuCl$_{3}$ to stem from the zone boundaries in the antiferromagnetic zigzag structure. The neutron experiments find no evidence for low-energy excitations with ferromagnetic character, which contrasts to the findings in $α$-RuCl$_{3}$. Our results are consistent with a recently proposed microscopic model that involves an antiferromagnetic Heisenberg nearest-neighbor exchange in Na$_2$IrO$_3$ in contrast to the ferromagnetic one considered for $α$-RuCl$_{3}$. Although the magnetic response shows the signatures of bond-directional anisotropy in both materials the different relative signs of Kitaev and Heisenberg interaction result in different deviations from the initial Kitaev model. Low-energy ferromagnetic fluctuations cannot be considered as a fingerprint of ferromagnetic Kitaev interaction.",
      "authors": [
        "Alexandre Bertin",
        "Hengdi Zhao",
        "Gang Cao",
        "Andrea Piovano",
        "Paul Steffens",
        "Alexandre Ivanov",
        "Markus Braden"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-02-16 08:51:19+00:00",
      "link": "https://arxiv.org/pdf/2602.14563v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14557v1",
      "title": "Dissipative Spectroscopy",
      "abstract": "We introduce dissipative spectroscopy as a framework for extracting spectral information from quantum systems via controlled dissipation. By establishing a general dissipative response theory applicable to both Markovian and non-Markovian environments, we develop a protocol to access the dissipative spectrum (DS) through driven oscillation-dissipation resonance. We show that the DS can identify two-particle soft modes near quantum critical points and, on the normal-phase side, predict the emergence of macroscopic order exhibiting power-law growth following a dissipation quench. These distinctive signatures appear in quasiparticle-dominant regimes, previously considered trivial. Furthermore, we introduce extended dissipative susceptibilities that capture leading memory effects and demonstrate their utility in a dissipative fermionic model. Our results indicate that the DS is readily accessible and offers a versatile tool for probing equilibrium properties as well as predicting nonequilibrium dissipative dynamics.",
      "authors": [
        "Xudong He",
        "Yu Chen"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.quant-gas"
      ],
      "published": "2026-02-16 08:35:11+00:00",
      "link": "https://arxiv.org/pdf/2602.14557v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14549v1",
      "title": "Realization of a Synthetic Hall Torus with a Spinor Bose-Einstein Condensate",
      "abstract": "We report the first experimental realization of a synthetic Hall torus using a spinor Bose-Einstein condensate confined in a ring-shaped trap with in situ imaging. By cyclically coupling three hyperfine spin states via Raman and microwave fields, we impose a periodic boundary condition in the synthetic dimension, which together with a real-space ring trap, realizes a toroidal geometry with a synthetic magnetic flux. This flux induces azimuthal density modulations in the condensate, whose periodicity is uniquely determined by the quantized toroidal magnetic flux-a hallmark of the Hall torus geometry. By varying the relative phase between the couplings across repeated experimental runs, we control the location of the density extrema, emulating the behavior of Thouless charge pump in a toroidal geometry. We further investigate the onset of these modulations as the system transitions from a cylindrical to a toroidal topology. Our results establish a versatile platform for investigating quantum Hall physics and topological phenomena in synthetic curved spaces.",
      "authors": [
        "T. -H. Chien",
        "S. -C. Wu",
        "Y. -H. Su",
        "L. -R. Liu",
        "N. -C. Chiu",
        "M. Sarkar",
        "Q. Zhou",
        "Y. -J. Lin"
      ],
      "primary_category": "cond-mat.quant-gas",
      "categories": [
        "cond-mat.quant-gas"
      ],
      "published": "2026-02-16 08:11:27+00:00",
      "link": "https://arxiv.org/pdf/2602.14549v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14400v1",
      "title": "Programming active-molecule dynamics via intramolecular nonreciprocity",
      "abstract": "The dynamics of a self-propelled particle are typically hard-wired by its microscopic construction, limiting the range of behaviors accessible without redesigning the particle itself. Here we show that intramolecular nonreciprocity provides a minimal and versatile mechanism to overcome this constraint. We construct active molecules from short chains of two species of self-propelled particles whose propulsion directions are coupled nonreciprocally according to a prescribed internal sequence. At the single-molecule level, homogeneous sequences exhibit standard persistent random-walk dynamics, whereas heterogeneous sequences produce distinct trajectories inaccessible to either constituent species alone. At the collective level, using motility-induced phase separation (MIPS) as a representative example, we find that modifying the internal sequence shifts the MIPS onset by multiple orders of magnitude in propulsion strength, without altering particle-level interactions. These results demonstrate that intramolecular nonreciprocity among a small set of active components enables sequence-level programmability from single-molecule dynamics to emergent collective behavior, providing a minimal mechanism to encode and control active-matter dynamics across scales.",
      "authors": [
        "Ye Zhang",
        "Meng Xiao",
        "Duanduan Wan"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft"
      ],
      "published": "2026-02-16 02:16:00+00:00",
      "link": "https://arxiv.org/pdf/2602.14400v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14362v1",
      "title": "Polymer Brushes and Grafted Polymers: AI/ML-Driven Synthesis, Simulation, and Characterization towards autonomous SDL",
      "abstract": "Polymer brushes and grafted polymers have attracted significant interest at the intersection of polymers, interfacial chemistry, colloidal science, and nanostructuring. The confinement of high-density grafted polymers and differences in swelling regimes govern the synthetic challenges and the interesting physics underlying their macromolecular dynamics. In this article, we focus on another intersection, artificial intelligence and machine learning (AI/ML), and how workflows will enhance the microstructure and composition of these systems. It will also accelerate potential applications through high-throughput experimentation (HTE) and data-driven intelligence, enabling scientific discovery and optimization. Applications in microfluidics, sensors, bioimplants, drug delivery, and related areas may yet offer more opportunities for ML-driven optimization. There is also interest in applying these studies with self-driving laboratories (SDLs) that can leverage autonomous systems for synthesis screening, characterization, and application evaluation.",
      "authors": [
        "Rigoberto C. Advincula",
        "Jihua Chen"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft"
      ],
      "published": "2026-02-16 00:28:46+00:00",
      "link": "https://arxiv.org/pdf/2602.14362v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14113v1",
      "title": "Quarkyonic matter and hadron-quark crossover from an ultracold atom perspective",
      "abstract": "The dense matter equation of state is of great interest due to the recent development of astrophysical observations for neutron stars. A rapid increase in pressure indicates a continuous crossover from a hadron phase to a quark phase without any phase transitions, yet its microscopic mechanism remains elusive. Recently, a peak in the speed of sound and a baryon momentum-shell structure, which are predicted from a quarkyonic matter picture, have been regarded as key features of the hadron-quark crossover. In this work, we explore a field-theoretical framework to describe the hadron-quark crossover, drawing an analogy with the Bose-Einstein condensate to Bardeen-Cooper-Schrieffer (BEC-BCS) crossover established in ultracold atomic experiments. Strikingly, a peak in the speed of sound and the baryon momentum-shell structure can simultaneously be explained by the tripling fluctuation effect arising from a different context of quantum many-body physics. We demonstrate these properties in a simplified model and provide a microscopic derivation of the quarkyonic matter model within our field-theoretical framework.",
      "authors": [
        "Hiroyuki Tajima",
        "Kei Iida",
        "Toru Kojo",
        "Haozhao Liang"
      ],
      "primary_category": "nucl-th",
      "categories": [
        "nucl-th",
        "astro-ph.HE",
        "cond-mat.quant-gas",
        "cond-mat.supr-con",
        "hep-ph"
      ],
      "published": "2026-02-15 12:09:49+00:00",
      "link": "https://arxiv.org/pdf/2602.14113v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14085v1",
      "title": "Synergism in radiation effects in condensed matter. Fundamental and application aspects",
      "abstract": "The impressive success achieved by condensed matter radiation physics over its 170-year development period is related to the solution of problems in three areas, the emergence of new materials, the development of new sources of radiation, and the formulation of new concepts with a wide range of applications. In the borderlands of the 20th and 21st centuries, significant changes occurred in each of these aspects (not-so-catastrophic disasters, R. Tom). A major role was played by the emergence of a new ideology - Complexity, which led to the birth of four paradigms, self-organization, dynamic chaos, self-organized criticality and nonadditivity (the first three are related to the concept of synergetics, the fourth - synergism). This article is devoted to radiation synergism, with an emphasis on combinations of radiation and other effects. It presents methods of graphical techniques to identify the specific issue of synergism effects, which is the non-additivity of the overall radiation effect. A parameter expression is proposed to account for the non-additivity of the radiation effect in the experiment, which can be compared to the q parameter introduced by Tsallis in the general science of Complexity, opening up new possibilities in condensed matter radiation physics for both living and non-living objects.",
      "authors": [
        "Boris Oksengendler",
        "Muhsin Ashurov",
        "Sultan Suleymanov",
        "Nigora Turayeva",
        "Farida Iskandarova",
        "Gulnoza Akhmatova",
        "Rahmatillo Ibrohimov"
      ],
      "primary_category": "cond-mat.other",
      "categories": [
        "cond-mat.other"
      ],
      "published": "2026-02-15 10:26:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14085v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14031v1",
      "title": "A Magnon-Based Electric Field Controlled Magnetoelectric Device for Energy-Efficient Logic-in-Memory",
      "abstract": "We demonstrate a non-volatile magnetoelectric magnonic memory (MEMM) that enables fully electrical write/read via direct magnon-driven sensing in an insulating antiferromagnet. A fabricated SrIrO3/La-BiFeO3/SrIrO3 trilayer exhibits sub-100 ps switching, a remnant polarization of 20 uC/cm2, and a readout voltage contrast close to 1mV between high and low-resistance states. To connect device physics to circuit behavior, we develop and experimentally validate a compact circuit model that captures spin Hall injection and spin transport. Simulations with optimized material parameters predict output voltages > 100mV, enabling cascading without external amplification. Using this framework, we design MEMM-based memory and logic blocks, including a 1T1R array, two inverter implementations (complementary two-device and single-device), and a three-input majority gate, and evaluate deep-pipelined operation. The model projects switching energies down to 1 aJ per operation and logic propagation delays of 30-60 ps, indicating MEMM as a promising platform for energy-constrained, high throughput computing.",
      "authors": [
        "Rongqing Cong",
        "Sajid Husain",
        "Yumin Su",
        "Sasikanth Manipatruni",
        "Naveed Ahmed",
        "Dmitri E. Nikonov",
        "Ramamoorthy Ramesh",
        "Kaiyuan Yang",
        "Zhi Jackie Yao"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-15 07:35:02+00:00",
      "link": "https://arxiv.org/pdf/2602.14031v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13765v1",
      "title": "Non-monotonic Irreversibility in Polytropic Steering",
      "abstract": "The efficient manipulation of thermodynamic states within the finite time is fundamentally constrained by the intrinsic dissipative cost. While the slow-driving regime is well-characterized by a universal $1/τ$-scaling of irreversibility, the physics governing fast, non-adiabatic transitions remains elusive. Here, we propose the polytropic steering protocols that provide an exact analytical bridge between the isothermal and adiabatic limits for Brownian particles far-from-equilibrium. We demonstrate that for any protocol duration $τ$, the system can be precisely steered along a prescribed polytropic trajectory, revealing a striking non-monotonic dependence of irreversibility on the driving rate. Contrary to the near-equilibrium paradigm where faster driving necessitates higher energetic costs, we identify a most-irreversible timescale, beyond which dissipation is anomalously suppressed by rapid driving. By mapping these protocols onto a broad class of controllable thermodynamic cycle, we establish power-efficiency tradeoffs and position the polytropic index as a genuine thermodynamic control knob for the rational design of high-speed, high-performance microscopic thermal machines.",
      "authors": [
        "Cong Fu",
        "Youhui Lin",
        "Shanhe Su",
        "Yu-Han Ma"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-14 13:25:53+00:00",
      "link": "https://arxiv.org/pdf/2602.13765v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13749v2",
      "title": "Interplay between non-Fermi liquid and non-Hermiticity: A multi-method study of non-Hermitian multichannel Kondo model",
      "abstract": "Non-Hermitian multichannel Kondo problems host both non-Fermi liquid and non-Hermitian physics, which provide a prototypical model to explore exotic collective quantum phenomena driven by the two different ingredients. Here, we first propose an experimental setup that realizes this model with exact channel symmetry as well as a controllable PT symmetry. Then, we perform a multi-method study of this model, focusing on the low-energy spectrum, the thermodynamic quantities, and the transport properties associated with different fixed points. Using the Bethe ansatz approach, we identify existence of the Yu-Shiba-Rusinov-like state previously found in the non-Hermitian single-channel Kondo model. Then, based on non-Hermitian numerical renormalization group calculations, we reveal clear numerical signatures of the Yu-Shiba-Rusinov state emerging in the relatively strong non-Hermiticity regime of the PT-asymmetric model. Furthermore, our boundary conformal field theory, which is found to be applicable for the PT-symmetric model, uncovers an anomalous temperature dependence of the Kondo conductance, which is beyond conventional Hermitian Kondo systems.",
      "authors": [
        "Wei-Zhu Yi",
        "Yun Chen",
        "Jun-Jun Pang",
        "Hong Chen",
        "Baigeng Wang",
        "Rui Wang"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-02-14 12:46:34+00:00",
      "link": "https://arxiv.org/pdf/2602.13749v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13608v1",
      "title": "Magnonic spontaneous oscillation induced by parametric pumping",
      "abstract": "Spontaneous dynamic systems have attracted significant attention for their rich underlying physics such as phase-locking and synchronization. In this work, we report a new mechanism of generating magnetic spontaneous oscillation via parametric pumping. By applying a pump tone to excite propagating spin waves in a yttrium iron garnet delay line, four-wave mixing converts the pump mode into two phase-autonomous propagating magnon modes, i.e. a spontaneous mode with nearly twice the wavenumber of the pump mode and an idler mode with nearly zero wavenumber. This allows us to reliably generate ultrasharp spin wave dynamics with broad frequency tunability from the pump and magnetic field. We show that the spontaneous mode can be phase-locked to a probe tone, similar to an auto-oscillator. Furthermore, the spontaneous dynamics can be used to implement a high-gain magnonic parametric amplifier with a gain up to 40 dB. Our results open a new avenue for studying nonlinear magnonics and synchronization physics in propagating magnon geometry and for developing new magnonic devices.",
      "authors": [
        "Yi Li",
        "Carissa Kiehl",
        "Jinho Lim",
        "Cliff Abbott",
        "Pratap K. Pal",
        "Alex J. Szymczak",
        "Juliang Li",
        "Ralu Divan",
        "Clarence L. Chang",
        "Charudatta Phatak",
        "Dmytro A. Bozhko",
        "Axel Hoffmann",
        "Valentine Novosad"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall"
      ],
      "published": "2026-02-14 05:27:37+00:00",
      "link": "https://arxiv.org/pdf/2602.13608v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13490v1",
      "title": "Trion transfer in mixed-dimensional heterostructures",
      "abstract": "Charged excitons, or trions, offering unique spin and charge degrees of freedom, have primarily been investigated in doped systems where charges are long considered indispensable. Here, we present an alternative route to ultra-efficient trion emission from an intrinsic, defect-free semiconductor via a transfer mechanism. By exciting trions in two-dimensional tungsten-diselenide donors and transferring them into one-dimensional carbon-nanotube acceptors in mixed-dimensional heterostructures, we circumvent the usual carrier requirement, overcoming intrinsic Auger-quenching limitations. Benefitting from a reservoir effect induced by dimensional heterogeneity, this process achieves trion emission efficiencies increased by over 100-fold compared to conventional doping-based approaches, and remains robust across diverse doping conditions. Our findings extend the exciton transfer paradigm to the three-body quasiparticles, offering a new platform for advancing excitonic physics and trion-based optoelectronic/spintronic applications.",
      "authors": [
        "N. Fang",
        "U. Erkilic",
        "Y. R. Chang",
        "S. Fujii",
        "D. Yamashita",
        "C. F. Fong",
        "S. Morito",
        "K. Kanahashi",
        "T. Taniguchi",
        "K. Watanabe",
        "K. Ueno",
        "K. Nagashio",
        "Y. K. Kato"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall"
      ],
      "published": "2026-02-13 21:52:17+00:00",
      "link": "https://arxiv.org/pdf/2602.13490v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13190v1",
      "title": "Disorder viscosity correction approach to calculate spinodal temperature and wavelength",
      "abstract": "Spinodal decomposition, a key mechanism to microstructure formation in materials, has long posed challenges for predictive modeling, due to the need for parameter-free approaches that accurately capture local energy landscapes. In this work, we propose an approach to predict spinodal behavior by introducing a disorder viscosity correction to bulk free energies computed from finite, small, representative cells. We approximate the energy penalty required to transition into a disordered state to enable the stabilization of locally concave bulk free energy regions - essential for interface formation - while suppressing long-range concentration fluctuations. This approximation circumvents the complexity of full ab initio parameterization of interfacial properties and is well-suited for high-throughput and machine-learning frameworks. Our approach captures the necessary physics underpinning spinodal kinetics, offering a scalable route to predict spinodal regions in compositionally complex and high-entropy materials.",
      "authors": [
        "Simon Divilov",
        "Hagen Eckert",
        "Nico Hotz",
        "Xiomara Campilongo",
        "Stefano Curtarolo"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-13 18:56:21+00:00",
      "link": "https://arxiv.org/pdf/2602.13190v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13101v1",
      "title": "Physics-Informed Glass-Structure Descriptors for Assessing the Intrinsic Reactivity of Mixed Amorphous-Crystalline Precursors in Alkali-Activated Materials",
      "abstract": "Rapid and reliable assessment of the intrinsic reactivity of amorphous aluminosilicates is critical for their application in alkali-activated materials (AAMs) and blended cements. Although physics-informed glass-structure descriptors have demonstrated strong structure-reactivity relationships for predominantly amorphous systems, their extension to heterogeneous precursors with mixed crystalline-amorphous phases has been limited. Here, quantitative X-ray diffraction combined with bulk compositional analysis was used to reconstruct the effective amorphous compositions of five fly ashes (FAs) and three ground granulated blast-furnace slags (GGBSs). These compositions served as inputs for molecular dynamics simulations employing a melt-and-quench approach to generate atomic-scale structural models of the glassy phases. Based on these structures, the previously introduced descriptors, i.e., average metal oxygen dissociation energy and average metal oxygen bond strength, were refined to cover a broader compositional space spanning SiO2-Al2O3-TiO2-Fe2O3-CaO-MgO-MnO-Na2O-K2O. The refined descriptors exhibit strong inverse correlations with multiple independent reactivity indicators, including cumulative heat release from isothermal calorimetry, bound water content from thermogravimetric analysis, and compressive strength, for both single precursors and binary FA-GGBS blends activated with NaOH. These results demonstrate that physics-informed glass-structure descriptors can be extended from ideal amorphous systems to heterogeneous mixed-phase precursors and capture relative intrinsic reactivity trends in alkaline solutions. The proposed framework provides a transferable, structure-informed basis for comparative assessment of precursor reactivity that complements experimental testing and may inform precursor screening and mix designs for AAM and blended cement systems.",
      "authors": [
        "Zhu Pan",
        "Xinru Li",
        "Yucheng Wang",
        "Samira Hossain",
        "Kai Gong"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.dis-nn"
      ],
      "published": "2026-02-13 17:05:36+00:00",
      "link": "https://arxiv.org/pdf/2602.13101v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13034v1",
      "title": "Modulated Anti-Ferroelectric Smectic Phases with Orthogonal and Tilted Structures",
      "abstract": "The discovery of the ferroelectric nematic phase has brought with it a plethora of new polar liquid crystalline phases. One in particular is the anti-ferroelectric smectic A SmA\\textsubscript{AF} phase. In this letter we show via observation and analysis of satellite peaks in the X-ray scattering pattern that the structure of the SmA\\textsubscript{AF} phase involves a density modulation of $\\approx$10-20 nm lateral to the smectic layer normal. Further, we demonstrate a previously undiscovered phase where the anti-ferroelectric order is maintained into a tilted smectic phase demonstrating the robustness of the underlying frustration that leads to the modulated structure. We suggest that the modulations are only in a single dimension and appear parallel to the tilt plane. This new phase also shows a significantly different and complex response to an electric field from other discovered polar LC phases due to the ability to modulate both tilt and polarisation direction.",
      "authors": [
        "Jordan Hobbs",
        "Calum J. Gibb",
        "William C. Ogle",
        "Peter Medle Rupnik",
        "Natan Osterman",
        "Nerea Sebastián",
        "Alenka Mertelj",
        "Richard J. Mandle"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft"
      ],
      "published": "2026-02-13 15:42:32+00:00",
      "link": "https://arxiv.org/pdf/2602.13034v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12998v1",
      "title": "Variational study of the magnetization plateaus in the spin-1/2 kagome Heisenberg antiferromagnet: an approach from vision transformer neural quantum states",
      "abstract": "We analyze the magnetization curve of the spin-1/2 kagome Heisenberg model in a magnetic field. Using state-of-the-art variational wavefunctions based on neural networks, we confirm the presence of robust magnetization plateaus at $m=1/3$, $5/9$ and $7/9$ of the saturation value, stabilized by a spontaneous symmetry breaking of lattice translations with a $\\sqrt{3}\\times \\sqrt{3}$ unit cell. Regarding the more challenging $m=1/9$ plateau, we find two competing valence bond crystals depending on the system size, both breaking translation as well as point group symmetries and with a larger $3\\times 3$ unit cell. Such quantum states with local modulations of the magnetization average values could be observed experimentally in the near future.",
      "authors": [
        "Andreas Raikos",
        "Sylvain Capponi",
        "Fabien Alet"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-02-13 15:09:03+00:00",
      "link": "https://arxiv.org/pdf/2602.12998v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12855v1",
      "title": "Lecture notes: From Gaussian processes to feature learning",
      "abstract": "These lecture notes develop the theory of learning in deep and recurrent neuronal networks from the point of view of Bayesian inference. The aim is to enable the reader to understand typical computations found in the literature in this field. Initial chapters develop the theoretical tools, such as probabilities, moment and cumulant-generating functions, and some notions of large deviation theory, as far as they are needed to understand collective network behavior with large numbers of parameters. The main part of the notes derives the theory of Bayesian inference for deep and recurrent networks, starting with the neural network Gaussian process (lazy-learning) limit, which is subsequently extended to study feature learning from the point of view of adaptive kernels. The notes also expose the link between the adaptive kernel approach and approaches of kernel rescaling.",
      "authors": [
        "Moritz Helias",
        "Javed Lindner",
        "Lars Schutzeichel",
        "Zohar Ringel"
      ],
      "primary_category": "cond-mat.dis-nn",
      "categories": [
        "cond-mat.dis-nn"
      ],
      "published": "2026-02-13 12:05:32+00:00",
      "link": "https://arxiv.org/pdf/2602.12855v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12848v1",
      "title": "Exploring Wetting and Optical Properties of CuAg Alloys via Surface Texture Morphology Analysis",
      "abstract": "Copper-silver (CuAg) alloys are increasingly explored for applications in high-performance electrical and electronic systems, owing to their unique combination of high electrical and thermal conductivity and enhanced mechanical strength. Nevertheless, a thorough understanding of how these alloys surface characteristics fundamentally influence properties remains largely underdeveloped. Here, we explored the complex interplay between surface texture morphology, layer composition, wetting, and optical properties of Cu, Ag, and CuAg thin films deposited on textured silicon substrates via magnetron sputtering. Employing data mining and machine learning techniques, we identified robust correlations between contact angle and surface fractal dimension across all layer types promoting Cassie-Baxter surface state formation. Our analysis revealed a significant connection between layer thickness and surface topography entropy deficit, suggesting a dynamic evolution of surface order/disorder during metal film growth. Furthermore, we observed that contact angle sensitivity to layer thickness implied a correlation with microstructure evolution. Through K-Means clustering, we successfully categorized the formed surface textures morphology. Finally, a Random Forest regression model was developed to accurately predict water contact angles (Mean Absolute Error around 5 deg) using only texture and optical parameters. The model, along with accompanying Python code, is publicly available. Our findings establish a pathway towards targeted surface texture morphology engineering for tailored material performance.",
      "authors": [
        "Krzysztof Wieczerzak",
        "Grzegorz Cios",
        "Piotr Bała",
        "Johann Michler",
        "Benedykt R. Jany"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-13 11:54:10+00:00",
      "link": "https://arxiv.org/pdf/2602.12848v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12737v1",
      "title": "Quantum Anomalous Hall Effect in Rhombohedral Multilayer Graphene/hBN Moiré Superlattices",
      "abstract": "The recent discovery of robust quantum anomalous Hall (QAH) effect in rhombohedral multilayer graphene (RMG) aligned with hexagonal boron nitride (hBN) has established a highly versatile platform for correlated topological matter. This review synthesizes the experimental and theoretical progress in understanding these interaction-driven topological phases. Experimentally, the landscape has rapidly expanded from initial Chern insulators in trilayer systems to fully quantized QAH states in thicker systems. Theoretically, it is believed that moiré potential and electron-electron interaction cooperate and produce the QAH effect in such systems. Theoretical calculations also bring interesting questions, such as the formation of an interaction-driven topological phase known as an anomalous Hall crystal (AHC). This review comprehensively covers the experimental hallmarks, the theoretical frameworks, including continuum models and many-body approaches, and the ensuing physical picture that reconciles the roles of interactions, displacement fields, and the moiré potentials. We conclude by outlining outstanding open questions and future directions, positioning RMG/hBN systems at the forefront of topological quantum matter.",
      "authors": [
        "Jiannan Hua",
        "Jing Ding",
        "W. Zhu",
        "Shui-gang Xu"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-02-13 09:05:22+00:00",
      "link": "https://arxiv.org/pdf/2602.12737v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12608v1",
      "title": "Introduction to High-Temperature Superconductivity for Solid State Chemists",
      "abstract": "Superconductivity is one of the most amazing properties that metallic conductors exhibit. Electrical resistance is completely eliminated below the critical temperature (Tc), which is the most important parameter in superconductivity. Since the discovery of copper oxide superconductors 39 years ago, many solid state chemists have made significant contributions to the field by discovering new compounds and producing high-quality samples for physical measurements. However, superconductivity research remains challenging for most solid state chemists because it requires knowledge of complicated solid state physics. This manuscript aims to provide a simple, intuitive introduction to superconductivity using only fundamental physics concepts that solid state chemists are familiar with. The author investigates a wide range of materials and classifies them according to the superconductivity mechanisms that may drive them. Specifically focusing on a series of copper oxide superconductors with the highest Tc at ambient conditions, the remarkable material dependence of Tc and the underlying, unconventional superconductivity mechanism that leads to the high Tc are thoroughly examined. Although our understanding of cuprate superconductivity is still fragmented, the author believes that once the branches and leaves are removed, the story will be fairly simple, similar to the phonon-based superconductivity mechanism revealed by the BCS theory. Furthermore, potential strategies for raising the Tc of cuprates and other superconductors are discussed. The author hopes that this article will pique interest in superconductors in young solid state chemists and encourage them to pursue the discovery of still unknown and unexplored room-temperature superconductors in the future.",
      "authors": [
        "Zenji Hiroi"
      ],
      "primary_category": "cond-mat.supr-con",
      "categories": [
        "cond-mat.supr-con"
      ],
      "published": "2026-02-13 04:27:46+00:00",
      "link": "https://arxiv.org/pdf/2602.12608v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12607v1",
      "title": "Anomalous electrowetting of physicochemically heterogeneous surfaces",
      "abstract": "In the present work, a physiochemically heterogeneous surface has been fabricated to investigate the electrowetting behaviour of the surface. The polystyrene (PS) micro-humps with varied size are developed on the polydimethylsiloxane (PDMS) surface, which show an anomalous electrowetting behaviour. The surfaces are observed to be more electro-wettable than it is predicted by the classical Lippmann-Young equation. The observations are well understood considering the chemical heterogeneity of the surface, exhibiting a surface energy mismatch between the PS micro-humps and the PDMS layer. Further, the anomaly is comprehended by following the ridge formation around the triple-phase contact line and the varied surface roughness. A surface parameter is introduced in the Lippmann-Young equation that follows the experimental data with varied values of the parameter representing the physicochemically heterogeneous surfaces. A positive value of the surface parameter indicates strong pinning while a negative value represents depinning of the droplet. This parameter explains the faster electrowetting than predicted by the Lippmann-Young equation.",
      "authors": [
        "Rumal Singh",
        "Donjo George",
        "Prashant Hitaishi",
        "Samarendra P Singh",
        "Sajal K Ghosh"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft",
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-13 04:24:15+00:00",
      "link": "https://arxiv.org/pdf/2602.12607v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12588v1",
      "title": "Topology and edge modes surviving criticality in non-Hermitian Floquet systems",
      "abstract": "The discovery of critical points that can host quantized nonlocal order parameters and degenerate edge modes relocate the study of symmetry-protected topological phases (SPTs) to gapless regions. In this letter, we reveal gapless SPTs (gSPTs) in systems tuned out-of-equilibrium by periodic drivings and non-Hermitian couplings. Focusing on one-dimensional models with sublattice symmetry, we introduce winding numbers by applying the Cauchy's argument principle to generalized Brillouin zone (GBZ), yielding unified topological characterizations and bulk-edge correspondence in both gapped phases and at gapless critical points. The theory is demonstrated in a broad class of Floquet bipartite lattices, unveiling unique topological criticality of non-Hermitian Floquet origin. Our findings identify gSPTs in driven open systems and uncover robust topological edge modes at phase transitions beyond equilibrium.",
      "authors": [
        "Longwen Zhou"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall",
        "cond-mat.stat-mech",
        "quant-ph"
      ],
      "published": "2026-02-13 04:01:55+00:00",
      "link": "https://arxiv.org/pdf/2602.12588v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12538v1",
      "title": "Starch granules are instructive scaffolds for synergistic reinforcement and dissipation in hydrogel composites",
      "abstract": "A fundamental challenge in soft material design is the competition between rigidity and dynamicity, as stiffening mechanisms typically suppress energy dissipation. Here, we demonstrate that starch granules serve as instructive scaffolds that overcome this constraint, enabling the synergistic amplification of both elastic reinforcement and dynamic dissipation in hydrogels. We show that engineering the charge and structure of the filler-matrix interface enhances this synergistic response, which we propose arises from a dual-action physical mechanism: filler-induced polymer bundling of the polymer matrix provides structural reinforcement, while transient filler-matrix hydrogen bonding facilitates dissipation. Moreover, we reveal that binary blends of disparate filler species unexpectedly suppress these emergent properties, which we argue arises from enhanced entropic mixing. Our results provide a physical framework to overcome current design limitations in soft composites and sculpt their viscoelastic response from synergistic enhancement to strategic suppression for applications ranging from high-performance soft robotics to biomimetic tissue engineering.",
      "authors": [
        "Shirlaine Juliano",
        "Jasmine Samaniego",
        "Ian M Lillie",
        "Geraldine Ramirez",
        "Peter M Iovine",
        "Rae M Robertson-Anderson"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft"
      ],
      "published": "2026-02-13 02:36:56+00:00",
      "link": "https://arxiv.org/pdf/2602.12538v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12417v1",
      "title": "Information lattice approach to the metal-insulator transition",
      "abstract": "Correlation functions and correlation lengths are frequently used to describe phase transitions in quantum systems, but they require an explicit choice of observables. The recently introduced information lattice instead provides an observable-independent way to identify where and at which scale information is contained in quantum lattice models. Here, we use it to study the difference between the metallic and insulating regime of one-dimensional tight-binding chains. We find that the information per scale follows a power law in metals at low temperature and that Friedel-like oscillations are visible in the information lattice. At high temperature or in insulators at low temperature, the information per scale decays exponentially. Thus, the information lattice is a useful tool for analyzing the metal-insulator transition.",
      "authors": [
        "William Skoglund",
        "Elton Giacomelli",
        "Yiqi Yang",
        "Jens H. Bardarson",
        "Erik van Loon"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el",
        "quant-ph"
      ],
      "published": "2026-02-12 21:15:29+00:00",
      "link": "https://arxiv.org/pdf/2602.12417v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11963v1",
      "title": "Melting of quantum Hall Wigner and bubble crystals",
      "abstract": "A two-dimensional crystal melts via the proliferation and unbinding of topological defects, yet quantitatively predicting the melting temperature $T_m$ in real systems is challenging. Here we resolve this discrepancy in quantum Hall electron bubble phases by combining Corbino-geometry transport experiment in an ultraclean GaAs/AlGaAs quantum well for Landau levels 2 to 5 with Hartree--Fock elasticity and the full Kosterlitz--Thouless--Halperin--Nelson--Young melting criterion including the finite-temperature renormalization-group calculation. The theoretically obtained $T_m$ quantitatively captures the measured solid-liquid phase transition boundaries across all probed ranges, validating the bubble-crystal interpretation and establishing defect--mediated melting as a predictive framework for strongly interacting electronic solids. This agreement further supports using bulk transport to probe the energetics of topological defects and screening in quantum Hall physics, and the approach is readily extendable to other electronic crystals, including the generalized Wigner crystal in moiré Chern bands.",
      "authors": [
        "H. Xia",
        "Qianhui Xu",
        "Jiasen Niu",
        "Jian Sun",
        "Yang Liu",
        "L. N. Pfeiffer",
        "K. W. West",
        "Pengjie Wang",
        "Bo Yang",
        "Xi Lin"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall"
      ],
      "published": "2026-02-12 13:58:05+00:00",
      "link": "https://arxiv.org/pdf/2602.11963v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11916v1",
      "title": "Microscopic field theory for active Brownian particles with translational and rotational inertia",
      "abstract": "While active matter physics has traditionally focused on particles with overdamped dynamics, recent years have seen an increase of experimental and theoretical work on active systems with inertia. This also leads to an increased need for theoretical models that describe inertial active dynamics. Here, we present a microscopic derivation for a general continuum model describing the nonequilibrium thermodynamics of inertial active matter that generalizes several previously existing works. It applies to particles with translational and rotational inertia and contains particle density, velocity, angular velocity, temperature, polarization, velocity polarization, and angular velocity polarization as dynamical variables. We moreover discuss to which extend commonly used approximations (factorization and local equilibrium) used in the derivation of hydrodynamic models are applicable to inertial active matter.",
      "authors": [
        "Michael te Vrugt"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-12 13:11:50+00:00",
      "link": "https://arxiv.org/pdf/2602.11916v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11589v1",
      "title": "Thermodynamics of Shastry-Sutherland Model under Magnetic Field",
      "abstract": "Motivated by the recent experimental discovery of the $T$-linear specific heat in pressurized and magnetized Shastry-Sutherland Mott insulator SrCu$_2$(BO$_3$)$_2$, we perform the state-of-the-art thermal tensor-network computation on the Shastry-Sutherland model under a magnetic field. Our simulation results suggest the existence of a symmetric intermediate phase with $T$-linear specific heat at low temperature, occupying a large parameter space and separating the plaquette-singlet phase and antiferromagnetic phase at low fields and other symmetry-breaking phases at high fields before the system is fully polarized. Such an unexpected novel state bears an astonishing similarity to the experimental findings in the material. It opens the door to further investigations of the possible liberation of deconfined magnetized Dirac spinons by the competing interactions in this highly frustrated quantum magnet model, and by the combined effects of magnetic field and pressure in the the associated Shastry-Sutherland Mott insulator SrCu$_2$(BO$_3$)$_2$.",
      "authors": [
        "Menghan Song",
        "Chengkang Zhou",
        "Cheng Huang",
        "Zi Yang Meng"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-02-12 05:15:21+00:00",
      "link": "https://arxiv.org/pdf/2602.11589v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11302v1",
      "title": "Jamming-controlled stochasticity in metal-insulator switching",
      "abstract": "Understanding and controlling phase transitions is a fundamental part of physics and has been central to many technological revolutions, from steam engines to field-effect transistors. At present, there is strong interest in materials with strongly coupled structural and electronic phase transitions, which hold promise for energy-efficient technologies. Utilizing a structural phase transition and controlling its plasticity naturally leads to built-in memory, a key feature for emulating neurons and synapses in neuromorphic technologies. Here, $\\textit{operando}$ Bragg X-ray photon correlation spectroscopy is used to study the evolution of the nano-domain distribution at the micron-scale in neuromorphic devices made from the archetypal Mott insulator vanadium dioxide. It is found that after electrical switching, slow nano-domain reconfiguration occurs on timescales of thousands of seconds and that the domains undergo a jamming transition, offering control over switching stochasticity at the micron scale. More precisely, repetitive above-threshold currents plastically drive the system into a jammed/glassy state where switching becomes deterministic, while sub-threshold currents erase the short-term memory contained in the nano-domain distribution, recovering stochastic switching, thus offering a path for in-device learning. The results illustrate the importance of studying the nanoscale physics associated with phase transitions in strongly correlated materials, even for macroscopic devices, and offer guidance for future device operation schemes.",
      "authors": [
        "Nicolò D'Anna",
        "Nareg Ghazikhanian",
        "Katherine Matthews",
        "Daseul Ham",
        "Su Yong Lee",
        "Alex Frano",
        "Ivan K. Schuller",
        "Oleg Shpyrko"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ],
      "published": "2026-02-11 19:21:50+00:00",
      "link": "https://arxiv.org/pdf/2602.11302v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11285v1",
      "title": "Resource-Scalable Fully Quantum Metropolis-Hastings for Integer Linear Programming",
      "abstract": "Integer linear programming (ILP) remains computationally challenging due to its NP-complete nature despite its central role in scheduling, logistics, and design optimization. We introduce a fully quantum Metropolis-Hastings algorithm for ILP that implements a coherent random walk over the discrete feasible region using only reversible quantum circuits, without quantum-RAM assumptions or classical pre/post-processing. Each walk step is a unitary update that prepares coherent candidate moves, evaluates the objective and constraints reversibly -- including a constraint-satisfaction counter to enforce feasibility -- and encodes Metropolis acceptance amplitudes via a low-overhead linearized rule. At the logical level, the construction uses $\\mathcal{O}(n\\log_2 N)$ qubits to represent $n$ integer variables over the interval $[-N,\\,N-1]$, and the Toffoli-equivalent cost per Metropolis step grows linearly with the total logical qubit count. Using explicit ripple-carry adder constructions, we support linear objectives and mixed equality/inequality constraints. Numerical circuit-level simulations on a broad ensemble of randomly generated instances validate the predicted linear resource scaling and exhibit progressive thermalization toward low-cost feasible solutions under the annealing schedule. Overall, the method provides a coherent, resource-characterized baseline for fully quantum constraint programming and a foundation for incorporating additional quantum speedups in combinatorial optimization.",
      "authors": [
        "Gabriel Escrig",
        "Roberto Campos",
        "M. A. Martin-Delgado"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-11 19:01:45+00:00",
      "link": "https://arxiv.org/pdf/2602.11285v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11265v1",
      "title": "Thermal precondensation in gauge-fermion theories",
      "abstract": "Precondensation is a peculiar phenomenon in phase transitions, characterised by the occurrence of a condensate only over a finite range of length scales. It is closely connected to the emergence of domains, pseudo-gapped phases and spatial inhomogeneities in equilibrium. In this work, we show its occurrence in gauge-fermion theories in the chiral limit, close to the thermal chiral phase transition. We further show that the precondensation regime becomes increasingly pronounced and extends over a wider temperature range as the number of fermion flavours is increased. We analyse the underlying dynamics which is shared by a broad class of fermionic systems, ranging from condensed matter to high-energy physics. Specifically, we discuss the potential relevance of this phenomenon for physics beyond the Standard Model.",
      "authors": [
        "Álvaro Pastor-Gutiérrez",
        "Jan M. Pawlowski",
        "Franz R. Sattler"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "cond-mat.stat-mech",
        "cond-mat.str-el",
        "hep-lat",
        "hep-th"
      ],
      "published": "2026-02-11 19:00:02+00:00",
      "link": "https://arxiv.org/pdf/2602.11265v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11111v1",
      "title": "Nonreciprocal many-body physics",
      "abstract": "Reciprocity is a fundamental symmetry present in many natural phenomena and engineered systems. Distinct situations where this symmetry is broken are typically grouped under the umbrella term \"nonreciprocity\", colloquially defined by: the action of A on B $\\neq$ the action of B on A. In this review, we elucidate what nonreciprocity is by providing an introduction to its most salient classes: nonvariational dynamics, violations of Newton's third law, broken detailed balance, nonreciprocal responses and nonreciprocity of arbitrary linear operators. Next, we point out where to find these manifestations of non-reciprocity, from ensembles of particles with field mediated interactions to synthetic neural networks and open quantum systems. Given this breadth of contexts and the lack of an all-encompassing definition, it makes it all the more intriguing that some general conclusions can be gathered, when distinct definitions of nonreciprocity overlap. We explore what these universal consequences are with a special emphasis on collective phenomena that arise in nonreciprocal many-body systems. The topics covered include nonreciprocal phase transitions and non-normal amplification of noise and perturbations. We conclude with some open questions.",
      "authors": [
        "Michel Fruchart",
        "Vincenzo Vitelli"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "cond-mat.soft",
        "nlin.PS",
        "quant-ph"
      ],
      "published": "2026-02-11 18:24:32+00:00",
      "link": "https://arxiv.org/pdf/2602.11111v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11104v1",
      "title": "Reentrance in a Hamiltonian flocking model",
      "abstract": "The clustering of self-motile and repulsive particles, so-called motility-induced phase separation (MIPS), is one of the clearest signatures of active physics. Typically, increasing the amplitude of self-motility increases the degree of clustering, however for high enough self-motility the homogeneous phase is reentered. Here, we report that such reentrance naturally emerges in a Hamiltonian (conservative) model known to recapitulate properties of (active) bird flocks, and exhibits clustering behaviour reminiscent of MIPS. We numerically demonstrate the reentrance of the homogeneous phase and identify the underlying mechanism as a competition between the amplitude of a spin-velocity coupled drive and mobility-limited kinetic frustration. Specifically, we reveal that strong spin-velocity coupling suppresses transverse diffusion, thereby leading the system into an arrest that closes the window for phase separation. Overall, our work offers a Hamiltonian, conservative, bridge between reentrant physics across equilibrium and non-equilibrium materials.",
      "authors": [
        "Letian Chen",
        "Luke K. Davis"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-11 18:16:22+00:00",
      "link": "https://arxiv.org/pdf/2602.11104v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11071v1",
      "title": "Long-range electrostatics in atomistic machine learning: a physical perspective",
      "abstract": "The inclusion of long-range electrostatics in atomistic machine learning (ML) is receiving increasing attention for achieving quantum-mechanical accuracy in predicting a wide range of molecular and material properties. However, there is still no general prescription on how long-range physical effects should be incorporated into the model while preserving well-established locality principles underlying most transferable ML representations. Here, we provide a physical perspective on the problem, by discussing how distinct contributions to the system's electrostatics can be captured through the adoption of different learning paradigms. Specifically, we discern between local charge models, which rely either on explicit charge-density decompositions or implicit auxiliary variables, and models where a notion of nonlocality is deliberately introduced, either via self-consistent procedures or by using nonlocal descriptors and learning architectures. We further address the related aspect of incorporating finite-field effects through the coupling with the system's polarization, relevant for the application of an external electric bias. We conclude by discussing the implications for the simulation of electrochemical interfaces, where long-range electrostatics are essential to capture the interplay between charge redistribution, interfacial dynamics, and ionic screening, and for ionic transport phenomena, which, although less explored, appear far less sensitive to their inclusion.",
      "authors": [
        "Federico Grasselli",
        "Kevin Rossi",
        "Stefano de Gironcoli",
        "Andrea Grisafi"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-11 17:38:33+00:00",
      "link": "https://arxiv.org/pdf/2602.11071v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10950v1",
      "title": "Photon counting beyond the rotating-wave approximation",
      "abstract": "Open quantum systems are often described by a Lindblad master equation, which relies on a set of approximations, most importantly the rotating-wave approximation which is only valid for weak damping. In the Lindblad setting, dissipative processes are described through jump operators, distinguishing between absorption and emission of photons. This enables the simple identification of emitted photons which provides a straightforward way to obtain the radiation statistics. Outside the rotating-wave limit, the Lindblad approach does not work. Open quantum systems can then be described by, e.g., the quantum Langevin equation. However, in this framework the number of emitted photons is not easily accessible. In this work, we point out how to obtain the photon counting statistics from a quantum Langevin equation and provide an expression for the photon current operator, for arbitrary systems coupled to linear environments. As an example, we employ the method to study the radiation statistics of a damped harmonic oscillator at finite temperature beyond the rotating-wave approximation. We show that even outside the rotating-wave limit, the most important contribution to the radiation statistics can be captured by an effective Lindblad equation, thus extending the range of possible applications of the Lindblad framework.",
      "authors": [
        "Steven Kim",
        "Fabian Hassler"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall",
        "quant-ph"
      ],
      "published": "2026-02-11 15:37:06+00:00",
      "link": "https://arxiv.org/pdf/2602.10950v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10830v1",
      "title": "Emulation of large-scale qubit registers with a phase space approach",
      "abstract": "A phase-space approach is used and benchmarked for the simulation of the continuous-time evolution of large registers of qubits. It is based on a statistical ensemble of independent mean-field trajectories, where mean-field is introduced at the level of the qubits, substituting quantum fluctuations/correlations with classical ones. The approach only involves at worse a quadratic cost in the system size, allowing to simulate up to several thousands of qubits on a classical computer. It provides qualitatively accurate description of one-qubit observables evolutions, making it a useful reference in comparison to techniques limited to small qubit numbers. The predictive power is however less robust for multi-qubits observables. We benchmark the method on the $k$-local transverse-field Ising model (TFIM), considering a large variety of systems ranging from local to all-to-all interactions, and from weak to strong coupling regimes, with up to 2000 qubits. To showcase the versatility of the approach, simulations on 2D and 3D Ising models are also made.",
      "authors": [
        "Christian de Correc",
        "Denis Lacroix",
        "Corentin Bertrand"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.str-el",
        "nucl-th"
      ],
      "published": "2026-02-11 13:16:25+00:00",
      "link": "https://arxiv.org/pdf/2602.10830v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10421v1",
      "title": "Quantum Brownian motion with non-Gaussian noises: Fluctuation-Dissipation Relation and nonlinear Langevin equation",
      "abstract": "Building upon the work of Hu, Paz, and Zhang [1,2] on open quantum systems we consider the quantum Brownian motion (QBM) model with one oscillator (position variable $x$) as the system, {\\it nonlinearly} coupled to an environment of $N$ harmonic oscillators (with mass $m_n$, natural frequency $ω_n$, position $q_n$ and momentum $p_n$ variables) in the form $\\sum_{n}\\left(v_{n1}(x)q_{n}^{k}+v_{n2}(x)p_{n}^{l}\\right)$ where $k, l$ are integers (the present work only considers the $k=l=2$ cases). The vertex functions $v_{n1}, v_{n2} $ are of the form $v_{n1}=λC_{n1} f(x), v_{n2}(x)=-λ\\,C_{n2}m_{n}^{-2}ω_{n}^{-2}f(x)$ where $C_{n1,2}$ are the coupling constants with the $n$th oscillator, $f(x)$ is any arbitrary function of $x$, and $λ$ is a dimensionless constant. Employing the closed-time-path formalism the influence action $S_{IF}$ is calculated using a perturbative expansion in $λ$. It is possible to identify the terms in $S_{IF}$ quadratic or higher in $Δ(s)\\equiv f(x_{+}(s))-f(x_{-}(s))$ to constitute the noise kernel, while terms linear in $Δ$ to that of the dissipation kernel. The non-Gaussian noise kernel gives rise to non-zero three-point correlation function of the corresponding stochastic force. The pathway presented here should be useful for the exploration of \\textit{non-Gaussian properties of systems nonlinearly coupled with their environments}; examples in early universe cosmology and in quantum optomechanics (QOM) are mentioned. A modified fluctuation-dissipation relation (FDR) is also established, which ensures the consistency of the model and the accuracy of results even at higher perturbative orders. Another result of significance is the derivation of a nonlinear Langevin equation which is expected to be useful for many open quantum system applications.",
      "authors": [
        "Hing-Tong Cho",
        "Bei-Lok Hu"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.stat-mech",
        "hep-th"
      ],
      "published": "2026-02-11 02:03:26+00:00",
      "link": "https://arxiv.org/pdf/2602.10421v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10351v1",
      "title": "Superconductivity in strongly correlated systems for local repulsive interactions",
      "abstract": "The understanding of the mechanisms responsible for superconductivity in strongly correlated systems is an interesting and important subject in condensed matter physics. Several theoretical proposals were considered for these systems. The Coulomb interaction between electrons allow a new approach to study this problem. In this paper, we use a usual Hubbard model with a local repulsive interaction to describe a 2D system. The system of equations are solved using the Green's functions method, within a Hubbard-I mean field approximation, which allows to treat the strong interaction limit. We consider both cases of attractive and repulsive interactions and obtain the zero temperature phase diagram of the model. Our results show, in the repulsive case, the existence of a superconducting ground state mediated by the kinetic electronic energy and described by a non-local order parameter. A minimum value of the repulsive interaction $U_{min}$ is required to create a pairing state. At finite temperatures, for strong interactions, the critical temperature $T_c$ shows a saturation similar to the Bose-Einstein condensation observed for strong attractive interactions.",
      "authors": [
        "Humberto M. Silva",
        "Francisco Dinola Neto",
        "Griffith M. A. R.",
        "Minos A. Neto",
        "Octavio D. R. Salmon",
        "Mucio A. Continentino",
        "Amos Troper"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-02-10 22:46:56+00:00",
      "link": "https://arxiv.org/pdf/2602.10351v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10276v1",
      "title": "Cyclic active refrigerators",
      "abstract": "Thermodynamic cycles are idealized processes that can convert heat into work or produce heat flow against a temperature gradient with the input of work. They remain an active area of research in modern stochastic thermodynamics. In particular, cyclic active heat engines have been shown to display a rich phenomenology, such as ``violations'' of the Carnot bound on efficiency and an improved performance in comparison to their passive counterparts. We introduce the concept of cyclic active refrigerators using a previously derived second law for cyclic active systems. We show that for cyclic active refrigerators, a naive definition of the coefficient of performance can exceed the bound set by the standard second law for passive refrigerators. We also show that cyclic active systems can behave like a Maxwell's demon, with heat flowing from the cold to the hot reservoir without any work input. Beyond this phase, cyclic active systems can enter a hybrid phase, functioning as both a heat engine and a refrigerator simultaneously. Our results are obtained with two models that involve active Brownian particles, a simpler one that allows for analytical results and a more realistic one that is analyzed through numerical simulations.",
      "authors": [
        "S. Liu",
        "A. Datta",
        "A. C. Barato"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-10 20:40:11+00:00",
      "link": "https://arxiv.org/pdf/2602.10276v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10236v1",
      "title": "Computational discovery of cathode materials for rechargeable aqueous zinc-ion batteries",
      "abstract": "Rechargeable aqueous zinc-ion batteries (RAZIBs) attract considerable scientific and commercial interest for deployment in grid-scale energy storage due to higher safety and lower manufacturing cost when compared to lithium-ion batteries. However, currently studied cathode materials suffer from severe capacity fade when cycling at rates appropriate for grid-scale applications ($<$ C/2), which hampers the commercialization of RAZIBs. To address the present limitation on cathode material availability, more than 2000 previously synthesized oxides, chalcogenides, Prussian blue analogues, and polyanion materials were computationally screened for the discovery of highly stable RAZIB cathode materials. The structural, electrochemical, and chemical properties of the materials were respectively evaluated through an investigation of the available Zn$^{2+}$ percolation paths in the crystal structure, the stability of the material in aqueous media under RAZIB operation conditions, and the attained transition metal oxidation state during cycling. The transition metal oxidation state and intercalating ion coordination environment were determined to govern the magnitude of the calculated intercalation potential, with this finding directly supporting the development of batteries with high operation potentials. Finally, 10 previously unexplored materials were identified with leading metrics for operation as RAZIB cathode materials, such as high Zn$^{2+}$ (de)intercalation potential, electrochemical stability, theoretical gravimetric capacity, and energy density, being here proposed for experimental testing. The materials identified in this study demonstrate a guide for advancing the available cathode materials for RAZIB, and help expedite the establishment of RAZIB as a commercially viable technology for grid-scale energy storage.",
      "authors": [
        "Caio Miranda Miliante",
        "Brian D. Adams",
        "Drew Higgins",
        "Oleg Rubel"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-10 19:33:35+00:00",
      "link": "https://arxiv.org/pdf/2602.10236v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10214v1",
      "title": "Excited String States and D-branes from Infinite Width Neural Networks",
      "abstract": "We explore recent proposal to represent worldsheet string path integrals by integrating over parameters of a wide random-feature neural network whose output is identified with the embedding field $X^μ$. In this paper we extend it focusing on scattering with excited states insertions and for worldsheets with boundaries introducing fixed-feature Gaussian normal-ordering prescription for derivative composites (removing the neural contact term at finite width), and propose realization of mixed Neumann/Dirichlet boundary conditions interpreted as a neural D$p$-brane. As concrete outputs, we derive the sphere four-point integrand with a single $(1,1)$ insertion and the disk four-tachyon amplitude on a D$p$-brane, recovering the expected derivative prefactors, boundary exponents, and momentum-conservation limits after renormalization.",
      "authors": [
        "Dmitry S. Ageev",
        "Yulia A. Ageeva"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "cond-mat.dis-nn"
      ],
      "published": "2026-02-10 19:06:00+00:00",
      "link": "https://arxiv.org/pdf/2602.10214v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09881v1",
      "title": "Framework for (non-)adiabatic chiral state conversion: from non-Hermitian Hamiltonians to Liouvillians",
      "abstract": "Adiabatic chiral state conversion (CSC) is one of the many counterintuitive effects associated with non-Hermitian physics. In quantum systems, numerous works have demonstrated this phenomenon under both non-Hermitian Hamiltonian and Lindblad evolution. However, despite considerable progress, the physical mechanism behind it has been a subject of debate. In this work, we present a unified framework that explains CSC in any non-Hermitian system, encompassing non-Hermitian Hamiltonian, Lindblad, and hybrid settings. Our framework relies on perturbative, non-adiabatic corrections to adiabatic evolution and consistently predicts CSC with only the lowest-order corrections. We demonstrate its efficacy with models of single and coupled dissipative qubits, obtaining analytical solutions for the conversion fidelity. Our analysis further reveals the role of non-perturbative dynamics, which can be present even in apparently slow trajectories. We show that this property can be utilised to considerably enhance state conversion. Finally, we demonstrate that CSC can be observed in a model without the presence of exceptional points.",
      "authors": [
        "Elna Svegborn",
        "Shishir Khandelwal"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.mes-hall"
      ],
      "published": "2026-02-10 15:21:56+00:00",
      "link": "https://arxiv.org/pdf/2602.09881v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09855v1",
      "title": "Multiple Layer-Selective Polar Charge Density Waves in ${\\rm{EuTe}}_{4}$",
      "abstract": "${\\rm{EuTe}}_{4}$ is a polar charge density wave (CDW) material, with giant thermal hysteresis and non-volatile state switching under electric and optical fields, attracting great attention in recent years. However, the in-depth understanding of these anomalous phenomena remains elusive. Herein, via first-principles calculations, we reveal that the polar CDW state in ${\\rm{EuTe}}_{4}$ hosts a novel layer-selective nature, wherein multiple energetically close CDW configurations coexist and exhibit low interconversion energy barriers. Monte Carlo simulations indicate that the giant thermal hysteresis in ${\\rm{EuTe}}_{4}$ originates from a phase transition mainly driven by the change of configurational entropy, around which the material hosts a metastable CDW state characterized by diverse local polar configurations breaking the out-of-plane translational symmetry. The configurational composition of this metastable CDW state can be effectively controlled by electric and optical fields, thereby enabling non-volatile state switching. Our theoretical findings align well with recent experimental observations in ${\\rm{EuTe}}_{4}$ and pave the way for exploring the emerging phenomena and applications of polar CDW in multilayered systems.",
      "authors": [
        "Wen-Han Dong",
        "Wenhui Duan",
        "Yong Xu",
        "Peizhe Tang"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall"
      ],
      "published": "2026-02-10 14:55:19+00:00",
      "link": "https://arxiv.org/pdf/2602.09855v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09739v1",
      "title": "MoireStudio: A Universal Twisted Electronic Structure Calculation Package",
      "abstract": "Twistronics is an emerging and captivating field in condensed matter physics and material science. However, accurately and efficiently calculating the electronic structures of twisted systems remains a significant challenge. To address this, we have developed MoireStudio, a universal Python-based computational package for twisted electronic structures. Its functionalities include commensurate structure search, structure generation, parameterization, and construction for tight-binding models and continuum models, and the precise incorporation of full relaxation effects. The package is applicable to arbitrary combinations of two-dimensional materials, including rectangular lattices and heterostructures. User-friendly and easy to use, MoireStudio supports parallel large-scale computations, provides visualization capabilities, and offers interfaces with third-party software. It is poised to become a convenient and powerful tool for researchers in twistronics fields.",
      "authors": [
        "Junxi Yu",
        "Yichen Liu",
        "Cheng-Cheng Liu"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-10 12:51:46+00:00",
      "link": "https://arxiv.org/pdf/2602.09739v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09709v1",
      "title": "Raman Spectroscopic Investigation of Kitaev Quantum Spin Liquids",
      "abstract": "Quantum spin liquids, a highly topologically entangled, dynamically correlated state where quantum fluctuations preclude any long-range ordering down to absolute zero. In the search for a topologically robust qubit, the scientific community has been in continuous hunt for real quantum spin liquid systems. Alexei Kitaev in his exactly solvable model for a spin-1/2 two-dimensional honeycomb lattice, presented a system that hosts a topologically protected state (Majorana zero-modes). Under an applied external field, the Kitaev spin liquids turn into a topologically non-trivial chiral spin-liquid state with non-abelian anionic excitations, which is crucial for quantum computing. Earlier theoretical predictions advocated that Kitaev physics can be realized in spin-orbit-coupled Mott insulators such as honeycomb irradiates and ruthenates. However, the experimental findings continuously challenge the theoretical aspects, indicating the presence of non-Kitaev interactions in real materials, where the dimensionality, disorder (vacancy), chemical composition, generalized spin-S, and external perturbations (pressure, magnetic field, temperature) can actively tune the Kitaev interactions and the ground state excitations. In this review article, a comprehensive discussion is included with an updated literature survey in the context of the potential of Raman spectroscopy as a probe for Kitaev quantum spin liquids.",
      "authors": [
        "Vivek Kumar",
        "Pradeep Kumar"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-02-10 12:12:04+00:00",
      "link": "https://arxiv.org/pdf/2602.09709v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09218v1",
      "title": "A parameterised equation of state, glass transition and jamming of the hard sphere system",
      "abstract": "A Gamma-distribution based potential energy landscape (PEL) theory has recently been proposed for supercooled liquids and glasses. This new PEL theory introduces a singularity term in the equation of state (EoS) suitable for representing the pressure of a glassy or jammed system. Using this framework, a parameterised EoS, Z(eta J), is developed with the random-jammed-packing fraction, eta J, as an input. This EoS is capable of accurately calculating the compressibility (pressure) across the entire metastable and glassy region from eta J=0.62 to 0.66, while seamlessly passing through the stable fluid region. Two special cases (paths) are examined in detail. The first path exhibits a singularity at the random close packing eta J=eta rcp=0.64, traversing the metastable region explored by most simulations. Various thermodynamic properties calculated are compared to simulation data, showing excellent agreements. The second case addresses the first analytical EoS for the ideal glass transition in the hard sphere system. Finally, the transport properties of the hard sphere fluid are modeled using the Arrhenius law and the excess entropy scaling law. It is found that both laws fail (with slope changing) at eta=0.555, where the heat capacity peaks and the contributions of inherent structures and jamming effects begin to emerge.",
      "authors": [
        "Hongqin Liu"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-09 21:40:52+00:00",
      "link": "https://arxiv.org/pdf/2602.09218v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09149v1",
      "title": "Quantum annealing and condensed matter physics",
      "abstract": "Quantum annealing leverages the properties of interacting quantum spin systems to solve computational problems, typically optimisation problems. Current hardware now has capabilities that can be used to solve condensed matter physics problems, too. In this topical review, we provide an overview of quantum annealing aimed at condensed matter physicists, to show the mutual benefits of working together to understand and improve how quantum annealers work, and to use them to advance condensed matter physics.",
      "authors": [
        "Viv Kendon",
        "Nicholas Chancellor"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.dis-nn"
      ],
      "published": "2026-02-09 19:52:44+00:00",
      "link": "https://arxiv.org/pdf/2602.09149v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09086v1",
      "title": "Volume-law protection of metrological advantage",
      "abstract": "Although entanglement can boost metrological precision beyond the standard quantum limit, the advantage often disappears with particle loss. We demonstrate that scrambling safeguards precision by dispersing information about the encoded parameter into many-body correlations. For Haar-random scrambling unitaries, we derive exact formulas for the average quantum Fisher information (QFI) of the reduced state after tracing out lost particles. The result exhibits a threshold; any remaining subsystem larger than $N/2$ recovers the full QFI, while smaller subsystems contain negligible information. We link this threshold to the scrambling-induced transition from area-law to volume-law entanglement and the associated growth of the Schmidt rank. We outline two realizations -- a brickwork circuit and chaotic XX-chain evolution -- and demonstrate the protection of one-axis-twisted probes against the loss of up to half of the particles.",
      "authors": [
        "Piotr Wysocki",
        "Jan Chwedeńczuk",
        "Marcin Płodzień"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.quant-gas"
      ],
      "published": "2026-02-09 19:00:00+00:00",
      "link": "https://arxiv.org/pdf/2602.09086v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.08982v1",
      "title": "W-SLDA Toolkit: A simulation platform for ultracold Fermi gases",
      "abstract": "We present the W-SLDA Toolkit, a general-purpose software package for simulating ultracold Fermi gases within the framework of density functional theory and its time-dependent extensions. The toolkit enables fully microscopic studies of interacting superfluid systems across the BCS-BEC crossover, including spin-imbalanced configurations and arbitrary external geometries. It provides both static and time-dependent solvers capable of describing a broad range of phenomena in one-, two-, and three-dimensional settings. In addition, the toolkit incorporates functionality for solving the standard Bogoliubov-de Gennes equations for fermions, extending its applicability to other physical systems such as superconductors. The code is implemented in C with GPU acceleration and is optimized for hybrid CPU/GPU execution on modern high-performance computing platforms. It ensures scalability on leadership-class supercomputers, enabling fully three-dimensional simulations with large atomic numbers, and allows for direct benchmarks of ultracold-atom experimental setups. Its modular architecture facilitates straightforward extensions, user customization, and seamless interoperability with other scientific software frameworks. Furthermore, an extensive collection of practical usage examples is provided through the integrated reproducibility packs functionality, ensuring transparency and reproducibility of computational results.",
      "authors": [
        "Gabriel Wlazłowski",
        "Piotr Magierski",
        "Michael McNeil Forbes",
        "Aurel Bulgac"
      ],
      "primary_category": "cond-mat.quant-gas",
      "categories": [
        "cond-mat.quant-gas",
        "cond-mat.supr-con"
      ],
      "published": "2026-02-09 18:28:50+00:00",
      "link": "https://arxiv.org/pdf/2602.08982v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16649v1",
      "title": "Design Principles for Fluid Molecular Ferroelectrics",
      "abstract": "Fluid molecular ferroelectrics are a new class of organic materials where ferroelectricity is found in conjunction with 3D fluidity whilst still retaining spontaneous polarization values comparable to their traditional solid state counterparts. One of the major challenges for soft condensed matter physics is predicting whether a fluid molecular material will form ferroelectric phase with nematic or smectic order. Through the synthesis of forty five systematically varied molecules, and by analogy to solid molecular ferroelectrics, is it shown that subtle hydrogen fluorine substitution allows for tuneable syn-parallel pairing motifs resulting in either specific pairings leading too geometrically constrained lamellar order or diversified pairings stabilising nematic ordering. Large-scale, fully atomistic molecular dynamics simulations reveal that smectic ferroelectricity emerges from discrete lateral pairing modes, whereas nematic phases arise from a multiplicity of equivalent polar configurations. Together, these findings establish experimentally validated design principles for fluid molecular ferroelectrics and provide a predictive framework for engineering functional polar fluids.",
      "authors": [
        "Calum J Gibb",
        "Jordan Hobbs",
        "William C Ogle",
        "Richard J Mandle"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-18 17:45:26+00:00",
      "link": "https://arxiv.org/pdf/2602.16649v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16471v1",
      "title": "Monte Carlo study of the classical antiferromagnetic $J_1$-$J_2$-$J_3$ Heisenberg model on a simple cubic lattice",
      "abstract": "An extensive Monte Carlo study of the classical Heisenberg model on a simple cubic lattice with antiferromagnetic exchange interactions $J_n$ between the first, second, and third neighbors is performed in a broad region of $J_2 / J_1$, $J_3 / J_1$ ratios, and temperature. The character of the phase transitions is analyzed via the Binder cumulant method. The Neel temperature $T_{\\mathrm{N}}$ and the frustration parameter (the ratio $f= |θ|/T_{\\mathrm{N}}$, $θ$ being the Curie-Weiss temperature) are calculated. A comparison with the Tyablikov approximation is carried out. The strength of the frustration effects is explored. Possible applications to antiferromagnetic perovskites, such as CaMnO$_3$ and HgMnO$_3$, are discussed.",
      "authors": [
        "A. N. Ignatenko",
        "S. V. Streltsov",
        "V. Yu. Irkhin"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-02-18 14:02:37+00:00",
      "link": "https://arxiv.org/pdf/2602.16471v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16331v1",
      "title": "Where Multipartite Entanglement Localizes: The Junction Law for Genuine Multi-Entropy",
      "abstract": "We uncover a \"junction law\" for genuine multipartite entanglement, suggesting that in gapped local systems multipartite entanglement is controlled and effectively localized near junctions where subsystem boundaries meet. Using the Rényi-2 genuine multi-entropy $\\mathrm{GM}^{(\\mathtt{q})}_2$ as a diagnostic of genuine $\\mathtt{q}$-partite entanglement, we establish this behavior in $(2+1)$-dimensional gapped free-fermion lattices with correlation length $ξ$. For partitions with a single junction, $\\mathrm{GM}^{(\\mathtt{q})}_2$ exhibits a universal scaling crossover in $L/ξ$, growing for $L\\llξ$ and saturating to a $ξ$-dependent constant for $L\\ggξ$, up to $\\mathcal{O}(e^{-L/ξ})$ corrections. In sharp contrast, for partitions without a junction, $\\mathrm{GM}^{(\\mathtt{q})}_2$ is exponentially suppressed in $L/ξ$ and drops below numerical resolution once $L\\ggξ$. We observe the same pattern for $\\mathtt{q}=3$ (tripartite) and $\\mathtt{q}=4$ (quadripartite) cases, and further corroborate this localization by translating the junction at fixed system size. We also provide a geometric explanation of the junction law in holography. Altogether, these results show that in this gapped free-fermion setting genuine multipartite entanglement is localized within a correlation-length neighborhood of junctions.",
      "authors": [
        "Norihiro Iizuka",
        "Akihiro Miyata"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "cond-mat.stat-mech",
        "quant-ph"
      ],
      "published": "2026-02-18 10:12:06+00:00",
      "link": "https://arxiv.org/pdf/2602.16331v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16176v1",
      "title": "Reinforcement learning for path integrals in quantum statistical physics",
      "abstract": "Machine learning is rapidly finding its way into the field of computational quantum physics. One of the most popular and widely studied approaches in this direction is to use neural networks to model quantum states (NQS) in the Hamiltonian formulation of quantum mechanics. However, an alternative angle of attack to leverage machine learning in physics is through the path integral formulation, which has so far received far more limited attention. In this paper, we explore how reinforcement learning can be used to compute a class of Euclidean path integrals that yield the thermal density matrix of a quantum system, thereby enabling the computation of the free energy or other thermal expectation values. In particular, we propose a two-step approach with the unique feature that after a variational approximation for a quantity is obtained in a first step, it can then be used to efficiently compute the exact result in a second step. We benchmark this method on several simple systems and then apply it to the quantum rotor chain.",
      "authors": [
        "Timour Ichmoukhamedov",
        "Dries Sels"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-18 04:26:03+00:00",
      "link": "https://arxiv.org/pdf/2602.16176v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15662v1",
      "title": "Quantum Coulomb Liquids of Different Rank in the Breathing Pyrochlore Antiferromagnet",
      "abstract": "Emergent gauge fields and Coulomb liquids have long been central to the physics of frustrated pyrochlore magnets, yet their realization beyond conventional, i.e. rank-1 $U(1)$, spin ice and into fully quantum higher-rank regimes has remained elusive. Here we provide a controlled demonstration of this physics in the spin-$\\tfrac{1}{2}$ quantum Heisenberg antiferromagnet on the breathing pyrochlore lattice with symmetry-allowed Dzyaloshinskii--Moriya interactions, using the pseudofermion functional renormalization group. We show that tuning the breathing asymmetry stabilizes extended quantum analogues of both rank-1 and rank-2 $U(1)$ Coulomb liquids within a single microscopic model, directly distinguished by their characteristic pinch-point morphologies in momentum space. This provides the first controlled quantum realization in three dimensions where gauge theories of different rank emerge within a single microscopic spin Hamiltonian. In addition, quantum fluctuations qualitatively reshape the classical nearest-neighbor atlas of phases, causing an incommensurate spiral instability and an extended quantum-disordered regime without dipolar order, both absent from the classical model. Our results establish the breathing pyrochlore as a timely and experimentally relevant platform where higher-rank gauge constraints, conventional magnetic order, and fluctuation-driven quantum phases compete on equal footing, opening a direct route to diagnosing emergent gauge structure in three-dimensional quantum magnets.",
      "authors": [
        "Lasse Gresista",
        "Daniel Lozano-Gómez",
        "Matthias Vojta",
        "Simon Trebst",
        "Yasir Iqbal"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-02-17 15:38:21+00:00",
      "link": "https://arxiv.org/pdf/2602.15662v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15574v1",
      "title": "The physics of crêpes: Elasto-gravity control of soft folding",
      "abstract": "Like a crêpe resting on a plate, a thin elastic sheet can fold smoothly under its own weight, forming reversible shapes without creases or imposed hinges. Such soft folds arise from a balance between elastic bending and gravity, yet their stability, packing limits, and dynamics remain poorly understood. Here we show that these behaviors are governed by a single physical length scale, the elasto-gravity length $\\ell_{eg}$. Using experiments and heavy-elastica theory, we demonstrate that $\\ell_{eg}$ sets the characteristic fold geometry, determines when a fold becomes unstable and unfolds, and limits how many reversible folds can be stacked in rectangular and circular sheets. In particular, when lengths are rescaled by $\\ell_{eg}$, fold shapes and stability thresholds collapse across materials and thicknesses. We further show that unfolding follows a universal speed scaling $v \\sim \\sqrt{g\\,\\ell_{eg}}$, revealing a gravity-controlled time scale for the release of stored bending energy. Together, these results establish a unified physical framework for reversible folding, compact storage, and gravity-assisted deployment of thin elastic sheets.",
      "authors": [
        "Tom Marzin",
        "Barath Venkateswaran",
        "Yuchen Xi",
        "Sunghwan Jung",
        "P. -T. Brun"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft"
      ],
      "published": "2026-02-17 13:38:55+00:00",
      "link": "https://arxiv.org/pdf/2602.15574v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15512v1",
      "title": "Anomalous transport in the Fermi-Pasta-Ulam-Tsingou model: a review and open problems",
      "abstract": "This review provides an up-to-date account of energy transport in Fermi-Pasta-Ulam-Tsingou (FPUT) chains, a key testbed for nonequilibrium statistical physics. We discuss the transition from the historical puzzle of thermalization to the discovery of anomalous heat transport, where the effective thermal conductivity $κ$ diverges with system size $L$ as $κ\\propto L^δ$. The article clarifies the distinction between two universality classes: the FPUT-$αβ$ model, characterized by $δ= 1/3$ and linked to Kardar-Parisi-Zhang (KPZ) physics, and the symmetric FPUT-$β$ model, where numerical and theoretical evidence support $δ= 2/5$. We investigate how finite-size effects - unavoidably induced by the thermostatting protocols - can disguise the asymptotic scaling. Additionally, we analyze the role of conservative noise in preserving hydrodynamic properties and examine how proximity to integrable limits leads to long-lived quasi-particles and, thereby, to diffusive regimes over intermediate spatial scales.",
      "authors": [
        "Stefano Lepri",
        "Roberto Livi",
        "Antonio Politi"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "nlin.CD"
      ],
      "published": "2026-02-17 11:40:41+00:00",
      "link": "https://arxiv.org/pdf/2602.15512v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15495v1",
      "title": "Ising Model with Power Law Resetting",
      "abstract": "We investigate the nonequilibrium dynamics of the nearest-neighbour Ising model subjected to stochastic resetting, where the system is intermittently returned to an initial configuration with magnetisation $m_0$, with the inter-reset times drawn from the power law distribution $ατ_0^α/ τ^{α+1}$. The heavy-tailed resets generate magnetisation distributions that differ significantly from both equilibrium dynamics and the previously studied Ising model with exponentially distributed reset times. In two dimensions, for $T > T_C$, we find a quasi-ferro state for all $α$, marked by a double-peaked distribution that diverges at $m=0$ and $m=m_0$; no steady state exists for $α< 1$, while a stationary state emerges for $α> 1$. For $T < T_C$, power law resetting produces two distinct regimes separated by a crossover exponent $α^* = 1-c$: a single-peak ferromagnetic phase localised at $m_{eq}$ for $α< α^*$, and a dual-peak ferromagnetic phase with divergences at $m_{eq}$ and $m_0$ for $α> α^*$. Analytic results in one and two dimensions, supported by simulations, yield a rich phase diagram in the $(T,α)$ plane and reveal how heavy-tailed resetting generates nonequilibrium phases very different from those seen in the case of exponential resetting.",
      "authors": [
        "Anagha V K",
        "Apoorva Nagar"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-17 11:04:31+00:00",
      "link": "https://arxiv.org/pdf/2602.15495v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15494v1",
      "title": "Generalized Geometric Brownian motion and the Infinite Ergodicity concept",
      "abstract": "We investigate stochastic processes that generalize geometric Brownian motion, focusing on cases where the standard invariant measure, i.e. the solution of the stationary Fokker-Planck equation does not necessarily exist. We demonstrate that the existence of such a measure depends sensitively on the structure of the drift and diffusion terms, as well as on the chosen discretization scheme of the underlying stochastic dynamics. To ground our discussion, we draw motivation from phenomenological models in statistical theories of turbulence, where geometric Brownian motion serves as a classical example. To address situations where the standard invariant measure fails to exist, we heuristically explore the concept of infinite ergodicity, a notion recently introduced in the context of statistical physics for drift-diffusion stochastic processes.",
      "authors": [
        "S. Giordano",
        "R. Blossey"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-17 11:04:18+00:00",
      "link": "https://arxiv.org/pdf/2602.15494v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15482v1",
      "title": "Uniform Narrow Excitonic Spectrum in Large-Area Suspended WSe2 Monolayers",
      "abstract": "Uniformity in the excitonic spectrum is a key requirement for accessing intrinsic excitonic physics in two-dimensional semiconductors; however, in supported transition-metal dichalcogenide (TMD) monolayers, exciton energies and linewidths can vary spatially due to inhomogeneities created by contact with other materials or contamination left by fabrication procedures. Suspended TMD monolayers provide an effective route to minimizing substrate-induced disorder. Here we demonstrate the spatially uniform excitonic spectrum from high-quality WSe2 suspended monolayers fabricated by gold-assisted exfoliation directly onto an Au contact electrode of a gate-tunable device. The resulting membranes span narrow suspended regions up to ~80 um and show spatially uniform photoluminescence at cryogenic temperatures with neutral-exciton linewidths as low as ~4.5 meV, comparable to the narrowest values reported for high-quality monolayers. Spectral reproducibility across the suspended regions supports an intrinsic optical response, while gate-dependent measurements resolve multiple excitonic species. This approach provides a practical route to electrically tunable potential landscapes in suspended TMD monolayers with a highly uniform excitonic response.",
      "authors": [
        "Giacomo Mariani",
        "Riccardo Lodo",
        "Keigo Matsuyama",
        "Yoji Kunihashi",
        "Taro Wakamura",
        "Satoshi Sasaki",
        "Louis Smet",
        "Makoto Kohda",
        "Junsaku Nitta",
        "Haruki Sanada"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall"
      ],
      "published": "2026-02-17 10:36:52+00:00",
      "link": "https://arxiv.org/pdf/2602.15482v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15466v1",
      "title": "Electric-field-tuned consecutive topological phase transitions between distinct correlated insulators in moire MoTe2/WSe2 heterobilayer",
      "abstract": "Consecutive topological phase transitions (TPTs) between strongly correlated electronic phases that differ simultaneously in symmetry breaking and topological order are of fundamental interest in condensed matter physics, yet are rarely realized experimentally. We report two consecutive electric-field-driven TPTs at half filling (nu = 1) in angle-aligned MoTe2/WSe2 moire heterobilayers. With increasing out-of-plane displacement field, a geometrically frustrated Mott insulator evolves into a ferromagnetic quantum anomalous Hall (QAH) Mott insulator, i.e., a spin-polarized topological Mott insulator without an observable charge-gap closure, and subsequently into an antiferromagnetic, valley-coherent Mott insulator (VC-AFM) accompanied by a continuous charge-gap collapse and the emergence of a critical metallic state. Layer-resolved magnetic circular dichroism (MCD), magneto-transport, and compressibility measurements jointly determine the phase diagram. The high-field evolution of the antiferromagnetic state reveals a metamagnetic-like transition at a critical field B*, above which a Chern insulating transport response reappears. Our results establish the MoTe2/WSe2 moire platform as a tunable realization of an extended Kane-Mele-Hubbard model hosting sequential correlation-topology-intertwined transitions.",
      "authors": [
        "Xumin Chang",
        "Zui Tao",
        "Bowen Shen",
        "Wanghao Tian",
        "Jenny Hu",
        "Kateryna Pistunova",
        "Kenji Watanabe",
        "Takashi Taniguchi",
        "Tony F. Heinz",
        "Tingxin Li",
        "Kin Fai Mak",
        "Jie Shan",
        "Shengwei Jiang"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-17 10:13:42+00:00",
      "link": "https://arxiv.org/pdf/2602.15466v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15369v1",
      "title": "Entropy Has No Direction: A Mirror-State Paradox Against Universal Monotonic Entropy Increase and a First-Principles Proof that Constraints Reshape the Entropy Distribution",
      "abstract": "We present a purely theoretical, self-contained argument that the Second Law of Thermodynamics cannot be a universal fundamental law in the form ``entropy does not decrease'' (whether asserted trajectory-wise or as a universal statistical principle) when the underlying microscopic dynamics are time-reversal invariant. The core is a mirror-state construction: for any microstate $A$ one constructs its time-reversed partner $B$ (momenta inverted). If a universal monotonicity statement is applied to both $A$ and $B$, it implies that $A$ is a local minimum of entropy at every moment, which forces entropy to be constant and destroys any entropic arrow of time. The consistent replacement is that entropy is a stochastic variable described by a probability distribution $P(S)$, whose shape depends on constraints and boundary conditions. We then prove from first principles that constraints necessarily reshape the long-time entropy distribution $P_{\\infty}(S;λ)$ by altering the invariant measure through changes in the Hamiltonian and/or the accessible phase space. A sharp criterion is given: in the microcanonical setting, the \\emph{only} way $P_{\\infty}^{(E)}(S;λ)$ can remain the same up to translation is when all accessible macrostate volumes are scaled by a common factor; otherwise the distribution changes structurally.",
      "authors": [
        "Ting Peng"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-17 05:41:09+00:00",
      "link": "https://arxiv.org/pdf/2602.15369v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15224v1",
      "title": "Phase Transitions in Neural Networks Pruning",
      "abstract": "Deep neural networks are strongly over-parameterized, often containing far more weights than required for their task. Although such redundancy can aid optimization, it leads to inefficient deployment and high computational cost, motivating model compression techniques. Among these, network pruning provides a clear and effective route to sparsity. We study pruning from a statistical-physics perspective, interpreting performance degradation under weight removal as a phase transition. Focusing on magnitude-based pruning with fine-tuning, we show that deep networks undergo a sharp transition from a cooperative, functional phase to a disordered phase with collapsed performance. This transition is characterized by scaling laws consistent with second-order critical behavior, with connectivity as the control parameter. Our findings suggest universal pruning-induced criticality across architectures and datasets. Finally, we show that there exists a large class of subnetworks sharing the same nodes' degrees with similar learning ability, thus linking model performance to its topological properties.",
      "authors": [
        "Diego Pesce",
        "Yang-Hui He",
        "Guido Caldarelli"
      ],
      "primary_category": "cond-mat.dis-nn",
      "categories": [
        "cond-mat.dis-nn",
        "nlin.AO"
      ],
      "published": "2026-02-16 22:07:50+00:00",
      "link": "https://arxiv.org/pdf/2602.15224v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.14359v1",
      "title": "Effects of the symmetry energy slope on magnetized neutron stars",
      "abstract": "In this work, we study the effect of the symmetry slope on the observables of weakly and strongly magnetized neutron stars within the chaotic magnetic field approximation. We investigate the impact of the symmetry energy slope in the equation of state, as well as on the observables of neutron stars, by calculating their masses, radii, redshifts, tidal deformabilities, and fundamental-mode gravitational-wave frequencies.",
      "authors": [
        "Luiz L. Lopes",
        "Cesar V. Flores",
        "Débora P. Menezes"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "gr-qc",
        "nucl-th"
      ],
      "published": "2026-02-16 00:24:32+00:00",
      "link": "https://arxiv.org/pdf/2602.14359v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14324v1",
      "title": "Gravitational waves from supercooled phase transitions and pulsar timing array signals",
      "abstract": "The recent detection of a gravitational wave background in the nano-Hertz frequency range by Pulsar Timing Array (PTA) collaborations, including NANOGrav, EPTA, and PPTA, has opened a new avenue for exploring fundamental physics in the early universe. In this work, we analyze a supercooled first-order phase transition in a hidden sector with a spontaneously broken $U(1)_X$ gauge symmetry as a source for this signal. We demonstrate that the thermal history of the hidden and visible sectors plays a crucial role in the gravitational wave power spectrum analysis. Our analysis shows that supercooled phase transitions can generate gravitational waves strong enough to explain the PTA observations while satisfying cosmological constraints from Big Bang Nucleosynthesis.",
      "authors": [
        "Jinzheng Li",
        "Pran Nath"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "hep-ph"
      ],
      "published": "2026-02-15 22:25:17+00:00",
      "link": "https://arxiv.org/pdf/2602.14324v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14088v1",
      "title": "Current status and prospects of light bino-higgsino dark matter in natural SUSY",
      "abstract": "Given recent advancements in dark matter (DM) search experiments, particularly the latest LUX-ZEPLIN (LZ) direct detection (DD) results, we systematically investigate the light bino-higgsino DM scenario within the natural supersymmetric framework. Requiring the electroweak fine-tuning parameter $Δ_{\\text{EW}} < 30$ fixes the higgsino mass parameter in the range $|μ| \\in [100, 350]$ GeV, while we extend the bino mass to $M_1 \\in [10, 350]$ GeV. Incorporating constraints from Higgs physics, rare $B$ decays, LEP limits, and DD experiments, we find that part of the parameter space remains viable. However, the relic density of neutralino DM necessarily lies below the observed Planck value, contributing at most $\\sim 2\\%$ of the total DM abundance. Some of the surviving parameter space is already excluded by current 13 TeV LHC searches, while the future 14 TeV HL-LHC with 3000 fb$^{-1}$ luminosity will probe the remaining region.",
      "authors": [
        "XinTian Wang",
        "Murat Abdughani"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-02-15 10:35:07+00:00",
      "link": "https://arxiv.org/pdf/2602.14088v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13142v1",
      "title": "Constraining ALP-Meson overlaps from $Kπ$ form factors",
      "abstract": "We present the first constraints on the overlaps between an Axion-like particle (ALP) and the $π^0$ and $η$ mesons from the analysis of the distortions to the $\\langle K|\\overline{s}γ^μu | π\\rangle$ form factors. We demonstrate that these distortions can be tightly constrained by combining data from $τ^-\\to π^0 K^-ν$ and $K^+\\to π^0\\ell^+ν$ decays, and go on to map the constraints to the ALP-meson overlaps. We establish that, in general, the ALP-meson and meson-ALP overlaps are different due to the presence of ALP-quark derivative couplings in the UV Lagrangian, and need to be treated separately. Using lattice results and BaBar, Belle, and NA48/2 data, we obtain exclusion limits on the overlaps and give projections for Belle II. Our techniques are independent of the branching ratios of the ALP, hence, robust against ALP decay channel assumptions. For masses of the ALP below 1 GeV, the bounds on the effective scale of the ALP physics extend to $\\mathcal{O}$(TeV) for restricted regions of the parameter space for the ALP-$π$ and $π$-ALP overlaps. On the other hand, these bounds persist for extended regions of the parameter space for ALP-$η$ and $η$-ALP overlaps.",
      "authors": [
        "Triparno Bandyopadhyay",
        "Subhajit Ghosh"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-ex"
      ],
      "published": "2026-02-13 17:51:21+00:00",
      "link": "https://arxiv.org/pdf/2602.13142v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12454v1",
      "title": "Probing the Scalar Sector: Discovery Reach for Heavy Higgs Pairs at a $\\sqrt{s} = 6$ TeV Muon Collider in the 2HDM Alignment Limit",
      "abstract": "This study provides a comprehensive phenomenological investigation into the discovery potential of heavy Higgs boson pairs ($HH, HA, AA, H^+H^-$) at a $\\sqrt{s}=6$~TeV Muon Collider. Utilizing the Two-Higgs-Doublet Model (2HDM) Type-I within the alignment limit ($\\sin(β-α) \\approx 1$), we evaluate two primary benchmarks with degenerate scalar masses of 1000~GeV (BP1) and 2000~GeV (BP2). Theoretical calculations performed reveal that Type-I branching fractions to third-generation fermions remain uniquely independent of $\\tanβ$, providing a stable signal across the investigated parameter space. We demonstrate that the Muon Collider environment allows for the precise identification of high-multiplicity hadronic final states. A key finding of this research is that the signal processes yield distinctive topological signatures: an 8-jet state ($4j+4b$) for charged pairs and a highly complex 12-jet state ($8j+4b$) for neutral pairs ($HA/AA$). These signatures, combined with hard transverse momentum distributions and central pseudorapidity ($|η| \\le 3$), allow for nearly absolute suppression of Standard Model backgrounds like $t\\bar{t}$, $W^+W^-Z$, and $ZZZ$. At an integrated luminosity of 10~ab$^{-1}$, we report a staggering statistical significance of 104,000 for the $H^+H^-$ channel and 3343 for the $HA$ channel in the BP1 scenario. Furthermore, total selection efficiencies were found to increase from approximately 20\\% at BP1 to 47\\% at BP2, suggesting that the decay products of heavier scalars are kinematically easier to resolve. We conclude that a 6~TeV Muon Collider offers an unparalleled discovery reach for the extended scalar sector, providing a definitive facility for probing physics beyond the Standard Model.",
      "authors": [
        "Ijaz Ahmed",
        "M. Umar Farooq",
        "Farzana Ahmad",
        "Jamil Muhammad"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-02-12 22:19:08+00:00",
      "link": "https://arxiv.org/pdf/2602.12454v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12442v1",
      "title": "Precision Physics with Muons : A Decade of Theoretical and Experimental Advances",
      "abstract": "The muon has been instrumental in establishing the Standard Model of particle physics and continues to play a key role in exploring the nature of New Physics. A global program is underway to enhance the discovery potential of a wide range of muon probes, with significant increases in sensitivity anticipated over the next decade. In this review, we examine recent experimental advancements in the study of muon decays, the determination of the muon magnetic and electric dipole moments, and the search for charged lepton flavor violating transitions. We explore the implications for scenarios of physics beyond the Standard Model, focusing on models involving light new particles, such as axions or hidden sectors. Opportunities from novel experimental concepts and proposal for new muon facilities are also discussed.",
      "authors": [
        "Bertrand Echenard",
        "Alexey A. Petrov"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-ex",
        "nucl-ex"
      ],
      "published": "2026-02-12 21:59:50+00:00",
      "link": "https://arxiv.org/pdf/2602.12442v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12326v1",
      "title": "Higgs decays to four leptons to $\\mathcal{O}(1/Λ^4)$ in SMEFT",
      "abstract": "We study the decays $h \\to \\ell \\bar{\\ell} \\left(Z \\to \\ell' \\bar{\\ell'}\\right)$ and $h\\to\\ell\\barν_\\ellν_{\\ell'}\\bar{\\ell'}$ within the SMEFT framework and including effects up to $\\mathcal O(1/Λ^4)$, where $Λ$ is the new physics scale suppressing higher dimensional operators. To work to this order, we must include the square of dimension-six operators and the interference of dimension-eight operators with the Standard Model. We study angular asymmetries and other differential decay observables and determine which are most sensitive to $\\mathcal O(1/Λ^4)$ effects. While new kinematic structures arising in higher dimensional operators have the potential to induce novel angular dependency, we find this does not occur for $h\\to\\ell\\bar{\\ell}\\left(Z\\xrightarrow{}\\ell'\\bar{\\ell'}\\right)$. For $h \\to \\ell \\barν_\\ell ν_{\\ell'} \\bar{\\ell'}$, new angular dependencies do arise at $\\mathcal O(1/Λ^4)$, though they require a fully reconstructible (meaning we can go to the Higgs rest frame) final state. For non-reconstructible final states such as $\\ell \\barν_\\ell ν_{\\ell'} \\bar{\\ell'}$, we must study Higgs production and decay together with the appropriate observables, which we find obscures the new angular effects.",
      "authors": [
        "Mario Flores-Hernandez",
        "Adam Martin"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-02-12 19:00:02+00:00",
      "link": "https://arxiv.org/pdf/2602.12326v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12232v1",
      "title": "Extending the Cosmological Collider: New Scaling Regimes and Constraints from BOSS",
      "abstract": "Primordial non-Gaussianity generated by additional fields during inflation offers a compelling observational target. Heavy fields imprint characteristic oscillatory signals in non-Gaussian correlation functions of the inflaton, a process sometimes referred to as cosmological-collider physics. These distinct signatures are compelling windows into ultra-high-energy physics, but are often suppressed, making standard equilateral non-Gaussianity the most promising discovery channel in many scenarios. In this paper, we show that direct couplings between the inflaton and additional fields can lead to a wide variety of novel, observationally relevant signals which open new parameter regimes that simultaneously exhibit the characteristics of light and heavy fields. We identify these primordial signatures in the late-time observables of the large-scale structure of the Universe, where they most significantly modify the scale-dependent bias of the galaxy power spectrum to include an oscillatory modulation around a non-trivial power law. We explore the full range of parameters that phenomenologically arise in these models and study the sensitivity of current and future galaxy surveys, finding that this new class of primordial non-Gaussianity is particularly accessible in near-term surveys due to its oscillatory feature. Finally, we perform an analysis of existing data from the final release of the Baryon Oscillation Spectroscopic Survey (BOSS DR12). While we find no evidence for a signal, we demonstrate significant improvements in sensitivity over respective non-oscillatory scenarios and place the first constraints on this extended parameter space of oscillatory non-Gaussianity.",
      "authors": [
        "Daniel Green",
        "Jiashu Han",
        "Benjamin Wallisch"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "hep-ph",
        "hep-th"
      ],
      "published": "2026-02-12 18:10:34+00:00",
      "link": "https://arxiv.org/pdf/2602.12232v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12101v1",
      "title": "Black Holes Trapped by Ghosts",
      "abstract": "Violent cosmic events, from black hole mergers to stellar collapses, often leave behind highly excited black hole remnants that inevitably relax to equilibrium. The prevailing view, developed over decades, holds that this relaxation is rapidly filtered into a linear regime, establishing linear perturbation theory as the bedrock of black hole spectroscopy and a key pillar of gravitational-wave physics. Here we unveil a distinct nonlinear regime that transcends the traditional paradigm: before the familiar linear ringdown, an intrinsically nonlinear, long-lived bottleneck can dominate the evolution. This stage is controlled by a saddle-node ghost in phase space, which traps the remnant and delays the onset of linearity by a timescale obeying a universal power-law. The ghost imprints a distinctive quiescence-burst signature on the emitted radiation: a prolonged silence followed by a violent burst and a delayed ringdown. Rooted in the bifurcation topology, it extends naturally to neutron and boson stars, echoing a topological universality shared with diverse nonlinear systems in nature. Our results expose a missing nonlinear chapter in gravitational dynamics and identify ghost-induced quiescence-burst patterns as clear targets for future observations.",
      "authors": [
        "Cheng-Yong Zhang",
        "Yunqi Liu",
        "Bin Wang"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "hep-ph"
      ],
      "published": "2026-02-12 15:55:39+00:00",
      "link": "https://arxiv.org/pdf/2602.12101v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11997v1",
      "title": "Recent progress in decays of $b$ and $c$ hadrons",
      "abstract": "In the last ten years there has been great progress in calculations of decays of $B$ and $D$ mesons, and baryons containing a heavy $b$ or $c$ quark. One propelling factor has been the measurement of several anomalies in $b\\to s$ and $b\\to c$ transitions, these are one of the only signs of physics beyond the Standard Model. The deviations included measurements of branching ratios, angular observables and lepton universality ratios. Another factor is the exclusive-inclusive discrepancy in the determination of the CKM elements $V_{ub}$ and $V_{cb}$. We will first review recent calculations involving $b\\to s$ and $c\\to u$ transitions that could shed light on the neutral current anomalies. We will then summarise the progress the determination of the CKM elements, $V_{ub}$ and $V_{cb}$. Finally we will discuss the current theoretical status and experimental prospects for the lepton universality ratios in $b\\to s$ and $b\\to c$ semileptonic decays.",
      "authors": [
        "Aoife Bharucha"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-02-12 14:26:48+00:00",
      "link": "https://arxiv.org/pdf/2602.11997v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11888v1",
      "title": "Full Three-Loop Electroweak Multiplet Contributions to the Electron Electric Dipole Moment",
      "abstract": "Experimental sensitivity to the electric dipole moment (EDM) of the electron has improved remarkably in recent years. Consequently, future prospects could probe new physics whose contribution to the electron EDM first arises at three-loop order. Additional SU(2)$_L$ multiplets with CP-violating Yukawa interactions, which contribute to the electron EDM at three-loop level, is one such testable new physics scenario. In this scenario, the electron EDM is radiatively induced from two contributions: the CP-odd trilinear $W$-boson coupling, called the electroweak-Weinberg operator, and the CP-odd dipole operator of electron. The former and the latter operators are generated at two-loop and three-loop levels, respectively, after integrating out the SU(2)$_L$ multiplets. Within the same models, according to an analysis based on the Standard Model Effective Field Theory (SMEFT), we previously found that the contribution to the electron EDM from the electroweak-Weinberg operator can be probed in future experiments. However, the one-loop matching condition between the electron EDM and the electroweak-Weinberg operator does not receive a large logarithmic enhancement because the associated anomalous dimension is zero. The CP-odd dipole operator of the electron would contribute to the electron EDM at the same three-loop order as the contribution through the electroweak-Weinberg operator. In this paper, we directly calculate the electron EDM induced by the CP-violating Yukawa interactions of the SU(2)$_L$ multiplets at full three-loop level. A central result is that the full three-loop calculation is a factor of three larger than that of the electroweak-Weinberg operator alone.",
      "authors": [
        "Tatsuya Banno",
        "Junji Hisano",
        "Teppei Kitahara",
        "Kiyoto Ogawa",
        "Naohiro Osamura"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-02-12 12:37:26+00:00",
      "link": "https://arxiv.org/pdf/2602.11888v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11556v1",
      "title": "Multi-Particle Invariant Mass -- Standard Expressions and Corrections to Order $(m/E)^4$",
      "abstract": "In collider-based particle physics, $invariant\\ mass$ refers to the magnitude of the total-momentum 4-vector of a system of particles. An expression for the invariant mass of a 2-particle system is well known; it assumes that both the total energy $E$ and the transverse momentum $p_\\mathrm{T}$ of each particle in the system greatly exceed its mass $m$. This note explores these assumptions by computing correction terms in powers of $m/E$ up to order $(m/E)^4$. The assumptions are found to be robust: not only is the leading correction quadratic in $m/E$, but also cancellations reduce its coefficient and that of the next-to-leading correction, which is of order $(m/E)^4$. Three- and four-particle systems are also treated and the generalisation to larger numbers of particles indicated. The zeroth-order expressions for these multi-particle systems are remarkably simple; they deserve to be better known.",
      "authors": [
        "M. P. Fewell"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-02-12 04:24:21+00:00",
      "link": "https://arxiv.org/pdf/2602.11556v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10903v1",
      "title": "Weak Annihilation Contribution to Angular Observables in $B_{c}^+\\to D^{\\ast+}\\ell^{+}\\ell^{-}$ Decays",
      "abstract": "We analyze the rare semileptonic decays $B_{c}^+ \\to D^{\\ast+}(\\to P_1 P_2)\\ell^{+}\\ell^{-}$, with $P_1 P_2 = D^+ π^0$ or $D^0 π^+$, and $\\ell=μ, τ$. We focus on the impact of weak annihilation contributions alongside penguin, box, and long-distance effects. Using the effective Hamiltonian for $b \\to d \\ell^+ \\ell^-$ transitions and $B_c \\to D^{*}$ form factors from covariant confined quark model inputs, we compute the differential branching ratios, forward-backward asymmetry, longitudinal helicity fraction of the $D^{\\ast}$, and various normalized angular coefficients. The results of the observables show that weak annihilation effects are sizable, particularly at low $q^2$, significantly modifying several observables and shifting zero-crossings. Resonance effects dominate at high $q^2$, restricting reliable analysis windows. We conclude that the inclusion of weak annihilation is essential for precise Standard Model predictions and for isolating possible New Physics effects in $B_c^+ \\to D^{*+} \\ell^+ \\ell^-$ decays.",
      "authors": [
        "Zohaib Aarfi",
        "Qazi Maaz Us Salam",
        "Ishtiaq Ahmed",
        "Faisal Munir Bhutta",
        "M. Ali Paracha"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-02-11 14:29:08+00:00",
      "link": "https://arxiv.org/pdf/2602.10903v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10807v1",
      "title": "Three-loop helicity amplitudes of four-lepton scattering in QED",
      "abstract": "We present the analytic expressions of the three-loop virtual corrections to the helicity amplitudes of 2 -> 2 four-fermion scattering processes in massless QED. The contributing Feynman diagrams are grouped into integrand families characterised by independent Symanzik polynomials and decomposed in terms of master integrals using an optimised integration-by-parts strategy. Upon the renormalisation of the ultraviolet divergences and the extraction of the universal infrared pole structure, the finite results are expressed in terms of generalised polylogarithms up to transcendental weight six. Amplitudes for dimuon production in electron-positron annihilations, electron-muon scattering, and Bhabha scattering are explicitly derived.",
      "authors": [
        "Giulio Crisanti",
        "Thomas Dave",
        "Pierpaolo Mastrolia",
        "Jonathan Ronca",
        "Sid Smith",
        "William J. Torres Bobadilla"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-th"
      ],
      "published": "2026-02-11 12:48:45+00:00",
      "link": "https://arxiv.org/pdf/2602.10807v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10791v1",
      "title": "A multidimensional landscape of the $η$ and $η'$ mesons",
      "abstract": "We employ a recently proposed form-invariant algebraic model for the quark propagator and the Bethe-Salpeter amplitude of pseudoscalar mesons to study the internal structure of $η$ and $η'$ mesons. This model facilitates the construction of the Bethe-Salpeter wavefunction, whose projection onto an appropriate flavor-basis leads to the light-front wavefunction for convenient linear combinations of the $s \\bar{s}$ and $l\\bar{l}\\sim(u \\bar{u} + d \\bar{d})$ states. Using an overlap representation, we compute the valence-quark generalized parton distributions (GPDs). The construction of the model ensures that this multidimensional quantity is determined entirely by the corresponding valence-quark distribution amplitudes. Once the GPDs are constructed, we carry out a straightforward derivation of other desired physical observables such as the distribution functions and the electromagnetic form factors. We also provide explicit comparisons with available results, demonstrating that the present model offers a consistent physical picture for all ground-state pseudoscalar mesons.",
      "authors": [
        "L. Albino",
        "K. Raya",
        "R. J. Hernández-Pinto",
        "B. Almeida-Zamora",
        "J. Segovia",
        "A. Huet",
        "A. Bashir"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "nucl-th"
      ],
      "published": "2026-02-11 12:32:46+00:00",
      "link": "https://arxiv.org/pdf/2602.10791v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10651v1",
      "title": "Improving integration-by-parts and differential equations",
      "abstract": "In this talk, we discuss how ideas from geometry help to improve Feynman integral reduction and the construction of $\\varepsilon$-factorised differential equations. In particular, we outline a systematic procedure to obtain an $\\varepsilon$-factorised differential equation for any Feynman integral.",
      "authors": [
        "Iris Bree",
        "Federico Gasparotto",
        "Antonela Matijašić",
        "Pouria Mazloumi",
        "Dmytro Melnichenko",
        "Sebastian Pögel",
        "Toni Teschke",
        "Xing Wang",
        "Stefan Weinzierl",
        "Konglong Wu",
        "Xiaofeng Xu"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "hep-ph"
      ],
      "published": "2026-02-11 08:58:14+00:00",
      "link": "https://arxiv.org/pdf/2602.10651v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10197v1",
      "title": "Pushing the Limits of Atomic Dark Matter: First-Principles Recombination Rates and Cosmological Constraints",
      "abstract": "Minimal atomic dark matter with its distinctive cooling mechanisms offers an instructive framework for understanding the potential impact of dark matter on small-scale structure formation and early cosmology. The model consists of two fermions with opposite charges under a hidden Abelian gauge symmetry $U(1)_{D}$ and masses $m_{p_{D}}$ and $m_{e_{D}}$, respectively. Analogous to hydrogen in the Standard Model, these fermions interact via their own electromagnetic-like force, with a dark fine structure constant denoted by $α_{D}$, and can bind into neutral atomic (and molecular) dark states. Previous work has largely focused on the benchmark scenario where the dark sector mirrors ordinary matter, with $m_{e_{D}}$ near the electron mass, $m_{p_{D}}$ near the proton mass, and $α_{D}\\sim 1/137$. We extend this analysis by investigating dark recombination and cooling physics across the full parameter space of masses and couplings. Combining Cosmic Microwave Background (CMB) measurements from Planck and ACT with BAO and Pantheon+ data, we place new constraints on the atomic dark matter parameter space, identifying regions where acoustic damping and recombination dynamics leave observable imprints on the CMB.",
      "authors": [
        "Jared Barron",
        "Rouven Essig",
        "Megan H. McDuffie",
        "Jesús Pérez-Ríos",
        "Gregory Suczewski"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "astro-ph.CO"
      ],
      "published": "2026-02-10 19:00:04+00:00",
      "link": "https://arxiv.org/pdf/2602.10197v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10112v1",
      "title": "Minimal Freeze-in Dark Matter: Reviving electroweak doublet dark matter with Boltzmann suppressed freeze-in",
      "abstract": "Dark matter communicating with the Standard Model solely via electroweak interactions provides a compelling picture. However, thermal freeze-out of electroweak doublet dark matter is generically strongly excluded by direct detection. We show that SU(2)${}_L$ doublet fermion dark matter evades direct detection if its mass exceeds $10^{10}$ GeV. If the neutral Dirac fermion is split into a pseudo-Dirac pair (via high dimension operator) this limit can be relaxed to 300 GeV. Provided the dark matter mass is above the reheat temperature of the Universe, the production rate never exceeds the Hubble rate in cases of interest, thus the dark matter never thermalizes. We apply constraints from direct detection (e.g. LZ) and consider the discovery potential of Darwin. This scenario presents the most minimal model of freeze-in dark matter, and is both elegant and highly predictive.",
      "authors": [
        "Nicolás Bernal",
        "Sagnik Mukherjee",
        "James Unwin"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "astro-ph.CO"
      ],
      "published": "2026-02-10 18:59:37+00:00",
      "link": "https://arxiv.org/pdf/2602.10112v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09705v2",
      "title": "Non-minimally Coupled Running Curvaton: A Unified Approach to Early-Universe Inflation and Phantom Dark Energy",
      "abstract": "Recent observations from the Dark Energy Spectroscopic Instrument (DESI) 2024, combined with CMB and SNIa data, indicate a preference for a dynamical dark energy equation of state that crosses the phantom divide ($w < -1$). This finding challenges the standard $Λ$CDM model and minimally coupled scalar field scenarios, including the original Running Curvaton model, which is typically constrained to the quintessence regime. In this work, we propose a unified cosmological framework by extending the Running Curvaton model via a non-minimal gravitational coupling of the form $ξχ^2 R$. We demonstrate that this geometric modification allows the effective equation of state to naturally evolve from a quintessence-like to a phantom-like regime in the Jordan frame, thereby providing a superior fit to the DESI observational contours ($w_0 > -1, w_a < 0$). Crucially, we show that the introduction of non-minimal coupling does not compromise the model's success in describing the early universe. Through a parameter re-tuning mechanism involving the coupling constant ($g_0^{obs} = g_0 + 2ξ$), the predictions for the primordial power spectrum (spectral index $n_s$) and local-type non-Gaussianity ($f_{NL}$) remain strictly preserved and consistent with Planck data. Furthermore, we perform a comprehensive stability analysis within the Horndeski framework, verifying that the model remains free from ghost and gradient instabilities ($c_s^2 = 1$). Our results suggest that the non-minimally coupled Running Curvaton offers a robust, stable, and unified description of inflation and late-time accelerated expansion compatible with the latest precision cosmology data.",
      "authors": [
        "Bichu Li",
        "Lei-Hua Liu"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "gr-qc",
        "hep-ph",
        "hep-th"
      ],
      "published": "2026-02-10 12:06:01+00:00",
      "link": "https://arxiv.org/pdf/2602.09705v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09692v1",
      "title": "$S-P-D$ Mixing in Vector Quarkonia from the Salpeter Equation with Optimized Wave Function Representations",
      "abstract": "This paper proposes a novel mechanism based on the instantaneous Bethe-Salpeter (Salpeter) equation for investigating wave function mixing in vector mesons such as $ψ(3770)$. Conventional theories typically treat $ψ(3770)$ as a $2S-1D$ mixed state; however, considering only tensor forces or relativistic corrections alone often leads to mixing angles that are too small and inconsistent with experimental data. Phenomenological $2S-1D$ mixing requires experimental data as input to determine the mixing angles, resulting in limited theoretical studies on states like $Υ(1D, 2D)$ in the absence of experimental data. To more accurately describe $S-D$ mixing and its relativistic effects, this paper systematically compares eight possible relativistic wave function representations ($\\varphi_1$ to $\\varphi_8$) by solving the Salpeter equation and calculates the mass spectra and dileptonic decay widths of charmonium and bottomonium. The study finds that the wave function representation $\\varphi_2$ can simultaneously reproduce the experimental data of both charmonium and bottomonium well. Further analysis reveals that, in addition to $S-D$ mixing, the wave functions of vector mesons contain a non-negligible $P$-wave component, meaning they are $S-P-D$ mixed states. We predict the mixing angles for bottomonium $Υ(1D)$ and $Υ(2D)$ to be $(1.78^{+0.32}_{-0.25})^\\circ$ and $(5.44^{+1.10}_{-0.76})^\\circ$, with dileptonic decay widths of $2.29^{+0.86}_{-0.69}$ eV and $10.5^{+4.2}_{-3.1}$ eV, respectively.",
      "authors": [
        "Wen-Yuan Ke",
        "Qiang Li",
        "Tianhong Wang",
        "Tai-Fu Feng",
        "Guo-Li Wang"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-ex"
      ],
      "published": "2026-02-10 11:48:10+00:00",
      "link": "https://arxiv.org/pdf/2602.09692v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09334v1",
      "title": "Constructing Dimension-8 SMEFT from Conserved Currents",
      "abstract": "Effective Field Theories (EFTs) are the primary tool for interpreting precision collider data in the absence of new resonances. However, in the dimension-8 Standard Model Effective Field Theory (SMEFT), the utility of traditional algebraically minimal bases is fundamentally limited by kinematic mixing: multiple operators contribute to a single high-energy amplitude, creating degeneracies that obscure ultraviolet interpretations and complicate the application of theoretical constraints. We introduce a generative framework that resolves this by constructing operators directly from the conserved Noether currents of the Standard Model. The resulting Kinematically Diagonalized Current Basis (KDCB) ensures that each operator maps to a unique asymptotic energy scaling ($E^4$, $E^2$, $E^0$) in scattering amplitudes. This organization makes S-matrix positivity bounds manifest, enables a stable auxiliary-field formulation for Monte Carlo simulation, and provides direct diagnostics for universal versus non-universal ultraviolet completions through current decomposition. By rotating the operator space into physically interpretable sectors, the KDCB offers a transformative framework for global fits and a clear pathway from high-energy data to the structure of new physics.",
      "authors": [
        "Leonardo P. G. De Assis"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-02-10 02:08:19+00:00",
      "link": "https://arxiv.org/pdf/2602.09334v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09187v1",
      "title": "pMSSM versus complete models and the excellent prospects for top-squark discovery at HL-LHC",
      "abstract": "LHC sparticle search limits are usually performed within the context of simplified models and subsequently interpreted within the 19 parameter phenomenological MSSM (pMSSM) as to how many models avoid search limits for a particular sparticle mass, often including WIMP dark matter constraints. We provide a critical discussion of this procedure and how it can go wrong due to the introduction of new prejudices. By ameliorating these conditions, one is pushed into the more plausible four extra parameter non-universal Higgs model (NUHM4). Implementing a decoupling/quasi-degeneracy solution to the SUSY flavor and CP problems leads to first/second generation sfermions in the tens-of-TeV range. In this case, the natural solutions typically contain top-squarks in the 1-2 TeV range which are accessible to high-lumi LHC (HL-LHC) searches. This search channel, along with higgsino and wino pair production, may allow a nearly complete scan of natural/plausible parameter space by HL-LHC.",
      "authors": [
        "Howard Baer",
        "Vernon Barger",
        "Kairui Zhang"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-02-09 20:48:51+00:00",
      "link": "https://arxiv.org/pdf/2602.09187v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09089v1",
      "title": "WISPedia -- the WISPs Encyclopedia",
      "abstract": "The Weakly-Interacting Slim Particle encyclopedia (WISPedia) is a comprehensive reference work dedicated to the systematic compilation of theoretical models, Effective Field Theories, and frameworks involving Weakly Interacting Slim Particles (WISPs): a broad class of light, feebly coupled particles proposed in extensions of the Standard Model. In current times, where the number of models largely surpasses the number of new physics signals, this encyclopedia aims to provide a concise reference of their landscape. The goal is to provide a useful tool to the community to navigate among them. It does not aim to review all the models in detail, but to define their essential characteristics, and point the reader to useful and minimal material such as the original sources, review articles, tools and general compilations of bounds. Hence, the format of this reference resembles the direct style of a model encyclopedia of WISPs.",
      "authors": [
        "Conrado Albertus",
        "Francesca Chadha-Day",
        "Arturo de Giorgi",
        "Rafid H. Dejrah",
        "Marta Fuentes Zamoro",
        "Christian Käding",
        "Luca Merlo",
        "María Ángeles Pérez-García",
        "Xavier Ponce Díaz",
        "Federico Urban",
        "Wen Yin"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-ex"
      ],
      "published": "2026-02-09 19:00:00+00:00",
      "link": "https://arxiv.org/pdf/2602.09089v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16514v1",
      "title": "Atmospheric Neutrino Charged-Current Interactions at Large Liquid-Scintillator Detectors: I. Physics of Neutrino-Antineutrino Discrimination",
      "abstract": "In this work, we present a systematic study of the event characteristics and physics of neutrino-antineutrino discrimination associated with atmospheric neutrino charged-current interactions in large liquid scintillator detectors. This study encompasses the primary neutrino interactions, the sequential second interactions of final-state particles, and the final neutron captures. We carefully investigate the properties of final-state charged leptons and hadrons, providing distinct distributions of inelasticity and captured neutron multiplicity for both neutrino and antineutrino interactions. These distributions are employed to assess the quantitative performance of neutrino-antineutrino discrimination. Our findings lay the groundwork for atmospheric neutrino oscillation studies in large liquid scintillator detectors, particularly in the determination of neutrino mass ordering.",
      "authors": [
        "Xinhai He",
        "Gao-song Li",
        "Yu-Feng Li",
        "Wuming Luo",
        "Liang-jian Wen"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-ex"
      ],
      "published": "2026-02-18 15:02:32+00:00",
      "link": "https://arxiv.org/pdf/2602.16514v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16369v1",
      "title": "Rapidity dependence of mean transverse momentum fluctuation and decorrelation in baryon-dense medium",
      "abstract": "I study the event-by-event fluctuation and rapidity decorrelation of the mean transverse momentum $\\spt$, which has recently been proposed as a sensitive probe of the equation of state at finite baryon density. The investigation reveals that, in a baryon-rich medium, the event-by-event fluctuation of the mean transverse momentum is driven by the combined effects of energy-density and net-baryon-density fluctuations. Consequently, the rapidity dependence of this observable provides a promising handle to probe the three-dimensional structure of both energy and baryon density profiles. Previous studies have shown that $\\spt$ decorrelation along rapidity is largely insensitive to shear and bulk viscosity; however, its dependence on baryon diffusion, another key transport coefficient in baryonic matter, has not been explored. I find that baryon diffusion has a negligible impact, establishing this observable as a robust probe of the equation of state. Furthermore, I present predictions for identified hadrons and observe a pronounced splitting in the rapidity decorrelation of mean transverse momentum between protons and antiprotons, indicating different transverse flow dynamics for baryons and antibaryons.",
      "authors": [
        "Tribhuban Parida"
      ],
      "primary_category": "nucl-th",
      "categories": [
        "nucl-th",
        "hep-ph",
        "nucl-ex"
      ],
      "published": "2026-02-18 11:12:06+00:00",
      "link": "https://arxiv.org/pdf/2602.16369v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16230v1",
      "title": "Electromagnetic Production of Kaons on the Nucleon",
      "abstract": "Studies of the electromagnetic production of strange quarks began in the 1950s as something of a curiosity that puzzled experimentalists and theorists alike. As the datasets increased, concomitant advances in theoretical models were realized. A paradigm shift occurred in the 1990s with the development of second-generation facilities at ELSA, MAMI, SPring-8, and JLab, which brought nuclear physics experiments forward by orders of magnitude in counting statistics compared to the first-generation efforts. This was an utter boon to strangeness physics investigations, and to date, more than 50 dedicated experiments in kaon photo- and electroproduction have been completed at facilities around the world, leading to a host of experimental observables that have enabled significant advances in the exploration of strongly interacting systems that decay via $s\\bar{s}$ quark pair creation. This review was designed to provide the first-ever in-depth overview of both the experimental and theoretical progress in the field of the electromagnetic production of strangeness. This work looks back over 70 years of past developments, discusses ongoing work and near-term plans, and details future possibilities being considered for third-generation facilities. Throughout this work, the primary impacts of these explorations are highlighted, along with connections to a wide range of related phenomenological applications. An important goal of this review is to provide a complete, self-contained guide into this field prepared at a level that is relevant for both new and seasoned scientists, whether experimentalists, phenomenologists, or theorists, to better understand what has been accomplished by so many dedicated folks-each building on what has come before-and to appreciate the exciting future potential for continued studies in this area. A more complete abstract is provided in the paper.",
      "authors": [
        "Terry Mart",
        "Jovan Alfian Djaja",
        "Daniel S. Carman"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-ex",
        "nucl-ex",
        "nucl-th"
      ],
      "published": "2026-02-18 07:10:24+00:00",
      "link": "https://arxiv.org/pdf/2602.16230v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15947v1",
      "title": "Statistics of Daily Modulation in Dark Matter Direct Detection Experiments",
      "abstract": "The time-dependent modulation of the event rate in dark matter direct detection experiments, arising from the motion of the Earth with respect to the Galactic rest frame, is a distinctive signature whose observation is crucial for claiming a discovery of dark matter. While annual modulation has been well studied for decades, daily modulation due to the Earth's rotation has attracted increased attention recently due to the identification of anisotropic solid-state detector materials that yield a direction-dependent scattering rate without sacrificing the overall rate. We perform a statistical analysis of daily modulation in dark matter scattering experiments, with the goal of maximizing the statistical significance of a modulating signal in the presence of an unknown background rate, which may be either flat (non-modulating), or modulating over a 24-hour period with a known or unknown phase. In the background-dominated regime, we find that the discovery significance scales as $f_\\text{RMS} \\sqrt{T}$, where $T$ is the total exposure time and $f_\\text{RMS}$ is the root-mean-square modulation amplitude; in particular, the significance continues to improve with exposure rather than saturating due to systematic uncertainties in the background rate. Using anisotropic trans-stilbene detectors for sub-GeV dark matter as a benchmark example, we provide prescriptions for optimizing the significance for a given total detector mass and location. In an example analysis using three detectors, optimizing the detector orientations can reduce the required exposure by a factor of $\\sim 5$ for a desired discovery or exclusion significance, even after profiling over an unknown modulating background phase.",
      "authors": [
        "Carlos Blanco",
        "Joshua W. Foster",
        "Yonatan Kahn",
        "Benjamin Lillard"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "astro-ph.IM",
        "hep-ex"
      ],
      "published": "2026-02-17 19:04:34+00:00",
      "link": "https://arxiv.org/pdf/2602.15947v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15295v1",
      "title": "Update to the U.S. National Input to the European Strategy Update for Particle Physics",
      "abstract": "In this document we update the status of U.S. community inputs for the European Strategy for Particle Physics Update (ESPPU) since April 1, 2025, and offer responses to the revised questions. Major new inputs include a long-term strategy report from the National Academies of Sciences, Engineering, and Medicine and the formal formation of a U.S. Muon Collider Collaboration.",
      "authors": [
        "André de Gouvêa",
        "Hitoshi Murayama",
        "Mark Palmer",
        "Heidi Schellman"
      ],
      "primary_category": "hep-ex",
      "categories": [
        "hep-ex",
        "hep-ph"
      ],
      "published": "2026-02-17 01:36:58+00:00",
      "link": "https://arxiv.org/pdf/2602.15295v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15104v1",
      "title": "ABCMB: A Python+JAX Package for the Cosmic Microwave Background Power Spectrum",
      "abstract": "We present ABCMB, a differentiable Einstein-Boltzmann solver for the cosmic microwave background (CMB). ABCMB is a complete code capturing important effects to linear order in $Λ{\\rm CDM}$ cosmology. It computes the CMB power spectrum and includes effects like lensing, polarization, massive neutrinos, and a state-of-the-art treatment of BBN and recombination. ABCMB has sub-percent-level agreement with CLASS and can be run on a GPU with competitive, and sometimes even faster, run times. It is refactored compared to previous codes and takes advantage of object-oriented programming to improve extensibility, meaning new physics can be added to it without the need for modifying source files. ABCMB provides accurate and stable gradients to the user, making Fisher analyses straightforward, and enabling the use of efficient gradient-based sampling methods.",
      "authors": [
        "Zilu Zhou",
        "Cara Giovanetti",
        "Hongwan Liu"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "hep-ph"
      ],
      "published": "2026-02-16 19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2602.15104v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15027v1",
      "title": "Complementarity of di-top and four-top searches in interpreting possible signals of new physics",
      "abstract": "Final states comprising two or more top quarks are important search channels at the Large Hadron Collider for scalar particles predicted in models of physics beyond the Standard Model. While the di-top final state profits from a higher signal cross section, it can be subject to intricate interference patterns. Besides the interference with the large QCD background, in case of the presence of more than one high-mass scalar also large signal--signal interference contributions can occur. We show that in such scenarios it is crucial to account for loop-level mixing for obtaining accurate exclusion bounds. We demonstrate how the interference patterns can obscure the interpretation of possible deviations from the Standard Model expectations. We show that the four-top final state, while giving rise to a smaller signal cross section, provides important complementary information due to its much smaller signal--background interference contributions. Thus, the results obtained from the four-top final state can be instrumental for pinpointing the underlying new physics scenario.",
      "authors": [
        "Henning Bahl",
        "Philipp Gadow",
        "Romal Kumar",
        "Krisztian Peters",
        "Panagiotis Stylianou",
        "Georg Weiglein"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-02-16 18:59:33+00:00",
      "link": "https://arxiv.org/pdf/2602.15027v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14665v1",
      "title": "S-matrices in the holomorphic modular bootstrap approach",
      "abstract": "We numerically determine the S-matrix by using connection formulae in the modular linear differential equation (MLDE) approach to the holomorphic modular bootstrap. We then determine exact formulae using the fact that entries in the $S$-matrix are integer entries in a cyclotomic extension of the field of rational numbers. This provides a method that is intrinsic to the MLDE setup and does not require inputs outside this framework. The method is illustrated with a selection of examples.",
      "authors": [
        "Suresh Govindarajan",
        "Aditya Jain",
        "Akhila Sadanandan",
        "Abhiram Kidambi"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th"
      ],
      "published": "2026-02-16 11:43:37+00:00",
      "link": "https://arxiv.org/pdf/2602.14665v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15077v1",
      "title": "Horizon-Brightened Acceleration Radiation and Optical Signatures of Generic Regular Black Holes from Nonlinear Electrodynamics",
      "abstract": "We investigate horizon-brightened acceleration radiation (HBAR) and optical signatures for a broad class of regular black holes sourced by nonlinear electrodynamics. The spacetimes considered are static, spherically symmetric, and nonsingular, and they include Bardeen-like, and Hayward-like regular black-hole limits as spacial cases. We characterize the horizon structure and thermodynamics properties, and we compute key optical observables by determining the photon-sphere location and the corresponding shadow size as seen by distant observers, including controlled perturbative limits and full numerical solutions. Using angular-size constraints for SgrA* and M87* from the Event Horizon Telescope and the GRAVITY collaboration, we perform a Markov Chain Monte Carlo analysis to infer the admissible parameter ranges of the model and to quantify degeneracies among the black-hole mass and nonlinear-electrodynimcs parameters. On the quantum side, we develop the near-horizon reduction relevant for HBAR, showing that the dominant sector governing the detector response exhibits conformal behavior and leads to a thermal excitation spectrum governed by the horizon temperature. We formulate a Lindblad master-equation description of the radiation field, identify the thermal steady state, and derive an HBAR entropy-energy relation consistent with a Clausius-type first law. Finally, we establish a Wien-type displacement law for the HBAR spectrum, expressing the peak wavelength in terms of the horizon thermodynamics, thereby providing an additional observable link between nonlinear electrodynamics, regularity, and near-horizon quantum radiation.",
      "authors": [
        "Uktamjon Uktamov",
        "Ali Övgün",
        "Reggie C. Pantig",
        "Bobomurat Ahmedov"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "hep-th"
      ],
      "published": "2026-02-16 07:10:37+00:00",
      "link": "https://arxiv.org/pdf/2602.15077v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13694v1",
      "title": "Spherically symmetric black holes in Gravity from Entropy and spontaneous emission",
      "abstract": "We investigate static and dynamical spherically symmetric black hole solutions within the Gravity from Entropy (GfE) framework. We derive and solve the modified vacuum field equations for a static, spherically symmetric spacetime, revealing that the classical Schwarzschild geometry receives perturbative corrections scaling as $r^{-4}$. We establish that the GfE framework is consistent with current strong-field astrophysical observations. Higher-order geometric stresses inherent to the GfE vacuum drive a consistent mass-evolution profile. In the limit of large black hole mass, the theory predicts a constant background evaporation rate $ -β/24$, suggesting an inherent \"entropic leakage\" of the vacuum. At intermediate scales, the framework replicates the standard Hawking radiation mass-loss law as $\\dot{M} \\propto M^{-2}$ through a purely classical response of the modified background.",
      "authors": [
        "Udaykrishna Thattarampilly",
        "Yunlong Zheng",
        "Vishnu Kakkat"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "hep-th"
      ],
      "published": "2026-02-14 09:33:48+00:00",
      "link": "https://arxiv.org/pdf/2602.13694v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.13627v1",
      "title": "Higher Connection in Open String Field Theory",
      "abstract": "We define a 2-form connection in the space of classical solutions of the bosonic open string field theory, using the open string star product and integration. The corresponding higher holonomies and the 3-form curvature are new observables invariant under the infinite-dimensional gauge algebra of open string field theory. The definition is analogous to that of Berry phase in quantum mechanics and is motivated by recent studies on higher Berry phase in condensed matter physics and quantum field theory. We suggest identifying this 2-form connection with the Kalb-Ramond $B$-field of the closed string background at least in favorable situations. Also discussed are sigma models whose target space is the moduli space of conformal boundary conditions of a two-dimensional CFT with the $B$-field given by a cousin of this 2-form connection.",
      "authors": [
        "Yichul Choi"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th"
      ],
      "published": "2026-02-14 06:35:33+00:00",
      "link": "https://arxiv.org/pdf/2602.13627v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13570v1",
      "title": "Defect Approach to Giant Graviton Dynamics",
      "abstract": "We develop a framework of zero dimensional defects for analyzing light-light-heavy-heavy (LLHH) correlators in conformal field theories. We specifically apply this formalism to correlators of giant gravitons in $\\mathcal{N}=4$ super Yang-Mills to probe the nontrivial physics beyond planarity. By combining this framework with bootstrap techniques, we compute all four-point functions at strong coupling involving two maximal giant gravitons and two supergravitons of arbitrary dimensions. We identify a partially broken, higher-dimensional hidden symmetry -- a defect extension of 10d hidden conformal symmetry -- present at both strong and weak coupling, which allows these correlators to be packaged into a single generating function. Furthermore, we perform a systematic OPE analysis of the strong-coupling correlators, extracting the complete spectrum of anomalous dimensions for the defect-channel double-particle operators. Finally, we argue that the defect perspective provides the natural nonperturbative description for any LLHH correlator by showing that four-point conformal blocks reduce to defect two-point blocks in the heavy limit.",
      "authors": [
        "Junding Chen",
        "Yunfeng Jiang",
        "Xinan Zhou"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th"
      ],
      "published": "2026-02-14 03:10:41+00:00",
      "link": "https://arxiv.org/pdf/2602.13570v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13387v1",
      "title": "Physical Predictions in Closed Quantum Gravity",
      "abstract": "Recent developments in gravitational path integrals indicate that the nonperturbative physical Hilbert space of a closed universe is one-dimensional within each superselection sector. This raises a basic puzzle: how can a unique quantum-gravity state give rise to semiclassical physics, measurement outcomes, and classical probabilities? In this paper, we develop a framework in which nontrivial and statistically stable predictions emerge despite the one-dimensionality of the fully constrained Hilbert space. The key idea is to extract physical predictions in an enlarged, unconstrained Hilbert space by conditioning on observational data. We show that partial observability -- reflecting the limited access of observers to the degrees of freedom of the universe -- suppresses ensemble fluctuations associated with microscopic structure in the gravitational path integral, thereby restoring semiclassical predictability with exponential accuracy. We formulate the construction explicitly including contributions from the Hartle--Hawking no-boundary state, define a gauge-invariant Hilbert space for observations via a density operator, and generalize the formalism to conditioning on histories, clarifying the emergence of classical probabilities and an effective arrow of time. Finally, we explore whether this framework can support a realistic cosmology and identify assumptions that the underlying theory of quantum gravity must satisfy.",
      "authors": [
        "Yasunori Nomura",
        "Tomonori Ugajin"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "gr-qc"
      ],
      "published": "2026-02-13 19:00:00+00:00",
      "link": "https://arxiv.org/pdf/2602.13387v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11503v1",
      "title": "Generalized entropic uncertainty relation and non-classicality in Schwarzschild black hole",
      "abstract": "The uncertainty principle constitutes a fundamental pillar of quantum theory, representing one of the most distinctive features that differentiates quantum mechanics from classical physics. In this study, we firstly propose a novel generalized entropic uncertainty relation (EUR) for arbitrary multi-measurement in the many-body systems, and rigorously derive a significantly tighter bound compared to existing formulations. Specifically, we discuss the proposed EUR in the context of Schwarzschild black hole, where we demonstrate the superior tightness of our derived bound. The study further elucidates the dynamical evolution of multipartite quantum coherence and entanglement in the curved spacetime. A particularly noteworthy finding reveals the exact equivalence between entanglement and $l_1$-norm coherence for arbitrary $N$-partite Greenberger-Horne-Zeilinger-type (GHZ-type) states. Moreover, we find that quantum coherence is significantly diminished and the measurement uncertainty increases to a stable maximum with increasing Hawking temperature. Thus, the findings of this study contribute to a deeper understanding of non-classicality and quantum resources in black holes.",
      "authors": [
        "Rui-Jie Yao",
        "Dong Wang"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "hep-th",
        "quant-ph"
      ],
      "published": "2026-02-12 02:57:25+00:00",
      "link": "https://arxiv.org/pdf/2602.11503v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09599v1",
      "title": "Highly suppressed tensor-to-scalar ratio from a modified Lennard-Jones inflationary potential",
      "abstract": "The increasingly stringent observational bounds on primordial gravitational waves strongly constrain inflationary model building, favoring scenarios that predict highly suppressed tensor perturbations. While many viable constructions rely on non-canonical kinetic terms, non-minimal couplings, or modifications of gravity, it remains an open question whether comparably small tensor amplitudes can emerge within a minimal, single-field framework driven solely by potential dynamics. In this work we propose a novel inflationary scenario based on a modified Lennard-Jones potential. Inspired by a well-known interaction potential in molecular physics, the proposed form naturally combines a smooth minimum with an extended flat plateau at large field values. This intrinsic structure supports slow-roll inflation and ensures a graceful exit without introducing additional degrees of freedom. We perform a detailed analysis of the inflationary dynamics and confront the model with current observational constraints. We find that the scalar spectral index is fully consistent with CMB data, while the tensor-to-scalar ratio is predicted to be extremely small, reaching values as low as $r\\sim10^{-7}$. Finally, the running of the scalar spectral index is also found to be small, well withing the 1$σ$ recent observational bounds from Atacama Cosmology Telescope.",
      "authors": [
        "Panagiotis G. Stavros",
        "Spyros Basilakos",
        "Emmanuel N. Saridakis"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "gr-qc",
        "hep-th"
      ],
      "published": "2026-02-10 09:50:27+00:00",
      "link": "https://arxiv.org/pdf/2602.09599v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16627v1",
      "title": "Dynamic effects of external axion fields in a system of many particles with spin",
      "abstract": "We develop the theoretical model that describes dynamic non-equilibrium effects of external inertial and axion fields in a system of particles with spin. The possibility of using the spin density and the current density of non-relativistic quantum particle systems for the detection of the hypothetical axion-like dark matter is discussed. The resulting closed system of dynamic equations encompasses the continuity equation, the momentum balance equation, and the spin density evolution equation, accounting for the influence of the spin-rotation coupling and the external axion fields. The new formalism opens up new perspectives for an experimental search of dark matter axions.",
      "authors": [
        "Mariya Iv. Trukhanova",
        "Yuri N. Obukhov"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th"
      ],
      "published": "2026-02-18 17:22:26+00:00",
      "link": "https://arxiv.org/pdf/2602.16627v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16380v1",
      "title": "Asymptotic Freedom of V-A Fermi Interaction",
      "abstract": "We consider the V-A Fermi interaction and apply an earlier developed method for summing up the leading asymptotics for scattering amplitudes in non-renormalizable theories. We consider the amplitude of fermion-antifermion scattering and derive the corresponding RG equation that sums the leading logarithmic contributions just like in renormalizable models. Numerical solution of this equation in the asymptotic regime $s\\sim t\\sim u \\sim E^2 \\to \\infty$ leads to amplitude logarithmically decreasing with energy, thus restoring the unitarity violated at the tree level.",
      "authors": [
        "A. T. Borlakov",
        "D. I. Kazakov"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th"
      ],
      "published": "2026-02-18 11:39:51+00:00",
      "link": "https://arxiv.org/pdf/2602.16380v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16294v1",
      "title": "Entropy Modifications from Stochastic Metric Fluctuations",
      "abstract": "Deviations from the area law of the horizon entropy, in the cosmological setup, are known to lead to modified Friedmann equations governing the evolution of the universe. In this work, we propose that such modifications need not be introduced phenomenologically but can emerge dynamically from stochastic fluctuations of the spacetime metric. We consider a Friedmann-Robertson-Walker (FRW) universe perturbed by a conformal, time-dependent noise factor, whose ensemble average vanishes, leaving the mean background geometry unchanged. By averaging the Einstein equations to second order in the fluctuation amplitude, we derive a modified Friedmann equation that includes an effective correction term. This correction is shown to be equivalent to the general expression obtained from an arbitrary deformation of the entropy-area relation. By specifying the statistical properties, particularly the variance of the conformal noise, we successfully reproduce the Friedmann equation corrections associated with several well-known generalized entropy frameworks, including Rényi, (dual) Kaniadakis, Barrow, logarithmic, and MOND inspired hypergeometric entropies. Our results suggest that deviations from the area law can be interpreted as the macroscopic, coarse-grained imprint of unresolved, microscopic stochastic degrees of freedom in spacetime.",
      "authors": [
        "Amir A. Khodahami",
        "Ahmad Sheykhi"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "hep-th"
      ],
      "published": "2026-02-18 09:22:27+00:00",
      "link": "https://arxiv.org/pdf/2602.16294v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16190v1",
      "title": "Comments on Entire Functions of the Derivative Operator",
      "abstract": "Many attempts to introduce fundamental nonlocality into quantum (or classical) field theory are based on the assumption that exponentials of the d'Alembertian are positive-definite, so that these operators can be employed without engendering the Ostrogradskian instability associated with higher derivative Lagrangians. {\\bf This assumption is false.} Working in the simple context of a 1-dimensional, point particle $q(t)$, I demonstrate that the equation $\\exp[T^2 \\tfrac{d^2}{dt^2}] q(t) = 0$ has an infinite number of rapidly oscillating, exponentially rising and falling solutions. This infinite kernel is in one-to-one correspondence with the ability to specify ``initial value data'' {\\it arbitrarily} over {\\it any} finite interval $t_1 < t < t_2$.",
      "authors": [
        "R. P. Woodard"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "hep-th"
      ],
      "published": "2026-02-18 05:18:11+00:00",
      "link": "https://arxiv.org/pdf/2602.16190v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15570v1",
      "title": "ModMax-AdS Black Hole with Global Monopole as Source in Kalb-Ramond Gravity",
      "abstract": "In this work, we investigate in detail the thermodynamic properties of a spherically symmetric ModMax-AdS black hole sourced by a global monopole within the Kalb-Ramond gravity. We derive the key thermodynamic quantities, including the Hawking temperature, Gibbs free energy, and specific heat capacity, and analyze how the geometric parameters influence these physical quantities. The first law of thermodynamics and the corresponding Smarr formula are explicitly verified. Furthermore, we study the thermodynamic criticality of the system by deriving the critical points and examining the effects of the space-time geometric parameters. We also obtain the inversion temperature and demonstrate that the minimum inversion temperature is modified by the space-time parameters. In addition, the sparsity of Hawking radiation and thermal fluctuations of the system are investigated, highlighting the effects of the parameters on the entropy corrections. Finally, we analyze the optical properties of the black hole, in particular the photon sphere and shadow radius, showing how these parameters influence these features.",
      "authors": [
        "Faizuddin Ahmed",
        "Ahmad Al-Badawi",
        "Edilberto O. Silva"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "hep-th"
      ],
      "published": "2026-02-17 13:28:25+00:00",
      "link": "https://arxiv.org/pdf/2602.15570v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15216v1",
      "title": "Black-hole thermodynamics in doubly special relativity: local-frame MDRs and rainbow metrics",
      "abstract": "Doubly Special Relativity (DSR) deforms special-relativistic kinematics while preserving the relativity principle by introducing a second invariant scale, typically the Planck energy $E_{\\rm Pl}$. Extending DSR-inspired modified dispersion relations (MDRs) to curved spacetimes is challenging, as ambiguous definitions of the deformation energy risk reintroducing preferred frames.   We review three common extensions beyond flat spacetime: (i) MDRs in local orthonormal frames on fixed backgrounds, (ii) phase-space/Hamiltonian geometry with relative locality, and (iii) rainbow metrics. Using black-hole thermodynamics for static spherically symmetric horizons, we compare two implementations: (A) energy-independent background with local-frame MDR, and (B) energy-dependent rainbow metric.   When the same prescription is used for the deformation energy scale $E_\\star$, both approaches yield identical Hawking temperatures: \\begin{equation} T(E_\\star)=T_0\\,\\frac{g(E_\\star/E_{\\rm Pl})}{f(E_\\star/E_{\\rm Pl})}\\,,\\qquad T_0=\\frac{κ_0}{2π}\\,, \\end{equation} where $κ_0$ is the classical surface gravity.   This $g/f$ scaling holds for examples such as Amelino--Camelia-type MDRs (leading correction $\\propto E p^2/E_{\\rm Pl}$, giving $T(E_\\star)\\simeq T_0(1-\\fracη{2}E_\\star/E_{\\rm Pl})$ for $η>0$) and the Magueijo--Smolin invariant ($f=g$, so $T(E_\\star)=T_0$).   Further DSR effects on evaporation (thresholds, phase space, greybody factors, composition laws) are discussed. Discrepancies in the literature arise mainly from different choices of $E_\\star$ (energy at infinity vs.\\ local frame). For macroscopic black holes, corrections are suppressed by $T_0/E_{\\rm Pl}$ and become relevant only near the Planck regime, where full quantum gravity dominates.",
      "authors": [
        "Abdelmalek Boumali"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "hep-th"
      ],
      "published": "2026-02-16 21:48:30+00:00",
      "link": "https://arxiv.org/pdf/2602.15216v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14898v1",
      "title": "Tarnished by Tools: Cost of Systematics in Golden Dark Siren Cosmology",
      "abstract": "Golden dark sirens - exceptionally well-localized gravitational-wave (GW) sources without electromagnetic counterparts - offer a powerful route to precision measurements of the Hubble constant, $H_0$, with next-generation (XG) detectors. The statistical promise of this method, however, places stringent demands on waveform accuracy and detector calibration, as even small systematic errors can dominate over statistical uncertainties at high signal-to-noise ratios. We investigate the impact of waveform-modeling systematics on golden dark siren cosmology using a synthetic population of binary black holes consistent with current GW observations and analyzed in the XG-detector era. By comparing state-of-the-art waveform models against numerical-relativity-based reference signals, we quantify modeling inaccuracies from both modeling and data-analysis perspectives and assess how they propagate into biases in luminosity distance, host-galaxy association, and single-event $H_0$ inference. We find that while current waveform models often allow recovery of statistically consistent $H_0$ posteriors, small waveform-induced biases can significantly affect three-dimensional localization and host galaxy ranking, occasionally leading to incorrect redshift assignments. We further derive order-of-magnitude requirements on detector calibration accuracy needed to ensure that calibration systematics remain subdominant for golden dark sirens observed with XG networks. To realize sub-percent $H_0$ measurements with golden dark sirens will require waveform and calibration accuracies that scale as $\\mathcal{O}(ρ^{-2})$ with signal-to-noise ratio, motivating sustained advances in waveform modeling, numerical relativity, and detector calibration for the XG era.",
      "authors": [
        "Giovanni Benetti",
        "Koustav Chandra",
        "Bangalore S. Sathyaprakash"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-16 16:34:30+00:00",
      "link": "https://arxiv.org/pdf/2602.14898v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14659v1",
      "title": "Investigating the impact of quasi-universal relations on neutron star constraints in third-generation detectors",
      "abstract": "Gravitational-wave observations of binary neutron star systems can shed light on the currently unknown dense matter equation of state. The equation of state determines a large number of neutron star properties, such as tidal deformability, radius, and quadrupole moment, several of which directly affect the emitted gravitational-wave signals. To reduce the dimensionality when computing gravitational-waves and when interpreting observational data, quasi-universal relations are commonly employed to connect different neutron star properties. However, quasi-universal relations are not exact and their use may introduce uncertainty and bias. We explore the potential biases arising from different quasi-universal relations in the third generation era: (i) the Love-Q relation connecting the spin-induced quadrupole moment and the tidal deformability, (ii) the relation between the fundamental mode frequency and the tidal deformability, and (iii) the binary Love relation. We find that for the quadrupole relation biases are only present for rapidly rotating systems, for the binary-Love relation induces moderate biases only in the next-to-leading-order tidal parameters, which can however propagate into the inferred equation of state at low masses. Regarding fundamental mode frequencies, we find that the employed relation introduces only negligible biases, while waveform systematic effects can become comparatively large. Our results highlight that while quasi-universal relations remain a useful tool within gravitational-wave analyses, careful treatment is needed to avoid biases in equation of state measurements with next-generation detectors.",
      "authors": [
        "Natalie Williams",
        "Anna Puecher",
        "Guilherme Grams",
        "César V. Flores",
        "Tim Dietrich"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "astro-ph.HE"
      ],
      "published": "2026-02-16 11:34:14+00:00",
      "link": "https://arxiv.org/pdf/2602.14659v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14082v1",
      "title": "The Theoretical Landscape of Mimetic Gravity: A Comprehensive Review",
      "abstract": "Mimetic gravity has emerged as a compelling extension of General Relativity (GR), originally motivated by the attempt to isolate the conformal degree of freedom of the gravitational field. By reparametrizing the physical metric in terms of an auxiliary metric and a scalar field, the theory naturally gives rise to a longitudinal degree of freedom that mimics the behavior of cold dark matter. This review provides a comprehensive survey of the theoretical landscape of mimetic gravity and its multifaceted applications to cosmology and high-energy physics. We begin by examining the original formulation and addressing the fundamental question of its equivalence to GR, highlighting how a singular disformal transformation introduces new physical degrees of freedom. We then explore minimal generalizations that lead to unified cosmological models, including mimetic matter scenarios and extensions into $f(R, φ)$ gravity, which allow for the reconstruction of any desired expansion history. Significant attention is given to the ``limiting curvature'' hypothesis through $f(\\Box φ)$ modifications, providing a classical mechanism for resolving cosmological and black hole singularities. We critically assess the challenges facing the theory, specifically the gradient and ghost instabilities identified in cosmological perturbations, and discuss modern resolutions such as ghost-free mimetic massive gravity and covariant formulations of Hořava gravity. Finally, we discuss the role of the mimetic field in the early universe, specifically in the context of asymptotically free gravity and the resolution of the self-reproduction problem in inflation.",
      "authors": [
        "O. Malaeb"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-15 10:21:27+00:00",
      "link": "https://arxiv.org/pdf/2602.14082v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13923v1",
      "title": "Hidden Conformal Symmetry and Emergent Holographic Structure in the AdS Teo Rotating Wormhole",
      "abstract": "We study scalar perturbations of the rotating Teo wormhole embedded in asymptotically Anti-de Sitter (AdS) spacetime and demonstrate that the radial Klein Gordon equation exhibits an emergent conformal structure. The smooth traversable throat induces a logarithmic tortoise coordinate that allows the radial equation to be recast as the quadratic Casimir eigenvalue equation, paralleling the hidden conformal symmetry of the rotating Kerr black hole but arising here in a horizonless geometry. The AdS-Teo spacetime possesses two disconnected timelike AdS conformal boundaries that remain causally connected through the wormhole throat, in contrast to the two-sided eternal AdS black hole where horizons play a central role. Using the emergent conformal symmetry, we construct the near-throat generators, derive the effective potential, and obtain a discrete quasinormal-mode spectrum determined by regularity at the throat and standard AdS boundary conditions at infinity. The AdS embedding further enables a minimal holographic interpretation. As an explicit illustration, we compute an equal-time two-point function in the large-Delta (geodesic) limit from a regulated spacelike geodesic that traverses the wormhole, showing how the bulk geometry couples the two asymptotic boundaries. Together, these results provide a unified description of hidden conformal structure, spectral properties, and boundary correlators in a rotating, horizonless asymptotically AdS wormhole.",
      "authors": [
        "Ramesh Radhakrishnan",
        "Gerald B. Cleaver",
        "William Julius"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-14 23:25:03+00:00",
      "link": "https://arxiv.org/pdf/2602.13923v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13854v1",
      "title": "Bounding the graviton mass using non-linear density wave theory",
      "abstract": "In this paper we use the Newtonian gravitational potential corrected by non-liner effects to obtain new bounds on graviton mass using non-linear density wave theory (NLDW). This potential differs from the gravitational potential obtained in other modified gravity theories (e.g. the weak field limit of Yukawa gravity, Modified Newtonian Dynamics, non-local theories, $Λ$ cold dark matter..). Using this model, we are able to define wavelength of the non-linear wave as an analytical solution of integrable non-linear differential equation (namely, non-linear Schrodinger equation). Assuming that the wavelength of the non-linear wave represents the graviton Compton wavelength, we have found the corresponding upper bound of graviton mass. We compare obtained result with first assessments of LIGO $\\&$ Virgo collaboration and we find they are in a good agreement. Present model used to determine the upper limit of graviton mass is completely independent from other methods published until now. We have compared our result with results obtained using several chosen published methods.",
      "authors": [
        "M. Vukcevic"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-14 19:36:18+00:00",
      "link": "https://arxiv.org/pdf/2602.13854v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12728v1",
      "title": "Dynamical system and statefinder analysis of cosmological models in f(T, B) gravity",
      "abstract": "This study systematically investigates the cosmological dynamics of two well-motivated functional forms in $f(T,B)$ gravity within a flat Friedmann-Lemaître-Robertson-Walker (FLRW) universe. Here $T$ denotes the torsion scalar and $B$ the boundary term, with the special choice $f(T,B) = - T + B$ recovering General Relativity. We focus on a multiplicative power-law model $f(T,B) = c_1 T^αB^β$ and an additive mixed power-law model $f(T,B) = c_2 T^α+ c_3 B^β$. Using dynamical system techniques, we construct autonomous systems and identify de Sitter attractors that naturally explain late-time cosmic acceleration. Analytical stability conditions for these fixed points are derived, and numerical simulations reveal characteristic evolutionary patterns, such as spiral trajectories and damped oscillations in the additive mixed power-law model. Furthermore, statefinder diagnostics are applied to quantitatively distinguish these models from the standard $Λ$CDM paradigm and other dark energy scenarios. The results indicate that $f(T,B)$ gravity offers a theoretically consistent and observationally distinguishable geometric framework for explaining cosmic acceleration, presenting a compelling alternative to conventional dark energy models.",
      "authors": [
        "Jianwen Liu",
        "Fabao Gao",
        "Aqeela Razzaq"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-13 08:56:57+00:00",
      "link": "https://arxiv.org/pdf/2602.12728v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12011v1",
      "title": "pespace: A new tool of GPU-accelerated and auto-differentiable response generation and likelihood evaluation for space-borne gravitational wave detectors",
      "abstract": "Space-borne gravitational wave detectors will expand the scope of gravitational wave astronomy to the milli-Hertz band in the near future. The development of data analysis software infrastructure at the current stage is crucial. In this paper, we introduce \\texttt{pespace} which can be used for the full Bayesian parameter estimation of massive black hole binaries with detectors including LISA, Taiji, and Tianqin. The core computations are implemented using the high-performance parallel programming framework \\texttt{taichi-lang} which enables automatic differentiation and hardware acceleration across different architectures. We also reimplement the waveform models \\texttt{PhenomXAS} and \\texttt{PhenomXHM} in the separate package \\texttt{tiwave} to integrate waveform generation within the \\texttt{taichi-lang} scope, making the entire computation accelerated and differentiable. To demonstrate the functionality of the tool, we use a typical signal from a massive black hole binary to perform the full Bayesian parameter estimation with the complete likelihood function for three scenarios: including a single detector using the waveform with only the dominant mode; a single detector using the waveform including higher modes; and a detector network with higher modes included. The results demonstrate that higher modes are essential in breaking degeneracies, and coincident observations by the detector network can significantly improve the measurement of source properties. Additionally, automatic differentiation provides an accurate way to obtain the Fisher matrix without manual fine-tuning of the finite difference step size. Using a subset of extrinsic parameters, we show that the approximated posteriors obtained by the Fisher matrix agree well with those derived from Bayesian parameter estimation.",
      "authors": [
        "Rui Niu",
        "Chang Feng",
        "Wen Zhao"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "astro-ph.IM"
      ],
      "published": "2026-02-12 14:41:08+00:00",
      "link": "https://arxiv.org/pdf/2602.12011v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11525v1",
      "title": "Precessions and parameter constraints from quasiperiodic oscillations in a rotating charged black hole",
      "abstract": "We investigate quasi-periodic oscillations (QPOs) as a diagnostic tool for probing frame-dragging effects and accretion disk physics in the spacetime of a rotating regular magnetic black hole (BH). Specifically, we analyze the precession of bound orbits and the epicyclic oscillations of test particles under small perturbations in the equatorial plane. We demonstrate how the BH nonminimal coupling parameter (lambda/M^4) and dimensionless magnetic charge (Q/M) significantly influence the three fundamental epicyclic frequencies. By applying the relativistic precession model and employing Markov Chain Monte Carlo simulations (MCMC), we constrain the BH characteristic parameters, including mass, spin, magnetic charge, and nonminimal coupling, using observational QPO data from five X-ray binaries: GRO J1655-40, XTE J1859+226, H1743-322, XTE J1550-564, and GRS 1915+105. Furthermore, we examine the Lense-Thirring, geodetic, and general spin precession frequencies of a test gyroscope attached to a stationary observer around the black hole. Our theoretical results indicate that the regular charged black hole suppresses these precession frequencies compared with the Kerr black hole case.",
      "authors": [
        "R. H. Ali",
        "Meng-He Wu",
        "Hong Guo",
        "Xiao-Mei Kuang"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-12 03:32:08+00:00",
      "link": "https://arxiv.org/pdf/2602.11525v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11297v1",
      "title": "Dynamical systems approach to stellar modelling in $f(G, B)$ gravity",
      "abstract": "The novel proposal to invoke the split of the Ricci scalar into bulk and boundary terms in the gravitational action, opens up a new avenue of investigation into stellar dynamics. The Lagrangian contains functional forms of the bulk while the boundary terms do not contribute to the dynamics. The advantage of the proposition is that the stellar structure equations are up to order two thus the theory is not haunted by ghosts. We obtain explicitly the defining equations for the thermodynamical variables and the geometry for the pure quadratic case since the linear case amounts to general relativity. In trying to establish the vacuum geometry associated with the theory it turns out that two possible metrics emerge through the vanishing of the energy-momentum tensor. Next we analyse the isotropy equation and make the observation that it is autonomous. It is rare that this happens in astrophysical modelling. This behaviour prompted the use of dynamical systems to understand the stability properties of fixed points or fixed manifolds. It was necessary to choose a gauge in order to split the autonomous equation into a system from which we could plot a phase portrait and deduce the stability of solution trajectories. We find that the fixed curves were generally stable with nearby paths approaching the fixed curves.",
      "authors": [
        "Sudan Hansraj",
        "Christian Boehmer",
        "Ndumiso Buthelezi"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-11 19:12:11+00:00",
      "link": "https://arxiv.org/pdf/2602.11297v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10889v1",
      "title": "Wave Propagation and Effective Refraction in Lorentz-Violating Wormhole Geometries",
      "abstract": "We study the propagation of massless scalar waves in static, spherically symmetric Lorentz-violating wormhole spacetimes within a geometric-optical framework. Starting from a general metric characterized by an arbitrary lapse function and areal radius, we derive curvature invariants, establish regularity conditions at the wormhole throat, and reduce the Klein-Gordon equation to a Helmholtz-type radial wave equation. This formulation naturally leads to a position- and frequency-dependent effective refractive index determined by the underlying spacetime geometry and Lorentz-violating structure, resulting in effective frequency-dependent wave-optical behavior. We show that divergences of the refractive index coincide with Killing horizons, while curvature-induced turning points control reflection, transmission, and confinement of scalar waves. By analyzing constant, linear, and quadratic lapse profiles, we identify horizonless transmission regimes, asymmetric wave propagation, and multi-horizon trapping structures. Our results reveal that Lorentz violation can significantly modify wave-optical properties of curved spacetime, generating graded-index analogues and geometric confinement of modes without curvature singularities. This unified optical perspective provides a robust framework for investigating wave scattering, resonances, and potential observational signatures in Lorentz-violating gravitational backgrounds.",
      "authors": [
        "Semra Gurtas Dogan",
        "Omar Mustafa",
        "Abdulkerim Karabulut",
        "Abdullah Guvendi"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "nucl-th"
      ],
      "published": "2026-02-11 14:17:45+00:00",
      "link": "https://arxiv.org/pdf/2602.10889v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10768v1",
      "title": "Exact Dynamical Regular Black Holes from Generalized Polytropic Matter",
      "abstract": "We present a class of exact, dynamical, and fully analytic solutions describing regular black holes formed via the gravitational collapse of matter obeying a generalized polytropic equation of state. Starting from a Vaidya-type geometry with a radially dependent mass function, we demonstrate that regularization of the Kiselev solutions can be achieved through a physically motivated modification of the energy density profile. This procedure leads to nonsingular spacetimes with a de~Sitter core and finite curvature invariants at the center.   We show that the resulting matter content is naturally described by a generalized polytropic equation of state of the form $P=αρ-ζρ^γ$, where the polytropic index $γ$ is uniquely determined by the regularization scheme. Within this framework, we obtain exact dynamical generalizations of several well-known regular black hole solutions, including the Hayward and Bardeen spacetimes, as particular cases corresponding to specific values of the polytropic parameters.   Remarkably, the requirement that the equation of state remains coordinate independent imposes a universal constraint relating the regularization scale to the mass function, which in turn guarantees the existence of a regular de~Sitter core with a curvature scale independent of the black hole mass. Our results provide a unified analytic description of Hayward-like and Bardeen-like black holes emerging from gravitational collapse, offering a consistent effective-matter interpretation rooted in generalized polytropic matter.",
      "authors": [
        "Dmitriy Kudryavcev",
        "Yi Ling",
        "Vitalii Vertogradov"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-11 11:57:26+00:00",
      "link": "https://arxiv.org/pdf/2602.10768v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10462v1",
      "title": "Spacetime of rotating black holes surrounded by massive scalar charges",
      "abstract": "Massive scalar charges are ubiquitous in extensions to General Relativity and the Standard Model in particle physics. We describe spectral methods which can accurately construct the spacetime of rotating black holes with dimensionless spin up to $a \\leq 0.8$ surrounded by massive scalar fields nonminimally coupled to spacetime curvature. We consider axi dilaton, dynamical Chern Simons, and scalar Gauss Bonnet couplings, and obtain leading order solutions for both the scalar field and the associated metric modifications. Our method accurately resolves massive scalar fields with Compton wavelengths as short as 5 times the black hole mass, achieving residual errors $\\lesssim 10^{-5}$, and yields the corresponding leading order spacetime modifications with residual errors $\\lesssim 10^{-3}$. Using the constructed spacetimes, we computes the leading-order shifts in the surface gravity and the angular velocity of the event horizon, important information for computing the quasinormal modes. These results pave the way to incorporate massive scalar charges into electromagnetic observations and gravitational-wave detections of black holes, potentially enabling new probes of fundamental scalar degrees of freedom.",
      "authors": [
        "Adrian Ka-Wai Chung"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-11 03:00:48+00:00",
      "link": "https://arxiv.org/pdf/2602.10462v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09682v1",
      "title": "Thermodynamic Interpretation of the Kompanneets-Chernov-Kantowski-Sachs Solutions",
      "abstract": "The spatially homogeneous perfect fluid solutions by Kompanneets-Chernov-Kantowski-Sachs are interpreted as a thermodynamic perfect fluid in isentropic evolution, namely, the isentropic limit of their non-homogeneous generalizations, the T-models. Some specific solutions that model a generic ideal gas are examined, and the associated thermodynamic variables are obtained. We show that the necessary macroscopic conditions for physical reality are fulfilled in wide spacetime domains. The field equations for a classical ideal gas are established, and the behavior of the solution is analyzed. The models fulfilling a relativistic $γ$-law are also examined, and the solutions for some particular cases are obtained.",
      "authors": [
        "Salvador Mengual",
        "Joan Josep Ferrando"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-10 11:37:41+00:00",
      "link": "https://arxiv.org/pdf/2602.09682v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09568v1",
      "title": "Revisiting critical orbits of test particles traveling in a black hole background",
      "abstract": "This paper systematically revisits the critical orbits of test particles moving in various black hole backgrounds, including the Schwarzschild, Reissner-Nordström, Kerr, and Kerr-Newman spacetimes. We identify the critical orbit cases directly from the root structure of the radial equation, and provide explicit expressions relating the relevant parameters -- energy, angular momentum, and charge-to-mass ratio -- to the critical radius, as well as explicit expressions for the critical orbits in each scenario. Special attention is given to the relationship between the photon spheres, black hole shadows and the critical null geodesics. Extensive numerical results are also provided.",
      "authors": [
        "Ping Li",
        "Jun Cheng",
        "Jiang-he Yang"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-10 09:20:04+00:00",
      "link": "https://arxiv.org/pdf/2602.09568v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09498v1",
      "title": "Constraints on Interacting Early Dark Energy from a Modified Temperature-Redshift Relation and CMB Acoustic Scales",
      "abstract": "The Hubble tension, reflecting a persistent discrepancy between early- and late-time determinations of the Hubble constant, continues to motivate extensions of the standard cosmological model The Hubble tension motivates extensions of the standard cosmological model that modify pre-recombination physics. In this work we study an early dark energy scalar field coupled to radiation prior to recombination. The interaction leads to energy exchange between the two components and modifies the standard cosmic microwave background temperature redshift relation.   We derive the modified temperature evolution from the background equations and interpret it in terms of effective photon non-conservation. We also study linear scalar perturbations in the tight-coupling regime relevant for cosmic microwave background acoustic physics. We show that the interaction affects the background evolution without introducing new dynamical degrees of freedom at the perturbation level.   The dominant observational effect arises through a shift in the sound horizon at recombination, which modifies the angular acoustic scale. Using the Planck constraint on the acoustic scale we obtain a consistency bound on the coupling strength and show that deviations from the standard temperature redshift relation are tightly constrained.",
      "authors": [
        "Y Bisabr"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-10 07:52:52+00:00",
      "link": "https://arxiv.org/pdf/2602.09498v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09249v1",
      "title": "Towards a general field equation for galaxies and galaxy clusters",
      "abstract": "The MONDian theory of AQUAL (AQUAdratic Lagrangian) and the theory of GRAS (GRavitational Anti-Screening) are alternatives to the theory of dark matter. When these theories are applied to galaxy dynamics they are in excellent agreement with observations including the galactic RAR (Radial Acceleration Relationship). However, when applied to galaxy clusters they do not explain the bulk of the missing mass. This manuscript develops a modified version of the GRAS/AQUAL field equation that can be extended to galaxy clusters. It involves just a single free parameter. The new field equation is then applied to a sample of galaxy clusters and checked against modeled galaxies and solar system constraints. Further to this, the modified field equation leads to an understanding of the difference between the galactic RAR and the RAR recently found for clusters.",
      "authors": [
        "Albert Raymond Penner"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA",
        "gr-qc"
      ],
      "published": "2026-02-09 22:31:24+00:00",
      "link": "https://arxiv.org/pdf/2602.09249v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09244v1",
      "title": "Temperature of a spinning black hole via a simple derivation",
      "abstract": "According to current theory a black hole has a nonzero temperature and thus radiates like any black body. This remarkable result was first shown by Hawking for a non-spinning black hole using general relativity to describe the black hole gravitational field and quantum field theory to describe the radiation. Since then the temperature of a spinning Kerr black hole has been calculated. There have also been many heuristic derivations for the temperature. In this work we derive the temperature of a Kerr spinning black hole using only classical general relativity and thermodynamics. It is very similar to Ref. 11 but is mathematically simpler and more self-contained. Our purpose is mainly pedagogical, to be more accessible to students and non-specialists with a knowledge of general relativity. We also call further attention to the expected explosive evaporation of small black holes, not yet observed, which would be an almost unique window into Planck scale physics. Finally, we discuss the idea that the cosmological dark matter, whose nature is currently unknown, may be composed of small primordial black hole remnants.",
      "authors": [
        "Ronald J. Adler"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-09 22:17:14+00:00",
      "link": "https://arxiv.org/pdf/2602.09244v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09125v1",
      "title": "Quantum State Characterization of Gravitational Waves via Graviton Counting Statistics",
      "abstract": "Although gravitational waves are now routinely observed, the detection of individual gravitons has long been regarded as impossible. Recent work, however, has demonstrated that single-graviton detection can be achieved and may be feasible in the near future. Here we show that beyond mere particle detection, these detectors provide access to the quantum state and particle statistics of gravitational waves. We show that graviton detection probabilities enable the discrimination between squeezed, coherent, and thermal radiation. We further demonstrate that the full quantum statistics contained in the second-order correlation function of the passing wave can be directly measured at the detector, independent of the weak gravitational interaction strength. Building on recent quantum-optical techniques, this capability opens the way to full quantum state tomography of Gaussian states. Our results demonstrate that single-graviton detection is not only of foundational significance but also of practical value, allowing for the characterization of quantum statistics and the states of the gravitational radiation field, which remain currently unknown.",
      "authors": [
        "Kristian Toccacelo",
        "Thomas Beitel",
        "Ulrik Lund Andersen",
        "Igor Pikovski"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "gr-qc"
      ],
      "published": "2026-02-09 19:16:13+00:00",
      "link": "https://arxiv.org/pdf/2602.09125v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09102v1",
      "title": "Polarization Signatures of Inspiraling Hotspots around Kerr Black Holes",
      "abstract": "Polarimetric interferometry is a powerful tool for probing both black hole accretion physics and the background spacetime. Current models aimed at explaining the observed multiwavelength flares in Sgr A* often assume hotspots moving on geodesic, Keplerian orbits. In many scenarios, though, a hotspot may instead follow an inspiraling trajectory, potentially transitioning into a plunge toward the black hole. In this work, we present a general framework to simulate the polarized emission from generic equatorial inspiraling hotspots in Kerr spacetime using a parametric four-velocity profile. This parametrization defines a continuous family of flows, ranging from Cunningham's disk model (fixed radius orbits outside the innermost stable circular orbit and plunging motion within the innermost stable circular orbit) to purely radial motion, thereby extending the standard assumptions. Within this framework, we show that inspiral motion produces a distinctive observational signature: a precessing, unwinding evolution of the polarimetric Stokes Q-U looping pattern, in sharp contrast with the closed Q-U loops associated with stable orbits at a fixed radius. We then explore how the morphology of these signatures depends on black hole spin, observer inclination, and magnetic-field configuration. The presented model can be applied to current and near-future interferometric observations of linear polarization, offering a new avenue to probe the physics of matter spiraling inward and the relativistic velocities of plunging plasma.",
      "authors": [
        "Pablo Ruales",
        "Delilah E. A. Gates",
        "Alejandro Cárdenas-Avendaño"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "gr-qc"
      ],
      "published": "2026-02-09 19:00:04+00:00",
      "link": "https://arxiv.org/pdf/2602.09102v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16428v1",
      "title": "The Penrose-Rindler equation and horizon thermodynamics of stationary black holes",
      "abstract": "Black holes are the natural arena for exploring the interplay between gravity and thermodynamics. Although the association between black hole mechanics and black hole thermodynamics is well-established, the comprehensive geometric formulation of thermodynamic variables deserves further investigation. In this work, both Newman-Penrose (NP) and Geroch-Held-Penrose (GHP) formalisms are considered within the framework of horizon thermodynamics. We show that the NP formalism reformulates the horizon condition as the Penrose-Rindler equation. In this context, a Smarr-like formula for stationary black holes is recovered from the Penrose-Rindler equation reinterpreted as a horizon equilibrium of pressures, which includes a pressure associated with the horizon rotation. A complete geometric reformulation of this reinterpretation of the Penrose-Rindler equation evaluated at the horizon is developed within the GHP formalism. The GHP approach further inspires the introduction of the horizon-averaged matter pressure and its conjugate volume, thereby enabling a quasi-local realization of the Smarr-like formula for stationary black holes. This geometric formulation clarifies the connection between horizon dynamics and thermodynamics and offers a unified setting for extending black hole thermodynamics beyond spherical symmetry.",
      "authors": [
        "Diego Fernández-Silvestre",
        "Alberto Guilabert",
        "Pedro Bargueño",
        "Juan A. Miralles"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-18 13:00:08+00:00",
      "link": "https://arxiv.org/pdf/2602.16428v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16117v1",
      "title": "Solving BDNK diffusion using physics-informed neural networks",
      "abstract": "In this work, we reformulate the relativistic BDNK (Bemfica-Disconzi-Noronha-Kovtun) diffusion equation in flux-conservative form, and solve the resulting equations in $(1+1)$D using both a second-order Kurganov-Tadmor finite volume scheme and physics-informed neural networks (PINNs). In particular, we introduce the SA-PINN-ACTO framework, which combines the self-adaptive PINN technique with an exact enforcement of initial and periodic boundary conditions through an algebraic transform of the network's raw output, allowing the network to focus solely on minimizing the PDE residual. We test both approaches on smooth and discontinuous initial data, for both trivial and dynamically evolving velocity and temperature BDNK backgrounds, and for two characteristic speeds. The SA-PINN-ACTO method matches the converged Kurganov-Tadmor solutions for smooth profiles, while for discontinuous profiles the errors increase, reflecting an expected limitation of PINNs near sharp gradients.",
      "authors": [
        "Vicente Chomalí-Castro",
        "Nick Clarisse",
        "Nicki Mullins",
        "Jorge Noronha"
      ],
      "primary_category": "nucl-th",
      "categories": [
        "nucl-th",
        "astro-ph.HE",
        "gr-qc"
      ],
      "published": "2026-02-18 00:58:19+00:00",
      "link": "https://arxiv.org/pdf/2602.16117v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15991v1",
      "title": "Power-Law Inflation in n-Dimensional Fractional Scalar Field Cosmology: Observational Constraints and Dynamical Analysis",
      "abstract": "Power-law inflation with $a(t) \\propto t^m$ is conceptually simple and predicts a scalar tilt $n_s = 1 - 2/m$ compatible with CMB data, but in four-dimensional Einstein gravity it typically yields a tensor-to-scalar ratio $r = 16/m$ that is too large to satisfy current bounds. We show that a minimal extension based on fractional scalar-field cosmology resolves this tension. Introducing a fractional order $α\\neq 1$ generates non-local (memory) corrections in the Friedmann and Klein-Gordon dynamics that suppress $r$ while keeping $n_s$ essentially unchanged. We derive an explicit mapping $α(n,m)$ and recover the standard power-law limit as $α\\to 1$. For observationally favored values $α\\approx 0.8$-$0.9$ in four dimensions we obtain $n_s \\approx 0.965$ and $r \\lesssim 0.04$, bringing power-law inflation into agreement with data. The scalar potential follows self-consistently as an exponential, and a dynamical-systems analysis shows the fractional power-law solutions form stable inflationary attractors over the viable parameter range. These results establish fractional power-law inflation as a predictive and testable framework, with clear targets for forthcoming CMB polarization measurements.",
      "authors": [
        "Daniel Oliveira",
        "Seyed Rasouli",
        "Joao Marto",
        "Paulo Moniz"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-02-17 20:27:38+00:00",
      "link": "https://arxiv.org/pdf/2602.15991v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14823v1",
      "title": "The Habitable Worlds Observatory in Historical Context",
      "abstract": "We summarize the past four decades of astrophysics and exoplanet direct imaging mission concept studies, technology developments, and scientific progress that have led to the initiation of the Habitable Worlds Observatory project by NASA.",
      "authors": [
        "Marc Postman",
        "Karl Stapelfeldt"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-02-16 15:14:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14823v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14628v1",
      "title": "Large-scale and local environmental drivers of quenching: tracing H$α$ concentration in X-ray and optical galaxy groups",
      "abstract": "To explore the environmental mechanisms causing quenching in nearby star-forming galaxies, we study the variation with local and large-scale environments of a star formation concentration index, C-index $\\equiv\\log{(r_{50,{\\rm H}α}/r_{50,\\rm cont}})$, that traces the spatially-resolved distribution of H$α$ emission. Our analysis combines (i) GAMA spectroscopic redshift survey data to optically select galaxy groups and reconstruct the cosmic web, (ii) eROSITA data to identify X-ray-emitting groups, and (iii) SAMI Galaxy Survey data to characterise spatially-resolved star formation. We find that galaxies in X-ray+optical groups exhibit the lowest median C-index and the highest fraction of centrally-concentrated star-forming galaxies relative to optical groups and the field (independently of group or stellar mass). Star-forming galaxies in more X-ray luminous groups at fixed dynamical mass show more concentrated star formation. At large scales, nodes show the lowest median C-index and the highest fraction of centrally-concentrated star-forming galaxies relative to filaments and voids, which have similar C-index distributions. C-index correlates most strongly with the distance to the closest node, leaving no significant role for other local or large-scale environment metrics. Finally, regular star-forming galaxies tend to have spins aligned parallel to filaments, consistent with smooth gas accretion, while centrally-concentrated galaxies tend have spins aligned perpendicular to filaments, likely driven by mergers and associated with bulge growth. These results suggest that multi-scale environmental processes, i.e. locally and at large-scale, act to concentrate star formation toward galaxy centres, via gas-related mechanisms in nodes and ram-pressure stripping in X-ray+optical groups.",
      "authors": [
        "Stefania Barsanti",
        "Di Wang",
        "Matthew Colless",
        "Ang Liu",
        "Esra Bulbul",
        "Matt S. Owers",
        "Scott M. Croom",
        "Benedetta Vulcani",
        "Julia J. Bryant",
        "Yifan Mai",
        "Sree Oh",
        "Andrei Ristea",
        "Sarah M. Sweet",
        "Jesse van de Sande"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-16 10:34:24+00:00",
      "link": "https://arxiv.org/pdf/2602.14628v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14533v1",
      "title": "Zel'dovich smearing approximation of the BAO feature for model-agnostic cosmological inference",
      "abstract": "A model-agnostic description of the baryon acoustic oscillation (BAO) feature in redshift space requires a number of ingredients. Physically, one must describe the impact of cosmological bulk flows which progressively and anisotropically smear out the feature over time. One must also model the effects of the scale dependence of tracer bias and the mode coupling between short and long scales. All of these can be incorporated using the Zel'dovich approximation alone, without reference to any particular cosmological model. On the technical front, one needs a robust, complete and cosmology-independent basis to describe the shape of the real space BAO feature in linear theory, which can then be propagated to the nonlinearly evolved, measured feature in redshift space. In this work, we describe how these ingredients -- which we have systematically constructed in recent work -- come together in an accurate framework capable of describing the BAO-scale pairwise measurements of state-of-the-art galaxy surveys. Using mock observations and $N$-body simulations, we show that our template-free framework can produce unbiased and precise cosmological constraints for samples with realistic levels of nonlinearity. This work represents one of the final steps in constructing a data-ready analysis framework for model-agnostic cosmological inference from the BAO feature.",
      "authors": [
        "Aseem Paranjape",
        "Ravi K. Sheth"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-16 07:42:28+00:00",
      "link": "https://arxiv.org/pdf/2602.14533v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.14087v1",
      "title": "S-PLUS: Beyond Spectroscopy IV. Stellar Parameters and Elemental-abundance Ratios for Six Million Stars from DR4 and First Results for the Magellanic Clouds",
      "abstract": "We combine narrow/medium-band filter photometry from the Southern Photometric Local Universe Survey (S-PLUS) DR4 with ultra broad-band filter photometry from Gaia EDR3 to derive fundamental stellar parameters ($T_{\\rm eff}$, $\\log g$, [Fe/H], ages) and elemental-abundance ratios ([C/Fe] and [$α$/Fe]) for 5.4 million stars in the Galaxy (4.9 million dwarfs and 0.5 million giants), as well as for over 0.7 million red giant stars in the Large and Small Magellanic Clouds (LMC and SMC). The precisions of the abundance estimates range from 0.05-0.10 dex for metallicity in the relatively metal-rich range ([Fe/H] $> -1.0$) to 0.10-0.30 dex in the metal-poor regime ([Fe/H] $<-1.0$), 0.10-0.20\\,dex for [C/Fe], and 0.05 dex for [$α$/Fe]. The stellar parameters for LMC and SMC member stars are somewhat less precise than those from the S-PLUS main survey, primarily because of the effect of high reddening. The use of both metallicity- and carbon-sensitive filters provides unbiased measurements of both [Fe/H] and [C/Fe], of particular importance for very low-metallicity ([Fe/H] $< -2.0$) stars, where carbon enhancement can lead to systematically high estimates of [Fe/H] when only a single metallicity-sensitive filter is employed. Furthermore, multiple narrow-band filters enable metallicity estimates down to [Fe/H] $\\sim -4.0$ with an accuracy of around 0.3 dex, exceeding the precision typically achieved by low/medium-resolution spectroscopy. This extensive photometric dataset, combined with the other three datasets in this series, will serve as a valuable legacy resource for Milky Way and Magellanic Clouds studies.",
      "authors": [
        "Yang Huang",
        "Timothy C. Beers",
        "Kai Xiao",
        "C. Mendes de Oliveira",
        "Felipe Almeida-Fernandes",
        "G. B. Oliveira Schwarz",
        "Young Sun Lee",
        "Jihye Hong",
        "Huiling Chen",
        "Huawei Zhang",
        "Guilherme Limberg",
        "Maiara S. Carvalho",
        "P. K. Humire",
        "André Luiz Figueiredo",
        "Bruno Dias",
        "Alvaro Alvarez-Candal",
        "Marcos Fonseca-Faria",
        "A. Kanaan",
        "T. Ribeiro",
        "W. Schoenell",
        "Silvia Rossi"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA"
      ],
      "published": "2026-02-15 10:27:51+00:00",
      "link": "https://arxiv.org/pdf/2602.14087v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14052v1",
      "title": "Constraining Lorentz Violation using 21cm and CMB Cross Correlations",
      "abstract": "Lorentz symmetry is a fundamental pillar of modern Physics, yet high-energy theories often predict its violation. One potential signature of such a violation is cosmic birefringence - rotation of the polarization plane of photons due to Chern-Simons coupling in Maxwell's electrodynamics. This rotation angle, aka birefringence angle, depends upon the distance travelled by the photon and is thus different for CMB and 21cm photons. While the rotation angle in CMB, i.e., $α_\\mathrm{CMB}$, has been tightly constrained by CMB experiments, the potential of the 21cm cosmological signal to constrain this parameter, as well as constrain $α_\\mathrm{21cm}$, remains largely unexplored. In this work, we provide constraints on both these angles by cross-correlating 21cm and CMB signals. Using the Fisher matrix formalism, we give our forecasts for 21cm experiments, including SKA, HIRAX, and PUMA, and Planck like CMB experiment. We find that best constraints $σ_{α_\\mathrm{CMB}} \\sim 4.4^\\circ$ and $σ_{α_\\mathrm{21cm}} \\sim 100^\\circ$ are found using $C_\\ell^{T_{21} B_\\mathrm{CMB}}$ and $C_\\ell^{T_{21} B_{21}}$ respectively. Since birefringence hasn't yet been detected in 21cm, we choose the fiducial value $α_\\mathrm{21cm}^\\mathrm{fid}=0$ assuming the null hypothesis.",
      "authors": [
        "Bhuwan Joshi",
        "Rahul Kothari",
        "Shyam Chaudhary"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-15 08:43:58+00:00",
      "link": "https://arxiv.org/pdf/2602.14052v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13996v1",
      "title": "Superhumps and their Relation to the Disk Instability Model",
      "abstract": "Since the discovery of superhumps in 1974, these photometric modulations have provided a crucial observational window into disk instabilities in cataclysmic variable stars, particularly the tidal instability associated with the 3:1 resonance. Over the past few decades, extensive time-resolved photometry has revealed a rich diversity of superhump-related phenomena, including delayed superhump development, early superhumps in WZ Sge-type dwarf novae, systematic stage A-B-C evolution, negative superhumps, and superhumps observed in related systems such as intermediate polars and AM CVn stars. In this invited review, we summarize key observational advances since the establishment of the thermal-tidal instability framework, discuss their theoretical interpretations within the disk instability model, and highlight remaining open problems. These developments have been driven by coordinated networks of amateur observers, wide-field robotic surveys, and continuous high-precision space-based photometry from Kepler and TESS. Together, they demonstrate that superhumps remain a powerful probe of disk dynamics, binary parameters, and the interplay between thermal, tidal, and geometric effects in accretion disks.",
      "authors": [
        "Daisaku Nogami"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR"
      ],
      "published": "2026-02-15 05:35:22+00:00",
      "link": "https://arxiv.org/pdf/2602.13996v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13992v1",
      "title": "Dense Molecular Clumps with Large Blue Asymmetries: Evidence for Collapse",
      "abstract": "An analysis of the Millimetre Astronomy Legacy Team 90 GHz (MALT90) survey has produced a sample of 27 candidate dense molecular clumps with large collapse motions, as revealed by large ``blue'' asymmetrical line profiles of the optically thick \\hcop\\, line. %with respect to the optically thin \\nthp\\, line. New, more sensitive molecular line observations of this sample, conducted with the Mopra 22-m telescope, confirm the blue asymmetries in the \\hcop\\, line profiles, with large, positive values of the asymmetry parameter $A$ ($\\bar{A}_{HCO^+} = 0.69\\pm0.01$), and positive, but smaller asymmetries in the \\hcn\\, and \\hnc\\, lines: ($\\bar{A}_{HCN} = 0.35\\pm0.01$ and $\\bar{A}_{HNC} = 0.28\\pm0.01$), as expected for a less optically thick tracer in collapsing clumps. The small, positive mean asymmetry parameters for \\cch\\, and \\htcop, $\\bar{A}_{C_2H} = 0.15\\pm0.02$ and $\\bar{A}_{H^{13}CO^+} = 0.18\\pm0.03$, likely indicate slightly optically thick emission for at least some clumps. The hyperfine ratios for \\nthp\\, are in their optically thin, LTE, values, but for \\hcn\\ they are not; the $F=1 \\to 1$ hyperfine line shows abnormally weak intensities. A simple two-component model shows that self-absorption of the background $F = 1 \\to 1$ hyperfine line by the main $F = 2 \\to 1$ hyperfine line of a cold, foreground, redshifted cloud can reproduce the observed \\hcn\\, hyperfine intensities and match the \\hcn\\, and \\hcop\\, line profiles. All of these results are consistent with self-absorption of the optically thick lines on the red side of the profile, as expected for collapsing clumps. A simple two-cloud model suggests that this sample represents dense clumps with extreme collapse velocities, $V_{inf} \\sim 2.4$ \\kms.",
      "authors": [
        "James M. Jackson",
        "J. Scott Whitaker",
        "Edward Chambers",
        "Robert Simon",
        "Cristian Guevara",
        "David Allingham",
        "Philippa Patterson",
        "Nicholas Killerby-Smith",
        "Jacob Askew",
        "Patricio Sanhueza",
        "Ian W. Stephens",
        "Anika Shmiedeke",
        "Jacob Askew",
        "Robert Loughnane"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-15 05:07:58+00:00",
      "link": "https://arxiv.org/pdf/2602.13992v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13902v1",
      "title": "J-PAS: Semi-Supervised Sim-to-Obs Transfer for Robust Star--Galaxy--Quasar Classification",
      "abstract": "Modern studies in astrophysics and cosmology increasingly rely on simulations and cross-survey analyses, yet differences in data generation, instrumentation, calibration, and unmodeled physics introduce distribution mismatches between datasets (``domain shift''). In machine-learning pipelines, this occurs when the joint distribution of inputs and labels differs between the training (source) and application (target) domains, causing source-trained models to underperform on the target. Transfer learning and domain adaptation provide principled ways to mitigate this effect. We study a concrete simulation-to-observation case: semi-supervised domain adaptation (SSDA) to transfer a four-class spectral classifier -- high-redshift quasars, low-redshift quasars, galaxies, and stars -- from J-PAS mock catalogs based on DESI spectra to real J-PAS observations. Our pipeline pretrains on abundant labeled DESI$\\rightarrow$J-PAS mocks and adapts to the target domain using a small labeled J-PAS subset. We benchmark SSDA against two baselines: a J-PAS--only supervised model trained with the same target-label budget, and a mocks-only model evaluated on held-out J-PAS data. On this held-out J-PAS data, SSDA achieves a macro-F1 score (balancing precision and recall) of $0.82$ and an overall true positive rate of $0.89$, compared to $0.79/0.85$ for the J-PAS--only baseline and $0.73/0.87$ for the mocks-only model. The gains are driven primarily by improved quasar classification, especially in the high-redshift subclass ($\\mathrm{F1}=0.66$ vs.\\ $0.55/0.37$), yielding better-calibrated candidate lists for spectroscopic targeting (e.g., WEAVE-QSO) and AGN searches. This study shows how modest target supervision enables robust, data-efficient simulation-to-observation transfer when simulations are plentiful but target labels are scarce.",
      "authors": [
        "Daniel López-Cano",
        "L. Raul Abramo",
        "L. Nakazono",
        "I. Pérez-Ràfols",
        "G. Martínez-Solaeche",
        "J. Chaves-Montero",
        "Matthew M. Pieri",
        "Jailson Alcaniz",
        "Narciso Benitez",
        "Silvia Bonoli",
        "Saulo Carneiro",
        "Javier Cenarro",
        "David Cristóbal-Hornillos",
        "Simone Daflon",
        "Renato Dupke",
        "Alessandro Ederoclite",
        "Rosa González Delgado",
        "Antonio Hernán-Caballero",
        "Carlos Hernández-Monteagudo",
        "Jifeng Liu",
        "Carlos López-Sanjuan",
        "Antonio Marín-Franch",
        "Claudia Mendes de Oliveira",
        "Mariano Moles",
        "Fernando Roig",
        "Laerte Sodré",
        "Keith Taylor",
        "Jesús Varela",
        "Héctor Vázquez Ramió",
        "Jose Vilchez",
        "Javier Zaragoza-Cardiel"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO"
      ],
      "published": "2026-02-14 21:51:38+00:00",
      "link": "https://arxiv.org/pdf/2602.13902v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13523v1",
      "title": "The Cosmological Parameters (2025)",
      "abstract": "This is a review article for The Review of Particle Physics 2026 (aka the Particle Data Book), appearing as Chapter 25. It forms a compact review of knowledge of the cosmological parameters near the end of 2025. Topics included are Parametrizing the Universe; Extensions to the standard model; Probes; Bringing observations together; Outlook for the future.",
      "authors": [
        "Marina Cortês",
        "Ofer Lahav",
        "Andrew R Liddle"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-13 23:21:31+00:00",
      "link": "https://arxiv.org/pdf/2602.13523v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13471v1",
      "title": "Searching for Neutron Star Mergers in the Absence of Gravitational Waves with Optical Afterglow Emission",
      "abstract": "With the forth observing run of the LIGO-Virgo-KAGRA gravitational-wave network, which enabled the discovery of the kilonova (KN) counterpart to GW170817, ending with no new confirmed neutron star mergers, the intrinsic rate of these events must be even lower than previously estimated. As a result, building a sample of KNe will remain challenging even with continued GW observations, motivating complementary discovery strategies that do not rely on gravitational-wave triggers. In this work, we consider how leveraging bright short gamma-ray burst afterglows can aid in the discovery on KNe with the Rubin Observatory's upcoming Legacy Survey of Space and Time (LSST), whose unprecedented depth will make such detections feasible. We find that nearly on-axis ($θ_{\\rm view} \\leq 30°$) afterglows can enhance KN detection rates in the LSST $g$-band from $29^{+51}_{-21} \\ \\rm yr^{-1}$ to $91^{+160}_{-65} \\ \\rm yr^{-1}$. We further show how the colors of the observed events can be used to distinguish between neutron star merger counterparts with and without KN emission. This study demonstrates how critical multi-wavelength and multi-survey observations are for these rare events, especially without context from gravitational waves. Fortunately, detectable events will likely be discovered near peak with LSST, allowing for rapid follow-up and confirmation. We discuss key uncertainties in our study, particularly volume rate of merger events, and the degeneracy between the empirically determined explosion energy and ambient medium density.",
      "authors": [
        "Haille M. L. Perkins",
        "Gautham Narayan",
        "Brian D. Fields",
        "Ved G. Shah",
        "Genevieve Schroeder"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE"
      ],
      "published": "2026-02-13 21:22:47+00:00",
      "link": "https://arxiv.org/pdf/2602.13471v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13396v1",
      "title": "MeerKAT discovery of a high-redshift strongly-lensed hydroxyl gigamaser",
      "abstract": "At low redshifts, hydroxyl megamasers (OHMs) have been shown to trace galaxy mergers, obscured starbursts, high molecular gas densities, and candidate dual supermassive black hole systems. Given this astrophysical utility, exploring these sources at larger cosmological look-back times is therefore of key interest. While previous OHM surveys have been limited to redshifts of $z \\lesssim 0.25$, the ability to expand the OHM frontier is significantly enhanced with new high-sensitivity radio facilities such as MeerKAT. In this Letter, we report the discovery of an OHM in the gravitational lens system HATLAS J142935.3-002836 at $z = 1.027$, the most distant OHM source yet detected. The spectrum has blended 1667 and 1665 MHz emission and exhibits a highly complex profile, with spectral components ranging in widths of $<8$ km s$^{-1}$ to $\\sim300$ km s$^{-1}$. The integrated (magnification uncorrected) luminosity of log($L_{\\rm OH} / L_{\\odot}$) = 5.51 $\\pm$ 0.67 makes this the most apparently luminous OHM known to date. In the same wide-band dataset, we have also detected a previously unknown ${\\rm H I}$ absorption line. The signal-to-noise ratio of over 150 with just a 4.7 h observation highlights the potential that MeerKAT and the future Square Kilometre Array mid-frequency array offer to explore the high-redshift OHM universe.",
      "authors": [
        "Thato E. Manamela",
        "Roger P. Deane",
        "Tariq Blecher",
        "Ian Heywood",
        "Athol J. Kemball",
        "Danail Obreschkow"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-13 19:01:03+00:00",
      "link": "https://arxiv.org/pdf/2602.13396v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.13394v1",
      "title": "ARCHITECTS II: Impact of subgrid physics on the observable properties of the circumgalactic medium",
      "abstract": "Galaxy evolution is driven by star formation and stellar feedback on scales unresolved by current high-resolution cosmological simulations, requiring robust subgrid models. However, these models remain degenerate, often calibrated primarily to match observed stellar masses. To explore these degeneracies, we conduct three state-of-the-art cosmological zoom-in simulations of the same galaxy, each incorporating different subgrid models: mechanical feedback, a combination of mechanical and thermal feedback, and delayed cooling. We compare their circumgalactic media (CGM) through quasar absorption sightlines of HI, MgII, CIV, and OVI. Our findings demonstrate that despite producing galaxies with the same stellar masses, the models lead to distinct feedback modes and CGM properties. Column densities and covering fractions serve as effective diagnostics of subgrid models, with all four ions providing strong constraints as they trace diverse gas phases, exhibit complementary spatial distributions, and originate from different mechanisms. Although all simulations bracket observed column density distributions, direct comparisons are limited by scarce detections and significant scatter in absorption strengths. Covering fractions of weak absorbers provides the most robust constraints. All models fail to reproduce HI and MgII covering fractions, and delayed cooling overproduces OVI covering fractions, while the other models underproduce them. The simulation including mechanical feedback reproduces the observed CIV covering fractions well, whereas the other models show slight offsets. We argue that this discrepancy is likely driven by unresolved thermal structures for HI and MgII, and insufficient metals for CIV and OVI, arising from missing physics such as AGNs or cosmic rays.",
      "authors": [
        "Maxime Rey",
        "Jérémy Blaizot",
        "Taysun Kimm",
        "Joakim Rosdahl",
        "Léo Michel-Dansac",
        "Valentin Mauerhofer"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-13 19:00:07+00:00",
      "link": "https://arxiv.org/pdf/2602.13394v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13385v1",
      "title": "Modeling Globular Cluster Stellar Streams with a Basis-Expansion N-body Code",
      "abstract": "Globular cluster stellar streams probe galaxy-formation processes and can potentially reveal the distribution of dark matter in galaxies. In many theoretical studies, streams are modeled with particle-spray or direct N-body codes. But particle-spray methods abstract away the internal dynamics of the progenitor by making strong assumptions about the escape physics, while direct N-body is prohibitively expensive for realistic (N>10^5) systems. In this paper, we present the stream-modeling capabilities of KRIOS, a new basis-expansion N-body code for collisional stellar dynamics, that bridges this runtime vs. accuracy gap. We show that KRIOS reproduces NBODY6++GPU cluster models, and their associated streams, more accurately than particle spray in a fraction of the NBODY6++GPU wall-clock time. We then compare KRIOS to various particle-spray methods on 10 orbits similar to known Milky Way streams. The morphology and kinematics of these streams most disagree when the progenitor is tightly bound to the host, as these systems are often subject to stronger tidal forces. Finally, we discuss which elements of the progenitor physics are most important for modeling stellar streams and how these might be incorporated into particle-spray methods.",
      "authors": [
        "Brian T. Cook",
        "Kerwann Tep",
        "Carl L. Rodriguez",
        "Leah English",
        "Tjitske Starkenburg",
        "Robyn Sanderson",
        "Newlin C. Weatherford",
        "Sarah Pearson",
        "Nondh Panithanpaisal"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA",
        "astro-ph.IM"
      ],
      "published": "2026-02-13 19:00:00+00:00",
      "link": "https://arxiv.org/pdf/2602.13385v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13137v1",
      "title": "Presaging Doppler beaming discoveries of double white dwarfs during the Rubin LSST era",
      "abstract": "Double white dwarfs (DWDs) are by far the most common compact binaries in the Milky Way, are important low-frequency gravitational-wave sources, and in some cases merge to become Type Ia supernovae. So far, no DWD has been identified solely through relativistic Doppler beaming, even though the beaming amplitude directly relates to the radial velocity semi-amplitude. In this work, we initiate a comprehensive binary population synthesis using SeBa and incorporate the resulting binaries into a tripartite Galaxy model. Our proof-of-concept simulations demonstrate that the Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST) can reliably recover relatively bright ($r \\lesssim20~$mag) unequal-mass binaries in compact orbits with P $\\approx$ 10-600 minutes with moderate to high inclinations. We find that LSST can detect at least 287 short-period DWDs, of which 47 are LISA-detectable gravitational wave sources. LSST lightcurves allow us to readily determine the period and fully characterize the orbit, in contrast with the challenges of orbit determination for DWDs in spectroscopic searches. The formation of unequal mass, short-period DWDs strongly depends on the assumptions regarding the mass-transfer phases during binary population synthesis, and the total number and characteristics of Doppler-beamed DWD systems observed in LSST will provide new tests of models of stellar binary evolution. Here, we lay the foundation for the comprehensive integration of synthetic Galactic binary population into realistic LSST survey simulations, thereby enabling quantitative forecasts of the number and characteristics of any binary sub-population during the LSST era.",
      "authors": [
        "Gautham Adamane Pallathadka",
        "Yossef Zenati",
        "Nadia L. Zakamska",
        "Ngan H. Nguyen",
        "Anthony L. Piro"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA",
        "astro-ph.HE"
      ],
      "published": "2026-02-13 17:43:25+00:00",
      "link": "https://arxiv.org/pdf/2602.13137v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13125v1",
      "title": "TIC65910228b: A single-transit discovery of a massive long-period warm Jupiter with TESS",
      "abstract": "Context. Warm Jupiters are excellent case studies for the investigation of giant planet internal structures and formation theories. However, the sample of long-period transiting giants is still small today for a better understanding of this population. Aims. Starting from a single transit found in the Transiting Exoplanet Survey Satellite (TESS) data, we confirm the planetary nature of the signal and measure its orbital parameters, mass, and radius. We put this system in the context of long-period giant transiting planets and analyzed the viability to sustain atmospheric or dynamical follow-up. Methods. We carried out a spectroscopic follow-up using FEROS and PLATOSpec to obtain precise radial velocities. We added a photometric follow-up with HATPI and Observatoire Moana to obtain a more precise estimate of the orbital period. We derived the orbital and physical parameters through a joint analysis of this data. Results. We report the discovery and characterization of TIC65910228b, a transiting warm Jupiter with a mass of $4.554 \\pm 0.255$ $M_J$ and a radius of $1.088 \\pm 0.061$ $R_J$, orbiting an evolved F-type star every $\\sim 180.52$ days in an eccentric orbit ($e = 0.25 \\pm 0.04$). Conclusions. This planet joins a still under-explored population of long-period ($P > 100$) massive ($M_p > 4$ $M_J$) transiting giant planets, being one of the few with a mild eccentricity. This target is a nice example of the potential of single-transit events to populate this region of the parameter space.",
      "authors": [
        "Felipe I. Rojas",
        "Rafael Brahm",
        "Matías I. Jones",
        "Márcio Catelan",
        "Jozef Liptak",
        "Lorena Acuña",
        "Jan Eberhardt",
        "Néstor Espinoza",
        "Thomas Henning",
        "Andrés Jordán",
        "Yared Reinarz",
        "Marcelo Tala Pinto",
        "Trifon Trifonov",
        "Michaela Vítková",
        "Luca Antonucci",
        "Gaspar Bakos",
        "Attila Bódi",
        "Gavin Boyle",
        "Zoltán Csubry",
        "Joel Hartman",
        "Jan Janík",
        "Petr Kabáth",
        "Anthony Keyes",
        "Markus Roth",
        "Petr Škoda",
        "Alton Spencer",
        "Vincent Suc",
        "Geert Jan Talens",
        "Jan Vaclavik",
        "Leonardo Vanzi"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP"
      ],
      "published": "2026-02-13 17:24:33+00:00",
      "link": "https://arxiv.org/pdf/2602.13125v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12995v1",
      "title": "Statements of Current States of the Art for Key non-Coronagraphic Technologies for HWO",
      "abstract": "In preparation for development of both key technologies and instrument concept studies to use those technologies, the Habitable Worlds Observatory Technology Maturation Project Office at the NASA Goddard Space Flight Center has compiled a series of statements of state of the art for those same key technologies. These statements are being provided to the public as exemplars and suggestions for possible future collaboration for those same instrument concept studies, but without mandate, to enable proposing teams to be able to find the technical solutions they need to field a compelling proposal. This information resides in the public domain and is presented without prejudice.",
      "authors": [
        "Paul Scowen",
        "Manuel Quijada",
        "Emily Kan",
        "Michael Hoenk",
        "Prabal Saxena",
        "Oswald Siegmund",
        "Alexander Kutyrev",
        "Massimo Roberto",
        "Randy McEntaffer",
        "Juan Larruquert"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-02-13 15:06:06+00:00",
      "link": "https://arxiv.org/pdf/2602.12995v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12977v2",
      "title": "TIC-65910228 b / NGTS-38 b, a 180 day transiting warm super-Jupiter",
      "abstract": "We present the discovery of TIC-65910228 b / NGTS-38 b, a giant exoplanet with a radius of $1.081\\pm0.047$ R$_\\text{J}$ and a mass of $4.78_{-0.37}^{+0.40}$ M$_\\text{J}$ on a long-period ($180.52791\\pm0.00038$ day), moderately eccentric ($e=0.308\\pm0.011$) orbit transiting a bright (V=$10.230\\pm0.020$ mag) metal rich ([Fe/H]=$0.33\\pm0.09$, 'dex') F6V-F7V type host star. The planet was initially detected from a single transit in TESS Sector 33. A photometric monitoring campaign of 228 nights with NGTS detected a transit egress of the planet, which together with spectroscopic radial velocity monitoring with CORALIE and HARPS identified an orbital period of ~180.5,d. These radial velocity measurements also showed the mass of the companion to be planetary. Additional transit observations coordinated by the TESS follow-up observing program allowed further confirmation and refinement of this period. With its relatively cool equilibrium temperature of $458\\pm11$ K, NGTS-38 b joins a small but growing population of well characterised transiting warm-Jupiters and has one of the longest periods of any discovered to date. The target is situated in the LOPS2 field of the upcoming PLATO mission which will allow for greater refinement of the system parameters and potential for the discovery of additional companions too small and/or too long-period to be seen by TESS or NGTS. NGTS-38 b's bright host star and wide orbital separation make it an attractive target for further study, including potential measurement of its spin-orbit alignment or targeted exomoon/ring searches.",
      "authors": [
        "Toby Rodel",
        "Solène Ulmer-Moll",
        "Samuel Gill",
        "Christopher. A. Watson",
        "Yoshi Nike Emilia Eschen",
        "Alix V. Freckelton",
        "Annelies Mortier",
        "Karen A. Collins",
        "Diana Dragomir",
        "Zahra Essack",
        "Brett Skinner",
        "Niamh Mallaghan",
        "Peter J. Wheatley",
        "David R. Anderson",
        "Ioannis Apergis",
        "Khalid Barkaoui",
        "Matthew P. Battley",
        "Daniel Bayliss",
        "François Bouchy",
        "Edward M. Bryant",
        "Matthew R. Burleigh",
        "Benjamin M. J. Cadell",
        "Samuel J. Carlier",
        "Yann Carteret",
        "Sarah L. Casewell",
        "Alastair B. Claringbold",
        "Jean C. Costes",
        "Benjamin D. R. Davies",
        "Lauren Doyle",
        "Phil Evans",
        "Jorge Fernández Fernández",
        "Emile Fontanet",
        "Edward Gillen",
        "Michael R. Goad",
        "George Harvey",
        "Faith Hawthorn",
        "Katlyn L. Hobbs",
        "Melissa Hobson",
        "Giovanni Isopi",
        "James S. Jenkins",
        "Alicia Kendall",
        "David Kipping",
        "Monika Lendl",
        "Franco Mallia",
        "Christopher Mann",
        "James McCormac",
        "Ernst J. W. de Mooij",
        "Maximiliano Moyano",
        "Arianna Nigioni",
        "Mohammad Odeh",
        "Vera Maria Passegger",
        "Suman Saha",
        "Richard P. Schwarz",
        "Amber Sedgley",
        "Avi Shporer",
        "Abderahmane Soubkiou",
        "Stéphane Udry",
        "Dimitri Veras",
        "Jean. P. Vignes",
        "Steven Villanueva",
        "José I. Vinés",
        "Richard West",
        "Thomas G. Wilson",
        "Hannah L. Worters",
        "Mitchell E. Young",
        "Aldo Zapparata"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP"
      ],
      "published": "2026-02-13 14:55:59+00:00",
      "link": "https://arxiv.org/pdf/2602.12977v2",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12948v1",
      "title": "A nearby He-rich superluminous supernova at photospheric phases",
      "abstract": "Aim. We present and interpret the data of the nearby hydrogen-deficient but helium-rich superluminous supernova SN~2021bnw which reached a magnitude of -20.7 at maximum luminosity in g band. Methods. We discuss the light curves and spectra of SN 2021bnw based on its spectro-photometric follow up exploiting different observational facilities. We reproduce the NIR spectrum of SN 2021bnw with TARDIS to inspect the chemical composition at late photospheric phases and identify helium features. We also use a STELLA model coupling hydrodynamics and radiation transport to constrain the physical parameters of the explosion assmunig a 56Ni+CSM scenario. Results. We suggest that SN 2021bnw was mainly powered by the interaction of the ejecta with a previously lost He-rich circumstellar material, coupled with a central power source. Conclusions. This work expands the data sample of He-rich superluminous supernovae rich (SLSNe Ib) and, assuming a single progenitor scenario, can constrain the masses and the physics of their progenitors.",
      "authors": [
        "A. Fiore",
        "A. Kozyreva",
        "L. Yan",
        "S. Benetti",
        "J. P. Anderson",
        "P. Baklanov",
        "Y. -Z. Cai",
        "E. Cappellaro",
        "T. -W. Chen",
        "N. Elias-Rosa",
        "A. Gal-Yam",
        "M. J. Graham",
        "M. Gromadzki",
        "S. L. Groom",
        "C. P. Gutiérrez",
        "D. Hiramatsu",
        "D. A. Howell",
        "C. Inserra",
        "M. M. Kasliwal",
        "R. Könyves-Tóth",
        "P. Lundqvist",
        "C. McCully",
        "A. Mironov",
        "S. Moran",
        "T. E. Müller-Bravo",
        "M. Newsome",
        "M. Nicholl",
        "P. Ochner",
        "E. Padilla Gonzalez",
        "A. Pastorello",
        "P. J. Pessi",
        "G. Pignata",
        "F. Ragosta",
        "A. Reguitti",
        "T. M. Reynolds",
        "R. L. Riddle",
        "B. Rusholme",
        "I. Salmaso",
        "S. Schulze",
        "J. Sollerman",
        "L. Tomasella",
        "D. Warshofsky",
        "S. Yang",
        "D. R. Young"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.SR"
      ],
      "published": "2026-02-13 14:14:35+00:00",
      "link": "https://arxiv.org/pdf/2602.12948v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12929v2",
      "title": "STEP survey: III. STEPping stones between the clouds: the star formation history of the Magellanic Bridge",
      "abstract": "The Magellanic Clouds (MCs) offer a unique laboratory for studying galaxy interaction and the evolution of dwarf galaxies. By investigating when and how stars formed, the star formation history (SFH) is a powerful tool to provide constraints for dynamical modeling of the system's past interactions and understand the processes of stripping and triggered star formation in tidally influenced environments. We aim to reconstruct the SFH of the Magellanic Bridge, the gaseous and stellar stream connecting the two Clouds. We used data from the deep optical STEP survey, which covers 54 $\\mathrm{deg\\, {^{2}}}$ across the Small Magellanic Cloud (SMC) and the Bridge, reaching stars below the oldest main sequence turnoff at the distance of the MCs. We applied the synthetic color-magnitude diagram (CMD) technique to 14 deg$^2$ of STEP data. We constructed two libraries of synthetic stellar populations based on the PARSEC-COLIBRI and BaSTI stellar evolutionary models, with metallicities in the range $-2.0\\leq[$Fe/H$]\\leq0$ across the whole Hubble time. We find a clear peak of recent star formation $\\sim100$ Myr ago in the Magellanic Bridge, which becomes increasingly pronounced toward the SMC. The low metallicity of this population suggests that it formed from gas stripped from the SMC during its most recent close encounter with the LMC. In the eastern part of the Bridge (LMC side), the star formation peaks at earlier times, around 10 Gyr and 2 Gyr ago. We estimate a total stellar mass in the Bridge of $ (5.1 \\pm 0.2) \\times 10^5 M_\\odot$ and a present-day stellar metallicity of $[$Fe/H$]\\sim-0.6$ dex, close to SMC value.",
      "authors": [
        "F. Ficara",
        "V. Ripepi",
        "M. Cignoni",
        "M. Gatto",
        "M. Marconi",
        "M. Tosi",
        "M. Bellazzini",
        "E. K. Grebel",
        "M. R. Cioni",
        "C. Tortora",
        "A. Mercurio"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA",
        "astro-ph.SR"
      ],
      "published": "2026-02-13 13:39:47+00:00",
      "link": "https://arxiv.org/pdf/2602.12929v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12907v1",
      "title": "Observations of Binary Stars with the 1.3-m Devasthal Fast Optical Telescope Using Speckle Interferometry: An Attempt",
      "abstract": "We present a feasibility study exploring the implementation of optical interferometry and speckle techniques with the 1.3-m Devasthal Fast Optical Telescope (DFOT) at ARIES, which is currently dedicated to photometric observations. Using the sCMOS camera as the DFOT backend, we perform interferometric speckle observations of several binary stars. Standard Speckle Interferometry (SI) algorithms are applied to analyze the recorded data. While this study does not aim to achieve the diffraction limit of DFOT or address a full science-driven resolution case, it serves as a crucial testbed for instrumentation, data acquisition, and analysis of Speckles with DFOT. Notably, we successfully identify and correct tracking-related positional errors in the observed binary systems, demonstrating the viability of the approach. These results provide strong motivation for more systematic observations and future implementation of optical interferometry techniques at meter-class telescopes.",
      "authors": [
        "Km Nitu Rai",
        "Arjun Dawn",
        "Neelam Panwar",
        "Jeewan C Pandey",
        "Subrata Sarangi",
        "Prasenjit Saha"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-02-13 13:06:55+00:00",
      "link": "https://arxiv.org/pdf/2602.12907v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12870v1",
      "title": "GAME: Genetic Algorithms with Marginalised Ensembles for model-independent reconstruction of cosmological quantities",
      "abstract": "Genetic Algorithms (GA) are a powerful tool for stochastic optimisation and non-parametric symbolic regression, already widely used in cosmology. They are capable of reconstructing analytical functions directly from data points without introducing new physical models. A limitation of this approach is that while the reconstructed function is very efficient at reproducing the behaviour of the data points, non-observable quantities involving derivatives are particularly sensitive to stochasticity, hyperparameters, and to the choice of the best-fit function obtained by the GA, which implies the risk of the algorithm getting stuck in a local minimum. In this work we propose an update to the GA methodology for the reconstruction of analytical functions that involves computing a weighted average of an ensemble of GA configurations (\\texttt{GAME}). We define the weights via a quantity that accounts for both the goodness-of-fit of the points and the smoothness of the resulting function. We also present a practical method to analytically estimate and correct the errors on the averaged function by combining a path-integral approach with an ensemble variance. We demonstrate the improvement offered by \\texttt{GAME} methodology on a generic test function. We then apply the new methodology to a non-parametric reconstruction of the Hubble rate $H(z)$ using Cosmic Chronometers data and, assuming a flat Friedmann-Lemaître-Robertson-Walker background and General Relativity, we infer the corresponding dark energy equation of state $w(z)$. Through consistency tests, we show that current data produces results compatible with $Λ$CDM, and that Stage IV cosmology surveys will allow GA reinforced with \\texttt{GAME} methodology to become an even more competitive tool for discriminating between different models.",
      "authors": [
        "Matteo Peronaci",
        "Matteo Martinelli",
        "Savvas Nesseris"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-13 12:20:46+00:00",
      "link": "https://arxiv.org/pdf/2602.12870v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12864v1",
      "title": "BSN-VI: Multiband Light Curve Modeling of Four W UMa-Type Contact Binaries I. Revisiting Energy Transfer Mechanisms and Luminosity Behavior",
      "abstract": "We presented the first high-precision, detailed photometric analysis of four W Ursae Majoris (W UMa)-type contact binaries, Linear 10772300, Linear 11150338, Linear 20372537 and DM Cir. In addition to ground-based multiband photometric observations, data from the Transiting Exoplanet Survey Satellite (TESS) were employed for the analysis of the DM Cir system. New ephemeris and linear fit to the O-C diagrams were derived using extracted times of minima and additional literature. The light curve modeling was performed using the PHysics Of Eclipsing BinariEs (PHOEBE) Python code and the BSN application, employing a Markov Chain Monte Carlo approach. In each systems, the two stellar components exhibited minimal temperature differences ($ΔT<150$ K), confirming efficient energy exchange within their common convective envelopes. Absolute parameters were estimated using the Gaia Data Release 3 (Gaia DR3) parallax and astrophysical equations. Based on effective temperatures and component masses, two systems were classified as W-subtype systems, while others belonged to the A-subtype. We computed the initial masses of the primary ($M_{1i}$) and secondary ($M_{2i}$) components for four target systems using a method based on the observational properties of overluminous secondary components. We found initial primary masses in the range 0.6-1.0$M_\\odot$ and initial secondary masses in the range 0.9-1.7$M_\\odot$ with mass loss $<1.0M_{\\odot}$. We investigated the relative energy transfer rates ($U_{1}$ and $U_{2}$) and nuclear luminosities ($L_{10}$ and $L_{20}$) based on the physical parameters of 411 W UMa-type contact binaries, including the four systems analyzed in this study, through wide range of mass ratios. The results for all systems provided a comprehensive view of energy transfer behavior throughout different evolutionary stages of contact binaries.",
      "authors": [
        "Elham Sarvari",
        "Atila Poro",
        "Raul Michel",
        "Anna Francesca Pala",
        "Mehmet Tanriver",
        "Ahmet Bulut",
        "Ahmet Keskin",
        "Mark G. Blackford"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR"
      ],
      "published": "2026-02-13 12:15:42+00:00",
      "link": "https://arxiv.org/pdf/2602.12864v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12793v1",
      "title": "CHIME/Slow overview and pilot survey: A new backend to search for second-duration radio transients with the CHIME telescope",
      "abstract": "We present an overview of CHIME/Slow, a real-time transient search backend under development to search for second-duration radio transients using the CHIME telescope, and results obtained from a pilot survey carried out using the prototype version of the search pipeline. The prototype CHIME/Slow pipeline was tested on archival data obtained in December 2022, January 2023 and February 2023 with a total on-sky time of 17 days with an instantaneous Field of View (FoV) of $\\sim$13 deg$^2$ . In this pilot survey, we detected nine bursts, one from a new non-repeating source and eight from the known hyperactive repeating source FRB 20220912A. Out of these nine bursts, two bursts from the repeater were not detected by CHIME/FRB, while the non-repeater was detected in the side-lobe of a beam in the CHIME/FRB exhibiting shorter pulse width and narrower bandwidth compared to the CHIME/Slow detection. Here we report properties of the bursts, discuss the sensitivity and completeness of the current version of the CHIME/Slow pipeline, and outline future development to improve its performance. Finally, based on these results, we report the all-sky rate (95% credible region) of radio transients with pulse widths between 16 ms to 5 s, fluence above 5 Jy ms and observing frequency of 600 MHz to be between 184 and 4556 bursts sky$^{-1}$ day$^{-1}$.",
      "authors": [
        "Sujay Mate",
        "Kevin Luke",
        "Yash Bhusare",
        "Arvind Balasubramanian",
        "Ziggy Pleunis",
        "Paul Scholz",
        "Shriharsh P. Tendulkar",
        "Mohit Bhardwaj",
        "Charanjot Brar",
        "Fengqiu Adam Dong",
        "Emmanuel Fonseca",
        "B. M. Gaensler",
        "Jason Hessels",
        "Jeff Huang",
        "Naman Jain",
        "Ronniy C. Joseph",
        "Victoria M. Kaspi",
        "Afrokk Khan",
        "Robert Main",
        "Bradley W. Meyers",
        "Nikola Milutinovic",
        "Kenzie Nimmo",
        "Kaitlyn Shin",
        "David Spear",
        "Ingrid Stairs",
        "Chia Min Tan"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.HE"
      ],
      "published": "2026-02-13 10:21:53+00:00",
      "link": "https://arxiv.org/pdf/2602.12793v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12717v1",
      "title": "ESO White Paper on Intensity Interferometry: Cosmology, Fundamental Physics, Quantum Optics",
      "abstract": "In this whitepaper, we outline how recent technological advances and ongoing developments open qualitatively new science opportunities in cosmology, fundamental physics, and quantum astrophysics. First, intensity interferometry can contribute to one of the most foundational observables in cosmology: the expansion rate of the Universe. Its angular resolution allows it to resolve the angular extent of extragalactic objects such as supernovae or quasars; combined with a physical scale local to the source, this yields an angular diameter distance and hence a 'Hubble diagram'. Second, the nature of dark matter can be probed via the astrometric lensing signatures of tiny dark matter halos. Third, intensity interferometry gives direct access to second-order coherence properties of astrophysical emission, opening a window onto genuinely quantum aspects of astrophysical light.",
      "authors": [
        "Robin Kaiser",
        "William Guerin",
        "Farrokh Vakili",
        "Jean-Philippe Berger",
        "Andrei Nomerotski",
        "Sergei Kulkov",
        "Peter Svihra",
        "Eva Santos",
        "Colin Carlile",
        "Dainis Dravins",
        "Stefan Funk",
        "Prasenjit Saha",
        "Roland Walter",
        "Marcelo Borges Fernandes",
        "Alex G. Kim",
        "David Dunsky",
        "Ken Van Tilburg",
        "Masha Baryakhtar",
        "Marios Galanis",
        "Robert V. Wagoner",
        "Neal Dalal",
        "Junwu Huang",
        "Charles Gammie",
        "Norman W. Murray"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-02-13 08:45:03+00:00",
      "link": "https://arxiv.org/pdf/2602.12717v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12677v1",
      "title": "Murriyang cryogenic phased array feed: spectral-line results and noise-reduction methods",
      "abstract": "Spectral-line results from a new cryogenic phased array feed (cryoPAF) on the Murriyang telescope at Parkes are presented. This array offers a significant improvement in field of view, aperture efficiency, bandwidth, chromaticity and survey speed compared with conventional horn-fed receivers. We demonstrate this with measurements of sky calibrators and observations of 21-cm neutral hydrogen (HI) in the LMC and the nearby galaxy NGC 6744. Within 0.3 deg of the optical axis, the ratio of system temperature to dish aperture efficiency is 25 K and the ratio with beam efficiency is 21 K (at 1.4 GHz). For the previously measured $T_{sys} = 17$ K, respective efficiency values 0.7 and 0.8 are derived. Our HI observational results are in good agreement with previous results, although detailed comparison with multibeam observations of the LMC suggests that the earlier observations may have missed an extended component of low-column-density gas ($8\\times 10^{18}$ cm$^{-2}$). We use the cryoPAF zoom-band and wideband data to make a preliminary investigation of whether the large number of simultaneous beams (72) permits the use of novel data reduction methods to reduce the effects of foreground/background continuum contamination and RFI. We also investigate if these methods can better protect against signal loss for the detection of faint, extended cosmological signals such as HI intensity maps. Using robust higher-order singular value decomposition (SVD) techniques, we find encouraging results for the detection of both compact and extended sources, including challenging conditions with high RFI occupancy and significant sky continuum structure. Examples are shown that demonstrate that 3D SVD techniques offer a significant improvement in noise reduction and signal capture compared with more traditional layered 2D techniques.",
      "authors": [
        "L. Staveley-Smith",
        "S. Barker",
        "R. Berangi",
        "A. B. Bolin",
        "S. Broadhurst",
        "J. D. Bunton",
        "N. Carter",
        "S. Castillo",
        "W. Chandler",
        "A. Chippendale",
        "J. R. Dawson",
        "F. Di Dio",
        "A. R. Dunning",
        "S. Gordon",
        "J. A. Green",
        "A. Hafner",
        "D. B. Hayman",
        "D. Humphrey",
        "A. Jameson",
        "S. Johnston",
        "J. F. Kaczmarek",
        "J. Ma",
        "G. Perry",
        "M. Pilawa",
        "J. Rhee",
        "L. Toomey",
        "J. van Aardt",
        "N. Wang"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO"
      ],
      "published": "2026-02-13 07:18:39+00:00",
      "link": "https://arxiv.org/pdf/2602.12677v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12560v1",
      "title": "Graph Neural Network Prediction of Infrared Spectra of Interstellar Polycyclic Aromatic Hydrocarbons",
      "abstract": "Polycyclic aromatic hydrocarbons (PAHs) are recognized as the primary contributors to the aromatic infrared bands (AIBs) widely observed in space. However, analyzing these AIBs remains challenging because of the immense structural diversity within the PAH family, which makes the computation of reliable reference spectra difficult. To address this, we developed an efficient graph neural network (GNN) framework that can predict PAH absorption spectra up to 10,000 times faster than traditional quantum chemical methods. We evaluated four representative GNN architectures, including graph convolutional network (GCN), graph attention network (GAT), message passing neural network (MPNN), and attentive fingerprint (AFP). The AFP model is found to deliver the best overall performance and is further trained using five different spectral distance metrics as loss functions, among which the Jensen-Shannon divergence yields the most accurate and stable results. The model performs best for PAHs containing 20-40 carbon atoms, while accuracy decreases for larger molecules, reflecting the limited availability of training data. Overall, this framework offers a fast method to generate approximate reference spectra for small- to medium-sized PAHs, supporting future AIB analysis.",
      "authors": [
        "Guoqing Tang",
        "Jiang He",
        "Zhao Wang",
        "Dong Qiu"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA",
        "astro-ph.IM",
        "astro-ph.SR"
      ],
      "published": "2026-02-13 03:17:38+00:00",
      "link": "https://arxiv.org/pdf/2602.12560v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12554v1",
      "title": "Bundle adjustment of Hayabusa2's ONC images and controlled color mosaic map of Ryugu",
      "abstract": "JAXA's Hayabusa2 mission successfully returned samples from the asteroid Ryugu in December 2020. It executed two touchdowns to collect the surface and subsurface materials, one close to the crater created by an artificial impactor. The onboard camera system, Optical Navigation Camera (ONC), with two wide-angle cameras and one narrow-angle camera with seven color filters, was crucial for mapping geomorphology and composition such as hydrated minerals during navigation and scientific observation. More than 8,300 images revealed Ryugu's spinning-top shape and boulder-covered surface. However, most high-resolution images captured during descent/touchdown operations lacked precise location data and camera position/orientation information. Image geometry was refined using photogrammetric bundle adjustment. This method enabled the refinement of all high-resolution images captured during descent/touchdown operations. Furthermore, map-projected GeoTIFF images in GIS format containing geographic metadata were created for all ONC images, and these were integrated to construct global and regional mosaic maps. To facilitate scientific research on Ryugu, these refined image geometry information, maps, and mosaics are publicly available via https://doi.org/10.7910/DVN/WW3IH0",
      "authors": [
        "Naoyuki Hirata",
        "Eri Tatsumi",
        "Mayumi Ichikawa",
        "Kazuhiro Honda",
        "Sayuri Tanaka"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP",
        "astro-ph.IM"
      ],
      "published": "2026-02-13 03:03:11+00:00",
      "link": "https://arxiv.org/pdf/2602.12554v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.15057v1",
      "title": "A New Plotly-Dash-based Query Infrastructure for the Keck Observatory Archive",
      "abstract": "The Keck Observatory Archive (KOA) curates all observational data acquired at the W. M. Keck Observatory. The archive is expected to grow rapidly as complex new instruments are commissioned and as the expectations of archive users have expanded. In response, KOA has implemented a new Python-based, VO-compliant query infrastructure. This work is a continuation of the architectural design and technology selection identified at ADASS 2024. We have deployed real-time ingestion of newly acquired data and a dedicated interface for observers to manage these data. Our ADASS 2024 poster identified the new technologies chosen: Plotly-Dash, a low-code framework that exploits event-driven callbacks to simplify the handling of user interactions; R-tree spatial indexing to speed up spatial searches by x20; a VO-compliant TAP middleware, already in use at the NASA Exoplanet Archive and NEID archive; and mViewer, a visualization engine in the Montage Image Mosaic toolkit that is optimized for astronomy images.   These technologies will underpin new services that can be hosted on web pages or in Jupyter notebooks, and when completed, will replace the current query infrastructure. We have completed two new services now in beta release. The first is the Data Discovery Service, a web-based dashboard that returns spatial and temporal queries of the entire archive in seconds. It supports filtering observations by keywords, previewing results in an interactive data grid, and visualizing images, and it offers data downloads. The second is a Jupyter notebook that performs interactive visualization of Keck observations of protostars in the Rho Oph Dark Cloud and uses data from CDS and IRSA, as well as KOA.",
      "authors": [
        "R. Moseley",
        "G. Bruce Berriman",
        "Christopher R. Gelino",
        "John C. Good",
        "Meca Lynn",
        "Melanie Swain",
        "Toba Oluyide"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-02-12 22:41:07+00:00",
      "link": "https://arxiv.org/pdf/2602.15057v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12364v1",
      "title": "TSSC comet-centered data products from TESS 3I/ATLAS observations",
      "abstract": "3I/ATLAS is the third known interstellar object to pass through our Solar System. NASA's Transiting Exoplanet Survey Satellite (TESS) made dedicated observations of 3I/ATLAS between 15 -- 22 January 2026 (Sector 1751), capturing high-cadence observations at 200s and 20s cadence. We present two High Level Science Products (HLSPs): (1) comet-centered image time series, corrected for background scattered light and stars; and (2) aperture light curves extracted from the corrected images. We created these data products using the official TESS products and they are publicly available at the Mikulski Archive for Space Telescopes (MAST). TESS's high-precision, near-continuous photometry will provide unique insights into the comet's activity following its closest approach to the Sun. The TESS Science Support Center (TSSC) has created these data products to facilitate scientific analyses by the TESS and Solar System communities.",
      "authors": [
        "Jorge Martinez-Palomera",
        "Amy Tuson",
        "TESS Science Support Center"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP",
        "astro-ph.GA",
        "astro-ph.IM"
      ],
      "published": "2026-02-12 19:48:41+00:00",
      "link": "https://arxiv.org/pdf/2602.12364v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.12358v1",
      "title": "Eye of the beholder: Observer reference frame bias in Hickson-like compact groups of galaxies",
      "abstract": "[Abridged] We investigate how the identification of Hickson-like CGs depends on the observer's reference frame, quantifying how frequently the same system would be recognised from different vantage points. Using a mock lightcone built from the Millennium I Simulation plus a semi-analytic model of galaxy formation, we identified 7709 CGs when applying the standard Hickson-like criteria. For each CG, we placed 1000 random observers on a surrounding sphere and reapplied the velocity and compactness requirements to test recoverability. We also examined the variation of population and local isolation. The velocity concordance criterion shows modest sensitivity to the observer's location: 10% of CGs fail for some observers, typically groups with members with high peculiar velocities (>1000 km/s). The compactness requirement is far more fragile, as 44% of CGs are missed by most observers, and these systems are very elongated or are chance alignments in real space. Tightening selection limits reduces this dependence. Lowering the surface brightness threshold to $μ\\leq 23 \\ mag/arcsec^2$ reduces the compactness dependence to 16%, while reducing the velocity limit to $ΔV\\leq 250 \\ km/s$ lowers velocity-driven failures to less than 4%. Applying both cuts simultaneously yields up to 84% observer-independent groups, although with a substantially smaller sample. Population and isolation are affected by bright interlopers seen from different directions. While such interlopers are common, they have only a minor effect on the compactness and velocity concordance criteria; however, the local isolation is commonly broken. Observer frame effects, dominated by the compactness criterion, can significantly bias Hickson-like CG samples. However, adjusting surface brightness and velocity difference thresholds allows users to balance the physical reliability according to their specific scientific goals.",
      "authors": [
        "A. Zandivarez",
        "E. Diaz-Gimenez",
        "A. R. Callen"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-12 19:35:58+00:00",
      "link": "https://arxiv.org/pdf/2602.12358v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.12355v1",
      "title": "Precursors in tidal disruption events: repeating, fast, and AGN-hosted TDEs",
      "abstract": "Context. Tidal disruption events (TDEs) are rare transients that provide important insights into the physics of galactic nuclei. A recently identified feature in their optical light curves is the presence of early bump-like structures (precursors) that appear before the onset of the main flare or during its rise. Aims. We aim to build and study the first sample of precursor TDEs in order to improve our understanding of these features, which could be key to revealing the origin of the optical emission in TDEs. Methods. We compiled all known precursor TDEs from the literature, searched for additional candidates, and analyzed them as a sample. Results. We find that precursor TDEs predominantly fall within the repeating TDE, fast TDE, and TDE in active galactic nucleus (AGN) subclasses. We reveal a positive correlation between the occurrence time of the precursors relative to the main peak and the central black hole mass. Conclusions. We suggest that the precursors appear due to interactions between the incoming stellar debris and the disk or leftover material from an earlier disruption (repeating and fast TDEs) or a stable pre-existing disk (TDEs in AGNs). Precursors are therefore potentially key signatures of repeating partial TDEs in previously quiescent galaxies.",
      "authors": [
        "Patrik Milán Veres"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.GA"
      ],
      "published": "2026-02-12 19:32:30+00:00",
      "link": "https://arxiv.org/pdf/2602.12355v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12348v1",
      "title": "Excitation and Damping of Oscillation Modes in Gaseous Planets",
      "abstract": "The excitation and damping mechanisms for oscillation modes of gas giant planets are undetermined. We show that differential rotation may greatly enhance convective viscosity in giant planets, resulting in damping times of $t_{\\rm damp} \\sim 10^5-10^6 \\, {\\rm years}$ for f modes and low-order p modes. Radiative diffusion damps p modes on time scales of $t_{\\rm damp} \\sim 10^3-10^7 \\, {\\rm years}$. While the lethargic convective motions cannot effectively excite f mode or p modes, storms driven by condensation of water and/or silicates may play a role. High-order p modes are most effectively excited by cometary/asteroid impacts. Applying these calculations to solar system planets, water storms, rock storms, and impacts may all contribute to exciting the observed f modes amplitudes of Saturn via ring seismology. Similar f mode amplitudes with fractional gravitational perturbations of $δΦ/Φ\\sim 10^{-10}-10^{-9}$ are expected for Jupiter and Uranus, apart from their lowest $\\ell$ f modes which could have larger gravitational perturbations of $δΦ/Φ\\sim 10^{-7}$. Rock storms may contribute to mode driving in Jupiter, while water storms are more important for Uranus. The highest-amplitude p modes are predicted to have periods of $\\sim$10-30 minutes, with surface velocities of $\\sim$10 cm/s for Jupiter and Saturn, and $\\sim$1 cm/s for Uranus. These oscillation modes may be detectable with radial velocity measurements, ring seismology, or spacecraft Doppler tracking. However, both the damping and excitation physics are uncertain by orders of magnitude, so more careful examination of the relevant physics is required for robust estimates.",
      "authors": [
        "Jim Fuller",
        "Marzia Parisi",
        "Steve Markham",
        "A. James Friedson",
        "J. R. Fuentes"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP",
        "astro-ph.SR"
      ],
      "published": "2026-02-12 19:11:46+00:00",
      "link": "https://arxiv.org/pdf/2602.12348v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12343v1",
      "title": "An analytic approximation to the covariance between pre- and post-reconstruction galaxy two-point statistics",
      "abstract": "We present a simple analytic approximation for the covariance between pre-reconstruction galaxy power spectrum measurements and post-reconstruction two-point correlation functions. This cross-covariance is essential for joint analyses that combine full-shape clustering information with baryon acoustic oscillation (BAO) measurements, as commonly performed in modern spectroscopic surveys. Our model builds on the disconnected contribution to the covariance and accounts for the damping of correlations due to the BAO reconstruction process. We validate our analytic prescription against numerical simulations from the Dark Energy Spectroscopic Instrument (DESI), testing both idealized cubic geometries and realistic survey configurations including complex footprints and fiber assignment effects. Despite neglecting survey window functions in the analytic calculation, we find excellent agreement with simulation-based covariances and demonstrate that cosmological parameter constraints are virtually unchanged when using our approximation. Our results show that the pre-post cross-covariance is sufficiently small that even approximate treatments are adequate for cosmological inference, opening a pathway toward fully analytic covariance matrices for next-generation galaxy surveys.",
      "authors": [
        "M. Maus",
        "A. Baleato Lizancos",
        "M. White",
        "A. de Mattia",
        "S. Chen"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-12 19:02:07+00:00",
      "link": "https://arxiv.org/pdf/2602.12343v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12238v1",
      "title": "Status of the $S_8$ Tension: A 2026 Review of Probe Discrepancies",
      "abstract": "The parameter $S_8 \\equiv σ_8 (Ω_m/0.3)^{0.5}$ quantifies the amplitude of matter density fluctuations. A persistent discrepancy exists between early-universe CMB observations and late-universe probes. This review assesses the ``$S_8$ tension'' against a new 2026 baseline: a unified ``Combined CMB'' framework incorporating Planck, ACT DR6, and SPT-3G. This combined analysis yields $S_8 = 0.836^{+0.012}_{-0.013}$, providing a higher central value and reduced uncertainties compared to Planck alone. Compiling measurements from 2019--2026, we reveal a striking bifurcation: DES Year 6 results exhibit a statistically significant tension of $2.4σ$--$2.7σ$ \\citep{DESY6}, whereas KiDS Legacy results demonstrate statistical consistency at $<1σ$ \\citep{Wright2025}. We examine systematic origins of this dichotomy, including photometric redshift calibration, intrinsic alignment modeling, and shear measurement pipelines. We further contextualize these findings with cluster counts (where eROSITA favors high values while SPT favors low), galaxy-galaxy lensing, and redshift-space distortions. The heterogeneous landscape suggests survey-specific systematic effects contribute substantially to observed discrepancies, though new physics beyond $Λ$CDM cannot be excluded.",
      "authors": [
        "Ioannis Pantos",
        "Leandros Perivolaropoulos"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-12 18:17:18+00:00",
      "link": "https://arxiv.org/pdf/2602.12238v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12174v1",
      "title": "Probing baryonic feedback with fast radio bursts: joint analyses with cosmic shear and galaxy clustering",
      "abstract": "Cosmological inference from weak lensing (WL) surveys is increasingly limited by uncertainties in baryonic physics, which suppress the non-linear matter power spectrum on small scales. Multi-probe analyses that incorporate complementary tracers of the gas distribution around haloes offer a pathway to calibrate these effects and recover unbiased cosmological information. In this work, we forecast the constraining power of a joint analysis combining fiducial data from a Stage-IV WL survey with measurements of the dispersion measure from fast radio bursts (FRBs). We evaluate the ability of this approach to simultaneously constrain cosmological parameters and the astrophysical processes governing baryonic feedback, and we quantify the impact of key FRB systematics, including redshift uncertainties and source clustering. We find that, even after accounting for these effects, a 3$\\times$2-point analysis of WL and FRBs significantly improves cosmological constraints, reducing the degradation factor on $S_8$ by $\\sim 80\\%$ compared to WL alone. We further show that FRBs alone are sensitive only to a degenerate combination of the key baryonic parameters, $\\log_{10} M_{\\rm c}$ and $η_{\\rm b}$, and that the inclusion of WL measurements breaks this degeneracy. Finally, we extend our framework to incorporate galaxy clustering measurements using Luminous Red Galaxy and Emission Line Galaxy samples, performing a unified 6$\\times$2-point analysis of WL, dispersion measures of FRBs, and galaxy clustering. While this combined approach tightens constraints on $Ω_{\\rm m}$ and $\\log_{10} M_{\\rm c}$, it does not lead to a significant improvement in $S_8$ constraints beyond those obtained from WL and FRBs alone.",
      "authors": [
        "Amy Wayland",
        "David Alonso",
        "Robert Reischke"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-12 17:06:08+00:00",
      "link": "https://arxiv.org/pdf/2602.12174v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11989v1",
      "title": "Simulation-Based Cosmological Mass Calibration of XXL Galaxy Clusters using HSC Weak Lensing",
      "abstract": "We present a cosmological analysis of the X-ray-selected galaxy cluster sample from the XXL survey, employing a simulation-based inference (SBI) framework to jointly constrain cosmological parameters and X-ray scaling relations through forward modeling of cluster counts, X-ray observables, and weak-lensing measurements. Our analysis combines X-ray data from the XMM-XXL survey with shear measurements from the three-year shape catalog of the Hyper Suprime-Cam Subaru Strategic Program. The analysis focuses on the XXL C1 sample, comprising 171 clusters for abundance modeling, a subset of 86 clusters located within the XXL-N region for lensing-based mass calibration, and 162 clusters with X-ray temperature and luminosity measurements used to constrain scaling relations. Using the density-estimation likelihood-free inference (DELFI) algorithm, we construct a forward model with 12 parameters that incorporates the XXL selection function and cluster population modeling and accounts for key systematic effects including cluster miscentering, photometric redshift bias, and mass-dependent weak-lensing bias. Our SBI analysis yields a constraint on the cosmological parameter $S_8 \\equiv σ_8 (Ω_{m}/0.3)^{0.5} = 0.867 \\pm 0.063$, with an additional 3% systematic uncertainty from neural network stochasticity. The result is consistent with Planck and recent cluster-based measurements. The inferred temperature-mass relation is consistent with self-similar expectations within uncertainties, whereas the luminosity-temperature relation exhibits a slope steeper than the self-similar prediction. From the resulting posterior distribution of the forward model, we derive lensing-calibrated mass estimates for all individual XXL clusters with measured X-ray temperatures or luminosities. These results provide a self-consistent mass calibration for future multi-probe cosmological analyses of the XXL sample.",
      "authors": [
        "Sut-Ieng Tam",
        "Keiichi Umetsu",
        "Adam Amara",
        "Dominique Eckert",
        "Manon Regamey",
        "Nicolas Cerardi",
        "I-Non Chiu",
        "Mauro Sereno",
        "Florian Pacaud",
        "Sunayana Bhargava",
        "Christian Garrel",
        "Fabio Gastaldello",
        "Elias Koulouridis",
        "Ben Maughan",
        "Rogerio Monteiro-Oliveira",
        "Marguerite Pierre"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-12 14:18:00+00:00",
      "link": "https://arxiv.org/pdf/2602.11989v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11864v1",
      "title": "Selecting Optimal Stellar Calibration Fields for the CSST Imaging Survey",
      "abstract": "The Chinese Space Station Survey Telescope (CSST) will perform a decade-long high-precision wide-field imaging survey that relies on rigorous on-orbit calibration. This necessitates stable celestial benchmark fields to maintain photometric and astrometric consistency throughout the mission lifetime. We establish comprehensive selection criteria including observational visibility, stellar number density, bright-star contamination, and interstellar dust extinction. Using the CSST Observation Strategy Analysis Tool (COSAT) and all-sky dust maps from Planck and SFD, we constrain eligible regions to the ranges of ecliptic latitude $ |β| > 50^\\circ$ and galactic latitude $|b| > 15^\\circ$. From an initial sample of 29 candidate clusters meeting these spatial constraints, six globular clusters (M13, M92, NGC 104, NGC 362, NGC 1261, and NGC 1851) are identified as optimal calibration fields, fulfilling all the critical criteria. These selected clusters are recommended as optimal calibration field candidates for CSST's on-orbit calibration program, and are fundamental to achieving unprecedented photometric precision in CSST's space-based survey.",
      "authors": [
        "Chenxiaoji Ling",
        "Juanjuan Ren",
        "Li Shao",
        "Zhimin Zhou",
        "Peng Wei",
        "Youhua Xu",
        "Jinyu Hu",
        "Xin Zhang",
        "Su Yao",
        "Hu Zhan",
        "Chao Liu"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA",
        "astro-ph.IM"
      ],
      "published": "2026-02-12 12:09:58+00:00",
      "link": "https://arxiv.org/pdf/2602.11864v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12307v1",
      "title": "GAMERA-OP: A three-dimensional finite-volume MHD solver for orthogonal curvilinear geometries",
      "abstract": "We present GAMERA-OP (Orthogonal-Plus), a three-dimensional finite-volume magnetohydrodynamics (MHD) solver for orthogonal curvilinear geometries. The solver advances magnetic fields using constrained transport to preserve $\\nabla\\!\\cdot\\!\\mathbf{B}=0$ to machine precision and employs geometry-consistent high-order reconstruction with an enhanced Partial Donor Cell method (e-PDM) that accounts for geometry curvature. Flexible numerics include various numerical fluxes and time integrators. In axial symmetric coordinates, angular momentum are preserved to round-off, and a ring-averaging treatment near the axis relaxes CFL constraints while maintaining divergence-free magnetic fields. Optional capabilities include the semi-relativistic (Boris) correction, background-field splitting, and an anisotropic MHD formulation. Rewritten in C, the code adopts a modular design that simplifies case setup and facilitates the addition of physics modules and coupling to other first-principles codes. Standard benchmarks across multiple geometries verify the code's high accuracy, low numerical diffusion, and robust handling of coordinate singularities and rotating flows. GAMERA-OP provides a practical, high-order framework for space and astrophysical plasma applications where orthogonal curvilinear coordinates and exact angular-momentum conservation are advantageous.",
      "authors": [
        "Hongyang Luo",
        "Binzheng Zhang",
        "Jiaxing Tian",
        "Jinshu Cai",
        "Junjie Chen",
        "Enhao Feng",
        "Zhiqi Zheng",
        "Sheng Xi",
        "John G. Lyon"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.EP"
      ],
      "published": "2026-02-12 08:24:53+00:00",
      "link": "https://arxiv.org/pdf/2602.12307v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11617v1",
      "title": "The ALMA-QUARKS Survey: Discovery of Dusty Fibrils inside Massive Star-forming Clumps",
      "abstract": "We report the discovery of more than 323 superfine dusty filamentary structures (fibrils) inside 121 massive star forming clumps that are located in widely different Galactic environments (Galactocentric distances of $\\sim$0.5-12.7 kpc). These fibrils are identified from the 1.3~mm continuum emission in the ALMA-QUARKS survey, which has a linear resolution of $\\sim900$ AU for a source at $\\sim$3 kpc, using the \\textit{FilFinder} software. Using \\textit{RadFil} software, we find that the typical width of these fibrils is $\\sim$0.01 pc, which is about ten times narrower than that of dusty filaments in nearby clouds identified by the \\textit{Herschel} Space Observatory. The mass ($M$) versus length ($L$) relation for these fibrils follows $M\\propto L^{2}$, similar to that of Galactic filaments identified in space (e.g., \\textit{Herschel}) and ground-based single-dish (e.g., \\textit{APEX}) surveys. However, these fibrils are significantly denser ($\\mathrm{N_{H_2} = 10^{23}-10^{24}\\ cm^{-2}}$) than the filaments found in previous \\textit{Herschel} surveys ($\\mathrm{N_{H_2} = 10^{20}-10^{23}\\ cm^{-2}}$). This work contributes a large sample of superfine fibrils in massive clumps, following the identification of large 0.1-pc wide filaments and associated internal velocity coherent fibers in nearby molecular clouds, further emphasizing the crucial role played by filamentary structures in star formation at various physical scales.",
      "authors": [
        "Yan-Kun Zhang",
        "Tie Liu",
        "Wenyu Jiao",
        "Pak-Shing Li",
        "Jia Zeng",
        "Chao Zhang",
        "Pablo García",
        "Mika Juvela",
        "Guido Garay",
        "Amelia M. Stutz",
        "Sami Dib",
        "Dezhao Meng",
        "Jian-Cheng Feng",
        "Dongting Yang",
        "Fengwei Xu",
        "Anandmayee Tej",
        "Enrique Vázquez-Semadeni",
        "Gilberto C. Gómez",
        "Yong Zhang",
        "Xindi Tang",
        "Paul F. Goldsmith",
        "Kee-Tae Kim",
        "James O. Chibueze",
        "Zhiyuan Ren",
        "Patricio Sanhueza",
        "Aiyuan Yang",
        "Jihye Hwang",
        "Shanghuo Li",
        "Tapas Baug",
        "Shivani Gupta",
        "Swagat R. Das",
        "Gang Wu",
        "Jianjun Zhou",
        "Chang Won Lee",
        "Lokesh Dewangan",
        "Prasanta Gorai",
        "Tianning Lyu",
        "Lei Zhu"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA",
        "astro-ph.SR"
      ],
      "published": "2026-02-12 06:12:11+00:00",
      "link": "https://arxiv.org/pdf/2602.11617v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.11356v1",
      "title": "ALMA Band1 observations of the rhoOphW filament I. Enhanced power from excess microwave emission at high spatial frequencies",
      "abstract": "The rhoOphW photo-dissociation region (PDR) is an example source of bright excess microwave emission (EME), over synchrotron, free-free, and the Rayleigh-Jeans tail of the sub-millimetre (sub-mm) dust continuum. Its filamentary morphology follows roughly that of the IR poly-cyclic aromatic hydrocarbon (PAHs) bands. The EME signal in rhoOphW drops abruptly above ~30GHz and its spectrum can be interpreted in terms of electric-dipole radiation from spinning dust grains, or ``spinning dust''. Deep and high-fidelity imaging and spectroscopy of rhoOphW may reveal the detailed morphology of the EME signal, free from imaging priors, while also enabling a search for fine structure in its spectrum. The same observations may constrain the spectral index of the high-frequency drop. An ALMA Band1 mosaic yields a deep deconvolved image of the filament at 36-44GHz, which we use as template for the extraction of a spectrum via cross-correlation in the uv-plane. Simulations and cross-correlations on near-infrared ancillary data yield estimates of flux-loss and biases. The spectrum is a power law, with no detectable fine structure. It follows a spectral index alpha=-0.78+-0.05, in frequency, with some variations along the filament. Interestingly, the Band1 power at high spatial frequencies increases relative to that of the IR signal, with a factor of two more power in Band1 at ~20'' than at ~100'' (relative to IRAC3.6um). An extreme of such radio-only structures is a compact EME source, without IR counterpart. It is embedded in strong and filamentary Band1 signal, while the IRAC maps are smooth in the same region. We provide multi-frequency intensity estimates for spectral modelling.",
      "authors": [
        "Simon Casassus",
        "Matias Vidal",
        "Miguel Carcamo",
        "Laurent Verstraete",
        "Nathalie Ysard",
        "Emilie Habart"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA",
        "astro-ph.SR"
      ],
      "published": "2026-02-11 20:44:07+00:00",
      "link": "https://arxiv.org/pdf/2602.11356v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11261v1",
      "title": "BlastBerries: How Supernovae Affect Lyman Continuum Escape Fractions and Ionizing Photon Production in Local Analogs of High-Redshift Galaxies",
      "abstract": "While compact, star-forming galaxies are believed to play a key role in cosmic reionization, the physical mechanisms enabling the escape of ionizing photons through the galactic interstellar medium remain unclear. Supernova (SN) feedback is one possible mechanism for clearing neutral gas channels to allow the escape of Lyman continuum photons. Here, we use SN discoveries in low-redshift analogs of high-redshift star-forming galaxies -- Green Pea galaxies and their even lower-redshift counterparts, Blueberry (BB) galaxies -- to understand how SNe shape the properties of their host galaxies at high redshifts. We cross-match 1242 BB galaxies with transient discovery reports and identify 11 SNe, ten of which are likely core-collapse SNe, and compare their hosts to the larger BB population. We find that SN-hosting BBs exhibit elevated star formation rates, burstier star formation histories within the last $\\sim$50 Myr, and higher stellar masses. We estimate the occurrence rates of SNe in BB galaxies, finding that the SN rate may be slightly suppressed in BBs compared to field galaxies of similar mass, but we are unable to fully control for observational uncertainties. Finally, SN hosts show bluer UV slopes than non-host BB galaxies at 2.1$σ$ significance and lower ionizing photon production efficiency at 7.9$σ$ significance; the former result offers modest support for the hypothesis that SN-driven feedback plays a role in facilitating the escape of ionizing photons, while the latter may imply that SN-driven quenching decreases the rate of ionizing photon production in compact star-forming galaxies during the epoch of reionization.",
      "authors": [
        "Miranda Y. Kong",
        "David O. Jones",
        "Nicole E. Drakos",
        "Sangeeta Malhotra",
        "Kartheik Iyer",
        "Brian C. Lemaux",
        "Rohan P. Naidu",
        "Thomas de Boer",
        "Ken C. Chambers",
        "John Fairlamb",
        "Willem B. Hoogendam",
        "Mark E. Huber",
        "Chien-Cheng Lin",
        "Thomas Bernard Lowe",
        "Eugene A. Magnier",
        "Paloma Mínguez",
        "Gregory S. H. Paek",
        "Angie Schultz",
        "Richard J. Wainscoat"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA",
        "astro-ph.HE"
      ],
      "published": "2026-02-11 19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2602.11261v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.11094v1",
      "title": "Future Perspectives on Black Hole Jet Mechanisms: Insights from Next-Generation Observatories and Theoretical Developments",
      "abstract": "Black hole jets represent one of the most extreme manifestations of astrophysical processes, linking accretion physics, relativistic magnetohydrodynamics, and large-scale feedback in galaxies and clusters. Despite decades of observational and theoretical work, the mechanisms governing jet launching, collimation, and energy dissipation remain open questions. In this article, we discuss how upcoming facilities such as the Event Horizon Telescope (EHT), the Cherenkov Telescope Array (CTA), the Vera C. Rubin Observatory (LSST), and the Whole Earth Blazar Telescope (WEBT) will provide unprecedented constraints on jet dynamics, variability, and multi-wavelength signatures. Furthermore, we highlight theoretical challenges, including the role of magnetically arrested disks (MADs), plasma microphysics, and general relativistic magnetohydrodynamic (GRMHD) simulations in shaping our understanding of jet formation. By combining high-resolution imaging, time-domain surveys, and advanced simulations, the next decade promises transformative progress in unveiling the physics of black hole jets.",
      "authors": [
        "Andre L. B. Ribeiro",
        "Nathalia M. N. da Rocha"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.IM"
      ],
      "published": "2026-02-11 18:07:01+00:00",
      "link": "https://arxiv.org/pdf/2602.11094v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11068v1",
      "title": "Most Strong Lensing Deflectors in the AGEL Survey are in Group and Cluster Environments",
      "abstract": "The environments of deflectors in strong lensing systems affect our ability to test cosmological models and constrain evolutionary properties of galaxies. Here we measure the deflector scale (Einstein mass) and deflector environment (halo mass) of 89 spectroscopically confirmed strong lenses in the ASTRO3D Galaxy Evolution With Lenses (AGEL) survey. We classify deflector scale by measuring $θ_{\\rm{E}}$ to determine the mass enclosed by the Einstein radius, $M(<θ_{\\rm{E}})$. We quantify deflector environment by using photometric redshifts to determine the galaxy surface density to the fifth-nearest neighbor $Σ_5(z)$. We find that 47.2% of our deflectors are embedded in cluster environments, whereas only 9.0% have cluster-scale Einstein radii (masses). We measure a weak correlation ($r = 0.38$) between Einstein mass and $Σ_5(z)$, suggesting that the assumption of single galaxy-scale deflectors in lens modeling is overly-simplified. We hypothesize that the weak correlation results from galaxy-scale bias in the original AGEL selection and the observational challenge of detecting faint arcs with large Einstein radii. Comparing number densities, $N_{\\rm{gal}}$, between AGEL and control fields, we find that AGEL deflectors are in systematically denser environments. Our study provides a method to identify strong lenses as a function of deflector environment and approximate the impact of large-scale environment in lens modeling. We provide the measured lensing parameters for our 89 AGEL systems as well as $z_{\\rm{phot}}$ and $r$-mag (AB) maps of the line-of-sight.",
      "authors": [
        "William J. Gottemoller",
        "Nandini Sahu",
        "Rodrigo Cordova-Rosado",
        "Leena Iwamoto",
        "Courtney B. Watson",
        "Kim-Vy H. Tran",
        "A. Makai Baker",
        "Tania M. Barone",
        "Duncan J. Bowden",
        "Karl Glazebrook",
        "Anishya Harshan",
        "Tucker Jones",
        "Glenn G. Kacprzak",
        "Camryn M. Neches"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-11 17:36:25+00:00",
      "link": "https://arxiv.org/pdf/2602.11068v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10987v1",
      "title": "Beyond $Λ$CDM: fundamental constants as cosmological observables",
      "abstract": "Recent cosmological tensions pose difficulties for $Λ$CDM. Forthcoming facilities will be able to check whether these tensions result from systematic effects or indeed with the $Λ$CDM model itself. However, these new data will primarily probe gravitational interactions and provide only limited information about non-gravitational interactions. Distinguishing between competing models that make similar predictions yet rely on fundamentally different principles, therefore requires suitably diverse physical tests. Observational constraints on spacetime variations of fundamental constants fill this need. The fine-structure constant, $α= e^2/\\hbar c$, can be measured using absorption systems towards bright quasars using the Many Multiplet method, and using atomic doublets from line emitting gas in galaxies. A spectroscopic facility such as the WST could produce more than 100,000 new measurements of $α$ from quasars together with a million measurements from galaxies. When combined with other probes, such a large and homogeneous dataset of $α$ measurements would provide unprecedented constraints on physics beyond $Λ$CDM.",
      "authors": [
        "Dinko Milaković",
        "John K. Webb"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-11 16:13:51+00:00",
      "link": "https://arxiv.org/pdf/2602.10987v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10895v1",
      "title": "GECAM discovery of the second FRB-associated Magnetar X-ray Burst from SGR J1935+2154",
      "abstract": "Fast radio burst (FRB) is mysterious phenomenon with millisecond-duration radio pulses observed mostly from cosmological distance. The association between FRB 200428 and a magnetar X-ray burst (MXB) from SGR J1935+2154 has significantly advanced the understanding of FRB and magnetar bursts. However, it is uncertain whether this association between MXB and FRB (i.e. MXB/FRB 200428) is genuine or just coincidental only based on this single event. Here we report the discovery of a bright ($\\rm\\sim7.6\\times10^{-7}\\,erg \\cdot cm^{-2}$ in 1-250 keV) magnetar X-ray burst detected by GECAM on October 14th, 2022 (dubbed as MXB 221014) from SGR J1935+2154, which is associated with a FRB detected by CHIME and GBT. We conducted a detailed temporal and spectral analysis of MXB 221014 with GECAM data and find that it is a bright and typical ($T_{90}\\sim$250 ms) X-ray burst from this magnetar. Interestingly, we find two narrow X-ray pulses in the MXB, one of which temporally aligns with the main pulse of the FRB 221014 $\\sim5.70$ ms latter than the peak time of FRB 221014), resembling the feature found in MXB/FRB 200428. Furthermore, we did comprehensive comparison between MXB/FRB 221014 and MXB/FRB 200428, and find that while the two events share several common features, they also exhibit distinct differences, highlighting the variety of the MXB-FRB association morphology. This finding not only confirms the association between MXB and FRB but also provides new insights into the mechanism of and the relationship between FRB and MXB.",
      "authors": [
        "Chen-Wei Wang",
        "Shao-Lin Xiong",
        "Yue Wang",
        "Wen-Jun Tan",
        "Xiao-Bo Li",
        "Dong-Zi Li",
        "Yan-Qiu Zhang",
        "Shu-Xu Yi",
        "Ming-Yu Ge",
        "Sheng-Lun Xie",
        "Wang-Chen Xue",
        "Bing Li",
        "Cheng-Kui Li",
        "Zheng-Hua An",
        "Ce Cai",
        "Pei-Yi Feng",
        "Min Gao",
        "Ke Gong",
        "Dong-Ya Guo",
        "Hao-Xuan Guo",
        "Yue Huang",
        "Jia-Cong Liu",
        "Xin-Qiao Li",
        "Ya-Qing Liu",
        "Xiao-Jing Liu",
        "Xiang Ma",
        "Wen-Xi Peng",
        "Rui Qiao",
        "Yang-Zhao Ren",
        "Li-Ming Song",
        "Xi-Lei Sun",
        "Jin Wang",
        "Jin-Zhou Wang",
        "Ping Wang",
        "Xiang-Yang Wen",
        "Shuo Xiao",
        "Sheng Yang",
        "Qi-Bin Yi",
        "Zheng-Hang Yu",
        "Da-Li Zhang",
        "Fan Zhang",
        "Wen-Long Zhang",
        "Jin-Peng Zhang",
        "Peng Zhang",
        "Shuan-Nan Zhang",
        "Zhen Zhang",
        "Xiao-Yun Zhao",
        "Yi Zhao",
        "Chao Zheng",
        "Shi-Jie Zheng"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE"
      ],
      "published": "2026-02-11 14:25:40+00:00",
      "link": "https://arxiv.org/pdf/2602.10895v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10859v1",
      "title": "The metal-poor tail of the APOGEE survey I. Uncovering [Fe/H] < -2.5 stars from the inner Galaxy to the Magellanic Clouds",
      "abstract": "In the search for metal-poor stars, large spectroscopic surveys are an invaluable tool. However, the spectra of metal-poor stars can be difficult to analyse because of the relative lack of available lines, which can also lead to misclassification. We aim to identify the stars observed by the APOGEE survey that are below the metallicity limit of APOGEE's analysis. For the highest confidence candidates, we classify the orbital properties of the stars to investigate whether their orbital distribution matches what we would expect for stars that are this metal poor and to select especially interesting targets for spectroscopic follow-up purposes. We examined the properties derived by APOGEE for metal-poor stars from the literature to find signatures of stars with a metallicity below the range of the grid used for spectral analysis. The calibrated APOGEE stellar parameters provide a clear signature of the most metal-poor stars in the survey, indicated by null values for their metallicities while having effective temperatures and surface gravities determined by the pipeline. From comparison with the literature, we find that, within a temperature range of 3700 - 6700 K and above a threshold of S/N > 30, the vast majority of APOGEE stars without calibrated metallicities are very metal poor. The radial velocities provided by APOGEE, Gaia DR3 positions and astrometry along with spectrophotometric distances derived in this work allowed for the computation of their orbits. In this work, we select 289 very metal-poor red giant stars (likely below = -2.5) from the APOGEE results. Our sample contains 16 very metal-poor member candidates of the Magellanic Clouds, 14 very metal-poor stars with orbits confined to the inner Galaxy, and 13 inner Galaxy halo interlopers.",
      "authors": [
        "M. Montelius",
        "E. Starkenburg",
        "H. Woudenberg",
        "A. Angrilli Muglia",
        "A. Ardern-Arentsen",
        "A. Viswanathan",
        "A. Byström",
        "A. Helmi",
        "N. Martin",
        "T. Matsuno",
        "C. Navarrete",
        "J. Navarro"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-11 13:46:54+00:00",
      "link": "https://arxiv.org/pdf/2602.10859v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10511v1",
      "title": "A 682-second X-ray Periodicity in CH Cygni: Evidence for a Magnetic White Dwarf",
      "abstract": "Symbiotic stars are interacting binaries consisting of a red giant and typically a white dwarf, important as potential Type Ia supernova progenitors. Despite theoretical predictions that white dwarfs in symbiotic systems should often be magnetic, direct evidence has been elusive. We report the discovery of a $682.5 \\pm 7$ s periodicity in the XMM-Newton X-ray light curve that we interpret as the spin period of the WD in CH Cygni. This detection provides strong evidence for a magnetic white dwarf in CH Cygni, making it only the second WD symbiotic star with confirmed X-ray pulsations after R Aquarii. Our discovery supports the magnetic propeller model previously proposed for CH Cygni's jet activity and state transitions.",
      "authors": [
        "Manuel Pichardo Marcano",
        "Thomas J. Maccarone",
        "Liliana E. Rivera Sandoval"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.SR"
      ],
      "published": "2026-02-11 04:22:21+00:00",
      "link": "https://arxiv.org/pdf/2602.10511v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10325v1",
      "title": "Carbon-Enhanced Metal-Poor Star Candidates in the Milky Way from J-PLUS and S-PLUS",
      "abstract": "Recent large-scale multi-band photometric surveys now enable elemental-abundance estimates for millions of stars with accuracies approaching those of low- to medium-resolution spectroscopy. Using [Fe/H] and [C/Fe] estimates derived from the Javalambre Photometric Local Universe Survey (J-PLUS) DR3 and the Southern Photometric Local Universe Survey (S-PLUS) DR4, which together cover $\\sim$6,200 deg$^2$ of the sky, we identify large numbers of carbon-enhanced metal-poor (CEMP) stars in the Milky Way. After applying data-quality cuts and evolutionary corrections to the carbon-abundance estimates, we construct a combined J/S-PLUS sample of $\\sim$6.40 million stars and identify $\\sim$104,900 CEMP candidates, roughly twice the number of CEMP candidates identified from Gaia XP spectra by Lucey et al. We photometrically confirm that the absolute carbon abundance $A$(C) separates CEMP stars into two primary groups, CEMP-no and CEMP-$s$ stars, consistent with previous spectroscopic studies. We also recover CEMP morphological Groups I-III in the Yoon-Beers diagram, as well as the recently proposed Group IV, and show that it is statistically distinct even in photometric data. A cumulative frequency analysis confirms that the CEMP fraction increases toward lower metallicity and that CEMP-no stars dominate in the most metal-poor regime. By comparing frequencies with and without Group IV stars, we assess their relation to CEMP-no and CEMP-$s$ stars, and examine CEMP distributions across different Galactic components. The resulting catalog provides a substantial sample for future spectroscopic follow-up, in particular to constrain the likely origin(s) of the Group IV stars.",
      "authors": [
        "Jihye Hong",
        "Timothy C. Beers",
        "Yang Huang",
        "Jonathan Cabrera Garcia",
        "Young Sun Lee",
        "Vinicius M. Placco",
        "Evan N. Kirby"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-10 22:02:41+00:00",
      "link": "https://arxiv.org/pdf/2602.10325v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10244v1",
      "title": "The S-PLUS Fornax Project (S+FP): An extragalactic catalog covering $\\sim$ 5 virial radii around NGC 1399 with galaxy properties",
      "abstract": "Observational extragalactic catalogs over wide sky areas are essential for uncovering the large-scale structure of the Universe. They allow, among others, cosmological studies and density analyses that impose strong constraints on models of galaxy formation and evolution. By taking advantage of the wide field images and the 12 optical bands of the Southern Photometric Local Universe Survey (S-PLUS), we aim at providing a catalog of galaxies located, in projection, towards the Fornax galaxy cluster, within $\\sim$ 5 virial radii in right ascension (R.A.) and $\\sim$ 3 virial radius in declination (Dec) around NGC,1399, the dominant galaxy of the cluster. Such a catalog will allow unprecedented large-scale structure studies in that sky region. Supervised deep learning algorithms have been developed, utilizing neural networks complemented with dimensionality reduction techniques, to classify and separate spurious objects, stars and galaxies in a photometric catalog previously built for the S-PLUS Fornax Project (S+FP). That catalog was built using a combination of SExtractor configurations optimized for galaxy detection and characterization. A catalog of 119,580 galaxies was obtained in the direction of the Fornax cluster containing photometric information in the 12 optical bands of S-PLUS complemented with GALEX (UV), VHS-VISTA (NIR) and AllWISE (MIR) data. We estimate photometric redshifts (σ_ NMAD $\\sim$ 0.0219) with a lower limit of z_ lim $\\sim$ 0.03. Stellar masses, star formation rates (SFRs) and D4000_N index estimates were obtained through a machine learning approach, by matching S-PLUS photometric data to SDSS spectroscopic data. The completeness of the catalog (72%) was calculated by comparing with mock catalogs ...",
      "authors": [
        "R. F. Haack",
        "A. V. Smith Castelli",
        "L. Sodré",
        "C. Mendes de Oliveira",
        "A. R. Lopes",
        "L. A. Gutiérrez-Soto",
        "R. Demarco",
        "D. E. Olave-Rojas",
        "E. R. Carrasco",
        "P. K. Humire",
        "J. P. Calderón",
        "F. de Almeida Fernandes",
        "L. Lomelí-Núñez",
        "G. Sepúlveda",
        "C. Lima-Dias",
        "S. Torres Flores",
        "E. Telles",
        "N. M. Cardoso",
        "D. Palma",
        "L. Doubrawa",
        "D. Pallero",
        "M. Marinello",
        "W. Schoenell",
        "T. Ribeiro",
        "A. Kanaan"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-10 19:39:33+00:00",
      "link": "https://arxiv.org/pdf/2602.10244v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10207v1",
      "title": "Optimizing Deep Learning Photometric Redshifts for the Roman Space Telescope with HST/CANDELS",
      "abstract": "Photometric redshifts (photo-$z$'s) will be crucial for studies of galaxy evolution, large-scale structure, and transients with the Nancy Grace Roman Space Telescope. Deep learning methods leverage pixel-level information from ground-based images to achieve the best photo-$z$'s for low-redshift galaxies, but their efficacy at higher redshifts with deep, space-based imaging remains largely untested. We used Hubble Space Telescope CANDELS optical and near-infrared imaging to evaluate fully-supervised, self-supervised, and semi-supervised deep learning photo-$z$ algorithms out to $z\\sim3$. Compared to template-based and classical machine learning photometry methods, the fully-supervised and semi-supervised models achieved better performance. Our new semi-supervised model, PITA (Photo-$z$ Inference with a Triple-loss Algorithm), outperformed all others by learning from unlabeled and labeled data through a three-part loss function that incorporates images and colors for all objects as well as redshifts when available. PITA produces a latent space that varies smoothly in magnitude, color, and redshift, resulting in the best photo-$z$ performance even when the redshift training set was significantly reduced. In contrast, the self-supervised approach produced a latent space with significant color and redshift fluctuations that hindered photo-$z$ inference. Looking forward to Roman, we recommend using semi supervised deep learning to take full advantage of the information contained in the hundreds of millions of high-resolution images and color measurements, together with the limited redshift measurements available, to achieve the most accurate photo-$z$ estimates for both faint and bright sources.",
      "authors": [
        "Ashod Khederlarian",
        "Brett H. Andrews",
        "Jeffrey A. Newman",
        "Tianqing Zhang",
        "Biprateep Dey"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.GA"
      ],
      "published": "2026-02-10 19:01:05+00:00",
      "link": "https://arxiv.org/pdf/2602.10207v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10191v1",
      "title": "Machine Learning Methods for Stellar Collisions. I. Predicting Outcomes of SPH Simulations",
      "abstract": "Stellar collisions can occur frequently in dense cluster environments, and play a crucial role in producing exotic phenomena from blue stragglers in globular clusters to high-energy transients in galactic nuclei. Successive collisions and mergers of massive stars could also lead to the formation of massive black holes, serving as seeds for supermassive black hole in the early universe. While analytic fitting formulae exist for predicting collision outcomes, they do not generalize across different energy scales or stellar evolutionary phases. Smoothed particle hydrodynamics (SPH) simulations are often used to compute the outcomes of stellar collisions, but, even at low resolution, their computational cost makes running on-the-fly calculations during an $N$-body simulation quite challenging. Here we present a new grid of $27,720$ SPH calculations of main-sequence star collisions, spanning a wide range of masses, ages, relative velocities, and impact parameters. Using this grid, we train machine learning models to predict both collision outcomes (merger vs disruption, or flyby) and final remnant masses. We compare the performance of nearest neighbors, support vector machines, and neural networks, achieving classification balanced accuracy of $98.4\\%$, and regression relative errors as low as $0.11\\%$ and $0.15\\%$ for the final stars $1$ and $2$, respectively. We make our trained models publicly available as part of the package collAIder, enabling rapid predictions of stellar collision outcomes in $N$-body models of dense star cluster dynamics.",
      "authors": [
        "Elena González Prieto",
        "James C. Lombardi,",
        "Sanaea C. Rose",
        "Charles F. A. Gibson",
        "Christopher E. O'Connor",
        "Tjitske Starkenburg",
        "Fulya Kıroğlu",
        "Kyle Kremer",
        "Tristan C. Parmerlee",
        "Frederic A. Rasio"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.GA",
        "astro-ph.IM",
        "astro-ph.SR"
      ],
      "published": "2026-02-10 19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2602.10191v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.10107v1",
      "title": "Measurement of the Full Shape of the Thermal Sunyaev-Zeldovich Power Spectrum from South Pole Telescope and {\\it Herschel}-SPIRE Observations",
      "abstract": "We present a measurement of the full shape of the power spectrum of the thermal Sunyaev-Zeldovich (tSZ) effect down to arcminute scales using cosmic microwave background (CMB) data from the South Pole Telescope (SPT) over roughly 100 ${\\rm deg}^{2}$ field. The analysis incorporates data from the 2019/20 seasons of the SPT-3G survey in bands centered at 95, 150, and 220 GHz; from the full SPTpol dataset at 150 GHz; and from {\\it Herschel}-SPIRE survey in bands centered at 600 and 857 GHz. We combine data from all the above bands using linear combination (LC) techniques to produce a tSZ or Compton-$y$ map. We modify the LC weights to produce multiple versions of the Compton-$y$ map, including minimum-variance (MV) and foreground-minimized (-min) maps. We measure the auto- and cross-spectra of a subset of these maps in the range $\\ell \\in [500, 5000]$. While this power spectrum includes contributions from signals other than tSZ, we present numerous checks to show that the most challenging foreground signal, the cosmic infrared background (CIB) is much lower than the desired tSZ signal in the scales of interest in this work. The final tSZ power spectrum is measured at $9.3σ$ with both the MV and CIB-min maps. Our results are consistent with those reported in other CMB surveys across the literature. Using the difference in the tSZ power spectrum from MV and CIB-min maps, we reconstruct the scale-dependent tSZ-CIB cross-correlation $ρ_{\\ell}^{\\rm tSZ \\times CIB}$, finding $3.1σ$ evidence for a nonzero correlation coefficient that is positive on large scales and approaches zero for $\\ell > 2500$. This result represents the deepest tSZ maps ever produced and provides new constraints that can help refine astrophysical feedback mechanisms and models of the intracluster medium.",
      "authors": [
        "S. Raghunathan",
        "P. A. R. Ade",
        "D. Anbajagane",
        "A. J. Anderson",
        "B. Ansarinejad",
        "M. Archipley",
        "J. E. Austermann",
        "L. Balkenhol",
        "D. R. Barron",
        "P. S. Barry",
        "J. A. Beall",
        "K. Benabed",
        "A. N. Bender",
        "B. A. Benson",
        "F. Bianchini",
        "L. E. Bleem",
        "J. Bock",
        "S. Bocquet",
        "F. R. Bouchet",
        "L. Bryant",
        "E. Camphuis",
        "M. G. Campitiello",
        "J. E. Carlstrom",
        "J. Carron",
        "C. L. Chang",
        "P. Chaubal",
        "H. C. Chiang",
        "P. M. Chichura",
        "A. Chokshi",
        "T. -L. Chou",
        "R. Citron",
        "A. Coerver",
        "C. Corbett Moran",
        "T. M. Crawford",
        "A. T. Crites",
        "C. Daley",
        "T. de Haan",
        "K. R. Dibert",
        "M. A. Dobbs",
        "M. Doohan",
        "A. Doussot",
        "D. Dutcher",
        "W. Everett",
        "C. Feng",
        "K. R. Ferguson",
        "N. C. Ferree",
        "K. Fichman",
        "A. Foster",
        "S. Galli",
        "J. Gallicchio",
        "A. E. Gambrel",
        "A. K. Gao",
        "R. W. Gardner",
        "F. Ge",
        "E. M. George",
        "N. Goeckner-Wald",
        "R. Gualtieri",
        "F. Guidi",
        "S. Guns",
        "N. Gupta",
        "N. W. Halverson",
        "E. Hivon",
        "A. Y. Q. Ho",
        "G. P. Holder",
        "W. L. Holzapfel",
        "J. C. Hood",
        "J. D. Hrubes",
        "A. Hryciuk",
        "N. Huang",
        "J. Hubmayr",
        "K. D. Irwin",
        "T. Jhaveri",
        "F. Kéruzoré",
        "A. R. Khalife",
        "L. Knox",
        "M. Korman",
        "K. Kornoelje",
        "C. -L. Kuo",
        "A. T. Lee",
        "K. Levy",
        "Y. Li",
        "D. Li",
        "A. E. Lowitz",
        "A. Lowitz",
        "C. Lu",
        "G. P. Lynch",
        "T. J. Maccarone",
        "A. S. Maniyar",
        "E. S. Martsen",
        "J. J. McMahon",
        "F. Menanteau",
        "M. Millea",
        "J. Montgomery",
        "Y. Nakato",
        "T. Natoli",
        "J. P. Nibarger",
        "G. I. Noble",
        "V. Novosad",
        "Y. Omori",
        "A. Ouellette",
        "S. Padin",
        "Z. Pan",
        "P. Paschos",
        "S. Patil",
        "K. A. Phadke",
        "A. W. Pollak",
        "K. Prabhu",
        "C. Pryke",
        "W. Quan",
        "M. Rahimi",
        "A. Rahlin",
        "C. L. Reichardt",
        "M. Rouble",
        "J. E. Ruhl",
        "B. R. Saliwanchik",
        "K. K. Schaffer",
        "E. Schiappucci",
        "C. Sievers",
        "A. C. Silva Oliveira",
        "A. Simpson",
        "G. Smecher",
        "J. A. Sobrin",
        "A. A. Stark",
        "J. Stephen",
        "C. Tandoi",
        "B. Thorne",
        "C. Trendafilova",
        "C. Tucker",
        "C. Umilta",
        "T. Veach",
        "J. D. Vieira",
        "A. G. Vieregg",
        "M. P. Viero",
        "A. Vitrier",
        "Y. Wan",
        "G. Wang",
        "N. Whitehorn",
        "W. L. K. Wu",
        "V. Yefremenko",
        "M. R. Young",
        "J. A. Zebrowski",
        "M. Zemcov"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-10 18:59:09+00:00",
      "link": "https://arxiv.org/pdf/2602.10107v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10065v1",
      "title": "Dark Energy Survey Year 6 Results: Cosmological Constraints from Cosmic Shear",
      "abstract": "We present legacy cosmic shear measurements and cosmological constraints using six years of Dark Energy Survey imaging data. From these data, we study ~140 million galaxies (8.29 galaxies/arcmin$^2$) that are 50% complete at i=24.0 and extend beyond z=1.2. We divide the galaxies into four redshift bins, and obtain cosmic shear measurement with a signal-to-noise of 83, a factor of 2 higher than the Year 3 analysis. We model the uncertainties due to shear and redshift calibrations, and discard measurements on small angular scales to mitigate baryon feedback and other small-scale uncertainties. We consider two fiducial models to account for the intrinsic alignment (IA) of the galaxies. We conduct a blind analysis in the context of the $Λ$CDM model and find $S_8 \\equiv σ_8(Ω_m/0.3)^{0.5}=0.798^{+0.014}_{-0.015}$ (marginalized mean with 68% CL) when using the non-linear alignment model (NLA) and $S_{8} = 0.783^{+0.019}_{-0.015}$ with the tidal alignment and tidal torque model (TATT), providing 1.8% and 2.5% uncertainty on $S_8$. Compared to constraints from the cosmic microwave background from Planck 2018, ACT DR6 and SPT-3G DR1, we find consistency in the full parameter space at 1.1$σ$ (1.7$σ$) and in $S_8$ at 2.0$σ$ (2.3$σ$) for NLA (TATT). The result using the NLA model is preferred according to the Bayesian evidence. We find that the model choice for IA and baryon feedback can impact the value of our $S_8$ constraint up to $1σ$. For our fiducial model choices, the resultant uncertainties in $S_8$ are primarily degraded by the removal of scales, as well as the marginalization over the IA parameters. We demonstrate that our result is internally consistent and robust to different choices in calibrating the data, owing to methodological improvements in shear and redshift measurement, laying the foundation for next-generation cosmic shear programs.",
      "authors": [
        "DES Collaboration",
        "T. M. C. Abbott",
        "M. Aguena",
        "A. Alarcon",
        "O. Alves",
        "A. Amon",
        "D. Anbajagane",
        "F. Andrade-Oliveira",
        "W. d'Assignies",
        "S. Avila",
        "D. Bacon",
        "J. Beas-Gonzalez",
        "K. Bechtol",
        "M. R. Becker",
        "G. M. Bernstein",
        "J. Blazek",
        "S. Bocquet",
        "D. Brooks",
        "H. Camacho",
        "G. Camacho-Ciurana",
        "R. Camilleri",
        "G. Campailla",
        "A. Campos",
        "A. Carnero Rosell",
        "M. Carrasco Kind",
        "J. Carretero",
        "F. J. Castander",
        "R. Cawthon",
        "C. Chang",
        "A. Choi",
        "J. M. Coloma-Nadal",
        "C. Conselice",
        "L. N. da Costa",
        "M. Costanzi",
        "M. Crocce",
        "T. M. Davis",
        "J. De Vicente",
        "D. L. DePoy",
        "J. DeRose",
        "S. Desai",
        "H. T. Diehl",
        "P. Doel",
        "C. Doux",
        "A. Drlica-Wagner",
        "T. F. Eifler",
        "S. Everett",
        "A. E. Evrard",
        "A. Ferté",
        "B. Flaugher",
        "P. Fosalba",
        "O. Friedrich",
        "J. Frieman",
        "J. García-Bellido",
        "M. Gatti",
        "G. Giannini",
        "P. Giles",
        "K. Glazebrook",
        "D. Gruen",
        "R. A. Gruendl",
        "G. Gutierrez",
        "I. Harrison",
        "W. G. Hartley",
        "K. Herner",
        "S. R. Hinton",
        "D. L. Hollowood",
        "K. Honscheid",
        "D. Huterer",
        "B. Jain",
        "D. J. James",
        "M. Jarvis",
        "N. Jeffrey",
        "T. Jeltema",
        "T. Kacprzak",
        "S. Kent",
        "E. Krause",
        "O. Lahav",
        "S. Lee",
        "E. Legnani",
        "H. Lin",
        "J. L. Marshall",
        "S. Mau",
        "J. Mena-Fernández",
        "F. Menanteau",
        "R. Miquel",
        "J. J. Mohr",
        "J. Muir",
        "J. Myles",
        "R. C. Nichol",
        "R. L. C. Ogando",
        "A. Palmese",
        "M. Paterno",
        "W. J. Percival",
        "D. Petravick",
        "A. A. Plazas Malagón",
        "A. Porredon",
        "J. Prat",
        "C. Preston",
        "M. Raveri",
        "M. Rodriguez-Monroy",
        "A. K. Romer",
        "A. Roodman",
        "E. S. Rykoff",
        "S. Samuroff",
        "C. Sánchez",
        "E. Sanchez",
        "D. Sanchez Cid",
        "T. Schutt",
        "I. Sevilla-Noarbe",
        "E. Sheldon",
        "T. Shin",
        "M. E. da Silva Pereira",
        "M. Smith",
        "M. Soares-Santos",
        "E. Suchyta",
        "M. E. C. Swanson",
        "M. Tabbutt",
        "G. Tarle",
        "D. Thomas",
        "C. To",
        "M. A. Troxel",
        "V. Vikram",
        "M. Vincenzi",
        "N. Weaverdyck",
        "J. Weller",
        "P. Wiseman",
        "M. Yamamoto",
        "B. Yanny",
        "B. Yin",
        "J. Zuntz"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-10 18:33:06+00:00",
      "link": "https://arxiv.org/pdf/2602.10065v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09871v1",
      "title": "Resolved Dust Emission and CO Isotopologues in Giant Molecular Clouds of the Andromeda Galaxy",
      "abstract": "Dust emission at submillimeter wavelengths can be used to reliably trace the basic properties of molecular clouds. Early results from a recent Submillimeter Array (SMA) survey of the Andromeda Galaxy (M31) include the first detections of resolved dust continuum emission from individual giant molecular clouds (GMCs) in an external spiral galaxy. This paper updates on the now-complete SMA survey of 80 Herschel-identified giant molecular associations (GMAs) in M31. The SMA survey simultaneously probes dust continuum emission at 230 GHz and the $J = 2 \\rightarrow 1$ transitions of the CO isotopologues, $^{12}\\rm CO$, $^{13}\\rm CO$, and $\\rm C^{18}O$ at a spatial resolution of $\\lesssim 15~\\mathrm{pc}$. Dust continuum emission was detected in 71 cloud cores, of which 26 were resolved. This more than doubles the size of the previous sample. By comparing dust and CO observations with identical astrometry, we directly measure the dust mass to-light ratios, $\\rm α^{\\prime}_{^{12}CO}$, and $\\rm α^{\\prime}_{^{13}CO}$. We derive $<α^{\\prime}_{\\rm ^{12}\\rm CO}>~=~0.070~\\pm~0.031~M_{\\odot}\\,(\\rm K~km~s^{-1}~pc^{2})^{-1}$ and $<α^{\\prime}_{\\rm ^{13}\\rm CO}>~=~0.37~\\pm~0.20~M_{\\odot}\\,(\\rm K~km~s^{-1}~pc^{2})^{-1}$ for the increased sample, which are in agreement with previously reported values. From virial analysis, we find that 80% of the GMC regions traced by resolved dust emission are bound and close to virial equilibrium. Finally, we update our analysis on the metallicity dependence of $\\rm α^{\\prime}_{\\rm CO}$ by combining SMA observations with existing MMT/Hectospec optical spectroscopy toward H II regions. We find no trend in $\\rm α^{\\prime}_{\\rm CO}$ with metallicity, supporting the previous findings.",
      "authors": [
        "Chloe Bosomworth",
        "Jan Forbrich",
        "Charles J. Lada",
        "Glen Petitpas"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-10 15:16:30+00:00",
      "link": "https://arxiv.org/pdf/2602.09871v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09865v1",
      "title": "A comparison of G-band brightness as a proxy-magnetometer in various magnetic configurations",
      "abstract": "We investigate the diagnostic potential of the G-band at 430.4 nm for probing small-scale magnetic fields in the solar photosphere. Combining three-dimensional MHD simulations from the MURaM code and spectral synthesis via the RH 1.5D code, we evaluate the intensity contrast in the G-band filtergrams by comparing the filter centered at 430.4 nm in comparison to the conventional 430.5 nm. Our results show that filtergrams centered at 430.4 nm provide higher contrast across varying magnetic environments, particularly at narrow filter widths. This enhancement arises from its slightly higher formation height and greater sensitivity to temperature variations in magnetized regions. These findings indicate that G-band filtergrams centered at 430.4 nm show enhanced diagnostic potential under the assumptions of the present modeling. The obtained results are also relevant and suggest potential applications in stellar contexts, where molecular bands are often used as proxies for magnetic activity.",
      "authors": [
        "Malay Shukla",
        "Sneha Pandit",
        "Nitin Yadav"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "astro-ph.IM"
      ],
      "published": "2026-02-10 15:08:28+00:00",
      "link": "https://arxiv.org/pdf/2602.09865v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09819v1",
      "title": "Estimating Electron Densities in the Middle Solar Corona using White-light and Radio Observations",
      "abstract": "The electron density of the solar corona is a fundamental parameter in many areas of solar physics. Traditionally, routine estimates of coronal density have relied exclusively on white-light observations. However, these density estimates, obtained by inverting the white-light data, require simplifying assumptions, which may affect the robustness of the measurements. Hence, to improve the reliability of coronal density measurements, it is highly desirable to explore other complementary methods. In this study, we estimate the coronal electron densities in the middle corona, between approximately $1.7-3.5R_\\odot$, using low-frequency radio observations from the recently commissioned Long Wavelength Array at the Owens Valley Radio Observatory (OVRO-LWA). The results demonstrate consistency with those derived from white-light coronagraph data and predictions from theoretical models. We also derive a density model valid between 1.7--3.5 $r_\\odot$ and is given by $ρ(r')=1.27r'^{-2}+29.02r'^{-4}+71.18r'^{-6}$, where $r'=r/R_\\odot$, and $r$ is the heliocentric distance. OVRO-LWA is a solar-dedicated radio interferometer that provides science-ready images with low latency, making it well-suited for generating regular and independent estimates of coronal densities to complement existing white-light techniques.",
      "authors": [
        "Surajit Mondal",
        "Shaheda Begum Shaik",
        "Russell A. Howard",
        "Peijin Zhang",
        "Bin Chen",
        "Xingyao Chen",
        "Sijie Yu",
        "Dale Gary",
        "Marin M. Anderson",
        "Judd D. Bowman",
        "Ruby Byrne",
        "Morgan Catha",
        "Sherry Chhabra",
        "Larry D Addario",
        "Ivey Davis",
        "Jayce Dowell",
        "Gregg Hallinan",
        "Charlie Harnach",
        "Greg Hellbourg",
        "Jack Hickish",
        "Rick Hobbs",
        "David Hodge",
        "Mark Hodges",
        "Yuping Huang",
        "Andrea Isella",
        "Daniel C. Jacobs",
        "Ghislain Kemby",
        "John T. Klinefelter",
        "Matthew Kolopanis",
        "Nikita Kosogorov",
        "James Lamb",
        "Casey Law",
        "Nivedita Mahesh",
        "Brian O Donnell",
        "Corey Posner",
        "Travis Powell",
        "Vinand Prayag",
        "Andres Rizo",
        "Andrew Romero Wolf",
        "Jun Shi",
        "Greg Taylor",
        "Jordan Trim",
        "Mike Virgin",
        "Akshatha Vydula",
        "Sandy Weinreb",
        "Scott White",
        "David Woody",
        "Thomas Zentmeyer"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR"
      ],
      "published": "2026-02-10 14:27:01+00:00",
      "link": "https://arxiv.org/pdf/2602.09819v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09779v1",
      "title": "Analysis of Galactic cirrus filaments in HSC-SSP high-resolution deep images using artificial neural networks",
      "abstract": "The existence of Galactic optical cirrus poses a challenge for observing faint objects within our Galaxy and dim extragalactic structures. To investigate individual cirrus filaments in the Hyper Suprime-Cam Subaru Strategic Program public data release 3 (HSC-SSP DR3) we use a technique based on convolutional neural networks and ensemble learning. This approach allows us to distinguish cirrus filaments from foreground and background objects across the entire HSC-SSP, using optical images in the $g$, $r$, and $i$ wavebands. A comparison with previous work using deep Sloan Digital Sky Survey Stripe~82 (SDSS Stripe~82) data reveals that the cirrus clouds identified in this study are highly consistent in location within the overlapping survey region. However, in the deeper HSC-SSP dataset, we were able to detect $4.5$ times more cirrus clouds. Our study indicates that the sky background in HSC-SSP coadd images is over-subtracted, as evidenced by the surface brightness distribution in cirrus filaments and surrounding regions. Objects with surface brightness of $m = 29~\\mbox{mag~arcsec}^{-2}$ near large filaments can be dimmed by over-subtraction of $0.5$ magnitude in the $r$ band. This suggests that cirrus clouds should be taken into account in algorithms for estimating the sky background. For practical use, we provide a catalog of filaments and a framework that allows one to train neural network models for segmenting cirri in HSC-SSP coadd images.",
      "authors": [
        "Denis M. Poliakov",
        "Anton A. Smirnov",
        "Sergey S. Savchenko",
        "Alexander A. Marchuk",
        "Aleksandr V. Mosenkov",
        "Vladimir B. Ilin",
        "George A. Gontcharov",
        "Daria G. Turichina",
        "Andrey D. Panasyuk"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-10 13:39:33+00:00",
      "link": "https://arxiv.org/pdf/2602.09779v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.09670v1",
      "title": "Talking with the Latents -- how to convert your LLM into an astronomer",
      "abstract": "Recent advances in Large Language Models (LLMs) offer unique opportunities for scientific tasks, yet their ability to reason over complex numerical data remains largely unexplored. We propose a simple mechanism to introduce domain-specific physical knowledge into LLMs by fusing pre-trained latent physical features with a pre-trained language model. Our method employs a teacher-student knowledge distillation framework where a large LLM (teacher) generates synthetic question-answer supervision to transfer physical reasoning to a smaller LLM (student). The student is conditioned on latent physical features and trained via a lightweight adapter and Low-Rank Adaptation (LoRA). We demonstrate that this approach, applied to models with 1B, 8B, and 32B parameters, enables effective reasoning over real scientific data. Our models substantially outperform strong baselines, such as Gemini 3 Pro, across multiple downstream tasks without task-specific fine-tuning. We show that the model combines latent information with general physical understanding to predict complex properties and can be \"steered\" by identifying physically meaningful directions in the latent space. This allows for explicit physical manipulation and natural language interpretation of latent structures. While our experiments focus on astrophysics, the framework is domain-agnostic and applicable to various scientific fields. Our main contribution is a general framework for using LLMs as interpretable interfaces to scientific latent spaces, enabling a single model to perform diverse tasks through natural language guidance. This work marks a step toward developing scientifically capable and useful LLMs.",
      "authors": [
        "Ilay Kamai",
        "Marc-Huertas Company",
        "Mike J. Smith",
        "Hagai B. Perets"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-02-10 11:25:25+00:00",
      "link": "https://arxiv.org/pdf/2602.09670v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09658v2",
      "title": "EMU Radio Observations of Barred Spiral Galaxy NGC 5938 (Araish)",
      "abstract": "We present multi-wavelength observations of the nearby spiral galaxy NGC 5938 (Araish) to investigate the origin of its radio emission, specifically the contribution from active galactic nucleus (AGN) activity and star formation. Using Evolutionary Map of the Universe (EMU) data, we detect extended radio emission extending outwards to the galactic axis, with a steep non-thermal spectral index ($α= -1.2 \\pm 0.2$) indicative of synchrotron radiation from an AGN jet. The jet has a physical extent of $\\approx 8.2\\,kpc$ (angular length of $64^{\\prime\\prime}$). Multi-wavelength data from The Dark Energy Camera Plane Survey 2 (DECaPS2), Wide-field Infrared Survey Explorer (WISE), and extended Roentgen Survey with an Imaging Telescope Array (eROSITA) provide further support for this interpretation. The colour-colour diagram presenting WISE infrared observations suggests the presence of dust and young stars that trace the galaxy's disk structure. Our analysis reveals a radio jet, alongside star formation traced by infrared emission, demonstrating the complex interplay of AGN activity and star formation in this well-resolved galaxy. Intriguingly, the spatial relationship reveals the brighter X-ray emission to be largely adjacent to and enveloping the extended radio emission. This suggests that the radio jet, while extending at a significant angle to the galactic disk, is confined by the larger X-ray gas halo, similar to other systems (i.e., ESO 295-IG022, Centaurus A) and may indicate jet collimation and channelling effects.",
      "authors": [
        "H. Zakir",
        "M. D. Filipović",
        "L. Barnes",
        "R. Z. E. Alsaberi",
        "T. An",
        "K. Dage",
        "S. W. Duchesne",
        "A. M. Hopkins",
        "A. Kapinska",
        "B. Koribalski",
        "S. Lazarević",
        "D. Leahy",
        "Z. Liu",
        "R. P. Norris",
        "A. Rau",
        "Z. J. Smeaton",
        "T. Jarrett"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-10 11:08:48+00:00",
      "link": "https://arxiv.org/pdf/2602.09658v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10165v1",
      "title": "The indiscriminate adoption of AI threatens the foundations of academia",
      "abstract": "Artificial intelligence offers much promise, but its use in scientific research should be restrained so that the primary aim of academia -- advancing knowledge for humans -- is safeguarded.",
      "authors": [
        "Roberto Trotta"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-02-10 10:51:01+00:00",
      "link": "https://arxiv.org/pdf/2602.10165v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.09232v1",
      "title": "Transient Relativistic Iron Emission Line from an X-ray Flaring Supermassive Black Hole",
      "abstract": "We report the discovery of the first transient relativistic iron Kα line in an Active Galactic Nucleus (AGN) J1047+5907. The line was detected 21.5 days (rest-frame) after an X-ray coronal flare observed in 2008 and it exhibits significant broadening consistent with relativistic reflection from the accretion disk in the vicinity of the central supermassive black hole (SMBH). The line has a width of ~300 eV, corresponding to a Keplerian velocity of 14,000 km s-1, at a distance of 5-41 light-days from the SMBH, strongly implying that the observed coronal flare triggered the emergence of the line. This event provides rare direct evidence of the response of the accretion disk to impulsive coronal illumination and offers a new method to probe the SMBH and disk physics. The relativistic modeling favors a broadened line produced by distant reflection from an accretion disk around a rapidly spinning black hole viewed at an intermediate inclination, consistent with other observations. Systematic monitoring of type 1 AGN following strong X-ray flares may open a new observational window into the innermost regions of AGN, enabling constraints on the physics of SMBH and its accretion disk at different radii that are otherwise challenging to access.",
      "authors": [
        "Xiurui Zhao",
        "Marco Ajello",
        "Francesca Civano",
        "Javier A. Garcıa",
        "Elias Kammoun",
        "Stefano Marchesi",
        "Yue Shen",
        "Daniel Stern",
        "Qian Yang",
        "Peter G. Boorman",
        "Fiona Harrison",
        "Erin Kara",
        "Andrealuna Pizzetti",
        "Ross Silver",
        "Kirill V. Sokolovsky",
        "Zachary Stone",
        "Nuria Torres-Alba",
        "Qiaoya Wu",
        "Peixin Zhu"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.GA"
      ],
      "published": "2026-02-09 21:57:05+00:00",
      "link": "https://arxiv.org/pdf/2602.09232v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09230v1",
      "title": "Modeling Redshift Uncertainties in Roman Weak Lensing Cosmology",
      "abstract": "Cosmological constraints using weak gravitational lensing measurements from the Roman Space Telescope will require a powerful method for modelling uncertainties in the galaxy redshift distribution. In this work, we use an optimized version of the principal component analysis (PCA) to model uncertainties in the full shape of the redshift distributions, a method proposed by \\cite{pca_method} and recently used in the Dark Energy Survey Y6 analysis. Here, we implement this new approach within the Roman High Latitude Imaging Survey (HLIS) Cosmology Project Infrastructure Team (PIT) pipeline, namely Cobaya-Cosmolike Joint Architecture (\\texttt{CoCoA}). To validate the PCA in mitigating biases on cosmological parameters, $S_8$ and $Ω_m$, we use a set of redshift distributions from \\texttt{Cardinal} generated for a variety of Roman configurations. Overall, when the simulated cosmic shear data vector is not strongly miscalibrated relative to the fiducial one, both the mean-shift and the PCA-based approaches produce consistent cosmological constraints when marginalizing over nuisance parameters. For mild to strong miscalibration, including additional PCs progressively mitigates biases in $S_8$ and $Ω_m$, and can achieve comparable performance with fewer parameters than the nine tomographic-bin mean-shift model.",
      "authors": [
        "Diogo H. F. de Souza",
        "Boyan Yin",
        "Tim Eifler",
        "Vivian Miranda",
        "Chun-Hao To",
        "Brett H. Andrews",
        "Katarina Markovič",
        "Eric Huff",
        "Michael A. Troxel",
        "Olivier Doré"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-09 21:53:49+00:00",
      "link": "https://arxiv.org/pdf/2602.09230v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09223v1",
      "title": "astromorph: Self-supervised machine learning pipeline for astronomical morphology analysis",
      "abstract": "Modern telescopes generate increasingly large and diverse datasets, often consisting of complex and morphologically rich structures. To efficiently explore such data requires automated methods that can extract and organize physically meaningful information, ideally without the need for extensive manual interaction. We aim to provide a user-friendly implementation of a self-supervised machine learning framework to explore morphological properties of large datasets, based on the BYOL (Bootstrap Your Own Latents) method. By enabling the generation of meaningful image embeddings without manually labelled data, the framework will enable key tasks such as clustering, anomaly detection, and similarity based exploration. In contrast to existing BYOL implementations, astromorph accommodates data of varying dimensions and resolutions, including both single-channel FITS images and multi-channel spectral cubes. The package is built with usability in mind, offering streamlined pipeline scripts for ease of use as well as deeper customization options via PyTorch-based classes. To demonstrate the utility of astromorph, we apply it in two contrasting science cases representing different astronomical domains: images of protoplanetary disks observed with ALMA, and infrared dark clouds observed with Spitzer and Herschel. In both cases, we demonstrate how astromorph produces scientifically meaningful embeddings that capture morphological differences and similarities across large samples. astromorph enables users to apply a robust, label-free approach for uncovering morphological patterns in astronomical datasets. The successful application to two markedly different datasets suggest that the pipeline is broadly applicable across a wide range of imaging-rich astronomical context, providing a user friendly tool for advancing discovery in observational astronomy.",
      "authors": [
        "Per Bjerkeli",
        "Jouni Kainulainen",
        "Maria Carmen Toribio",
        "Leon Boschman",
        "Otoniel Maya Lucas"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-02-09 21:46:43+00:00",
      "link": "https://arxiv.org/pdf/2602.09223v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09025v1",
      "title": "An Exploration of the Equation of State Dependence of Core-Collapse Supernova Explosion Outcomes and Signatures",
      "abstract": "We explore, using a state-of-the-art simulation code in 3D and to late enough times to witness final observables, the dependence of core-collapse supernova explosions on the nuclear equation of state. Going beyond questions of explodability, we compare final explosion energies, nucleosynthetic yields, recoil kicks, and gravitational-wave and neutrino signatures using the SFHo and DD2 nuclear equations of state (EOS) for a 9-$M_{\\odot}$/solar-metallicity progenitor star. The DD2 EOS is stiffer and has a lower effective nucleon mass. The result is a more extended protoneutron star (PNS) and lower central densities. As a consequence, the mean neutrino energies, final explosion energy, and recoil kick speed are lower. Moreover, the evolution of PNS convection differs between the two EOS models in significant ways. This translates in part into interestingly altered neutrino ``light\" curves and noticeably altered gravitational-wave signal strengths and frequency characteristics that may be diagnostic. The faster exploding model (SFHo) yields slightly more neutron-rich ejecta and more species with atomic weights between 60 and 90 and a weak r-process. However, this is merely a preliminary study. The next step is a more comprehensive and multi-progenitor set of 3D supernova simulations for various EOSes to late times when the observables have asymptoted. Such a future investigation will have a direct bearing on the neutron star and black hole birth mass functions and the quest towards a fully quantitative theory of supernova observables.",
      "authors": [
        "Aleksandr Rusakov",
        "Adam S. Burrows",
        "Tianshu Wang",
        "David Vartanyan"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.SR"
      ],
      "published": "2026-02-09 18:59:59+00:00",
      "link": "https://arxiv.org/pdf/2602.09025v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16550v1",
      "title": "Searching for White Dwarf Candidates Formed Through Binary evolution in Star Clusters",
      "abstract": "White dwarfs (WDs), the evolutionary endpoints of most stars, can form through both single-star and binary channels. While single-star evolutionary models enable reliable WD age estimates, binary evolution introduces interactions that can accelerate WD formation and result in a variety of exotic WDs, which may exhibit strong magnetic fields, rapid rotation, or even serve as potential gravitational wave sources. Such systems offer valuable insights into magnetic field generation, angular momentum evolution, and compact object physics. Star clusters, with their approximately coeval populations, allow precise age determination of member WDs. If a WD's total age derived from single-star evolution exceeds that of its host cluster, it likely indicates a binary origin. In this study, we use \\textit{Gaia} 5D astrometry to identify 439 WD candidates in 117 open clusters, with 244 likely formed via binary evolution. We discuss the possibility of dynamical ejection for WDs meeting only 2D (proper motion space) membership criteria. Spectroscopic observations further reveal a subset with strong magnetic fields and rapid rotation, supporting their binary evolutionary origin.",
      "authors": [
        "Huahui Yan",
        "Li Wang",
        "David R. Miller",
        "Chenyu He",
        "Jiamao Lin",
        "Xiaoying Pang",
        "Jingkun Zhao",
        "Jincheng Guo",
        "Richard de Grijs",
        "Hongwei Ge",
        "Zhen Guo",
        "Bo Ma",
        "Dichang Chen",
        "Chengyuan Li"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA"
      ],
      "published": "2026-02-18 15:53:07+00:00",
      "link": "https://arxiv.org/pdf/2602.16550v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16415v1",
      "title": "The Astronomical Telescope of the University of Stuttgart (ATUS): Development, Optimization, and Lessons Learned",
      "abstract": "ATUS, the Astronomical Telescope of the University of Stuttgart, is a fully remote-controlled 0.6 m f/8.17 Ritchey-Chrétien telescope optimized for high-cadence, high-fidelity photometry of transient sources. Observations are time-referenced with very high accuracy and precision, making it an ideal platform for time-domain astronomy and space situational awareness. Initially conceived to support instrument developments and operations of SOFIA, the Stratospheric Observatory for Infrared Astronomy, it evolved into a scientific instrument for various use cases in instrument development, astronomical research, and teaching. This paper presents an overview of its development and optimization to achieve diffraction-limited images and highly accurate pointing and tracking, even at high speeds. The findings and lessons learned are universally applicable to other telescopes that are currently at the planning stage, or where similar issues might be encountered.",
      "authors": [
        "Karsten Schindler",
        "Jürgen Wolf",
        "Alfred Krabbe"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-02-18 12:46:01+00:00",
      "link": "https://arxiv.org/pdf/2602.16415v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.16396v1",
      "title": "Deepest ever photographed Geminid with small but not negligible terminal mass",
      "abstract": "We report an instrumental observation of the very exceptional Geminid fireball which was observed in scope of the Czech part of the European Fireball Network (EN) on 13 December 2012 at 4h12m59.4s UT. The uniqueness of this Geminid fireball consists of the record depth of its penetration in the atmosphere (to the height of 32.5 km) and in the fact that most likely a very small fraction of its initial mass survived severe deceleration in the atmosphere and landed on the ground. Such deeply penetrating Geminid with so precise and reliable data has not yet been observed. From a comparison with a large number of Geminids observed by the European Fireball Network and all brightest Geminids from the Prairie Fireball Network in USA and the Canadian MORP Network, we have shown that for Geminids with an entry mass greater than approximately 10 grams, the terminal altitude limit does not decrease further as it does for smaller Geminids, but remains constant at around 38 km. In this comparison, we have shown that there is only one exception, and that is the Geminid presented here. This one penetrated nearly 6 km deeper with very low terminal speed for Geminids. During the atmospheric flight this Geminid meteoroid slowed down from its original speed of 35.75 km/s to 6.8 km/s. This small meteoroid with initial mass of only 0.25 kg is probably the fastest candidate for a meteorite dropping event ever observed. This solid meteoroid belonging to the meteor shower survived a significant dynamic pressure of almost 2 MPa and thus ranks among the interplanetary bodies of asteroidal origin that caused the observed meteorite fall. Although a similar Geminid event has been previously presented in the literature, we demonstrate here that this claim was flawed.",
      "authors": [
        "Pavel Spurný",
        "Jiří Borovička"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP"
      ],
      "published": "2026-02-18 12:09:00+00:00",
      "link": "https://arxiv.org/pdf/2602.16396v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16095v1",
      "title": "Three Saturn-mass Microlensing Planets Identified through Signals from Peripheral-caustic Perturbations",
      "abstract": "We present the discovery and analysis of three microlensing planets identified through brief positive anomalies on the wings of their light curves. The events, KMT-2021-BLG-0852, KMT-2024-BLG-2005, and KMT-2025-BLG-0481, were detected in high-cadence survey data from the KMTNet, OGLE, MOA, and PRIME collaborations. The anomaly morphologies are consistent with major-image perturbations induced by planetary-mass companions located near the peripheral caustic. A systematic exploration of model degeneracies, including binary-source scenarios, higher mass-ratio binary lenses, and the inner--outer caustic degeneracy, firmly establishes the planetary origin of each signal. Measurements of the angular Einstein radius and event timescale, combined with Bayesian priors from a Galactic model, yield the physical parameters of each system. The hosts are low-mass stars (0.12--0.75~$M_\\odot$), while the companions are Saturn-mass planets (0.16--0.59 $M_{\\rm J}$) projected at separations of 1.1--7.8 au, placing them beyond the snowline of their hosts. These results demonstrate the capability of microlensing to detect and characterize cold giant planets around low-mass stars at kpc distances, populating the critical transition region between ice giants and gas giants.",
      "authors": [
        "Cheongho Han",
        "Chung-Uk Lee",
        "Andrzej Udalski",
        "Ian A. Bond",
        "Michael D. Albrow",
        "Sun-Ju Chung",
        "Andrew Gould",
        "Youn Kil Jung",
        "Kyu-Ha Hwang",
        "Yoon-Hyun Ryu",
        "Yossi Shvartzvald",
        "In-Gu Shin",
        "Jennifer C. Yee",
        "Weicheng Zang",
        "Hongjing Yang",
        "Doeon Kim",
        "Dong-Jin Kim",
        "Sang-Mok Cha",
        "Seung-Lee Kim",
        "Dong-Joo Lee",
        "Yongseok Lee",
        "Byeong-Gon Park",
        "Kyeongsoo Hong",
        "Richard W. Pogge",
        "Przemek Mróz",
        "Michał K. Szymański",
        "Jan Skowron",
        "Radosław Poleski",
        "Igor Soszyński",
        "Paweł Pietrukowicz",
        "Szymon Kozłowski",
        "Krzysztof A. Rybicki",
        "Patryk Iwanek",
        "Krzysztof Ulaczyk",
        "Marcin Wrona",
        "Mariusz Gromadzki",
        "Mateusz J. Mróz",
        "Fumio Abe",
        "David P. Bennett",
        "Aparna Bhattacharya",
        "Ryusei Hamada",
        "Yuki Hirao",
        "Asahi Idei",
        "Stela Ishitani Silva",
        "Shuma Makida",
        "Shota Miyazaki",
        "Yasushi Muraki",
        "Tutumi Nagai",
        "Togo Nagano",
        "Seiya Nakayama",
        "Mayu Nishio",
        "Kansuke Nunota",
        "Ryo Ogawa",
        "Ryunosuke Oishi",
        "Yui Okumoto",
        "Greg Olmschenk",
        "Clément Ranc",
        "Nicholas J. Rattenbury",
        "Yuki Satoh",
        "Takahiro Sumi",
        "Daisuke Suzuki",
        "Takuto Tamaoki",
        "Sean K. Terry",
        "Paul J. Tristram",
        "Aikaterini Vandorou",
        "Hibiki Yama"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP",
        "astro-ph.GA"
      ],
      "published": "2026-02-17 23:51:31+00:00",
      "link": "https://arxiv.org/pdf/2602.16095v1",
      "tags": [
        "query:SR"
      ]
    },
    {
      "id": "2602.16082v1",
      "title": "Evolution of Low-Mass Population III Stars: Convection, Mass Loss, Nucleosynthesis, and Neutrinos",
      "abstract": "The first stars likely formed from pristine clouds, marking a transformative epoch after the dark ages by initiating reionisation and synthesising the first heavy elements. Among these, low-mass Population III stars are of particular interest, as their long lifespans raise the possibility that some may survive to the present day in the Milky Way's stellar halo or satellite dwarfs. As the first paper in a series, we present hydrodynamic evolutionary models for 0.7 - 1 MSun stars evolved up to the white dwarf phase, utilising the MESA software instrument. We systematically vary mass-loss efficiencies, convective transport, and overshooting prescriptions, thereby mapping how uncertain physics influences nucleosynthetic yields; surface enrichment, including nitrogen-rich post-main sequence stars arising from convective shell mergers; remnant properties, such as low-mass helium or carbon-oxygen white dwarfs (M_WD ~ 0.45-0.55 MSun) and transient UV-bright phases; and potential observational signatures, including neutrino emission during shell mergers and helium flashes. These models establish a predictive framework for identifying surviving Pop III stars and their descendants, providing both evolutionary and observational constraints that were previously unexplored.",
      "authors": [
        "Thiago Ferreira",
        "Earl P. Bellinger",
        "Ebraheem Farag",
        "Christopher J. Lindsay"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA"
      ],
      "published": "2026-02-17 23:15:44+00:00",
      "link": "https://arxiv.org/pdf/2602.16082v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16043v1",
      "title": "Diffusive Instabilities in Dusty Disks: Linear Growth and Nonlinear Breakdown",
      "abstract": "We revisit the diffusive instability in dusty disks that arises when the dust mass diffusivity and/or viscosity decreases sufficiently steeply with increasing dust density. Our updated model includes an incompressible, viscous gas that responds azimuthally and couples to the dust through drag. We show that the basic criterion for diffusion-slope-driven instability remains approximately $β_\\mathrm{diff}\\lesssim -2$ for small dust stopping times, with gas feedback providing only modest quantitative changes for parameters motivated by streaming-instability turbulence. We perform nonlinear numerical calculations and confirm linear growth and mode selection toward the fastest-growing wavenumber. However, for power-law closures $D\\proptoΣ^{β_\\mathrm{diff}}$ with $β_\\mathrm{diff}<0$, the nonlinear evolution does not saturate. Instead, steepening gradients amplify the nonlinear dust-pressure term and drive finite-time collapse into increasingly sharp spikes. Motivated by the absence of multidimensional saturation channels in our 1D framework, we test a simple piecewise closure in which the negative diffusion slope operates only over a finite density interval. This modification eliminates blowup and produces peak densities controlled by the imposed saturation scale. Our results support diffusive instabilities as a linear organizing mechanism in dusty turbulence, while highlighting that realistic nonlinear saturation requires additional physics beyond the present closure.",
      "authors": [
        "Konstantin Gerbig",
        "Min-Kai Lin"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP"
      ],
      "published": "2026-02-17 21:53:26+00:00",
      "link": "https://arxiv.org/pdf/2602.16043v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15976v1",
      "title": "Early Results from the Coma Legacy IFU Survey (CLIFS): Ram Pressure Induced Shocks and Ionization in Jellyfish Tails",
      "abstract": "Jellyfish galaxies, which exhibit tails of gas opposite to their direction of motion, are a galaxy population showcasing the most extreme effects of ram pressure stripping (RPS). We present the emission line properties of a preliminary sample of five jellyfish galaxies in the Coma cluster, observed with the WEAVE Large-IFU as part of the Coma Legacy IFU Survey (CLIFS). When complete, CLIFS will form a sample of 29 jellyfish galaxies in Coma, selected based on the presence of one-sided tails in the radio continuum, enabling a comprehensive picture of the effects of ram pressure on galaxies in the Coma cluster. We extract emission line properties and confirm consistency between disk fluxes measured from WEAVE and MaNGA for galaxies with overlapping disk coverage between surveys. Comparing resolved radio and H$α$-based star formation rates, we find that, in contrast to the disk, the dominant source of tail emission is not star formation. We find evidence for diffuse ionized gas excited by RPS-driven shocks in the tails, as indicated by: (1) LINER-like tail emission with the [OI]/H$α$ BPT diagnostic; (2) enhanced [OII]/H$α$ ratios in the tails relative to the disks; and (3) similarly elevated emission line velocities and velocity dispersions in the tails with respect to the disks. These results demonstrate that ram-pressure-driven shocks dominate the ionized emission in jellyfish galaxy tails.",
      "authors": [
        "Lauren M. Foster",
        "Ian D. Roberts",
        "Laura C. Parker",
        "Timothy A. Davis",
        "Alessandro Ignesti",
        "Sean McGee",
        "Nikki Zabel",
        "Ming Sun",
        "Reinout J. van Weeren"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-17 19:55:18+00:00",
      "link": "https://arxiv.org/pdf/2602.15976v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15949v1",
      "title": "The LOFAR Two-metre Sky Survey: VII. Third Data Release",
      "abstract": "We present the third data release of the LOFAR Two-metre Sky Survey (LoTSS-DR3). The survey images cover 88% of the northern sky and were created from 12,950 hrs of data (18.6 PB) accumulated over 10.5 years. The images were produced through direction-independent and direction-dependent calibration pipelines that correct for instrumental effects as well as spatially and temporally varying ionospheric distortions. In our 120-168 MHz continuum mosaic images with an angular resolution of 6 arcsec (9 arcsec below declination 10$^\\circ$) we catalogue 13,667,877 sources, formed from 16,943,656 Gaussian components. The scatter in the astrometric precision approximately follows the expected noise-like behaviour but with an additional systematic component of at least 0.24 arcsec that is likely due to calibration imperfections. The random flux density scale error is 6%, while the systematic offset was previously shown to be within 2%. The median sensitivity of our mosaics is 92$μ$Jy beam$^{-1}$. Completeness simulations, accounting for realistic source models, time- and bandwidth-smearing effects, and astrometric errors, indicate that we detect more than 95% of compact sources with integrated flux densities exceeding 9 times the local root mean square (RMS) noise. However, the recovered source counts in a particular integrated flux density bin do not match the injected counts until flux densities exceed 45 times the local RMS noise. The Euclidean-normalised differential source counts derived from the survey constrain the radio source population over five orders of magnitude and are in good agreement with previous deep and wide-area surveys. All data products are publicly available, including catalogues, individual-field Stokes I, Q, U, and V images, mosaicked Stokes I images, and $uv$ data with associated direction-dependent calibration solutions.",
      "authors": [
        "T. W. Shimwell",
        "M. J. Hardcastle",
        "C. Tasse",
        "A. Drabent",
        "A. Botteon",
        "W. L. Williams",
        "P. N. Best",
        "H. J. A. Röttgering",
        "M. Brüggen",
        "G. Brunetti",
        "J. R. Callingham",
        "K. T. Chyży",
        "J. E. Conway",
        "F. De Gasperin",
        "M. Haverkorn",
        "C. Horellou",
        "N. Jackson",
        "G. K. Miley",
        "L. K. Morabito",
        "R. Morganti",
        "S. P. O'Sullivan",
        "D. J. Schwarz",
        "D. J. B. Smith",
        "R. J. van Weeren",
        "H. K. Vedantham",
        "G. J. White",
        "A. Ahmadi",
        "L. Alegre",
        "M. Arias",
        "B. Asabere",
        "B. Bahr-Kalus",
        "B. Barkus",
        "M. Bilicki",
        "L. Böhme",
        "M. Brentjens",
        "M. Brienza",
        "D. J. Bomans",
        "A. Bonafede",
        "M. Bonato",
        "E. Bonnassieux",
        "J. M. Boxelaar",
        "S. Camera",
        "R. Cassano",
        "J. Chilufya",
        "M. Cianfaglione",
        "J. H. Croston",
        "V. Cuciti",
        "P. Dabhade",
        "E. De Rubeis",
        "J. M. G. H. J. de Jong",
        "D. Dallacasa",
        "R. J. Dettmar",
        "K. J. Duncan",
        "G. Di Gennaro",
        "H. W. Edler",
        "C. Groeneveld",
        "G. Gürkan",
        "M. Hajduk",
        "C. L. Hale",
        "V. Heesen",
        "D. N. Hoang",
        "M. Hoeft",
        "H. Holties",
        "M. A. Horton",
        "M. Iacobelli",
        "M. Jamrozy",
        "M. J. Jarvis",
        "V. Jelic",
        "M. Kadler",
        "R. Kondapally",
        "M. Kunert-Bajraszewska",
        "M. Loose",
        "M. Magliocchetti",
        "K. Małek",
        "C. Manzano",
        "J. P. McKean",
        "M. Mevius",
        "B. Mingo",
        "A. Miskolczi",
        "A. Misra",
        "J. Moldón",
        "D. G. Nair",
        "S. J. Nakoneczny",
        "E. Orru",
        "M. Pashapour-Ahmadabadi",
        "T. Pasini",
        "J. Petley",
        "J. C. S. Pierce",
        "I. Prandoni",
        "D. Rafferty",
        "K. Rajpurohit",
        "C. J. Riseley",
        "I. D. Roberts",
        "S. Sethi",
        "A. Shulevski",
        "M. Stein",
        "C. Stuardi",
        "F. Sweijen",
        "S. ter Veen",
        "R. Timmerman",
        "M. Vaccari",
        "S. Wijnholds"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA",
        "astro-ph.CO",
        "astro-ph.HE",
        "astro-ph.IM"
      ],
      "published": "2026-02-17 19:05:49+00:00",
      "link": "https://arxiv.org/pdf/2602.15949v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15930v1",
      "title": "A targeted machine learning approach for detecting diffuse radio emission with Astronomaly: Protege",
      "abstract": "Diffuse radio emission in galaxy clusters, such as radio halos, relics, and mini halos, is a key tracer of non-thermal processes, turbulence, and magnetic fields within the intra-cluster medium. However, their low surface brightness, as well as contamination from compact sources and imaging artefacts, makes their detection challenging. The sheer volume of data from instruments such as the Square Kilometre Array will render traditional manual-inspection based detection methods infeasible. This paper introduces a novel machine learning approach that uses active learning to rapidly identify diffuse emission candidates from a small, optimally-selected subset of data. We apply the self-supervised deep learning algorithm Bootstrap Your Own Latent to extract features from source cutouts in the MeerKAT Galaxy Cluster Legacy Survey (MGCLS). We then pass these features through the Astronomaly: Protege anomaly detection framework to identify the final candidates. Using a human-labelled set, we evaluate our pipeline on high-resolution (~7''), convolved (15''), and combined-feature MGCLS datasets. Interestingly, the high-resolution features identify diffuse sources more efficiently than the convolved resolution, which are in turn outperformed by the combined features. Of the top 100 sources ranked by Protege, 99% exhibit diffuse characteristics, with 55% confirmed as cluster-related emission. Our work shows that Protege can identify diffuse emission with minimal human labelling effort, offering a powerful, scalable tool capable of detecting both known and novel diffuse radio sources.",
      "authors": [
        "Verlon Etsebeth",
        "Michelle Lochner",
        "Konstantinos Kolokythas",
        "Kenda Knowles",
        "Emma Tolley"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-02-17 19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2602.15930v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15692v1",
      "title": "Hot subdwarf stars from the Hamburg Quasar Survey",
      "abstract": "Hot subluminous stars (sdO/B) are evolved low mass stars originating from red giants that lost their envelope almost entirely. The multitude of observed phenomena imply that several pathways may form hot subdwarfs, most involving close binary channels. The Hamburg Quasar Survey (HQS) led to the discovery of many faint blue stars including hot subdwarf. Many of the HQS-sdB stars have been studied in detail, but analyses of the helium-rich sdOB and sdO stars are lacking. The recent development of hybrid LTE/non-LTE model spectra 2nd generation Bamberg model grids enables us to improve the spectroscopic analyses of the sdB stars as well as of the previously unstudied sdO stars allowing precise atmospheric parameters to be derived, while consistently accounting for parameter correlations and systematic uncertainties. ... We use spectral energy distributions to identify composite-colour sdB binaries and present the result of detailed spectroscopic analyses of 122 non-composite subdwarfs from the HQS to identify potential evolutionary pathways. ...Their derived mass distribution and median mass of 0.45 Msun is consistent with the canonical EHB mass. ... The helium-rich sdOB and sdO stars, are found near the helium main-sequence (He-MS). The derived mass distribution of the extremely He-rich subdwarfs is broader (0.48 to 1.05 Msun) and peaks at a median of 0.70 Msun, significantly larger than those of the hydrogen-rich stars. Intermediate He-rich subdwarfs are also He-MS stars, but of lower mass (0.55 Msun) than the extremely He-rich. This strongly supports the merger scenario for the origin of He-rich sdO stars, in which two helium white dwarfs merge following orbital decay driven by gravitational-wave emission, producing a He-rich sdO or sdOB star. From comparison to the results of similar studies we speculate that older populations produce more massive He-WD mergers.(abbreviated)",
      "authors": [
        "Ulrich Heber",
        "Lennard Kufleitner",
        "Matti Dorsch",
        "Marilyn Latour",
        "Harry Dawson",
        "Fabian Mattig",
        "Stephan Geier"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR"
      ],
      "published": "2026-02-17 16:20:07+00:00",
      "link": "https://arxiv.org/pdf/2602.15692v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15561v1",
      "title": "Inference of horizontal velocity fields from the induction equation in the solar atmosphere. I. Analytical and numerical solutions in 2D",
      "abstract": "Spectroscopic and spectropolarimetric observations, which rely on the Doppler effect, only provide access to the line-of-sight component of the solar plasma velocity (vz). However, many dynamic processes in the solar atmosphere involve strong horizontal motions (in the plane perpendicular to the line-of-sight: vx, vy). Existing methods for estimating horizontal velocities are generally insensitive to variations in height (the z-coordinate), providing them only on a single plane perpendicular to the line-of-sight: vx(x,y), vy(x,y). Motivated by the fact that modern analysis techniques allow us to retrieve the height dependence of vz and B, our goal is to infer also this height dependence for the horizontal velocity field in the solar atmosphere. As a first step, we present, and test a method for the two-dimensional case on the (y,z) plane so as to show that the z dependence can be successfully retrieved. The components of the two-dimensional magnetic induction equation are discretized via finite differences, leading to an overdetermined system whose solution provides vy. The method assumes that B, its time variation, as well as vz are known. This is currently possible through modern Stokes inversion techniques applied to spatially and temporally resolved spectropolarimetric observations. Using analytically prescribed values and two-dimensional magneto-hydrodynamic simulations of the solar surface, we demonstrate that, in these idealized cases, the horizontal velocity component in a two-dimensional domain, can be successfully recovered with a mean error of about 1 %. The proposed method successfully retrieves the horizontal velocity field in the (y,z) plane, thereby establishing the foundation for future extensions to three-dimensional reconstructions of the horizontal velocity field.",
      "authors": [
        "H. Vila Crespo",
        "J. M. Borrero",
        "I. Milić",
        "G. Vigeesh",
        "A. Asensio Ramos"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR"
      ],
      "published": "2026-02-17 13:16:56+00:00",
      "link": "https://arxiv.org/pdf/2602.15561v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15459v1",
      "title": "A Quantum Genetic Algorithm with application to Cosmological Parameters Estimation",
      "abstract": "An Amplitude-Encoded Quantum Genetic Algorithm (AEQGA) has been developed to minimize $χ^2$ functions of different cosmological probes (Supernovae Type Ia, Baryon Acoustic Oscillations, Cosmic Microwave Background Radiation), to find the best-fit value for two cosmological parameters, namely the Hubble Constant and the density matter content of the Universe today. Our main aim is to pave the way to testing the adoption of quantum optimization in the inference of the cosmological parameters that describe the universe evolution. AEQGA computes the merit function classically, and then uses a quantum circuit to entangle the population and perform crossover and mutation operations. The results show consistency with the isocontours of the objective functions. We then tested the general behavior of AEQGA as a function of its hyperparameters and compared it with a second quantum genetic algorithm found in the literature as well as with classical algorithms, finding consistent results.",
      "authors": [
        "Giuseppe Sarracino",
        "Vincenzo Fabrizio Cardone",
        "Roberto Scaramella",
        "Giuseppe Riccio",
        "Andrea Bulgarelli",
        "Carlo Burigana",
        "Luca Cappelli",
        "Stefano Cavuoti",
        "Farida Farsian",
        "Irene Graziotti",
        "Massimo Meneghetti",
        "Giuseppe Murante",
        "Niccolò Parmiggiani",
        "Alessandro Rizzo",
        "Francesco Schillirò",
        "Vincenzo Testa",
        "Tiziana Trombetti"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-17 09:48:29+00:00",
      "link": "https://arxiv.org/pdf/2602.15459v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.15255v1",
      "title": "Helium superluminous SN 2021bnw : an explosion of a massive star with a pre-outburst",
      "abstract": "Superluminous supernovae (SLSNe) remain an intriguing topic in supernova (SN) transient astronomy. While the majority of SLSNe are shown to be explained by energy streaming from the newly born magnetar, there are others which are powered by different mechanisms. We analyse the pseudo-bolometric light curve of the nearby helium-rich SLSN 2021bnw. We built models and run hydrodynamics radiative-transfer simulations with STELLA. Our best-fit models include 15-22.5 Msun of ejecta enriched with 1.7 Msun of 56 Ni and carrying energy of 4 foe, and colliding w ith 7 Msun of circumstellar matter which match the observed light curve very well. The early data can be explained as cooling of an expanding shell with the mass of 0.5 Msun and kinetic energy of 0.7 foe. We tend to exclude a pulsational pair-instability (PPISN) origin for SLSN 2021bnw. Instead we conclude that SLSN 2021bnw was preferably a core-collapse explosion of a star with the initial mass of not less than 61 Msun aided by magnetorotational effects.",
      "authors": [
        "Alexandra Kozyreva",
        "Matteo Bugli",
        "Alexey Mironov",
        "Petr Baklanov"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.SR"
      ],
      "published": "2026-02-16 23:22:20+00:00",
      "link": "https://arxiv.org/pdf/2602.15255v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15123v1",
      "title": "AGN in massive galaxies identified via optical broadband variability: lessons from VST-COSMOS for future LSST science",
      "abstract": "We study the properties of 56 massive (M$_{\\rm{\\star}}$ > 10$^{10}$ M$_{\\odot}$) galaxies at $z<1$ that host AGN, detected via their broadband optical variability in the VST-COSMOS survey. VST-COSMOS provides a nearly-identical single visit depth ($r$ $\\sim$ 24.6 mag) and temporal baseline (eleven years) as the forthcoming Legacy Survey of Space and Time (LSST), albeit in a much smaller 1 deg$^2$ footprint (four orders of magnitude smaller than that of the LSST). We compare the properties (morphologies, the presence of interactions, rest-frame colours and environment) of our AGN to galaxies in a control sample, which are drawn from the non-variable population and matched in redshift and stellar mass to their AGN counterparts. The fraction of AGN with early-type morphology ($\\sim$55 per cent) and the fraction that is interacting ($\\sim$23 per cent) are similar to what is observed in the controls, suggesting that these AGN are not primarily triggered by interactions. Similarly, the AGN and controls do not show strong differences in their rest-frame $(u-z)$ colours or local environment, suggesting that neither the recent star formation histories nor the surroundings of the AGN are strongly atypical of the general galaxy population. This study provides a glimpse into forthcoming AGN science using the LSST. With vastly improved statistics, LSST will offer unprecedented insights into AGN demographics, host-galaxy evolution and the processes that fuel supermassive black holes, potentially reshaping our understanding of their place in the Universe.",
      "authors": [
        "B. Bichang'a",
        "D. De Cicco",
        "S. Kaviraj",
        "I. Lazar",
        "A. Watkins",
        "G. Martin",
        "D. Kakkad"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-02-16 19:01:31+00:00",
      "link": "https://arxiv.org/pdf/2602.15123v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15107v1",
      "title": "Barium Stars Across the Milky Way: Probing Their Origins via the GALAH Survey",
      "abstract": "Barium stars are unusually enriched in barium ([Ba/Fe] >= 1.0 dex) and not predicted by current Galactic chemical evolution models. Previous observations of barium stars have found evidence that they form through mass transfer from a companion asymptotic giant branch (AGB) star or through radiative levitation. The chemical abundance and kinematic information of barium stars may help constrain AGB stellar nucleosynthesis, binary star evolution, and internal evolutionary processes that affect surface abundances. Using ~450,000 stars from the GALactic Archaeology with Hermes (GALAH) survey, we identify nearly 3000 new barium-rich stars and separate them into hot (Teff > 6000 K) and cool (Teff < 6000 K) populations. Cross-matching with Gaia DR3, we find that 47.7% of our barium stars within 1 kpc have elevated re-normalized unit weight error (RUWE >= 1.4), compared to 16.3% of a comparable sample of the GALAH field, suggesting multiplicity plays an important role in the formation of both populations of barium stars. A subset of hot barium stars exhibit low RUWE (RUWE < 1.2) and [alpha/Fe] < -0.2, supporting radiative levitation as an origin as well. We determine Galactic memberships using both kinematics and chemistry and find that barium stars exist in the thin disk, thick disk, and halo though they are slightly more prevalent at lower metallicities. Overall, we show evidence for barium stars produced by mass transfer and for those produced by radiative levitation, with both formation mechanisms occurring ubiquitously across the Galaxy.",
      "authors": [
        "Jaden Levine",
        "Catherine Manea",
        "Keith Hawkins",
        "Kendall Sullivan",
        "Kate H. R. Rubin",
        "Zachary Maas",
        "Andrew C. Nine"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA",
        "astro-ph.SR"
      ],
      "published": "2026-02-16 19:00:02+00:00",
      "link": "https://arxiv.org/pdf/2602.15107v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15105v1",
      "title": "Searching for Extragalactic Exoplanets: A Survey of the Sagittarius Dwarf Galaxy Stream with TESS",
      "abstract": "To date no exoplanets have been detected outside the Milky Way, and their extragalactic occurrence rates are poorly constrained. Using available data from TESS we perform the first transit survey of the Sagittarius dwarf galaxy stream using 15,176 main sequence stars identified as likely members. We calculate an upper limit of $<$1.01% for hot Jupiters with radii of 1-2 R$_{Jup}$ and periods of 0.6-10 days after detecting zero planets. We compare our calculated occurrence rate upper limits to the upper limits found in the Milky Way globular clusters M4 and 47 Tuc. Our 1-$σ$ occurrence rate upper limit of $<$0.37% for the Sagittarius dwarf galaxy stream, for planets with radii of 1.5-2 R$_{Jup}$ and periods $<$10 days, is lower than the $<$0.57% upper limit measured in 47 Tuc. Similarly, our 2 sigma upper limit of $<$0.78% for planets with radii of 1.4-2 $_{Jup}$ and periods $<$8 days is below the $<$0.81% upper limit measured in M4. We predict that a future analysis of TESS data with a high detection efficiency for hot Jupiter transit depths would require $η_{extragalactic}$ $\\geq$ 11,467 target stars to detect a planet of extragalactic origin. Therefore, we predict that a future investigation of TESS data which includes additional extragalactic stellar streams will be able to either detect the first extragalactic origin planet or provide evidence that older, lower metallicity extragalactic environments may experience a lower hot Jupiter occurrence rate than is observed for the Milky Way.",
      "authors": [
        "William Schap",
        "Jason Dittmann",
        "Elizabeth Lada"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP",
        "astro-ph.GA",
        "astro-ph.IM",
        "astro-ph.SR"
      ],
      "published": "2026-02-16 19:00:02+00:00",
      "link": "https://arxiv.org/pdf/2602.15105v1",
      "tags": [
        "keyword:SR"
      ]
    }
  ],
  "queries": [
    {
      "type": "keyword",
      "tag": "SR",
      "paper_tag": "keyword:SR",
      "query_text": "Symbolic Regression physics astronomy survey",
      "logic_cn": "重点关注符号回归在物理或天文中的应用，排除综述类论文。",
      "boolean_expr": "",
      "bm25_mode": "normal",
      "sim_scores": {
        "2602.12259v1": {
          "score": 10.309999181781262,
          "rank": 1
        },
        "2602.15085v1": {
          "score": 10.11027727984748,
          "rank": 2
        },
        "2602.16166v1": {
          "score": 8.978168712175023,
          "rank": 3
        },
        "2602.15296v1": {
          "score": 8.349606280641831,
          "rank": 4
        },
        "2602.10576v1": {
          "score": 7.655889488488952,
          "rank": 5
        },
        "2602.16415v1": {
          "score": 7.552554919837647,
          "rank": 6
        },
        "2602.15169v1": {
          "score": 7.473395756409902,
          "rank": 7
        },
        "2602.10427v1": {
          "score": 6.379749614333969,
          "rank": 8
        },
        "2602.13021v2": {
          "score": 6.367554724946638,
          "rank": 9
        },
        "2602.09443v1": {
          "score": 6.161692991255695,
          "rank": 10
        },
        "2602.11666v1": {
          "score": 6.031202483573409,
          "rank": 11
        },
        "2602.13992v1": {
          "score": 5.547724170529572,
          "rank": 12
        },
        "2602.10598v1": {
          "score": 5.2608044557920755,
          "rank": 13
        },
        "2602.10480v2": {
          "score": 5.0835908376307435,
          "rank": 14
        },
        "2602.12311v1": {
          "score": 5.00089016354567,
          "rank": 15
        },
        "2602.15255v1": {
          "score": 4.9895529941917225,
          "rank": 16
        },
        "2602.15743v1": {
          "score": 4.97536304701343,
          "rank": 17
        },
        "2602.15603v1": {
          "score": 4.94132823116149,
          "rank": 18
        },
        "2602.13419v1": {
          "score": 4.903213010963956,
          "rank": 19
        },
        "2602.15353v1": {
          "score": 4.8680302036483285,
          "rank": 20
        },
        "2602.14335v1": {
          "score": 4.863412259819285,
          "rank": 21
        },
        "2602.11583v1": {
          "score": 4.785554297557059,
          "rank": 22
        },
        "2602.14918v1": {
          "score": 4.779828695861309,
          "rank": 23
        },
        "2602.12232v1": {
          "score": 4.76586087004136,
          "rank": 24
        },
        "2602.12851v1": {
          "score": 4.735464840700424,
          "rank": 25
        },
        "2602.09303v1": {
          "score": 4.6677449228683106,
          "rank": 26
        },
        "2602.12889v1": {
          "score": 4.667658505577067,
          "rank": 27
        },
        "2602.11414v1": {
          "score": 4.636077011007357,
          "rank": 28
        },
        "2602.09149v1": {
          "score": 4.572921427990069,
          "rank": 29
        },
        "2602.12706v1": {
          "score": 4.534416604052494,
          "rank": 30
        },
        "2602.12442v1": {
          "score": 4.529546220468237,
          "rank": 31
        },
        "2602.09980v1": {
          "score": 4.503913827695296,
          "rank": 32
        },
        "2602.09761v1": {
          "score": 4.485123595605202,
          "rank": 33
        },
        "2602.11097v1": {
          "score": 4.475717966482035,
          "rank": 34
        },
        "2602.13834v1": {
          "score": 4.47386929751552,
          "rank": 35
        },
        "2602.16000v1": {
          "score": 4.4736162725947475,
          "rank": 36
        },
        "2602.14108v1": {
          "score": 4.424280068242325,
          "rank": 37
        },
        "2602.11291v1": {
          "score": 4.4240170957558105,
          "rank": 38
        },
        "2602.15068v1": {
          "score": 4.374011052830765,
          "rank": 39
        },
        "2602.13873v1": {
          "score": 4.371290683523362,
          "rank": 40
        },
        "2602.12238v1": {
          "score": 4.352467588539449,
          "rank": 41
        },
        "2602.15954v1": {
          "score": 4.3511932387609775,
          "rank": 42
        },
        "2602.11208v1": {
          "score": 4.310113941705612,
          "rank": 43
        },
        "2602.09223v1": {
          "score": 4.22286373740347,
          "rank": 44
        },
        "2602.12109v1": {
          "score": 4.167156444319055,
          "rank": 45
        },
        "2602.09709v1": {
          "score": 4.167094246062746,
          "rank": 46
        },
        "2602.10611v1": {
          "score": 4.162979829815299,
          "rank": 47
        },
        "2602.15295v1": {
          "score": 4.149957726894719,
          "rank": 48
        },
        "2602.10836v1": {
          "score": 4.143795947644979,
          "rank": 49
        },
        "2602.14601v1": {
          "score": 4.1413722881472514,
          "rank": 50
        },
        "2602.15993v1": {
          "score": 4.132174608101173,
          "rank": 51
        },
        "2602.15618v1": {
          "score": 4.126711262152257,
          "rank": 52
        },
        "2602.12011v1": {
          "score": 4.1001322116948025,
          "rank": 53
        },
        "2602.15057v1": {
          "score": 4.084304943491813,
          "rank": 54
        },
        "2602.09550v1": {
          "score": 4.081622726792248,
          "rank": 55
        },
        "2602.11021v1": {
          "score": 4.05975845154346,
          "rank": 56
        },
        "2602.11313v1": {
          "score": 4.004063763076075,
          "rank": 57
        },
        "2602.14835v1": {
          "score": 3.9945305035248757,
          "rank": 58
        },
        "2602.13936v1": {
          "score": 3.984341653268352,
          "rank": 59
        },
        "2602.09708v1": {
          "score": 3.9790618158826274,
          "rank": 60
        },
        "2602.16176v1": {
          "score": 3.9737959530971922,
          "rank": 61
        },
        "2602.11230v1": {
          "score": 3.9638565001380606,
          "rank": 62
        },
        "2602.15027v1": {
          "score": 3.9633059299863653,
          "rank": 63
        },
        "2602.14440v1": {
          "score": 3.9492584589550384,
          "rank": 64
        },
        "2602.14082v1": {
          "score": 3.863944597451392,
          "rank": 65
        },
        "2602.13386v1": {
          "score": 3.795846738323032,
          "rank": 66
        },
        "2602.13583v1": {
          "score": 3.7947346524901793,
          "rank": 67
        },
        "2602.09145v1": {
          "score": 3.7905052043022325,
          "rank": 68
        },
        "2602.10009v1": {
          "score": 3.7835264336168097,
          "rank": 69
        },
        "2602.10451v1": {
          "score": 3.745768262165151,
          "rank": 70
        },
        "2602.09720v1": {
          "score": 3.739658399853604,
          "rank": 71
        },
        "2602.16514v1": {
          "score": 3.739125816165715,
          "rank": 72
        },
        "2602.11864v1": {
          "score": 3.735229334063141,
          "rank": 73
        },
        "2602.11265v1": {
          "score": 3.725209466879447,
          "rank": 74
        },
        "2602.15592v1": {
          "score": 3.708756268849233,
          "rank": 75
        },
        "2602.15468v1": {
          "score": 3.6976852369720694,
          "rank": 76
        },
        "2602.15312v1": {
          "score": 3.6912144839627405,
          "rank": 77
        },
        "2602.12717v1": {
          "score": 3.6908676143873995,
          "rank": 78
        },
        "2602.16167v1": {
          "score": 3.6814737451892707,
          "rank": 79
        },
        "2602.11621v1": {
          "score": 3.6501471346665695,
          "rank": 80
        },
        "2602.10745v1": {
          "score": 3.639107336041408,
          "rank": 81
        },
        "2602.13811v1": {
          "score": 3.6372185198066633,
          "rank": 82
        },
        "2602.13805v1": {
          "score": 3.6372185198066633,
          "rank": 83
        },
        "2602.12174v1": {
          "score": 3.630045035314081,
          "rank": 84
        },
        "2602.09988v1": {
          "score": 3.617500025947521,
          "rank": 85
        },
        "2602.14803v2": {
          "score": 3.6044727135145287,
          "rank": 86
        },
        "2602.12870v1": {
          "score": 3.6037160963291983,
          "rank": 87
        },
        "2602.14968v1": {
          "score": 3.593361572260023,
          "rank": 88
        },
        "2602.10587v1": {
          "score": 3.582816332992085,
          "rank": 89
        },
        "2602.11104v1": {
          "score": 3.5723112659433216,
          "rank": 90
        },
        "2602.16117v1": {
          "score": 3.5723112659433216,
          "rank": 91
        },
        "2602.09487v1": {
          "score": 3.5719886315716893,
          "rank": 92
        },
        "2602.15512v1": {
          "score": 3.553288417130326,
          "rank": 93
        },
        "2602.11094v1": {
          "score": 3.5469924091849925,
          "rank": 94
        },
        "2602.13101v1": {
          "score": 3.5466743317632448,
          "rank": 95
        },
        "2602.13809v1": {
          "score": 3.542472185542164,
          "rank": 96
        },
        "2602.10274v1": {
          "score": 3.53610888391646,
          "rank": 97
        },
        "2602.10681v1": {
          "score": 3.521716306523284,
          "rank": 98
        },
        "2602.16151v1": {
          "score": 3.5206700121791883,
          "rank": 99
        },
        "2602.16256v1": {
          "score": 3.5162049004033133,
          "rank": 100
        },
        "2602.12898v1": {
          "score": 3.5158441039889423,
          "rank": 101
        },
        "2602.15754v1": {
          "score": 3.4996763159997384,
          "rank": 102
        },
        "2602.12633v1": {
          "score": 3.4974163355277685,
          "rank": 103
        },
        "2602.16193v1": {
          "score": 3.4974163355277685,
          "rank": 104
        },
        "2602.16645v1": {
          "score": 3.4974163355277685,
          "rank": 105
        },
        "2602.10432v1": {
          "score": 3.4791807326173583,
          "rank": 106
        },
        "2602.11290v2": {
          "score": 3.4626066970111458,
          "rank": 107
        },
        "2602.15684v1": {
          "score": 3.4613560539113273,
          "rank": 108
        },
        "2602.13902v1": {
          "score": 3.4610831058172034,
          "rank": 109
        },
        "2602.11136v2": {
          "score": 3.454467206877086,
          "rank": 110
        },
        "2602.11630v1": {
          "score": 3.448844442244473,
          "rank": 111
        },
        "2602.12486v1": {
          "score": 3.4432741240729627,
          "rank": 112
        },
        "2602.09458v1": {
          "score": 3.4432741240729627,
          "rank": 113
        },
        "2602.10746v1": {
          "score": 3.4376536471442303,
          "rank": 114
        },
        "2602.13689v1": {
          "score": 3.4373616211189413,
          "rank": 115
        },
        "2602.09798v1": {
          "score": 3.4265352408414333,
          "rank": 116
        },
        "2602.13608v1": {
          "score": 3.425597321471182,
          "rank": 117
        },
        "2602.13729v1": {
          "score": 3.4244630900841058,
          "rank": 118
        },
        "2602.13537v2": {
          "score": 3.4199540340635752,
          "rank": 119
        },
        "2602.12864v1": {
          "score": 3.391622740616687,
          "rank": 120
        },
        "2602.12114v1": {
          "score": 3.3881808534367948,
          "rank": 121
        },
        "2602.13523v1": {
          "score": 3.380200964717009,
          "rank": 122
        },
        "2602.10150v1": {
          "score": 3.379334509280648,
          "rank": 123
        },
        "2602.15184v1": {
          "score": 3.379334509280648,
          "rank": 124
        },
        "2602.13362v1": {
          "score": 3.346666039807205,
          "rank": 125
        },
        "2602.11757v1": {
          "score": 3.3454492025097817,
          "rank": 126
        },
        "2602.09996v2": {
          "score": 3.335328569639652,
          "rank": 127
        },
        "2602.15533v1": {
          "score": 3.328760109263869,
          "rank": 128
        },
        "2602.16376v1": {
          "score": 3.322528819047497,
          "rank": 129
        },
        "2602.09905v1": {
          "score": 3.3145794207983412,
          "rank": 130
        },
        "2602.13314v1": {
          "score": 3.30131192556492,
          "rank": 131
        },
        "2602.09498v1": {
          "score": 3.2904589809730567,
          "rank": 132
        },
        "2602.10176v1": {
          "score": 3.2891684474735126,
          "rank": 133
        },
        "2602.16671v1": {
          "score": 3.283181483448456,
          "rank": 134
        },
        "2602.14480v1": {
          "score": 3.2764532004118934,
          "rank": 135
        },
        "2602.15949v1": {
          "score": 3.2722852423381203,
          "rank": 136
        },
        "2602.13152v1": {
          "score": 3.25935792025363,
          "rank": 137
        },
        "2602.13385v1": {
          "score": 3.258324109905624,
          "rank": 138
        },
        "2602.12242v2": {
          "score": 3.253029221703982,
          "rank": 139
        },
        "2602.14642v1": {
          "score": 3.2372473086692786,
          "rank": 140
        },
        "2602.09647v1": {
          "score": 3.2372473086692786,
          "rank": 141
        },
        "2602.09774v1": {
          "score": 3.233085000576978,
          "rank": 142
        },
        "2602.13054v1": {
          "score": 3.232020645020336,
          "rank": 143
        },
        "2602.11229v1": {
          "score": 3.2268108314760564,
          "rank": 144
        },
        "2602.13079v1": {
          "score": 3.2268108314760564,
          "rank": 145
        },
        "2602.11238v1": {
          "score": 3.2152207057999926,
          "rank": 146
        },
        "2602.16463v1": {
          "score": 3.2132527285424253,
          "rank": 147
        },
        "2602.16081v1": {
          "score": 3.2061384591076054,
          "rank": 148
        },
        "2602.14085v1": {
          "score": 3.2061384591076054,
          "rank": 149
        },
        "2602.09232v1": {
          "score": 3.201011686189343,
          "rank": 150
        },
        "2602.10365v1": {
          "score": 3.1844943372749754,
          "rank": 151
        },
        "2602.15652v1": {
          "score": 3.180667511701598,
          "rank": 152
        },
        "2602.13708v1": {
          "score": 3.175621809706623,
          "rank": 153
        },
        "2602.15662v1": {
          "score": 3.175621809706623,
          "rank": 154
        },
        "2602.13377v1": {
          "score": 3.1638488360792407,
          "rank": 155
        },
        "2602.16371v1": {
          "score": 3.160580300712136,
          "rank": 156
        },
        "2602.11302v1": {
          "score": 3.160580300712136,
          "rank": 157
        },
        "2602.11700v1": {
          "score": 3.15642650312861,
          "rank": 158
        },
        "2602.10381v1": {
          "score": 3.1483707559285543,
          "rank": 159
        },
        "2602.13520v2": {
          "score": 3.145680609872829,
          "rank": 160
        },
        "2602.16091v1": {
          "score": 3.1373426050569413,
          "rank": 161
        },
        "2602.15992v1": {
          "score": 3.136571353112804,
          "rank": 162
        },
        "2602.09102v1": {
          "score": 3.135825283150183,
          "rank": 163
        },
        "2602.14663v1": {
          "score": 3.1309207409109696,
          "rank": 164
        },
        "2602.13778v1": {
          "score": 3.126031516471068,
          "rank": 165
        },
        "2602.12399v1": {
          "score": 3.124167465286386,
          "rank": 166
        },
        "2602.09658v2": {
          "score": 3.117864521614068,
          "rank": 167
        },
        "2602.15021v1": {
          "score": 3.1140927595359926,
          "rank": 168
        },
        "2602.14561v1": {
          "score": 3.111455035688242,
          "rank": 169
        },
        "2602.12793v1": {
          "score": 3.110330112029816,
          "rank": 170
        },
        "2602.12117v1": {
          "score": 3.097013862331366,
          "rank": 171
        },
        "2602.16665v1": {
          "score": 3.097013862331366,
          "rank": 172
        },
        "2602.10613v1": {
          "score": 3.077039141480566,
          "rank": 173
        },
        "2602.14826v1": {
          "score": 3.0743123642826626,
          "rank": 174
        },
        "2602.14599v1": {
          "score": 3.0732408454695834,
          "rank": 175
        },
        "2602.12534v1": {
          "score": 3.059797266195867,
          "rank": 176
        },
        "2602.12853v1": {
          "score": 3.050535723718758,
          "rank": 177
        },
        "2602.16090v1": {
          "score": 3.045190586589116,
          "rank": 178
        },
        "2602.15780v1": {
          "score": 3.044124186598024,
          "rank": 179
        },
        "2602.10557v1": {
          "score": 3.040801307677795,
          "rank": 180
        },
        "2602.09167v1": {
          "score": 3.0377605357451323,
          "rank": 181
        },
        "2602.12365v1": {
          "score": 3.0359539426765725,
          "rank": 182
        },
        "2602.15751v1": {
          "score": 3.031356601278426,
          "rank": 183
        },
        "2602.16586v1": {
          "score": 3.021232153223774,
          "rank": 184
        },
        "2602.09963v1": {
          "score": 3.0176477402647652,
          "rank": 185
        },
        "2602.12608v1": {
          "score": 3.0176477402647652,
          "rank": 186
        },
        "2602.10170v1": {
          "score": 3.013105632360987,
          "rank": 187
        },
        "2602.09351v1": {
          "score": 2.990225911275897,
          "rank": 188
        },
        "2602.13394v1": {
          "score": 2.986137556236708,
          "rank": 189
        },
        "2602.13690v1": {
          "score": 2.9816897402783606,
          "rank": 190
        },
        "2602.16002v1": {
          "score": 2.977255154550445,
          "rank": 191
        },
        "2602.16656v1": {
          "score": 2.968425438362659,
          "rank": 192
        },
        "2602.09871v1": {
          "score": 2.9431909257411446,
          "rank": 193
        },
        "2602.09734v1": {
          "score": 2.942904548743172,
          "rank": 194
        },
        "2602.12348v1": {
          "score": 2.9422477566090794,
          "rank": 195
        },
        "2602.11888v1": {
          "score": 2.9293312956769615,
          "rank": 196
        },
        "2602.15820v1": {
          "score": 2.920590035899252,
          "rank": 197
        },
        "2602.12935v1": {
          "score": 2.916765367299873,
          "rank": 198
        },
        "2602.12343v1": {
          "score": 2.911816426596742,
          "rank": 199
        },
        "2602.10859v1": {
          "score": 2.9099207494622807,
          "rank": 200
        },
        "2602.13876v1": {
          "score": 2.908695657840763,
          "rank": 201
        },
        "2602.09489v1": {
          "score": 2.8851810751148155,
          "rank": 202
        },
        "2602.15904v1": {
          "score": 2.882471901299166,
          "rank": 203
        },
        "2602.16531v1": {
          "score": 2.8702672812259302,
          "rank": 204
        },
        "2602.16230v1": {
          "score": 2.8664135509643383,
          "rank": 205
        },
        "2602.14662v1": {
          "score": 2.8632352765271936,
          "rank": 206
        },
        "2602.14387v1": {
          "score": 2.8489754657046795,
          "rank": 207
        },
        "2602.10750v1": {
          "score": 2.8457506577948095,
          "rank": 208
        },
        "2602.09456v1": {
          "score": 2.8312406930188545,
          "rank": 209
        },
        "2602.09230v1": {
          "score": 2.83018187304684,
          "rank": 210
        },
        "2602.09778v1": {
          "score": 2.818594954381765,
          "rank": 211
        },
        "2602.09279v1": {
          "score": 2.816877944951851,
          "rank": 212
        },
        "2602.12988v1": {
          "score": 2.802809366159479,
          "rank": 213
        },
        "2602.09543v1": {
          "score": 2.7979527715650483,
          "rank": 214
        },
        "2602.09589v1": {
          "score": 2.7842650653043077,
          "rank": 215
        },
        "2602.15074v1": {
          "score": 2.779870369207588,
          "rank": 216
        },
        "2602.12845v1": {
          "score": 2.7797551966576384,
          "rank": 217
        },
        "2602.11682v1": {
          "score": 2.779459749877909,
          "rank": 218
        },
        "2602.10265v1": {
          "score": 2.7608552015557173,
          "rank": 219
        },
        "2602.16606v1": {
          "score": 2.7608552015557173,
          "rank": 220
        },
        "2602.09113v1": {
          "score": 2.749259213356116,
          "rank": 221
        },
        "2602.14324v1": {
          "score": 2.7489254555616514,
          "rank": 222
        },
        "2602.12379v1": {
          "score": 2.738164670333412,
          "rank": 223
        },
        "2602.11535v1": {
          "score": 2.726461402544461,
          "rank": 224
        },
        "2602.15494v1": {
          "score": 2.726461402544461,
          "rank": 225
        },
        "2602.16481v1": {
          "score": 2.715737587627389,
          "rank": 226
        },
        "2602.11916v1": {
          "score": 2.7116882340849253,
          "rank": 227
        },
        "2602.09739v1": {
          "score": 2.7116882340849253,
          "rank": 228
        },
        "2602.12465v1": {
          "score": 2.7070173911719637,
          "rank": 229
        },
        "2602.09151v1": {
          "score": 2.7059105324899164,
          "rank": 230
        },
        "2602.12489v1": {
          "score": 2.7026255321790886,
          "rank": 231
        },
        "2602.09743v1": {
          "score": 2.6970742978987916,
          "rank": 232
        },
        "2602.11569v1": {
          "score": 2.6925296296086136,
          "rank": 233
        },
        "2602.10417v1": {
          "score": 2.689826239563274,
          "rank": 234
        },
        "2602.09472v1": {
          "score": 2.6881743363220996,
          "rank": 235
        },
        "2602.14537v1": {
          "score": 2.6881743363220996,
          "rank": 236
        },
        "2602.13039v2": {
          "score": 2.6805513309364803,
          "rank": 237
        },
        "2602.13011v1": {
          "score": 2.6678662983971586,
          "rank": 238
        },
        "2602.14029v1": {
          "score": 2.6637308530909207,
          "rank": 239
        },
        "2602.16357v1": {
          "score": 2.6541625483600946,
          "rank": 240
        },
        "2602.12569v1": {
          "score": 2.6412614575209488,
          "rank": 241
        },
        "2602.11678v1": {
          "score": 2.6412614575209488,
          "rank": 242
        },
        "2602.10996v1": {
          "score": 2.6412614575209488,
          "rank": 243
        },
        "2602.11617v1": {
          "score": 2.634658804883089,
          "rank": 244
        },
        "2602.13490v1": {
          "score": 2.6332146921149615,
          "rank": 245
        },
        "2602.15104v1": {
          "score": 2.6332146921149615,
          "rank": 246
        },
        "2602.15976v1": {
          "score": 2.6306202192255146,
          "rank": 247
        },
        "2602.16554v1": {
          "score": 2.626305360559162,
          "rank": 248
        },
        "2602.13627v1": {
          "score": 2.626305360559162,
          "rank": 249
        },
        "2602.13862v1": {
          "score": 2.622580078111478,
          "rank": 250
        },
        "2602.10471v1": {
          "score": 2.613579940289777,
          "rank": 251
        },
        "2602.09089v1": {
          "score": 2.612594906577124,
          "rank": 252
        },
        "2602.09779v1": {
          "score": 2.6106115969827974,
          "rank": 253
        },
        "2602.15050v1": {
          "score": 2.5990268582180818,
          "rank": 254
        },
        "2602.13190v1": {
          "score": 2.5990268582180818,
          "rank": 255
        },
        "2602.09378v1": {
          "score": 2.5972799998458096,
          "rank": 256
        },
        "2602.13471v1": {
          "score": 2.5948225223736605,
          "rank": 257
        },
        "2602.10963v1": {
          "score": 2.5922955446069254,
          "rank": 258
        },
        "2602.14362v1": {
          "score": 2.5922955446069254,
          "rank": 259
        },
        "2602.13849v1": {
          "score": 2.585599008269748,
          "rank": 260
        },
        "2602.11844v1": {
          "score": 2.585599008269748,
          "rank": 261
        },
        "2602.10320v1": {
          "score": 2.5832980851810237,
          "rank": 262
        },
        "2602.09809v1": {
          "score": 2.5832980851810237,
          "rank": 263
        },
        "2602.11068v1": {
          "score": 2.5831054848972363,
          "rank": 264
        },
        "2602.15107v1": {
          "score": 2.5831054848972363,
          "rank": 265
        },
        "2602.09093v1": {
          "score": 2.578936980386248,
          "rank": 266
        },
        "2602.12093v2": {
          "score": 2.5657153884808386,
          "rank": 267
        },
        "2602.12707v1": {
          "score": 2.5529477683207,
          "rank": 268
        },
        "2602.09536v1": {
          "score": 2.5529477683207,
          "rank": 269
        },
        "2602.15123v1": {
          "score": 2.5485807922863555,
          "rank": 270
        },
        "2602.13526v1": {
          "score": 2.546135250535678,
          "rank": 271
        },
        "2602.13137v1": {
          "score": 2.544801599051416,
          "rank": 272
        },
        "2602.12368v1": {
          "score": 2.53967478045128,
          "rank": 273
        },
        "2602.16273v1": {
          "score": 2.53967478045128,
          "rank": 274
        },
        "2602.15105v1": {
          "score": 2.5372767372854166,
          "rank": 275
        },
        "2602.10386v1": {
          "score": 2.5338699696555977,
          "rank": 276
        },
        "2602.15224v1": {
          "score": 2.533247012508763,
          "rank": 277
        },
        "2602.14088v1": {
          "score": 2.533247012508763,
          "rank": 278
        },
        "2602.09801v1": {
          "score": 2.527824133133806,
          "rank": 279
        },
        "2602.14947v1": {
          "score": 2.5204885948451086,
          "rank": 280
        },
        "2602.15951v1": {
          "score": 2.5204885948451086,
          "rank": 281
        },
        "2602.11963v1": {
          "score": 2.5204885948451086,
          "rank": 282
        },
        "2602.16649v1": {
          "score": 2.514157457227437,
          "rank": 283
        },
        "2602.10987v1": {
          "score": 2.514157457227437,
          "rank": 284
        },
        "2602.13999v1": {
          "score": 2.507858045896384,
          "rank": 285
        },
        "2602.11825v1": {
          "score": 2.5073643033452013,
          "rank": 286
        },
        "2602.10840v1": {
          "score": 2.5015901229701623,
          "rank": 287
        },
        "2602.11563v1": {
          "score": 2.4953534529392183,
          "rank": 288
        },
        "2602.11359v1": {
          "score": 2.489147802636736,
          "rank": 289
        },
        "2602.10325v1": {
          "score": 2.485823474219233,
          "rank": 290
        },
        "2602.11425v1": {
          "score": 2.482972941209582,
          "rank": 291
        },
        "2602.15990v1": {
          "score": 2.482972941209582,
          "rank": 292
        },
        "2602.11642v1": {
          "score": 2.476828640089672,
          "rank": 293
        },
        "2602.11037v1": {
          "score": 2.476828640089672,
          "rank": 294
        },
        "2602.16041v1": {
          "score": 2.476828640089672,
          "rank": 295
        },
        "2602.11997v1": {
          "score": 2.476828640089672,
          "rank": 296
        },
        "2602.11556v1": {
          "score": 2.476828640089672,
          "rank": 297
        },
        "2602.12218v1": {
          "score": 2.470714672965775,
          "rank": 298
        },
        "2602.10041v1": {
          "score": 2.470714672965775,
          "rank": 299
        },
        "2602.12948v1": {
          "score": 2.464630815755723,
          "rank": 300
        },
        "2602.12929v2": {
          "score": 2.460871550489601,
          "rank": 301
        },
        "2602.16390v1": {
          "score": 2.4585768465790343,
          "rank": 302
        },
        "2602.13765v1": {
          "score": 2.4585768465790343,
          "rank": 303
        },
        "2602.15183v1": {
          "score": 2.4574618212193253,
          "rank": 304
        },
        "2602.10903v1": {
          "score": 2.452552545729941,
          "rank": 305
        },
        "2602.13570v1": {
          "score": 2.452552545729941,
          "rank": 306
        },
        "2602.14969v1": {
          "score": 2.452003641277841,
          "rank": 307
        },
        "2602.14628v1": {
          "score": 2.450330554705051,
          "rank": 308
        },
        "2602.11989v1": {
          "score": 2.446836928264562,
          "rank": 309
        },
        "2602.14563v1": {
          "score": 2.44655769565081,
          "rank": 310
        },
        "2602.14549v1": {
          "score": 2.44655769565081,
          "rank": 311
        },
        "2602.16023v1": {
          "score": 2.443881587073772,
          "rank": 312
        },
        "2602.12695v1": {
          "score": 2.4369409087426512,
          "rank": 313
        },
        "2602.14031v1": {
          "score": 2.4346554881558147,
          "rank": 314
        },
        "2602.09881v1": {
          "score": 2.4346554881558147,
          "rank": 315
        },
        "2602.12095v2": {
          "score": 2.4287477061315528,
          "rank": 316
        },
        "2602.14494v1": {
          "score": 2.4287477061315528,
          "rank": 317
        },
        "2602.12140v1": {
          "score": 2.4287477061315528,
          "rank": 318
        },
        "2602.11503v1": {
          "score": 2.4287477061315528,
          "rank": 319
        },
        "2602.15188v1": {
          "score": 2.422868525609962,
          "rank": 320
        },
        "2602.12227v1": {
          "score": 2.422868525609962,
          "rank": 321
        },
        "2602.11098v1": {
          "score": 2.422868525609962,
          "rank": 322
        },
        "2602.14087v1": {
          "score": 2.4158369126625674,
          "rank": 323
        },
        "2602.12244v1": {
          "score": 2.412690126592032,
          "rank": 324
        },
        "2602.14979v1": {
          "score": 2.4111951422623585,
          "rank": 325
        },
        "2602.16297v1": {
          "score": 2.4111951422623585,
          "rank": 326
        },
        "2602.15482v1": {
          "score": 2.4111951422623585,
          "rank": 327
        },
        "2602.13158v2": {
          "score": 2.409568000825755,
          "rank": 328
        },
        "2602.10240v1": {
          "score": 2.399633704310544,
          "rank": 329
        },
        "2602.14630v1": {
          "score": 2.399633704310544,
          "rank": 330
        },
        "2602.11084v1": {
          "score": 2.3995595424903944,
          "rank": 331
        },
        "2602.14113v1": {
          "score": 2.388182609138194,
          "rank": 332
        },
        "2602.12385v1": {
          "score": 2.3824979476214936,
          "rank": 333
        },
        "2602.09334v1": {
          "score": 2.3824979476214936,
          "rank": 334
        },
        "2602.10462v1": {
          "score": 2.3768402845745538,
          "rank": 335
        },
        "2602.15692v1": {
          "score": 2.372420945649045,
          "rank": 336
        },
        "2602.10968v2": {
          "score": 2.3712094281150997,
          "rank": 337
        },
        "2602.10351v1": {
          "score": 2.3712094281150997,
          "rank": 338
        },
        "2602.16550v1": {
          "score": 2.3712094281150997,
          "rank": 339
        },
        "2602.11111v1": {
          "score": 2.3656051881748734,
          "rank": 340
        },
        "2602.15574v1": {
          "score": 2.3656051881748734,
          "rank": 341
        },
        "2602.11525v1": {
          "score": 2.3656051881748734,
          "rank": 342
        },
        "2602.14475v1": {
          "score": 2.360027376478248,
          "rank": 343
        },
        "2602.10910v1": {
          "score": 2.3587865223757487,
          "rank": 344
        },
        "2602.10160v1": {
          "score": 2.3544758065211466,
          "rank": 345
        },
        "2602.15335v1": {
          "score": 2.3544758065211466,
          "rank": 346
        },
        "2602.11928v2": {
          "score": 2.3544758065211466,
          "rank": 347
        },
        "2602.10107v1": {
          "score": 2.3529047969234766,
          "rank": 348
        },
        "2602.13749v2": {
          "score": 2.3489502935502515,
          "rank": 349
        },
        "2602.09244v1": {
          "score": 2.3489502935502515,
          "rank": 350
        },
        "2602.13378v1": {
          "score": 2.345000338905935,
          "rank": 351
        },
        "2602.15939v1": {
          "score": 2.3434506545425102,
          "rank": 352
        },
        "2602.12101v1": {
          "score": 2.337976708184926,
          "rank": 353
        },
        "2602.15781v1": {
          "score": 2.3271051765992565,
          "rank": 354
        },
        "2602.09153v1": {
          "score": 2.321707237117515,
          "rank": 355
        },
        "2602.16502v1": {
          "score": 2.321707237117515,
          "rank": 356
        },
        "2602.13184v1": {
          "score": 2.321707237117515,
          "rank": 357
        },
        "2602.11734v1": {
          "score": 2.321707237117515,
          "rank": 358
        },
        "2602.14674v2": {
          "score": 2.317683604498217,
          "rank": 359
        },
        "2602.16551v1": {
          "score": 2.317683604498217,
          "rank": 360
        },
        "2602.14205v1": {
          "score": 2.3163342817401453,
          "rank": 361
        },
        "2602.14692v1": {
          "score": 2.3129352268900845,
          "rank": 362
        },
        "2602.10447v1": {
          "score": 2.310986137411041,
          "rank": 363
        },
        "2602.15466v1": {
          "score": 2.310986137411041,
          "rank": 364
        },
        "2602.10916v1": {
          "score": 2.307587182792696,
          "rank": 365
        },
        "2602.15925v1": {
          "score": 2.306530154097728,
          "rank": 366
        },
        "2602.12307v1": {
          "score": 2.305662632668681,
          "rank": 367
        },
        "2602.10065v1": {
          "score": 2.3054908851113733,
          "rank": 368
        },
        "2602.11216v1": {
          "score": 2.3003635976278036,
          "rank": 369
        },
        "2602.16082v1": {
          "score": 2.3003635976278036,
          "rank": 370
        },
        "2602.09651v1": {
          "score": 2.2950888639613334,
          "rank": 371
        },
        "2602.10197v1": {
          "score": 2.2846116351275585,
          "rank": 372
        },
        "2602.13387v1": {
          "score": 2.2794088109378454,
          "rank": 373
        },
        "2602.10476v1": {
          "score": 2.2778189001759275,
          "rank": 374
        },
        "2602.11463v1": {
          "score": 2.275029638497601,
          "rank": 375
        },
        "2602.13438v1": {
          "score": 2.269073931645197,
          "rank": 376
        },
        "2602.13142v1": {
          "score": 2.2639415563997547,
          "rank": 377
        },
        "2602.12595v1": {
          "score": 2.2588323464015287,
          "rank": 378
        },
        "2602.10064v1": {
          "score": 2.2588323464015287,
          "rank": 379
        },
        "2602.14052v1": {
          "score": 2.2486827976201456,
          "rank": 380
        },
        "2602.12704v1": {
          "score": 2.244377941945004,
          "rank": 381
        },
        "2602.16675v1": {
          "score": 2.2386240502159653,
          "rank": 382
        },
        "2602.15262v1": {
          "score": 2.2386240502159653,
          "rank": 383
        },
        "2602.12326v1": {
          "score": 2.2386240502159653,
          "rank": 384
        },
        "2602.09599v1": {
          "score": 2.2386240502159653,
          "rank": 385
        },
        "2602.10541v1": {
          "score": 2.233628347095448,
          "rank": 386
        },
        "2602.16530v1": {
          "score": 2.233628347095448,
          "rank": 387
        },
        "2602.15223v1": {
          "score": 2.233628347095448,
          "rank": 388
        },
        "2602.14677v1": {
          "score": 2.2323472887111806,
          "rank": 389
        },
        "2602.12355v1": {
          "score": 2.228654891104491,
          "rank": 390
        },
        "2602.12589v1": {
          "score": 2.2204449248461726,
          "rank": 391
        },
        "2602.11225v1": {
          "score": 2.2187741287141107,
          "rank": 392
        },
        "2602.09819v1": {
          "score": 2.2187741287141107,
          "rank": 393
        },
        "2602.16043v1": {
          "score": 2.2187741287141107,
          "rank": 394
        },
        "2602.12364v1": {
          "score": 2.2108970185755275,
          "rank": 395
        },
        "2602.11801v1": {
          "score": 2.2086688092044073,
          "rank": 396
        },
        "2602.10173v1": {
          "score": 2.2041161740771402,
          "rank": 397
        },
        "2602.12743v1": {
          "score": 2.2041161740771402,
          "rank": 398
        },
        "2602.16459v1": {
          "score": 2.202827468418,
          "rank": 399
        },
        "2602.14414v1": {
          "score": 2.202827468418,
          "rank": 400
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR",
      "paper_tag": "keyword:SR",
      "query_text": "Symbolic Regression\" \"Genetic Programming\" \"Equation Discovery",
      "logic_cn": "检索符号回归核心术语，或通过遗传算法进行方程发现的相关研究",
      "boolean_expr": "",
      "bm25_mode": "normal",
      "sim_scores": {
        "2602.12259v1": {
          "score": 15.213918244905823,
          "rank": 1
        },
        "2602.13021v2": {
          "score": 13.880664632952081,
          "rank": 2
        },
        "2602.15070v1": {
          "score": 11.824093580757854,
          "rank": 3
        },
        "2602.10576v1": {
          "score": 11.725715972332349,
          "rank": 4
        },
        "2602.15468v1": {
          "score": 11.665446371837538,
          "rank": 5
        },
        "2602.12870v1": {
          "score": 10.93219350940729,
          "rank": 6
        },
        "2602.09772v1": {
          "score": 10.235359982534634,
          "rank": 7
        },
        "2602.13730v1": {
          "score": 10.191383886135048,
          "rank": 8
        },
        "2602.15387v1": {
          "score": 8.258215006124766,
          "rank": 9
        },
        "2602.16481v1": {
          "score": 7.682678504126596,
          "rank": 10
        },
        "2602.15459v1": {
          "score": 7.649243581539971,
          "rank": 11
        },
        "2602.13419v1": {
          "score": 7.620903558873762,
          "rank": 12
        },
        "2602.13864v1": {
          "score": 7.566739704989126,
          "rank": 13
        },
        "2602.13513v2": {
          "score": 7.56401418064973,
          "rank": 14
        },
        "2602.15169v1": {
          "score": 7.473395756409902,
          "rank": 15
        },
        "2602.13583v1": {
          "score": 7.282619191068859,
          "rank": 16
        },
        "2602.10891v1": {
          "score": 7.131590573771475,
          "rank": 17
        },
        "2602.10471v1": {
          "score": 7.106971286914374,
          "rank": 18
        },
        "2602.16091v1": {
          "score": 6.719580545639486,
          "rank": 19
        },
        "2602.16504v1": {
          "score": 6.667678087659333,
          "rank": 20
        },
        "2602.09801v1": {
          "score": 6.6327754767906555,
          "rank": 21
        },
        "2602.15247v1": {
          "score": 6.593844393236907,
          "rank": 22
        },
        "2602.15554v1": {
          "score": 6.149465339108051,
          "rank": 23
        },
        "2602.10249v1": {
          "score": 6.091320385950796,
          "rank": 24
        },
        "2602.12867v1": {
          "score": 6.0262396794444175,
          "rank": 25
        },
        "2602.16291v1": {
          "score": 5.990440522442831,
          "rank": 26
        },
        "2602.14337v1": {
          "score": 5.838164977026683,
          "rank": 27
        },
        "2602.08990v1": {
          "score": 5.8170027398362745,
          "rank": 28
        },
        "2602.09093v1": {
          "score": 5.752983247403484,
          "rank": 29
        },
        "2602.09774v1": {
          "score": 5.726686902141696,
          "rank": 30
        },
        "2602.12472v1": {
          "score": 5.671398900487632,
          "rank": 31
        },
        "2602.11947v1": {
          "score": 5.573512816406478,
          "rank": 32
        },
        "2602.12465v1": {
          "score": 5.424707939081769,
          "rank": 33
        },
        "2602.09374v1": {
          "score": 5.370671692345702,
          "rank": 34
        },
        "2602.10632v1": {
          "score": 5.353001103088506,
          "rank": 35
        },
        "2602.12214v1": {
          "score": 5.304167234800701,
          "rank": 36
        },
        "2602.10598v1": {
          "score": 5.2608044557920755,
          "rank": 37
        },
        "2602.16166v1": {
          "score": 5.208890462552516,
          "rank": 38
        },
        "2602.11481v1": {
          "score": 5.149474514522448,
          "rank": 39
        },
        "2602.11285v1": {
          "score": 5.117032114192787,
          "rank": 40
        },
        "2602.09702v1": {
          "score": 5.114299288810516,
          "rank": 41
        },
        "2602.10480v2": {
          "score": 5.0835908376307435,
          "rank": 42
        },
        "2602.09756v1": {
          "score": 5.0258875598089885,
          "rank": 43
        },
        "2602.09266v1": {
          "score": 4.981028807339234,
          "rank": 44
        },
        "2602.14072v1": {
          "score": 4.976990414691709,
          "rank": 45
        },
        "2602.14102v1": {
          "score": 4.964257041410028,
          "rank": 46
        },
        "2602.16551v1": {
          "score": 4.964029632795288,
          "rank": 47
        },
        "2602.09784v1": {
          "score": 4.9533817724670515,
          "rank": 48
        },
        "2602.16574v1": {
          "score": 4.946118517041944,
          "rank": 49
        },
        "2602.15603v1": {
          "score": 4.94132823116149,
          "rank": 50
        },
        "2602.13961v1": {
          "score": 4.926484367311034,
          "rank": 51
        },
        "2602.16342v1": {
          "score": 4.895398354094185,
          "rank": 52
        },
        "2602.10476v1": {
          "score": 4.878647152988986,
          "rank": 53
        },
        "2602.15353v1": {
          "score": 4.8680302036483285,
          "rank": 54
        },
        "2602.10171v1": {
          "score": 4.848239809302762,
          "rank": 55
        },
        "2602.14727v1": {
          "score": 4.803965827814665,
          "rank": 56
        },
        "2602.15712v1": {
          "score": 4.7865339110388625,
          "rank": 57
        },
        "2602.12966v1": {
          "score": 4.771040727364195,
          "rank": 58
        },
        "2602.14270v1": {
          "score": 4.764776505352588,
          "rank": 59
        },
        "2602.11312v1": {
          "score": 4.757997641048694,
          "rank": 60
        },
        "2602.15541v1": {
          "score": 4.753744041394963,
          "rank": 61
        },
        "2602.12851v1": {
          "score": 4.735464840700424,
          "rank": 62
        },
        "2602.14946v1": {
          "score": 4.732035669545884,
          "rank": 63
        },
        "2602.09620v1": {
          "score": 4.70541962696563,
          "rank": 64
        },
        "2602.13410v1": {
          "score": 4.698652750172895,
          "rank": 65
        },
        "2602.15647v1": {
          "score": 4.695837736205984,
          "rank": 66
        },
        "2602.09946v1": {
          "score": 4.689120178958054,
          "rank": 67
        },
        "2602.12889v1": {
          "score": 4.667658505577067,
          "rank": 68
        },
        "2602.11849v1": {
          "score": 4.658209481434511,
          "rank": 69
        },
        "2602.10920v1": {
          "score": 4.640546203023769,
          "rank": 70
        },
        "2602.09443v1": {
          "score": 4.6297924010104685,
          "rank": 71
        },
        "2602.09435v2": {
          "score": 4.625036171505377,
          "rank": 72
        },
        "2602.13791v1": {
          "score": 4.617463500406762,
          "rank": 73
        },
        "2602.13312v1": {
          "score": 4.613347120087198,
          "rank": 74
        },
        "2602.09249v1": {
          "score": 4.593666482400739,
          "rank": 75
        },
        "2602.15269v1": {
          "score": 4.590655966906154,
          "rank": 76
        },
        "2602.14287v1": {
          "score": 4.5815460492442135,
          "rank": 77
        },
        "2602.12816v1": {
          "score": 4.578249686127327,
          "rank": 78
        },
        "2602.15911v1": {
          "score": 4.568029182810104,
          "rank": 79
        },
        "2602.15621v1": {
          "score": 4.549665619567377,
          "rank": 80
        },
        "2602.16005v1": {
          "score": 4.539727962181338,
          "rank": 81
        },
        "2602.10529v1": {
          "score": 4.532128458702259,
          "rank": 82
        },
        "2602.14685v1": {
          "score": 4.507651781216125,
          "rank": 83
        },
        "2602.10085v2": {
          "score": 4.504546274735381,
          "rank": 84
        },
        "2602.16549v1": {
          "score": 4.502441563591253,
          "rank": 85
        },
        "2602.09761v1": {
          "score": 4.485123595605202,
          "rank": 86
        },
        "2602.10511v1": {
          "score": 4.468911412627865,
          "rank": 87
        },
        "2602.14456v1": {
          "score": 4.438435282812106,
          "rank": 88
        },
        "2602.13630v1": {
          "score": 4.431500369485818,
          "rank": 89
        },
        "2602.10324v1": {
          "score": 4.428015152905582,
          "rank": 90
        },
        "2602.16627v1": {
          "score": 4.425041219405081,
          "rank": 91
        },
        "2602.11291v1": {
          "score": 4.4240170957558105,
          "rank": 92
        },
        "2602.13769v1": {
          "score": 4.416827420877461,
          "rank": 93
        },
        "2602.11118v1": {
          "score": 4.4010736344005155,
          "rank": 94
        },
        "2602.16435v1": {
          "score": 4.372807864899898,
          "rank": 95
        },
        "2602.13471v1": {
          "score": 4.363717151312113,
          "rank": 96
        },
        "2602.15306v1": {
          "score": 4.363466452083851,
          "rank": 97
        },
        "2602.13963v1": {
          "score": 4.362152772082594,
          "rank": 98
        },
        "2602.15957v1": {
          "score": 4.359210025607529,
          "rank": 99
        },
        "2602.15228v1": {
          "score": 4.336143475048801,
          "rank": 100
        },
        "2602.16428v1": {
          "score": 4.335730711602846,
          "rank": 101
        },
        "2602.10163v1": {
          "score": 4.332852403394726,
          "rank": 102
        },
        "2602.10282v1": {
          "score": 4.315245157477467,
          "rank": 103
        },
        "2602.11991v1": {
          "score": 4.303813296818053,
          "rank": 104
        },
        "2602.10950v1": {
          "score": 4.290277805140338,
          "rank": 105
        },
        "2602.12409v1": {
          "score": 4.2775059572904315,
          "rank": 106
        },
        "2602.14928v1": {
          "score": 4.271269151441328,
          "rank": 107
        },
        "2602.15947v1": {
          "score": 4.271269151441328,
          "rank": 108
        },
        "2602.16122v1": {
          "score": 4.251809547398714,
          "rank": 109
        },
        "2602.14636v1": {
          "score": 4.23573683839219,
          "rank": 110
        },
        "2602.12511v1": {
          "score": 4.224078313415621,
          "rank": 111
        },
        "2602.14561v1": {
          "score": 4.208088834274045,
          "rank": 112
        },
        "2602.12454v1": {
          "score": 4.187483348436716,
          "rank": 113
        },
        "2602.16263v1": {
          "score": 4.184983625984809,
          "rank": 114
        },
        "2602.14136v1": {
          "score": 4.169207351145436,
          "rank": 115
        },
        "2602.11123v1": {
          "score": 4.1686080743812095,
          "rank": 116
        },
        "2602.12109v1": {
          "score": 4.167156444319055,
          "rank": 117
        },
        "2602.11019v1": {
          "score": 4.1542921026253605,
          "rank": 118
        },
        "2602.16020v1": {
          "score": 4.1400741231089375,
          "rank": 119
        },
        "2602.14617v1": {
          "score": 4.133070754708112,
          "rank": 120
        },
        "2602.10741v1": {
          "score": 4.130711927595399,
          "rank": 121
        },
        "2602.11642v1": {
          "score": 4.121969800229075,
          "rank": 122
        },
        "2602.13962v1": {
          "score": 4.112213909921859,
          "rank": 123
        },
        "2602.12607v1": {
          "score": 4.110928317798492,
          "rank": 124
        },
        "2602.16038v1": {
          "score": 4.104951343656849,
          "rank": 125
        },
        "2602.11487v1": {
          "score": 4.1011611004945365,
          "rank": 126
        },
        "2602.13786v1": {
          "score": 4.099945830771466,
          "rank": 127
        },
        "2602.16380v1": {
          "score": 4.097624651653609,
          "rank": 128
        },
        "2602.13673v1": {
          "score": 4.094476562973652,
          "rank": 129
        },
        "2602.14659v1": {
          "score": 4.092904331877504,
          "rank": 130
        },
        "2602.14568v1": {
          "score": 4.089435489418609,
          "rank": 131
        },
        "2602.16440v1": {
          "score": 4.081278994216819,
          "rank": 132
        },
        "2602.14802v1": {
          "score": 4.0781559616806184,
          "rank": 133
        },
        "2602.13169v1": {
          "score": 4.067347651457706,
          "rank": 134
        },
        "2602.15300v1": {
          "score": 4.065063226155482,
          "rank": 135
        },
        "2602.14670v1": {
          "score": 4.06358271634608,
          "rank": 136
        },
        "2602.14318v1": {
          "score": 4.06358271634608,
          "rank": 137
        },
        "2602.13067v1": {
          "score": 4.043209511717473,
          "rank": 138
        },
        "2602.10156v1": {
          "score": 4.039171219906677,
          "rank": 139
        },
        "2602.14105v1": {
          "score": 4.036792256387496,
          "rank": 140
        },
        "2602.16254v1": {
          "score": 4.025082011674882,
          "rank": 141
        },
        "2602.12436v1": {
          "score": 4.020610397521559,
          "rank": 142
        },
        "2602.13775v1": {
          "score": 4.0163609076340485,
          "rank": 143
        },
        "2602.09298v1": {
          "score": 4.00930887074572,
          "rank": 144
        },
        "2602.13363v1": {
          "score": 4.008704033450006,
          "rank": 145
        },
        "2602.08967v1": {
          "score": 3.9932643929057345,
          "rank": 146
        },
        "2602.09687v1": {
          "score": 3.9858795938842864,
          "rank": 147
        },
        "2602.09547v1": {
          "score": 3.9704116124240914,
          "rank": 148
        },
        "2602.09505v1": {
          "score": 3.9704116124240914,
          "rank": 149
        },
        "2602.09409v1": {
          "score": 3.95213029408508,
          "rank": 150
        },
        "2602.14598v1": {
          "score": 3.9502145407698115,
          "rank": 151
        },
        "2602.14440v1": {
          "score": 3.9492584589550384,
          "rank": 152
        },
        "2602.09767v1": {
          "score": 3.937912739355148,
          "rank": 153
        },
        "2602.15548v1": {
          "score": 3.932261844055641,
          "rank": 154
        },
        "2602.10475v1": {
          "score": 3.9279146190265655,
          "rank": 155
        },
        "2602.15595v1": {
          "score": 3.9251350176205957,
          "rank": 156
        },
        "2602.11666v1": {
          "score": 3.9111220196605334,
          "rank": 157
        },
        "2602.14070v1": {
          "score": 3.9097218661182285,
          "rank": 158
        },
        "2602.14555v1": {
          "score": 3.906855777351908,
          "rank": 159
        },
        "2602.16348v1": {
          "score": 3.9022658531225307,
          "rank": 160
        },
        "2602.13612v1": {
          "score": 3.8874388166582907,
          "rank": 161
        },
        "2602.10827v1": {
          "score": 3.8739121552658418,
          "rank": 162
        },
        "2602.11092v1": {
          "score": 3.868646663954748,
          "rank": 163
        },
        "2602.13923v1": {
          "score": 3.8384544565929124,
          "rank": 164
        },
        "2602.09132v1": {
          "score": 3.8318824540951004,
          "rank": 165
        },
        "2602.14545v1": {
          "score": 3.824107479096278,
          "rank": 166
        },
        "2602.12676v1": {
          "score": 3.8149622271828765,
          "rank": 167
        },
        "2602.11485v1": {
          "score": 3.8149622271828765,
          "rank": 168
        },
        "2602.09650v1": {
          "score": 3.8149622271828765,
          "rank": 169
        },
        "2602.10303v1": {
          "score": 3.809867351520053,
          "rank": 170
        },
        "2602.10768v1": {
          "score": 3.809867351520053,
          "rank": 171
        },
        "2602.15984v1": {
          "score": 3.80177518556295,
          "rank": 172
        },
        "2602.13396v1": {
          "score": 3.80177518556295,
          "rank": 173
        },
        "2602.15370v1": {
          "score": 3.8013054900896943,
          "rank": 174
        },
        "2602.15601v1": {
          "score": 3.8007900017342076,
          "rank": 175
        },
        "2602.14654v1": {
          "score": 3.8007900017342076,
          "rank": 176
        },
        "2602.13364v1": {
          "score": 3.8002540836265664,
          "rank": 177
        },
        "2602.12383v1": {
          "score": 3.793743302164085,
          "rank": 178
        },
        "2602.16693v1": {
          "score": 3.786368027795029,
          "rank": 179
        },
        "2602.11917v1": {
          "score": 3.7780278809322203,
          "rank": 180
        },
        "2602.16346v1": {
          "score": 3.772137337036323,
          "rank": 181
        },
        "2602.16126v1": {
          "score": 3.7658158733048515,
          "rank": 182
        },
        "2602.11855v1": {
          "score": 3.760411183687416,
          "rank": 183
        },
        "2602.12455v1": {
          "score": 3.759081652995252,
          "rank": 184
        },
        "2602.13589v1": {
          "score": 3.7520057830798987,
          "rank": 185
        },
        "2602.14392v2": {
          "score": 3.7493661853168048,
          "rank": 186
        },
        "2602.09671v1": {
          "score": 3.7402284481202366,
          "rank": 187
        },
        "2602.09720v1": {
          "score": 3.739658399853604,
          "rank": 188
        },
        "2602.14503v1": {
          "score": 3.728024265667127,
          "rank": 189
        },
        "2602.12619v1": {
          "score": 3.717919672753958,
          "rank": 190
        },
        "2602.11617v1": {
          "score": 3.7142266601684977,
          "rank": 191
        },
        "2602.09692v1": {
          "score": 3.713080536350188,
          "rank": 192
        },
        "2602.09806v1": {
          "score": 3.7111766353736386,
          "rank": 193
        },
        "2602.14412v1": {
          "score": 3.704458012849993,
          "rank": 194
        },
        "2602.13561v1": {
          "score": 3.704458012849993,
          "rank": 195
        },
        "2602.15061v1": {
          "score": 3.669162828405012,
          "rank": 196
        },
        "2602.14737v1": {
          "score": 3.6515722826456005,
          "rank": 197
        },
        "2602.14262v1": {
          "score": 3.6476594095099752,
          "rank": 198
        },
        "2602.12608v1": {
          "score": 3.6470385015255857,
          "rank": 199
        },
        "2602.10236v1": {
          "score": 3.6415490462183495,
          "rank": 200
        },
        "2602.10745v1": {
          "score": 3.639107336041408,
          "rank": 201
        },
        "2602.09133v1": {
          "score": 3.637856769586847,
          "rank": 202
        },
        "2602.16473v1": {
          "score": 3.628106675253072,
          "rank": 203
        },
        "2602.14820v1": {
          "score": 3.625691661197969,
          "rank": 204
        },
        "2602.14801v1": {
          "score": 3.613857311272419,
          "rank": 205
        },
        "2602.10651v1": {
          "score": 3.601137384057579,
          "rank": 206
        },
        "2602.13398v1": {
          "score": 3.598221234582634,
          "rank": 207
        },
        "2602.16508v1": {
          "score": 3.593852249837143,
          "rank": 208
        },
        "2602.13125v1": {
          "score": 3.5928776457729525,
          "rank": 209
        },
        "2602.10587v1": {
          "score": 3.582816332992085,
          "rank": 210
        },
        "2602.12502v1": {
          "score": 3.58012979567006,
          "rank": 211
        },
        "2602.12300v1": {
          "score": 3.58012979567006,
          "rank": 212
        },
        "2602.11883v1": {
          "score": 3.5625671731330524,
          "rank": 213
        },
        "2602.15104v1": {
          "score": 3.561292455471498,
          "rank": 214
        },
        "2602.16367v1": {
          "score": 3.546279260600726,
          "rank": 215
        },
        "2602.10274v1": {
          "score": 3.53610888391646,
          "rank": 216
        },
        "2602.10895v1": {
          "score": 3.5351288277472723,
          "rank": 217
        },
        "2602.14047v1": {
          "score": 3.5334052167707446,
          "rank": 218
        },
        "2602.12163v1": {
          "score": 3.529483100319733,
          "rank": 219
        },
        "2602.13854v1": {
          "score": 3.5196721161685938,
          "rank": 220
        },
        "2602.16256v1": {
          "score": 3.5162049004033133,
          "rank": 221
        },
        "2602.12977v2": {
          "score": 3.4942822239582156,
          "rank": 222
        },
        "2602.14651v1": {
          "score": 3.4786954899177043,
          "rank": 223
        },
        "2602.11290v2": {
          "score": 3.4626066970111458,
          "rank": 224
        },
        "2602.15684v1": {
          "score": 3.4613560539113273,
          "rank": 225
        },
        "2602.14213v1": {
          "score": 3.460155024118177,
          "rank": 226
        },
        "2602.11136v2": {
          "score": 3.454467206877086,
          "rank": 227
        },
        "2602.15635v1": {
          "score": 3.4523038557645838,
          "rank": 228
        },
        "2602.11630v1": {
          "score": 3.448844442244473,
          "rank": 229
        },
        "2602.10746v1": {
          "score": 3.4376536471442303,
          "rank": 230
        },
        "2602.12046v1": {
          "score": 3.436907998490387,
          "rank": 231
        },
        "2602.13866v1": {
          "score": 3.4347843577114245,
          "rank": 232
        },
        "2602.09798v1": {
          "score": 3.4265352408414333,
          "rank": 233
        },
        "2602.09462v1": {
          "score": 3.426091119918186,
          "rank": 234
        },
        "2602.13729v1": {
          "score": 3.4244630900841058,
          "rank": 235
        },
        "2602.09875v1": {
          "score": 3.420544699305384,
          "rank": 236
        },
        "2602.13537v2": {
          "score": 3.4199540340635752,
          "rank": 237
        },
        "2602.16369v1": {
          "score": 3.419676694286519,
          "rank": 238
        },
        "2602.09799v1": {
          "score": 3.413971258148547,
          "rank": 239
        },
        "2602.16475v1": {
          "score": 3.413971258148547,
          "rank": 240
        },
        "2602.09906v1": {
          "score": 3.409147059162489,
          "rank": 241
        },
        "2602.09429v2": {
          "score": 3.4082848283580613,
          "rank": 242
        },
        "2602.16294v1": {
          "score": 3.4082848283580613,
          "rank": 243
        },
        "2602.13753v1": {
          "score": 3.4026173101000823,
          "rank": 244
        },
        "2602.09293v1": {
          "score": 3.4026173101000823,
          "rank": 245
        },
        "2602.10889v1": {
          "score": 3.4026173101000823,
          "rank": 246
        },
        "2602.14573v1": {
          "score": 3.3917538000180523,
          "rank": 247
        },
        "2602.12114v1": {
          "score": 3.3881808534367948,
          "rank": 248
        },
        "2602.12940v1": {
          "score": 3.37456011705546,
          "rank": 249
        },
        "2602.14156v1": {
          "score": 3.3643060723443106,
          "rank": 250
        },
        "2602.13362v1": {
          "score": 3.346666039807205,
          "rank": 251
        },
        "2602.11889v1": {
          "score": 3.3414962732718703,
          "rank": 252
        },
        "2602.09996v2": {
          "score": 3.335328569639652,
          "rank": 253
        },
        "2602.11058v1": {
          "score": 3.3332911121742366,
          "rank": 254
        },
        "2602.14912v1": {
          "score": 3.3314418825015846,
          "rank": 255
        },
        "2602.15777v1": {
          "score": 3.3314182978960787,
          "rank": 256
        },
        "2602.11206v1": {
          "score": 3.325206135830303,
          "rank": 257
        },
        "2602.16376v1": {
          "score": 3.322528819047497,
          "rank": 258
        },
        "2602.11490v1": {
          "score": 3.3169558501666345,
          "rank": 259
        },
        "2602.14309v1": {
          "score": 3.309074060007557,
          "rank": 260
        },
        "2602.09647v1": {
          "score": 3.309074060007557,
          "rank": 261
        },
        "2602.15758v1": {
          "score": 3.3088481123424374,
          "rank": 262
        },
        "2602.14359v1": {
          "score": 3.299213548321461,
          "rank": 263
        },
        "2602.12959v1": {
          "score": 3.298443887788446,
          "rank": 264
        },
        "2602.11025v1": {
          "score": 3.292750966187849,
          "rank": 265
        },
        "2602.14400v1": {
          "score": 3.28476098359563,
          "rank": 266
        },
        "2602.16671v1": {
          "score": 3.283181483448456,
          "rank": 267
        },
        "2602.14480v1": {
          "score": 3.2764532004118934,
          "rank": 268
        },
        "2602.13152v1": {
          "score": 3.25935792025363,
          "rank": 269
        },
        "2602.13874v1": {
          "score": 3.253185085546014,
          "rank": 270
        },
        "2602.14154v1": {
          "score": 3.245385738066195,
          "rank": 271
        },
        "2602.12442v1": {
          "score": 3.242130443186393,
          "rank": 272
        },
        "2602.11297v1": {
          "score": 3.235814867325904,
          "rank": 273
        },
        "2602.09218v1": {
          "score": 3.2307059950747425,
          "rank": 274
        },
        "2602.14447v1": {
          "score": 3.2263855020138665,
          "rank": 275
        },
        "2602.10509v1": {
          "score": 3.2263855020138665,
          "rank": 276
        },
        "2602.10814v1": {
          "score": 3.2222104758294137,
          "rank": 277
        },
        "2602.15995v1": {
          "score": 3.2222104758294137,
          "rank": 278
        },
        "2602.12644v1": {
          "score": 3.220536495144425,
          "rank": 279
        },
        "2602.13674v1": {
          "score": 3.216243140985893,
          "rank": 280
        },
        "2602.15522v1": {
          "score": 3.215475715841381,
          "rank": 281
        },
        "2602.16463v1": {
          "score": 3.2132527285424253,
          "rank": 282
        },
        "2602.12588v1": {
          "score": 3.207741206509157,
          "rank": 283
        },
        "2602.09419v1": {
          "score": 3.191820141261478,
          "rank": 284
        },
        "2602.10365v1": {
          "score": 3.1844943372749754,
          "rank": 285
        },
        "2602.12706v1": {
          "score": 3.180490758275801,
          "rank": 286
        },
        "2602.11856v1": {
          "score": 3.180490758275801,
          "rank": 287
        },
        "2602.14665v1": {
          "score": 3.176303442241892,
          "rank": 288
        },
        "2602.16538v1": {
          "score": 3.1755549564928023,
          "rank": 289
        },
        "2602.11248v1": {
          "score": 3.1694009458411547,
          "rank": 290
        },
        "2602.11491v1": {
          "score": 3.165767141385208,
          "rank": 291
        },
        "2602.09757v1": {
          "score": 3.161997704501475,
          "rank": 292
        },
        "2602.16293v1": {
          "score": 3.1608390435980076,
          "rank": 293
        },
        "2602.09988v1": {
          "score": 3.1575038020641912,
          "rank": 294
        },
        "2602.11700v1": {
          "score": 3.15642650312861,
          "rank": 295
        },
        "2602.12008v1": {
          "score": 3.1511039742442017,
          "rank": 296
        },
        "2602.11077v1": {
          "score": 3.1472944964678113,
          "rank": 297
        },
        "2602.13978v1": {
          "score": 3.1462588922740595,
          "rank": 298
        },
        "2602.14954v1": {
          "score": 3.141428686855395,
          "rank": 299
        },
        "2602.14958v1": {
          "score": 3.139994050663304,
          "rank": 300
        },
        "2602.14362v1": {
          "score": 3.1329706023557247,
          "rank": 301
        },
        "2602.10822v1": {
          "score": 3.127752429345068,
          "rank": 302
        },
        "2602.12399v1": {
          "score": 3.124167465286386,
          "rank": 303
        },
        "2602.09584v1": {
          "score": 3.118219792924503,
          "rank": 304
        },
        "2602.14241v1": {
          "score": 3.111127835343063,
          "rank": 305
        },
        "2602.13610v1": {
          "score": 3.096892844094835,
          "rank": 306
        },
        "2602.11837v1": {
          "score": 3.08996736301983,
          "rank": 307
        },
        "2602.12973v1": {
          "score": 3.0898240862112605,
          "rank": 308
        },
        "2602.10112v1": {
          "score": 3.0850304116604805,
          "rank": 309
        },
        "2602.09025v1": {
          "score": 3.079959217637585,
          "rank": 310
        },
        "2602.11760v1": {
          "score": 3.0771826561772175,
          "rank": 311
        },
        "2602.15512v1": {
          "score": 3.0771826561772175,
          "rank": 312
        },
        "2602.10613v1": {
          "score": 3.077039141480566,
          "rank": 313
        },
        "2602.14800v1": {
          "score": 3.071415123548003,
          "rank": 314
        },
        "2602.09333v1": {
          "score": 3.069374725907104,
          "rank": 315
        },
        "2602.10798v1": {
          "score": 3.061868828461955,
          "rank": 316
        },
        "2602.16684v1": {
          "score": 3.061606318464301,
          "rank": 317
        },
        "2602.12534v1": {
          "score": 3.059797266195867,
          "rank": 318
        },
        "2602.12207v2": {
          "score": 3.0549588749839556,
          "rank": 319
        },
        "2602.08977v1": {
          "score": 3.0549588749839556,
          "rank": 320
        },
        "2602.14502v1": {
          "score": 3.0461868777466083,
          "rank": 321
        },
        "2602.14479v1": {
          "score": 3.044000741417439,
          "rank": 322
        },
        "2602.11063v2": {
          "score": 3.04123211293534,
          "rank": 323
        },
        "2602.09167v1": {
          "score": 3.0377605357451323,
          "rank": 324
        },
        "2602.11087v1": {
          "score": 3.034414886777461,
          "rank": 325
        },
        "2602.09705v2": {
          "score": 3.0342876773261502,
          "rank": 326
        },
        "2602.13155v1": {
          "score": 3.0276281552522586,
          "rank": 327
        },
        "2602.16113v1": {
          "score": 3.0233467517675967,
          "rank": 328
        },
        "2602.16586v1": {
          "score": 3.021232153223774,
          "rank": 329
        },
        "2602.10437v2": {
          "score": 3.015809299526014,
          "rank": 330
        },
        "2602.09116v2": {
          "score": 3.015809299526014,
          "rank": 331
        },
        "2602.16616v1": {
          "score": 3.015809299526014,
          "rank": 332
        },
        "2602.12001v1": {
          "score": 3.0119561032910176,
          "rank": 333
        },
        "2602.13034v1": {
          "score": 3.0083093367973723,
          "rank": 334
        },
        "2602.14784v1": {
          "score": 3.007448895993597,
          "rank": 335
        },
        "2602.12881v1": {
          "score": 3.0008465845795005,
          "rank": 336
        },
        "2602.15634v1": {
          "score": 3.0008465845795005,
          "rank": 337
        },
        "2602.14506v1": {
          "score": 3.000782119531002,
          "rank": 338
        },
        "2602.16392v1": {
          "score": 3.000782119531002,
          "rank": 339
        },
        "2602.12006v1": {
          "score": 2.9906143758454187,
          "rank": 340
        },
        "2602.10283v1": {
          "score": 2.9906143758454187,
          "rank": 341
        },
        "2602.09351v1": {
          "score": 2.990225911275897,
          "rank": 342
        },
        "2602.13160v1": {
          "score": 2.989950836955913,
          "rank": 343
        },
        "2602.09540v1": {
          "score": 2.9875368468626418,
          "rank": 344
        },
        "2602.11079v2": {
          "score": 2.986031609441525,
          "rank": 345
        },
        "2602.11589v1": {
          "score": 2.986031609441525,
          "rank": 346
        },
        "2602.14856v1": {
          "score": 2.981238499201492,
          "rank": 347
        },
        "2602.14638v1": {
          "score": 2.972576787225777,
          "rank": 348
        },
        "2602.15216v1": {
          "score": 2.972576787225777,
          "rank": 349
        },
        "2602.09667v1": {
          "score": 2.9678867352460965,
          "rank": 350
        },
        "2602.12045v1": {
          "score": 2.96408140749619,
          "rank": 351
        },
        "2602.09187v1": {
          "score": 2.96408140749619,
          "rank": 352
        },
        "2602.16524v1": {
          "score": 2.9560517778549635,
          "rank": 353
        },
        "2602.13668v1": {
          "score": 2.9484934263437657,
          "rank": 354
        },
        "2602.14064v1": {
          "score": 2.9475355939714936,
          "rank": 355
        },
        "2602.09568v1": {
          "score": 2.9475355939714936,
          "rank": 356
        },
        "2602.16247v1": {
          "score": 2.942451560789453,
          "rank": 357
        },
        "2602.16044v1": {
          "score": 2.942451560789453,
          "rank": 358
        },
        "2602.16668v1": {
          "score": 2.9390683382211424,
          "rank": 359
        },
        "2602.12737v1": {
          "score": 2.935311592723063,
          "rank": 360
        },
        "2602.14227v1": {
          "score": 2.925822898250236,
          "rank": 361
        },
        "2602.15722v1": {
          "score": 2.9230265261960278,
          "rank": 362
        },
        "2602.13996v1": {
          "score": 2.9211351069253073,
          "rank": 363
        },
        "2602.15820v1": {
          "score": 2.920590035899252,
          "rank": 364
        },
        "2602.16699v1": {
          "score": 2.9167283918632547,
          "rank": 365
        },
        "2602.14611v1": {
          "score": 2.9104573398792613,
          "rank": 366
        },
        "2602.14539v1": {
          "score": 2.9104573398792613,
          "rank": 367
        },
        "2602.15561v1": {
          "score": 2.9091840537247755,
          "rank": 368
        },
        "2602.16497v1": {
          "score": 2.907094897487532,
          "rank": 369
        },
        "2602.10937v2": {
          "score": 2.9056802591314383,
          "rank": 370
        },
        "2602.11702v1": {
          "score": 2.900125283811676,
          "rank": 371
        },
        "2602.13494v1": {
          "score": 2.8979957872151747,
          "rank": 372
        },
        "2602.10802v1": {
          "score": 2.8918049423795624,
          "rank": 373
        },
        "2602.15800v1": {
          "score": 2.8918049423795624,
          "rank": 374
        },
        "2602.09947v1": {
          "score": 2.886285833825201,
          "rank": 375
        },
        "2602.09489v1": {
          "score": 2.8851810751148155,
          "rank": 376
        },
        "2602.12337v1": {
          "score": 2.881132814362233,
          "rank": 377
        },
        "2602.11632v1": {
          "score": 2.879502266293515,
          "rank": 378
        },
        "2602.16057v1": {
          "score": 2.8794155225085696,
          "rank": 379
        },
        "2602.13723v1": {
          "score": 2.8733900996071893,
          "rank": 380
        },
        "2602.14949v1": {
          "score": 2.8733900996071893,
          "rank": 381
        },
        "2602.14624v1": {
          "score": 2.8733900996071893,
          "rank": 382
        },
        "2602.10463v1": {
          "score": 2.872429844963289,
          "rank": 383
        },
        "2602.16531v1": {
          "score": 2.8702672812259302,
          "rank": 384
        },
        "2602.12736v1": {
          "score": 2.865772556593195,
          "rank": 385
        },
        "2602.11729v1": {
          "score": 2.8589994403804986,
          "rank": 386
        },
        "2602.13068v1": {
          "score": 2.8569966530191557,
          "rank": 387
        },
        "2602.14944v1": {
          "score": 2.8490408806662355,
          "rank": 388
        },
        "2602.10750v1": {
          "score": 2.8457506577948095,
          "rank": 389
        },
        "2602.11609v1": {
          "score": 2.8455488036982484,
          "rank": 390
        },
        "2602.09128v1": {
          "score": 2.843214397840975,
          "rank": 391
        },
        "2602.10487v1": {
          "score": 2.838870834538149,
          "rank": 392
        },
        "2602.14711v1": {
          "score": 2.838870834538149,
          "rank": 393
        },
        "2602.11057v1": {
          "score": 2.8372551537157253,
          "rank": 394
        },
        "2602.09456v1": {
          "score": 2.8312406930188545,
          "rank": 395
        },
        "2602.15415v1": {
          "score": 2.8254372108232637,
          "rank": 396
        },
        "2602.13161v1": {
          "score": 2.8254372108232637,
          "rank": 397
        },
        "2602.16190v1": {
          "score": 2.8254372108232637,
          "rank": 398
        },
        "2602.10421v1": {
          "score": 2.8248449374733715,
          "rank": 399
        },
        "2602.10809v1": {
          "score": 2.8190236755551625,
          "rank": 400
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR",
      "paper_tag": "keyword:SR",
      "query_text": "Symbolic Regression\" \"Deep Learning\" \"Transformer\" \"Reinforcement Learning",
      "logic_cn": "检索结合深度学习、Transformer或强化学习等现代机器学习技术的符号回归方法",
      "boolean_expr": "",
      "bm25_mode": "normal",
      "sim_scores": {
        "2602.10598v1": {
          "score": 13.550438568799654,
          "rank": 1
        },
        "2602.16264v1": {
          "score": 9.674678590547556,
          "rank": 2
        },
        "2602.10745v1": {
          "score": 9.514728382027517,
          "rank": 3
        },
        "2602.15484v1": {
          "score": 9.391057759969485,
          "rank": 4
        },
        "2602.14169v1": {
          "score": 9.264475135702986,
          "rank": 5
        },
        "2602.09810v2": {
          "score": 9.175414892776569,
          "rank": 6
        },
        "2602.09206v1": {
          "score": 9.120317248241383,
          "rank": 7
        },
        "2602.09157v1": {
          "score": 8.936942357451523,
          "rank": 8
        },
        "2602.10044v1": {
          "score": 8.909138840011904,
          "rank": 9
        },
        "2602.14519v1": {
          "score": 8.897130394909496,
          "rank": 10
        },
        "2602.12847v1": {
          "score": 8.884424612094259,
          "rank": 11
        },
        "2602.09569v1": {
          "score": 8.846838063659677,
          "rank": 12
        },
        "2602.15169v1": {
          "score": 8.845707593612667,
          "rank": 13
        },
        "2602.09726v1": {
          "score": 8.718069548049751,
          "rank": 14
        },
        "2602.16435v1": {
          "score": 8.635779869186958,
          "rank": 15
        },
        "2602.16665v1": {
          "score": 8.617597137304283,
          "rank": 16
        },
        "2602.16256v1": {
          "score": 8.612938360577267,
          "rank": 17
        },
        "2602.13896v1": {
          "score": 8.560448953902798,
          "rank": 18
        },
        "2602.16174v1": {
          "score": 8.45460855525776,
          "rank": 19
        },
        "2602.12146v1": {
          "score": 8.425782466788947,
          "rank": 20
        },
        "2602.16475v1": {
          "score": 8.413570355885629,
          "rank": 21
        },
        "2602.16216v1": {
          "score": 8.329866201612997,
          "rank": 22
        },
        "2602.16525v1": {
          "score": 8.220547664858847,
          "rank": 23
        },
        "2602.09761v1": {
          "score": 8.060700521189158,
          "rank": 24
        },
        "2602.12724v1": {
          "score": 7.966650246911567,
          "rank": 25
        },
        "2602.14473v1": {
          "score": 7.8838001975696175,
          "rank": 26
        },
        "2602.16548v1": {
          "score": 7.8838001975696175,
          "rank": 27
        },
        "2602.12379v1": {
          "score": 7.878893050705109,
          "rank": 28
        },
        "2602.15904v1": {
          "score": 7.8510947726452995,
          "rank": 29
        },
        "2602.14578v1": {
          "score": 7.738067403423398,
          "rank": 30
        },
        "2602.13949v1": {
          "score": 7.686792673597154,
          "rank": 31
        },
        "2602.10894v1": {
          "score": 7.6640438678733345,
          "rank": 32
        },
        "2602.14761v1": {
          "score": 7.635113860950265,
          "rank": 33
        },
        "2602.11626v1": {
          "score": 7.623752576799471,
          "rank": 34
        },
        "2602.12380v1": {
          "score": 7.609896786416284,
          "rank": 35
        },
        "2602.12402v1": {
          "score": 7.601740360219549,
          "rank": 36
        },
        "2602.11410v1": {
          "score": 7.575305943054349,
          "rank": 37
        },
        "2602.16473v1": {
          "score": 7.421376827344605,
          "rank": 38
        },
        "2602.14561v1": {
          "score": 7.388153794186112,
          "rank": 39
        },
        "2602.14844v1": {
          "score": 7.359601865573836,
          "rank": 40
        },
        "2602.09615v1": {
          "score": 7.356268212800162,
          "rank": 41
        },
        "2602.10496v2": {
          "score": 7.333636674102533,
          "rank": 42
        },
        "2602.10576v1": {
          "score": 7.263191538050063,
          "rank": 43
        },
        "2602.11800v1": {
          "score": 7.230706892705145,
          "rank": 44
        },
        "2602.10071v1": {
          "score": 7.208174545907029,
          "rank": 45
        },
        "2602.13934v1": {
          "score": 7.153948184463997,
          "rank": 46
        },
        "2602.12099v1": {
          "score": 7.098372395822004,
          "rank": 47
        },
        "2602.15817v1": {
          "score": 7.084039442449639,
          "rank": 48
        },
        "2602.12183v1": {
          "score": 7.083725630658455,
          "rank": 49
        },
        "2602.09489v1": {
          "score": 7.019859144873038,
          "rank": 50
        },
        "2602.10315v1": {
          "score": 7.017971592178284,
          "rank": 51
        },
        "2602.12035v1": {
          "score": 7.016672192358888,
          "rank": 52
        },
        "2602.11234v1": {
          "score": 7.007984166305664,
          "rank": 53
        },
        "2602.10997v1": {
          "score": 6.962331766652149,
          "rank": 54
        },
        "2602.12375v1": {
          "score": 6.934577905540626,
          "rank": 55
        },
        "2602.10750v1": {
          "score": 6.91391548701601,
          "rank": 56
        },
        "2602.15926v1": {
          "score": 6.904180977081481,
          "rank": 57
        },
        "2602.16301v1": {
          "score": 6.8949958011501735,
          "rank": 58
        },
        "2602.10539v1": {
          "score": 6.89419188977629,
          "rank": 59
        },
        "2602.16166v1": {
          "score": 6.86474916455582,
          "rank": 60
        },
        "2602.14523v1": {
          "score": 6.829451843332491,
          "rank": 61
        },
        "2602.16204v1": {
          "score": 6.824975956782568,
          "rank": 62
        },
        "2602.16696v1": {
          "score": 6.811655183315226,
          "rank": 63
        },
        "2602.11863v1": {
          "score": 6.801876694198313,
          "rank": 64
        },
        "2602.10207v1": {
          "score": 6.8006225857991485,
          "rank": 65
        },
        "2602.13583v1": {
          "score": 6.795343476594605,
          "rank": 66
        },
        "2602.16543v1": {
          "score": 6.778754416661096,
          "rank": 67
        },
        "2602.11805v1": {
          "score": 6.770631206523137,
          "rank": 68
        },
        "2602.12273v1": {
          "score": 6.768406736131593,
          "rank": 69
        },
        "2602.14997v1": {
          "score": 6.761797632640122,
          "rank": 70
        },
        "2602.11281v1": {
          "score": 6.760614687544164,
          "rank": 71
        },
        "2602.14697v1": {
          "score": 6.747445305061687,
          "rank": 72
        },
        "2602.11142v1": {
          "score": 6.727850578616733,
          "rank": 73
        },
        "2602.13040v1": {
          "score": 6.677939204302359,
          "rank": 74
        },
        "2602.13035v1": {
          "score": 6.621262767665682,
          "rank": 75
        },
        "2602.12049v1": {
          "score": 6.606482373420313,
          "rank": 76
        },
        "2602.09994v1": {
          "score": 6.593715468710046,
          "rank": 77
        },
        "2602.09305v1": {
          "score": 6.580988565683176,
          "rank": 78
        },
        "2602.10419v1": {
          "score": 6.5746302166263515,
          "rank": 79
        },
        "2602.10623v1": {
          "score": 6.554472407606046,
          "rank": 80
        },
        "2602.14228v1": {
          "score": 6.553792208351254,
          "rank": 81
        },
        "2602.14468v1": {
          "score": 6.536538590121516,
          "rank": 82
        },
        "2602.13831v1": {
          "score": 6.535695912656712,
          "rank": 83
        },
        "2602.15089v1": {
          "score": 6.533090192459018,
          "rank": 84
        },
        "2602.12244v1": {
          "score": 6.528437657493408,
          "rank": 85
        },
        "2602.12109v1": {
          "score": 6.523353003484262,
          "rank": 86
        },
        "2602.13953v1": {
          "score": 6.519283441219936,
          "rank": 87
        },
        "2602.14440v1": {
          "score": 6.518103614030116,
          "rank": 88
        },
        "2602.09720v1": {
          "score": 6.50888928916801,
          "rank": 89
        },
        "2602.10381v1": {
          "score": 6.482467852274004,
          "rank": 90
        },
        "2602.11084v1": {
          "score": 6.447343970903036,
          "rank": 91
        },
        "2602.12855v1": {
          "score": 6.434246026305333,
          "rank": 92
        },
        "2602.13977v1": {
          "score": 6.433230230642373,
          "rank": 93
        },
        "2602.12444v2": {
          "score": 6.419755357287235,
          "rank": 94
        },
        "2602.10520v2": {
          "score": 6.417635824318762,
          "rank": 95
        },
        "2602.14363v1": {
          "score": 6.417317309661056,
          "rank": 96
        },
        "2602.10503v1": {
          "score": 6.39019953273731,
          "rank": 97
        },
        "2602.16176v1": {
          "score": 6.388516461156539,
          "rank": 98
        },
        "2602.10478v2": {
          "score": 6.383829095034703,
          "rank": 99
        },
        "2602.11779v1": {
          "score": 6.3762121276378245,
          "rank": 100
        },
        "2602.14445v1": {
          "score": 6.336283790216429,
          "rank": 101
        },
        "2602.10224v1": {
          "score": 6.326066446276593,
          "rank": 102
        },
        "2602.16531v1": {
          "score": 6.314839728452836,
          "rank": 103
        },
        "2602.10564v2": {
          "score": 6.313660183646781,
          "rank": 104
        },
        "2602.09162v1": {
          "score": 6.30298157246406,
          "rank": 105
        },
        "2602.15367v1": {
          "score": 6.290630300359938,
          "rank": 106
        },
        "2602.14339v1": {
          "score": 6.27954983375246,
          "rank": 107
        },
        "2602.11648v1": {
          "score": 6.259189487479581,
          "rank": 108
        },
        "2602.09927v1": {
          "score": 6.2561249493494415,
          "rank": 109
        },
        "2602.15830v1": {
          "score": 6.253584471121658,
          "rank": 110
        },
        "2602.12520v1": {
          "score": 6.237214041776339,
          "rank": 111
        },
        "2602.12030v1": {
          "score": 6.232799690346118,
          "rank": 112
        },
        "2602.11455v1": {
          "score": 6.2314140181028606,
          "rank": 113
        },
        "2602.15060v1": {
          "score": 6.20792438050129,
          "rank": 114
        },
        "2602.11143v1": {
          "score": 6.18979773019594,
          "rank": 115
        },
        "2602.11700v1": {
          "score": 6.174826009242714,
          "rank": 116
        },
        "2602.12566v1": {
          "score": 6.16914917633778,
          "rank": 117
        },
        "2602.14318v1": {
          "score": 6.148284610544932,
          "rank": 118
        },
        "2602.09396v1": {
          "score": 6.148053102815124,
          "rank": 119
        },
        "2602.09378v1": {
          "score": 6.142242531003859,
          "rank": 120
        },
        "2602.12395v1": {
          "score": 6.139362224123728,
          "rank": 121
        },
        "2602.12913v1": {
          "score": 6.111135359827357,
          "rank": 122
        },
        "2602.11000v1": {
          "score": 6.098020384636626,
          "rank": 123
        },
        "2602.12529v1": {
          "score": 6.093617065789333,
          "rank": 124
        },
        "2602.15167v1": {
          "score": 6.073962189174968,
          "rank": 125
        },
        "2602.12490v1": {
          "score": 6.067834893802057,
          "rank": 126
        },
        "2602.14676v1": {
          "score": 6.025136567038843,
          "rank": 127
        },
        "2602.11453v1": {
          "score": 6.0205852158603355,
          "rank": 128
        },
        "2602.12872v1": {
          "score": 6.012724582511919,
          "rank": 129
        },
        "2602.12338v1": {
          "score": 6.0126600713799565,
          "rank": 130
        },
        "2602.09324v1": {
          "score": 6.008836043665848,
          "rank": 131
        },
        "2602.10801v1": {
          "score": 6.007756595567454,
          "rank": 132
        },
        "2602.14033v1": {
          "score": 6.000732763743885,
          "rank": 133
        },
        "2602.13348v1": {
          "score": 5.999971708940572,
          "rank": 134
        },
        "2602.09446v1": {
          "score": 5.993674711968912,
          "rank": 135
        },
        "2602.11076v1": {
          "score": 5.991154402663499,
          "rank": 136
        },
        "2602.12851v1": {
          "score": 5.987902786881096,
          "rank": 137
        },
        "2602.14147v1": {
          "score": 5.982898844338178,
          "rank": 138
        },
        "2602.10867v1": {
          "score": 5.964133862443314,
          "rank": 139
        },
        "2602.11661v1": {
          "score": 5.960690072072635,
          "rank": 140
        },
        "2602.14390v1": {
          "score": 5.959034535021116,
          "rank": 141
        },
        "2602.11583v1": {
          "score": 5.955893601579665,
          "rank": 142
        },
        "2602.15533v1": {
          "score": 5.950431187585518,
          "rank": 143
        },
        "2602.15552v1": {
          "score": 5.9488741807784535,
          "rank": 144
        },
        "2602.14726v1": {
          "score": 5.945302047379085,
          "rank": 145
        },
        "2602.09300v1": {
          "score": 5.93972997881516,
          "rank": 146
        },
        "2602.11973v1": {
          "score": 5.933333178981011,
          "rank": 147
        },
        "2602.10357v1": {
          "score": 5.933294904468404,
          "rank": 148
        },
        "2602.14577v1": {
          "score": 5.933103452533036,
          "rank": 149
        },
        "2602.16196v1": {
          "score": 5.929034924544721,
          "rank": 150
        },
        "2602.11978v1": {
          "score": 5.924477958678006,
          "rank": 151
        },
        "2602.12841v1": {
          "score": 5.918378315993779,
          "rank": 152
        },
        "2602.09173v1": {
          "score": 5.918378315993779,
          "rank": 153
        },
        "2602.10067v3": {
          "score": 5.890229139992771,
          "rank": 154
        },
        "2602.14759v1": {
          "score": 5.890023858211398,
          "rank": 155
        },
        "2602.12534v1": {
          "score": 5.872159469229965,
          "rank": 156
        },
        "2602.10019v1": {
          "score": 5.868166185740809,
          "rank": 157
        },
        "2602.16629v1": {
          "score": 5.867816862467455,
          "rank": 158
        },
        "2602.15643v1": {
          "score": 5.865664768072483,
          "rank": 159
        },
        "2602.09370v1": {
          "score": 5.863125858062983,
          "rank": 160
        },
        "2602.08977v1": {
          "score": 5.847979298705521,
          "rank": 161
        },
        "2602.16523v1": {
          "score": 5.839460640664923,
          "rank": 162
        },
        "2602.11780v1": {
          "score": 5.822923406413777,
          "rank": 163
        },
        "2602.13842v1": {
          "score": 5.816767898642835,
          "rank": 164
        },
        "2602.12674v1": {
          "score": 5.812084200184223,
          "rank": 165
        },
        "2602.15245v1": {
          "score": 5.803634900408167,
          "rank": 166
        },
        "2602.10982v1": {
          "score": 5.7986904718880306,
          "rank": 167
        },
        "2602.09022v1": {
          "score": 5.793423914584897,
          "rank": 168
        },
        "2602.14191v1": {
          "score": 5.771944009419888,
          "rank": 169
        },
        "2602.12579v1": {
          "score": 5.763005409178023,
          "rank": 170
        },
        "2602.10437v2": {
          "score": 5.763005409178023,
          "rank": 171
        },
        "2602.14102v1": {
          "score": 5.7521482713269,
          "rank": 172
        },
        "2602.13940v1": {
          "score": 5.742903245529393,
          "rank": 173
        },
        "2602.10493v1": {
          "score": 5.717106790317425,
          "rank": 174
        },
        "2602.16608v1": {
          "score": 5.716360751254577,
          "rank": 175
        },
        "2602.10614v1": {
          "score": 5.7009556411203075,
          "rank": 176
        },
        "2602.14559v1": {
          "score": 5.693256074832843,
          "rank": 177
        },
        "2602.13062v1": {
          "score": 5.673075275980326,
          "rank": 178
        },
        "2602.15733v1": {
          "score": 5.666795473547916,
          "rank": 179
        },
        "2602.13344v1": {
          "score": 5.665133619709569,
          "rank": 180
        },
        "2602.15602v1": {
          "score": 5.664087194067706,
          "rank": 181
        },
        "2602.15640v1": {
          "score": 5.654152138117363,
          "rank": 182
        },
        "2602.14024v1": {
          "score": 5.6512512429386055,
          "rank": 183
        },
        "2602.14635v1": {
          "score": 5.639354760419012,
          "rank": 184
        },
        "2602.10355v1": {
          "score": 5.639311916458785,
          "rank": 185
        },
        "2602.08965v2": {
          "score": 5.6300538334085335,
          "rank": 186
        },
        "2602.09355v1": {
          "score": 5.617991030780662,
          "rank": 187
        },
        "2602.15076v1": {
          "score": 5.601692706624057,
          "rank": 188
        },
        "2602.16353v1": {
          "score": 5.596493152332888,
          "rank": 189
        },
        "2602.11574v1": {
          "score": 5.594793870292387,
          "rank": 190
        },
        "2602.10458v1": {
          "score": 5.591491807837253,
          "rank": 191
        },
        "2602.11262v1": {
          "score": 5.581583038908403,
          "rank": 192
        },
        "2602.13685v1": {
          "score": 5.568102411339419,
          "rank": 193
        },
        "2602.11399v1": {
          "score": 5.567457818986137,
          "rank": 194
        },
        "2602.13154v4": {
          "score": 5.566640369874891,
          "rank": 195
        },
        "2602.15074v1": {
          "score": 5.562911578623366,
          "rank": 196
        },
        "2602.09343v1": {
          "score": 5.561101134683611,
          "rank": 197
        },
        "2602.09767v1": {
          "score": 5.559256949908252,
          "rank": 198
        },
        "2602.11210v1": {
          "score": 5.549334738921428,
          "rank": 199
        },
        "2602.11668v1": {
          "score": 5.537509342511462,
          "rank": 200
        },
        "2602.13307v1": {
          "score": 5.53041440800753,
          "rank": 201
        },
        "2602.11735v1": {
          "score": 5.523694637440482,
          "rank": 202
        },
        "2602.10439v1": {
          "score": 5.523694637440482,
          "rank": 203
        },
        "2602.13987v1": {
          "score": 5.520500481916607,
          "rank": 204
        },
        "2602.12107v1": {
          "score": 5.51650018990814,
          "rank": 205
        },
        "2602.11551v1": {
          "score": 5.512176399032937,
          "rank": 206
        },
        "2602.13367v1": {
          "score": 5.492018520674016,
          "rank": 207
        },
        "2602.12408v1": {
          "score": 5.486763234890295,
          "rank": 208
        },
        "2602.10575v1": {
          "score": 5.486312058590611,
          "rank": 209
        },
        "2602.14160v1": {
          "score": 5.484632578318816,
          "rank": 210
        },
        "2602.09207v1": {
          "score": 5.484632578318816,
          "rank": 211
        },
        "2602.11794v1": {
          "score": 5.483723663111334,
          "rank": 212
        },
        "2602.11128v1": {
          "score": 5.475512373628968,
          "rank": 213
        },
        "2602.15128v1": {
          "score": 5.47244361451769,
          "rank": 214
        },
        "2602.14482v1": {
          "score": 5.457362656657151,
          "rank": 215
        },
        "2602.12036v1": {
          "score": 5.457362656657151,
          "rank": 216
        },
        "2602.14252v1": {
          "score": 5.4390786658065196,
          "rank": 217
        },
        "2602.10052v1": {
          "score": 5.43267118973729,
          "rank": 218
        },
        "2602.12420v1": {
          "score": 5.428359192400598,
          "rank": 219
        },
        "2602.12386v1": {
          "score": 5.425503370406988,
          "rank": 220
        },
        "2602.09351v1": {
          "score": 5.425310833766874,
          "rank": 221
        },
        "2602.11075v1": {
          "score": 5.4214218114001325,
          "rank": 222
        },
        "2602.12259v1": {
          "score": 5.420425672119623,
          "rank": 223
        },
        "2602.16637v1": {
          "score": 5.415868381275377,
          "rank": 224
        },
        "2602.10090v2": {
          "score": 5.412510446485991,
          "rank": 225
        },
        "2602.14322v1": {
          "score": 5.403628329289089,
          "rank": 226
        },
        "2602.15593v1": {
          "score": 5.400656526398633,
          "rank": 227
        },
        "2602.10356v1": {
          "score": 5.391011720418946,
          "rank": 228
        },
        "2602.13024v1": {
          "score": 5.380042335748717,
          "rank": 229
        },
        "2602.13810v1": {
          "score": 5.368404769107189,
          "rank": 230
        },
        "2602.14068v1": {
          "score": 5.368389476662918,
          "rank": 231
        },
        "2602.09578v1": {
          "score": 5.368389476662918,
          "rank": 232
        },
        "2602.11437v1": {
          "score": 5.359651460443404,
          "rank": 233
        },
        "2602.11767v1": {
          "score": 5.343916001853361,
          "rank": 234
        },
        "2602.10587v1": {
          "score": 5.332427439607053,
          "rank": 235
        },
        "2602.14338v1": {
          "score": 5.324982009303035,
          "rank": 236
        },
        "2602.13155v1": {
          "score": 5.320722044417186,
          "rank": 237
        },
        "2602.12123v1": {
          "score": 5.307524634438141,
          "rank": 238
        },
        "2602.09598v1": {
          "score": 5.303429813947477,
          "rank": 239
        },
        "2602.11472v1": {
          "score": 5.30092411608045,
          "rank": 240
        },
        "2602.14709v1": {
          "score": 5.298891862516018,
          "rank": 241
        },
        "2602.16305v1": {
          "score": 5.295981419692722,
          "rank": 242
        },
        "2602.12691v1": {
          "score": 5.294343375863223,
          "rank": 243
        },
        "2602.09971v1": {
          "score": 5.284131066324953,
          "rank": 244
        },
        "2602.14293v1": {
          "score": 5.282270875616454,
          "rank": 245
        },
        "2602.13912v2": {
          "score": 5.276106457505849,
          "rank": 246
        },
        "2602.14587v1": {
          "score": 5.265377654305248,
          "rank": 247
        },
        "2602.09719v1": {
          "score": 5.259477127554052,
          "rank": 248
        },
        "2602.10699v2": {
          "score": 5.256971498596495,
          "rank": 249
        },
        "2602.13802v1": {
          "score": 5.255268547338927,
          "rank": 250
        },
        "2602.10238v1": {
          "score": 5.252508680486575,
          "rank": 251
        },
        "2602.11759v1": {
          "score": 5.252411146115283,
          "rank": 252
        },
        "2602.15146v2": {
          "score": 5.24653338848482,
          "rank": 253
        },
        "2602.11089v1": {
          "score": 5.240239453266644,
          "rank": 254
        },
        "2602.15684v1": {
          "score": 5.209570687812947,
          "rank": 255
        },
        "2602.11669v1": {
          "score": 5.198330710043471,
          "rank": 256
        },
        "2602.09155v1": {
          "score": 5.184216399738244,
          "rank": 257
        },
        "2602.09501v1": {
          "score": 5.178493802921211,
          "rank": 258
        },
        "2602.11360v1": {
          "score": 5.1765127929386665,
          "rank": 259
        },
        "2602.09566v1": {
          "score": 5.1765127929386665,
          "rank": 260
        },
        "2602.16018v1": {
          "score": 5.175487600814066,
          "rank": 261
        },
        "2602.09367v1": {
          "score": 5.161166734147619,
          "rank": 262
        },
        "2602.11730v1": {
          "score": 5.1581518570962634,
          "rank": 263
        },
        "2602.09685v1": {
          "score": 5.158127178432125,
          "rank": 264
        },
        "2602.14872v1": {
          "score": 5.152550405184103,
          "rank": 265
        },
        "2602.11208v1": {
          "score": 5.149708626174641,
          "rank": 266
        },
        "2602.14234v1": {
          "score": 5.146615970416499,
          "rank": 267
        },
        "2602.14351v1": {
          "score": 5.143965300098561,
          "rank": 268
        },
        "2602.10863v1": {
          "score": 5.143965300098561,
          "rank": 269
        },
        "2602.14225v1": {
          "score": 5.14204198769273,
          "rank": 270
        },
        "2602.12517v1": {
          "score": 5.13541123600547,
          "rank": 271
        },
        "2602.12628v2": {
          "score": 5.1340247297482025,
          "rank": 272
        },
        "2602.09969v1": {
          "score": 5.124559702817735,
          "rank": 273
        },
        "2602.11701v1": {
          "score": 5.116148295246219,
          "rank": 274
        },
        "2602.10150v1": {
          "score": 5.109431458140917,
          "rank": 275
        },
        "2602.10655v2": {
          "score": 5.107834379155431,
          "rank": 276
        },
        "2602.09519v1": {
          "score": 5.101679011955058,
          "rank": 277
        },
        "2602.12681v1": {
          "score": 5.096116550978809,
          "rank": 278
        },
        "2602.13021v2": {
          "score": 5.09404377995731,
          "rank": 279
        },
        "2602.09443v1": {
          "score": 5.0885685981439375,
          "rank": 280
        },
        "2602.13823v1": {
          "score": 5.078596376439434,
          "rank": 281
        },
        "2602.16177v1": {
          "score": 5.073404757726496,
          "rank": 282
        },
        "2602.12744v1": {
          "score": 5.053889064365811,
          "rank": 283
        },
        "2602.09474v1": {
          "score": 5.051538676874938,
          "rank": 284
        },
        "2602.11825v1": {
          "score": 5.042655634069369,
          "rank": 285
        },
        "2602.15620v2": {
          "score": 5.039731846993918,
          "rank": 286
        },
        "2602.11465v1": {
          "score": 5.02615759788095,
          "rank": 287
        },
        "2602.16062v1": {
          "score": 5.024352079446946,
          "rank": 288
        },
        "2602.14098v1": {
          "score": 5.018814732501979,
          "rank": 289
        },
        "2602.14939v1": {
          "score": 5.018133356096512,
          "rank": 290
        },
        "2602.14701v1": {
          "score": 5.017534290800607,
          "rank": 291
        },
        "2602.12469v1": {
          "score": 5.0116736868049125,
          "rank": 292
        },
        "2602.16675v1": {
          "score": 5.010705329167109,
          "rank": 293
        },
        "2602.11655v1": {
          "score": 5.005880674962532,
          "rank": 294
        },
        "2602.15449v1": {
          "score": 4.99573712385381,
          "rank": 295
        },
        "2602.10949v1": {
          "score": 4.991455116879652,
          "rank": 296
        },
        "2602.11523v1": {
          "score": 4.986301682025506,
          "rank": 297
        },
        "2602.10266v1": {
          "score": 4.9717146491211395,
          "rank": 298
        },
        "2602.10407v1": {
          "score": 4.970520848561613,
          "rank": 299
        },
        "2602.14110v1": {
          "score": 4.967604960927142,
          "rank": 300
        },
        "2602.15490v1": {
          "score": 4.954597729405061,
          "rank": 301
        },
        "2602.12268v1": {
          "score": 4.948840114818873,
          "rank": 302
        },
        "2602.13681v1": {
          "score": 4.937437056911906,
          "rank": 303
        },
        "2602.09238v3": {
          "score": 4.936740670927742,
          "rank": 304
        },
        "2602.14868v1": {
          "score": 4.935403674333406,
          "rank": 305
        },
        "2602.10299v1": {
          "score": 4.931142493852571,
          "rank": 306
        },
        "2602.14186v1": {
          "score": 4.926627143551114,
          "rank": 307
        },
        "2602.14615v1": {
          "score": 4.922083833542825,
          "rank": 308
        },
        "2602.15930v1": {
          "score": 4.917622758048328,
          "rank": 309
        },
        "2602.12524v1": {
          "score": 4.908956717771149,
          "rank": 310
        },
        "2602.12360v1": {
          "score": 4.908956717771149,
          "rank": 311
        },
        "2602.11463v1": {
          "score": 4.905414091062933,
          "rank": 312
        },
        "2602.13559v1": {
          "score": 4.904612688003866,
          "rank": 313
        },
        "2602.11118v1": {
          "score": 4.902184866764924,
          "rank": 314
        },
        "2602.13330v1": {
          "score": 4.894300116381092,
          "rank": 315
        },
        "2602.11861v1": {
          "score": 4.8931514871524175,
          "rank": 316
        },
        "2602.13156v1": {
          "score": 4.892374577973242,
          "rank": 317
        },
        "2602.16564v1": {
          "score": 4.88556582730311,
          "rank": 318
        },
        "2602.16468v1": {
          "score": 4.878289618103864,
          "rank": 319
        },
        "2602.16165v1": {
          "score": 4.861168773635411,
          "rank": 320
        },
        "2602.11801v1": {
          "score": 4.853911160500825,
          "rank": 321
        },
        "2602.13814v1": {
          "score": 4.852985781673521,
          "rank": 322
        },
        "2602.16000v1": {
          "score": 4.8528584656376585,
          "rank": 323
        },
        "2602.16101v1": {
          "score": 4.851141429698304,
          "rank": 324
        },
        "2602.13601v1": {
          "score": 4.847862288309076,
          "rank": 325
        },
        "2602.11549v1": {
          "score": 4.84685799471001,
          "rank": 326
        },
        "2602.13910v1": {
          "score": 4.844544198149716,
          "rank": 327
        },
        "2602.09782v1": {
          "score": 4.836754396704438,
          "rank": 328
        },
        "2602.09730v1": {
          "score": 4.831885328539555,
          "rank": 329
        },
        "2602.10006v1": {
          "score": 4.825549117207784,
          "rank": 330
        },
        "2602.12205v2": {
          "score": 4.8224097443354985,
          "rank": 331
        },
        "2602.10261v1": {
          "score": 4.814684023827905,
          "rank": 332
        },
        "2602.15632v1": {
          "score": 4.8086593877412795,
          "rank": 333
        },
        "2602.14526v1": {
          "score": 4.80794672764601,
          "rank": 334
        },
        "2602.12530v1": {
          "score": 4.80794672764601,
          "rank": 335
        },
        "2602.13455v1": {
          "score": 4.79836554178357,
          "rank": 336
        },
        "2602.13865v1": {
          "score": 4.779909416047424,
          "rank": 337
        },
        "2602.13022v1": {
          "score": 4.77886260102609,
          "rank": 338
        },
        "2602.16515v1": {
          "score": 4.774228159932979,
          "rank": 339
        },
        "2602.14244v1": {
          "score": 4.76535922207145,
          "rank": 340
        },
        "2602.09023v1": {
          "score": 4.762732046520343,
          "rank": 341
        },
        "2602.13055v1": {
          "score": 4.752750132289173,
          "rank": 342
        },
        "2602.10875v1": {
          "score": 4.752630508347432,
          "rank": 343
        },
        "2602.15564v1": {
          "score": 4.75137820242251,
          "rank": 344
        },
        "2602.11834v1": {
          "score": 4.737856633763199,
          "rank": 345
        },
        "2602.09746v1": {
          "score": 4.737856633763199,
          "rank": 346
        },
        "2602.14582v1": {
          "score": 4.731111677176568,
          "rank": 347
        },
        "2602.10432v1": {
          "score": 4.73070020737967,
          "rank": 348
        },
        "2602.16322v1": {
          "score": 4.73070020737967,
          "rank": 349
        },
        "2602.15224v1": {
          "score": 4.709158551776275,
          "rank": 350
        },
        "2602.10870v1": {
          "score": 4.703979650959051,
          "rank": 351
        },
        "2602.13930v1": {
          "score": 4.701152367583246,
          "rank": 352
        },
        "2602.10819v1": {
          "score": 4.696162509527217,
          "rank": 353
        },
        "2602.11239v1": {
          "score": 4.695771730754051,
          "rank": 354
        },
        "2602.14280v1": {
          "score": 4.694323521149672,
          "rank": 355
        },
        "2602.13010v1": {
          "score": 4.693489873339207,
          "rank": 356
        },
        "2602.12933v1": {
          "score": 4.688767001805003,
          "rank": 357
        },
        "2602.09869v1": {
          "score": 4.686477861041931,
          "rank": 358
        },
        "2602.15923v1": {
          "score": 4.674209663162975,
          "rank": 359
        },
        "2602.11630v1": {
          "score": 4.661446117930924,
          "rank": 360
        },
        "2602.15780v1": {
          "score": 4.654054507027724,
          "rank": 361
        },
        "2602.15617v1": {
          "score": 4.644395679139677,
          "rank": 362
        },
        "2602.11679v1": {
          "score": 4.642250392385131,
          "rank": 363
        },
        "2602.15579v1": {
          "score": 4.637235064946654,
          "rank": 364
        },
        "2602.16586v1": {
          "score": 4.633830783444431,
          "rank": 365
        },
        "2602.12656v1": {
          "score": 4.633388453451153,
          "rank": 366
        },
        "2602.12757v1": {
          "score": 4.628184793870221,
          "rank": 367
        },
        "2602.10155v1": {
          "score": 4.622786953821787,
          "rank": 368
        },
        "2602.15783v1": {
          "score": 4.6226704644979515,
          "rank": 369
        },
        "2602.12215v1": {
          "score": 4.621749349166739,
          "rank": 370
        },
        "2602.15005v1": {
          "score": 4.607009965945379,
          "rank": 371
        },
        "2602.14078v1": {
          "score": 4.598285556219784,
          "rank": 372
        },
        "2602.11145v1": {
          "score": 4.565295078836724,
          "rank": 373
        },
        "2602.15306v1": {
          "score": 4.5578503174733935,
          "rank": 374
        },
        "2602.09572v2": {
          "score": 4.550944576224138,
          "rank": 375
        },
        "2602.10094v1": {
          "score": 4.5486620609955555,
          "rank": 376
        },
        "2602.12087v1": {
          "score": 4.54664332772998,
          "rank": 377
        },
        "2602.16005v1": {
          "score": 4.538877259175222,
          "rank": 378
        },
        "2602.12458v1": {
          "score": 4.512871438018836,
          "rank": 379
        },
        "2602.16224v1": {
          "score": 4.504138608076191,
          "rank": 380
        },
        "2602.10549v1": {
          "score": 4.502260151691887,
          "rank": 381
        },
        "2602.13121v1": {
          "score": 4.501757821426439,
          "rank": 382
        },
        "2602.13309v1": {
          "score": 4.496177771105804,
          "rank": 383
        },
        "2602.10397v1": {
          "score": 4.489789713130398,
          "rank": 384
        },
        "2602.09315v1": {
          "score": 4.482021768957759,
          "rank": 385
        },
        "2602.13043v1": {
          "score": 4.482021768957759,
          "rank": 386
        },
        "2602.09909v1": {
          "score": 4.476114809032473,
          "rank": 387
        },
        "2602.09591v2": {
          "score": 4.472601644704998,
          "rank": 388
        },
        "2602.11028v1": {
          "score": 4.469794614731437,
          "rank": 389
        },
        "2602.12162v1": {
          "score": 4.468075282399168,
          "rank": 390
        },
        "2602.09843v3": {
          "score": 4.468075282399168,
          "rank": 391
        },
        "2602.09792v1": {
          "score": 4.465532537061679,
          "rank": 392
        },
        "2602.10573v1": {
          "score": 4.4634025429280175,
          "rank": 393
        },
        "2602.11810v1": {
          "score": 4.461476207083811,
          "rank": 394
        },
        "2602.10784v1": {
          "score": 4.456857273877693,
          "rank": 395
        },
        "2602.10285v2": {
          "score": 4.452403875295931,
          "rank": 396
        },
        "2602.15820v1": {
          "score": 4.44804587374837,
          "rank": 397
        },
        "2602.12643v1": {
          "score": 4.438734206340418,
          "rank": 398
        },
        "2602.10829v1": {
          "score": 4.436051078351444,
          "rank": 399
        },
        "2602.11516v1": {
          "score": 4.405172766451727,
          "rank": 400
        }
      }
    },
    {
      "type": "llm_query",
      "tag": "SR",
      "paper_tag": "query:SR",
      "query_text": "帮我找符号回归与其他学科交叉并且有实证实验的最新论文",
      "logic_cn": "语义上偏向跨学科和实证验证。",
      "boolean_expr": "",
      "bm25_mode": "normal",
      "sim_scores": {
        "2602.14965v1": {
          "score": 0.0,
          "rank": 1
        },
        "2602.14961v1": {
          "score": 0.0,
          "rank": 2
        },
        "2602.14960v1": {
          "score": 0.0,
          "rank": 3
        },
        "2602.14958v1": {
          "score": 0.0,
          "rank": 4
        },
        "2602.14955v1": {
          "score": 0.0,
          "rank": 5
        },
        "2602.14952v1": {
          "score": 0.0,
          "rank": 6
        },
        "2602.14951v1": {
          "score": 0.0,
          "rank": 7
        },
        "2602.15092v1": {
          "score": 0.0,
          "rank": 8
        },
        "2602.14948v1": {
          "score": 0.0,
          "rank": 9
        },
        "2602.14947v1": {
          "score": 0.0,
          "rank": 10
        },
        "2602.15091v1": {
          "score": 0.0,
          "rank": 11
        },
        "2602.14941v1": {
          "score": 0.0,
          "rank": 12
        },
        "2602.14940v1": {
          "score": 0.0,
          "rank": 13
        },
        "2602.14939v1": {
          "score": 0.0,
          "rank": 14
        },
        "2602.14938v1": {
          "score": 0.0,
          "rank": 15
        },
        "2602.14934v1": {
          "score": 0.0,
          "rank": 16
        },
        "2602.14929v1": {
          "score": 0.0,
          "rank": 17
        },
        "2602.14928v1": {
          "score": 0.0,
          "rank": 18
        },
        "2602.14926v1": {
          "score": 0.0,
          "rank": 19
        },
        "2602.14922v1": {
          "score": 0.0,
          "rank": 20
        },
        "2602.14919v1": {
          "score": 0.0,
          "rank": 21
        },
        "2602.14917v1": {
          "score": 0.0,
          "rank": 22
        },
        "2602.14915v1": {
          "score": 0.0,
          "rank": 23
        },
        "2602.14914v1": {
          "score": 0.0,
          "rank": 24
        },
        "2602.14913v1": {
          "score": 0.0,
          "rank": 25
        },
        "2602.15090v1": {
          "score": 0.0,
          "rank": 26
        },
        "2602.14910v1": {
          "score": 0.0,
          "rank": 27
        },
        "2602.14907v2": {
          "score": 0.0,
          "rank": 28
        },
        "2602.14904v1": {
          "score": 0.0,
          "rank": 29
        },
        "2602.14903v1": {
          "score": 0.0,
          "rank": 30
        },
        "2602.14901v1": {
          "score": 0.0,
          "rank": 31
        },
        "2602.14896v1": {
          "score": 0.0,
          "rank": 32
        },
        "2602.14890v1": {
          "score": 0.0,
          "rank": 33
        },
        "2602.14889v1": {
          "score": 0.0,
          "rank": 34
        },
        "2602.14885v1": {
          "score": 0.0,
          "rank": 35
        },
        "2602.14881v1": {
          "score": 0.0,
          "rank": 36
        },
        "2602.14879v1": {
          "score": 0.0,
          "rank": 37
        },
        "2602.14878v1": {
          "score": 0.0,
          "rank": 38
        },
        "2602.14874v1": {
          "score": 0.0,
          "rank": 39
        },
        "2602.14872v1": {
          "score": 0.0,
          "rank": 40
        },
        "2602.14871v1": {
          "score": 0.0,
          "rank": 41
        },
        "2602.14869v1": {
          "score": 0.0,
          "rank": 42
        },
        "2602.14868v1": {
          "score": 0.0,
          "rank": 43
        },
        "2602.14867v1": {
          "score": 0.0,
          "rank": 44
        },
        "2602.14865v1": {
          "score": 0.0,
          "rank": 45
        },
        "2602.14862v1": {
          "score": 0.0,
          "rank": 46
        },
        "2602.14859v1": {
          "score": 0.0,
          "rank": 47
        },
        "2602.14858v1": {
          "score": 0.0,
          "rank": 48
        },
        "2602.14857v1": {
          "score": 0.0,
          "rank": 49
        },
        "2602.14855v1": {
          "score": 0.0,
          "rank": 50
        },
        "2602.14853v1": {
          "score": 0.0,
          "rank": 51
        },
        "2602.14852v1": {
          "score": 0.0,
          "rank": 52
        },
        "2602.14850v1": {
          "score": 0.0,
          "rank": 53
        },
        "2602.14849v1": {
          "score": 0.0,
          "rank": 54
        },
        "2602.14846v1": {
          "score": 0.0,
          "rank": 55
        },
        "2602.14844v1": {
          "score": 0.0,
          "rank": 56
        },
        "2602.14837v1": {
          "score": 0.0,
          "rank": 57
        },
        "2602.14835v1": {
          "score": 0.0,
          "rank": 58
        },
        "2602.14834v1": {
          "score": 0.0,
          "rank": 59
        },
        "2602.14833v1": {
          "score": 0.0,
          "rank": 60
        },
        "2602.14832v1": {
          "score": 0.0,
          "rank": 61
        },
        "2602.14831v1": {
          "score": 0.0,
          "rank": 62
        },
        "2602.14828v1": {
          "score": 0.0,
          "rank": 63
        },
        "2602.14819v1": {
          "score": 0.0,
          "rank": 64
        },
        "2602.14815v1": {
          "score": 0.0,
          "rank": 65
        },
        "2602.14816v1": {
          "score": 0.0,
          "rank": 66
        },
        "2602.14814v1": {
          "score": 0.0,
          "rank": 67
        },
        "2602.14812v1": {
          "score": 0.0,
          "rank": 68
        },
        "2602.15089v1": {
          "score": 0.0,
          "rank": 69
        },
        "2602.14805v1": {
          "score": 0.0,
          "rank": 70
        },
        "2602.14799v1": {
          "score": 0.0,
          "rank": 71
        },
        "2602.15909v1": {
          "score": 0.0,
          "rank": 72
        },
        "2602.14798v1": {
          "score": 0.0,
          "rank": 73
        },
        "2602.15088v1": {
          "score": 0.0,
          "rank": 74
        },
        "2602.14795v1": {
          "score": 0.0,
          "rank": 75
        },
        "2602.14794v1": {
          "score": 0.0,
          "rank": 76
        },
        "2602.14793v1": {
          "score": 0.0,
          "rank": 77
        },
        "2602.14791v1": {
          "score": 0.0,
          "rank": 78
        },
        "2602.14789v1": {
          "score": 0.0,
          "rank": 79
        },
        "2602.14788v1": {
          "score": 0.0,
          "rank": 80
        },
        "2602.14785v1": {
          "score": 0.0,
          "rank": 81
        },
        "2602.14784v1": {
          "score": 0.0,
          "rank": 82
        },
        "2602.14783v1": {
          "score": 0.0,
          "rank": 83
        },
        "2602.14780v1": {
          "score": 0.0,
          "rank": 84
        },
        "2602.14778v2": {
          "score": 0.0,
          "rank": 85
        },
        "2602.14777v1": {
          "score": 0.0,
          "rank": 86
        },
        "2602.14772v1": {
          "score": 0.0,
          "rank": 87
        },
        "2602.14771v1": {
          "score": 0.0,
          "rank": 88
        },
        "2602.14770v2": {
          "score": 0.0,
          "rank": 89
        },
        "2602.14768v1": {
          "score": 0.0,
          "rank": 90
        },
        "2602.14767v1": {
          "score": 0.0,
          "rank": 91
        },
        "2602.14763v1": {
          "score": 0.0,
          "rank": 92
        },
        "2602.14761v1": {
          "score": 0.0,
          "rank": 93
        },
        "2602.14760v1": {
          "score": 0.0,
          "rank": 94
        },
        "2602.14759v1": {
          "score": 0.0,
          "rank": 95
        },
        "2602.14757v1": {
          "score": 0.0,
          "rank": 96
        },
        "2602.14755v1": {
          "score": 0.0,
          "rank": 97
        },
        "2602.15087v1": {
          "score": 0.0,
          "rank": 98
        },
        "2602.14751v1": {
          "score": 0.0,
          "rank": 99
        },
        "2602.14749v1": {
          "score": 0.0,
          "rank": 100
        },
        "2602.14748v1": {
          "score": 0.0,
          "rank": 101
        },
        "2602.14744v1": {
          "score": 0.0,
          "rank": 102
        },
        "2602.14743v1": {
          "score": 0.0,
          "rank": 103
        },
        "2602.14740v1": {
          "score": 0.0,
          "rank": 104
        },
        "2602.14737v1": {
          "score": 0.0,
          "rank": 105
        },
        "2602.14735v1": {
          "score": 0.0,
          "rank": 106
        },
        "2602.14733v1": {
          "score": 0.0,
          "rank": 107
        },
        "2602.14731v1": {
          "score": 0.0,
          "rank": 108
        },
        "2602.14729v1": {
          "score": 0.0,
          "rank": 109
        },
        "2602.14728v1": {
          "score": 0.0,
          "rank": 110
        },
        "2602.14726v1": {
          "score": 0.0,
          "rank": 111
        },
        "2602.15086v1": {
          "score": 0.0,
          "rank": 112
        },
        "2602.14722v1": {
          "score": 0.0,
          "rank": 113
        },
        "2602.14721v1": {
          "score": 0.0,
          "rank": 114
        },
        "2602.14717v1": {
          "score": 0.0,
          "rank": 115
        },
        "2602.14710v1": {
          "score": 0.0,
          "rank": 116
        },
        "2602.14708v1": {
          "score": 0.0,
          "rank": 117
        },
        "2602.14706v1": {
          "score": 0.0,
          "rank": 118
        },
        "2602.14705v1": {
          "score": 0.0,
          "rank": 119
        },
        "2602.14704v1": {
          "score": 0.0,
          "rank": 120
        },
        "2602.14701v1": {
          "score": 0.0,
          "rank": 121
        },
        "2602.14699v1": {
          "score": 0.0,
          "rank": 122
        },
        "2602.14697v1": {
          "score": 0.0,
          "rank": 123
        },
        "2602.14696v1": {
          "score": 0.0,
          "rank": 124
        },
        "2602.15084v1": {
          "score": 0.0,
          "rank": 125
        },
        "2602.14691v1": {
          "score": 0.0,
          "rank": 126
        },
        "2602.14690v1": {
          "score": 0.0,
          "rank": 127
        },
        "2602.14689v1": {
          "score": 0.0,
          "rank": 128
        },
        "2602.14687v1": {
          "score": 0.0,
          "rank": 129
        },
        "2602.14684v1": {
          "score": 0.0,
          "rank": 130
        },
        "2602.14682v1": {
          "score": 0.0,
          "rank": 131
        },
        "2602.14681v1": {
          "score": 0.0,
          "rank": 132
        },
        "2602.14679v1": {
          "score": 0.0,
          "rank": 133
        },
        "2602.14677v1": {
          "score": 0.0,
          "rank": 134
        },
        "2602.14676v1": {
          "score": 0.0,
          "rank": 135
        },
        "2602.14675v1": {
          "score": 0.0,
          "rank": 136
        },
        "2602.14674v2": {
          "score": 0.0,
          "rank": 137
        },
        "2602.14672v1": {
          "score": 0.0,
          "rank": 138
        },
        "2602.14670v1": {
          "score": 0.0,
          "rank": 139
        },
        "2602.14668v1": {
          "score": 0.0,
          "rank": 140
        },
        "2602.14666v1": {
          "score": 0.0,
          "rank": 141
        },
        "2602.14664v1": {
          "score": 0.0,
          "rank": 142
        },
        "2602.14663v1": {
          "score": 0.0,
          "rank": 143
        },
        "2602.14662v1": {
          "score": 0.0,
          "rank": 144
        },
        "2602.14656v1": {
          "score": 0.0,
          "rank": 145
        },
        "2602.14655v1": {
          "score": 0.0,
          "rank": 146
        },
        "2602.14653v1": {
          "score": 0.0,
          "rank": 147
        },
        "2602.14652v1": {
          "score": 0.0,
          "rank": 148
        },
        "2602.14649v1": {
          "score": 0.0,
          "rank": 149
        },
        "2602.14648v1": {
          "score": 0.0,
          "rank": 150
        },
        "2602.14643v2": {
          "score": 0.0,
          "rank": 151
        },
        "2602.14642v1": {
          "score": 0.0,
          "rank": 152
        },
        "2602.14641v1": {
          "score": 0.0,
          "rank": 153
        },
        "2602.14636v1": {
          "score": 0.0,
          "rank": 154
        },
        "2602.14635v1": {
          "score": 0.0,
          "rank": 155
        },
        "2602.14634v1": {
          "score": 0.0,
          "rank": 156
        },
        "2602.14633v1": {
          "score": 0.0,
          "rank": 157
        },
        "2602.14626v1": {
          "score": 0.0,
          "rank": 158
        },
        "2602.14625v1": {
          "score": 0.0,
          "rank": 159
        },
        "2602.15082v1": {
          "score": 0.0,
          "rank": 160
        },
        "2602.14622v2": {
          "score": 0.0,
          "rank": 161
        },
        "2602.14615v1": {
          "score": 0.0,
          "rank": 162
        },
        "2602.14612v1": {
          "score": 0.0,
          "rank": 163
        },
        "2602.14611v1": {
          "score": 0.0,
          "rank": 164
        },
        "2602.14607v1": {
          "score": 0.0,
          "rank": 165
        },
        "2602.14606v1": {
          "score": 0.0,
          "rank": 166
        },
        "2602.14602v1": {
          "score": 0.0,
          "rank": 167
        },
        "2602.14598v1": {
          "score": 0.0,
          "rank": 168
        },
        "2602.14595v1": {
          "score": 0.0,
          "rank": 169
        },
        "2602.14594v1": {
          "score": 0.0,
          "rank": 170
        },
        "2602.14592v1": {
          "score": 0.0,
          "rank": 171
        },
        "2602.14591v1": {
          "score": 0.0,
          "rank": 172
        },
        "2602.14589v1": {
          "score": 0.0,
          "rank": 173
        },
        "2602.14587v1": {
          "score": 0.0,
          "rank": 174
        },
        "2602.14584v1": {
          "score": 0.0,
          "rank": 175
        },
        "2602.14582v1": {
          "score": 0.0,
          "rank": 176
        },
        "2602.14580v1": {
          "score": 0.0,
          "rank": 177
        },
        "2602.14578v1": {
          "score": 0.0,
          "rank": 178
        },
        "2602.14577v1": {
          "score": 0.0,
          "rank": 179
        },
        "2602.14575v1": {
          "score": 0.0,
          "rank": 180
        },
        "2602.14572v2": {
          "score": 0.0,
          "rank": 181
        },
        "2602.14573v1": {
          "score": 0.0,
          "rank": 182
        },
        "2602.14571v1": {
          "score": 0.0,
          "rank": 183
        },
        "2602.14566v1": {
          "score": 0.0,
          "rank": 184
        },
        "2602.14564v1": {
          "score": 0.0,
          "rank": 185
        },
        "2602.14561v1": {
          "score": 0.0,
          "rank": 186
        },
        "2602.14560v1": {
          "score": 0.0,
          "rank": 187
        },
        "2602.14559v1": {
          "score": 0.0,
          "rank": 188
        },
        "2602.14553v1": {
          "score": 0.0,
          "rank": 189
        },
        "2602.14552v1": {
          "score": 0.0,
          "rank": 190
        },
        "2602.14551v1": {
          "score": 0.0,
          "rank": 191
        },
        "2602.14550v1": {
          "score": 0.0,
          "rank": 192
        },
        "2602.14544v1": {
          "score": 0.0,
          "rank": 193
        },
        "2602.14543v1": {
          "score": 0.0,
          "rank": 194
        },
        "2602.14540v1": {
          "score": 0.0,
          "rank": 195
        },
        "2602.14539v1": {
          "score": 0.0,
          "rank": 196
        },
        "2602.14536v1": {
          "score": 0.0,
          "rank": 197
        },
        "2602.14534v1": {
          "score": 0.0,
          "rank": 198
        },
        "2602.15078v1": {
          "score": 0.0,
          "rank": 199
        },
        "2602.14529v1": {
          "score": 0.0,
          "rank": 200
        },
        "2602.14528v1": {
          "score": 0.0,
          "rank": 201
        },
        "2602.14526v1": {
          "score": 0.0,
          "rank": 202
        },
        "2602.14525v1": {
          "score": 0.0,
          "rank": 203
        },
        "2602.14524v1": {
          "score": 0.0,
          "rank": 204
        },
        "2602.14523v1": {
          "score": 0.0,
          "rank": 205
        },
        "2602.14519v1": {
          "score": 0.0,
          "rank": 206
        },
        "2602.14518v1": {
          "score": 0.0,
          "rank": 207
        },
        "2602.14517v1": {
          "score": 0.0,
          "rank": 208
        },
        "2602.14516v1": {
          "score": 0.0,
          "rank": 209
        },
        "2602.14514v1": {
          "score": 0.0,
          "rank": 210
        },
        "2602.14512v1": {
          "score": 0.0,
          "rank": 211
        },
        "2602.14509v1": {
          "score": 0.0,
          "rank": 212
        },
        "2602.14506v1": {
          "score": 0.0,
          "rank": 213
        },
        "2602.14505v1": {
          "score": 0.0,
          "rank": 214
        },
        "2602.14503v1": {
          "score": 0.0,
          "rank": 215
        },
        "2602.14502v1": {
          "score": 0.0,
          "rank": 216
        },
        "2602.14501v1": {
          "score": 0.0,
          "rank": 217
        },
        "2602.14498v1": {
          "score": 0.0,
          "rank": 218
        },
        "2602.14495v1": {
          "score": 0.0,
          "rank": 219
        },
        "2602.14493v1": {
          "score": 0.0,
          "rank": 220
        },
        "2602.14492v2": {
          "score": 0.0,
          "rank": 221
        },
        "2602.14490v1": {
          "score": 0.0,
          "rank": 222
        },
        "2602.14488v1": {
          "score": 0.0,
          "rank": 223
        },
        "2602.14486v1": {
          "score": 0.0,
          "rank": 224
        },
        "2602.14482v1": {
          "score": 0.0,
          "rank": 225
        },
        "2602.14481v1": {
          "score": 0.0,
          "rank": 226
        },
        "2602.14478v1": {
          "score": 0.0,
          "rank": 227
        },
        "2602.14477v1": {
          "score": 0.0,
          "rank": 228
        },
        "2602.14476v1": {
          "score": 0.0,
          "rank": 229
        },
        "2602.14474v1": {
          "score": 0.0,
          "rank": 230
        },
        "2602.14473v1": {
          "score": 0.0,
          "rank": 231
        },
        "2602.14472v1": {
          "score": 0.0,
          "rank": 232
        },
        "2602.14471v1": {
          "score": 0.0,
          "rank": 233
        },
        "2602.15076v1": {
          "score": 0.0,
          "rank": 234
        },
        "2602.14470v1": {
          "score": 0.0,
          "rank": 235
        },
        "2602.14469v1": {
          "score": 0.0,
          "rank": 236
        },
        "2602.14468v1": {
          "score": 0.0,
          "rank": 237
        },
        "2602.14467v1": {
          "score": 0.0,
          "rank": 238
        },
        "2602.14466v1": {
          "score": 0.0,
          "rank": 239
        },
        "2602.14464v1": {
          "score": 0.0,
          "rank": 240
        },
        "2602.14462v1": {
          "score": 0.0,
          "rank": 241
        },
        "2602.14457v1": {
          "score": 0.0,
          "rank": 242
        },
        "2602.14456v1": {
          "score": 0.0,
          "rank": 243
        },
        "2602.14452v1": {
          "score": 0.0,
          "rank": 244
        },
        "2602.14451v1": {
          "score": 0.0,
          "rank": 245
        },
        "2602.14445v1": {
          "score": 0.0,
          "rank": 246
        },
        "2602.14444v1": {
          "score": 0.0,
          "rank": 247
        },
        "2602.14443v1": {
          "score": 0.0,
          "rank": 248
        },
        "2602.15074v1": {
          "score": 0.0,
          "rank": 249
        },
        "2602.14442v1": {
          "score": 0.0,
          "rank": 250
        },
        "2602.14441v1": {
          "score": 0.0,
          "rank": 251
        },
        "2602.14440v1": {
          "score": 0.0,
          "rank": 252
        },
        "2602.14438v1": {
          "score": 0.0,
          "rank": 253
        },
        "2602.14436v1": {
          "score": 0.0,
          "rank": 254
        },
        "2602.14434v1": {
          "score": 0.0,
          "rank": 255
        },
        "2602.14433v1": {
          "score": 0.0,
          "rank": 256
        },
        "2602.14432v1": {
          "score": 0.0,
          "rank": 257
        },
        "2602.14431v1": {
          "score": 0.0,
          "rank": 258
        },
        "2602.14430v1": {
          "score": 0.0,
          "rank": 259
        },
        "2602.14428v1": {
          "score": 0.0,
          "rank": 260
        },
        "2602.14425v1": {
          "score": 0.0,
          "rank": 261
        },
        "2602.14423v1": {
          "score": 0.0,
          "rank": 262
        },
        "2602.14419v1": {
          "score": 0.0,
          "rank": 263
        },
        "2602.14415v1": {
          "score": 0.0,
          "rank": 264
        },
        "2602.14413v1": {
          "score": 0.0,
          "rank": 265
        },
        "2602.14409v1": {
          "score": 0.0,
          "rank": 266
        },
        "2602.14408v1": {
          "score": 0.0,
          "rank": 267
        },
        "2602.14406v1": {
          "score": 0.0,
          "rank": 268
        },
        "2602.14407v1": {
          "score": 0.0,
          "rank": 269
        },
        "2602.14404v1": {
          "score": 0.0,
          "rank": 270
        },
        "2602.14401v1": {
          "score": 0.0,
          "rank": 271
        },
        "2602.14399v1": {
          "score": 0.0,
          "rank": 272
        },
        "2602.14397v1": {
          "score": 0.0,
          "rank": 273
        },
        "2602.14393v1": {
          "score": 0.0,
          "rank": 274
        },
        "2602.14391v1": {
          "score": 0.0,
          "rank": 275
        },
        "2602.14390v1": {
          "score": 0.0,
          "rank": 276
        },
        "2602.14386v1": {
          "score": 0.0,
          "rank": 277
        },
        "2602.14385v1": {
          "score": 0.0,
          "rank": 278
        },
        "2602.14384v1": {
          "score": 0.0,
          "rank": 279
        },
        "2602.14381v1": {
          "score": 0.0,
          "rank": 280
        },
        "2602.14379v1": {
          "score": 0.0,
          "rank": 281
        },
        "2602.14376v1": {
          "score": 0.0,
          "rank": 282
        },
        "2602.14375v1": {
          "score": 0.0,
          "rank": 283
        },
        "2602.14374v1": {
          "score": 0.0,
          "rank": 284
        },
        "2602.14372v1": {
          "score": 0.0,
          "rank": 285
        },
        "2602.14371v1": {
          "score": 0.0,
          "rank": 286
        },
        "2602.14370v1": {
          "score": 0.0,
          "rank": 287
        },
        "2602.14367v1": {
          "score": 0.0,
          "rank": 288
        },
        "2602.14365v1": {
          "score": 0.0,
          "rank": 289
        },
        "2602.14364v1": {
          "score": 0.0,
          "rank": 290
        },
        "2602.14363v1": {
          "score": 0.0,
          "rank": 291
        },
        "2602.14360v1": {
          "score": 0.0,
          "rank": 292
        },
        "2602.14358v1": {
          "score": 0.0,
          "rank": 293
        },
        "2602.14357v1": {
          "score": 0.0,
          "rank": 294
        },
        "2602.14356v1": {
          "score": 0.0,
          "rank": 295
        },
        "2602.14352v1": {
          "score": 0.0,
          "rank": 296
        },
        "2602.14351v1": {
          "score": 0.0,
          "rank": 297
        },
        "2602.14345v1": {
          "score": 0.0,
          "rank": 298
        },
        "2602.14344v1": {
          "score": 0.0,
          "rank": 299
        },
        "2602.14342v1": {
          "score": 0.0,
          "rank": 300
        },
        "2602.14338v1": {
          "score": 0.0,
          "rank": 301
        },
        "2602.14337v1": {
          "score": 0.0,
          "rank": 302
        },
        "2602.14335v1": {
          "score": 0.0,
          "rank": 303
        },
        "2602.14331v1": {
          "score": 0.0,
          "rank": 304
        },
        "2602.14329v1": {
          "score": 0.0,
          "rank": 305
        },
        "2602.14326v1": {
          "score": 0.0,
          "rank": 306
        },
        "2602.15904v1": {
          "score": 0.0,
          "rank": 307
        },
        "2602.14322v1": {
          "score": 0.0,
          "rank": 308
        },
        "2602.14321v1": {
          "score": 0.0,
          "rank": 309
        },
        "2602.14320v2": {
          "score": 0.0,
          "rank": 310
        },
        "2602.14318v1": {
          "score": 0.0,
          "rank": 311
        },
        "2602.14313v1": {
          "score": 0.0,
          "rank": 312
        },
        "2602.14311v1": {
          "score": 0.0,
          "rank": 313
        },
        "2602.14307v1": {
          "score": 0.0,
          "rank": 314
        },
        "2602.14302v1": {
          "score": 0.0,
          "rank": 315
        },
        "2602.14301v1": {
          "score": 0.0,
          "rank": 316
        },
        "2602.14299v2": {
          "score": 0.0,
          "rank": 317
        },
        "2602.14297v1": {
          "score": 0.0,
          "rank": 318
        },
        "2602.14296v1": {
          "score": 0.0,
          "rank": 319
        },
        "2602.14295v1": {
          "score": 0.0,
          "rank": 320
        },
        "2602.14293v1": {
          "score": 0.0,
          "rank": 321
        },
        "2602.14291v1": {
          "score": 0.0,
          "rank": 322
        },
        "2602.14289v1": {
          "score": 0.0,
          "rank": 323
        },
        "2602.14287v1": {
          "score": 0.0,
          "rank": 324
        },
        "2602.14285v1": {
          "score": 0.0,
          "rank": 325
        },
        "2602.14284v1": {
          "score": 0.0,
          "rank": 326
        },
        "2602.14283v1": {
          "score": 0.0,
          "rank": 327
        },
        "2602.14281v1": {
          "score": 0.0,
          "rank": 328
        },
        "2602.14280v1": {
          "score": 0.0,
          "rank": 329
        },
        "2602.14279v1": {
          "score": 0.0,
          "rank": 330
        },
        "2602.14278v1": {
          "score": 0.0,
          "rank": 331
        },
        "2602.14276v1": {
          "score": 0.0,
          "rank": 332
        },
        "2602.14275v1": {
          "score": 0.0,
          "rank": 333
        },
        "2602.14274v1": {
          "score": 0.0,
          "rank": 334
        },
        "2602.14272v1": {
          "score": 0.0,
          "rank": 335
        },
        "2602.14270v1": {
          "score": 0.0,
          "rank": 336
        },
        "2602.14267v1": {
          "score": 0.0,
          "rank": 337
        },
        "2602.14265v1": {
          "score": 0.0,
          "rank": 338
        },
        "2602.14263v1": {
          "score": 0.0,
          "rank": 339
        },
        "2602.14262v1": {
          "score": 0.0,
          "rank": 340
        },
        "2602.14259v1": {
          "score": 0.0,
          "rank": 341
        },
        "2602.14257v1": {
          "score": 0.0,
          "rank": 342
        },
        "2602.14256v1": {
          "score": 0.0,
          "rank": 343
        },
        "2602.14255v1": {
          "score": 0.0,
          "rank": 344
        },
        "2602.14254v1": {
          "score": 0.0,
          "rank": 345
        },
        "2602.14252v1": {
          "score": 0.0,
          "rank": 346
        },
        "2602.14251v1": {
          "score": 0.0,
          "rank": 347
        },
        "2602.14250v1": {
          "score": 0.0,
          "rank": 348
        },
        "2602.14247v1": {
          "score": 0.0,
          "rank": 349
        },
        "2602.14244v1": {
          "score": 0.0,
          "rank": 350
        },
        "2602.14243v1": {
          "score": 0.0,
          "rank": 351
        },
        "2602.15072v1": {
          "score": 0.0,
          "rank": 352
        },
        "2602.14239v1": {
          "score": 0.0,
          "rank": 353
        },
        "2602.14238v1": {
          "score": 0.0,
          "rank": 354
        },
        "2602.14237v1": {
          "score": 0.0,
          "rank": 355
        },
        "2602.14236v1": {
          "score": 0.0,
          "rank": 356
        },
        "2602.14234v1": {
          "score": 0.0,
          "rank": 357
        },
        "2602.14233v1": {
          "score": 0.0,
          "rank": 358
        },
        "2602.14232v1": {
          "score": 0.0,
          "rank": 359
        },
        "2602.14231v1": {
          "score": 0.0,
          "rank": 360
        },
        "2602.14229v1": {
          "score": 0.0,
          "rank": 361
        },
        "2602.14228v1": {
          "score": 0.0,
          "rank": 362
        },
        "2602.14226v1": {
          "score": 0.0,
          "rank": 363
        },
        "2602.14225v1": {
          "score": 0.0,
          "rank": 364
        },
        "2602.14224v1": {
          "score": 0.0,
          "rank": 365
        },
        "2602.14223v1": {
          "score": 0.0,
          "rank": 366
        },
        "2602.14222v1": {
          "score": 0.0,
          "rank": 367
        },
        "2602.14219v1": {
          "score": 0.0,
          "rank": 368
        },
        "2602.14216v1": {
          "score": 0.0,
          "rank": 369
        },
        "2602.14214v1": {
          "score": 0.0,
          "rank": 370
        },
        "2602.14211v1": {
          "score": 0.0,
          "rank": 371
        },
        "2602.14209v1": {
          "score": 0.0,
          "rank": 372
        },
        "2602.14208v1": {
          "score": 0.0,
          "rank": 373
        },
        "2602.15071v1": {
          "score": 0.0,
          "rank": 374
        },
        "2602.14201v1": {
          "score": 0.0,
          "rank": 375
        },
        "2602.14200v1": {
          "score": 0.0,
          "rank": 376
        },
        "2602.14199v1": {
          "score": 0.0,
          "rank": 377
        },
        "2602.14193v1": {
          "score": 0.0,
          "rank": 378
        },
        "2602.14189v1": {
          "score": 0.0,
          "rank": 379
        },
        "2602.14188v1": {
          "score": 0.0,
          "rank": 380
        },
        "2602.14186v1": {
          "score": 0.0,
          "rank": 381
        },
        "2602.14183v1": {
          "score": 0.0,
          "rank": 382
        },
        "2602.14179v1": {
          "score": 0.0,
          "rank": 383
        },
        "2602.14178v1": {
          "score": 0.0,
          "rank": 384
        },
        "2602.14177v1": {
          "score": 0.0,
          "rank": 385
        },
        "2602.14174v1": {
          "score": 0.0,
          "rank": 386
        },
        "2602.14172v2": {
          "score": 0.0,
          "rank": 387
        },
        "2602.14169v1": {
          "score": 0.0,
          "rank": 388
        },
        "2602.14162v1": {
          "score": 0.0,
          "rank": 389
        },
        "2602.14161v1": {
          "score": 0.0,
          "rank": 390
        },
        "2602.14160v1": {
          "score": 0.0,
          "rank": 391
        },
        "2602.14159v1": {
          "score": 0.0,
          "rank": 392
        },
        "2602.14158v1": {
          "score": 0.0,
          "rank": 393
        },
        "2602.14157v1": {
          "score": 0.0,
          "rank": 394
        },
        "2602.14154v1": {
          "score": 0.0,
          "rank": 395
        },
        "2602.14153v1": {
          "score": 0.0,
          "rank": 396
        },
        "2602.14147v1": {
          "score": 0.0,
          "rank": 397
        },
        "2602.14143v1": {
          "score": 0.0,
          "rank": 398
        },
        "2602.14140v1": {
          "score": 0.0,
          "rank": 399
        },
        "2602.14135v2": {
          "score": 0.0,
          "rank": 400
        }
      }
    },
    {
      "type": "llm_query",
      "tag": "SR",
      "paper_tag": "query:SR",
      "query_text": "Recent advances and state-of-the-art methods in symbolic regression",
      "logic_cn": "查询符号回归领域的最新进展和最先进的方法",
      "boolean_expr": "",
      "bm25_mode": "normal",
      "sim_scores": {
        "2602.13021v2": {
          "score": 17.047266548089866,
          "rank": 1
        },
        "2602.15169v1": {
          "score": 16.934568707951748,
          "rank": 2
        },
        "2602.12109v1": {
          "score": 16.600327472909633,
          "rank": 3
        },
        "2602.10476v1": {
          "score": 16.232359004862506,
          "rank": 4
        },
        "2602.09761v1": {
          "score": 15.96573758601878,
          "rank": 5
        },
        "2602.10576v1": {
          "score": 15.171481280327738,
          "rank": 6
        },
        "2602.14440v1": {
          "score": 14.153143387297387,
          "rank": 7
        },
        "2602.14337v1": {
          "score": 14.128691087424052,
          "rank": 8
        },
        "2602.12259v1": {
          "score": 13.690804913201045,
          "rank": 9
        },
        "2602.15603v1": {
          "score": 13.530192430314441,
          "rank": 10
        },
        "2602.11291v1": {
          "score": 13.45811828700603,
          "rank": 11
        },
        "2602.12244v1": {
          "score": 12.985862275815329,
          "rank": 12
        },
        "2602.13419v1": {
          "score": 12.874742973902586,
          "rank": 13
        },
        "2602.09720v1": {
          "score": 12.251441759394893,
          "rank": 14
        },
        "2602.10155v1": {
          "score": 12.213218085889032,
          "rank": 15
        },
        "2602.16166v1": {
          "score": 12.205515952303934,
          "rank": 16
        },
        "2602.09489v1": {
          "score": 12.091839195272906,
          "rank": 17
        },
        "2602.15750v1": {
          "score": 11.88529414714706,
          "rank": 18
        },
        "2602.16481v1": {
          "score": 11.875923283164344,
          "rank": 19
        },
        "2602.10794v1": {
          "score": 11.848765322678089,
          "rank": 20
        },
        "2602.11630v1": {
          "score": 11.761640532141689,
          "rank": 21
        },
        "2602.11666v1": {
          "score": 11.70333012463625,
          "rank": 22
        },
        "2602.11678v1": {
          "score": 11.694287242641291,
          "rank": 23
        },
        "2602.16586v1": {
          "score": 11.606230247584106,
          "rank": 24
        },
        "2602.09679v1": {
          "score": 11.509713153179094,
          "rank": 25
        },
        "2602.12159v1": {
          "score": 11.493840864582868,
          "rank": 26
        },
        "2602.14018v1": {
          "score": 11.256518700699194,
          "rank": 27
        },
        "2602.11861v1": {
          "score": 11.248002946709137,
          "rank": 28
        },
        "2602.13362v1": {
          "score": 11.20648537998942,
          "rank": 29
        },
        "2602.10233v1": {
          "score": 11.082856036110115,
          "rank": 30
        },
        "2602.13108v1": {
          "score": 11.082593422410183,
          "rank": 31
        },
        "2602.14480v1": {
          "score": 10.950715770449104,
          "rank": 32
        },
        "2602.13010v1": {
          "score": 10.930933759771607,
          "rank": 33
        },
        "2602.10598v1": {
          "score": 10.804450880395365,
          "rank": 34
        },
        "2602.14157v1": {
          "score": 10.800091636792644,
          "rank": 35
        },
        "2602.16000v1": {
          "score": 10.788023713378173,
          "rank": 36
        },
        "2602.09615v1": {
          "score": 10.780221036361198,
          "rank": 37
        },
        "2602.16091v1": {
          "score": 10.699070315020883,
          "rank": 38
        },
        "2602.11066v1": {
          "score": 10.689922405520232,
          "rank": 39
        },
        "2602.14060v1": {
          "score": 10.597446280926519,
          "rank": 40
        },
        "2602.09996v2": {
          "score": 10.501518932983162,
          "rank": 41
        },
        "2602.10425v1": {
          "score": 10.496279460424565,
          "rank": 42
        },
        "2602.09642v1": {
          "score": 10.44696613856129,
          "rank": 43
        },
        "2602.10480v2": {
          "score": 10.435919787948452,
          "rank": 44
        },
        "2602.11477v1": {
          "score": 10.331004861271852,
          "rank": 45
        },
        "2602.12465v1": {
          "score": 10.278758420320177,
          "rank": 46
        },
        "2602.13836v1": {
          "score": 10.271168188802378,
          "rank": 47
        },
        "2602.10016v2": {
          "score": 10.145850770914427,
          "rank": 48
        },
        "2602.10261v1": {
          "score": 10.117853684049471,
          "rank": 49
        },
        "2602.09848v1": {
          "score": 10.075879635792617,
          "rank": 50
        },
        "2602.09449v1": {
          "score": 10.00708170238501,
          "rank": 51
        },
        "2602.09472v1": {
          "score": 9.978777719186692,
          "rank": 52
        },
        "2602.15353v1": {
          "score": 9.928983156682994,
          "rank": 53
        },
        "2602.15337v1": {
          "score": 9.899370708506423,
          "rank": 54
        },
        "2602.09589v1": {
          "score": 9.889285830186282,
          "rank": 55
        },
        "2602.11139v1": {
          "score": 9.850252986878841,
          "rank": 56
        },
        "2602.16573v1": {
          "score": 9.703656367950199,
          "rank": 57
        },
        "2602.13583v1": {
          "score": 9.69700916541084,
          "rank": 58
        },
        "2602.13043v1": {
          "score": 9.682164290050093,
          "rank": 59
        },
        "2602.10179v1": {
          "score": 9.6434682395555,
          "rank": 60
        },
        "2602.10451v1": {
          "score": 9.639108163127913,
          "rank": 61
        },
        "2602.12379v1": {
          "score": 9.632963285882088,
          "rank": 62
        },
        "2602.12851v1": {
          "score": 9.592305693485098,
          "rank": 63
        },
        "2602.12489v1": {
          "score": 9.582108669777423,
          "rank": 64
        },
        "2602.10708v1": {
          "score": 9.556191355948929,
          "rank": 65
        },
        "2602.13873v1": {
          "score": 9.554777794908762,
          "rank": 66
        },
        "2602.12889v1": {
          "score": 9.532530379989034,
          "rank": 67
        },
        "2602.10936v1": {
          "score": 9.523354715452166,
          "rank": 68
        },
        "2602.15000v1": {
          "score": 9.517662820795803,
          "rank": 69
        },
        "2602.11421v1": {
          "score": 9.445833392046767,
          "rank": 70
        },
        "2602.13549v1": {
          "score": 9.437639122485166,
          "rank": 71
        },
        "2602.11880v1": {
          "score": 9.399061337392244,
          "rank": 72
        },
        "2602.12561v1": {
          "score": 9.376773494166962,
          "rank": 73
        },
        "2602.10609v1": {
          "score": 9.352964158939479,
          "rank": 74
        },
        "2602.09816v1": {
          "score": 9.350282991884464,
          "rank": 75
        },
        "2602.10586v1": {
          "score": 9.326214965355586,
          "rank": 76
        },
        "2602.16665v1": {
          "score": 9.326109977074253,
          "rank": 77
        },
        "2602.10924v1": {
          "score": 9.31292630996222,
          "rank": 78
        },
        "2602.12704v1": {
          "score": 9.30075727035648,
          "rank": 79
        },
        "2602.10587v1": {
          "score": 9.177279289741936,
          "rank": 80
        },
        "2602.10471v1": {
          "score": 9.159053517739563,
          "rank": 81
        },
        "2602.16461v1": {
          "score": 9.157786471440982,
          "rank": 82
        },
        "2602.09378v1": {
          "score": 9.146395209851967,
          "rank": 83
        },
        "2602.15287v1": {
          "score": 9.114484397144585,
          "rank": 84
        },
        "2602.10583v1": {
          "score": 9.095440962391445,
          "rank": 85
        },
        "2602.12769v1": {
          "score": 9.048780991161966,
          "rank": 86
        },
        "2602.10881v1": {
          "score": 9.03703603425705,
          "rank": 87
        },
        "2602.15277v1": {
          "score": 9.031678449434107,
          "rank": 88
        },
        "2602.12300v1": {
          "score": 8.98838861849593,
          "rank": 89
        },
        "2602.13507v1": {
          "score": 8.973515442653147,
          "rank": 90
        },
        "2602.12870v1": {
          "score": 8.874793916449555,
          "rank": 91
        },
        "2602.11583v1": {
          "score": 8.85557262946102,
          "rank": 92
        },
        "2602.11705v1": {
          "score": 8.849854426844244,
          "rank": 93
        },
        "2602.11118v1": {
          "score": 8.807244738961622,
          "rank": 94
        },
        "2602.11961v1": {
          "score": 8.78251519868452,
          "rank": 95
        },
        "2602.09774v1": {
          "score": 8.760002532439731,
          "rank": 96
        },
        "2602.10541v1": {
          "score": 8.73545017635437,
          "rank": 97
        },
        "2602.15360v1": {
          "score": 8.6973224571172,
          "rank": 98
        },
        "2602.14399v1": {
          "score": 8.693553090805468,
          "rank": 99
        },
        "2602.15547v1": {
          "score": 8.693278244523317,
          "rank": 100
        },
        "2602.10158v1": {
          "score": 8.659284332319194,
          "rank": 101
        },
        "2602.13891v1": {
          "score": 8.651788242301635,
          "rank": 102
        },
        "2602.15727v1": {
          "score": 8.650726629755237,
          "rank": 103
        },
        "2602.16548v1": {
          "score": 8.648418932770118,
          "rank": 104
        },
        "2602.12961v1": {
          "score": 8.645311510641115,
          "rank": 105
        },
        "2602.11539v1": {
          "score": 8.636443908517503,
          "rank": 106
        },
        "2602.14983v1": {
          "score": 8.625228541381635,
          "rank": 107
        },
        "2602.09999v1": {
          "score": 8.585031084448246,
          "rank": 108
        },
        "2602.11670v1": {
          "score": 8.579712376859913,
          "rank": 109
        },
        "2602.12612v1": {
          "score": 8.565056570790237,
          "rank": 110
        },
        "2602.13610v1": {
          "score": 8.558845197827157,
          "rank": 111
        },
        "2602.10994v1": {
          "score": 8.536508291745864,
          "rank": 112
        },
        "2602.09972v1": {
          "score": 8.516521254411982,
          "rank": 113
        },
        "2602.09008v1": {
          "score": 8.510317817486305,
          "rank": 114
        },
        "2602.16069v1": {
          "score": 8.499643820337406,
          "rank": 115
        },
        "2602.13773v1": {
          "score": 8.476999408260012,
          "rank": 116
        },
        "2602.15202v1": {
          "score": 8.469108965243688,
          "rank": 117
        },
        "2602.13653v1": {
          "score": 8.46249387093095,
          "rank": 118
        },
        "2602.10491v1": {
          "score": 8.313240141090061,
          "rank": 119
        },
        "2602.09207v1": {
          "score": 8.310378917015658,
          "rank": 120
        },
        "2602.13699v1": {
          "score": 8.282309420669616,
          "rank": 121
        },
        "2602.16707v1": {
          "score": 8.245835436761313,
          "rank": 122
        },
        "2602.15959v1": {
          "score": 8.22998332057989,
          "rank": 123
        },
        "2602.09109v1": {
          "score": 8.18090079224953,
          "rank": 124
        },
        "2602.15539v1": {
          "score": 8.173684233518058,
          "rank": 125
        },
        "2602.09459v1": {
          "score": 8.163308246083886,
          "rank": 126
        },
        "2602.09167v1": {
          "score": 8.145154007872614,
          "rank": 127
        },
        "2602.09443v1": {
          "score": 8.134378090211275,
          "rank": 128
        },
        "2602.11966v1": {
          "score": 8.134292196928573,
          "rank": 129
        },
        "2602.12853v1": {
          "score": 8.121680510634407,
          "rank": 130
        },
        "2602.10464v1": {
          "score": 8.117731340042578,
          "rank": 131
        },
        "2602.14083v1": {
          "score": 8.098719823376594,
          "rank": 132
        },
        "2602.13353v1": {
          "score": 8.090200169182436,
          "rank": 133
        },
        "2602.11339v2": {
          "score": 8.0853737955801,
          "rank": 134
        },
        "2602.11850v2": {
          "score": 8.071910137745267,
          "rank": 135
        },
        "2602.13818v1": {
          "score": 8.071341969493071,
          "rank": 136
        },
        "2602.09883v1": {
          "score": 8.059649272055754,
          "rank": 137
        },
        "2602.15675v1": {
          "score": 8.052181281794725,
          "rank": 138
        },
        "2602.12631v1": {
          "score": 8.050478467399044,
          "rank": 139
        },
        "2602.12740v1": {
          "score": 7.99002367313581,
          "rank": 140
        },
        "2602.09971v1": {
          "score": 7.955347909262761,
          "rank": 141
        },
        "2602.15820v1": {
          "score": 7.915296645117277,
          "rank": 142
        },
        "2602.12500v1": {
          "score": 7.910041114822251,
          "rank": 143
        },
        "2602.10619v1": {
          "score": 7.866832020640705,
          "rank": 144
        },
        "2602.16502v1": {
          "score": 7.865872082881075,
          "rank": 145
        },
        "2602.13055v1": {
          "score": 7.865600939798616,
          "rank": 146
        },
        "2602.13880v1": {
          "score": 7.8518739772886335,
          "rank": 147
        },
        "2602.12656v1": {
          "score": 7.823263090029427,
          "rank": 148
        },
        "2602.15817v1": {
          "score": 7.818937591848918,
          "rank": 149
        },
        "2602.11589v1": {
          "score": 7.807356946862216,
          "rank": 150
        },
        "2602.10090v2": {
          "score": 7.806135782985231,
          "rank": 151
        },
        "2602.09868v1": {
          "score": 7.777585394069438,
          "rank": 152
        },
        "2602.13631v1": {
          "score": 7.721492296006931,
          "rank": 153
        },
        "2602.12389v1": {
          "score": 7.71658489497592,
          "rank": 154
        },
        "2602.09351v1": {
          "score": 7.7008281504459255,
          "rank": 155
        },
        "2602.14127v1": {
          "score": 7.69545343597319,
          "rank": 156
        },
        "2602.15181v1": {
          "score": 7.678514078467565,
          "rank": 157
        },
        "2602.16341v1": {
          "score": 7.656108723392002,
          "rank": 158
        },
        "2602.15322v1": {
          "score": 7.649599215381534,
          "rank": 159
        },
        "2602.11622v1": {
          "score": 7.640389414651551,
          "rank": 160
        },
        "2602.10656v1": {
          "score": 7.591501671123074,
          "rank": 161
        },
        "2602.12402v1": {
          "score": 7.584356910875554,
          "rank": 162
        },
        "2602.14035v1": {
          "score": 7.579323003648894,
          "rank": 163
        },
        "2602.11335v1": {
          "score": 7.578284569713571,
          "rank": 164
        },
        "2602.10745v1": {
          "score": 7.573094864751483,
          "rank": 165
        },
        "2602.12980v1": {
          "score": 7.561125050514154,
          "rank": 166
        },
        "2602.16606v1": {
          "score": 7.493402708939593,
          "rank": 167
        },
        "2602.16360v1": {
          "score": 7.4842746213239915,
          "rank": 168
        },
        "2602.09013v2": {
          "score": 7.481934137020956,
          "rank": 169
        },
        "2602.14289v1": {
          "score": 7.458582381819247,
          "rank": 170
        },
        "2602.14537v1": {
          "score": 7.446886638924783,
          "rank": 171
        },
        "2602.11862v1": {
          "score": 7.446462273848219,
          "rank": 172
        },
        "2602.14224v1": {
          "score": 7.429513583436811,
          "rank": 173
        },
        "2602.13011v1": {
          "score": 7.4291207603660645,
          "rank": 174
        },
        "2602.10278v1": {
          "score": 7.424558575867559,
          "rank": 175
        },
        "2602.16208v1": {
          "score": 7.416684568202679,
          "rank": 176
        },
        "2602.12233v1": {
          "score": 7.414480080708485,
          "rank": 177
        },
        "2602.11113v1": {
          "score": 7.409414830952348,
          "rank": 178
        },
        "2602.10546v1": {
          "score": 7.399865611053654,
          "rank": 179
        },
        "2602.09867v2": {
          "score": 7.385793357702041,
          "rank": 180
        },
        "2602.10274v1": {
          "score": 7.379969963901251,
          "rank": 181
        },
        "2602.14414v1": {
          "score": 7.3733572319208385,
          "rank": 182
        },
        "2602.12370v1": {
          "score": 7.368741982175941,
          "rank": 183
        },
        "2602.14408v1": {
          "score": 7.363042929429138,
          "rank": 184
        },
        "2602.09082v1": {
          "score": 7.343697204571231,
          "rank": 185
        },
        "2602.16256v1": {
          "score": 7.3272658180613846,
          "rank": 186
        },
        "2602.11320v2": {
          "score": 7.319069857633313,
          "rank": 187
        },
        "2602.10114v1": {
          "score": 7.318665189216637,
          "rank": 188
        },
        "2602.15971v1": {
          "score": 7.275373731665347,
          "rank": 189
        },
        "2602.16468v1": {
          "score": 7.256810039506185,
          "rank": 190
        },
        "2602.09690v1": {
          "score": 7.226892764195048,
          "rank": 191
        },
        "2602.10978v1": {
          "score": 7.222930728546139,
          "rank": 192
        },
        "2602.12442v1": {
          "score": 7.2133283205230025,
          "rank": 193
        },
        "2602.12717v1": {
          "score": 7.204809165150504,
          "rank": 194
        },
        "2602.09528v1": {
          "score": 7.194487518789362,
          "rank": 195
        },
        "2602.15684v1": {
          "score": 7.192721264383018,
          "rank": 196
        },
        "2602.09081v1": {
          "score": 7.1926716946349085,
          "rank": 197
        },
        "2602.10746v1": {
          "score": 7.175161929919268,
          "rank": 198
        },
        "2602.16290v1": {
          "score": 7.169537938294521,
          "rank": 199
        },
        "2602.12162v1": {
          "score": 7.165408695384846,
          "rank": 200
        },
        "2602.10764v1": {
          "score": 7.164188943600542,
          "rank": 201
        },
        "2602.14662v1": {
          "score": 7.16384157213076,
          "rank": 202
        },
        "2602.09798v1": {
          "score": 7.160688884939701,
          "rank": 203
        },
        "2602.11021v1": {
          "score": 7.158812646813127,
          "rank": 204
        },
        "2602.09949v1": {
          "score": 7.156058129607571,
          "rank": 205
        },
        "2602.11290v2": {
          "score": 7.152612126450535,
          "rank": 206
        },
        "2602.09024v1": {
          "score": 7.14506103131749,
          "rank": 207
        },
        "2602.13729v1": {
          "score": 7.142203224069499,
          "rank": 208
        },
        "2602.14914v1": {
          "score": 7.134945623618738,
          "rank": 209
        },
        "2602.13537v2": {
          "score": 7.12749538913283,
          "rank": 210
        },
        "2602.11714v1": {
          "score": 7.12539778032012,
          "rank": 211
        },
        "2602.12080v1": {
          "score": 7.124734204444546,
          "rank": 212
        },
        "2602.09164v1": {
          "score": 7.121833296912709,
          "rank": 213
        },
        "2602.16271v1": {
          "score": 7.110123623168576,
          "rank": 214
        },
        "2602.11136v2": {
          "score": 7.0984572872744405,
          "rank": 215
        },
        "2602.09716v1": {
          "score": 7.08918033886052,
          "rank": 216
        },
        "2602.10696v1": {
          "score": 7.0854913098761445,
          "rank": 217
        },
        "2602.09801v1": {
          "score": 7.075095557911695,
          "rank": 218
        },
        "2602.15313v1": {
          "score": 7.068540031575559,
          "rank": 219
        },
        "2602.09609v1": {
          "score": 7.063865813561329,
          "rank": 220
        },
        "2602.15229v1": {
          "score": 7.0589740045776725,
          "rank": 221
        },
        "2602.14183v1": {
          "score": 7.043392088184793,
          "rank": 222
        },
        "2602.13814v1": {
          "score": 7.032759401395864,
          "rank": 223
        },
        "2602.11084v1": {
          "score": 7.028580161718246,
          "rank": 224
        },
        "2602.09730v1": {
          "score": 7.017433530295533,
          "rank": 225
        },
        "2602.12114v1": {
          "score": 7.006975140163536,
          "rank": 226
        },
        "2602.14565v1": {
          "score": 6.995753828200701,
          "rank": 227
        },
        "2602.11903v1": {
          "score": 6.9907589206356295,
          "rank": 228
        },
        "2602.14898v1": {
          "score": 6.985673885660099,
          "rank": 229
        },
        "2602.12575v1": {
          "score": 6.979745054946353,
          "rank": 230
        },
        "2602.10172v1": {
          "score": 6.9787942356865775,
          "rank": 231
        },
        "2602.09855v1": {
          "score": 6.97864728252135,
          "rank": 232
        },
        "2602.16337v1": {
          "score": 6.973969217121337,
          "rank": 233
        },
        "2602.14761v1": {
          "score": 6.934338366557975,
          "rank": 234
        },
        "2602.16376v1": {
          "score": 6.931384120807167,
          "rank": 235
        },
        "2602.12843v1": {
          "score": 6.925073617639759,
          "rank": 236
        },
        "2602.14938v1": {
          "score": 6.92069273458393,
          "rank": 237
        },
        "2602.16317v1": {
          "score": 6.916362561513087,
          "rank": 238
        },
        "2602.11238v1": {
          "score": 6.899258223896462,
          "rank": 239
        },
        "2602.15031v1": {
          "score": 6.89617519216745,
          "rank": 240
        },
        "2602.13747v1": {
          "score": 6.896071553841784,
          "rank": 241
        },
        "2602.15925v1": {
          "score": 6.890478439863003,
          "rank": 242
        },
        "2602.16204v1": {
          "score": 6.88956567748735,
          "rank": 243
        },
        "2602.14679v1": {
          "score": 6.87789255041582,
          "rank": 244
        },
        "2602.16671v1": {
          "score": 6.860225065906551,
          "rank": 245
        },
        "2602.10411v1": {
          "score": 6.858345315709856,
          "rank": 246
        },
        "2602.15146v2": {
          "score": 6.850047528705242,
          "rank": 247
        },
        "2602.13335v1": {
          "score": 6.843588469915511,
          "rank": 248
        },
        "2602.10886v1": {
          "score": 6.830248912897512,
          "rank": 249
        },
        "2602.13152v1": {
          "score": 6.824513539317997,
          "rank": 250
        },
        "2602.14464v1": {
          "score": 6.824431236517505,
          "rank": 251
        },
        "2602.11150v1": {
          "score": 6.82397487434275,
          "rank": 252
        },
        "2602.13710v1": {
          "score": 6.822082371411537,
          "rank": 253
        },
        "2602.11625v1": {
          "score": 6.8150952361069725,
          "rank": 254
        },
        "2602.12993v1": {
          "score": 6.79589873986896,
          "rank": 255
        },
        "2602.11671v1": {
          "score": 6.790455238057303,
          "rank": 256
        },
        "2602.12096v1": {
          "score": 6.7785903785666095,
          "rank": 257
        },
        "2602.12652v1": {
          "score": 6.772579520301528,
          "rank": 258
        },
        "2602.16696v1": {
          "score": 6.761447936046392,
          "rank": 259
        },
        "2602.10397v1": {
          "score": 6.73579978533044,
          "rank": 260
        },
        "2602.10231v1": {
          "score": 6.7343151157637955,
          "rank": 261
        },
        "2602.10430v1": {
          "score": 6.729607090386669,
          "rank": 262
        },
        "2602.14089v1": {
          "score": 6.729248760335874,
          "rank": 263
        },
        "2602.16463v1": {
          "score": 6.725165651941698,
          "rank": 264
        },
        "2602.11769v1": {
          "score": 6.722881051744166,
          "rank": 265
        },
        "2602.10984v1": {
          "score": 6.720088040901172,
          "rank": 266
        },
        "2602.11812v1": {
          "score": 6.7193589887843075,
          "rank": 267
        },
        "2602.12528v1": {
          "score": 6.718369829057529,
          "rank": 268
        },
        "2602.15104v1": {
          "score": 6.714613150626492,
          "rank": 269
        },
        "2602.15279v1": {
          "score": 6.713288176968633,
          "rank": 270
        },
        "2602.11673v1": {
          "score": 6.711847458139406,
          "rank": 271
        },
        "2602.11325v2": {
          "score": 6.707688421502089,
          "rank": 272
        },
        "2602.15633v1": {
          "score": 6.680045463798677,
          "rank": 273
        },
        "2602.11024v1": {
          "score": 6.663500004596058,
          "rank": 274
        },
        "2602.13015v1": {
          "score": 6.660665681039138,
          "rank": 275
        },
        "2602.09181v1": {
          "score": 6.659190801683975,
          "rank": 276
        },
        "2602.09523v2": {
          "score": 6.658774580091062,
          "rank": 277
        },
        "2602.13884v1": {
          "score": 6.655920163594599,
          "rank": 278
        },
        "2602.12508v1": {
          "score": 6.655461570782567,
          "rank": 279
        },
        "2602.09125v1": {
          "score": 6.644895678880705,
          "rank": 280
        },
        "2602.10819v1": {
          "score": 6.64212452767353,
          "rank": 281
        },
        "2602.09586v1": {
          "score": 6.64170333779541,
          "rank": 282
        },
        "2602.09432v1": {
          "score": 6.638757073393781,
          "rank": 283
        },
        "2602.16196v1": {
          "score": 6.633813986440703,
          "rank": 284
        },
        "2602.10365v1": {
          "score": 6.6220178867701165,
          "rank": 285
        },
        "2602.14526v1": {
          "score": 6.620999037515066,
          "rank": 286
        },
        "2602.11332v1": {
          "score": 6.610275260968259,
          "rank": 287
        },
        "2602.14443v1": {
          "score": 6.606304604018443,
          "rank": 288
        },
        "2602.13780v1": {
          "score": 6.5726665671229885,
          "rank": 289
        },
        "2602.12157v2": {
          "score": 6.563612078848026,
          "rank": 290
        },
        "2602.11700v1": {
          "score": 6.5621493557950705,
          "rank": 291
        },
        "2602.15477v1": {
          "score": 6.559984649689547,
          "rank": 292
        },
        "2602.10905v1": {
          "score": 6.558762317651033,
          "rank": 293
        },
        "2602.10687v2": {
          "score": 6.5489950737503335,
          "rank": 294
        },
        "2602.10044v1": {
          "score": 6.548954902583854,
          "rank": 295
        },
        "2602.10985v1": {
          "score": 6.545208294187819,
          "rank": 296
        },
        "2602.15923v1": {
          "score": 6.543095314095997,
          "rank": 297
        },
        "2602.14788v1": {
          "score": 6.54169973543239,
          "rank": 298
        },
        "2602.15484v1": {
          "score": 6.536935582385788,
          "rank": 299
        },
        "2602.13986v1": {
          "score": 6.534380723458042,
          "rank": 300
        },
        "2602.16320v1": {
          "score": 6.528535893374875,
          "rank": 301
        },
        "2602.09252v1": {
          "score": 6.527468702770128,
          "rank": 302
        },
        "2602.11760v1": {
          "score": 6.527464762038156,
          "rank": 303
        },
        "2602.11911v1": {
          "score": 6.525821219761362,
          "rank": 304
        },
        "2602.11564v1": {
          "score": 6.51950867718322,
          "rank": 305
        },
        "2602.09927v1": {
          "score": 6.512661997444701,
          "rank": 306
        },
        "2602.12774v1": {
          "score": 6.512641802209667,
          "rank": 307
        },
        "2602.16308v1": {
          "score": 6.5008059845597295,
          "rank": 308
        },
        "2602.15138v1": {
          "score": 6.492580511746043,
          "rank": 309
        },
        "2602.11316v1": {
          "score": 6.492538603696087,
          "rank": 310
        },
        "2602.11062v1": {
          "score": 6.489302994850668,
          "rank": 311
        },
        "2602.10736v1": {
          "score": 6.484813506481876,
          "rank": 312
        },
        "2602.12976v1": {
          "score": 6.483229897616686,
          "rank": 313
        },
        "2602.13770v1": {
          "score": 6.479771193741727,
          "rank": 314
        },
        "2602.15776v1": {
          "score": 6.478386966973568,
          "rank": 315
        },
        "2602.12399v1": {
          "score": 6.472989804407972,
          "rank": 316
        },
        "2602.11408v1": {
          "score": 6.467021099478754,
          "rank": 317
        },
        "2602.13359v1": {
          "score": 6.465784474075036,
          "rank": 318
        },
        "2602.13920v2": {
          "score": 6.4453971787316835,
          "rank": 319
        },
        "2602.16052v1": {
          "score": 6.4427041465394215,
          "rank": 320
        },
        "2602.14642v1": {
          "score": 6.4378642795554155,
          "rank": 321
        },
        "2602.13357v1": {
          "score": 6.436610692023152,
          "rank": 322
        },
        "2602.12574v1": {
          "score": 6.43488288405427,
          "rank": 323
        },
        "2602.13866v1": {
          "score": 6.432956066568429,
          "rank": 324
        },
        "2602.14021v1": {
          "score": 6.431917669820092,
          "rank": 325
        },
        "2602.15903v1": {
          "score": 6.431475688203243,
          "rank": 326
        },
        "2602.10218v1": {
          "score": 6.425841830910298,
          "rank": 327
        },
        "2602.12534v1": {
          "score": 6.422296517534532,
          "rank": 328
        },
        "2602.10613v1": {
          "score": 6.420170223538309,
          "rank": 329
        },
        "2602.10854v1": {
          "score": 6.420016320519119,
          "rank": 330
        },
        "2602.15766v1": {
          "score": 6.4174492896128,
          "rank": 331
        },
        "2602.10506v1": {
          "score": 6.400729143309991,
          "rank": 332
        },
        "2602.12513v1": {
          "score": 6.396975285277816,
          "rank": 333
        },
        "2602.13042v1": {
          "score": 6.394451787058596,
          "rank": 334
        },
        "2602.09318v1": {
          "score": 6.391026059574939,
          "rank": 335
        },
        "2602.12742v1": {
          "score": 6.390578605316826,
          "rank": 336
        },
        "2602.11348v2": {
          "score": 6.383365367040204,
          "rank": 337
        },
        "2602.15184v1": {
          "score": 6.376145576281193,
          "rank": 338
        },
        "2602.12982v1": {
          "score": 6.370877222786417,
          "rank": 339
        },
        "2602.14376v1": {
          "score": 6.367930080770638,
          "rank": 340
        },
        "2602.11800v1": {
          "score": 6.365725416660214,
          "rank": 341
        },
        "2602.10173v1": {
          "score": 6.3415805172953394,
          "rank": 342
        },
        "2602.14751v1": {
          "score": 6.332932063869707,
          "rank": 343
        },
        "2602.15734v1": {
          "score": 6.3257024802811825,
          "rank": 344
        },
        "2602.10441v1": {
          "score": 6.324883315385021,
          "rank": 345
        },
        "2602.10806v1": {
          "score": 6.3139665945939685,
          "rank": 346
        },
        "2602.10662v1": {
          "score": 6.309534557682571,
          "rank": 347
        },
        "2602.09510v1": {
          "score": 6.306777018775367,
          "rank": 348
        },
        "2602.14533v1": {
          "score": 6.3064519851448955,
          "rank": 349
        },
        "2602.15572v1": {
          "score": 6.30605848055222,
          "rank": 350
        },
        "2602.11440v1": {
          "score": 6.300260184094976,
          "rank": 351
        },
        "2602.14726v1": {
          "score": 6.299841173893002,
          "rank": 352
        },
        "2602.11117v1": {
          "score": 6.297781292181734,
          "rank": 353
        },
        "2602.16015v1": {
          "score": 6.2966809522422995,
          "rank": 354
        },
        "2602.16669v1": {
          "score": 6.292638020682022,
          "rank": 355
        },
        "2602.14226v1": {
          "score": 6.287207639806527,
          "rank": 356
        },
        "2602.11573v2": {
          "score": 6.280071443387289,
          "rank": 357
        },
        "2602.13994v1": {
          "score": 6.278229457831313,
          "rank": 358
        },
        "2602.15400v1": {
          "score": 6.267877514490841,
          "rank": 359
        },
        "2602.12172v1": {
          "score": 6.264651000514953,
          "rank": 360
        },
        "2602.14874v1": {
          "score": 6.259548719493809,
          "rank": 361
        },
        "2602.11466v1": {
          "score": 6.258616284468896,
          "rank": 362
        },
        "2602.13136v1": {
          "score": 6.252037163784296,
          "rank": 363
        },
        "2602.12160v1": {
          "score": 6.2477001735798465,
          "rank": 364
        },
        "2602.15740v1": {
          "score": 6.2377262951980095,
          "rank": 365
        },
        "2602.10399v1": {
          "score": 6.235076709608494,
          "rank": 366
        },
        "2602.11128v1": {
          "score": 6.234981995567636,
          "rank": 367
        },
        "2602.14934v1": {
          "score": 6.225297750471061,
          "rank": 368
        },
        "2602.16617v1": {
          "score": 6.212816854371233,
          "rank": 369
        },
        "2602.10500v1": {
          "score": 6.211015131577876,
          "rank": 370
        },
        "2602.10063v1": {
          "score": 6.205615620319665,
          "rank": 371
        },
        "2602.11549v1": {
          "score": 6.205461255335221,
          "rank": 372
        },
        "2602.12995v1": {
          "score": 6.201974761126705,
          "rank": 373
        },
        "2602.11980v1": {
          "score": 6.19892858807401,
          "rank": 374
        },
        "2602.13091v1": {
          "score": 6.194935993789297,
          "rank": 375
        },
        "2602.09475v1": {
          "score": 6.184006855086526,
          "rank": 376
        },
        "2602.16020v1": {
          "score": 6.167686867870979,
          "rank": 377
        },
        "2602.16188v1": {
          "score": 6.159719510982796,
          "rank": 378
        },
        "2602.14345v1": {
          "score": 6.155276389393235,
          "rank": 379
        },
        "2602.13541v1": {
          "score": 6.151191597448837,
          "rank": 380
        },
        "2602.12192v1": {
          "score": 6.14466972364254,
          "rank": 381
        },
        "2602.11743v1": {
          "score": 6.140230018016257,
          "rank": 382
        },
        "2602.10965v1": {
          "score": 6.137437663231389,
          "rank": 383
        },
        "2602.16569v1": {
          "score": 6.132188377256452,
          "rank": 384
        },
        "2602.12074v1": {
          "score": 6.130268689295019,
          "rank": 385
        },
        "2602.15958v1": {
          "score": 6.129319314884017,
          "rank": 386
        },
        "2602.11653v1": {
          "score": 6.124421630880905,
          "rank": 387
        },
        "2602.15493v1": {
          "score": 6.120905498884346,
          "rank": 388
        },
        "2602.09316v2": {
          "score": 6.10955110993477,
          "rank": 389
        },
        "2602.13573v1": {
          "score": 6.103010345931924,
          "rank": 390
        },
        "2602.10489v1": {
          "score": 6.096375290589025,
          "rank": 391
        },
        "2602.16238v1": {
          "score": 6.09189261511272,
          "rank": 392
        },
        "2602.09496v1": {
          "score": 6.084704794153511,
          "rank": 393
        },
        "2602.16005v1": {
          "score": 6.072920394787615,
          "rank": 394
        },
        "2602.12622v1": {
          "score": 6.067834872608544,
          "rank": 395
        },
        "2602.16590v1": {
          "score": 6.06427809963891,
          "rank": 396
        },
        "2602.09541v1": {
          "score": 6.057907948137139,
          "rank": 397
        },
        "2602.13447v1": {
          "score": 6.054027444358685,
          "rank": 398
        },
        "2602.09681v1": {
          "score": 6.048765420697571,
          "rank": 399
        },
        "2602.15922v1": {
          "score": 6.0445256794901265,
          "rank": 400
        }
      }
    },
    {
      "type": "llm_query",
      "tag": "SR",
      "paper_tag": "query:SR",
      "query_text": "Symbolic regression for scientific discovery and physical law extraction",
      "logic_cn": "查询符号回归在科学发现和物理定律提取中的应用",
      "boolean_expr": "",
      "bm25_mode": "normal",
      "sim_scores": {
        "2602.12259v1": {
          "score": 28.15790636638112,
          "rank": 1
        },
        "2602.13021v2": {
          "score": 24.91171235959408,
          "rank": 2
        },
        "2602.10576v1": {
          "score": 23.631598944461967,
          "rank": 3
        },
        "2602.15603v1": {
          "score": 20.781742410825874,
          "rank": 4
        },
        "2602.16551v1": {
          "score": 20.408962593467823,
          "rank": 5
        },
        "2602.09443v1": {
          "score": 19.63274608829305,
          "rank": 6
        },
        "2602.08990v1": {
          "score": 18.577510012021232,
          "rank": 7
        },
        "2602.09801v1": {
          "score": 18.121740710837667,
          "rank": 8
        },
        "2602.13419v1": {
          "score": 17.440928821395786,
          "rank": 9
        },
        "2602.09132v1": {
          "score": 16.15829531986336,
          "rank": 10
        },
        "2602.15712v1": {
          "score": 15.249631740240654,
          "rank": 11
        },
        "2602.15169v1": {
          "score": 15.21883427294038,
          "rank": 12
        },
        "2602.09163v1": {
          "score": 14.85537789531509,
          "rank": 13
        },
        "2602.13312v1": {
          "score": 14.246952907442331,
          "rank": 14
        },
        "2602.15061v1": {
          "score": 14.089170824444054,
          "rank": 15
        },
        "2602.16166v1": {
          "score": 13.356071886403267,
          "rank": 16
        },
        "2602.10427v1": {
          "score": 13.138504593962804,
          "rank": 17
        },
        "2602.09809v1": {
          "score": 12.887839122391583,
          "rank": 18
        },
        "2602.11118v1": {
          "score": 12.76836513078054,
          "rank": 19
        },
        "2602.11630v1": {
          "score": 12.720554692999633,
          "rank": 20
        },
        "2602.11666v1": {
          "score": 12.669472478759733,
          "rank": 21
        },
        "2602.09670v1": {
          "score": 12.621401998699728,
          "rank": 22
        },
        "2602.16481v1": {
          "score": 12.365023080428523,
          "rank": 23
        },
        "2602.14674v2": {
          "score": 12.05865860760515,
          "rank": 24
        },
        "2602.10451v1": {
          "score": 11.825238982259943,
          "rank": 25
        },
        "2602.09430v1": {
          "score": 11.736508846330302,
          "rank": 26
        },
        "2602.10471v1": {
          "score": 11.482466901414673,
          "rank": 27
        },
        "2602.13769v1": {
          "score": 11.400739263148106,
          "rank": 28
        },
        "2602.16091v1": {
          "score": 11.214332775067335,
          "rank": 29
        },
        "2602.14318v1": {
          "score": 11.210437747581507,
          "rank": 30
        },
        "2602.11849v1": {
          "score": 11.162700480885743,
          "rank": 31
        },
        "2602.09494v1": {
          "score": 10.744346328393146,
          "rank": 32
        },
        "2602.10598v1": {
          "score": 10.7197954789936,
          "rank": 33
        },
        "2602.13871v1": {
          "score": 10.549220307822367,
          "rank": 34
        },
        "2602.09367v1": {
          "score": 10.420227717786625,
          "rank": 35
        },
        "2602.10840v1": {
          "score": 10.359627368604787,
          "rank": 36
        },
        "2602.10480v2": {
          "score": 10.35505989008666,
          "rank": 37
        },
        "2602.09116v2": {
          "score": 10.298408428208884,
          "rank": 38
        },
        "2602.15353v1": {
          "score": 10.018209135950269,
          "rank": 39
        },
        "2602.11123v1": {
          "score": 10.010684669656387,
          "rank": 40
        },
        "2602.09774v1": {
          "score": 9.959674944855735,
          "rank": 41
        },
        "2602.09947v1": {
          "score": 9.892238442401379,
          "rank": 42
        },
        "2602.10881v1": {
          "score": 9.853249092375115,
          "rank": 43
        },
        "2602.12870v1": {
          "score": 9.837081341924007,
          "rank": 44
        },
        "2602.16167v1": {
          "score": 9.798832376552204,
          "rank": 45
        },
        "2602.14456v1": {
          "score": 9.786023220820049,
          "rank": 46
        },
        "2602.13513v2": {
          "score": 9.779694494067694,
          "rank": 47
        },
        "2602.12851v1": {
          "score": 9.730152032732633,
          "rank": 48
        },
        "2602.15684v1": {
          "score": 9.601410069900112,
          "rank": 49
        },
        "2602.12889v1": {
          "score": 9.534387637868518,
          "rank": 50
        },
        "2602.13775v1": {
          "score": 9.495424583396877,
          "rank": 51
        },
        "2602.10670v1": {
          "score": 9.359668675858089,
          "rank": 52
        },
        "2602.15595v1": {
          "score": 9.298302399430888,
          "rank": 53
        },
        "2602.12465v1": {
          "score": 9.27071221511738,
          "rank": 54
        },
        "2602.09761v1": {
          "score": 9.234388946816916,
          "rank": 55
        },
        "2602.11291v1": {
          "score": 9.08969331530154,
          "rank": 56
        },
        "2602.15184v1": {
          "score": 9.07054064144475,
          "rank": 57
        },
        "2602.15984v1": {
          "score": 9.002572294265,
          "rank": 58
        },
        "2602.14362v1": {
          "score": 8.86976990963643,
          "rank": 59
        },
        "2602.15579v1": {
          "score": 8.79016802945089,
          "rank": 60
        },
        "2602.12203v1": {
          "score": 8.710886728945919,
          "rank": 61
        },
        "2602.11760v1": {
          "score": 8.704780261931996,
          "rank": 62
        },
        "2602.10236v1": {
          "score": 8.648162141925512,
          "rank": 63
        },
        "2602.12109v1": {
          "score": 8.639613960888614,
          "rank": 64
        },
        "2602.10377v1": {
          "score": 8.528407659364095,
          "rank": 65
        },
        "2602.09682v1": {
          "score": 8.525431652137012,
          "rank": 66
        },
        "2602.16302v1": {
          "score": 8.461177066773757,
          "rank": 67
        },
        "2602.10150v1": {
          "score": 8.443117860705573,
          "rank": 68
        },
        "2602.16217v1": {
          "score": 8.440446000394722,
          "rank": 69
        },
        "2602.14189v1": {
          "score": 8.434556332932326,
          "rank": 70
        },
        "2602.14928v1": {
          "score": 8.41433473045409,
          "rank": 71
        },
        "2602.10081v2": {
          "score": 8.339543950221877,
          "rank": 72
        },
        "2602.15634v1": {
          "score": 8.241760442608506,
          "rank": 73
        },
        "2602.13812v2": {
          "score": 8.226969799939548,
          "rank": 74
        },
        "2602.10476v1": {
          "score": 8.193319865758044,
          "rank": 75
        },
        "2602.15189v1": {
          "score": 8.125146210752408,
          "rank": 76
        },
        "2602.13748v1": {
          "score": 8.050460846482826,
          "rank": 77
        },
        "2602.15993v1": {
          "score": 7.9700841277641254,
          "rank": 78
        },
        "2602.14440v1": {
          "score": 7.941147594835267,
          "rank": 79
        },
        "2602.14198v1": {
          "score": 7.903183755667287,
          "rank": 80
        },
        "2602.12247v2": {
          "score": 7.858646322262944,
          "rank": 81
        },
        "2602.11626v1": {
          "score": 7.849014439293192,
          "rank": 82
        },
        "2602.12984v1": {
          "score": 7.845883827703431,
          "rank": 83
        },
        "2602.15991v1": {
          "score": 7.815410455462131,
          "rank": 84
        },
        "2602.09720v1": {
          "score": 7.750979149743467,
          "rank": 85
        },
        "2602.15451v1": {
          "score": 7.7459955014935264,
          "rank": 86
        },
        "2602.09963v1": {
          "score": 7.732539434939287,
          "rank": 87
        },
        "2602.11617v1": {
          "score": 7.718190884845567,
          "rank": 88
        },
        "2602.09723v1": {
          "score": 7.7160325616380625,
          "rank": 89
        },
        "2602.10652v1": {
          "score": 7.7061401950293265,
          "rank": 90
        },
        "2602.09319v2": {
          "score": 7.693830204643155,
          "rank": 91
        },
        "2602.12608v1": {
          "score": 7.635686198798008,
          "rank": 92
        },
        "2602.13583v1": {
          "score": 7.630054432824213,
          "rank": 93
        },
        "2602.10745v1": {
          "score": 7.611560457402499,
          "rank": 94
        },
        "2602.15980v1": {
          "score": 7.608845105615712,
          "rank": 95
        },
        "2602.12164v1": {
          "score": 7.600725434346649,
          "rank": 96
        },
        "2602.11081v1": {
          "score": 7.469688130512563,
          "rank": 97
        },
        "2602.13125v1": {
          "score": 7.456069856120482,
          "rank": 98
        },
        "2602.10587v1": {
          "score": 7.441147997073775,
          "rank": 99
        },
        "2602.14926v1": {
          "score": 7.4316141501343385,
          "rank": 100
        },
        "2602.09374v1": {
          "score": 7.416892558713574,
          "rank": 101
        },
        "2602.09570v1": {
          "score": 7.4167346690503155,
          "rank": 102
        },
        "2602.13348v1": {
          "score": 7.394388421272277,
          "rank": 103
        },
        "2602.16703v1": {
          "score": 7.351027793309589,
          "rank": 104
        },
        "2602.11898v1": {
          "score": 7.340610248534495,
          "rank": 105
        },
        "2602.16256v1": {
          "score": 7.332812604296418,
          "rank": 106
        },
        "2602.10300v1": {
          "score": 7.321572420120187,
          "rank": 107
        },
        "2602.09678v1": {
          "score": 7.290439645079988,
          "rank": 108
        },
        "2602.15306v1": {
          "score": 7.285637008116726,
          "rank": 109
        },
        "2602.10274v1": {
          "score": 7.278409609455463,
          "rank": 110
        },
        "2602.09986v1": {
          "score": 7.264226674749702,
          "rank": 111
        },
        "2602.16585v1": {
          "score": 7.236732054040554,
          "rank": 112
        },
        "2602.08963v1": {
          "score": 7.235831446798569,
          "rank": 113
        },
        "2602.12045v1": {
          "score": 7.215780671218534,
          "rank": 114
        },
        "2602.11290v2": {
          "score": 7.185725097667977,
          "rank": 115
        },
        "2602.16637v1": {
          "score": 7.1833863859793645,
          "rank": 116
        },
        "2602.10746v1": {
          "score": 7.169064632568666,
          "rank": 117
        },
        "2602.13144v1": {
          "score": 7.159771152197859,
          "rank": 118
        },
        "2602.13537v2": {
          "score": 7.14963150264437,
          "rank": 119
        },
        "2602.13729v1": {
          "score": 7.134726324814715,
          "rank": 120
        },
        "2602.13692v1": {
          "score": 7.118295558530401,
          "rank": 121
        },
        "2602.08982v1": {
          "score": 7.092944697857998,
          "rank": 122
        },
        "2602.09798v1": {
          "score": 7.090931037705443,
          "rank": 123
        },
        "2602.12737v1": {
          "score": 7.087174939769952,
          "rank": 124
        },
        "2602.11136v2": {
          "score": 7.0798818484978225,
          "rank": 125
        },
        "2602.09086v1": {
          "score": 7.069381641355656,
          "rank": 126
        },
        "2602.16435v1": {
          "score": 7.0640134312009035,
          "rank": 127
        },
        "2602.10632v1": {
          "score": 7.056633351242402,
          "rank": 128
        },
        "2602.09771v1": {
          "score": 7.053668901573796,
          "rank": 129
        },
        "2602.12114v1": {
          "score": 7.039748991629474,
          "rank": 130
        },
        "2602.16258v1": {
          "score": 7.023413517062098,
          "rank": 131
        },
        "2602.15570v1": {
          "score": 7.013020859131075,
          "rank": 132
        },
        "2602.11526v1": {
          "score": 6.972918324923133,
          "rank": 133
        },
        "2602.11215v1": {
          "score": 6.9699988549741585,
          "rank": 134
        },
        "2602.09996v2": {
          "score": 6.949181685476835,
          "rank": 135
        },
        "2602.10817v1": {
          "score": 6.942054377632919,
          "rank": 136
        },
        "2602.16376v1": {
          "score": 6.929213972847191,
          "rank": 137
        },
        "2602.13362v1": {
          "score": 6.922427196724069,
          "rank": 138
        },
        "2602.16639v1": {
          "score": 6.921818269993834,
          "rank": 139
        },
        "2602.11354v1": {
          "score": 6.910349414250253,
          "rank": 140
        },
        "2602.10384v2": {
          "score": 6.900006436835562,
          "rank": 141
        },
        "2602.13961v1": {
          "score": 6.886117205218029,
          "rank": 142
        },
        "2602.14141v1": {
          "score": 6.884595371164275,
          "rank": 143
        },
        "2602.10633v2": {
          "score": 6.867041657993536,
          "rank": 144
        },
        "2602.14633v1": {
          "score": 6.854166816821893,
          "rank": 145
        },
        "2602.11506v1": {
          "score": 6.842083700948597,
          "rank": 146
        },
        "2602.12989v1": {
          "score": 6.836277888691786,
          "rank": 147
        },
        "2602.16671v1": {
          "score": 6.833261847029265,
          "rank": 148
        },
        "2602.14480v1": {
          "score": 6.831547821816621,
          "rank": 149
        },
        "2602.11230v1": {
          "score": 6.807934939264575,
          "rank": 150
        },
        "2602.14922v1": {
          "score": 6.805188149014782,
          "rank": 151
        },
        "2602.09784v1": {
          "score": 6.790101895809288,
          "rank": 152
        },
        "2602.12537v1": {
          "score": 6.7710358541232845,
          "rank": 153
        },
        "2602.13152v1": {
          "score": 6.764332538442554,
          "rank": 154
        },
        "2602.12232v1": {
          "score": 6.762655814321292,
          "rank": 155
        },
        "2602.16463v1": {
          "score": 6.762300641436713,
          "rank": 156
        },
        "2602.09667v1": {
          "score": 6.748662952063142,
          "rank": 157
        },
        "2602.16631v1": {
          "score": 6.732678709422604,
          "rank": 158
        },
        "2602.09154v1": {
          "score": 6.699029873970453,
          "rank": 159
        },
        "2602.12883v1": {
          "score": 6.6940957559236285,
          "rank": 160
        },
        "2602.10365v1": {
          "score": 6.678774842423326,
          "rank": 161
        },
        "2602.15495v1": {
          "score": 6.65949634561117,
          "rank": 162
        },
        "2602.15068v1": {
          "score": 6.6375543431812805,
          "rank": 163
        },
        "2602.16331v1": {
          "score": 6.607630266390736,
          "rank": 164
        },
        "2602.12728v1": {
          "score": 6.5991454077780105,
          "rank": 165
        },
        "2602.13814v1": {
          "score": 6.586021149282568,
          "rank": 166
        },
        "2602.11356v1": {
          "score": 6.575217546030617,
          "rank": 167
        },
        "2602.12602v1": {
          "score": 6.571745007119242,
          "rank": 168
        },
        "2602.12399v1": {
          "score": 6.569654675719232,
          "rank": 169
        },
        "2602.11373v1": {
          "score": 6.567011322191562,
          "rank": 170
        },
        "2602.13758v1": {
          "score": 6.536260955411591,
          "rank": 171
        },
        "2602.15592v1": {
          "score": 6.525466291640925,
          "rank": 172
        },
        "2602.11700v1": {
          "score": 6.493398437365694,
          "rank": 173
        },
        "2602.16710v1": {
          "score": 6.478863705482412,
          "rank": 174
        },
        "2602.10165v1": {
          "score": 6.475576155504965,
          "rank": 175
        },
        "2602.15519v1": {
          "score": 6.423778232104179,
          "rank": 176
        },
        "2602.15649v1": {
          "score": 6.412305311922685,
          "rank": 177
        },
        "2602.12966v1": {
          "score": 6.411873680237802,
          "rank": 178
        },
        "2602.16095v1": {
          "score": 6.402988641377881,
          "rank": 179
        },
        "2602.09167v1": {
          "score": 6.398529294461218,
          "rank": 180
        },
        "2602.09569v1": {
          "score": 6.38667957317008,
          "rank": 181
        },
        "2602.14270v1": {
          "score": 6.386372165249674,
          "rank": 182
        },
        "2602.12534v1": {
          "score": 6.380992516697361,
          "rank": 183
        },
        "2602.16586v1": {
          "score": 6.364536294963803,
          "rank": 184
        },
        "2602.13319v1": {
          "score": 6.359878564886535,
          "rank": 185
        },
        "2602.13514v1": {
          "score": 6.33715662483528,
          "rank": 186
        },
        "2602.16379v1": {
          "score": 6.283431281180387,
          "rank": 187
        },
        "2602.10085v2": {
          "score": 6.270792727059963,
          "rank": 188
        },
        "2602.11886v1": {
          "score": 6.270532915001989,
          "rank": 189
        },
        "2602.11066v1": {
          "score": 6.2557161926505955,
          "rank": 190
        },
        "2602.15946v1": {
          "score": 6.253689146750449,
          "rank": 191
        },
        "2602.10170v1": {
          "score": 6.24808749477874,
          "rank": 192
        },
        "2602.10511v1": {
          "score": 6.2438018125351995,
          "rank": 193
        },
        "2602.11370v1": {
          "score": 6.216075196046316,
          "rank": 194
        },
        "2602.14823v1": {
          "score": 6.213160947498661,
          "rank": 195
        },
        "2602.11124v1": {
          "score": 6.211828077832921,
          "rank": 196
        },
        "2602.14755v1": {
          "score": 6.203869849275339,
          "rank": 197
        },
        "2602.09351v1": {
          "score": 6.2033720433448085,
          "rank": 198
        },
        "2602.10613v1": {
          "score": 6.1987875733175875,
          "rank": 199
        },
        "2602.13873v1": {
          "score": 6.190533480047802,
          "rank": 200
        },
        "2602.14812v1": {
          "score": 6.184269452582012,
          "rank": 201
        },
        "2602.15911v1": {
          "score": 6.174868565988541,
          "rank": 202
        },
        "2602.10803v2": {
          "score": 6.169042469698903,
          "rank": 203
        },
        "2602.13595v1": {
          "score": 6.168401429317274,
          "rank": 204
        },
        "2602.10324v1": {
          "score": 6.168274509708492,
          "rank": 205
        },
        "2602.15253v1": {
          "score": 6.158829895595502,
          "rank": 206
        },
        "2602.11122v2": {
          "score": 6.141749075397615,
          "rank": 207
        },
        "2602.11489v1": {
          "score": 6.130974862154786,
          "rank": 208
        },
        "2602.15820v1": {
          "score": 6.127535236700444,
          "rank": 209
        },
        "2602.10163v1": {
          "score": 6.085899469078844,
          "rank": 210
        },
        "2602.13471v1": {
          "score": 6.075278516996424,
          "rank": 211
        },
        "2602.09489v1": {
          "score": 6.046771372721584,
          "rank": 212
        },
        "2602.10363v1": {
          "score": 6.037223031486979,
          "rank": 213
        },
        "2602.15917v1": {
          "score": 6.036831430542597,
          "rank": 214
        },
        "2602.11414v1": {
          "score": 6.027285528436189,
          "rank": 215
        },
        "2602.14009v1": {
          "score": 6.026285211167826,
          "rank": 216
        },
        "2602.09748v1": {
          "score": 6.025502064473983,
          "rank": 217
        },
        "2602.12072v1": {
          "score": 6.016910136064503,
          "rank": 218
        },
        "2602.13512v1": {
          "score": 6.007764653464048,
          "rank": 219
        },
        "2602.14968v1": {
          "score": 5.985500899297551,
          "rank": 220
        },
        "2602.15947v1": {
          "score": 5.984377418372526,
          "rank": 221
        },
        "2602.16531v1": {
          "score": 5.9779143703952204,
          "rank": 222
        },
        "2602.09554v1": {
          "score": 5.952683022684129,
          "rank": 223
        },
        "2602.16006v1": {
          "score": 5.946038988779176,
          "rank": 224
        },
        "2602.09456v1": {
          "score": 5.944884312580608,
          "rank": 225
        },
        "2602.10750v1": {
          "score": 5.944873986805983,
          "rank": 226
        },
        "2602.16320v1": {
          "score": 5.9340468741445145,
          "rank": 227
        },
        "2602.11211v1": {
          "score": 5.919148404570766,
          "rank": 228
        },
        "2602.09279v1": {
          "score": 5.914085672353879,
          "rank": 229
        },
        "2602.12554v1": {
          "score": 5.912356537672862,
          "rank": 230
        },
        "2602.12454v1": {
          "score": 5.905487868050005,
          "rank": 231
        },
        "2602.13591v1": {
          "score": 5.876558596167554,
          "rank": 232
        },
        "2602.09647v1": {
          "score": 5.8559272454911895,
          "rank": 233
        },
        "2602.15074v1": {
          "score": 5.854321951440209,
          "rank": 234
        },
        "2602.09543v1": {
          "score": 5.845665881595879,
          "rank": 235
        },
        "2602.09971v1": {
          "score": 5.8421526886318125,
          "rank": 236
        },
        "2602.11019v1": {
          "score": 5.8417024717391985,
          "rank": 237
        },
        "2602.16020v1": {
          "score": 5.824483554521361,
          "rank": 238
        },
        "2602.16606v1": {
          "score": 5.813625265599899,
          "rank": 239
        },
        "2602.10265v1": {
          "score": 5.800757870687368,
          "rank": 240
        },
        "2602.09299v1": {
          "score": 5.798310000515678,
          "rank": 241
        },
        "2602.09729v1": {
          "score": 5.790394810774375,
          "rank": 242
        },
        "2602.16038v1": {
          "score": 5.783936325814135,
          "rank": 243
        },
        "2602.12379v1": {
          "score": 5.77102181935224,
          "rank": 244
        },
        "2602.11261v1": {
          "score": 5.756226374624298,
          "rank": 245
        },
        "2602.15343v1": {
          "score": 5.735601036116932,
          "rank": 246
        },
        "2602.14367v1": {
          "score": 5.731511149511395,
          "rank": 247
        },
        "2602.09817v1": {
          "score": 5.724965647792655,
          "rank": 248
        },
        "2602.12358v1": {
          "score": 5.724137063427785,
          "rank": 249
        },
        "2602.14285v1": {
          "score": 5.709825006815552,
          "rank": 250
        },
        "2602.10276v1": {
          "score": 5.705867946995239,
          "rank": 251
        },
        "2602.12489v1": {
          "score": 5.704684112485605,
          "rank": 252
        },
        "2602.12084v1": {
          "score": 5.699307370294614,
          "rank": 253
        },
        "2602.10055v1": {
          "score": 5.689162814971162,
          "rank": 254
        },
        "2602.14974v1": {
          "score": 5.681575515052301,
          "rank": 255
        },
        "2602.14670v1": {
          "score": 5.66273200847182,
          "rank": 256
        },
        "2602.14537v1": {
          "score": 5.620458224898404,
          "rank": 257
        },
        "2602.13321v1": {
          "score": 5.615926396078803,
          "rank": 258
        },
        "2602.09397v1": {
          "score": 5.610092414098709,
          "rank": 259
        },
        "2602.12361v1": {
          "score": 5.604044933476861,
          "rank": 260
        },
        "2602.11631v1": {
          "score": 5.592152588241618,
          "rank": 261
        },
        "2602.09387v2": {
          "score": 5.591624471495173,
          "rank": 262
        },
        "2602.10996v1": {
          "score": 5.584681581963129,
          "rank": 263
        },
        "2602.13067v1": {
          "score": 5.576421332333012,
          "rank": 264
        },
        "2602.09472v1": {
          "score": 5.573610426808721,
          "rank": 265
        },
        "2602.12569v1": {
          "score": 5.570799146397339,
          "rank": 266
        },
        "2602.13778v1": {
          "score": 5.56964552969132,
          "rank": 267
        },
        "2602.14029v1": {
          "score": 5.565055475535952,
          "rank": 268
        },
        "2602.15933v1": {
          "score": 5.560940239543014,
          "rank": 269
        },
        "2602.10980v1": {
          "score": 5.5456115925507925,
          "rank": 270
        },
        "2602.11678v1": {
          "score": 5.534682447854611,
          "rank": 271
        },
        "2602.13011v1": {
          "score": 5.519121123444671,
          "rank": 272
        },
        "2602.15493v1": {
          "score": 5.487156762529906,
          "rank": 273
        },
        "2602.12267v1": {
          "score": 5.483769276599419,
          "rank": 274
        },
        "2602.09378v1": {
          "score": 5.477798913555253,
          "rank": 275
        },
        "2602.16294v1": {
          "score": 5.4674898871909985,
          "rank": 276
        },
        "2602.10320v1": {
          "score": 5.450700577031745,
          "rank": 277
        },
        "2602.15139v1": {
          "score": 5.447651029069525,
          "rank": 278
        },
        "2602.11092v1": {
          "score": 5.431572416083226,
          "rank": 279
        },
        "2602.09218v1": {
          "score": 5.426244684024372,
          "rank": 280
        },
        "2602.09767v1": {
          "score": 5.415549985492555,
          "rank": 281
        },
        "2602.15085v1": {
          "score": 5.389635498188344,
          "rank": 282
        },
        "2602.16583v1": {
          "score": 5.3595074911089435,
          "rank": 283
        },
        "2602.14178v1": {
          "score": 5.351009359734716,
          "rank": 284
        },
        "2602.10386v1": {
          "score": 5.347751999594834,
          "rank": 285
        },
        "2602.10263v1": {
          "score": 5.326815946087616,
          "rank": 286
        },
        "2602.15369v1": {
          "score": 5.322984882134381,
          "rank": 287
        },
        "2602.15212v1": {
          "score": 5.317975355379784,
          "rank": 288
        },
        "2602.15743v1": {
          "score": 5.301860817478441,
          "rank": 289
        },
        "2602.11855v1": {
          "score": 5.301218116939582,
          "rank": 290
        },
        "2602.09831v1": {
          "score": 5.281478645390783,
          "rank": 291
        },
        "2602.09330v1": {
          "score": 5.278727260029236,
          "rank": 292
        },
        "2602.11825v1": {
          "score": 5.276254472606489,
          "rank": 293
        },
        "2602.15077v1": {
          "score": 5.268777602320055,
          "rank": 294
        },
        "2602.11021v1": {
          "score": 5.240564885567605,
          "rank": 295
        },
        "2602.11733v1": {
          "score": 5.229683182577176,
          "rank": 296
        },
        "2602.12632v1": {
          "score": 5.227926687736365,
          "rank": 297
        },
        "2602.12633v1": {
          "score": 5.216275348115106,
          "rank": 298
        },
        "2602.11917v1": {
          "score": 5.211350421746043,
          "rank": 299
        },
        "2602.10807v1": {
          "score": 5.186344837694058,
          "rank": 300
        },
        "2602.14969v1": {
          "score": 5.151087628464367,
          "rank": 301
        },
        "2602.10461v1": {
          "score": 5.149732267875981,
          "rank": 302
        },
        "2602.09325v1": {
          "score": 5.13213829454491,
          "rank": 303
        },
        "2602.16561v1": {
          "score": 5.128430423530334,
          "rank": 304
        },
        "2602.13396v1": {
          "score": 5.109395032369764,
          "rank": 305
        },
        "2602.12244v1": {
          "score": 5.096513352893299,
          "rank": 306
        },
        "2602.15183v1": {
          "score": 5.093703640242712,
          "rank": 307
        },
        "2602.09153v1": {
          "score": 5.090809918669853,
          "rank": 308
        },
        "2602.16346v1": {
          "score": 5.075742410590875,
          "rank": 309
        },
        "2602.09663v1": {
          "score": 5.05889355699003,
          "rank": 310
        },
        "2602.12886v1": {
          "score": 5.0520366150673,
          "rank": 311
        },
        "2602.10644v1": {
          "score": 5.044934471237242,
          "rank": 312
        },
        "2602.11461v1": {
          "score": 5.035436026744428,
          "rank": 313
        },
        "2602.11084v1": {
          "score": 5.0171083296827765,
          "rank": 314
        },
        "2602.14094v1": {
          "score": 5.0163317198368,
          "rank": 315
        },
        "2602.16367v1": {
          "score": 4.997782101973145,
          "rank": 316
        },
        "2602.10910v1": {
          "score": 4.993331443032064,
          "rank": 317
        },
        "2602.12218v1": {
          "score": 4.98759406039944,
          "rank": 318
        },
        "2602.10678v1": {
          "score": 4.982908551033731,
          "rank": 319
        },
        "2602.11133v1": {
          "score": 4.975862601836276,
          "rank": 320
        },
        "2602.13378v1": {
          "score": 4.974191345062446,
          "rank": 321
        },
        "2602.11757v1": {
          "score": 4.967412746837238,
          "rank": 322
        },
        "2602.13398v1": {
          "score": 4.961739136041912,
          "rank": 323
        },
        "2602.14692v1": {
          "score": 4.960430765952656,
          "rank": 324
        },
        "2602.16420v1": {
          "score": 4.96018092461901,
          "rank": 325
        },
        "2602.12938v1": {
          "score": 4.946384788089653,
          "rank": 326
        },
        "2602.11071v1": {
          "score": 4.946222683728847,
          "rank": 327
        },
        "2602.12977v2": {
          "score": 4.90902137209629,
          "rank": 328
        },
        "2602.13387v1": {
          "score": 4.907335286703662,
          "rank": 329
        },
        "2602.13180v1": {
          "score": 4.905421783800811,
          "rank": 330
        },
        "2602.15626v1": {
          "score": 4.902527788591258,
          "rank": 331
        },
        "2602.12063v2": {
          "score": 4.888208651371333,
          "rank": 332
        },
        "2602.10916v1": {
          "score": 4.855093260954487,
          "rank": 333
        },
        "2602.12410v1": {
          "score": 4.8494576775217215,
          "rank": 334
        },
        "2602.16120v1": {
          "score": 4.817652009148803,
          "rank": 335
        },
        "2602.15424v1": {
          "score": 4.812772735087674,
          "rank": 336
        },
        "2602.13833v1": {
          "score": 4.809332317540359,
          "rank": 337
        },
        "2602.13556v1": {
          "score": 4.805001949466034,
          "rank": 338
        },
        "2602.12704v1": {
          "score": 4.80332693793562,
          "rank": 339
        },
        "2602.14704v1": {
          "score": 4.790882466602975,
          "rank": 340
        },
        "2602.15777v1": {
          "score": 4.787605508986899,
          "rank": 341
        },
        "2602.14372v1": {
          "score": 4.781115126853433,
          "rank": 342
        },
        "2602.12589v1": {
          "score": 4.779070677080544,
          "rank": 343
        },
        "2602.14677v1": {
          "score": 4.778570967101463,
          "rank": 344
        },
        "2602.10061v1": {
          "score": 4.775291066216556,
          "rank": 345
        },
        "2602.14291v1": {
          "score": 4.768415921290581,
          "rank": 346
        },
        "2602.10895v1": {
          "score": 4.763059882548613,
          "rank": 347
        },
        "2602.14256v1": {
          "score": 4.762502933081683,
          "rank": 348
        },
        "2602.11463v1": {
          "score": 4.758353515959902,
          "rank": 349
        },
        "2602.16604v1": {
          "score": 4.751541158793625,
          "rank": 350
        },
        "2602.14743v1": {
          "score": 4.742959264314362,
          "rank": 351
        },
        "2602.15697v1": {
          "score": 4.736308277192249,
          "rank": 352
        },
        "2602.16459v1": {
          "score": 4.725455834738996,
          "rank": 353
        },
        "2602.14551v1": {
          "score": 4.723952982300619,
          "rank": 354
        },
        "2602.10920v1": {
          "score": 4.718612323989271,
          "rank": 355
        },
        "2602.11801v1": {
          "score": 4.710671988645864,
          "rank": 356
        },
        "2602.16415v1": {
          "score": 4.694854125118289,
          "rank": 357
        },
        "2602.13316v1": {
          "score": 4.672423431715861,
          "rank": 358
        },
        "2602.12306v1": {
          "score": 4.664195557917285,
          "rank": 359
        },
        "2602.12364v1": {
          "score": 4.66224758393304,
          "rank": 360
        },
        "2602.10689v1": {
          "score": 4.655680976368499,
          "rank": 361
        },
        "2602.15925v1": {
          "score": 4.655207218085632,
          "rank": 362
        },
        "2602.12417v1": {
          "score": 4.645146607337347,
          "rank": 363
        },
        "2602.14737v1": {
          "score": 4.638824957931913,
          "rank": 364
        },
        "2602.13195v1": {
          "score": 4.637339952629162,
          "rank": 365
        },
        "2602.09695v1": {
          "score": 4.632632437705076,
          "rank": 366
        },
        "2602.15893v1": {
          "score": 4.628645775084249,
          "rank": 367
        },
        "2602.12310v1": {
          "score": 4.625364809293955,
          "rank": 368
        },
        "2602.13093v2": {
          "score": 4.624788688799335,
          "rank": 369
        },
        "2602.09617v1": {
          "score": 4.619513083416517,
          "rank": 370
        },
        "2602.15282v1": {
          "score": 4.618051348609353,
          "rank": 371
        },
        "2602.12442v1": {
          "score": 4.617734801410726,
          "rank": 372
        },
        "2602.11583v1": {
          "score": 4.6149480231463675,
          "rank": 373
        },
        "2602.12257v1": {
          "score": 4.611908824881086,
          "rank": 374
        },
        "2602.14414v1": {
          "score": 4.6061229163115724,
          "rank": 375
        },
        "2602.14557v1": {
          "score": 4.606020389418055,
          "rank": 376
        },
        "2602.10791v1": {
          "score": 4.601872035796036,
          "rank": 377
        },
        "2602.15733v1": {
          "score": 4.599030295645665,
          "rank": 378
        },
        "2602.13987v1": {
          "score": 4.579957579805915,
          "rank": 379
        },
        "2602.15472v1": {
          "score": 4.579835831321536,
          "rank": 380
        },
        "2602.15437v1": {
          "score": 4.578939648489898,
          "rank": 381
        },
        "2602.10870v1": {
          "score": 4.570935181659761,
          "rank": 382
        },
        "2602.13694v1": {
          "score": 4.56788523887752,
          "rank": 383
        },
        "2602.14280v1": {
          "score": 4.552615515178436,
          "rank": 384
        },
        "2602.09827v1": {
          "score": 4.550700629889601,
          "rank": 385
        },
        "2602.12758v1": {
          "score": 4.544380472873098,
          "rank": 386
        },
        "2602.09270v1": {
          "score": 4.54309776525971,
          "rank": 387
        },
        "2602.12538v1": {
          "score": 4.53806541593791,
          "rank": 388
        },
        "2602.12511v1": {
          "score": 4.5350401654105115,
          "rank": 389
        },
        "2602.10544v1": {
          "score": 4.533271144811483,
          "rank": 390
        },
        "2602.11131v1": {
          "score": 4.526726197842119,
          "rank": 391
        },
        "2602.13791v1": {
          "score": 4.526098902689566,
          "rank": 392
        },
        "2602.09516v1": {
          "score": 4.524786949962737,
          "rank": 393
        },
        "2602.16422v1": {
          "score": 4.52444766191361,
          "rank": 394
        },
        "2602.15627v1": {
          "score": 4.5178028391032345,
          "rank": 395
        },
        "2602.11982v1": {
          "score": 4.517082048170162,
          "rank": 396
        },
        "2602.14216v1": {
          "score": 4.516731428355488,
          "rank": 397
        },
        "2602.15067v1": {
          "score": 4.516145593066416,
          "rank": 398
        },
        "2602.10387v1": {
          "score": 4.514289397874895,
          "rank": 399
        },
        "2602.11848v1": {
          "score": 4.512083174727734,
          "rank": 400
        }
      }
    },
    {
      "type": "llm_query",
      "tag": "SR",
      "paper_tag": "query:SR",
      "query_text": "Comparison of genetic programming and neural symbolic regression techniques",
      "logic_cn": "对比遗传规划与神经符号回归技术的优劣",
      "boolean_expr": "",
      "bm25_mode": "normal",
      "sim_scores": {
        "2602.15169v1": {
          "score": 24.852541982580387,
          "rank": 1
        },
        "2602.09772v1": {
          "score": 17.09921214959214,
          "rank": 2
        },
        "2602.15070v1": {
          "score": 15.875080020382509,
          "rank": 3
        },
        "2602.13583v1": {
          "score": 15.390825300810407,
          "rank": 4
        },
        "2602.15353v1": {
          "score": 15.266925793841931,
          "rank": 5
        },
        "2602.16166v1": {
          "score": 14.975197450691713,
          "rank": 6
        },
        "2602.12870v1": {
          "score": 14.504901629041264,
          "rank": 7
        },
        "2602.13419v1": {
          "score": 14.436096242585114,
          "rank": 8
        },
        "2602.10598v1": {
          "score": 14.051112971448708,
          "rank": 9
        },
        "2602.12851v1": {
          "score": 13.834658728105858,
          "rank": 10
        },
        "2602.12259v1": {
          "score": 13.661734984000088,
          "rank": 11
        },
        "2602.12889v1": {
          "score": 13.42126334942591,
          "rank": 12
        },
        "2602.10480v2": {
          "score": 13.232157046407334,
          "rank": 13
        },
        "2602.13864v1": {
          "score": 12.972031186913846,
          "rank": 14
        },
        "2602.14692v1": {
          "score": 12.86933244844756,
          "rank": 15
        },
        "2602.13021v2": {
          "score": 12.838225894744792,
          "rank": 16
        },
        "2602.15603v1": {
          "score": 12.723232786640324,
          "rank": 17
        },
        "2602.15354v1": {
          "score": 12.714391947505835,
          "rank": 18
        },
        "2602.15387v1": {
          "score": 12.439665074505363,
          "rank": 19
        },
        "2602.09761v1": {
          "score": 12.301451758397844,
          "rank": 20
        },
        "2602.11947v1": {
          "score": 11.668395530827356,
          "rank": 21
        },
        "2602.11666v1": {
          "score": 11.613426998685991,
          "rank": 22
        },
        "2602.14440v1": {
          "score": 10.883784273616527,
          "rank": 23
        },
        "2602.10754v1": {
          "score": 10.832272359211405,
          "rank": 24
        },
        "2602.15468v1": {
          "score": 10.636502407419346,
          "rank": 25
        },
        "2602.09225v1": {
          "score": 10.356767736999867,
          "rank": 26
        },
        "2602.15459v1": {
          "score": 10.321732576151494,
          "rank": 27
        },
        "2602.09946v1": {
          "score": 10.31586361117543,
          "rank": 28
        },
        "2602.10265v1": {
          "score": 10.234938319294166,
          "rank": 29
        },
        "2602.12569v1": {
          "score": 10.182011484558235,
          "rank": 30
        },
        "2602.13730v1": {
          "score": 9.899384663825847,
          "rank": 31
        },
        "2602.10171v1": {
          "score": 9.796375989072763,
          "rank": 32
        },
        "2602.09613v1": {
          "score": 9.746032559276236,
          "rank": 33
        },
        "2602.11463v1": {
          "score": 9.706822206389536,
          "rank": 34
        },
        "2602.10891v1": {
          "score": 9.549735718050865,
          "rank": 35
        },
        "2602.16606v1": {
          "score": 9.341439899913963,
          "rank": 36
        },
        "2602.14573v1": {
          "score": 9.30076099175336,
          "rank": 37
        },
        "2602.15684v1": {
          "score": 9.287620169607226,
          "rank": 38
        },
        "2602.15376v1": {
          "score": 9.259007996277495,
          "rank": 39
        },
        "2602.10266v1": {
          "score": 9.166746915052085,
          "rank": 40
        },
        "2602.15925v1": {
          "score": 9.164295341259201,
          "rank": 41
        },
        "2602.12273v1": {
          "score": 9.14336477295272,
          "rank": 42
        },
        "2602.09809v1": {
          "score": 9.113587926379118,
          "rank": 43
        },
        "2602.10012v1": {
          "score": 9.071991502666773,
          "rank": 44
        },
        "2602.14337v1": {
          "score": 9.036825582773272,
          "rank": 45
        },
        "2602.16504v1": {
          "score": 9.002476178786681,
          "rank": 46
        },
        "2602.11291v1": {
          "score": 8.963334714694872,
          "rank": 47
        },
        "2602.13106v1": {
          "score": 8.910785910746819,
          "rank": 48
        },
        "2602.15247v1": {
          "score": 8.90459409892068,
          "rank": 49
        },
        "2602.12993v1": {
          "score": 8.903918362614858,
          "rank": 50
        },
        "2602.15995v1": {
          "score": 8.886921194373357,
          "rank": 51
        },
        "2602.10576v1": {
          "score": 8.766512608057234,
          "rank": 52
        },
        "2602.12872v1": {
          "score": 8.748984139457091,
          "rank": 53
        },
        "2602.16459v1": {
          "score": 8.726186434696421,
          "rank": 54
        },
        "2602.13155v1": {
          "score": 8.658398243900166,
          "rank": 55
        },
        "2602.09647v1": {
          "score": 8.638492018418441,
          "rank": 56
        },
        "2602.16473v1": {
          "score": 8.501422104297024,
          "rank": 57
        },
        "2602.09321v1": {
          "score": 8.464323851003314,
          "rank": 58
        },
        "2602.12109v1": {
          "score": 8.448035479922744,
          "rank": 59
        },
        "2602.11332v1": {
          "score": 8.410815561882789,
          "rank": 60
        },
        "2602.16584v1": {
          "score": 8.377692430843927,
          "rank": 61
        },
        "2602.10996v1": {
          "score": 8.344214973595696,
          "rank": 62
        },
        "2602.11632v1": {
          "score": 8.27597991029951,
          "rank": 63
        },
        "2602.13181v1": {
          "score": 8.250592207866472,
          "rank": 64
        },
        "2602.13784v1": {
          "score": 8.233978801185394,
          "rank": 65
        },
        "2602.15554v1": {
          "score": 8.231692397852402,
          "rank": 66
        },
        "2602.10249v1": {
          "score": 8.215409876530373,
          "rank": 67
        },
        "2602.12949v1": {
          "score": 8.183869247985564,
          "rank": 68
        },
        "2602.12867v1": {
          "score": 8.153846801833811,
          "rank": 69
        },
        "2602.09552v1": {
          "score": 8.136002165966504,
          "rank": 70
        },
        "2602.12436v1": {
          "score": 8.117585644479174,
          "rank": 71
        },
        "2602.14262v1": {
          "score": 8.108550809887847,
          "rank": 72
        },
        "2602.16291v1": {
          "score": 8.099864385983214,
          "rank": 73
        },
        "2602.14624v1": {
          "score": 8.06675855087589,
          "rank": 74
        },
        "2602.11077v1": {
          "score": 8.039712374770094,
          "rank": 75
        },
        "2602.11063v2": {
          "score": 8.020070210901261,
          "rank": 76
        },
        "2602.10373v1": {
          "score": 7.953562873102787,
          "rank": 77
        },
        "2602.09667v1": {
          "score": 7.857559664175483,
          "rank": 78
        },
        "2602.11825v1": {
          "score": 7.807745864531077,
          "rank": 79
        },
        "2602.12704v1": {
          "score": 7.787531810695528,
          "rank": 80
        },
        "2602.10605v1": {
          "score": 7.743182817281529,
          "rank": 81
        },
        "2602.13000v1": {
          "score": 7.705251634807308,
          "rank": 82
        },
        "2602.09779v1": {
          "score": 7.697873200017881,
          "rank": 83
        },
        "2602.10870v1": {
          "score": 7.675376292290446,
          "rank": 84
        },
        "2602.13455v1": {
          "score": 7.665408375574659,
          "rank": 85
        },
        "2602.12677v1": {
          "score": 7.661544861559647,
          "rank": 86
        },
        "2602.15224v1": {
          "score": 7.627113584694099,
          "rank": 87
        },
        "2602.12472v1": {
          "score": 7.603163114015017,
          "rank": 88
        },
        "2602.15579v1": {
          "score": 7.600178283381115,
          "rank": 89
        },
        "2602.16213v1": {
          "score": 7.5960971479929915,
          "rank": 90
        },
        "2602.16303v1": {
          "score": 7.582471835992973,
          "rank": 91
        },
        "2602.09720v1": {
          "score": 7.561693781865772,
          "rank": 92
        },
        "2602.14287v1": {
          "score": 7.482402790539376,
          "rank": 93
        },
        "2602.10745v1": {
          "score": 7.384389301428951,
          "rank": 94
        },
        "2602.14663v1": {
          "score": 7.338973262720618,
          "rank": 95
        },
        "2602.11706v1": {
          "score": 7.323775801551733,
          "rank": 96
        },
        "2602.15068v1": {
          "score": 7.317808728525691,
          "rank": 97
        },
        "2602.10587v1": {
          "score": 7.278627243030226,
          "rank": 98
        },
        "2602.13348v1": {
          "score": 7.250770747664401,
          "rank": 99
        },
        "2602.10585v1": {
          "score": 7.237753430730304,
          "rank": 100
        },
        "2602.13378v1": {
          "score": 7.214688775039267,
          "rank": 101
        },
        "2602.15385v2": {
          "score": 7.2022985080356845,
          "rank": 102
        },
        "2602.12214v1": {
          "score": 7.196777942912556,
          "rank": 103
        },
        "2602.10274v1": {
          "score": 7.195534983326359,
          "rank": 104
        },
        "2602.10830v1": {
          "score": 7.171633947699487,
          "rank": 105
        },
        "2602.16256v1": {
          "score": 7.1491975640962035,
          "rank": 106
        },
        "2602.16170v1": {
          "score": 7.1324188815402625,
          "rank": 107
        },
        "2602.16118v1": {
          "score": 7.1270700386163615,
          "rank": 108
        },
        "2602.10355v1": {
          "score": 7.0616156504380445,
          "rank": 109
        },
        "2602.11290v2": {
          "score": 7.036188428181345,
          "rank": 110
        },
        "2602.11136v2": {
          "score": 6.9973179905607354,
          "rank": 111
        },
        "2602.13909v1": {
          "score": 6.991165339538551,
          "rank": 112
        },
        "2602.10746v1": {
          "score": 6.981558040326505,
          "rank": 113
        },
        "2602.11481v1": {
          "score": 6.978394721257955,
          "rank": 114
        },
        "2602.14997v1": {
          "score": 6.96503352979733,
          "rank": 115
        },
        "2602.11630v1": {
          "score": 6.964752597445348,
          "rank": 116
        },
        "2602.13729v1": {
          "score": 6.96299721293978,
          "rank": 117
        },
        "2602.10457v1": {
          "score": 6.959853744409766,
          "rank": 118
        },
        "2602.09798v1": {
          "score": 6.959107022114785,
          "rank": 119
        },
        "2602.14040v1": {
          "score": 6.954128808503242,
          "rank": 120
        },
        "2602.13537v2": {
          "score": 6.951327505173001,
          "rank": 121
        },
        "2602.09702v1": {
          "score": 6.941386787716803,
          "rank": 122
        },
        "2602.16573v1": {
          "score": 6.940775555179014,
          "rank": 123
        },
        "2602.10827v1": {
          "score": 6.936870510728873,
          "rank": 124
        },
        "2602.11285v1": {
          "score": 6.90377989165692,
          "rank": 125
        },
        "2602.12114v1": {
          "score": 6.892632709728306,
          "rank": 126
        },
        "2602.16417v1": {
          "score": 6.889982256565473,
          "rank": 127
        },
        "2602.10982v1": {
          "score": 6.862503277596753,
          "rank": 128
        },
        "2602.11154v1": {
          "score": 6.851804536808249,
          "rank": 129
        },
        "2602.13362v1": {
          "score": 6.789041653604581,
          "rank": 130
        },
        "2602.09996v2": {
          "score": 6.784833564798067,
          "rank": 131
        },
        "2602.16376v1": {
          "score": 6.755712632636387,
          "rank": 132
        },
        "2602.14102v1": {
          "score": 6.709821067374679,
          "rank": 133
        },
        "2602.16574v1": {
          "score": 6.704236347310635,
          "rank": 134
        },
        "2602.16671v1": {
          "score": 6.673284361583351,
          "rank": 135
        },
        "2602.14480v1": {
          "score": 6.665950945132188,
          "rank": 136
        },
        "2602.16342v1": {
          "score": 6.638447635550048,
          "rank": 137
        },
        "2602.13152v1": {
          "score": 6.627161475874012,
          "rank": 138
        },
        "2602.09190v1": {
          "score": 6.619247778776632,
          "rank": 139
        },
        "2602.12848v1": {
          "score": 6.618020362803971,
          "rank": 140
        },
        "2602.11506v1": {
          "score": 6.5675024165333316,
          "rank": 141
        },
        "2602.09774v1": {
          "score": 6.560595970323888,
          "rank": 142
        },
        "2602.11118v1": {
          "score": 6.55724631683883,
          "rank": 143
        },
        "2602.16463v1": {
          "score": 6.541866014747944,
          "rank": 144
        },
        "2602.12750v1": {
          "score": 6.538625453672312,
          "rank": 145
        },
        "2602.14239v1": {
          "score": 6.469764121330979,
          "rank": 146
        },
        "2602.10365v1": {
          "score": 6.462423484390564,
          "rank": 147
        },
        "2602.10679v1": {
          "score": 6.459217503251849,
          "rank": 148
        },
        "2602.15010v2": {
          "score": 6.429444798895638,
          "rank": 149
        },
        "2602.11700v1": {
          "score": 6.421413233017922,
          "rank": 150
        },
        "2602.16091v1": {
          "score": 6.394382532509432,
          "rank": 151
        },
        "2602.11966v1": {
          "score": 6.3925703183707165,
          "rank": 152
        },
        "2602.13410v1": {
          "score": 6.381631619906298,
          "rank": 153
        },
        "2602.09620v1": {
          "score": 6.379437082474304,
          "rank": 154
        },
        "2602.13140v1": {
          "score": 6.356507258515579,
          "rank": 155
        },
        "2602.12399v1": {
          "score": 6.337650483447939,
          "rank": 156
        },
        "2602.10751v1": {
          "score": 6.309172124079882,
          "rank": 157
        },
        "2602.09435v2": {
          "score": 6.28252828345968,
          "rank": 158
        },
        "2602.10613v1": {
          "score": 6.256170342462422,
          "rank": 159
        },
        "2602.15269v1": {
          "score": 6.2454609966002,
          "rank": 160
        },
        "2602.12534v1": {
          "score": 6.2367479094603135,
          "rank": 161
        },
        "2602.09457v1": {
          "score": 6.227288874077072,
          "rank": 162
        },
        "2602.09167v1": {
          "score": 6.1956833869713925,
          "rank": 163
        },
        "2602.13791v1": {
          "score": 6.180950228621399,
          "rank": 164
        },
        "2602.16005v1": {
          "score": 6.174053712189312,
          "rank": 165
        },
        "2602.13325v1": {
          "score": 6.168614880925765,
          "rank": 166
        },
        "2602.12865v1": {
          "score": 6.164620813030339,
          "rank": 167
        },
        "2602.10529v1": {
          "score": 6.163367507160404,
          "rank": 168
        },
        "2602.09746v1": {
          "score": 6.1511060839542555,
          "rank": 169
        },
        "2602.09210v1": {
          "score": 6.150294669832056,
          "rank": 170
        },
        "2602.16586v1": {
          "score": 6.143014354210377,
          "rank": 171
        },
        "2602.09215v1": {
          "score": 6.127406021675754,
          "rank": 172
        },
        "2602.09711v1": {
          "score": 6.109743383849243,
          "rank": 173
        },
        "2602.11785v1": {
          "score": 6.1094510676397125,
          "rank": 174
        },
        "2602.09351v1": {
          "score": 6.101217693738566,
          "rank": 175
        },
        "2602.13043v1": {
          "score": 6.094471212607724,
          "rank": 176
        },
        "2602.16522v1": {
          "score": 6.0500856432412755,
          "rank": 177
        },
        "2602.13630v1": {
          "score": 6.0321043221470045,
          "rank": 178
        },
        "2602.15632v1": {
          "score": 6.028942248999112,
          "rank": 179
        },
        "2602.10191v1": {
          "score": 6.028270424683676,
          "rank": 180
        },
        "2602.16075v1": {
          "score": 6.016217360830916,
          "rank": 181
        },
        "2602.15172v1": {
          "score": 5.995214493652429,
          "rank": 182
        },
        "2602.13607v1": {
          "score": 5.9774509471009925,
          "rank": 183
        },
        "2602.15820v1": {
          "score": 5.956649640980489,
          "rank": 184
        },
        "2602.11237v1": {
          "score": 5.919980572380866,
          "rank": 185
        },
        "2602.15957v1": {
          "score": 5.898005689546251,
          "rank": 186
        },
        "2602.15228v1": {
          "score": 5.893826328060716,
          "rank": 187
        },
        "2602.09489v1": {
          "score": 5.881287478430007,
          "rank": 188
        },
        "2602.16531v1": {
          "score": 5.845678616632363,
          "rank": 189
        },
        "2602.10286v1": {
          "score": 5.829151330632927,
          "rank": 190
        },
        "2602.10750v1": {
          "score": 5.804867913085687,
          "rank": 191
        },
        "2602.12694v2": {
          "score": 5.773370871997631,
          "rank": 192
        },
        "2602.09456v1": {
          "score": 5.764262102534083,
          "rank": 193
        },
        "2602.12808v1": {
          "score": 5.7304458386309065,
          "rank": 194
        },
        "2602.14561v1": {
          "score": 5.728516447159186,
          "rank": 195
        },
        "2602.10493v1": {
          "score": 5.712917997996765,
          "rank": 196
        },
        "2602.09543v1": {
          "score": 5.699557726587538,
          "rank": 197
        },
        "2602.09279v1": {
          "score": 5.681583937106419,
          "rank": 198
        },
        "2602.13072v1": {
          "score": 5.680222875853433,
          "rank": 199
        },
        "2602.14136v1": {
          "score": 5.674890578294053,
          "rank": 200
        },
        "2602.09865v1": {
          "score": 5.672619623021084,
          "rank": 201
        },
        "2602.15074v1": {
          "score": 5.649689180724959,
          "rank": 202
        },
        "2602.13847v2": {
          "score": 5.612095214459863,
          "rank": 203
        },
        "2602.12368v1": {
          "score": 5.611646832816856,
          "rank": 204
        },
        "2602.14548v1": {
          "score": 5.602394093730464,
          "rank": 205
        },
        "2602.13962v1": {
          "score": 5.589307402519537,
          "rank": 206
        },
        "2602.11487v1": {
          "score": 5.586083038779307,
          "rank": 207
        },
        "2602.11738v1": {
          "score": 5.577001914641964,
          "rank": 208
        },
        "2602.12379v1": {
          "score": 5.557651471627623,
          "rank": 209
        },
        "2602.14885v1": {
          "score": 5.555200618875806,
          "rank": 210
        },
        "2602.16481v1": {
          "score": 5.5441311942915465,
          "rank": 211
        },
        "2602.12465v1": {
          "score": 5.533831463939818,
          "rank": 212
        },
        "2602.12489v1": {
          "score": 5.511745902588977,
          "rank": 213
        },
        "2602.10214v1": {
          "score": 5.493939029991876,
          "rank": 214
        },
        "2602.10156v1": {
          "score": 5.490020953471043,
          "rank": 215
        },
        "2602.11281v1": {
          "score": 5.485595857459618,
          "rank": 216
        },
        "2602.14537v1": {
          "score": 5.479941140867247,
          "rank": 217
        },
        "2602.13575v1": {
          "score": 5.4727024884147735,
          "rank": 218
        },
        "2602.13363v1": {
          "score": 5.4707102302854915,
          "rank": 219
        },
        "2602.14853v1": {
          "score": 5.464897399867873,
          "rank": 220
        },
        "2602.13011v1": {
          "score": 5.453227272127539,
          "rank": 221
        },
        "2602.16209v1": {
          "score": 5.451761604273269,
          "rank": 222
        },
        "2602.14669v1": {
          "score": 5.437845459366779,
          "rank": 223
        },
        "2602.14029v1": {
          "score": 5.425956344078414,
          "rank": 224
        },
        "2602.09472v1": {
          "score": 5.423837410362634,
          "rank": 225
        },
        "2602.12508v1": {
          "score": 5.408106980763395,
          "rank": 226
        },
        "2602.11678v1": {
          "score": 5.39620098573286,
          "rank": 227
        },
        "2602.11320v2": {
          "score": 5.386821657935073,
          "rank": 228
        },
        "2602.14598v1": {
          "score": 5.3791393885397545,
          "rank": 229
        },
        "2602.10770v1": {
          "score": 5.362921594348548,
          "rank": 230
        },
        "2602.09914v1": {
          "score": 5.351088849386821,
          "rank": 231
        },
        "2602.11889v1": {
          "score": 5.342976990079692,
          "rank": 232
        },
        "2602.10471v1": {
          "score": 5.339661094832614,
          "rank": 233
        },
        "2602.09378v1": {
          "score": 5.300613694287685,
          "rank": 234
        },
        "2602.10320v1": {
          "score": 5.29073665770811,
          "rank": 235
        },
        "2602.14634v1": {
          "score": 5.261484299202822,
          "rank": 236
        },
        "2602.08980v1": {
          "score": 5.243984183738498,
          "rank": 237
        },
        "2602.15743v1": {
          "score": 5.240040106467039,
          "rank": 238
        },
        "2602.16318v1": {
          "score": 5.226009071524256,
          "rank": 239
        },
        "2602.16476v1": {
          "score": 5.212066086310914,
          "rank": 240
        },
        "2602.09597v1": {
          "score": 5.194580420143466,
          "rank": 241
        },
        "2602.14094v1": {
          "score": 5.187634649989189,
          "rank": 242
        },
        "2602.15370v1": {
          "score": 5.179080498176042,
          "rank": 243
        },
        "2602.10386v1": {
          "score": 5.1671297895483095,
          "rank": 244
        },
        "2602.09801v1": {
          "score": 5.155920037456906,
          "rank": 245
        },
        "2602.14960v1": {
          "score": 5.153478110381839,
          "rank": 246
        },
        "2602.13442v1": {
          "score": 5.132133434127816,
          "rank": 247
        },
        "2602.15992v1": {
          "score": 5.130459389741045,
          "rank": 248
        },
        "2602.12455v1": {
          "score": 5.128909411308635,
          "rank": 249
        },
        "2602.15676v1": {
          "score": 5.128754262912466,
          "rank": 250
        },
        "2602.15616v1": {
          "score": 5.125683732663658,
          "rank": 251
        },
        "2602.10173v1": {
          "score": 5.124345217483336,
          "rank": 252
        },
        "2602.09718v1": {
          "score": 5.121503213003873,
          "rank": 253
        },
        "2602.12657v1": {
          "score": 5.112831127488414,
          "rank": 254
        },
        "2602.14503v1": {
          "score": 5.08710529131879,
          "rank": 255
        },
        "2602.13017v1": {
          "score": 5.085286232165248,
          "rank": 256
        },
        "2602.16012v1": {
          "score": 5.081858866620072,
          "rank": 257
        },
        "2602.12438v1": {
          "score": 5.080832566017115,
          "rank": 258
        },
        "2602.16343v1": {
          "score": 5.075246957655857,
          "rank": 259
        },
        "2602.15704v1": {
          "score": 5.0691901951117515,
          "rank": 260
        },
        "2602.15360v1": {
          "score": 5.058696462673111,
          "rank": 261
        },
        "2602.15155v1": {
          "score": 5.037564480011732,
          "rank": 262
        },
        "2602.09009v1": {
          "score": 5.0254211274515255,
          "rank": 263
        },
        "2602.15749v1": {
          "score": 5.019414621368919,
          "rank": 264
        },
        "2602.14969v1": {
          "score": 5.017375271603752,
          "rank": 265
        },
        "2602.15458v1": {
          "score": 5.016984736266836,
          "rank": 266
        },
        "2602.15183v1": {
          "score": 5.008442470823024,
          "rank": 267
        },
        "2602.14397v1": {
          "score": 5.004047787427918,
          "rank": 268
        },
        "2602.09317v1": {
          "score": 5.002572499014676,
          "rank": 269
        },
        "2602.12954v1": {
          "score": 4.9991431825967965,
          "rank": 270
        },
        "2602.14086v1": {
          "score": 4.9941585420611085,
          "rank": 271
        },
        "2602.09133v1": {
          "score": 4.957262281680519,
          "rank": 272
        },
        "2602.12706v1": {
          "score": 4.931226538057585,
          "rank": 273
        },
        "2602.12244v1": {
          "score": 4.920358970709126,
          "rank": 274
        },
        "2602.16442v1": {
          "score": 4.919082770431057,
          "rank": 275
        },
        "2602.10244v1": {
          "score": 4.915102510272346,
          "rank": 276
        },
        "2602.10854v1": {
          "score": 4.9004067536752505,
          "rank": 277
        },
        "2602.15472v1": {
          "score": 4.899089369587947,
          "rank": 278
        },
        "2602.12300v1": {
          "score": 4.8967716586356005,
          "rank": 279
        },
        "2602.15423v1": {
          "score": 4.895528414667416,
          "rank": 280
        },
        "2602.12233v1": {
          "score": 4.88897992813967,
          "rank": 281
        },
        "2602.12502v1": {
          "score": 4.8742999595984955,
          "rank": 282
        },
        "2602.15104v1": {
          "score": 4.8682955444831,
          "rank": 283
        },
        "2602.11084v1": {
          "score": 4.847055477732986,
          "rank": 284
        },
        "2602.14047v1": {
          "score": 4.830058183021758,
          "rank": 285
        },
        "2602.12718v1": {
          "score": 4.827907992194465,
          "rank": 286
        },
        "2602.10832v1": {
          "score": 4.819241722125192,
          "rank": 287
        },
        "2602.16400v1": {
          "score": 4.817026312969584,
          "rank": 288
        },
        "2602.12907v1": {
          "score": 4.816283701237336,
          "rank": 289
        },
        "2602.11090v1": {
          "score": 4.796092547506694,
          "rank": 290
        },
        "2602.10608v1": {
          "score": 4.79103459085557,
          "rank": 291
        },
        "2602.15184v1": {
          "score": 4.78699852494942,
          "rank": 292
        },
        "2602.15756v1": {
          "score": 4.786574407817386,
          "rank": 293
        },
        "2602.10763v2": {
          "score": 4.78245994381365,
          "rank": 294
        },
        "2602.14793v1": {
          "score": 4.778928601802101,
          "rank": 295
        },
        "2602.13433v1": {
          "score": 4.771617242819667,
          "rank": 296
        },
        "2602.10910v1": {
          "score": 4.767766956203243,
          "rank": 297
        },
        "2602.14674v2": {
          "score": 4.751797507154659,
          "rank": 298
        },
        "2602.16551v1": {
          "score": 4.7469068785299395,
          "rank": 299
        },
        "2602.10031v1": {
          "score": 4.732555617997805,
          "rank": 300
        },
        "2602.12560v1": {
          "score": 4.729525466527229,
          "rank": 301
        },
        "2602.12798v1": {
          "score": 4.722369385617251,
          "rank": 302
        },
        "2602.15635v1": {
          "score": 4.705876919730662,
          "rank": 303
        },
        "2602.13866v1": {
          "score": 4.704266717726562,
          "rank": 304
        },
        "2602.10916v1": {
          "score": 4.701350993544943,
          "rank": 305
        },
        "2602.12236v1": {
          "score": 4.6870584017938635,
          "rank": 306
        },
        "2602.09966v1": {
          "score": 4.684504314174409,
          "rank": 307
        },
        "2602.09992v1": {
          "score": 4.681946443557584,
          "rank": 308
        },
        "2602.09462v1": {
          "score": 4.680231283711967,
          "rank": 309
        },
        "2602.11461v1": {
          "score": 4.674498699212071,
          "rank": 310
        },
        "2602.12406v1": {
          "score": 4.67062993388168,
          "rank": 311
        },
        "2602.16630v1": {
          "score": 4.669938485633499,
          "rank": 312
        },
        "2602.13121v1": {
          "score": 4.667937960621093,
          "rank": 313
        },
        "2602.10476v1": {
          "score": 4.662304465254412,
          "rank": 314
        },
        "2602.09288v1": {
          "score": 4.661333296595091,
          "rank": 315
        },
        "2602.16626v1": {
          "score": 4.658511046200147,
          "rank": 316
        },
        "2602.10552v1": {
          "score": 4.658107362309024,
          "rank": 317
        },
        "2602.16146v1": {
          "score": 4.658107362309024,
          "rank": 318
        },
        "2602.15264v1": {
          "score": 4.648505915954459,
          "rank": 319
        },
        "2602.16103v1": {
          "score": 4.645002264134136,
          "rank": 320
        },
        "2602.14975v1": {
          "score": 4.635794552588014,
          "rank": 321
        },
        "2602.15451v1": {
          "score": 4.6351225565767455,
          "rank": 322
        },
        "2602.09234v1": {
          "score": 4.634384713723733,
          "rank": 323
        },
        "2602.15499v1": {
          "score": 4.6141559409261665,
          "rank": 324
        },
        "2602.14855v1": {
          "score": 4.60667687024549,
          "rank": 325
        },
        "2602.11206v1": {
          "score": 4.6056933682282155,
          "rank": 326
        },
        "2602.16396v1": {
          "score": 4.6023699575913515,
          "rank": 327
        },
        "2602.14677v1": {
          "score": 4.58756331833208,
          "rank": 328
        },
        "2602.12635v1": {
          "score": 4.576531308876536,
          "rank": 329
        },
        "2602.13128v1": {
          "score": 4.565813469784647,
          "rank": 330
        },
        "2602.14567v1": {
          "score": 4.565482278988893,
          "rank": 331
        },
        "2602.12129v1": {
          "score": 4.565261704686949,
          "rank": 332
        },
        "2602.12712v1": {
          "score": 4.565137903822903,
          "rank": 333
        },
        "2602.11058v1": {
          "score": 4.558828044610376,
          "rank": 334
        },
        "2602.13910v1": {
          "score": 4.5585461546821024,
          "rank": 335
        },
        "2602.12589v1": {
          "score": 4.547255023178781,
          "rank": 336
        },
        "2602.12081v1": {
          "score": 4.537585176580763,
          "rank": 337
        },
        "2602.11490v1": {
          "score": 4.530103663807454,
          "rank": 338
        },
        "2602.14414v1": {
          "score": 4.523337929383725,
          "rank": 339
        },
        "2602.11801v1": {
          "score": 4.520668727143897,
          "rank": 340
        },
        "2602.12497v1": {
          "score": 4.519683281006305,
          "rank": 341
        },
        "2602.15118v1": {
          "score": 4.517707486865161,
          "rank": 342
        },
        "2602.12959v1": {
          "score": 4.51127582528682,
          "rank": 343
        },
        "2602.10303v1": {
          "score": 4.5099535297835525,
          "rank": 344
        },
        "2602.15758v1": {
          "score": 4.508279005967812,
          "rank": 345
        },
        "2602.10738v1": {
          "score": 4.502640365391961,
          "rank": 346
        },
        "2602.11025v1": {
          "score": 4.499179656254626,
          "rank": 347
        },
        "2602.10371v1": {
          "score": 4.498189155274414,
          "rank": 348
        },
        "2602.11135v1": {
          "score": 4.494025316879501,
          "rank": 349
        },
        "2602.14400v1": {
          "score": 4.487298433752934,
          "rank": 350
        },
        "2602.12980v1": {
          "score": 4.482682896823898,
          "rank": 351
        },
        "2602.16167v1": {
          "score": 4.473332232970095,
          "rank": 352
        },
        "2602.12009v1": {
          "score": 4.46290076931626,
          "rank": 353
        },
        "2602.15649v1": {
          "score": 4.462242283497362,
          "rank": 354
        },
        "2602.16471v1": {
          "score": 4.460409300965375,
          "rank": 355
        },
        "2602.14460v1": {
          "score": 4.459631029410116,
          "rank": 356
        },
        "2602.11467v1": {
          "score": 4.4490704995847095,
          "rank": 357
        },
        "2602.10489v1": {
          "score": 4.447986556413853,
          "rank": 358
        },
        "2602.09297v1": {
          "score": 4.446098365270117,
          "rank": 359
        },
        "2602.13874v1": {
          "score": 4.444087904347273,
          "rank": 360
        },
        "2602.12559v1": {
          "score": 4.443978892529564,
          "rank": 361
        },
        "2602.11841v1": {
          "score": 4.437635907646987,
          "rank": 362
        },
        "2602.11621v1": {
          "score": 4.433101966674716,
          "rank": 363
        },
        "2602.11583v1": {
          "score": 4.432874713592665,
          "rank": 364
        },
        "2602.14071v1": {
          "score": 4.430291712481798,
          "rank": 365
        },
        "2602.14729v1": {
          "score": 4.429127422952408,
          "rank": 366
        },
        "2602.14154v1": {
          "score": 4.428030847498195,
          "rank": 367
        },
        "2602.13890v1": {
          "score": 4.426564337305463,
          "rank": 368
        },
        "2602.09278v1": {
          "score": 4.423367405503446,
          "rank": 369
        },
        "2602.13811v1": {
          "score": 4.420795569796275,
          "rank": 370
        },
        "2602.09443v1": {
          "score": 4.418752550919582,
          "rank": 371
        },
        "2602.12998v1": {
          "score": 4.40565609395042,
          "rank": 372
        },
        "2602.10814v1": {
          "score": 4.40190141745935,
          "rank": 373
        },
        "2602.10607v1": {
          "score": 4.400840842085235,
          "rank": 374
        },
        "2602.16642v1": {
          "score": 4.390418544134667,
          "rank": 375
        },
        "2602.14099v1": {
          "score": 4.3813700075318,
          "rank": 376
        },
        "2602.14896v1": {
          "score": 4.376775620066941,
          "rank": 377
        },
        "2602.14486v1": {
          "score": 4.372904605026095,
          "rank": 378
        },
        "2602.12400v1": {
          "score": 4.367197348089498,
          "rank": 379
        },
        "2602.12267v1": {
          "score": 4.366115871948588,
          "rank": 380
        },
        "2602.15258v1": {
          "score": 4.364088998343881,
          "rank": 381
        },
        "2602.09419v1": {
          "score": 4.361298453446848,
          "rank": 382
        },
        "2602.12390v1": {
          "score": 4.35967795738109,
          "rank": 383
        },
        "2602.11747v1": {
          "score": 4.358025398529066,
          "rank": 384
        },
        "2602.09093v1": {
          "score": 4.3564312761333674,
          "rank": 385
        },
        "2602.16120v1": {
          "score": 4.355484394372941,
          "rank": 386
        },
        "2602.14126v1": {
          "score": 4.3468682333810245,
          "rank": 387
        },
        "2602.11772v1": {
          "score": 4.344686124585609,
          "rank": 388
        },
        "2602.16117v1": {
          "score": 4.343880833881181,
          "rank": 389
        },
        "2602.13414v1": {
          "score": 4.343238294884938,
          "rank": 390
        },
        "2602.11248v1": {
          "score": 4.334152649676096,
          "rank": 391
        },
        "2602.16015v1": {
          "score": 4.333893661038073,
          "rank": 392
        },
        "2602.09569v1": {
          "score": 4.333870562423472,
          "rank": 393
        },
        "2602.14881v1": {
          "score": 4.333841951911751,
          "rank": 394
        },
        "2602.14737v1": {
          "score": 4.33267401744579,
          "rank": 395
        },
        "2602.16177v1": {
          "score": 4.328299953913252,
          "rank": 396
        },
        "2602.13499v1": {
          "score": 4.327249556549249,
          "rank": 397
        },
        "2602.16656v1": {
          "score": 4.3271022690693774,
          "rank": 398
        },
        "2602.12982v1": {
          "score": 4.320366790113547,
          "rank": 399
        },
        "2602.09757v1": {
          "score": 4.318964087498586,
          "rank": 400
        }
      }
    }
  ]
}