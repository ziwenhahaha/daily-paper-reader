{
  "top_k": 200,
  "generated_at": "2026-01-10T17:27:03.255141+00:00",
  "papers": [
    {
      "id": "2601.05251v1",
      "title": "Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video",
      "abstract": "We propose Mesh4D, a feed-forward model for monocular 4D mesh reconstruction. Given a monocular video of a dynamic object, our model reconstructs the object's complete 3D shape and motion, represented as a deformation field. Our key contribution is a compact latent space that encodes the entire animation sequence in a single pass. This latent space is learned by an autoencoder that, during training, is guided by the skeletal structure of the training objects, providing strong priors on plausible deformations. Crucially, skeletal information is not required at inference time. The encoder employs spatio-temporal attention, yielding a more stable representation of the object's overall deformation. Building on this representation, we train a latent diffusion model that, conditioned on the input video and the mesh reconstructed from the first frame, predicts the full animation in one shot. We evaluate Mesh4D on reconstruction and novel view synthesis benchmarks, outperforming prior methods in recovering accurate 3D shape and deformation.",
      "authors": [
        "Zeren Jiang",
        "Chuanxia Zheng",
        "Iro Laina",
        "Diane Larlus",
        "Andrea Vedaldi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:56+00:00",
      "link": "https://arxiv.org/pdf/2601.05251v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05249v1",
      "title": "RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes",
      "abstract": "Nighttime color constancy remains a challenging problem in computational photography due to low-light noise and complex illumination conditions. We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. Our method begins with a statistical algorithm tailored for nighttime scenes, integrating salient gray pixel detection with novel illumination estimation. Building on this foundation, we develop the first deep reinforcement learning approach for color constancy that leverages the statistical algorithm as its core, mimicking professional AWB tuning experts by dynamically optimizing parameters for each image. To facilitate cross-sensor evaluation, we introduce the first multi-sensor nighttime dataset. Experiment results demonstrate that our method achieves superior generalization capability across low-light and well-illuminated images. Project page: https://ntuneillee.github.io/research/rl-awb/",
      "authors": [
        "Yuan-Kang Lee",
        "Kuan-Lin Chen",
        "Chia-Che Chang",
        "Yu-Lun Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:55+00:00",
      "link": "https://arxiv.org/pdf/2601.05249v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05250v1",
      "title": "QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer",
      "abstract": "Recently, Quantum Visual Fields (QVFs) have shown promising improvements in model compactness and convergence speed for learning the provided 2D or 3D signals. Meanwhile, novel-view synthesis has seen major advances with Neural Radiance Fields (NeRFs), where models learn a compact representation from 2D images to render 3D scenes, albeit at the cost of larger models and intensive training. In this work, we extend the approach of QVFs by introducing QNeRF, the first hybrid quantum-classical model designed for novel-view synthesis from 2D images. QNeRF leverages parameterised quantum circuits to encode spatial and view-dependent information via quantum superposition and entanglement, resulting in more compact models compared to the classical counterpart. We present two architectural variants. Full QNeRF maximally exploits all quantum amplitudes to enhance representational capabilities. In contrast, Dual-Branch QNeRF introduces a task-informed inductive bias by branching spatial and view-dependent quantum state preparations, drastically reducing the complexity of this operation and ensuring scalability and potential hardware compatibility. Our experiments demonstrate that -- when trained on images of moderate resolution -- QNeRF matches or outperforms classical NeRF baselines while using less than half the number of parameters. These results suggest that quantum machine learning can serve as a competitive alternative for continuous signal representation in mid-level tasks in computer vision, such as 3D representation learning from 2D observations.",
      "authors": [
        "Daniele Lizzio Bosco",
        "Shuteng Wang",
        "Giuseppe Serra",
        "Vladislav Golyanik"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:55+00:00",
      "link": "https://arxiv.org/pdf/2601.05250v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05248v1",
      "title": "LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model",
      "abstract": "Vision-Language-Action (VLA) models have recently demonstrated strong generalization capabilities in robotic manipulation. Some existing VLA approaches attempt to improve action accuracy by explicitly generating linguistic reasoning traces or future visual observations before action execution. However, explicit reasoning typically incurs non-negligible inference latency, which constrains the temporal resolution required for robotic manipulation. Moreover, such reasoning is confined to the linguistic space, imposing a representational bottleneck that struggles to faithfully capture ineffable physical attributes. To mitigate these limitations, we propose LaST$_0$, a framework that enables efficient reasoning before acting through a Latent Spatio-Temporal Chain-of-Thought (CoT), capturing fine-grained physical and robotic dynamics that are often difficult to verbalize. Specifically, we introduce a token-efficient latent CoT space that models future visual dynamics, 3D structural information, and robot proprioceptive states, and further extends these representations across time to enable temporally consistent implicit reasoning trajectories. Furthermore, LaST$_0$ adopts a dual-system architecture implemented via a Mixture-of-Transformers design, where a reasoning expert conducts low-frequency latent inference and an acting expert generates high-frequency actions conditioned on robotics-oriented latent representations. To facilitate coordination, LaST$_0$ is trained with heterogeneous operation frequencies, enabling adaptive switching between reasoning and action inference rates during deployment. Across ten simulated and six real-world manipulation tasks, LaST$_0$ improves mean success rates by 8% and 13% over prior VLA methods, respectively, while achieving substantially faster inference. Project website: https://sites.google.com/view/last0",
      "authors": [
        "Zhuoyang Liu",
        "Jiaming Liu",
        "Hao Chen",
        "Ziyu Guo",
        "Chengkai Hou",
        "Chenyang Gu",
        "Jiale Yu",
        "Xiangju Mi",
        "Renrui Zhang",
        "Zhengping Che",
        "Jian Tang",
        "Pheng-Ann Heng",
        "Shanghang Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 18:59:53+00:00",
      "link": "https://arxiv.org/pdf/2601.05248v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05247v1",
      "title": "Random Models and Guarded Logic",
      "abstract": "Building on ideas of Gurevich and Shelah for the Gödel Class, we present a new probabilistic proof of the finite model property for the Guarded Fragment of First-Order Logic. Our proof is conceptually simple and yields the optimal doubly-exponential upper bound on the size of minimal models. We precisely analyse the obtained bound, up to constant factors in the exponents, and construct sentences that enforce models of tightly matching size. The probabilistic approach adapts naturally to the Triguarded Fragment, an extension of the Guarded Fragment that also subsumes the Two-Variable Fragment. Finally, we derandomise the probabilistic proof by providing an explicit model construction which replaces randomness with deterministic hash functions.",
      "authors": [
        "Oskar Fiuk"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-01-08 18:59:50+00:00",
      "link": "https://arxiv.org/pdf/2601.05247v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05246v1",
      "title": "Pixel-Perfect Visual Geometry Estimation",
      "abstract": "Recovering clean and accurate geometry from images is essential for robotics and augmented reality. However, existing geometry foundation models still suffer severely from flying pixels and the loss of fine details. In this paper, we present pixel-perfect visual geometry models that can predict high-quality, flying-pixel-free point clouds by leveraging generative modeling in the pixel space. We first introduce Pixel-Perfect Depth (PPD), a monocular depth foundation model built upon pixel-space diffusion transformers (DiT). To address the high computational complexity associated with pixel-space diffusion, we propose two key designs: 1) Semantics-Prompted DiT, which incorporates semantic representations from vision foundation models to prompt the diffusion process, preserving global semantics while enhancing fine-grained visual details; and 2) Cascade DiT architecture that progressively increases the number of image tokens, improving both efficiency and accuracy. To further extend PPD to video (PPVD), we introduce a new Semantics-Consistent DiT, which extracts temporally consistent semantics from a multi-view geometry foundation model. We then perform reference-guided token propagation within the DiT to maintain temporal coherence with minimal computational and memory overhead. Our models achieve the best performance among all generative monocular and video depth estimation models and produce significantly cleaner point clouds than all other models.",
      "authors": [
        "Gangwei Xu",
        "Haotong Lin",
        "Hongcheng Luo",
        "Haiyang Sun",
        "Bing Wang",
        "Guang Chen",
        "Sida Peng",
        "Hangjun Ye",
        "Xin Yang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:49+00:00",
      "link": "https://arxiv.org/pdf/2601.05246v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05245v1",
      "title": "Optimal Lower Bounds for Online Multicalibration",
      "abstract": "We prove tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration.   In the general setting where group functions can depend on both context and the learner's predictions, we prove an $Ω(T^{2/3})$ lower bound on expected multicalibration error using just three disjoint binary groups. This matches the upper bounds of Noarov et al. (2025) up to logarithmic factors and exceeds the $O(T^{2/3-\\varepsilon})$ upper bound for marginal calibration (Dagan et al., 2025), thereby separating the two problems.   We then turn to lower bounds for the more difficult case of group functions that may depend on context but not on the learner's predictions. In this case, we establish an $\\widetildeΩ(T^{2/3})$ lower bound for online multicalibration via a $Θ(T)$-sized group family constructed using orthogonal function systems, again matching upper bounds up to logarithmic factors.",
      "authors": [
        "Natalie Collina",
        "Jiuyao Lu",
        "Georgy Noarov",
        "Aaron Roth"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.ST",
        "stat.ML"
      ],
      "published": "2026-01-08 18:59:32+00:00",
      "link": "https://arxiv.org/pdf/2601.05245v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05244v1",
      "title": "GREx: Generalized Referring Expression Segmentation, Comprehension, and Generation",
      "abstract": "Referring Expression Segmentation (RES) and Comprehension (REC) respectively segment and detect the object described by an expression, while Referring Expression Generation (REG) generates an expression for the selected object. Existing datasets and methods commonly support single-target expressions only, i.e., one expression refers to one object, not considering multi-target and no-target expressions. This greatly limits the real applications of REx (RES/REC/REG). This paper introduces three new benchmarks called Generalized Referring Expression Segmentation (GRES), Comprehension (GREC), and Generation (GREG), collectively denoted as GREx, which extend the classic REx to allow expressions to identify an arbitrary number of objects. We construct the first large-scale GREx dataset gRefCOCO that contains multi-target, no-target, and single-target expressions and their corresponding images with labeled targets. GREx and gRefCOCO are designed to be backward-compatible with REx, facilitating extensive experiments to study the performance gap of the existing REx methods on GREx tasks. One of the challenges of GRES/GREC is complex relationship modeling, for which we propose a baseline ReLA that adaptively divides the image into regions with sub-instance clues and explicitly models the region-region and region-language dependencies. The proposed ReLA achieves the state-of-the-art results on the both GRES and GREC tasks. The proposed gRefCOCO dataset and method are available at https://henghuiding.github.io/GREx.",
      "authors": [
        "Henghui Ding",
        "Chang Liu",
        "Shuting He",
        "Xudong Jiang",
        "Yu-Gang Jiang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:30+00:00",
      "link": "https://arxiv.org/pdf/2601.05244v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05243v1",
      "title": "Generate, Transfer, Adapt: Learning Functional Dexterous Grasping from a Single Human Demonstration",
      "abstract": "Functional grasping with dexterous robotic hands is a key capability for enabling tool use and complex manipulation, yet progress has been constrained by two persistent bottlenecks: the scarcity of large-scale datasets and the absence of integrated semantic and geometric reasoning in learned models. In this work, we present CorDex, a framework that robustly learns dexterous functional grasps of novel objects from synthetic data generated from just a single human demonstration. At the core of our approach is a correspondence-based data engine that generates diverse, high-quality training data in simulation. Based on the human demonstration, our data engine generates diverse object instances of the same category, transfers the expert grasp to the generated objects through correspondence estimation, and adapts the grasp through optimization. Building on the generated data, we introduce a multimodal prediction network that integrates visual and geometric information. By devising a local-global fusion module and an importance-aware sampling mechanism, we enable robust and computationally efficient prediction of functional dexterous grasps. Through extensive experiments across various object categories, we demonstrate that CorDex generalizes well to unseen object instances and significantly outperforms state-of-the-art baselines.",
      "authors": [
        "Xingyi He",
        "Adhitya Polavaram",
        "Yunhao Cao",
        "Om Deshmukh",
        "Tianrui Wang",
        "Xiaowei Zhou",
        "Kuan Fang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:30+00:00",
      "link": "https://arxiv.org/pdf/2601.05243v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05242v1",
      "title": "GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization",
      "abstract": "As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability. In this paper, we demonstrate that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, reducing the resolution of the training signal and resulting in suboptimal convergence and, in some cases, early training failure. We then introduce Group reward-Decoupled Normalization Policy Optimization (GDPO), a new policy optimization method to resolve these issues by decoupling the normalization of individual rewards, more faithfully preserving their relative differences and enabling more accurate multi-reward optimization, along with substantially improved training stability. We compare GDPO with GRPO across three tasks: tool calling, math reasoning, and coding reasoning, evaluating both correctness metrics (accuracy, bug ratio) and constraint adherence metrics (format, length). Across all settings, GDPO consistently outperforms GRPO, demonstrating its effectiveness and generalizability for multi-reward reinforcement learning optimization.",
      "authors": [
        "Shih-Yang Liu",
        "Xin Dong",
        "Ximing Lu",
        "Shizhe Diao",
        "Peter Belcak",
        "Mingjie Liu",
        "Min-Hung Chen",
        "Hongxu Yin",
        "Yu-Chiang Frank Wang",
        "Kwang-Ting Cheng",
        "Yejin Choi",
        "Jan Kautz",
        "Pavlo Molchanov"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 18:59:24+00:00",
      "link": "https://arxiv.org/pdf/2601.05242v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05241v1",
      "title": "RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation",
      "abstract": "The diversity, quantity, and quality of manipulation data are critical for training effective robot policies. However, due to hardware and physical setup constraints, collecting large-scale real-world manipulation data remains difficult to scale across diverse environments. Recent work uses text-prompt conditioned image diffusion models to augment manipulation data by altering the backgrounds and tabletop objects in the visual observations. However, these approaches often overlook the practical need for multi-view and temporally coherent observations required by state-of-the-art policy models. Further, text prompts alone cannot reliably specify the scene setup. To provide the diffusion model with explicit visual guidance, we introduce visual identity prompting, which supplies exemplar images as conditioning inputs to guide the generation of the desired scene setup. To this end, we also build a scalable pipeline to curate a visual identity pool from large robotics datasets. Using our augmented manipulation data to train downstream vision-language-action and visuomotor policy models yields consistent performance gains in both simulation and real-robot settings.",
      "authors": [
        "Boyang Wang",
        "Haoran Zhang",
        "Shujie Zhang",
        "Jinkun Hao",
        "Mingda Jia",
        "Qi Lv",
        "Yucheng Mao",
        "Zhaoyang Lyu",
        "Jia Zeng",
        "Xudong Xu",
        "Jiangmiao Pang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-08 18:59:22+00:00",
      "link": "https://arxiv.org/pdf/2601.05241v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05240v1",
      "title": "Robust Reasoning as a Symmetry-Protected Topological Phase",
      "abstract": "Large language models suffer from \"hallucinations\"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a \"Metric Phase,\" where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants. Empirically, we demonstrate a sharp topological phase transition: while Transformers and RNNs exhibit gapless decay, our Holonomic Network reveals a macroscopic \"mass gap,\" maintaining invariant fidelity below a critical noise threshold. Furthermore, in a variable-binding task on $S_{10}$ ($3.6 \\times 10^6$ states) representing symbolic manipulation, we demonstrate holonomic generalization: the topological model maintains perfect fidelity extrapolating $100\\times$ beyond training ($L=50 \\to 5000$), consistent with a theoretically indefinite causal horizon, whereas Transformers lose logical coherence. Ablation studies indicate this protection emerges strictly from non-Abelian gauge symmetry. This provides strong evidence for a new universality class for logical reasoning, linking causal stability to the topology of the semantic manifold.",
      "authors": [
        "Ilmo Sung"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "hep-th"
      ],
      "published": "2026-01-08 18:58:34+00:00",
      "link": "https://arxiv.org/pdf/2601.05240v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05239v1",
      "title": "Plenoptic Video Generation",
      "abstract": "Camera-controlled generative video re-rendering methods, such as ReCamMaster, have achieved remarkable progress. However, despite their success in single-view setting, these works often struggle to maintain consistency across multi-view scenarios. Ensuring spatio-temporal coherence in hallucinated regions remains challenging due to the inherent stochasticity of generative models. To address it, we introduce PlenopticDreamer, a framework that synchronizes generative hallucinations to maintain spatio-temporal memory. The core idea is to train a multi-in-single-out video-conditioned model in an autoregressive manner, aided by a camera-guided video retrieval strategy that adaptively selects salient videos from previous generations as conditional inputs. In addition, Our training incorporates progressive context-scaling to improve convergence, self-conditioning to enhance robustness against long-range visual degradation caused by error accumulation, and a long-video conditioning mechanism to support extended video generation. Extensive experiments on the Basic and Agibot benchmarks demonstrate that PlenopticDreamer achieves state-of-the-art video re-rendering, delivering superior view synchronization, high-fidelity visuals, accurate camera control, and diverse view transformations (e.g., third-person to third-person, and head-view to gripper-view in robotic manipulation). Project page: https://research.nvidia.com/labs/dir/plenopticdreamer/",
      "authors": [
        "Xiao Fu",
        "Shitao Tang",
        "Min Shi",
        "Xian Liu",
        "Jinwei Gu",
        "Ming-Yu Liu",
        "Dahua Lin",
        "Chen-Hsuan Lin"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:58:32+00:00",
      "link": "https://arxiv.org/pdf/2601.05239v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05237v1",
      "title": "ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos",
      "abstract": "Humans can effortlessly anticipate how objects might move or change through interaction--imagining a cup being lifted, a knife slicing, or a lid being closed. We aim to endow computational systems with a similar ability to predict plausible future object motions directly from passive visual observation. We introduce ObjectForesight, a 3D object-centric dynamics model that predicts future 6-DoF poses and trajectories of rigid objects from short egocentric video sequences. Unlike conventional world or dynamics models that operate in pixel or latent space, ObjectForesight represents the world explicitly in 3D at the object level, enabling geometrically grounded and temporally coherent predictions that capture object affordances and trajectories. To train such a model at scale, we leverage recent advances in segmentation, mesh reconstruction, and 3D pose estimation to curate a dataset of 2 million plus short clips with pseudo-ground-truth 3D object trajectories. Through extensive experiments, we show that ObjectForesight achieves significant gains in accuracy, geometric consistency, and generalization to unseen objects and scenes, establishing a scalable framework for learning physically grounded, object-centric dynamics models directly from observation. objectforesight.github.io",
      "authors": [
        "Rustin Soraki",
        "Homanga Bharadhwaj",
        "Ali Farhadi",
        "Roozbeh Mottaghi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:58:08+00:00",
      "link": "https://arxiv.org/pdf/2601.05237v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05232v1",
      "title": "Measuring and Fostering Peace through Machine Learning and Artificial Intelligence",
      "abstract": "We used machine learning and artificial intelligence: 1) to measure levels of peace in countries from news and social media and 2) to develop on-line tools that promote peace by helping users better understand their own media diet. For news media, we used neural networks to measure levels of peace from text embeddings of on-line news sources. The model, trained on one news media dataset also showed high accuracy when used to analyze a different news dataset. For social media, such as YouTube, we developed other models to measure levels of social dimensions important in peace using word level (GoEmotions) and context level (Large Language Model) methods. To promote peace, we note that 71% of people 20-40 years old daily view most of their news through short videos on social media. Content creators of these videos are biased towards creating videos with emotional activation, making you angry to engage you, to increase clicks. We developed and tested a Chrome extension, MirrorMirror, which provides real-time feedback to YouTube viewers about the peacefulness of the media they are watching. Our long term goal is for MirrorMirror to evolve into an open-source tool for content creators, journalists, researchers, platforms, and individual users to better understand the tone of their media creation and consumption and its effects on viewers. Moving beyond simple engagement metrics, we hope to encourage more respectful, nuanced, and informative communication.",
      "authors": [
        "P. Gilda",
        "P. Dungarwal",
        "A. Thongkham",
        "E. T. Ajayi",
        "S. Choudhary",
        "T. M. Terol",
        "C. Lam",
        "J. P. Araujo",
        "M. McFadyen-Mungalln",
        "L. S. Liebovitch",
        "P. T. Coleman",
        "H. West",
        "K. Sieck",
        "S. Carter"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "published": "2026-01-08 18:57:01+00:00",
      "link": "https://arxiv.org/pdf/2601.05232v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05230v1",
      "title": "Learning Latent Action World Models In The Wild",
      "abstract": "Agents capable of reasoning and planning in the real world require the ability of predicting the consequences of their actions. While world models possess this capability, they most often require action labels, that can be complex to obtain at scale. This motivates the learning of latent action models, that can learn an action space from videos alone. Our work addresses the problem of learning latent actions world models on in-the-wild videos, expanding the scope of existing works that focus on simple robotics simulations, video games, or manipulation data. While this allows us to capture richer actions, it also introduces challenges stemming from the video diversity, such as environmental noise, or the lack of a common embodiment across videos. To address some of the challenges, we discuss properties that actions should follow as well as relevant architectural choices and evaluations. We find that continuous, but constrained, latent actions are able to capture the complexity of actions from in-the-wild videos, something that the common vector quantization does not. We for example find that changes in the environment coming from agents, such as humans entering the room, can be transferred across videos. This highlights the capability of learning actions that are specific to in-the-wild videos. In the absence of a common embodiment across videos, we are mainly able to learn latent actions that become localized in space, relative to the camera. Nonetheless, we are able to train a controller that maps known actions to latent ones, allowing us to use latent actions as a universal interface and solve planning tasks with our world model with similar performance as action-conditioned baselines. Our analyses and experiments provide a step towards scaling latent action models to the real world.",
      "authors": [
        "Quentin Garrido",
        "Tushar Nagarajan",
        "Basile Terver",
        "Nicolas Ballas",
        "Yann LeCun",
        "Michael Rabbat"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-08 18:55:39+00:00",
      "link": "https://arxiv.org/pdf/2601.05230v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05227v1",
      "title": "Stochastic Deep Learning: A Probabilistic Framework for Modeling Uncertainty in Structured Temporal Data",
      "abstract": "I propose a novel framework that integrates stochastic differential equations (SDEs) with deep generative models to improve uncertainty quantification in machine learning applications involving structured and temporal data. This approach, termed Stochastic Latent Differential Inference (SLDI), embeds an Itô SDE in the latent space of a variational autoencoder, allowing for flexible, continuous-time modeling of uncertainty while preserving a principled mathematical foundation. The drift and diffusion terms of the SDE are parameterized by neural networks, enabling data-driven inference and generalizing classical time series models to handle irregular sampling and complex dynamic structure.   A central theoretical contribution is the co-parameterization of the adjoint state with a dedicated neural network, forming a coupled forward-backward system that captures not only latent evolution but also gradient dynamics. I introduce a pathwise-regularized adjoint loss and analyze variance-reduced gradient flows through the lens of stochastic calculus, offering new tools for improving training stability in deep latent SDEs. My paper unifies and extends variational inference, continuous-time generative modeling, and control-theoretic optimization, providing a rigorous foundation for future developments in stochastic probabilistic machine learning.",
      "authors": [
        "James Rice"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "econ.EM",
        "math.ST"
      ],
      "published": "2026-01-08 18:53:59+00:00",
      "link": "https://arxiv.org/pdf/2601.05227v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05225v1",
      "title": "Concurrent Balanced Augmented Trees",
      "abstract": "Augmentation makes search trees tremendously more versatile, allowing them to support efficient aggregation queries, order-statistic queries, and range queries in addition to insertion, deletion, and lookup. In this paper, we present the first lock-free augmented balanced search tree. Our algorithmic ideas build upon a recent augmented unbalanced search tree presented by Fatourou and Ruppert [DISC, 2024]. We implement both data structures, solving some memory reclamation challenges in the process, and provide an experimental performance analysis of them. We also present optimized versions of our balanced tree that use delegation to achieve better scalability and performance (by more than 2x in some workloads). Our experiments show that our augmented balanced tree is 2.2 to 30 times faster than the unbalanced augmented tree, and up to several orders of magnitude faster than unaugmented trees on 120 threads.",
      "authors": [
        "Evan Wrench",
        "Ajay Singh",
        "Younghun Roh",
        "Panagiota Fatourou",
        "Siddhartha Jayanti",
        "Eric Ruppert",
        "Yuanhao Wei"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-01-08 18:53:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05225v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05219v1",
      "title": "CAOS: Conformal Aggregation of One-Shot Predictors",
      "abstract": "One-shot prediction enables rapid adaptation of pretrained foundation models to new tasks using only one labeled example, but lacks principled uncertainty quantification. While conformal prediction provides finite-sample coverage guarantees, standard split conformal methods are inefficient in the one-shot setting due to data splitting and reliance on a single predictor. We propose Conformal Aggregation of One-Shot Predictors (CAOS), a conformal framework that adaptively aggregates multiple one-shot predictors and uses a leave-one-out calibration scheme to fully exploit scarce labeled data. Despite violating classical exchangeability assumptions, we prove that CAOS achieves valid marginal coverage using a monotonicity-based argument. Experiments on one-shot facial landmarking and RAFT text classification tasks show that CAOS produces substantially smaller prediction sets than split conformal baselines while maintaining reliable coverage.",
      "authors": [
        "Maja Waldron"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 18:44:21+00:00",
      "link": "https://arxiv.org/pdf/2601.05219v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05217v1",
      "title": "A complete characterization of testable hypotheses",
      "abstract": "We revisit a fundamental question in hypothesis testing: given two sets of probability measures $\\mathcal{P}$ and $\\mathcal{Q}$, when does a nontrivial (i.e.\\ strictly unbiased) test for $\\mathcal{P}$ against $\\mathcal{Q}$ exist? Le~Cam showed that, when $\\mathcal{P}$ and $\\mathcal{Q}$ have a common dominating measure, a test that has power exceeding its level by more than $\\varepsilon$ exists if and only if the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ are separated in total variation distance by more than $\\varepsilon$. The requirement of a dominating measure is frequently violated in nonparametric statistics. In a passing remark, Le~Cam described an approach to address more general scenarios, but he stopped short of stating a formal theorem. This work completes Le~Cam's program, by presenting a matching necessary and sufficient condition for testability: for the aforementioned theorem to hold without assumptions, one must take the closures of the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ in the space of bounded finitely additive measures. We provide simple elucidating examples, and elaborate on various subtle measure theoretic and topological points regarding compactness and achievability.",
      "authors": [
        "Martin Larsson",
        "Johannes Ruf",
        "Aaditya Ramdas"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.IT",
        "math.PR"
      ],
      "published": "2026-01-08 18:42:26+00:00",
      "link": "https://arxiv.org/pdf/2601.05217v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05215v1",
      "title": "MineNPC-Task: Task Suite for Memory-Aware Minecraft Agents",
      "abstract": "We present \\textsc{MineNPC-Task}, a user-authored benchmark and evaluation harness for testing memory-aware, mixed-initiative LLM agents in open-world \\emph{Minecraft}. Rather than relying on synthetic prompts, tasks are elicited from formative and summative co-play with expert players, normalized into parametric templates with explicit preconditions and dependency structure, and paired with machine-checkable validators under a bounded-knowledge policy that forbids out-of-world shortcuts. The harness captures plan/act/memory events-including plan previews, targeted clarifications, memory reads and writes, precondition checks, and repair attempts and reports outcomes relative to the total number of attempted subtasks, derived from in-world evidence.   As an initial snapshot, we instantiate the framework with GPT-4o and evaluate \\textbf{216} subtasks across \\textbf{8} experienced players. We observe recurring breakdown patterns in code execution, inventory/tool handling, referencing, and navigation, alongside recoveries supported by mixed-initiative clarifications and lightweight memory. Participants rated interaction quality and interface usability positively, while highlighting the need for stronger memory persistence across tasks. We release the complete task suite, validators, logs, and harness to support transparent, reproducible evaluation of future memory-aware embodied agents.",
      "authors": [
        "Tamil Sudaravan Mohan Doss",
        "Michael Xu",
        "Sudha Rao",
        "Andrew D. Wilson",
        "Balasaravanan Thoravi Kumaravel"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 18:39:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05215v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05214v1",
      "title": "Internal Representations as Indicators of Hallucinations in Agent Tool Selection",
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in tool calling and tool usage, but suffer from hallucinations where they choose incorrect tools, provide malformed parameters and exhibit 'tool bypass' behavior by performing simulations and generating outputs instead of invoking specialized tools or external systems. This undermines the reliability of LLM based agents in production systems as it leads to inconsistent results, and bypasses security and audit controls. Such hallucinations in agent tool selection require early detection and error handling. Unlike existing hallucination detection methods that require multiple forward passes or external validation, we present a computationally efficient framework that detects tool-calling hallucinations in real-time by leveraging LLMs' internal representations during the same forward pass used for generation. We evaluate this approach on reasoning tasks across multiple domains, demonstrating strong detection performance (up to 86.4\\% accuracy) while maintaining real-time inference capabilities with minimal computational overhead, particularly excelling at detecting parameter-level hallucinations and inappropriate tool selections, critical for reliable agent deployment.",
      "authors": [
        "Kait Healy",
        "Bharathi Srinivasan",
        "Visakh Madathil",
        "Jing Wu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 18:38:45+00:00",
      "link": "https://arxiv.org/pdf/2601.05214v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05212v1",
      "title": "FlowLet: Conditional 3D Brain MRI Synthesis using Wavelet Flow Matching",
      "abstract": "Brain Magnetic Resonance Imaging (MRI) plays a central role in studying neurological development, aging, and diseases. One key application is Brain Age Prediction (BAP), which estimates an individual's biological brain age from MRI data. Effective BAP models require large, diverse, and age-balanced datasets, whereas existing 3D MRI datasets are demographically skewed, limiting fairness and generalizability. Acquiring new data is costly and ethically constrained, motivating generative data augmentation. Current generative methods are often based on latent diffusion models, which operate in learned low dimensional latent spaces to address the memory demands of volumetric MRI data. However, these methods are typically slow at inference, may introduce artifacts due to latent compression, and are rarely conditioned on age, thereby affecting the BAP performance. In this work, we propose FlowLet, a conditional generative framework that synthesizes age-conditioned 3D MRIs by leveraging flow matching within an invertible 3D wavelet domain, helping to avoid reconstruction artifacts and reducing computational demands. Experiments show that FlowLet generates high-fidelity volumes with few sampling steps. Training BAP models with data generated by FlowLet improves performance for underrepresented age groups, and region-based analysis confirms preservation of anatomical structures.",
      "authors": [
        "Danilo Danese",
        "Angela Lombardi",
        "Matteo Attimonelli",
        "Giuseppe Fasano",
        "Tommaso Di Noia"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:36:29+00:00",
      "link": "https://arxiv.org/pdf/2601.05212v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05208v1",
      "title": "MoE3D: A Mixture-of-Experts Module for 3D Reconstruction",
      "abstract": "MoE3D is a mixture-of-experts module designed to sharpen depth boundaries and mitigate flying-point artifacts (highlighted in red) of existing feed-forward 3D reconstruction models (left side). MoE3D predicts multiple candidate depth maps and fuses them via dynamic weighting (visualized by MoE weights on the right side). When integrated with a pre-trained 3D reconstruction backbone such as VGGT, it substantially enhances reconstruction quality with minimal additional computational overhead. Best viewed digitally.",
      "authors": [
        "Zichen Wang",
        "Ang Cao",
        "Liam J. Wang",
        "Jeong Joon Park"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:33:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05208v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05205v1",
      "title": "EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI",
      "abstract": "Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.",
      "authors": [
        "Zain Iqbal",
        "Lorenzo Valerio"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.PF"
      ],
      "published": "2026-01-08 18:31:11+00:00",
      "link": "https://arxiv.org/pdf/2601.05205v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05202v1",
      "title": "Stock Market Price Prediction using Neural Prophet with Deep Neural Network",
      "abstract": "Stock market price prediction is a significant interdisciplinary research domain that depends at the intersection of finance, statistics, and economics. Forecasting Accurately predicting stock prices has always been a focal point for various researchers. However, existing statistical approaches for time-series prediction often fail to effectively forecast the probability range of future stock prices. Hence, to solve this problem, the Neural Prophet with a Deep Neural Network (NP-DNN) is proposed to predict stock market prices. The preprocessing technique used in this research is Z-score normalization, which normalizes stock price data by removing scale differences, making patterns easier to detect. Missing value imputation fills gaps in historical data, enhancing the models use of complete information for more accurate predictions. The Multi-Layer Perceptron (MLP) learns complex nonlinear relationships among stock market prices and extracts hidden patterns from the input data, thereby creating meaningful feature representations for better prediction accuracy. The proposed NP-DNN model achieved an accuracy of 99.21% compared with other approaches using the Fused Large Language Model. Keywords: deep neural network, forecasting stock prices, multi-layer perceptron, neural prophet, stock market price prediction.",
      "authors": [
        "Navin Chhibber",
        "Suneel Khemka",
        "Navneet Kumar Tyagi",
        "Rohit Tewari",
        "Bireswar Banerjee",
        "Piyush Ranjan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 18:24:22+00:00",
      "link": "https://arxiv.org/pdf/2601.05202v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05201v1",
      "title": "Mechanisms of Prompt-Induced Hallucination in Vision-Language Models",
      "abstract": "Large vision-language models (VLMs) are highly capable, yet often hallucinate by favoring textual prompts over visual evidence. We study this failure mode in a controlled object-counting setting, where the prompt overstates the number of objects in the image (e.g., asking a model to describe four waterlilies when only three are present). At low object counts, models often correct the overestimation, but as the number of objects increases, they increasingly conform to the prompt regardless of the discrepancy. Through mechanistic analysis of three VLMs, we identify a small set of attention heads whose ablation substantially reduces prompt-induced hallucinations (PIH) by at least 40% without additional training. Across models, PIH-heads mediate prompt copying in model-specific ways. We characterize these differences and show that PIH ablation increases correction toward visual evidence. Our findings offer insights into the internal mechanisms driving prompt-induced hallucinations, revealing model-specific differences in how these behaviors are implemented.",
      "authors": [
        "William Rudman",
        "Michal Golovanevsky",
        "Dana Arad",
        "Yonatan Belinkov",
        "Ritambhara Singh",
        "Carsten Eickhoff",
        "Kyle Mahowald"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 18:23:03+00:00",
      "link": "https://arxiv.org/pdf/2601.05201v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05200v1",
      "title": "Multivector Reranking in the Era of Strong First-Stage Retrievers",
      "abstract": "Learned multivector representations power modern search systems with strong retrieval effectiveness, but their real-world use is limited by the high cost of exhaustive token-level retrieval. Therefore, most systems adopt a \\emph{gather-and-refine} strategy, where a lightweight gather phase selects candidates for full scoring. However, this approach requires expensive searches over large token-level indexes and often misses the documents that would rank highest under full similarity. In this paper, we reproduce several state-of-the-art multivector retrieval methods on two publicly available datasets, providing a clear picture of the current multivector retrieval field and observing the inefficiency of token-level gathering. Building on top of that, we show that replacing the token-level gather phase with a single-vector document retriever -- specifically, a learned sparse retriever (LSR) -- produces a smaller and more semantically coherent candidate set. This recasts the gather-and-refine pipeline into the well-established two-stage retrieval architecture. As retrieval latency decreases, query encoding with two neural encoders becomes the dominant computational bottleneck. To mitigate this, we integrate recent inference-free LSR methods, demonstrating that they preserve the retrieval effectiveness of the dual-encoder pipeline while substantially reducing query encoding time. Finally, we investigate multiple reranking configurations that balance efficiency, memory, and effectiveness, and we introduce two optimization techniques that prune low-quality candidates early. Empirical results show that these techniques improve retrieval efficiency by up to 1.8$\\times$ with no loss in quality. Overall, our two-stage approach achieves over $24\\times$ speedup over the state-of-the-art multivector retrieval systems, while maintaining comparable or superior retrieval quality.",
      "authors": [
        "Silvio Martinico",
        "Franco Maria Nardini",
        "Cosimo Rulli",
        "Rossano Venturini"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-08 18:22:18+00:00",
      "link": "https://arxiv.org/pdf/2601.05200v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05199v1",
      "title": "Approximation theory for distant Bang calculus",
      "abstract": "Approximation semantics capture the observable behaviour of λ-terms, with Böhm Trees and Taylor Expansion standing as two central paradigms. Although conceptually different, these notions are related via the Commutation Theorem, which links the Taylor expansion of a term to that of its Böhm tree. These notions are well understood in Call-by-Name λ-calculus and have been more recently introduced in Call-by-Value settings. Since these two evaluation strategies traditionally require separate theories, a natural next step is to seek a unified setting for approximation semantics. The Bang-calculus offers exactly such a framework, subsuming both CbN and CbV through linear-logic translations while providing robust rewriting properties. However, its approximation semantics is yet to be fully developed. In this work, we develop the approximation semantics for dBang, the Bang-calculus with explicit substitutions and distant reductions. We define Böhm trees and Taylor expansion within dBang and establish their fundamental properties. Our results subsume and generalize Call-By-Name and Call-By-Value through their translations into Bang, offering a single framework that uniformly captures infinitary and resource-sensitive semantics across evaluation strategies.",
      "authors": [
        "Kostia Chardonnet",
        "Jules Chouquet",
        "Axel Kerinec"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-01-08 18:20:06+00:00",
      "link": "https://arxiv.org/pdf/2601.05199v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05195v1",
      "title": "Basis Number of Graphs Excluding Minors",
      "abstract": "The basis number of a graph $G$ is the minimum $k$ such that the cycle space of $G$ is generated by a family of cycles using each edge at most $k$ times. A classical result of Mac Lane states that planar graphs are exactly graphs with basis number at most 2, and more generally, graphs embedded on a fixed surface are known to have bounded basis number. Generalising this, we prove that graphs excluding a fixed minor $H$ have bounded basis number.   Our proof uses the Graph Minor Structure Theorem, which requires us to understand how basis number behaves in tree-decompositions. In particular, we prove that graphs of treewidth $k$ have basis number bounded by some function of $k$. We handle tree-decompositions using the proof framework developed by Bojańczyk and Pilipczuk in their proof of Courcelle's conjecture.   Combining our approach with independent results of Miraftab, Morin and Yuditsky (2025) on basis number and path-decompositions, one can moreover improve our upper bound to a polynomial one: there exists an absolute constant $c>0$ such that every $H$-minor free graph has basis number $O(|H|^c)$.",
      "authors": [
        "Colin Geniet",
        "Ugo Giocanti"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.DM"
      ],
      "published": "2026-01-08 18:18:10+00:00",
      "link": "https://arxiv.org/pdf/2601.05195v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05194v1",
      "title": "An interpretable data-driven approach to optimizing clinical fall risk assessment",
      "abstract": "In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.",
      "authors": [
        "Fardin Ganjkhanloo",
        "Emmett Springer",
        "Erik H. Hoyer",
        "Daniel L. Young",
        "Holley Farley",
        "Kimia Ghobadi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 18:17:31+00:00",
      "link": "https://arxiv.org/pdf/2601.05194v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05192v1",
      "title": "LELA: an LLM-based Entity Linking Approach with Zero-Shot Domain Adaptation",
      "abstract": "Entity linking (mapping ambiguous mentions in text to entities in a knowledge base) is a foundational step in tasks such as knowledge graph construction, question-answering, and information extraction. Our method, LELA, is a modular coarse-to-fine approach that leverages the capabilities of large language models (LLMs), and works with different target domains, knowledge bases and LLMs, without any fine-tuning phase. Our experiments across various entity linking settings show that LELA is highly competitive with fine-tuned approaches, and substantially outperforms the non-fine-tuned ones.",
      "authors": [
        "Samy Haffoudhi",
        "Fabian M. Suchanek",
        "Nils Holzenberger"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 18:15:34+00:00",
      "link": "https://arxiv.org/pdf/2601.05192v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05191v1",
      "title": "Cutting AI Research Costs: How Task-Aware Compression Makes Large Language Model Agents Affordable",
      "abstract": "When researchers deploy large language models for autonomous tasks like reviewing literature or generating hypotheses, the computational bills add up quickly. A single research session using a 70-billion parameter model can cost around $127 in cloud fees, putting these tools out of reach for many academic labs. We developed AgentCompress to tackle this problem head-on. The core idea came from a simple observation during our own work: writing a novel hypothesis clearly demands more from the model than reformatting a bibliography. Why should both tasks run at full precision? Our system uses a small neural network to gauge how hard each incoming task will be, based only on its opening words, then routes it to a suitably compressed model variant. The decision happens in under a millisecond. Testing across 500 research workflows in four scientific fields, we cut compute costs by 68.3% while keeping 96.2% of the original success rate. For labs watching their budgets, this could mean the difference between running experiments and sitting on the sidelines",
      "authors": [
        "Zuhair Ahmed Khan Taha",
        "Mohammed Mudassir Uddin",
        "Shahnawaz Alam"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 18:13:46+00:00",
      "link": "https://arxiv.org/pdf/2601.05191v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05187v1",
      "title": "SimuAgent: An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning",
      "abstract": "Large language models (LLMs) have revolutionized text-based code automation, but their potential in graph-oriented engineering workflows remains under-explored. We introduce SimuAgent, an LLM-powered modeling and simulation agent tailored for Simulink. SimuAgent replaces verbose XML with a concise, dictionary-style Python representation, dramatically cutting token counts, improving interpretability, and enabling fast, in-process simulation. A lightweight plan-execute architecture, trained in two stages, equips the agent with both low-level tool skills and high-level design reasoning. To tackle sparse rewards in long-horizon tasks, we propose Reflection-GRPO (ReGRPO), which augments Group Relative Policy Optimization (GRPO) with self-reflection traces that supply rich intermediate feedback, accelerating convergence and boosting robustness. Experiments on SimuBench, our newly released benchmark comprising 5300 multi-domain modeling tasks, show that a Qwen2.5-7B model fine-tuned with SimuAgent converges faster and achieves higher modeling accuracy than standard RL baselines, and even surpasses GPT-4o when evaluated with few-shot prompting on the same benchmark. Ablations confirm that the two-stage curriculum and abstract-reconstruct data augmentation further enhance generalization. SimuAgent trains and runs entirely on-premise with modest hardware, delivering a privacy-preserving, cost-effective solution for industrial model-driven engineering. SimuAgent bridges the gap between LLMs and graphical modeling environments, offering a practical solution for AI-assisted engineering design in industrial settings.",
      "authors": [
        "Yanchang Liang",
        "Xiaowei Zhao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 18:10:35+00:00",
      "link": "https://arxiv.org/pdf/2601.05187v1",
      "tags": [
        "keyword:RL",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05184v1",
      "title": "Observations and Remedies for Large Language Model Bias in Self-Consuming Performative Loop",
      "abstract": "The rapid advancement of large language models (LLMs) has led to growing interest in using synthetic data to train future models. However, this creates a self-consuming retraining loop, where models are trained on their own outputs and may cause performance drops and induce emerging biases. In real-world applications, previously deployed LLMs may influence the data they generate, leading to a dynamic system driven by user feedback. For example, if a model continues to underserve users from a group, less query data will be collected from this particular demographic of users. In this study, we introduce the concept of \\textbf{S}elf-\\textbf{C}onsuming \\textbf{P}erformative \\textbf{L}oop (\\textbf{SCPL}) and investigate the role of synthetic data in shaping bias during these dynamic iterative training processes under controlled performative feedback. This controlled setting is motivated by the inaccessibility of real-world user preference data from dynamic production systems, and enables us to isolate and analyze feedback-driven bias evolution in a principled manner. We focus on two types of loops, including the typical retraining setting and the incremental fine-tuning setting, which is largely underexplored. Through experiments on three real-world tasks, we find that the performative loop increases preference bias and decreases disparate bias. We design a reward-based rejection sampling strategy to mitigate the bias, moving towards more trustworthy self-improving systems.",
      "authors": [
        "Yaxuan Wang",
        "Zhongteng Cai",
        "Yujia Bao",
        "Xueru Zhang",
        "Yang Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 18:08:15+00:00",
      "link": "https://arxiv.org/pdf/2601.05184v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05181v1",
      "title": "Spacecube: A fast inverse hyperspectral georectification system",
      "abstract": "Hyperspectral cameras provide numerous advantages in terms of the utility of the data captured. They capture hundreds of data points per sample (pixel) instead of only the few of RGB or multispectral camera systems. Aerial systems sense such data remotely, but the data must be georectified to produce consistent images before analysis. We find the traditional direct georectification method to be slow, and it is prone to artifacts. To address its downsides, we propose Spacecube, a program that implements a complete hyperspectral georectification pipeline, including our own fast inverse georectification technique, using OpenGL graphics programming technologies. Spacecube operates substantially faster than real-time and eliminates pixel coverage artifacts. It facilitates high quality interactive viewing, data exploration, and export of final products. We release Spacecube's source code publicly for the community to use.",
      "authors": [
        "Thomas P. Watson",
        "Eddie L. Jacobs"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.GR"
      ],
      "published": "2026-01-08 18:04:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05181v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05180v1",
      "title": "The Adverse Effects of Omitting Records in Differential Privacy: How Sampling and Suppression Degrade the Privacy-Utility Tradeoff (Long Version)",
      "abstract": "Sampling is renowned for its privacy amplification in differential privacy (DP), and is often assumed to improve the utility of a DP mechanism by allowing a noise reduction. In this paper, we further show that this last assumption is flawed: When measuring utility at equal privacy levels, sampling as preprocessing consistently yields penalties due to utility loss from omitting records over all canonical DP mechanisms -- Laplace, Gaussian, exponential, and report noisy max -- as well as recent applications of sampling, such as clustering.   Extending this analysis, we investigate suppression as a generalized method of choosing, or omitting, records. Developing a theoretical analysis of this technique, we derive privacy bounds for arbitrary suppression strategies under unbounded approximate DP. We find that our tested suppression strategy also fails to improve the privacy-utility tradeoff. Surprisingly, uniform sampling emerges as one of the best suppression methods -- despite its still degrading effect. Our results call into question common preprocessing assumptions in DP practice.",
      "authors": [
        "Àlex Miranda-Pascual",
        "Javier Parra-Arnau",
        "Thorsten Strufe"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-08 18:03:57+00:00",
      "link": "https://arxiv.org/pdf/2601.05180v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05175v1",
      "title": "VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice",
      "abstract": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for multimodal large language models on video understanding tasks. However, its necessity and advantages over direct answering remain underexplored. In this paper, we first demonstrate that for RL-trained video models, direct answering often matches or even surpasses CoT performance, despite CoT producing step-by-step analyses at a higher computational cost. Motivated by this, we propose VideoAuto-R1, a video understanding framework that adopts a reason-when-necessary strategy. During training, our approach follows a Thinking Once, Answering Twice paradigm: the model first generates an initial answer, then performs reasoning, and finally outputs a reviewed answer. Both answers are supervised via verifiable rewards. During inference, the model uses the confidence score of the initial answer to determine whether to proceed with reasoning. Across video QA and grounding benchmarks, VideoAuto-R1 achieves state-of-the-art accuracy with significantly improved efficiency, reducing the average response length by ~3.3x, e.g., from 149 to just 44 tokens. Moreover, we observe a low rate of thinking-mode activation on perception-oriented tasks, but a higher rate on reasoning-intensive tasks. This suggests that explicit language-based reasoning is generally beneficial but not always necessary.",
      "authors": [
        "Shuming Liu",
        "Mingchen Zhuge",
        "Changsheng Zhao",
        "Jun Chen",
        "Lemeng Wu",
        "Zechun Liu",
        "Chenchen Zhu",
        "Zhipeng Cai",
        "Chong Zhou",
        "Haozhe Liu",
        "Ernie Chang",
        "Saksham Suri",
        "Hongyu Xu",
        "Qi Qian",
        "Wei Wen",
        "Balakrishnan Varadarajan",
        "Zhuang Liu",
        "Hu Xu",
        "Florian Bordes",
        "Raghuraman Krishnamoorthi",
        "Bernard Ghanem",
        "Vikas Chandra",
        "Yunyang Xiong"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:00:59+00:00",
      "link": "https://arxiv.org/pdf/2601.05175v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05174v1",
      "title": "FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts",
      "abstract": "Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes. FaST is underpinned by two key innovations. First, an adaptive graph agent attention mechanism is proposed to alleviate the computational burden inherent in conventional graph convolution and self-attention modules when applied to large-scale graphs. Second, we propose a new parallel MoE module that replaces traditional feed-forward networks with Gated Linear Units (GLUs), enabling an efficient and scalable parallel structure. Extensive experiments on real-world datasets demonstrate that FaST not only delivers superior long-horizon predictive accuracy but also achieves remarkable computational efficiency compared to state-of-the-art baselines. Our source code is available at: https://github.com/yijizhao/FaST.",
      "authors": [
        "Yiji Zhao",
        "Zihao Zhong",
        "Ao Wang",
        "Haomin Wen",
        "Ming Jin",
        "Yuxuan Liang",
        "Huaiyu Wan",
        "Hao Wu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 18:00:58+00:00",
      "link": "https://arxiv.org/pdf/2601.05174v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05173v1",
      "title": "Information-Theoretic Limits on Exact Subgraph Alignment Problem",
      "abstract": "The graph alignment problem aims to identify the vertex correspondence between two correlated graphs. Most existing studies focus on the scenario in which the two graphs share the same vertex set. However, in many real-world applications, such as computer vision, social network analysis, and bioinformatics, the task often involves locating a small graph pattern within a larger graph. Existing graph alignment algorithms and analysis cannot directly address these scenarios because they are not designed to identify the specific subset of vertices where the small graph pattern resides within the larger graph. Motivated by this limitation, we introduce the subgraph alignment problem, which seeks to recover both the vertex set and/or the vertex correspondence of a small graph pattern embedded in a larger graph. In the special case where the small graph pattern is an induced subgraph of the larger graph and both the vertex set and correspondence are to be recovered, the problem reduces to the subgraph isomorphism problem, which is NP-complete in the worst case. In this paper, we formally formulate the subgraph alignment problem by proposing the Erdos-Renyi subgraph pair model together with some appropriate recovery criterion. We then establish almost-tight information-theoretic results for the subgraph alignment problem and present some novel approaches for the analysis.",
      "authors": [
        "Chun Hei Michael Shiu",
        "Hei Victor Cheng",
        "Lele Wang"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-08 17:59:49+00:00",
      "link": "https://arxiv.org/pdf/2601.05173v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05172v1",
      "title": "CoV: Chain-of-View Prompting for Spatial Reasoning",
      "abstract": "Embodied question answering (EQA) in 3D environments often requires collecting context that is distributed across multiple viewpoints and partially occluded. However, most recent vision--language models (VLMs) are constrained to a fixed and finite set of input views, which limits their ability to acquire question-relevant context at inference time and hinders complex spatial reasoning. We propose Chain-of-View (CoV) prompting, a training-free, test-time reasoning framework that transforms a VLM into an active viewpoint reasoner through a coarse-to-fine exploration process. CoV first employs a View Selection agent to filter redundant frames and identify question-aligned anchor views. It then performs fine-grained view adjustment by interleaving iterative reasoning with discrete camera actions, obtaining new observations from the underlying 3D scene representation until sufficient context is gathered or a step budget is reached.   We evaluate CoV on OpenEQA across four mainstream VLMs and obtain an average +11.56\\% improvement in LLM-Match, with a maximum gain of +13.62\\% on Qwen3-VL-Flash. CoV further exhibits test-time scaling: increasing the minimum action budget yields an additional +2.51\\% average improvement, peaking at +3.73\\% on Gemini-2.5-Flash. On ScanQA and SQA3D, CoV delivers strong performance (e.g., 116 CIDEr / 31.9 EM@1 on ScanQA and 51.1 EM@1 on SQA3D). Overall, these results suggest that question-aligned view selection coupled with open-view search is an effective, model-agnostic strategy for improving spatial reasoning in 3D EQA without additional training.",
      "authors": [
        "Haoyu Zhao",
        "Akide Liu",
        "Zeyu Zhang",
        "Weijie Wang",
        "Feng Chen",
        "Ruihan Zhu",
        "Gholamreza Haffari",
        "Bohan Zhuang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 17:59:42+00:00",
      "link": "https://arxiv.org/pdf/2601.05172v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05171v1",
      "title": "Inside Out: Evolving User-Centric Core Memory Trees for Long-Term Personalized Dialogue Systems",
      "abstract": "Existing long-term personalized dialogue systems struggle to reconcile unbounded interaction streams with finite context constraints, often succumbing to memory noise accumulation, reasoning degradation, and persona inconsistency. To address these challenges, this paper proposes Inside Out, a framework that utilizes a globally maintained PersonaTree as the carrier of long-term user profiling. By constraining the trunk with an initial schema and updating the branches and leaves, PersonaTree enables controllable growth, achieving memory compression while preserving consistency. Moreover, we train a lightweight MemListener via reinforcement learning with process-based rewards to produce structured, executable, and interpretable {ADD, UPDATE, DELETE, NO_OP} operations, thereby supporting the dynamic evolution of the personalized tree. During response generation, PersonaTree is directly leveraged to enhance outputs in latency-sensitive scenarios; when users require more details, the agentic mode is triggered to introduce details on-demand under the constraints of the PersonaTree. Experiments show that PersonaTree outperforms full-text concatenation and various personalized memory systems in suppressing contextual noise and maintaining persona consistency. Notably, the small MemListener model achieves memory-operation decision performance comparable to, or even surpassing, powerful reasoning models such as DeepSeek-R1-0528 and Gemini-3-Pro.",
      "authors": [
        "Jihao Zhao",
        "Ding Chen",
        "Zhaoxin Fan",
        "Kerun Xu",
        "Mengting Hu",
        "Bo Tang",
        "Feiyu Xiong",
        "Zhiyu li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 17:59:11+00:00",
      "link": "https://arxiv.org/pdf/2601.05171v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05170v1",
      "title": "Reverse-engineering NLI: A study of the meta-inferential properties of Natural Language Inference",
      "abstract": "Natural Language Inference (NLI) has been an important task for evaluating language models for Natural Language Understanding, but the logical properties of the task are poorly understood and often mischaracterized. Understanding the notion of inference captured by NLI is key to interpreting model performance on the task. In this paper we formulate three possible readings of the NLI label set and perform a comprehensive analysis of the meta-inferential properties they entail. Focusing on the SNLI dataset, we exploit (1) NLI items with shared premises and (2) items generated by LLMs to evaluate models trained on SNLI for meta-inferential consistency and derive insights into which reading of the logical relations is encoded by the dataset.",
      "authors": [
        "Rasmus Blanck",
        "Bill Noble",
        "Stergios Chatzikyriakidis"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 17:58:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05170v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05167v1",
      "title": "RelayLLM: Efficient Reasoning via Collaborative Decoding",
      "abstract": "Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding. Unlike routers, RelayLLM empowers the SLM to act as an active controller that dynamically invokes the LLM only for critical tokens via a special command, effectively \"relaying\" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that RelayLLM achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the LLM for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.",
      "authors": [
        "Chengsong Huang",
        "Tong Zheng",
        "Langlin Huang",
        "Jinyuan Li",
        "Haolin Liu",
        "Jiaxin Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 17:56:16+00:00",
      "link": "https://arxiv.org/pdf/2601.05167v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05166v1",
      "title": "Inapproximability of Counting Permutation Patterns",
      "abstract": "Detecting and counting copies of permutation patterns are fundamental algorithmic problems, with applications in the analysis of rankings, nonparametric statistics, and property testing tasks such as independence and quasirandomness testing. From an algorithmic perspective, there is a sharp difference in complexity between detecting and counting the copies of a given length-$k$ pattern in a length-$n$ permutation. The former admits a $2^{\\mathcal{O}(k^2)} \\cdot n$ time algorithm (Guillemot and Marx, 2014) while the latter cannot be solved in time $f(k)\\cdot n^{o(k/\\log k)}$ unless the Exponential Time Hypothesis (ETH) fails (Berendsohn, Kozma, and Marx, 2021). In fact already for patterns of length 4, exact counting is unlikely to admit near-linear time algorithms under standard fine-grained complexity assumptions (Dudek and Gawrychowski, 2020).   Recently, Ben-Eliezer, Mitrović and Sristava (2026) showed that for patterns of length up to 5, a $(1+\\varepsilon)$-approximation of the pattern count can be computed in near-linear time, yielding a separation between exact and approximate counting for small patterns, and conjectured that approximate counting is asymptotically easier than exact counting in general. We strongly refute their conjecture by showing that, under ETH, no algorithm running in time $f(k)\\cdot n^{o(k/\\log k)}$ can approximate the number of copies of a length-$k$ pattern within a multiplicative factor $n^{(1/2-\\varepsilon)k}$. The lower bound on runtime matches the conditional lower bound for exact pattern counting, and the obtained bound on the multiplicative error factor is essentially tight, as an $n^{k/2}$-approximation can be computed in $2^{\\mathcal{O}(k^2)}\\cdot n$ time using an algorithm for pattern detection.",
      "authors": [
        "Michal Opler"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-01-08 17:55:57+00:00",
      "link": "https://arxiv.org/pdf/2601.05166v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05165v1",
      "title": "Fundamental Tradeoffs for ISAC Multiple Access in Finite-Blocklength Regime",
      "abstract": "This paper investigates the fundamental communication--sensing tradeoffs of uplink dual-functional integrated sensing and communication (ISAC) multiple access under finite blocklength (FBL) constraints. Unlike conventional asymptotic analyses, we explicitly account for the limitations under FBL constraints imposed by short packets and low-latency transmission. By examining the unbiased channel state sensing estimator, we establish a geometric decomposition of the sensing error, indicating that it is jointly determined by the signal-to-noise ratio and the correlation structure of the information codebook. This insight reveals how cross-correlation among active users in the codebook geometry fundamentally constrains dual-functional ISAC performance. Consequently, we derive achievability and converse bounds that characterize the tradeoff between communication code rate and sensing accuracy in the FBL regime, with the converse further bounded by Shannon capacity. Moreover, by treating channel state sensing as a high-level sensing objective, a universal Cramér--Rao bound is derived to link channel estimation accuracy to practical sensing parameters. Examples of parameter sensing are also provided based on 3GPP standard. Numerical results validate the theoretical analysis and demonstrate the impact of blocklength, antenna dimensions, and sensing requirements.",
      "authors": [
        "Zhentian Zhang",
        "Christos Masouros",
        "Kai-Kit Wong",
        "Jian Dang",
        "Zaichen Zhang",
        "Kaitao Meng",
        "Farshad Rostami Ghadi",
        "Mohammad Javad Ahmadi"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-08 17:55:55+00:00",
      "link": "https://arxiv.org/pdf/2601.05165v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05163v1",
      "title": "DocDancer: Towards Agentic Document-Grounded Information Seeking",
      "abstract": "Document Question Answering (DocQA) focuses on answering questions grounded in given documents, yet existing DocQA agents lack effective tool utilization and largely rely on closed-source models. In this work, we introduce DocDancer, an end-to-end trained open-source Doc agent. We formulate DocQA as an information-seeking problem and propose a tool-driven agent framework that explicitly models document exploration and comprehension. To enable end-to-end training of such agents, we introduce an Exploration-then-Synthesis data synthesis pipeline that addresses the scarcity of high-quality training data for DocQA. Training on the synthesized data, the trained models on two long-context document understanding benchmarks, MMLongBench-Doc and DocBench, show their effectiveness. Further analysis provides valuable insights for the agentic tool design and synthetic data.",
      "authors": [
        "Qintong Zhang",
        "Xinjie Lv",
        "Jialong Wu",
        "Baixuan Li",
        "Zhengwei Tao",
        "Guochen Yan",
        "Huanyao Zhang",
        "Bin Wang",
        "Jiahao Xu",
        "Haitao Mi",
        "Wentao Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 17:54:32+00:00",
      "link": "https://arxiv.org/pdf/2601.05163v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05162v1",
      "title": "GenAI-DrawIO-Creator: A Framework for Automated Diagram Generation",
      "abstract": "Diagrams are crucial for communicating complex information, yet creating and modifying them remains a labor-intensive task. We present GenAI-DrawIO-Creator, a novel framework that leverages Large Language Models (LLMs) to automate diagram generation and manipulation in the structured XML format used by draw.io. Our system integrates Claude 3.7 to reason about structured visual data and produce valid diagram representations. Key contributions include a high-level system design enabling real-time diagram updates, specialized prompt engineering and error-checking to ensure well-formed XML outputs. We demonstrate a working prototype capable of generating accurate diagrams (such as network architectures and flowcharts) from natural language or code, and even replicating diagrams from images. Simulated evaluations show that our approach significantly reduces diagram creation time and produces outputs with high structural fidelity. Our results highlight the promise of Claude 3.7 in handling structured visual reasoning tasks and lay the groundwork for future research in AI-assisted diagramming applications.",
      "authors": [
        "Jinze Yu",
        "Dayuan Jiang"
      ],
      "primary_category": "cs.GR",
      "categories": [
        "cs.GR",
        "cs.CV"
      ],
      "published": "2026-01-08 17:51:35+00:00",
      "link": "https://arxiv.org/pdf/2601.05162v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05159v1",
      "title": "Vision-Language Introspection: Mitigating Overconfident Hallucinations in MLLMs via Interpretable Bi-Causal Steering",
      "abstract": "Object hallucination critically undermines the reliability of Multimodal Large Language Models, often stemming from a fundamental failure in cognitive introspection, where models blindly trust linguistic priors over specific visual evidence. Existing mitigations remain limited: contrastive decoding approaches operate superficially without rectifying internal semantic misalignments, while current latent steering methods rely on static vectors that lack instance-specific precision. We introduce Vision-Language Introspection (VLI), a training-free inference framework that simulates a metacognitive self-correction process. VLI first performs Attributive Introspection to diagnose hallucination risks via probabilistic conflict detection and localize the causal visual anchors. It then employs Interpretable Bi-Causal Steering to actively modulate the inference process, dynamically isolating visual evidence from background noise while neutralizing blind confidence through adaptive calibration. VLI achieves state-of-the-art performance on advanced models, reducing object hallucination rates by 12.67% on MMHal-Bench and improving accuracy by 5.8% on POPE.",
      "authors": [
        "Shuliang Liu",
        "Songbo Yang",
        "Dong Fang",
        "Sihang Jia",
        "Yuqi Tang",
        "Lingfeng Su",
        "Ruoshui Peng",
        "Yibo Yan",
        "Xin Zou",
        "Xuming Hu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 17:49:13+00:00",
      "link": "https://arxiv.org/pdf/2601.05159v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05157v1",
      "title": "Learning Mixture Models via Efficient High-dimensional Sparse Fourier Transforms",
      "abstract": "In this work, we give a ${\\rm poly}(d,k)$ time and sample algorithm for efficiently learning the parameters of a mixture of $k$ spherical distributions in $d$ dimensions. Unlike all previous methods, our techniques apply to heavy-tailed distributions and include examples that do not even have finite covariances. Our method succeeds whenever the cluster distributions have a characteristic function with sufficiently heavy tails. Such distributions include the Laplace distribution but crucially exclude Gaussians.   All previous methods for learning mixture models relied implicitly or explicitly on the low-degree moments. Even for the case of Laplace distributions, we prove that any such algorithm must use super-polynomially many samples. Our method thus adds to the short list of techniques that bypass the limitations of the method of moments.   Somewhat surprisingly, our algorithm does not require any minimum separation between the cluster means. This is in stark contrast to spherical Gaussian mixtures where a minimum $\\ell_2$-separation is provably necessary even information-theoretically [Regev and Vijayaraghavan '17]. Our methods compose well with existing techniques and allow obtaining ''best of both worlds\" guarantees for mixtures where every component either has a heavy-tailed characteristic function or has a sub-Gaussian tail with a light-tailed characteristic function.   Our algorithm is based on a new approach to learning mixture models via efficient high-dimensional sparse Fourier transforms. We believe that this method will find more applications to statistical estimation. As an example, we give an algorithm for consistent robust mean estimation against noise-oblivious adversaries, a model practically motivated by the literature on multiple hypothesis testing. It was formally proposed in a recent Master's thesis by one of the authors, and has already inspired follow-up works.",
      "authors": [
        "Alkis Kalavasis",
        "Pravesh K. Kothari",
        "Shuchen Li",
        "Manolis Zampetakis"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-08 17:47:58+00:00",
      "link": "https://arxiv.org/pdf/2601.05157v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05152v1",
      "title": "Safe Continual Reinforcement Learning Methods for Nonstationary Environments. Towards a Survey of the State of the Art",
      "abstract": "This work provides a state-of-the-art survey of continual safe online reinforcement learning (COSRL) methods. We discuss theoretical aspects, challenges, and open questions in building continual online safe reinforcement learning algorithms. We provide the taxonomy and the details of continual online safe reinforcement learning methods based on the type of safe learning mechanism that takes adaptation to nonstationarity into account. We categorize safety constraints formulation for online reinforcement learning algorithms, and finally, we discuss prospects for creating reliable, safe online learning algorithms.   Keywords: safe RL in nonstationary environments, safe continual reinforcement learning under nonstationarity, HM-MDP, NSMDP, POMDP, safe POMDP, constraints for continual learning, safe continual reinforcement learning review, safe continual reinforcement learning survey, safe continual reinforcement learning, safe online learning under distribution shift, safe continual online adaptation, safe reinforcement learning, safe exploration, safe adaptation, constrained Markov decision processes, safe reinforcement learning, partially observable Markov decision process, safe reinforcement learning and hidden Markov decision processes, Safe Online Reinforcement Learning, safe online reinforcement learning, safe online reinforcement learning, safe meta-learning, safe meta-reinforcement learning, safe context-based reinforcement learning, formulating safety constraints for continual learning",
      "authors": [
        "Timofey Tomashevskiy"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 17:42:56+00:00",
      "link": "https://arxiv.org/pdf/2601.05152v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05151v1",
      "title": "ROOFS: RObust biOmarker Feature Selection",
      "abstract": "Feature selection (FS) is essential for biomarker discovery and in the analysis of biomedical datasets. However, challenges such as high-dimensional feature space, low sample size, multicollinearity, and missing values make FS non-trivial. Moreover, FS performances vary across datasets and predictive tasks. We propose roofs, a Python package available at https://gitlab.inria.fr/compo/roofs, designed to help researchers in the choice of FS method adapted to their problem. Roofs benchmarks multiple FS methods on the user's data and generates reports that summarize a comprehensive set of evaluation metrics, including downstream predictive performance estimated using optimism correction, stability, reliability of individual features, and true positive and false positive rates assessed on semi-synthetic data with a simulated outcome. We demonstrate the utility of roofs on data from the PIONeeR clinical trial, aimed at identifying predictors of resistance to anti-PD-(L)1 immunotherapy in lung cancer. The PIONeeR dataset contained 374 multi-source blood and tumor biomarkers from 435 patients. A reduced subset of 214 features was obtained through iterative variance inflation factor pre-filtering. Of the 34 FS methods gathered in roofs, we evaluated 23 in combination with 11 classifiers (253 models in total) and identified a filter based on the union of Benjamini-Hochberg false discovery rate-adjusted p-values from t-test and logistic regression as the optimal approach, outperforming other methods including the widely used LASSO. We conclude that comprehensive benchmarking with roofs has the potential to improve the robustness and reproducibility of FS discoveries and increase the translational value of clinical models.",
      "authors": [
        "Anastasiia Bakhmach",
        "Paul Dufossé",
        "Andrea Vaglio",
        "Florence Monville",
        "Laurent Greillier",
        "Fabrice Barlési",
        "Sébastien Benzekry"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-08 17:41:07+00:00",
      "link": "https://arxiv.org/pdf/2601.05151v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05150v1",
      "title": "$PC^2$: Politically Controversial Content Generation via Jailbreaking Attacks on GPT-based Text-to-Image Models",
      "abstract": "The rapid evolution of text-to-image (T2I) models has enabled high-fidelity visual synthesis on a global scale. However, these advancements have introduced significant security risks, particularly regarding the generation of harmful content. Politically harmful content, such as fabricated depictions of public figures, poses severe threats when weaponized for fake news or propaganda. Despite its criticality, the robustness of current T2I safety filters against such politically motivated adversarial prompting remains underexplored. In response, we propose $PC^2$, the first black-box political jailbreaking framework for T2I models. It exploits a novel vulnerability where safety filters evaluate political sensitivity based on linguistic context. $PC^2$ operates through: (1) Identity-Preserving Descriptive Mapping to obfuscate sensitive keywords into neutral descriptions, and (2) Geopolitically Distal Translation to map these descriptions into fragmented, low-sensitivity languages. This strategy prevents filters from constructing toxic relationships between political entities within prompts, effectively bypassing detection. We construct a benchmark of 240 politically sensitive prompts involving 36 public figures. Evaluation on commercial T2I models, specifically GPT-series, shows that while all original prompts are blocked, $PC^2$ achieves attack success rates of up to 86%.",
      "authors": [
        "Wonwoo Choi",
        "Minjae Seo",
        "Minkyoo Song",
        "Hwanjo Heo",
        "Seungwon Shin",
        "Myoungsung You"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-08 17:40:50+00:00",
      "link": "https://arxiv.org/pdf/2601.05150v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05149v1",
      "title": "Multi-Scale Local Speculative Decoding for Image Generation",
      "abstract": "Autoregressive (AR) models have achieved remarkable success in image synthesis, yet their sequential nature imposes significant latency constraints. Speculative Decoding offers a promising avenue for acceleration, but existing approaches are limited by token-level ambiguity and lack of spatial awareness. In this work, we introduce Multi-Scale Local Speculative Decoding (MuLo-SD), a novel framework that combines multi-resolution drafting with spatially informed verification to accelerate AR image generation. Our method leverages a low-resolution drafter paired with learned up-samplers to propose candidate image tokens, which are then verified in parallel by a high-resolution target model. Crucially, we incorporate a local rejection and resampling mechanism, enabling efficient correction of draft errors by focusing on spatial neighborhoods rather than raster-scan resampling after the first rejection. We demonstrate that MuLo-SD achieves substantial speedups - up to $\\mathbf{1.7\\times}$ - outperforming strong speculative decoding baselines such as EAGLE-2 and LANTERN in terms of acceleration, while maintaining comparable semantic alignment and perceptual quality. These results are validated using GenEval, DPG-Bench, and FID/HPSv2 on the MS-COCO 5k validation split. Extensive ablations highlight the impact of up-sampling design, probability pooling, and local rejection and resampling with neighborhood expansion. Our approach sets a new state-of-the-art in speculative decoding for image synthesis, bridging the gap between efficiency and fidelity.",
      "authors": [
        "Elia Peruzzo",
        "Guillaume Sautière",
        "Amirhossein Habibian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 17:39:35+00:00",
      "link": "https://arxiv.org/pdf/2601.05149v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05148v1",
      "title": "Atlas 2 -- Foundation models for clinical deployment",
      "abstract": "Pathology foundation models substantially advanced the possibilities in computational pathology -- yet tradeoffs in terms of performance, robustness, and computational requirements remained, which limited their clinical deployment. In this report, we present Atlas 2, Atlas 2-B, and Atlas 2-S, three pathology vision foundation models which bridge these shortcomings by showing state-of-the-art performance in prediction performance, robustness, and resource efficiency in a comprehensive evaluation across eighty public benchmarks. Our models were trained on the largest pathology foundation model dataset to date comprising 5.5 million histopathology whole slide images, collected from three medical institutions Charité - Universtätsmedizin Berlin, LMU Munich, and Mayo Clinic.",
      "authors": [
        "Maximilian Alber",
        "Timo Milbich",
        "Alexandra Carpen-Amarie",
        "Stephan Tietz",
        "Jonas Dippel",
        "Lukas Muttenthaler",
        "Beatriz Perez Cancer",
        "Alessandro Benetti",
        "Panos Korfiatis",
        "Elias Eulig",
        "Jérôme Lüscher",
        "Jiasen Wu",
        "Sayed Abid Hashimi",
        "Gabriel Dernbach",
        "Simon Schallenberg",
        "Neelay Shah",
        "Moritz Krügener",
        "Aniruddh Jammoria",
        "Jake Matras",
        "Patrick Duffy",
        "Matt Redlon",
        "Philipp Jurmeister",
        "David Horst",
        "Lukas Ruff",
        "Klaus-Robert Müller",
        "Frederick Klauschen",
        "Andrew Norgan"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 17:37:00+00:00",
      "link": "https://arxiv.org/pdf/2601.05148v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05144v1",
      "title": "Distilling the Thought, Watermarking the Answer: A Principle Semantic Guided Watermark for Large Reasoning Models",
      "abstract": "Reasoning Large Language Models (RLLMs) excelling in complex tasks present unique challenges for digital watermarking, as existing methods often disrupt logical coherence or incur high computational costs. Token-based watermarking techniques can corrupt the reasoning flow by applying pseudo-random biases, while semantic-aware approaches improve quality but introduce significant latency or require auxiliary models. This paper introduces ReasonMark, a novel watermarking framework specifically designed for reasoning-intensive LLMs. Our approach decouples generation into an undisturbed Thinking Phase and a watermarked Answering Phase. We propose a Criticality Score to identify semantically pivotal tokens from the reasoning trace, which are distilled into a Principal Semantic Vector (PSV). The PSV then guides a semantically-adaptive mechanism that modulates watermark strength based on token-PSV alignment, ensuring robustness without compromising logical integrity. Extensive experiments show ReasonMark surpasses state-of-the-art methods by reducing text Perplexity by 0.35, increasing translation BLEU score by 0.164, and raising mathematical accuracy by 0.67 points. These advancements are achieved alongside a 0.34% higher watermark detection AUC and stronger robustness to attacks, all with a negligible increase in latency. This work enables the traceable and trustworthy deployment of reasoning LLMs in real-world applications.",
      "authors": [
        "Shuliang Liu",
        "Xingyu Li",
        "Hongyi Liu",
        "Yibo Yan",
        "Bingchen Duan",
        "Qi Zheng",
        "Dong Fang",
        "Lingfeng Su",
        "Xuming Hu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 17:32:22+00:00",
      "link": "https://arxiv.org/pdf/2601.05144v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05143v1",
      "title": "A Lightweight and Explainable Vision-Language Framework for Crop Disease Visual Question Answering",
      "abstract": "Visual question answering for crop disease analysis requires accurate visual understanding and reliable language generation. This work presents a lightweight vision-language framework for crop and disease identification from leaf images. The proposed approach combines a Swin Transformer vision encoder with sequence-to-sequence language decoders. A two-stage training strategy is adopted to improve visual representation learning and cross-modal alignment. The model is evaluated on a large-scale crop disease dataset using classification and natural language generation metrics. Experimental results show high accuracy for both crop and disease identification. The framework also achieves strong performance on BLEU, ROUGE and BERTScore. Our proposed models outperform large-scale vision-language baselines while using significantly fewer parameters. Explainability is assessed using Grad-CAM and token-level attribution. Qualitative results demonstrate robust performance under diverse user-driven queries. These findings highlight the effectiveness of task-specific visual pretraining for crop disease visual question answering.",
      "authors": [
        "Md. Zahid Hossain",
        "Most. Sharmin Sultana Samu",
        "Md. Rakibul Islam",
        "Md. Siam Ansary"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.CL"
      ],
      "published": "2026-01-08 17:31:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05143v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05138v1",
      "title": "VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control",
      "abstract": "Video world models aim to simulate dynamic, real-world environments, yet existing methods struggle to provide unified and precise control over camera and multi-object motion, as videos inherently operate dynamics in the projected 2D image plane. To bridge this gap, we introduce VerseCrafter, a 4D-aware video world model that enables explicit and coherent control over both camera and object dynamics within a unified 4D geometric world state. Our approach is centered on a novel 4D Geometric Control representation, which encodes the world state through a static background point cloud and per-object 3D Gaussian trajectories. This representation captures not only an object's path but also its probabilistic 3D occupancy over time, offering a flexible, category-agnostic alternative to rigid bounding boxes or parametric models. These 4D controls are rendered into conditioning signals for a pretrained video diffusion model, enabling the generation of high-fidelity, view-consistent videos that precisely adhere to the specified dynamics. Unfortunately, another major challenge lies in the scarcity of large-scale training data with explicit 4D annotations. We address this by developing an automatic data engine that extracts the required 4D controls from in-the-wild videos, allowing us to train our model on a massive and diverse dataset.",
      "authors": [
        "Sixiao Zheng",
        "Minghao Yin",
        "Wenbo Hu",
        "Xiaoyu Li",
        "Ying Shan",
        "Yanwei Fu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 17:28:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05138v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05137v1",
      "title": "Neural Algorithmic Reasoning for Approximate $k$-Coloring with Recursive Warm Starts",
      "abstract": "Node coloring is the task of assigning colors to the nodes of a graph such that no two adjacent nodes have the same color, while using as few colors as possible. It is the most widely studied instance of graph coloring and of central importance in graph theory; major results include the Four Color Theorem and work on the Hadwiger-Nelson Problem. As an abstraction of classical combinatorial optimization tasks, such as scheduling and resource allocation, it is also rich in practical applications. Here, we focus on a relaxed version, approximate $k$-coloring, which is the task of assigning at most $k$ colors to the nodes of a graph such that the number of edges whose vertices have the same color is approximately minimized. While classical approaches leverage mathematical programming or SAT solvers, recent studies have explored the use of machine learning. We follow this route and explore the use of graph neural networks (GNNs) for node coloring. We first present an optimized differentiable algorithm that improves a prior approach by Schuetz et al. with orthogonal node feature initialization and a loss function that penalizes conflicting edges more heavily when their endpoints have higher degree; the latter inspired by the classical result that a graph is $k$-colorable if and only if its $k$-core is $k$-colorable. Next, we introduce a lightweight greedy local search algorithm and show that it may be improved by recursively computing a $(k-1)$-coloring to use as a warm start. We then show that applying such recursive warm starts to the GNN approach leads to further improvements. Numerical experiments on a range of different graph structures show that while the local search algorithms perform best on small inputs, the GNN exhibits superior performance at scale. The recursive warm start may be of independent interest beyond graph coloring for local search methods for combinatorial optimization.",
      "authors": [
        "Knut Vanderbush",
        "Melanie Weber"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.LG"
      ],
      "published": "2026-01-08 17:28:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05137v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05134v1",
      "title": "Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning",
      "abstract": "Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\\varepsilon,δ)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.",
      "authors": [
        "Polina Dolgova",
        "Sebastian U. Stich"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 17:23:13+00:00",
      "link": "https://arxiv.org/pdf/2601.05134v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05127v1",
      "title": "LooseRoPE: Content-aware Attention Manipulation for Semantic Harmonization",
      "abstract": "Recent diffusion-based image editing methods commonly rely on text or high-level instructions to guide the generation process, offering intuitive but coarse control. In contrast, we focus on explicit, prompt-free editing, where the user directly specifies the modification by cropping and pasting an object or sub-object into a chosen location within an image. This operation affords precise spatial and visual control, yet it introduces a fundamental challenge: preserving the identity of the pasted object while harmonizing it with its new context. We observe that attention maps in diffusion-based editing models inherently govern whether image regions are preserved or adapted for coherence. Building on this insight, we introduce LooseRoPE, a saliency-guided modulation of rotational positional encoding (RoPE) that loosens the positional constraints to continuously control the attention field of view. By relaxing RoPE in this manner, our method smoothly steers the model's focus between faithful preservation of the input image and coherent harmonization of the inserted object, enabling a balanced trade-off between identity retention and contextual blending. Our approach provides a flexible and intuitive framework for image editing, achieving seamless compositional results without textual descriptions or complex user input.",
      "authors": [
        "Etai Sella",
        "Yoav Baron",
        "Hadar Averbuch-Elor",
        "Daniel Cohen-Or",
        "Or Patashnik"
      ],
      "primary_category": "cs.GR",
      "categories": [
        "cs.GR"
      ],
      "published": "2026-01-08 17:17:47+00:00",
      "link": "https://arxiv.org/pdf/2601.05127v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05125v1",
      "title": "VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding",
      "abstract": "This work introduces VERSE, a methodology for analyzing and improving Vision-Language Models applied to Visually-rich Document Understanding by exploring their visual embedding space. VERSE enables the visualization of latent representations, supporting the assessment of model feasibility. It also facilitates the identification of problematic regions and guides the generation of synthetic data to enhance performance in those clusters. We validate the methodology by training on the synthetic MERIT Dataset and evaluating on its real-world counterpart, MERIT Secret. Results show that VERSE helps uncover the visual features associated with error-prone clusters, and that retraining with samples containing these features substantially boosts F1 performance without degrading generalization. Furthermore, we demonstrate that on-premise models such as Donut and Idefics2, when optimized with VERSE, match or even surpass the performance of SaaS solutions like GPT-4 and Pixtral.",
      "authors": [
        "Ignacio de Rodrigo",
        "Alvaro J. Lopez-Lopez",
        "Jaime Boal"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 17:15:15+00:00",
      "link": "https://arxiv.org/pdf/2601.05125v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05124v1",
      "title": "Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing",
      "abstract": "In-context image generation and editing (ICGE) enables users to specify visual concepts through interleaved image-text prompts, demanding precise understanding and faithful execution of user intent. Although recent unified multimodal models exhibit promising understanding capabilities, these strengths often fail to transfer effectively to image generation. We introduce Re-Align, a unified framework that bridges the gap between understanding and generation through structured reasoning-guided alignment. At its core lies the In-Context Chain-of-Thought (IC-CoT), a structured reasoning paradigm that decouples semantic guidance and reference association, providing clear textual target and mitigating confusion among reference images. Furthermore, Re-Align introduces an effective RL training scheme that leverages a surrogate reward to measure the alignment between structured reasoning text and the generated image, thereby improving the model's overall performance on ICGE tasks. Extensive experiments verify that Re-Align outperforms competitive methods of comparable model scale and resources on both in-context image generation and editing tasks.",
      "authors": [
        "Runze He",
        "Yiji Cheng",
        "Tiankai Hang",
        "Zhimin Li",
        "Yu Xu",
        "Zijin Yin",
        "Shiyi Zhang",
        "Wenxun Dai",
        "Penghui Du",
        "Ao Ma",
        "Chunyu Wang",
        "Qinglin Lu",
        "Jizhong Han",
        "Jiao Dai"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 17:13:00+00:00",
      "link": "https://arxiv.org/pdf/2601.05124v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05116v1",
      "title": "From Rays to Projections: Better Inputs for Feed-Forward View Synthesis",
      "abstract": "Feed-forward view synthesis models predict a novel view in a single pass with minimal 3D inductive bias. Existing works encode cameras as Plücker ray maps, which tie predictions to the arbitrary world coordinate gauge and make them sensitive to small camera transformations, thereby undermining geometric consistency. In this paper, we ask what inputs best condition a model for robust and consistent view synthesis. We propose projective conditioning, which replaces raw camera parameters with a target-view projective cue that provides a stable 2D input. This reframes the task from a brittle geometric regression problem in ray space to a well-conditioned target-view image-to-image translation problem. Additionally, we introduce a masked autoencoding pretraining strategy tailored to this cue, enabling the use of large-scale uncalibrated data for pretraining. Our method shows improved fidelity and stronger cross-view consistency compared to ray-conditioned baselines on our view-consistency benchmark. It also achieves state-of-the-art quality on standard novel view synthesis benchmarks.",
      "authors": [
        "Zirui Wu",
        "Zeren Jiang",
        "Martin R. Oswald",
        "Jie Song"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 17:03:44+00:00",
      "link": "https://arxiv.org/pdf/2601.05116v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05114v1",
      "title": "Evaluative Fingerprints: Stable and Systematic Differences in LLM Evaluator Behavior",
      "abstract": "LLM-as-judge systems promise scalable, consistent evaluation. We find the opposite: judges are consistent, but not with each other; they are consistent with themselves. Across 3,240 evaluations (9 judges x 120 unique video x pack items x 3 independent runs), inter-judge agreement is near-zero (Krippendorff's α = 0.042). On two dimensions, judges disagree more than random noise would predict (α < 0). Yet this disagreement isn't chaos; it's structured. A classifier identifies which judge produced an evaluation with 77.1% accuracy from rubric scores alone, rising to 89.9% with disposition features. Within model families, the signal is even stronger: GPT-4.1 and GPT-5.2 are distinguishable with 99.6% accuracy. We call this the reliability paradox: judges cannot agree on what constitutes quality, yet their disagreement patterns are so stable they function as fingerprints. Each judge implements a distinct, stable theory of quality: an \"evaluative disposition\" that shapes how it interprets any rubric. We characterize these dispositions along multiple axes: harshness/leniency, dimension emphasis, within-judge stability (ICC), and evidence behavior (receipt validity, semantic linkage via NLI, and shotgun index). The implication is stark: LLM judges are not interchangeable instruments measuring a shared construct. They are distinct measurement devices, each encoding its own implicit theory of quality. Averaging their scores produces a synthetic verdict that corresponds to no judge's actual values.",
      "authors": [
        "Wajid Nasser"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 17:02:22+00:00",
      "link": "https://arxiv.org/pdf/2601.05114v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05111v1",
      "title": "Agent-as-a-Judge",
      "abstract": "LLM-as-a-Judge has revolutionized AI evaluation by leveraging large language models for scalable assessments. However, as evaluands become increasingly complex, specialized, and multi-step, the reliability of LLM-as-a-Judge has become constrained by inherent biases, shallow single-pass reasoning, and the inability to verify assessments against real-world observations. This has catalyzed the transition to Agent-as-a-Judge, where agentic judges employ planning, tool-augmented verification, multi-agent collaboration, and persistent memory to enable more robust, verifiable, and nuanced evaluations. Despite the rapid proliferation of agentic evaluation systems, the field lacks a unified framework to navigate this shifting landscape. To bridge this gap, we present the first comprehensive survey tracing this evolution. Specifically, we identify key dimensions that characterize this paradigm shift and establish a developmental taxonomy. We organize core methodologies and survey applications across general and professional domains. Furthermore, we analyze frontier challenges and identify promising research directions, ultimately providing a clear roadmap for the next generation of agentic evaluation.",
      "authors": [
        "Runyang You",
        "Hongru Cai",
        "Caiqi Zhang",
        "Qiancheng Xu",
        "Meng Liu",
        "Tiezheng Yu",
        "Yongqi Li",
        "Wenjie Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 16:58:10+00:00",
      "link": "https://arxiv.org/pdf/2601.05111v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05110v1",
      "title": "GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts",
      "abstract": "Large Reasoning Models (LRMs) achieve remarkable performance by explicitly generating multi-step chains of thought, but this capability incurs substantial inference latency and computational cost. Collaborative inference offers a promising solution by selectively allocating work between lightweight and large models, yet a fundamental challenge remains: determining when a reasoning step requires the capacity of a large model or the efficiency of a small model. Existing routing strategies either rely on local token probabilities or post-hoc verification, introducing significant inference overhead. In this work, we propose a novel perspective on step-wise collaboration: the difficulty of a reasoning step can be inferred from its very first token. Inspired by the \"Aha Moment\" phenomenon in LRMs, we show that the entropy of the initial token serves as a strong predictor of step difficulty. Building on this insight, we introduce GlimpRouter, a training-free step-wise collaboration framework. GlimpRouter employs a lightweight model to generate only the first token of each reasoning step and routes the step to a larger model only when the initial token entropy exceeds a threshold. Experiments on multiple benchmarks demonstrate that our approach significantly reduces inference latency while preserving accuracy. For instance, GlimpRouter attains a substantial 10.7% improvement in accuracy while reducing inference latency by 25.9% compared to a standalone large model on AIME25. These results suggest a simple yet effective mechanism for reasoning: allocating computation based on a glimpse of thought rather than full-step evaluation.",
      "authors": [
        "Wenhao Zeng",
        "Xuteng Zhang",
        "Yuling Shi",
        "Chao Hu",
        "Yuting Chen",
        "Beijun Shen",
        "Xiaodong Gu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 16:58:07+00:00",
      "link": "https://arxiv.org/pdf/2601.05110v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05109v1",
      "title": "Nalar: An agent serving framework",
      "abstract": "LLM-driven agentic applications increasingly automate complex, multi-step tasks, but serving them efficiently remains challenging due to heterogeneous components, dynamic and model-driven control flow, long-running state, and unpredictable latencies. Nalar is a ground-up agent-serving framework that cleanly separates workflow specification from execution while providing the runtime visibility and control needed for robust performance. Nalar preserves full Python expressiveness, using lightweight auto-generated stubs that turn agent and tool invocations into futures carrying dependency and context metadata. A managed state layer decouples logical state from physical placement, enabling safe reuse, migration, and consistent retry behavior. A two-level control architecture combines global policy computation with local event-driven enforcement to support adaptive routing, scheduling, and resource management across evolving workflows. Together, these mechanisms allow Nalar to deliver scalable, efficient, and policy-driven serving of heterogeneous agentic applications without burdening developers with orchestration logic. Across three agentic workloads, Nalar cuts tail latency by 34--74\\%, achieves up to $2.9\\times$ speedups, sustains 80 RPS where baselines fail, and scales to 130K futures with sub-500 ms control overhead.",
      "authors": [
        "Marco Laju",
        "Donghyun Son",
        "Saurabh Agarwal",
        "Nitin Kedia",
        "Myungjin Lee",
        "Jayanth Srinivasa",
        "Aditya Akella"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.MA"
      ],
      "published": "2026-01-08 16:56:40+00:00",
      "link": "https://arxiv.org/pdf/2601.05109v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05108v1",
      "title": "Rule Rewriting Revisited: A Fresh Look at Static Filtering for Datalog and ASP",
      "abstract": "Static filtering is a data-independent optimisation method for Datalog, which generalises algebraic query rewriting techniques from relational databases. In spite of its early discovery by Kifer and Lozinskii in 1986, the method has been overlooked in recent research and system development, and special cases are being rediscovered independently. We therefore recall the original approach, using updated terminology and more general filter predicates that capture features of modern systems, and we show how to extend its applicability to answer set programming (ASP). The outcome is strictly more general but also more complex than the classical approach: double exponential in general and single exponential even for predicates of bounded arity. As a solution, we propose tractable approximations of the algorithm that can still yield much improved logic programs in typical cases, e.g., it can improve the performance of rule systems over real-world data in the order of magnitude.",
      "authors": [
        "Philipp Hanisch",
        "Markus Krötzsch"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.LO"
      ],
      "published": "2026-01-08 16:54:36+00:00",
      "link": "https://arxiv.org/pdf/2601.05108v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05107v1",
      "title": "Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction",
      "abstract": "As LLM-based agents are increasingly used in long-term interactions, cumulative memory is critical for enabling personalization and maintaining stylistic consistency. However, most existing systems adopt an ``all-or-nothing'' approach to memory usage: incorporating all relevant past information can lead to \\textit{Memory Anchoring}, where the agent is trapped by past interactions, while excluding memory entirely results in under-utilization and the loss of important interaction history. We show that an agent's reliance on memory can be modeled as an explicit and user-controllable dimension. We first introduce a behavioral metric of memory dependence to quantify the influence of past interactions on current outputs. We then propose \\textbf{Stee}rable \\textbf{M}emory Agent, \\texttt{SteeM}, a framework that allows users to dynamically regulate memory reliance, ranging from a fresh-start mode that promotes innovation to a high-fidelity mode that closely follows interaction history. Experiments across different scenarios demonstrate that our approach consistently outperforms conventional prompting and rigid memory masking strategies, yielding a more nuanced and effective control for personalized human-agent collaboration.",
      "authors": [
        "Muzhao Tian",
        "Zisu Huang",
        "Xiaohua Wang",
        "Jingwen Xu",
        "Zhengkang Guo",
        "Qi Qian",
        "Yuanzhe Shen",
        "Kaitao Song",
        "Jiakang Yuan",
        "Changze Lv",
        "Xiaoqing Zheng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 16:54:30+00:00",
      "link": "https://arxiv.org/pdf/2601.05107v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05106v1",
      "title": "Token-Level LLM Collaboration via FusionRoute",
      "abstract": "Large language models (LLMs) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose FusionRoute, a robust and effective token-level multi-LLM collaboration framework in which a lightweight router simultaneously (i) selects the most suitable expert at each decoding step and (ii) contributes a complementary logit that refines or corrects the selected expert's next-token distribution via logit addition. Unlike existing token-level collaboration methods that rely solely on fixed expert outputs, we provide a theoretical analysis showing that pure expert-only routing is fundamentally limited: unless strong global coverage assumptions hold, it cannot in general realize the optimal decoding policy. By augmenting expert selection with a trainable complementary generator, FusionRoute expands the effective policy class and enables recovery of optimal value functions under mild conditions. Empirically, across both Llama-3 and Gemma-2 families and diverse benchmarks spanning mathematical reasoning, code generation, and instruction following, FusionRoute outperforms both sequence- and token-level collaboration, model merging, and direct fine-tuning, while remaining competitive with domain experts on their respective tasks.",
      "authors": [
        "Nuoya Xiong",
        "Yuhang Zhou",
        "Hanqing Zeng",
        "Zhaorun Chen",
        "Furong Huang",
        "Shuchao Bi",
        "Lizhu Zhang",
        "Zhuokai Zhao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 16:53:16+00:00",
      "link": "https://arxiv.org/pdf/2601.05106v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05105v1",
      "title": "UniLiPs: Unified LiDAR Pseudo-Labeling with Geometry-Grounded Dynamic Scene Decomposition",
      "abstract": "Unlabeled LiDAR logs, in autonomous driving applications, are inherently a gold mine of dense 3D geometry hiding in plain sight - yet they are almost useless without human labels, highlighting a dominant cost barrier for autonomous-perception research. In this work we tackle this bottleneck by leveraging temporal-geometric consistency across LiDAR sweeps to lift and fuse cues from text and 2D vision foundation models directly into 3D, without any manual input. We introduce an unsupervised multi-modal pseudo-labeling method relying on strong geometric priors learned from temporally accumulated LiDAR maps, alongside with a novel iterative update rule that enforces joint geometric-semantic consistency, and vice-versa detecting moving objects from inconsistencies. Our method simultaneously produces 3D semantic labels, 3D bounding boxes, and dense LiDAR scans, demonstrating robust generalization across three datasets. We experimentally validate that our method compares favorably to existing semantic segmentation and object detection pseudo-labeling methods, which often require additional manual supervision. We confirm that even a small fraction of our geometrically consistent, densified LiDAR improves depth prediction by 51.5% and 22.0% MAE in the 80-150 and 150-250 meters range, respectively.",
      "authors": [
        "Filippo Ghilotti",
        "Samuel Brucker",
        "Nahku Saidy",
        "Matteo Matteucci",
        "Mario Bijelic",
        "Felix Heide"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 16:52:28+00:00",
      "link": "https://arxiv.org/pdf/2601.05105v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05104v1",
      "title": "How Human is AI? Examining the Impact of Emotional Prompts on Artificial and Human and Responsiveness",
      "abstract": "This research examines how the emotional tone of human-AI interactions shapes ChatGPT and human behavior. In a between-subject experiment, we asked participants to express a specific emotion while working with ChatGPT (GPT-4.0) on two tasks, including writing a public response and addressing an ethical dilemma. We found that compared to interactions where participants maintained a neutral tone, ChatGPT showed greater improvement in its answers when participants praised ChatGPT for its responses. Expressing anger towards ChatGPT also led to a higher albeit smaller improvement relative to the neutral condition, whereas blaming ChatGPT did not improve its answers. When addressing an ethical dilemma, ChatGPT prioritized corporate interests less when participants expressed anger towards it, while blaming increases its emphasis on protecting the public interest. Additionally, we found that people used more negative, hostile, and disappointing expressions in human-human communication after interactions during which participants blamed rather than praised for their responses. Together, our findings demonstrate that the emotional tone people apply in human-AI interactions not only shape ChatGPT's outputs but also carry over into subsequent human-human communication.",
      "authors": [
        "Florence Bernays",
        "Marco Henriques Pereira",
        "Jochen Menges"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "econ.GN"
      ],
      "published": "2026-01-08 16:50:00+00:00",
      "link": "https://arxiv.org/pdf/2601.05104v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05103v1",
      "title": "Semantically Orthogonal Framework for Citation Classification: Disentangling Intent and Content",
      "abstract": "Understanding the role of citations is essential for research assessment and citation-aware digital libraries. However, existing citation classification frameworks often conflate citation intent (why a work is cited) with cited content type (what part is cited), limiting their effectiveness in auto classification due to a dilemma between fine-grained type distinctions and practical classification reliability. We introduce SOFT, a Semantically Orthogonal Framework with Two dimensions that explicitly separates citation intent from cited content type, drawing inspiration from semantic role theory. We systematically re-annotate the ACL-ARC dataset using SOFT and release a cross-disciplinary test set sampled from ACT2. Evaluation with both zero-shot and fine-tuned Large Language Models demonstrates that SOFT enables higher agreement between human annotators and LLMs, and supports stronger classification performance and robust cross-domain generalization compared to ACL-ARC and SciCite annotation frameworks. These results confirm SOFT's value as a clear, reusable annotation standard, improving clarity, consistency, and generalizability for digital libraries and scholarly communication infrastructures. All code and data are publicly available on GitHub https://github.com/zhiyintan/SOFT.",
      "authors": [
        "Changxu Duan",
        "Zhiyin Tan"
      ],
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.CL"
      ],
      "published": "2026-01-08 16:48:36+00:00",
      "link": "https://arxiv.org/pdf/2601.05103v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05101v1",
      "title": "Arabic Prompts with English Tools: A Benchmark",
      "abstract": "Large Language Models (LLMs) are now integral to numerous industries, increasingly serving as the core reasoning engine for autonomous agents that perform complex tasks through tool-use. While the development of Arabic-native LLMs is accelerating, the benchmarks for evaluating their capabilities lag behind, with most existing frameworks focusing on English. A critical and overlooked area is tool-calling, where the performance of models prompted in non-English languages like Arabic is poorly understood, especially since these models are often pretrained on predominantly English data. This paper addresses this critical gap by introducing the first dedicated benchmark for evaluating the tool-calling and agentic capabilities of LLMs in the Arabic language. Our work provides a standardized framework to measure the functional accuracy and robustness of models in Arabic agentic workflows. Our findings reveal a huge performance gap: when users interact in Arabic, tool-calling accuracy drops by an average of 5-10\\%, regardless of whether the tool descriptions themselves are in Arabic or English. By shedding light on these critical challenges, this benchmark aims to foster the development of more reliable and linguistically equitable AI agents for Arabic-speaking users.",
      "authors": [
        "Konstantin Kubrak",
        "Ahmed El-Moselhy",
        "Ammar Alsulami",
        "Remaz Altuwaim",
        "Hassan Ismail Fawaz",
        "Faisal Alsaby"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 16:47:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05101v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05099v1",
      "title": "Multi-Disciplinary Dataset Discovery from Citation-Verified Literature Contexts",
      "abstract": "Identifying suitable datasets for a research question remains challenging because existing dataset search engines rely heavily on metadata quality and keyword overlap, which often fail to capture the semantic intent of scientific investigation. We introduce a literature-driven framework that discovers datasets from citation contexts in scientific papers, enabling retrieval grounded in actual research use rather than metadata availability. Our approach combines large-scale citation-context extraction, schema-guided dataset recognition with Large Language Models, and provenance-preserving entity resolution. We evaluate the system on eight survey-derived computer science queries and find that it achieves substantially higher recall than Google Dataset Search and DataCite Commons, with normalized recall ranging from an average of 47.47% to a highest value of 81.82%. Beyond recovering gold-standard datasets, the method also surfaces additional datasets not documented in the surveys. Expert assessments across five top-level Fields of Science indicate that a substantial portion of the additional datasets are considered high utility, and some are regarded as novel for the specific topics chosen by the experts. These findings establish citation-context mining as an effective and generalizable paradigm for dataset discovery, particularly in settings where datasets lack sufficient or reliable metadata. To support reproducibility and future extensions, we release our code, evaluation datasets, and results on GitHub (https://github.com/Fireblossom/citation-context-dataset-discovery).",
      "authors": [
        "Zhiyin Tan",
        "Changxu Duan"
      ],
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-01-08 16:46:06+00:00",
      "link": "https://arxiv.org/pdf/2601.05099v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05098v1",
      "title": "ECLIPSE: An Evolutionary Computation Library for Instrumentation Prototyping in Scientific Engineering",
      "abstract": "Designing scientific instrumentation often requires exploring large, highly constrained design spaces using computationally expensive physics simulations. These simulators pose substantial challenges for integrating evolutionary computation (EC) into scientific design workflows. Evolutionary computation typically requires numerous design evaluations, making the integration of slow, low-throughput simulators particularly challenging, as they are optimized for accuracy and ease of use rather than throughput. We present ECLIPSE, an evolutionary computation framework built to interface directly with complex, domain-specific simulation tools while supporting flexible geometric and parametric representations of scientific hardware. ECLIPSE provides a modular architecture consisting of (1) Individuals, which encode hardware designs using domain-aware, physically constrained representations; (2) Evaluators, which prepare simulation inputs, invoke external simulators, and translate the simulator's outputs into fitness measures; and (3) Evolvers, which implement EC algorithms suitable for high-cost, limited-throughput environments. We demonstrate the utility of ECLIPSE across several active space-science applications, including evolved 3D antennas and spacecraft geometries optimized for drag reduction in very low Earth orbit. We further discuss the practical challenges encountered when coupling EC with scientific simulation workflows, including interoperability constraints, parallelization limits, and extreme evaluation costs, and outline ongoing efforts to combat these challenges. ECLIPSE enables interdisciplinary teams of physicists, engineers, and EC researchers to collaboratively explore unconventional designs for scientific hardware while leveraging existing domain-specific simulation software.",
      "authors": [
        "Max Foreback",
        "Evan Imata",
        "Vincent Ragusa",
        "Jacob Weiler",
        "Christina Shao",
        "Joey Wagner",
        "Katherine G. Skocelas",
        "Jonathan Sy",
        "Aman Hafez",
        "Wolfgang Banzhaf",
        "Amy Conolly",
        "Kyle R. Helson",
        "Rick Marcusen",
        "Charles Ofria",
        "Marcin Pilinski",
        "Rajiv Ramnath",
        "Bryan Reynolds",
        "Anselmo C. Pontes",
        "Emily Dolson",
        "Julie Rolla"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-08 16:45:11+00:00",
      "link": "https://arxiv.org/pdf/2601.05098v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05095v1",
      "title": "Advanced Multimodal Learning for Seizure Detection and Prediction: Concept, Challenges, and Future Directions",
      "abstract": "Epilepsy is a chronic neurological disorder characterized by recurrent unprovoked seizures, affects over 50 million people worldwide, and poses significant risks, including sudden unexpected death in epilepsy (SUDEP). Conventional unimodal approaches, primarily reliant on electroencephalography (EEG), face several key challenges, including low SNR, nonstationarity, inter- and intrapatient heterogeneity, portability, and real-time applicability in clinical settings. To address these issues, a comprehensive survey highlights the concept of advanced multimodal learning for epileptic seizure detection and prediction (AMLSDP). The survey presents the evolution of epileptic seizure detection (ESD) and prediction (ESP) technologies across different eras. The survey also explores the core challenges of multimodal and non-EEG-based ESD and ESP. To overcome the key challenges of the multimodal system, the survey introduces the advanced processing strategies for efficient AMLSDP. Furthermore, this survey highlights future directions for researchers and practitioners. We believe this work will advance neurotechnology toward wearable and imaging-based solutions for epilepsy monitoring, serving as a valuable resource for future innovations in this domain.",
      "authors": [
        "Ijaz Ahmad",
        "Faizan Ahmad",
        "Sunday Timothy Aboyeji",
        "Yongtao Zhang",
        "Peng Yang",
        "Rab Nawaz",
        "Baiying Lei"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-08 16:43:06+00:00",
      "link": "https://arxiv.org/pdf/2601.05095v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05093v1",
      "title": "Why Are Some Countries More Politically Fragmented Online Than Others?",
      "abstract": "Online political divisions, such as fragmentation or polarization, are a growing global concern that can foster radicalization and hinder democratic cooperation; however, not all divisions are detrimental, some reflect pluralism and healthy diversity of opinion in a democracy. While prior research has predominantly focused on polarization in the United States, there remains a limited body of research on political divides in multiparty systems, and no universal method for comparing fragmentation across countries. Moreover, cross-country comparison is rare. This study first develops a novel measure of structural political fragmentation built on multi-scale community detection and the effective branching factor. Using a dataset of 18,325 political influencers from Brazil, Spain, and the United States, we assess online fragmentation in their Twitter/X co-following networks. We compare the fragmentation of the three countries, as well as the ideological groups within each. We further investigate factors associated with the level of fragmentation in each country. We find that political fragmentation differs across countries and is asymmetric between ideological groups. Brazil is the most fragmented, with higher fragmentation among the left-wing group, while Spain and the United States exhibit similar overall levels, with the left more fragmented in Spain and the right more fragmented in the United States. Additionally, we find that social identity plays a central role in political fragmentation. A strong alignment between ideological and social identities, with minimal overlap between ideologies, tends to promote greater integration and reduce fragmentation. Our findings provide explanations for cross-national and ideological differences in political fragmentation.",
      "authors": [
        "Yuan Zhang",
        "Laia Castro",
        "Frank Esser",
        "Alexandre Bovet"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI"
      ],
      "published": "2026-01-08 16:41:22+00:00",
      "link": "https://arxiv.org/pdf/2601.05093v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05092v1",
      "title": "Precoding Matrix Indicator in the 5G NR Protocol: A Tutorial on 3GPP Beamforming Codebooks",
      "abstract": "This paper bridges this critical gap by providing a systematic examination of the beamforming codebook technology, i.e., precoding matrix indicator (PMI), in the 5G NR from theoretical, standardization, and implementation perspectives. We begin by introducing the background of beamforming in multiple-input multiple-output (MIMO) systems and the signaling procedures for codebook-based beamforming in practical 5G systems. Then, we establish the fundamentals of regular codebooks and port-selection codebooks in 3GPP standards. Next, we provide rigorous technical analysis of 3GPP codebook evolution spanning Releases 15-18, with particular focus on: 1) We elucidate the core principles underlying codebook design, 2) provide clear physical interpretations for each symbolic variable in the codebook formulas, summarized in tabular form, and 3) offer intuitive visual illustrations to explain how codebook parameters convey information. These essential pedagogical elements are almost entirely absent in the often-obscure standardization documents. Through mathematical modeling, performance benchmarking, feedback comparisons, and scenario-dependent applicability analysis, we provide researchers and engineers with a unified understanding of beamforming codebooks in real-world systems. Furthermore, we identify future directions and other beamforming scenarios for ongoing research and development efforts. This work serves as both an informative tutorial and a guidance for future research, facilitating more effective collaboration between academia and industry in advancing wireless communication technologies.",
      "authors": [
        "Boyu Ning",
        "Haifan Yin",
        "Sixu Liu",
        "Hao Deng",
        "Songjie Yang",
        "Yuchen Zhang",
        "Weidong Mei",
        "David Gesbert",
        "Jaebum Park",
        "Robert W. Heath",
        "Emil Björnson"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-08 16:39:37+00:00",
      "link": "https://arxiv.org/pdf/2601.05092v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05091v1",
      "title": "Code-Mix Sentiment Analysis on Hinglish Tweets",
      "abstract": "The effectiveness of brand monitoring in India is increasingly challenged by the rise of Hinglish--a hybrid of Hindi and English--used widely in user-generated content on platforms like Twitter. Traditional Natural Language Processing (NLP) models, built for monolingual data, often fail to interpret the syntactic and semantic complexity of this code-mixed language, resulting in inaccurate sentiment analysis and misleading market insights. To address this gap, we propose a high-performance sentiment classification framework specifically designed for Hinglish tweets. Our approach fine-tunes mBERT (Multilingual BERT), leveraging its multilingual capabilities to better understand the linguistic diversity of Indian social media. A key component of our methodology is the use of subword tokenization, which enables the model to effectively manage spelling variations, slang, and out-of-vocabulary terms common in Romanized Hinglish. This research delivers a production-ready AI solution for brand sentiment tracking and establishes a strong benchmark for multilingual NLP in low-resource, code-mixed environments.",
      "authors": [
        "Aashi Garg",
        "Aneshya Das",
        "Arshi Arya",
        "Anushka Goyal",
        "Aditi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 16:39:26+00:00",
      "link": "https://arxiv.org/pdf/2601.05091v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05084v1",
      "title": "Driver-Intention Prediction with Deep Learning: Real-Time Brain-to-Vehicle Communication",
      "abstract": "Brain-computer interfaces (BCIs) allow direct communication between the brain and electronics without the need for speech or physical movement. Such interfaces can be particularly beneficial in applications requiring rapid response times, such as driving, where a vehicle's advanced driving assistance systems could benefit from immediate understanding of a driver's intentions. This study presents a novel method for predicting a driver's intention to steer using electroencephalography (EEG) signals through deep learning. A driving simulator created a controlled environment in which participants imagined controlling a vehicle during various driving scenarios, including left and right turns, as well as straight driving. A convolutional neural network (CNN) classified the detected EEG data with minimal pre-processing. Our model achieved an accuracy of 83.7% in distinguishing between the three steering intentions and demonstrated the ability of CNNs to process raw EEG data effectively. The classification accuracy was highest for right-turn segments, which suggests a potential spatial bias in brain activity. This study lays the foundation for more intuitive brain-to-vehicle communication systems.",
      "authors": [
        "Niloufar Alavi",
        "Swati Shah",
        "Rezvan Alamian",
        "Stefan Goetz"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "eess.SP",
        "eess.SY"
      ],
      "published": "2026-01-08 16:29:08+00:00",
      "link": "https://arxiv.org/pdf/2601.05084v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05083v1",
      "title": "Driving on Registers",
      "abstract": "We present DrivoR, a simple and efficient transformer-based architecture for end-to-end autonomous driving. Our approach builds on pretrained Vision Transformers (ViTs) and introduces camera-aware register tokens that compress multi-camera features into a compact scene representation, significantly reducing downstream computation without sacrificing accuracy. These tokens drive two lightweight transformer decoders that generate and then score candidate trajectories. The scoring decoder learns to mimic an oracle and predicts interpretable sub-scores representing aspects such as safety, comfort, and efficiency, enabling behavior-conditioned driving at inference. Despite its minimal design, DrivoR outperforms or matches strong contemporary baselines across NAVSIM-v1, NAVSIM-v2, and the photorealistic closed-loop HUGSIM benchmark. Our results show that a pure-transformer architecture, combined with targeted token compression, is sufficient for accurate, efficient, and adaptive end-to-end driving. Code and checkpoints will be made available via the project page.",
      "authors": [
        "Ellington Kirby",
        "Alexandre Boulch",
        "Yihong Xu",
        "Yuan Yin",
        "Gilles Puy",
        "Éloi Zablocki",
        "Andrei Bursuc",
        "Spyros Gidaris",
        "Renaud Marlet",
        "Florent Bartoccioni",
        "Anh-Quan Cao",
        "Nermin Samet",
        "Tuan-Hung VU",
        "Matthieu Cord"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-08 16:28:24+00:00",
      "link": "https://arxiv.org/pdf/2601.05083v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05082v1",
      "title": "Exploring Student Expectations and Confidence in Learning Analytics",
      "abstract": "Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.",
      "authors": [
        "Hayk Asatryan",
        "Basile Tousside",
        "Janis Mohr",
        "Malte Neugebauer",
        "Hildo Bijl",
        "Paul Spiegelberg",
        "Claudia Frohn-Schauf",
        "Jörg Frochte"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CY",
        "cs.HC"
      ],
      "published": "2026-01-08 16:27:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05082v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05081v1",
      "title": "Dynamics in Search Engine Query Suggestions for European Politicians",
      "abstract": "Search engines are commonly used for online political information seeking. Yet, it remains unclear how search query suggestions for political searches that reflect the latent interest of internet users vary across countries and over time. We provide a systematic analysis of Google search engine query suggestions for European and national politicians. Using an original dataset of search query suggestions for European politicians collected in ten countries, we find that query suggestions are less stable over time in politicians' countries of origin, when the politicians hold a supranational role, and for female politicians. Moreover, query suggestions for political leaders and male politicians are more similar across countries. We conclude by discussing possible future directions for studying information search about European politicians in online search.",
      "authors": [
        "Franziska Pradel",
        "Fabian Haak",
        "Sven-Oliver Proksch",
        "Philipp Schaer"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-08 16:27:04+00:00",
      "link": "https://arxiv.org/pdf/2601.05081v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05076v1",
      "title": "Chain-of-Sanitized-Thoughts: Plugging PII Leakage in CoT of Large Reasoning Models",
      "abstract": "Large Reasoning Models (LRMs) improve performance, reliability, and interpretability by generating explicit chain-of-thought (CoT) reasoning, but this transparency introduces a serious privacy risk: intermediate reasoning often leaks personally identifiable information (PII) even when final answers are sanitized. We study how to induce privacy-first reasoning, where models reason without exposing sensitive information, using deployable interventions rather than post-hoc redaction. We introduce PII-CoT-Bench, a supervised dataset with privacy-aware CoT annotations, and a category-balanced evaluation benchmark covering realistic and adversarial leakage scenarios. Our results reveal a capability-dependent trend: state-of-the-art models benefit most from prompt-based controls, whereas weaker models require fine-tuning to achieve meaningful leakage reduction. Across models and categories, both approaches substantially reduce PII exposure with minimal degradation in utility, demonstrating that private reasoning can be achieved without sacrificing performance. Overall, we show that private CoT reasoning can be achieved with minimal utility loss, providing practical guidance for building privacy-preserving reasoning systems.",
      "authors": [
        "Arghyadeep Das",
        "Sai Sreenivas Chintha",
        "Rishiraj Girmal",
        "Kinjal Pandey",
        "Sharvi Endait"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 16:19:43+00:00",
      "link": "https://arxiv.org/pdf/2601.05076v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05075v1",
      "title": "SemPA: Improving Sentence Embeddings of Large Language Models through Semantic Preference Alignment",
      "abstract": "Traditional sentence embedding methods employ token-level contrastive learning on non-generative pre-trained models. Recently, there have emerged embedding methods based on generative large language models (LLMs). These methods either rely on fixed prompt templates or involve modifications to the model architecture. The former lacks further optimization of the model and results in limited performance, while the latter alters the internal computational mechanisms of the model, thereby compromising its generative capabilities. We propose SemPA, a novel approach that boosts the sentence representations while preserving the generative ability of LLMs via semantic preference alignment. We leverage sentence-level Direct Preference Optimization (DPO) to efficiently optimize LLMs on a paraphrase generation task, where the model learns to discriminate semantically equivalent sentences while preserving inherent generative capacity. Theoretically, we establish a formal connection between DPO and contrastive learning under the Plackett-Luce model framework. Empirically, experimental results on both semantic textual similarity tasks and various benchmarks for LLMs show that SemPA achieves better semantic representations without sacrificing the inherent generation capability of LLMs.",
      "authors": [
        "Ziyang Chen",
        "Zhenxuan Huang",
        "Yile Wang",
        "Weiqin Wang",
        "Lu Yin",
        "Hui Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 16:19:24+00:00",
      "link": "https://arxiv.org/pdf/2601.05075v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05074v1",
      "title": "Compensation Effect Amplification Control (CEAC): A movement-based approach for coordinated position and velocity control of the elbow of upper-limb prostheses",
      "abstract": "Despite advances in upper-limb (UL) prosthetic design, achieving intuitive control of intermediate joints - such as the wrist and elbow - remains challenging, particularly for continuous and velocity-modulated movements. We introduce a novel movement-based control paradigm entitled Compensation Effect Amplification Control (CEAC) that leverages users' trunk flexion and extension as input for controlling prosthetic elbow velocity. Considering that the trunk can be both a functional and compensatory joint when performing upper-limb actions, CEAC amplifies the natural coupling between trunk and prosthesis while introducing a controlled delay that allows users to modulate both the position and velocity of the prosthetic joint. We evaluated CEAC in a generic drawing task performed by twelve able-bodied participants using a supernumerary prosthesis with an active elbow. Additionally a multiple-target-reaching task was performed by a subset of ten participants. Results demonstrate task performances comparable to those obtained with natural arm movements, even when gesture velocity or drawing size were varied, while maintaining ergonomic trunk postures. Analysis revealed that CEAC effectively restores joint coordinated action, distributes movement effort between trunk and elbow, enabling intuitive trajectory control without requiring extreme compensatory movements. Overall, CEAC offers a promising control strategy for intermediate joints of UL prostheses, particularly in tasks requiring continuous and precise coordination.",
      "authors": [
        "Julian Kulozik",
        "Nathanaël Jarrassé"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 16:18:10+00:00",
      "link": "https://arxiv.org/pdf/2601.05074v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05073v1",
      "title": "Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward",
      "abstract": "Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because \"black box\" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.",
      "authors": [
        "Jianlong Chen",
        "Daocheng Fu",
        "Shengze Xu",
        "Jiawei Chen",
        "Yuan Feng",
        "Yue Yang",
        "Junchi Yan",
        "Hongyuan Zha",
        "Renqiu Xia"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 16:17:56+00:00",
      "link": "https://arxiv.org/pdf/2601.05073v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05072v1",
      "title": "DAVOS: An Autonomous Vehicle Operating System in the Vehicle Computing Era",
      "abstract": "Vehicle computing represents a fundamental shift in how autonomous vehicles are designed and deployed, transforming them from isolated transportation systems into mobile computing platforms that support both safety-critical, real-time driving and data-centric services. In this setting, vehicles simultaneously support real-time driving pipelines and a growing set of data-driven applications, placing increased responsibility on the vehicle operating system to coordinate computation, data movement, storage, and access. These demands highlight recurring system considerations related to predictable execution, data and execution protection, efficient handling of high-rate sensor data, and long-term system evolvability, commonly summarized as Safety, Security, Efficiency, and Extensibility (SSEE). Existing vehicle operating systems and runtimes address these concerns in isolation, resulting in fragmented software stacks that limit coordination between autonomy workloads and vehicle data services. This paper presents DAVOS, the Delaware Autonomous Vehicle Operating System, a unified vehicle operating system architecture designed for the vehicle computing context. DAVOS provides a cohesive operating system foundation that supports both real-time autonomy and extensible vehicle computing within a single system framework.",
      "authors": [
        "Yuxin Wang",
        "Yuankai He",
        "Boyang Tian",
        "Lichen Xian",
        "Weisong Shi"
      ],
      "primary_category": "cs.OS",
      "categories": [
        "cs.OS",
        "cs.RO"
      ],
      "published": "2026-01-08 16:17:48+00:00",
      "link": "https://arxiv.org/pdf/2601.05072v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05065v1",
      "title": "Graph energy as a measure of community detectability in networks",
      "abstract": "A key challenge in network science is the detection of communities, which are sets of nodes in a network that are densely connected internally but sparsely connected to the rest of the network. A fundamental result in community detection is the existence of a nontrivial threshold for community detectability on sparse graphs that are generated by the planted partition model (PPM). Below this so-called ``detectability limit'', no community-detection method can perform better than random chance. Spectral methods for community detection fail before this detectability limit because the eigenvalues corresponding to the eigenvectors that are relevant for community detection can be absorbed by the bulk of the spectrum. One can bypass the detectability problem by using special matrices, like the non-backtracking matrix, but this requires one to consider higher-dimensional matrices. In this paper, we show that the difference in graph energy between a PPM and an Erdős--Rényi (ER) network has a distinct transition at the detectability threshold even for the adjacency matrices of the underlying networks. The graph energy is based on the full spectrum of an adjacency matrix, so our result suggests that standard graph matrices still allow one to separate the parameter regions with detectable and undetectable communities.",
      "authors": [
        "Lucas Böttcher",
        "Mason A. Porter",
        "Santo Fortunato"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI",
        "cond-mat.stat-mech",
        "physics.soc-ph"
      ],
      "published": "2026-01-08 16:10:01+00:00",
      "link": "https://arxiv.org/pdf/2601.05065v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05063v1",
      "title": "Quantitative mapping from conventional MRI using self-supervised physics-guided deep learning: applications to a large-scale, clinically heterogeneous dataset",
      "abstract": "Magnetic resonance imaging (MRI) is a cornerstone of clinical neuroimaging, yet conventional MRIs provide qualitative information heavily dependent on scanner hardware and acquisition settings. While quantitative MRI (qMRI) offers intrinsic tissue parameters, the requirement for specialized acquisition protocols and reconstruction algorithms restricts its availability and impedes large-scale biomarker research. This study presents a self-supervised physics-guided deep learning framework to infer quantitative T1, T2, and proton-density (PD) maps directly from widely available clinical conventional T1-weighted, T2-weighted, and FLAIR MRIs. The framework was trained and evaluated on a large-scale, clinically heterogeneous dataset comprising 4,121 scan sessions acquired at our institution over six years on four different 3 T MRI scanner systems, capturing real-world clinical variability. The framework integrates Bloch-based signal models directly into the training objective. Across more than 600 test sessions, the generated maps exhibited white matter and gray matter values consistent with literature ranges. Additionally, the generated maps showed invariance to scanner hardware and acquisition protocol groups, with inter-group coefficients of variation $\\leq$ 1.1%. Subject-specific analyses demonstrated excellent voxel-wise reproducibility across scanner systems and sequence parameters, with Pearson $r$ and concordance correlation coefficients exceeding 0.82 for T1 and T2. Mean relative voxel-wise differences were low across all quantitative parameters, especially for T2 ($<$ 6%). These results indicate that the proposed framework can robustly transform diverse clinical conventional MRI data into quantitative maps, potentially paving the way for large-scale quantitative biomarker research.",
      "authors": [
        "Jelmer van Lune",
        "Stefano Mandija",
        "Oscar van der Heide",
        "Matteo Maspero",
        "Martin B. Schilder",
        "Jan Willem Dankbaar",
        "Cornelis A. T. van den Berg",
        "Alessandro Sbrizzi"
      ],
      "primary_category": "physics.med-ph",
      "categories": [
        "physics.med-ph",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 16:08:58+00:00",
      "link": "https://arxiv.org/pdf/2601.05063v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05062v1",
      "title": "Compositional Steering of Large Language Models with Steering Tokens",
      "abstract": "Deploying LLMs in real-world applications requires controllable output that satisfies multiple desiderata at the same time. While existing work extensively addresses LLM steering for a single behavior, \\textit{compositional steering} -- i.e., steering LLMs simultaneously towards multiple behaviors -- remains an underexplored problem. In this work, we propose \\emph{compositional steering tokens} for multi-behavior steering. We first embed individual behaviors, expressed as natural language instructions, into dedicated tokens via self-distillation. Contrary to most prior work, which operates in the activation space, our behavior steers live in the space of input tokens, enabling more effective zero-shot composition. We then train a dedicated \\textit{composition token} on pairs of behaviors and show that it successfully captures the notion of composition: it generalizes well to \\textit{unseen} compositions, including those with unseen behaviors as well as those with an unseen \\textit{number} of behaviors. Our experiments across different LLM architectures show that steering tokens lead to superior multi-behavior control compared to competing approaches (instructions, activation steering, and LoRA merging). Moreover, we show that steering tokens complement natural language instructions, with their combination resulting in further gains.",
      "authors": [
        "Gorjan Radevski",
        "Kiril Gashteovski",
        "Giwon Hong",
        "Carolin Lawrence",
        "Goran Glavaš"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 16:08:44+00:00",
      "link": "https://arxiv.org/pdf/2601.05062v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05059v1",
      "title": "From Understanding to Engagement: Personalized pharmacy Video Clips via Vision Language Models (VLMs)",
      "abstract": "Vision Language Models (VLMs) are poised to revolutionize the digital transformation of pharmacyceutical industry by enabling intelligent, scalable, and automated multi-modality content processing. Traditional manual annotation of heterogeneous data modalities (text, images, video, audio, and web links), is prone to inconsistencies, quality degradation, and inefficiencies in content utilization. The sheer volume of long video and audio data further exacerbates these challenges, (e.g. long clinical trial interviews and educational seminars).   Here, we introduce a domain adapted Video to Video Clip Generation framework that integrates Audio Language Models (ALMs) and Vision Language Models (VLMs) to produce highlight clips. Our contributions are threefold: (i) a reproducible Cut & Merge algorithm with fade in/out and timestamp normalization, ensuring smooth transitions and audio/visual alignment; (ii) a personalization mechanism based on role definition and prompt injection for tailored outputs (marketing, training, regulatory); (iii) a cost efficient e2e pipeline strategy balancing ALM/VLM enhanced processing. Evaluations on Video MME benchmark (900) and our proprietary dataset of 16,159 pharmacy videos across 14 disease areas demonstrate 3 to 4 times speedup, 4 times cost reduction, and competitive clip quality. Beyond efficiency gains, we also report our methods improved clip coherence scores (0.348) and informativeness scores (0.721) over state of the art VLM baselines (e.g., Gemini 2.5 Pro), highlighting the potential of transparent, custom extractive, and compliance supporting video summarization for life sciences.",
      "authors": [
        "Suyash Mishra",
        "Qiang Li",
        "Srikanth Patil",
        "Anubhav Girdhar"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 16:02:56+00:00",
      "link": "https://arxiv.org/pdf/2601.05059v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05057v1",
      "title": "Supporting Secured Integration of Microarchitectural Defenses",
      "abstract": "There has been a plethora of microarchitectural-level attacks leading to many proposed countermeasures. This has created an unexpected and unaddressed security issue where naive integration of those defenses can potentially lead to security vulnerabilities. This occurs when one defense changes an aspect of a microarchitecture that is crucial for the security of another defense. We refer to this problem as a microarchitectural defense assumption violation} (MDAV).   We propose a two-step methodology to screen for potential MDAVs in the early-stage of integration. The first step is to design and integrate a composed model, guided by bounded model checking of security properties. The second step is to implement the model concretely on a simulator and to evaluate with simulated attacks. As a contribution supporting the first step, we propose an event-based modeling framework, called Maestro, for testing and evaluating microarchitectural models with integrated defenses. In our evaluation, Maestro reveals MDAVs (8), supports compact expression (~15x Alloy LoC ratio), enables semantic composability and eliminates performance degradations (>100x).   As a contribution supporting the second step, we use an event-based simulator (GEM5) for investigating integrated microarchitectural defenses. We show that a covert channel attack is possible on a naively integrated implementation of some state-of-the-art defenses, and a repaired implementation using our integration methodology is resilient to the attack.",
      "authors": [
        "Kartik Ramkrishnan",
        "Stephen McCamant",
        "Antonia Zhai",
        "Pen-Chung Yew"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AR"
      ],
      "published": "2026-01-08 15:58:30+00:00",
      "link": "https://arxiv.org/pdf/2601.05057v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05053v1",
      "title": "Reinforced Efficient Reasoning via Semantically Diverse Exploration",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in enhancing the reasoning of large language models (LLMs). Monte Carlo Tree Search (MCTS)-based extensions improve upon vanilla RLVR (e.g., GRPO) by providing tree-based reasoning rollouts that enable fine-grained and segment-level credit assignment. However, existing methods still suffer from limited exploration diversity and inefficient reasoning. To address the above challenges, we propose reinforced efficient reasoning via semantically diverse explorations, i.e., ROSE, for LLMs. To encourage more diverse reasoning exploration, our method incorporates a semantic-entropy-based branching strategy and an $\\varepsilon$-exploration mechanism. The former operates on already sampled reasoning rollouts to capture semantic uncertainty and select branching points with high semantic divergence to generate new successive reasoning paths, whereas the latter stochastically initiates reasoning rollouts from the root, preventing the search process from becoming overly local. To improve efficiency, we design a length-aware segment-level advantage estimator that rewards concise and correct reasoning while penalizing unnecessarily long reasoning chains. Extensive experiments on various mathematical reasoning benchmarks with Qwen and Llama models validate the effectiveness and efficiency of ROSE. Codes are available at https://github.com/ZiqiZhao1/ROSE-rl.",
      "authors": [
        "Ziqi Zhao",
        "Zhaochun Ren",
        "Jiahong Zou",
        "Liu Yang",
        "Zhiwei Xu",
        "Xuri Ge",
        "Zhumin Chen",
        "Xinyu Ma",
        "Daiting Shi",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Xin Xin"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 15:56:44+00:00",
      "link": "https://arxiv.org/pdf/2601.05053v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05052v1",
      "title": "DeepWeightFlow: Re-Basined Flow Matching for Generating Neural Network Weights",
      "abstract": "Building efficient and effective generative models for neural network weights has been a research focus of significant interest that faces challenges posed by the high-dimensional weight spaces of modern neural networks and their symmetries. Several prior generative models are limited to generating partial neural network weights, particularly for larger models, such as ResNet and ViT. Those that do generate complete weights struggle with generation speed or require finetuning of the generated models. In this work, we present DeepWeightFlow, a Flow Matching model that operates directly in weight space to generate diverse and high-accuracy neural network weights for a variety of architectures, neural network sizes, and data modalities. The neural networks generated by DeepWeightFlow do not require fine-tuning to perform well and can scale to large networks. We apply Git Re-Basin and TransFusion for neural network canonicalization in the context of generative weight models to account for the impact of neural network permutation symmetries and to improve generation efficiency for larger model sizes. The generated networks excel at transfer learning, and ensembles of hundreds of neural networks can be generated in minutes, far exceeding the efficiency of diffusion-based methods. DeepWeightFlow models pave the way for more efficient and scalable generation of diverse sets of neural networks.",
      "authors": [
        "Saumya Gupta",
        "Scott Biggs",
        "Moritz Laber",
        "Zohair Shafi",
        "Robin Walters",
        "Ayan Paul"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-08 15:56:28+00:00",
      "link": "https://arxiv.org/pdf/2601.05052v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05051v1",
      "title": "Publishing FAIR and Machine-actionable Reviews in Materials Science: The Case for Symbolic Knowledge in Neuro-symbolic Artificial Intelligence",
      "abstract": "Scientific reviews are central to knowledge integration in materials science, yet their key insights remain locked in narrative text and static PDF tables, limiting reuse by humans and machines alike. This article presents a case study in atomic layer deposition and etching (ALD/E) where we publish review tables as FAIR, machine-actionable comparisons in the Open Research Knowledge Graph (ORKG), turning them into structured, queryable knowledge. Building on this, we contrast symbolic querying over ORKG with large language model-based querying, and argue that a curated symbolic layer should remain the backbone of reliable neurosymbolic AI in materials science, with LLMs serving as complementary, symbolically grounded interfaces rather than standalone sources of truth.",
      "authors": [
        "Jennifer D'Souza",
        "Soren Auer",
        "Eleni Poupaki",
        "Alex Watkins",
        "Anjana Devi",
        "Riikka L. Puurunen",
        "Bora Karasulu",
        "Adrie Mackus",
        "Erwin Kessels"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DL",
        "cs.IT"
      ],
      "published": "2026-01-08 15:56:17+00:00",
      "link": "https://arxiv.org/pdf/2601.05051v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05050v1",
      "title": "Large language models can effectively convince people to believe conspiracies",
      "abstract": "Large language models (LLMs) have been shown to be persuasive across a variety of context. But it remains unclear whether this persuasive power advantages truth over falsehood, or if LLMs can promote misbeliefs just as easily as refuting them. Here, we investigate this question across three pre-registered experiments in which participants (N = 2,724 Americans) discussed a conspiracy theory they were uncertain about with GPT-4o, and the model was instructed to either argue against (\"debunking\") or for (\"bunking\") that conspiracy. When using a \"jailbroken\" GPT-4o variant with guardrails removed, the AI was as effective at increasing conspiracy belief as decreasing it. Concerningly, the bunking AI was rated more positively, and increased trust in AI, more than the debunking AI. Surprisingly, we found that using standard GPT-4o produced very similar effects, such that the guardrails imposed by OpenAI did little to revent the LLM from promoting conspiracy beliefs. Encouragingly, however, a corrective conversation reversed these newly induced conspiracy beliefs, and simply prompting GPT-4o to only use accurate information dramatically reduced its ability to increase conspiracy beliefs. Our findings demonstrate that LLMs possess potent abilities to promote both truth and falsehood, but that potential solutions may exist to help mitigate this risk.",
      "authors": [
        "Thomas H. Costello",
        "Kellin Pelrine",
        "Matthew Kowal",
        "Antonio A. Arechar",
        "Jean-François Godbout",
        "Adam Gleave",
        "David Rand",
        "Gordon Pennycook"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "econ.GN"
      ],
      "published": "2026-01-08 15:56:05+00:00",
      "link": "https://arxiv.org/pdf/2601.05050v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05049v1",
      "title": "How to Set the Learning Rate for Large-Scale Pre-training?",
      "abstract": "Optimal configuration of the learning rate (LR) is a fundamental yet formidable challenge in large-scale pre-training. Given the stringent trade-off between training costs and model performance, the pivotal question is whether the optimal LR can be accurately extrapolated from low-cost experiments. In this paper, we formalize this investigation into two distinct research paradigms: Fitting and Transfer. Within the Fitting Paradigm, we innovatively introduce a Scaling Law for search factor, effectively reducing the search complexity from O(n^3) to O(n*C_D*C_η) via predictive modeling. Within the Transfer Paradigm, we extend the principles of $μ$Transfer to the Mixture of Experts (MoE) architecture, broadening its applicability to encompass model depth, weight decay, and token horizons. By pushing the boundaries of existing hyperparameter research in terms of scale, we conduct a comprehensive comparison between these two paradigms. Our empirical results challenge the scalability of the widely adopted $μ$ Transfer in large-scale pre-training scenarios. Furthermore, we provide a rigorous analysis through the dual lenses of training stability and feature learning to elucidate the underlying reasons why module-wise parameter tuning underperforms in large-scale settings. This work offers systematic practical guidelines and a fresh theoretical perspective for optimizing industrial-level pre-training.",
      "authors": [
        "Yunhua Zhou",
        "Shuhao Xing",
        "Junhao Huang",
        "Xipeng Qiu",
        "Qipeng Guo"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 15:55:13+00:00",
      "link": "https://arxiv.org/pdf/2601.05049v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05039v1",
      "title": "FinDeepForecast: A Live Multi-Agent System for Benchmarking Deep Research Agents in Financial Forecasting",
      "abstract": "Deep Research (DR) Agents powered by advanced Large Language Models (LLMs) have fundamentally shifted the paradigm for completing complex research tasks. Yet, a comprehensive and live evaluation of their forecasting performance on real-world, research-oriented tasks in high-stakes domains (e.g., finance) remains underexplored. We introduce FinDeepForecast, the first live, end-to-end multi-agent system for automatically evaluating DR agents by continuously generating research-oriented financial forecasting tasks. This system is equipped with a dual-track taxonomy, enabling the dynamic generation of recurrent and non-recurrent forecasting tasks at both corporate and macro levels. With this system, we generate FinDeepForecastBench, a weekly evaluation benchmark over a ten-week horizon, encompassing 8 global economies and 1,314 listed companies, and evaluate 13 representative methods. Extensive experiments show that, while DR agents consistently outperform strong baselines, their performance still falls short of genuine forward-looking financial reasoning. We expect the proposed FinDeepForecast system to consistently facilitate future advancements of DR agents in research-oriented financial forecasting tasks. The benchmark and leaderboard are publicly available on the OpenFinArena Platform.",
      "authors": [
        "Xiangyu Li",
        "Xuan Yao",
        "Guohao Qi",
        "Fengbin Zhu",
        "Kelvin J. L. Koa",
        "Xiang Yao Ng",
        "Ziyang Liu",
        "Xingyu Ni",
        "Chang Liu",
        "Yonghui Yang",
        "Yang Zhang",
        "Wenjie Wang",
        "Fuli Feng",
        "Chao Wang",
        "Huanbo Luan",
        "Xiaofen Xing",
        "Xiangmin Xu",
        "Tat-Seng Chua",
        "Ke-Wei Huang"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA"
      ],
      "published": "2026-01-08 15:45:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05039v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05033v1",
      "title": "A Data-Driven Predictive Framework for Inventory Optimization Using Context-Augmented Machine Learning Models",
      "abstract": "Demand forecasting in supply chain management (SCM) is critical for optimizing inventory, reducing waste, and improving customer satisfaction. Conventional approaches frequently neglect external influences like weather, festivities, and equipment breakdowns, resulting in inefficiencies. This research investigates the use of machine learning (ML) algorithms to improve demand prediction in retail and vending machine sectors. Four machine learning algorithms. Extreme Gradient Boosting (XGBoost), Autoregressive Integrated Moving Average (ARIMA), Facebook Prophet (Fb Prophet), and Support Vector Regression (SVR) were used to forecast inventory requirements. Ex-ternal factors like weekdays, holidays, and sales deviation indicators were methodically incorporated to enhance precision. XGBoost surpassed other models, reaching the lowest Mean Absolute Error (MAE) of 22.7 with the inclusion of external variables. ARIMAX and Fb Prophet demonstrated noteworthy enhancements, whereas SVR fell short in performance. Incorporating external factors greatly improves the precision of demand forecasting models, and XGBoost is identified as the most efficient algorithm. This study offers a strong framework for enhancing inventory management in retail and vending machine systems.",
      "authors": [
        "Anees Fatima",
        "Mohammad Abdus Salam"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 15:43:28+00:00",
      "link": "https://arxiv.org/pdf/2601.05033v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05019v1",
      "title": "Hán Dān Xué Bù (Mimicry) or Qīng Chū Yú Lán (Mastery)? A Cognitive Perspective on Reasoning Distillation in Large Language Models",
      "abstract": "Recent Large Reasoning Models trained via reinforcement learning exhibit a \"natural\" alignment with human cognitive costs. However, we show that the prevailing paradigm of reasoning distillation -- training student models to mimic these traces via Supervised Fine-Tuning (SFT) -- fails to transmit this cognitive structure. Testing the \"Hán Dān Xué Bù\" (Superficial Mimicry) hypothesis across 14 models, we find that distillation induces a \"Functional Alignment Collapse\": while teacher models mirror human difficulty scaling ($\\bar{r}=0.64$), distilled students significantly degrade this alignment ($\\bar{r}=0.34$), often underperforming their own pre-distillation baselines (\"Negative Transfer\"). Our analysis suggests that SFT induces a \"Cargo Cult\" effect, where students ritualistically replicate the linguistic form of reasoning (verbosity) without internalizing the teacher's dynamic resource allocation policy. Consequently, reasoning distillation decouples computational cost from cognitive demand, revealing that human-like cognition is an emergent property of active reinforcement, not passive imitation.",
      "authors": [
        "Yueqing Hu",
        "Xinyang Peng",
        "Shuting Peng",
        "Hanqi Wang",
        "Tianhong Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.NC"
      ],
      "published": "2026-01-08 15:27:03+00:00",
      "link": "https://arxiv.org/pdf/2601.05019v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05011v1",
      "title": "Leveraging Prediction Entropy for Automatic Prompt Weighting in Zero-Shot Audio-Language Classification",
      "abstract": "Audio-language models have recently demonstrated strong zero-shot capabilities by leveraging natural-language supervision to classify audio events without labeled training data. Yet, their performance is highly sensitive to the wording of text prompts, with small variations leading to large fluctuations in accuracy. Prior work has mitigated this issue through prompt learning or prompt ensembling. However, these strategies either require annotated data or fail to account for the fact that some prompts may negatively impact performance. In this work, we present an entropy-guided prompt weighting approach that aims to find a robust combination of prompt contributions to maximize prediction confidence. To this end, we formulate a tailored objective function that minimizes prediction entropy to yield new prompt weights, utilizing low-entropy as a proxy for high confidence. Our approach can be applied to individual samples or a batch of audio samples, requiring no additional labels and incurring negligible computational overhead. Experiments on five audio classification datasets covering environmental, urban, and vocal sounds, demonstrate consistent gains compared to classical prompt ensembling methods in a zero-shot setting, with accuracy improvements 5-times larger across the whole benchmark.",
      "authors": [
        "Karim El Khoury",
        "Maxime Zanella",
        "Tiffanie Godelaine",
        "Christophe De Vleeschouwer",
        "Benoit Macq"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.LG"
      ],
      "published": "2026-01-08 15:11:04+00:00",
      "link": "https://arxiv.org/pdf/2601.05011v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.05002v1",
      "title": "On the Hidden Objective Biases of Group-based Reinforcement Learning",
      "abstract": "Group-based reinforcement learning methods, like Group Relative Policy Optimization (GRPO), are widely used nowadays to post-train large language models. Despite their empirical success, they exhibit structural mismatches between reward optimization and the underlying training objective. In this paper, we present a theoretical analysis of GRPO style methods by studying them within a unified surrogate formulation. This perspective reveals recurring properties that affect all the methods under analysis: (i) non-uniform group weighting induces systematic gradient biases on shared prefix tokens; (ii) interactions with the AdamW optimizer make training dynamics largely insensitive to reward scaling; and (iii) optimizer momentum can push policy updates beyond the intended clipping region under repeated optimization steps. We believe that these findings highlight fundamental limitations of current approaches and provide principled guidance for the design of future formulations.",
      "authors": [
        "Aleksandar Fontana",
        "Marco Simoni",
        "Giulio Rossolini",
        "Andrea Saracino",
        "Paolo Mori"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 15:00:35+00:00",
      "link": "https://arxiv.org/pdf/2601.05002v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04996v1",
      "title": "AlgBench: To What Extent Do Large Reasoning Models Understand Algorithms?",
      "abstract": "Reasoning ability has become a central focus in the advancement of Large Reasoning Models (LRMs). Although notable progress has been achieved on several reasoning benchmarks such as MATH500 and LiveCodeBench, existing benchmarks for algorithmic reasoning remain limited, failing to answer a critical question: Do LRMs truly master algorithmic reasoning? To answer this question, we propose AlgBench, an expert-curated benchmark that evaluates LRMs under an algorithm-centric paradigm.   AlgBench consists of over 3,000 original problems spanning 27 algorithms, constructed by ACM algorithmic experts and organized under a comprehensive taxonomy, including Euclidean-structured, non-Euclidean-structured, non-optimized, local-optimized, global-optimized, and heuristic-optimized categories. Empirical evaluations on leading LRMs (e.g., Gemini-3-Pro, DeepSeek-v3.2-Speciale and GPT-o3) reveal substantial performance heterogeneity: while models perform well on non-optimized tasks (up to 92%), accuracy drops sharply to around 49% on globally optimized algorithms such as dynamic programming. Further analysis uncovers \\textbf{strategic over-shifts}, wherein models prematurely abandon correct algorithmic designs due to necessary low-entropy tokens. These findings expose fundamental limitations of problem-centric reinforcement learning and highlight the necessity of an algorithm-centric training paradigm for robust algorithmic reasoning.",
      "authors": [
        "Henan Sun",
        "Kaichi Yu",
        "Yuyao Wang",
        "Bowen Liu",
        "Xunkai Li",
        "Rong-Hua Li",
        "Nuo Chen",
        "Jia Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 14:54:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04996v1",
      "tags": [
        "keyword:RL",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04978v1",
      "title": "A DQN-based model for intelligent network selection in heterogeneous wireless systems",
      "abstract": "Wireless communications have been at the center of the revolution in technology for the last few years. The 5G communication system is the pinnacle of these technologies; however 4G LTE, WiFi, and even satellite technologies are still employed worldwide. So, the aim of the next generation network is to take advantage of these technologies for the better of the end users. Our research analyzes this subject and reveals a new and intelligent method that allows users to select the suitable RAT at each time and, therefore, to switch to another RAT if necessary. The Deep Q Network DQN algorithm was utilized, which is a reinforcement learning algorithm that determines judgments based on antecedent actions (rewards and punishments). The approach exhibits a high accuracy, reaching 93 percent, especially after a given number of epochs (the exploration phase), compared to typical MADM methods where the accuracy does not exceed 75 percent",
      "authors": [
        "Fayssal Bendaoud",
        "Asma Amraoui",
        "karim Sehimi"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-01-08 14:29:38+00:00",
      "link": "https://arxiv.org/pdf/2601.04978v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04973v1",
      "title": "ConMax: Confidence-Maximizing Compression for Efficient Chain-of-Thought Reasoning",
      "abstract": "Recent breakthroughs in Large Reasoning Models (LRMs) have demonstrated that extensive Chain-of-Thought (CoT) generation is critical for enabling intricate cognitive behaviors, such as self-verification and backtracking, to solve complex tasks. However, this capability often leads to ``overthinking'', where models generate redundant reasoning paths that inflate computational costs without improving accuracy. While Supervised Fine-Tuning (SFT) on reasoning traces is a standard paradigm for the 'cold start' phase, applying existing compression techniques to these traces often compromises logical coherence or incurs prohibitive sampling costs. In this paper, we introduce ConMax (Confidence-Maximizing Compression), a novel reinforcement learning framework designed to automatically compress reasoning traces while preserving essential reasoning patterns. ConMax formulates compression as a reward-driven optimization problem, training a policy to prune redundancy by maximizing a weighted combination of answer confidence for predictive fidelity and thinking confidence for reasoning validity through a frozen auxiliary LRM. Extensive experiments across five reasoning datasets demonstrate that ConMax achieves a superior efficiency-performance trade-off. Specifically, it reduces inference length by 43% over strong baselines at the cost of a mere 0.7% dip in accuracy, proving its effectiveness in generating high-quality, efficient training data for LRMs.",
      "authors": [
        "Minda Hu",
        "Zexuan Qiu",
        "Zenan Xu",
        "Kun Li",
        "Bo Zhou",
        "Irwin King"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 14:22:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04973v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04968v1",
      "title": "SparseLaneSTP: Leveraging Spatio-Temporal Priors with Sparse Transformers for 3D Lane Detection",
      "abstract": "3D lane detection has emerged as a critical challenge in autonomous driving, encompassing identification and localization of lane markings and the 3D road surface. Conventional 3D methods detect lanes from dense birds-eye-viewed (BEV) features, though erroneous transformations often result in a poor feature representation misaligned with the true 3D road surface. While recent sparse lane detectors have surpassed dense BEV approaches, they completely disregard valuable lane-specific priors. Furthermore, existing methods fail to utilize historic lane observations, which yield the potential to resolve ambiguities in situations of poor visibility. To address these challenges, we present SparseLaneSTP, a novel method that integrates both geometric properties of the lane structure and temporal information into a sparse lane transformer. It introduces a new lane-specific spatio-temporal attention mechanism, a continuous lane representation tailored for sparse architectures as well as temporal regularization. Identifying weaknesses of existing 3D lane datasets, we also introduce a precise and consistent 3D lane dataset using a simple yet effective auto-labeling strategy. Our experimental section proves the benefits of our contributions and demonstrates state-of-the-art performance across all detection and error metrics on existing 3D lane detection benchmarks as well as on our novel dataset.",
      "authors": [
        "Maximilian Pittner",
        "Joel Janai",
        "Mario Faigle",
        "Alexandru Paul Condurache"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 14:16:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04968v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04960v1",
      "title": "A Unified Spoken Language Model with Injected Emotional-Attribution Thinking for Human-like Interaction",
      "abstract": "This paper presents a unified spoken language model for emotional intelligence, enhanced by a novel data construction strategy termed Injected Emotional-Attribution Thinking (IEAT). IEAT incorporates user emotional states and their underlying causes into the model's internal reasoning process, enabling emotion-aware reasoning to be internalized rather than treated as explicit supervision. The model is trained with a two-stage progressive strategy. The first stage performs speech-text alignment and emotional attribute modeling via self-distillation, while the second stage conducts end-to-end cross-modal joint optimization to ensure consistency between textual and spoken emotional expressions. Experiments on the Human-like Spoken Dialogue Systems Challenge (HumDial) Emotional Intelligence benchmark demonstrate that the proposed approach achieves top-ranked performance across emotional trajectory modeling, emotional reasoning, and empathetic response generation under both LLM-based and human evaluations.",
      "authors": [
        "Qing Wang",
        "Zehan Li",
        "Yaodong Song",
        "Hongjie Chen",
        "Jian Kang",
        "Jie Lian",
        "Jie Li",
        "Yongxiang Li",
        "Xuelong Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.SD"
      ],
      "published": "2026-01-08 14:07:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04960v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04948v1",
      "title": "SKATER: Synthesized Kinematics for Advanced Traversing Efficiency on a Humanoid Robot via Roller Skate Swizzles",
      "abstract": "Although recent years have seen significant progress of humanoid robots in walking and running, the frequent foot strikes with ground during these locomotion gaits inevitably generate high instantaneous impact forces, which leads to exacerbated joint wear and poor energy utilization. Roller skating, as a sport with substantial biomechanical value, can achieve fast and continuous sliding through rational utilization of body inertia, featuring minimal kinetic energy loss. Therefore, this study proposes a novel humanoid robot with each foot equipped with a row of four passive wheels for roller skating. A deep reinforcement learning control framework is also developed for the swizzle gait with the reward function design based on the intrinsic characteristics of roller skating. The learned policy is first analyzed in simulation and then deployed on the physical robot to demonstrate the smoothness and efficiency of the swizzle gait over traditional bipedal walking gait in terms of Impact Intensity and Cost of Transport during locomotion. A reduction of $75.86\\%$ and $63.34\\%$ of these two metrics indicate roller skating as a superior locomotion mode for enhanced energy efficiency and joint longevity.",
      "authors": [
        "Junchi Gu",
        "Feiyang Yuan",
        "Weize Shi",
        "Tianchen Huang",
        "Haopeng Zhang",
        "Xiaohu Zhang",
        "Yu Wang",
        "Wei Gao",
        "Shiwu Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 13:54:22+00:00",
      "link": "https://arxiv.org/pdf/2601.04948v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04925v1",
      "title": "Can AI-Generated Persuasion Be Detected? Persuaficial Benchmark and AI vs. Human Linguistic Differences",
      "abstract": "Large Language Models (LLMs) can generate highly persuasive text, raising concerns about their misuse for propaganda, manipulation, and other harmful purposes. This leads us to our central question: Is LLM-generated persuasion more difficult to automatically detect than human-written persuasion? To address this, we categorize controllable generation approaches for producing persuasive content with LLMs and introduce Persuaficial, a high-quality multilingual benchmark covering six languages: English, German, Polish, Italian, French and Russian. Using this benchmark, we conduct extensive empirical evaluations comparing human-authored and LLM-generated persuasive texts. We find that although overtly persuasive LLM-generated texts can be easier to detect than human-written ones, subtle LLM-generated persuasion consistently degrades automatic detection performance. Beyond detection performance, we provide the first comprehensive linguistic analysis contrasting human and LLM-generated persuasive texts, offering insights that may guide the development of more interpretable and robust detection tools.",
      "authors": [
        "Arkadiusz Modzelewski",
        "Paweł Golik",
        "Anna Kołos",
        "Giovanni Da San Martino"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 13:22:25+00:00",
      "link": "https://arxiv.org/pdf/2601.04925v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04922v1",
      "title": "AVX / NEON Intrinsic Functions: When Should They Be Used?",
      "abstract": "A cross-configuration benchmark is proposed to explore the capacities and limitations of AVX / NEON intrinsic functions in a generic context of development project, when a vectorisation strategy is required to optimise the code. The main aim is to guide developers to choose when using intrinsic functions, depending on the OS, architecture and/or available compiler. Intrinsic functions were observed highly efficient in conditional branching, with intrinsic version execution time reaching around 5% of plain code execution time. However, intrinsic functions were observed as unnecessary in many cases, as the compilers already well auto-vectorise the code.",
      "authors": [
        "Théo Boivin",
        "Joeffrey Legaux"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-08 13:21:19+00:00",
      "link": "https://arxiv.org/pdf/2601.04922v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04918v1",
      "title": "Breaking Robustness Barriers in Cognitive Diagnosis: A One-Shot Neural Architecture Search Perspective",
      "abstract": "With the advancement of network technologies, intelligent tutoring systems (ITS) have emerged to deliver increasingly precise and tailored personalized learning services. Cognitive diagnosis (CD) has emerged as a core research task in ITS, aiming to infer learners' mastery of specific knowledge concepts by modeling the mapping between learning behavior data and knowledge states. However, existing research prioritizes model performance enhancement while neglecting the pervasive noise contamination in observed response data, significantly hindering practical deployment. Furthermore, current cognitive diagnosis models (CDMs) rely heavily on researchers' domain expertise for structural design, which fails to exhaustively explore architectural possibilities, thus leaving model architectures' full potential untapped. To address this issue, we propose OSCD, an evolutionary multi-objective One-Shot neural architecture search method for Cognitive Diagnosis, designed to efficiently and robustly improve the model's capability in assessing learner proficiency. Specifically, OSCD operates through two distinct stages: training and searching. During the training stage, we construct a search space encompassing diverse architectural combinations and train a weight-sharing supernet represented via the complete binary tree topology, enabling comprehensive exploration of potential architectures beyond manual design priors. In the searching stage, we formulate the optimal architecture search under heterogeneous noise scenarios as a multi-objective optimization problem (MOP), and develop an optimization framework integrating a Pareto-optimal solution search strategy with cross-scenario performance evaluation for resolution. Extensive experiments on real-world educational datasets validate the effectiveness and robustness of the optimal architectures discovered by our OSCD model for CD tasks.",
      "authors": [
        "Ziwen Wang",
        "Shangshang Yang",
        "Xiaoshan Yu",
        "Haiping Ma",
        "Xingyi Zhang"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-08 13:17:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04918v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04915v1",
      "title": "OnomaCompass: A Texture Exploration Interface that Shuttles between Words and Images",
      "abstract": "Humans can finely perceive material textures, yet articulating such somatic impressions in words is a cognitive bottleneck in design ideation. We present OnomaCompass, a web-based exploration system that links sound-symbolic onomatopoeia and visual texture representations to support early-stage material discovery. Instead of requiring users to craft precise prompts for generative AI, OnomaCompass provides two coordinated latent-space maps--one for texture images and one for onomatopoeic term--built from an authored dataset of invented onomatopoeia and corresponding textures generated via Stable Diffusion. Users can navigate both spaces, trigger cross-modal highlighting, curate findings in a gallery, and preview textures applied to objects via an image-editing model. The system also supports video interpolation between selected textures and re-embedding of extracted frames to form an emergent exploration loop. We conducted a within-subjects study with 11 participants comparing OnomaCompass to a prompt-based image-generation workflow using Gemini 2.5 Flash Image (\"Nano Banana\"). OnomaCompass significantly reduced workload (NASA-TLX overall, mental demand, effort, and frustration; p < .05) and increased hedonic user experience (UEQ), while usability (SUS) favored the baseline. Qualitative findings indicate that OnomaCompass helps users externalize vague sensory expectations and promotes serendipitous discovery, but also reveals interaction challenges in spatial navigation. Overall, leveraging sound symbolism as a lightweight cue offers a complementary approach to Kansei-driven material ideation beyond prompt-centric generation.",
      "authors": [
        "Miki Okamura",
        "Shuhey Koyama",
        "Li Jingjing",
        "Yoichi Ochiai"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-08 13:13:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04915v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04912v1",
      "title": "Decentralized Privacy-Preserving Federal Learning of Computer Vision Models on Edge Devices",
      "abstract": "Collaborative training of a machine learning model comes with a risk of sharing sensitive or private data. Federated learning offers a way of collectively training a single global model without the need to share client data, by sharing only the updated parameters from each client's local model. A central server is then used to aggregate parameters from all clients and redistribute the aggregated model back to the clients. Recent findings have shown that even in this scenario, private data can be reconstructed only using information about model parameters. Current efforts to mitigate this are mainly focused on reducing privacy risks on the server side, assuming that other clients will not act maliciously. In this work, we analyzed various methods for improving the privacy of client data concerning both the server and other clients for neural networks. Some of these methods include homomorphic encryption, gradient compression, gradient noising, and discussion on possible usage of modified federated learning systems such as split learning, swarm learning or fully encrypted models. We have analyzed the negative effects of gradient compression and gradient noising on the accuracy of convolutional neural networks used for classification. We have shown the difficulty of data reconstruction in the case of segmentation networks. We have also implemented a proof of concept on the NVIDIA Jetson TX2 module used in edge devices and simulated a federated learning process.",
      "authors": [
        "Damian Harenčák",
        "Lukáš Gajdošech",
        "Martin Madaras"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.CV"
      ],
      "published": "2026-01-08 13:10:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04912v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04899v1",
      "title": "Rotation-Robust Regression with Convolutional Model Trees",
      "abstract": "We study rotation-robust learning for image inputs using Convolutional Model Trees (CMTs) [1], whose split and leaf coefficients can be structured on the image grid and transformed geometrically at deployment time. In a controlled MNIST setting with a rotation-invariant regression target, we introduce three geometry-aware inductive biases for split directions -- convolutional smoothing, a tilt dominance constraint, and importance-based pruning -- and quantify their impact on robustness under in-plane rotations. We further evaluate a deployment-time orientation search that selects a discrete rotation maximizing a forest-level confidence proxy without updating model parameters. Orientation search improves robustness under severe rotations but can be harmful near the canonical orientation when confidence is misaligned with correctness. Finally, we observe consistent trends on MNIST digit recognition implemented as one-vs-rest regression, highlighting both the promise and limitations of confidence-based orientation selection for model-tree ensembles.",
      "authors": [
        "Hongyi Li",
        "William Ward Armstrong",
        "Jun Xu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 12:53:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04899v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04897v1",
      "title": "V-FAT: Benchmarking Visual Fidelity Against Text-bias",
      "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated impressive performance on standard visual reasoning benchmarks. However, there is growing concern that these models rely excessively on linguistic shortcuts rather than genuine visual grounding, a phenomenon we term Text Bias. In this paper, we investigate the fundamental tension between visual perception and linguistic priors. We decouple the sources of this bias into two dimensions: Internal Corpus Bias, stemming from statistical correlations in pretraining, and External Instruction Bias, arising from the alignment-induced tendency toward sycophancy. To quantify this effect, we introduce V-FAT (Visual Fidelity Against Text-bias), a diagnostic benchmark comprising 4,026 VQA instances across six semantic domains. V-FAT employs a Three-Level Evaluation Framework that systematically increases the conflict between visual evidence and textual information: (L1) internal bias from atypical images, (L2) external bias from misleading instructions, and (L3) synergistic bias where both coincide. We introduce the Visual Robustness Score (VRS), a metric designed to penalize \"lucky\" linguistic guesses and reward true visual fidelity. Our evaluation of 12 frontier MLLMs reveals that while models excel in existing benchmarks, they experience significant visual collapse under high linguistic dominance.",
      "authors": [
        "Ziteng Wang",
        "Yujie He",
        "Guanliang Li",
        "Siqi Yang",
        "Jiaqi Xiong",
        "Songxiang Liu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "published": "2026-01-08 12:50:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04897v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04895v1",
      "title": "DVD: A Robust Method for Detecting Variant Contamination in Large Language Model Evaluation",
      "abstract": "Evaluating large language models (LLMs) is increasingly confounded by \\emph{variant contamination}: the training corpus contains semantically equivalent yet lexically or syntactically altered versions of test items. Unlike verbatim leakage, these paraphrased or structurally transformed variants evade existing detectors based on sampling consistency or perplexity, thereby inflating benchmark scores via memorization rather than genuine reasoning. We formalize this problem and introduce \\textbf{DVD} (\\textbf{D}etection via \\textbf{V}ariance of generation \\textbf{D}istribution), a single-sample detector that models the local output distribution induced by temperature sampling. Our key insight is that contaminated items trigger alternation between a \\emph{memory-adherence} state and a \\emph{perturbation-drift} state, yielding abnormally high variance in the synthetic difficulty of low-probability tokens; uncontaminated items remain in drift with comparatively smooth variance. We construct the first benchmark for variant contamination across two domains Omni-MATH and SuperGPQA by generating and filtering semantically equivalent variants, and simulate contamination via fine-tuning models of different scales and architectures (Qwen2.5 and Llama3.1). Across datasets and models, \\textbf{DVD} consistently outperforms perplexity-based, Min-$k$\\%++, edit-distance (CDD), and embedding-similarity baselines, while exhibiting strong robustness to hyperparameters. Our results establish variance of the generation distribution as a principled and practical fingerprint for detecting variant contamination in LLM evaluation.",
      "authors": [
        "Renzhao Liang",
        "Jingru Chen",
        "Bo Jia",
        "Bo Deng",
        "Chenggang Xie",
        "Yidong Wang",
        "Ke Jin",
        "Xin Wang",
        "Linfeng Zhang",
        "Cunxiang Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 12:48:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04895v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04887v1",
      "title": "Flexible Manufacturing Systems Intralogistics: Dynamic Optimization of AGVs and Tool Sharing Using Coloured-Timed Petri Nets and Actor-Critic RL with Actions Masking",
      "abstract": "Flexible Manufacturing Systems (FMS) are pivotal in optimizing production processes in today's rapidly evolving manufacturing landscape. This paper advances the traditional job shop scheduling problem by incorporating additional complexities through the simultaneous integration of automated guided vehicles (AGVs) and tool-sharing systems. We propose a novel approach that combines Colored-Timed Petri Nets (CTPNs) with actor-critic model-based reinforcement learning (MBRL), effectively addressing the multifaceted challenges associated with FMS. CTPNs provide a formal modeling structure and dynamic action masking, significantly reducing the action search space, while MBRL ensures adaptability to changing environments through the learned policy. Leveraging the advantages of MBRL, we incorporate a lookahead strategy for optimal positioning of AGVs, improving operational efficiency. Our approach was evaluated on small-sized public benchmarks and a newly developed large-scale benchmark inspired by the Taillard benchmark. The results show that our approach matches traditional methods on smaller instances and outperforms them on larger ones in terms of makespan while achieving a tenfold reduction in computation time. To ensure reproducibility, we propose a gym-compatible environment and an instance generator. Additionally, an ablation study evaluates the contribution of each framework component to its overall performance.",
      "authors": [
        "Sofiene Lassoued",
        "Laxmikant Shrikant Bahetic",
        "Nathalie Weiß-Borkowskib",
        "Stefan Lierc",
        "Andreas Schwunga"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 12:37:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04887v1",
      "tags": [
        "keyword:RL",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04881v1",
      "title": "Zero Wrench Control via Wrench Disturbance Observer for Learning-free Peg-in-hole Assembly",
      "abstract": "This paper proposes a Dynamic Wrench Disturbance Observer (DW-DOB) designed to achieve highly sensitive zero-wrench control in contact-rich manipulation. By embedding task-space inertia into the observer nominal model, DW-DOB cleanly separates intrinsic dynamic reactions from true external wrenches. This preserves sensitivity to small forces and moments while ensuring robust regulation of contact wrenches. A passivity-based analysis further demonstrates that DW-DOB guarantees stable interactions under dynamic conditions, addressing the shortcomings of conventional observers that fail to compensate for inertial effects. Peg-in-hole experiments at industrial tolerances (H7/h6) validate the approach, yielding deeper and more compliant insertions with minimal residual wrenches and outperforming a conventional wrench disturbance observer and a PD baseline. These results highlight DW-DOB as a practical learning-free solution for high-precision zero-wrench control in contact-rich tasks.",
      "authors": [
        "Kiyoung Choi",
        "Juwon Jeong",
        "Sehoon Oh"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 12:29:21+00:00",
      "link": "https://arxiv.org/pdf/2601.04881v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04876v1",
      "title": "ChronosAudio: A Comprehensive Long-Audio Benchmark for Evaluating Audio-Large Language Models",
      "abstract": "Although Audio Large Language Models (ALLMs) have witnessed substantial advancements, their long audio understanding capabilities remain unexplored. A plethora of benchmarks have been proposed for general audio tasks, they predominantly focus on short-form clips, leaving without a consensus on evaluating ALLMs over extended durations. This paper proposes ChronosAudio, the first multi-task benchmark tailored for long-audio understanding in ALLMs. It encompasses six major task categories and comprises 36,000 test instances totaling over 200 hours audio, stratified into short, middle, and long-form categories to comprehensively evaluate length generalization. Extensive experiments on 16 state-of-the-art models using ChronosAudio yield three critical findings: 1.Precipitous Long-Context Collapse: ALLMs exhibit a severe inability to sustain performance, with the transition from short to long contexts triggering a staggering performance degradation of over 90% in specific tasks. 2.Structural Attention Dilution: Performance degradation stems from a fundamental failure in maintaining temporal locality; attention mechanisms suffer from significant diffusion in later sequences. 3.Restorative Ceiling of Mitigation: Current strategies only offer 50% recovery. These findings reveal significant challenges in long-audio, underscoring the urgent need for approaches to achieve robust, document-level audio reasoning.",
      "authors": [
        "Kaiwen Luo",
        "Liang Lin",
        "Yibo Zhang",
        "Moayad Aloqaily",
        "Dexian Wang",
        "Zhenhong Zhou",
        "Junwei Zhang",
        "Kun Wang",
        "Li Sun",
        "Qingsong Wen"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD"
      ],
      "published": "2026-01-08 12:21:09+00:00",
      "link": "https://arxiv.org/pdf/2601.04876v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04873v1",
      "title": "FibreCastML: An Open Web Platform for Predicting Electrospun Nanofibre Diameter Distributions",
      "abstract": "Electrospinning is a scalable technique for producing fibrous scaffolds with tunable micro- and nanoscale architectures for applications in tissue engineering, drug delivery, and wound care. While machine learning (ML) has been used to support electrospinning process optimisation, most existing approaches predict only mean fibre diameters, neglecting the full diameter distribution that governs scaffold performance. This work presents FibreCastML, an open, distribution-aware ML framework that predicts complete fibre diameter spectra from routinely reported electrospinning parameters and provides interpretable insights into process structure relationships.   A meta-dataset comprising 68538 individual fibre diameter measurements extracted from 1778 studies across 16 biomedical polymers was curated. Six standard processing parameters, namely solution concentration, applied voltage, flow rate, tip to collector distance, needle diameter, and collector rotation speed, were used to train seven ML models using nested cross validation with leave one study out external folds. Model interpretability was achieved using variable importance analysis, SHapley Additive exPlanations, correlation matrices, and three dimensional parameter maps.   Non linear models consistently outperformed linear baselines, achieving coefficients of determination above 0.91 for several widely used polymers. Solution concentration emerged as the dominant global driver of fibre diameter distributions. Experimental validation across different electrospinning systems demonstrated close agreement between predicted and measured distributions. FibreCastML enables more reproducible and data driven optimisation of electrospun scaffold architectures.",
      "authors": [
        "Elisa Roldan",
        "Kirstie Andrews",
        "Stephen M. Richardson",
        "Reyhaneh Fatahian",
        "Glen Cooper",
        "Rasool Erfani",
        "Tasneem Sabir",
        "Neil D. Reeves"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 12:18:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04873v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04867v1",
      "title": "Gradient-based Optimisation of Modulation Effects",
      "abstract": "Modulation effects such as phasers, flangers and chorus effects are heavily used in conjunction with the electric guitar. Machine learning based emulation of analog modulation units has been investigated in recent years, but most methods have either been limited to one class of effect or suffer from a high computational cost or latency compared to canonical digital implementations. Here, we build on previous work and present a framework for modelling flanger, chorus and phaser effects based on differentiable digital signal processing. The model is trained in the time-frequency domain, but at inference operates in the time-domain, requiring zero latency. We investigate the challenges associated with gradient-based optimisation of such effects, and show that low-frequency weighting of loss functions avoids convergence to local minima when learning delay times. We show that when trained against analog effects units, sound output from the model is in some cases perceptually indistinguishable from the reference, but challenges still remain for effects with long delay times and feedback.",
      "authors": [
        "Alistair Carson",
        "Alec Wright",
        "Stefan Bilbao"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.LG",
        "cs.SD"
      ],
      "published": "2026-01-08 12:04:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04867v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04862v1",
      "title": "Wireless Communication with Cross-Linked Rotatable Antenna Array: Architecture Design and Rotation Optimization",
      "abstract": "Rotatable antenna (RA) technology can harness additional spatial degrees of freedom by enabling the dynamic three-dimensional orientation control of each antenna. Unfortunately, the hardware cost and control complexity of traditional RA systems is proportional to the number of RAs. To address the issue, we consider a cross-linked (CL) RA structure, which enables the coordinated rotation of multiple antennas, thereby offering a cost-effective solution. To evaluate the performance of the CL-RA array, we investigate a CL-RA-aided uplink system. Specifically, we first establish system models for both antenna element-level and antenna panel-level rotation. Then, we formulate a sum rate maximization problem by jointly optimizing the receive beamforming at the base station and the rotation angles. For the antenna element-level rotation, we derive the optimal solution of the CL-RA array under the single-user case. Subsequently, for two rotation schemes, we propose an alternating optimization algorithm to solve the formulated problem in the multi-user case, where the receive beamforming and the antenna rotation angles are obtained by applying the minimum mean square error method and feasible direction method, respectively. In addition, considering the hardware limitations, we apply the genetic algorithm to address the discrete rotation angles selection problem. Simulation results show that by carefully designing the row-column partition scheme, the performance of the CL-RA architecture is quite close to that of the flexible antenna orientation scheme. Moreover, the CL antenna element-level scheme surpasses the CL antenna panel-level scheme by 25% and delivers a 128% performance improvement over conventional fixed-direction antennas.",
      "authors": [
        "Ailing Zheng",
        "Qingqing Wu",
        "Ziyuan Zheng",
        "Qiaoyan Peng",
        "Yanze Zhu",
        "Honghao Wang",
        "Wen Chen",
        "Guoying Zhang"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-08 11:57:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04862v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04861v1",
      "title": "Orchestrating Intelligence: Confidence-Aware Routing for Efficient Multi-Agent Collaboration across Multi-Scale Models",
      "abstract": "While multi-agent systems (MAS) have demonstrated superior performance over single-agent approaches in complex reasoning tasks, they often suffer from significant computational inefficiencies. Existing frameworks typically deploy large language models (LLMs) uniformly across all agent roles, failing to account for the varying cognitive demands of different reasoning stages. We address this inefficiency by proposing OI-MAS framework, a novel multi-agent framework that implements an adaptive model-selection policy across a heterogeneous pool of multi-scale LLMs. Specifically, OI-MAS introduces a state-dependent routing mechanism that dynamically selects agent roles and model scales throughout the reasoning process. In addition, we introduce a confidence-aware mechanism that selects appropriate model scales conditioned on task complexity, thus reducing unnecessary reliance on large-scale models. Experimental results show that OI-MAS consistently outperforms baseline multi-agent systems, improving accuracy by up to 12.88\\% while reducing cost by up to 79.78\\%.",
      "authors": [
        "Jingbo Wang",
        "Sendong Zhao",
        "Jiatong Liu",
        "Haochun Wang",
        "Wanting Li",
        "Bing Qin",
        "Ting Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 11:56:09+00:00",
      "link": "https://arxiv.org/pdf/2601.04861v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04855v1",
      "title": "Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution",
      "abstract": "Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.",
      "authors": [
        "Francesco Ferrini",
        "Veronica Lachi",
        "Antonio Longa",
        "Bruno Lepri",
        "Matono Akiyoshi",
        "Andrea Passerini",
        "Xin Liu",
        "Manfred Jaeger"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 11:45:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04855v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04853v1",
      "title": "RAAR: Retrieval Augmented Agentic Reasoning for Cross-Domain Misinformation Detection",
      "abstract": "Cross-domain misinformation detection is challenging, as misinformation arises across domains with substantial differences in knowledge and discourse. Existing methods often rely on single-perspective cues and struggle to generalize to challenging or underrepresented domains, while reasoning large language models (LLMs), though effective on complex tasks, are limited to same-distribution data. To address these gaps, we introduce RAAR, the first retrieval-augmented agentic reasoning framework for cross-domain misinformation detection. To enable cross-domain transfer beyond same-distribution assumptions, RAAR retrieves multi-perspective source-domain evidence aligned with each target sample's semantics, sentiment, and writing style. To overcome single-perspective modeling and missing systematic reasoning, RAAR constructs verifiable multi-step reasoning paths through specialized multi-agent collaboration, where perspective-specific agents produce complementary analyses and a summary agent integrates them under verifier guidance. RAAR further applies supervised fine-tuning and reinforcement learning to train a single multi-task verifier to enhance verification and reasoning capabilities. Based on RAAR, we trained the RAAR-8b and RAAR-14b models. Evaluation on three cross-domain misinformation detection tasks shows that RAAR substantially enhances the capabilities of the base models and outperforms other cross-domain methods, advanced LLMs, and LLM-based adaptation approaches. The project will be released at https://github.com/lzw108/RAAR.",
      "authors": [
        "Zhiwei Liu",
        "Runteng Guo",
        "Baojie Qu",
        "Yuechen Jiang",
        "Min Peng",
        "Qianqian Xie",
        "Sophia Ananiadou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 11:43:16+00:00",
      "link": "https://arxiv.org/pdf/2601.04853v1",
      "tags": [
        "keyword:RL",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04842v1",
      "title": "Intelligent resource allocation in wireless networks via deep reinforcement learning",
      "abstract": "This study addresses the challenge of optimal power allocation in stochastic wireless networks by employing a Deep Reinforcement Learning (DRL) framework. Specifically, we design a Deep Q-Network (DQN) agent capable of learning adaptive power control policies directly from channel state observations, effectively bypassing the need for explicit system models. We formulate the resource allocation problem as a Markov Decision Process (MDP) and benchmark the proposed approach against classical heuristics, including fixed allocation, random assignment, and the theoretical water-filling algorithm. Empirical results demonstrate that the DQN agent achieves a system throughput of 3.88 Mbps, effectively matching the upper limit of the water fill, while outperforming the random and fixed allocation strategies by approximately 73% and 27%, respectively. Moreover, the agent exhibits emergent fairness, maintaining a Jain's Index of 0.91, and successfully optimizes the trade-off between spectral efficiency and energy consumption. These findings substantiate the efficacy of model-free DRL as a robust and scalable solution for resource management in next-generation communication systems.",
      "authors": [
        "Marie Diane Iradukunda",
        "Chabi F. Elégbédé",
        "Yaé Ulrich Gaba"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-01-08 11:22:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04842v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04824v1",
      "title": "SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models",
      "abstract": "Automatic identification of events and recurrent behavior analysis are critical for video surveillance. However, most existing content-based video retrieval benchmarks focus on scene-level similarity and do not evaluate the action discrimination required in surveillance. To address this gap, we introduce SOVABench (Surveillance Opposite Vehicle Actions Benchmark), a real-world retrieval benchmark built from surveillance footage and centered on vehicle-related actions. SOVABench defines two evaluation protocols (inter-pair and intra-pair) to assess cross-action discrimination and temporal direction understanding. Although action distinctions are generally intuitive for human observers, our experiments show that they remain challenging for state-of-the-art vision and multimodal models.   Leveraging the visual reasoning and instruction-following capabilities of Multimodal Large Language Models (MLLMs), we present a training-free framework for producing interpretable embeddings from MLLM-generated descriptions for both images and videos. The framework achieves strong performance on SOVABench as well as on several spatial and counting benchmarks where contrastive Vision-Language Models often fail. The code, annotations, and instructions to construct the benchmark are publicly available.",
      "authors": [
        "Oriol Rabasseda",
        "Zenjie Li",
        "Kamal Nasrollahi",
        "Sergio Escalera"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 10:58:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04824v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04813v1",
      "title": "Proof of Commitment: A Human-Centric Resource for Permissionless Consensus",
      "abstract": "Permissionless consensus protocols require a scarce resource to regulate leader election and provide Sybil resistance. Existing paradigms such as Proof of Work and Proof of Stake instantiate this scarcity through parallelizable resources like computation or capital. Once acquired, these resources can be subdivided across many identities at negligible marginal cost, making linear Sybil cost fundamentally unattainable.   We introduce Proof of Commitment (PoCmt), a consensus primitive grounded in a non-parallelizable resource: real-time human engagement. Validators maintain a commitment state capturing cumulative human effort, protocol participation, and online availability. Engagement is enforced through a Human Challenge Oracle that issues identity-bound, time-sensitive challenges, limiting the number of challenges solvable within each human window.   Under this model, sustaining multiple active identities requires proportional human-time effort. We establish a cost-theoretic separation showing that protocols based on parallelizable resources admit zero marginal Sybil cost, whereas PoCmt enforces a strictly linear cost profile. Using a weighted-backbone analysis, we show that PoCmt achieves safety, liveness, and commitment-proportional fairness under partial synchrony.   Simulations complement the analysis by isolating human-time capacity as the sole adversarial bottleneck and validating the predicted commitment drift and fairness properties. These results position PoCmt as a new point in the consensus design space, grounding permissionless security in sustained human effort rather than computation or capital.",
      "authors": [
        "Homayoun Maleki",
        "Nekane Sainz",
        "Jon Legarda"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC"
      ],
      "published": "2026-01-08 10:46:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04813v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04809v1",
      "title": "SCALER:Synthetic Scalable Adaptive Learning Environment for Reasoning",
      "abstract": "Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while preserving strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward sparsity, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.",
      "authors": [
        "Caijun Xu",
        "Changyi Xiao",
        "Zhongyuan Peng",
        "Xinrun Wang",
        "Yixin Cao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 10:42:04+00:00",
      "link": "https://arxiv.org/pdf/2601.04809v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04805v1",
      "title": "Thinking-Based Non-Thinking: Solving the Reward Hacking Problem in Training Hybrid Reasoning Models via Reinforcement Learning",
      "abstract": "Large reasoning models (LRMs) have attracted much attention due to their exceptional performance. However, their performance mainly stems from thinking, a long Chain of Thought (CoT), which significantly increase computational overhead. To address this overthinking problem, existing work focuses on using reinforcement learning (RL) to train hybrid reasoning models that automatically decide whether to engage in thinking or not based on the complexity of the query. Unfortunately, using RL will suffer the the reward hacking problem, e.g., the model engages in thinking but is judged as not doing so, resulting in incorrect rewards. To mitigate this problem, existing works either employ supervised fine-tuning (SFT), which incurs high computational costs, or enforce uniform token limits on non-thinking responses, which yields limited mitigation of the problem. In this paper, we propose Thinking-Based Non-Thinking (TNT). It does not employ SFT, and sets different maximum token usage for responses not using thinking across various queries by leveraging information from the solution component of the responses using thinking. Experiments on five mathematical benchmarks demonstrate that TNT reduces token usage by around 50% compared to DeepSeek-R1-Distill-Qwen-1.5B/7B and DeepScaleR-1.5B, while significantly improving accuracy. In fact, TNT achieves the optimal trade-off between accuracy and efficiency among all tested methods. Additionally, the probability of reward hacking problem in TNT's responses, which are classified as not using thinking, remains below 10% across all tested datasets.",
      "authors": [
        "Siyuan Gan",
        "Jiaheng Liu",
        "Boyan Wang",
        "Tianpei Yang",
        "Runqing Miao",
        "Yuyao Zhang",
        "Fanyu Meng",
        "Junlan Feng",
        "Linjian Meng",
        "Jing Huo",
        "Yang Gao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 10:38:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04805v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04801v1",
      "title": "MPM-LLM4DSE: Reaching the Pareto Frontier in HLS with Multimodal Learning and LLM-Driven Exploration",
      "abstract": "High-Level Synthesis (HLS) design space exploration (DSE) seeks Pareto-optimal designs within expansive pragma configuration spaces. To accelerate HLS DSE, graph neural networks (GNNs) are commonly employed as surrogates for HLS tools to predict quality of results (QoR) metrics, while multi-objective optimization algorithms expedite the exploration. However, GNN-based prediction methods may not fully capture the rich semantic features inherent in behavioral descriptions, and conventional multi-objective optimization algorithms often do not explicitly account for the domain-specific knowledge regarding how pragma directives influence QoR. To address these limitations, this paper proposes the MPM-LLM4DSE framework, which incorporates a multimodal prediction model (MPM) that simultaneously fuses features from behavioral descriptions and control and data flow graphs. Furthermore, the framework employs a large language model (LLM) as an optimizer, accompanied by a tailored prompt engineering methodology. This methodology incorporates pragma impact analysis on QoR to guide the LLM in generating high-quality configurations (LLM4DSE). Experimental results demonstrate that our multimodal predictive model significantly outperforms state-of-the-art work ProgSG by up to 10.25$\\times$. Furthermore, in DSE tasks, the proposed LLM4DSE achieves an average performance gain of 39.90\\% over prior methods, validating the effectiveness of our prompting methodology. Code and models are available at https://github.com/wslcccc/MPM-LLM4DSE.",
      "authors": [
        "Lei Xu",
        "Shanshan Wang",
        "Chenglong Xiao"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR",
        "cs.LG"
      ],
      "published": "2026-01-08 10:32:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04801v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04799v1",
      "title": "Neural-Symbolic Integration with Evolvable Policies",
      "abstract": "Neural-Symbolic (NeSy) Artificial Intelligence has emerged as a promising approach for combining the learning capabilities of neural networks with the interpretable reasoning of symbolic systems. However, existing NeSy frameworks typically require either predefined symbolic policies or policies that are differentiable, limiting their applicability when domain expertise is unavailable or when policies are inherently non-differentiable. We propose a framework that addresses this limitation by enabling the concurrent learning of both non-differentiable symbolic policies and neural network weights through an evolutionary process. Our approach casts NeSy systems as organisms in a population that evolve through mutations (both symbolic rule additions and neural weight changes), with fitness-based selection guiding convergence toward hidden target policies. The framework extends the NEUROLOG architecture to make symbolic policies trainable, adapts Valiant's Evolvability framework to the NeSy context, and employs Machine Coaching semantics for mutable symbolic representations. Neural networks are trained through abductive reasoning from the symbolic component, eliminating differentiability requirements. Through extensive experimentation, we demonstrate that NeSy systems starting with empty policies and random neural weights can successfully approximate hidden non-differentiable target policies, achieving median correct performance approaching 100%. This work represents a step toward enabling NeSy research in domains where the acquisition of symbolic knowledge from experts is challenging or infeasible.",
      "authors": [
        "Marios Thoma",
        "Vassilis Vassiliades",
        "Loizos Michael"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "published": "2026-01-08 10:29:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04799v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04794v1",
      "title": "APEX: Academic Poster Editing Agentic Expert",
      "abstract": "Designing academic posters is a labor-intensive process requiring the precise balance of high-density content and sophisticated layout. While existing paper-to-poster generation methods automate initial drafting, they are typically single-pass and non-interactive, often fail to align with complex, subjective user intent. To bridge this gap, we propose APEX (Academic Poster Editing agentic eXpert), the first agentic framework for interactive academic poster editing, supporting fine-grained control with robust multi-level API-based editing and a review-and-adjustment Mechanism. In addition, we introduce APEX-Bench, the first systematic benchmark comprising 514 academic poster editing instructions, categorized by a multi-dimensional taxonomy including operation type, difficulty, and abstraction level, constructed via reference-guided and reference-free strategies to ensure realism and diversity. We further establish a multi-dimensional VLM-as-a-judge evaluation protocol to assess instruction fulfillment, modification scope, and visual consistency & harmony. Experimental results demonstrate that APEX significantly outperforms baseline methods. Our implementation is available at https://github.com/Breesiu/APEX.",
      "authors": [
        "Chengxin Shi",
        "Qinnan Cai",
        "Zeyuan Chen",
        "Long Zeng",
        "Yibo Zhao",
        "Jing Yu",
        "Jianxiang Yu",
        "Xiang Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 10:21:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04794v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04789v1",
      "title": "NC2C: Automated Convexification of Generic Non-Convex Optimization Problems",
      "abstract": "Non-convex optimization problems are pervasive across mathematical programming, engineering design, and scientific computing, often posing intractable challenges for traditional solvers due to their complex objective functions and constrained landscapes. To address the inefficiency of manual convexification and the over-reliance on expert knowledge, we propose NC2C, an LLM-based end-to-end automated framework designed to transform generic non-convex optimization problems into solvable convex forms using large language models. NC2C leverages LLMs' mathematical reasoning capabilities to autonomously detect non-convex components, select optimal convexification strategies, and generate rigorous convex equivalents. The framework integrates symbolic reasoning, adaptive transformation techniques, and iterative validation, equipped with error correction loops and feasibility domain correction mechanisms to ensure the robustness and validity of transformed problems. Experimental results on a diverse dataset of 100 generic non-convex problems demonstrate that NC2C achieves an 89.3\\% execution rate and a 76\\% success rate in producing feasible, high-quality convex transformations. This outperforms baseline methods by a significant margin, highlighting NC2C's ability to leverage LLMs for automated non-convex to convex transformation, reduce expert dependency, and enable efficient deployment of convex solvers for previously intractable optimization tasks.",
      "authors": [
        "Xinyue Peng",
        "Yanming Liu",
        "Yihan Cang",
        "Yuwei Zhang",
        "Xinyi Wang",
        "Songhang Deng",
        "Jiannan Cao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 10:12:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04789v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04786v1",
      "title": "AgentOCR: Reimagining Agent History via Optical Self-Compression",
      "abstract": "Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual cache, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\\% of text-based agent performance while substantially reducing token consumption (>50\\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-compression.",
      "authors": [
        "Lang Feng",
        "Fuchao Yang",
        "Feng Chen",
        "Xin Cheng",
        "Haiyang Xu",
        "Zhenglin Wan",
        "Ming Yan",
        "Bo An"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 10:10:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04786v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04770v1",
      "title": "SciIF: Benchmarking Scientific Instruction Following Towards Rigorous Scientific Intelligence",
      "abstract": "As large language models (LLMs) transition from general knowledge retrieval to complex scientific discovery, their evaluation standards must also incorporate the rigorous norms of scientific inquiry. Existing benchmarks exhibit a critical blind spot: general instruction-following metrics focus on superficial formatting, while domain-specific scientific benchmarks assess only final-answer correctness, often rewarding models that arrive at the right result with the wrong reasons. To address this gap, we introduce scientific instruction following: the capability to solve problems while strictly adhering to the constraints that establish scientific validity. Specifically, we introduce SciIF, a multi-discipline benchmark that evaluates this capability by pairing university-level problems with a fixed catalog of constraints across three pillars: scientific conditions (e.g., boundary checks and assumptions), semantic stability (e.g., unit and symbol conventions), and specific processes(e.g., required numerical methods). Uniquely, SciIF emphasizes auditability, requiring models to provide explicit evidence of constraint satisfaction rather than implicit compliance. By measuring both solution correctness and multi-constraint adherence, SciIF enables finegrained diagnosis of compositional reasoning failures, ensuring that LLMs can function as reliable agents within the strict logical frameworks of science.",
      "authors": [
        "Encheng Su",
        "Jianyu Wu",
        "Chen Tang",
        "Lintao Wang",
        "Pengze Li",
        "Aoran Wang",
        "Jinouwen Zhang",
        "Yizhou Wang",
        "Yuan Meng",
        "Xinzhu Ma",
        "Shixiang Tang",
        "Houqiang Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "published": "2026-01-08 09:45:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04770v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04768v1",
      "title": "LANGSAE EDITING: Improving Multilingual Information Retrieval via Post-hoc Language Identity Removal",
      "abstract": "Dense retrieval in multilingual settings often searches over mixed-language collections, yet multilingual embeddings encode language identity alongside semantics. This language signal can inflate similarity for same-language pairs and crowd out relevant evidence written in other languages. We propose LANGSAE EDITING, a post-hoc sparse autoencoder trained on pooled embeddings that enables controllable removal of language-identity signal directly in vector space. The method identifies language-associated latent units using cross-language activation statistics, suppresses these units at inference time, and reconstructs embeddings in the original dimensionality, making it compatible with existing vector databases without retraining the base encoder or re-encoding raw text. Experiments across multiple languages show consistent improvements in ranking quality and cross-language coverage, with especially strong gains for script-distinct languages.",
      "authors": [
        "Dongjun Kim",
        "Jeongho Yoon",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-01-08 09:36:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04768v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04767v1",
      "title": "AT$^2$PO: Agentic Turn-based Policy Optimization via Tree Search",
      "abstract": "LLM agents have emerged as powerful systems for tackling multi-turn tasks by interleaving internal reasoning and external tool interactions. Agentic Reinforcement Learning has recently drawn significant research attention as a critical post-training paradigm to further refine these capabilities. In this paper, we present AT$^2$PO (Agentic Turn-based Policy Optimization via Tree Search), a unified framework for multi-turn agentic RL that addresses three core challenges: limited exploration diversity, sparse credit assignment, and misaligned policy optimization. AT$^2$PO introduces a turn-level tree structure that jointly enables Entropy-Guided Tree Expansion for strategic exploration and Turn-wise Credit Assignment for fine-grained reward propagation from sparse outcomes. Complementing this, we propose Agentic Turn-based Policy Optimization, a turn-level learning objective that aligns policy updates with the natural decision granularity of agentic interactions. ATPO is orthogonal to tree search and can be readily integrated into any multi-turn RL pipeline. Experiments across seven benchmarks demonstrate consistent improvements over the state-of-the-art baseline by up to 1.84 percentage points in average, with ablation studies validating the effectiveness of each component. Our code is available at https://github.com/zzfoutofspace/ATPO.",
      "authors": [
        "Zefang Zong",
        "Dingwei Chen",
        "Yang Li",
        "Qi Yi",
        "Bo Zhou",
        "Chengming Li",
        "Bo Qian",
        "Peng Chen",
        "Jie Jiang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 09:35:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04767v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04758v1",
      "title": "PILOT-Bench: A Benchmark for Legal Reasoning in the Patent Domain with IRAC-Aligned Classification Tasks",
      "abstract": "The Patent Trial and Appeal Board (PTAB) of the USPTO adjudicates thousands of ex parte appeals each year, requiring the integration of technical understanding and legal reasoning. While large language models (LLMs) are increasingly applied in patent and legal practice, their use has remained limited to lightweight tasks, with no established means of systematically evaluating their capacity for structured legal reasoning in the patent domain. In this work, we introduce PILOT-Bench, the first PTAB-centric benchmark that aligns PTAB decisions with USPTO patent data at the case-level and formalizes three IRAC-aligned classification tasks: Issue Type, Board Authorities, and Subdecision. We evaluate a diverse set of closed-source (commercial) and open-source LLMs and conduct analyses across multiple perspectives, including input-variation settings, model families, and error tendencies. Notably, on the Issue Type task, closed-source models consistently exceed 0.75 in Micro-F1 score, whereas the strongest open-source model (Qwen-8B) achieves performance around 0.56, highlighting a substantial gap in reasoning capabilities. PILOT-Bench establishes a foundation for the systematic evaluation of patent-domain legal reasoning and points toward future directions for improving LLMs through dataset design and model alignment. All data, code, and benchmark resources are available at https://github.com/TeamLab/pilot-bench.",
      "authors": [
        "Yehoon Jang",
        "Chaewon Lee",
        "Hyun-seok Min",
        "Sungchul Choi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 09:26:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04758v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04745v1",
      "title": "KnowMe-Bench: Benchmarking Person Understanding for Lifelong Digital Companions",
      "abstract": "Existing long-horizon memory benchmarks mostly use multi-turn dialogues or synthetic user histories, which makes retrieval performance an imperfect proxy for person understanding. We present \\BenchName, a publicly releasable benchmark built from long-form autobiographical narratives, where actions, context, and inner thoughts provide dense evidence for inferring stable motivations and decision principles. \\BenchName~reconstructs each narrative into a flashback-aware, time-anchored stream and evaluates models with evidence-linked questions spanning factual recall, subjective state attribution, and principle-level reasoning. Across diverse narrative sources, retrieval-augmented systems mainly improve factual accuracy, while errors persist on temporally grounded explanations and higher-level inferences, highlighting the need for memory mechanisms beyond retrieval. Our data is in \\href{KnowMeBench}{https://github.com/QuantaAlpha/KnowMeBench}.",
      "authors": [
        "Tingyu Wu",
        "Zhisheng Chen",
        "Ziyan Weng",
        "Shuhe Wang",
        "Chenglong Li",
        "Shuo Zhang",
        "Sen Hu",
        "Silin Wu",
        "Qizhen Lan",
        "Huacan Wang",
        "Ronghao Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-01-08 09:11:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04745v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04736v1",
      "title": "AM$^3$Safety: Towards Data Efficient Alignment of Multi-modal Multi-turn Safety for MLLMs",
      "abstract": "Multi-modal Large Language Models (MLLMs) are increasingly deployed in interactive applications. However, their safety vulnerabilities become pronounced in multi-turn multi-modal scenarios, where harmful intent can be gradually reconstructed across turns, and security protocols fade into oblivion as the conversation progresses. Existing Reinforcement Learning from Human Feedback (RLHF) alignment methods are largely developed for single-turn visual question-answer (VQA) task and often require costly manual preference annotations, limiting their effectiveness and scalability in dialogues. To address this challenge, we present InterSafe-V, an open-source multi-modal dialogue dataset containing 11,270 dialogues and 500 specially designed refusal VQA samples. This dataset, constructed through interaction between several models, is designed to more accurately reflect real-world scenarios and includes specialized VQA pairs tailored for specific domains. Building on this dataset, we propose AM$^3$Safety, a framework that combines a cold-start refusal phase with Group Relative Policy Optimization (GRPO) fine-tuning using turn-aware dual-objective rewards across entire dialogues. Experiments on Qwen2.5-VL-7B-Instruct and LLaVA-NeXT-7B show more than 10\\% decrease in Attack Success Rate (ASR) together with an increment of at least 8\\% in harmless dimension and over 13\\% in helpful dimension of MLLMs on multi-modal multi-turn safety benchmarks, while preserving their general abilities.",
      "authors": [
        "Han Zhu",
        "Jiale Chen",
        "Chengkun Cai",
        "Shengjie Sun",
        "Haoran Li",
        "Yujin Zhou",
        "Chi-Min Chan",
        "Pengcheng Wen",
        "Lei Li",
        "Sirui Han",
        "Yike Guo"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 08:57:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04736v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04732v1",
      "title": "The Role of Quantum in Hybrid Quantum-Classical Neural Networks: A Realistic Assessment",
      "abstract": "Quantum machine learning has emerged as a promising application domain for near-term quantum hardware, particularly through hybrid quantum-classical models that leverage both classical and quantum processing. Although numerous hybrid architectures have been proposed and demonstrated successfully on benchmark tasks, a significant open question remains regarding the specific contribution of quantum components to the overall performance of these models. In this work, we aim to shed light on the impact of quantum processing within hybrid quantum-classical neural network architectures through a rigorous statistical study. We systematically assess common hybrid models on medical signal data as well as planar and volumetric images, examining the influence attributable to classical and quantum aspects such as encoding schemes, entanglement, and circuit size. We find that in best-case scenarios, hybrid models show performance comparable to their classical counterparts, however, in most cases, performance metrics deteriorate under the influence of quantum components. Our multi-modal analysis provides realistic insights into the contributions of quantum components and advocates for cautious claims and design choices for hybrid models in near-term applications.",
      "authors": [
        "Dominik Freinberger",
        "Philipp Moser"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 08:54:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04732v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04728v1",
      "title": "Excess Description Length of Learning Generalizable Predictors",
      "abstract": "Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.",
      "authors": [
        "Elizabeth Donoway",
        "Hailey Joren",
        "Fabien Roger",
        "Jan Leike"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 08:46:42+00:00",
      "link": "https://arxiv.org/pdf/2601.04728v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04727v1",
      "title": "Training a Custom CNN on Five Heterogeneous Image Datasets",
      "abstract": "Deep learning has transformed visual data analysis, with Convolutional Neural Networks (CNNs) becoming highly effective in learning meaningful feature representations directly from images. Unlike traditional manual feature engineering methods, CNNs automatically extract hierarchical visual patterns, enabling strong performance across diverse real-world contexts. This study investigates the effectiveness of CNN-based architectures across five heterogeneous datasets spanning agricultural and urban domains: mango variety classification, paddy variety identification, road surface condition assessment, auto-rickshaw detection, and footpath encroachment monitoring. These datasets introduce varying challenges, including differences in illumination, resolution, environmental complexity, and class imbalance, necessitating adaptable and robust learning models.   We evaluate a lightweight, task-specific custom CNN alongside established deep architectures, including ResNet-18 and VGG-16, trained both from scratch and using transfer learning. Through systematic preprocessing, augmentation, and controlled experimentation, we analyze how architectural complexity, model depth, and pre-training influence convergence, generalization, and performance across datasets of differing scale and difficulty. The key contributions of this work are: (1) the development of an efficient custom CNN that achieves competitive performance across multiple application domains, and (2) a comprehensive comparative analysis highlighting when transfer learning and deep architectures provide substantial advantages, particularly in data-constrained environments. These findings offer practical insights for deploying deep learning models in resource-limited yet high-impact real-world visual classification tasks.",
      "authors": [
        "Anika Tabassum",
        "Tasnuva Mahazabin Tuba",
        "Nafisa Naznin"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.NE"
      ],
      "published": "2026-01-08 08:44:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04727v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04720v1",
      "title": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking",
      "abstract": "In this report, we introduce the Qwen3-VL-Embedding and Qwen3-VL-Reranker model series, the latest extensions of the Qwen family built on the Qwen3-VL foundation model. Together, they provide an end-to-end pipeline for high-precision multimodal search by mapping diverse modalities, including text, images, document images, and video, into a unified representation space. The Qwen3-VL-Embedding model employs a multi-stage training paradigm, progressing from large-scale contrastive pre-training to reranking model distillation, to generate semantically rich high-dimensional vectors. It supports Matryoshka Representation Learning, enabling flexible embedding dimensions, and handles inputs up to 32k tokens. Complementing this, Qwen3-VL-Reranker performs fine-grained relevance estimation for query-document pairs using a cross-encoder architecture with cross-attention mechanisms. Both model series inherit the multilingual capabilities of Qwen3-VL, supporting more than 30 languages, and are released in $\\textbf{2B}$ and $\\textbf{8B}$ parameter sizes to accommodate diverse deployment requirements. Empirical evaluations demonstrate that the Qwen3-VL-Embedding series achieves state-of-the-art results across diverse multimodal embedding evaluation benchmarks. Specifically, Qwen3-VL-Embedding-8B attains an overall score of $\\textbf{77.8}$ on MMEB-V2, ranking first among all models (as of January 8, 2025). This report presents the architecture, training methodology, and practical capabilities of the series, demonstrating their effectiveness on various multimodal retrieval tasks, including image-text retrieval, visual question answering, and video-text matching.",
      "authors": [
        "Mingxin Li",
        "Yanzhao Zhang",
        "Dingkun Long",
        "Keqin Chen",
        "Sibo Song",
        "Shuai Bai",
        "Zhibo Yang",
        "Pengjun Xie",
        "An Yang",
        "Dayiheng Liu",
        "Jingren Zhou",
        "Junyang Lin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 08:36:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04720v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04719v1",
      "title": "GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models",
      "abstract": "The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior",
      "authors": [
        "Maanas Taneja",
        "Purab Shingvi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.PF"
      ],
      "published": "2026-01-08 08:35:56+00:00",
      "link": "https://arxiv.org/pdf/2601.04719v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04716v1",
      "title": "Fame Fades, Nature Remains: Disentangling the Character Identity of Role-Playing Agents",
      "abstract": "Despite the rapid proliferation of Role-Playing Agents (RPAs) based on Large Language Models (LLMs), the structural dimensions defining a character's identity remain weakly formalized, often treating characters as arbitrary text inputs. In this paper, we propose the concept of \\textbf{Character Identity}, a multidimensional construct that disentangles a character into two distinct layers: \\textbf{(1) Parametric Identity}, referring to character-specific knowledge encoded from the LLM's pre-training, and \\textbf{(2) Attributive Identity}, capturing fine-grained behavioral properties such as personality traits and moral values. To systematically investigate these layers, we construct a unified character profile schema and generate both Famous and Synthetic characters under identical structural constraints. Our evaluation across single-turn and multi-turn interactions reveals two critical phenomena. First, we identify \\textit{\"Fame Fades\"}: while famous characters hold a significant advantage in initial turns due to parametric knowledge, this edge rapidly vanishes as models prioritize accumulating conversational context over pre-trained priors. Second, we find that \\textit{\"Nature Remains\"}: while models robustly portray general personality traits regardless of polarity, RPA performance is highly sensitive to the valence of morality and interpersonal relationships. Our findings pinpoint negative social natures as the primary bottleneck in RPA fidelity, guiding future character construction and evaluation.",
      "authors": [
        "Yonghyun Jun",
        "Junhyuk Choi",
        "Jihyeong Park",
        "Hwanhee Lee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 08:33:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04716v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04714v1",
      "title": "ThinkDrive: Chain-of-Thought Guided Progressive Reinforcement Learning Fine-Tuning for Autonomous Driving",
      "abstract": "With the rapid advancement of large language models (LLMs) technologies, their application in the domain of autonomous driving has become increasingly widespread. However, existing methods suffer from unstructured reasoning, poor generalization, and misalignment with human driving intent. While Chain-of-Thought (CoT) reasoning enhances decision transparency, conventional supervised fine-tuning (SFT) fails to fully exploit its potential, and reinforcement learning (RL) approaches face instability and suboptimal reasoning depth. We propose ThinkDrive, a CoT guided progressive RL fine-tuning framework for autonomous driving that synergizes explicit reasoning with difficulty-aware adaptive policy optimization. Our method employs a two-stage training strategy. First, we perform SFT using CoT explanations. Then, we apply progressive RL with a difficulty-aware adaptive policy optimizer that dynamically adjusts learning intensity based on sample complexity. We evaluate our approach on a public dataset. The results show that ThinkDrive outperforms strong RL baselines by 1.45%, 1.95%, and 1.01% on exam, easy-exam, and accuracy, respectively. Moreover, a 2B-parameter model trained with our method surpasses the much larger GPT-4o by 3.28% on the exam metric.",
      "authors": [
        "Chang Zhao",
        "Zheming Yang",
        "Yunqing Hu",
        "Qi Guo",
        "Zijian Wang",
        "Pengcheng Li",
        "Wen Ji"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 08:30:36+00:00",
      "link": "https://arxiv.org/pdf/2601.04714v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04710v1",
      "title": "Prior-Informed Zeroth-Order Optimization with Adaptive Direction Alignment for Memory-Efficient LLM Fine-Tuning",
      "abstract": "Fine-tuning large language models (LLMs) has achieved remarkable success across various NLP tasks, but the substantial memory overhead during backpropagation remains a critical bottleneck, especially as model scales grow. Zeroth-order (ZO) optimization alleviates this issue by estimating gradients through forward passes and Gaussian sampling, avoiding the need for backpropagation. However, conventional ZO methods suffer from high variance in gradient estimation due to their reliance on random perturbations, leading to slow convergence and suboptimal performance. We propose a simple plug-and-play method that incorporates prior-informed perturbations to refine gradient estimation. Our method dynamically computes a guiding vector from Gaussian samples, which directs perturbations toward more informative directions, significantly accelerating convergence compared to standard ZO approaches. We further investigate a greedy perturbation strategy to explore the impact of prior knowledge on gradient estimation. Theoretically, we prove that our gradient estimator achieves stronger alignment with the true gradient direction, enhancing optimization efficiency. Extensive experiments across LLMs of varying scales and architectures demonstrate that our proposed method could seamlessly integrate into existing optimization methods, delivering faster convergence and superior performance. Notably, on the OPT-13B model, our method outperforms traditional ZO optimization across all 11 benchmark tasks and surpasses gradient-based baselines on 9 out of 11 tasks, establishing a robust balance between efficiency and accuracy.",
      "authors": [
        "Feihu Jin",
        "Shipeng Cen",
        "Ying Tan"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 08:27:15+00:00",
      "link": "https://arxiv.org/pdf/2601.04710v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04707v1",
      "title": "MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training",
      "abstract": "Graph Neural Networks (GNNs) are powerful tools for learning graph-structured data, but their scalability is hindered by inefficient mini-batch generation, data transfer bottlenecks, and costly inter-GPU synchronization. Existing training frameworks fail to overlap these stages, leading to suboptimal resource utilization. This paper proposes MQ-GNN, a multi-queue pipelined framework that maximizes training efficiency by interleaving GNN training stages and optimizing resource utilization. MQ-GNN introduces Ready-to-Update Asynchronous Consistent Model (RaCoM), which enables asynchronous gradient sharing and model updates while ensuring global consistency through adaptive periodic synchronization. Additionally, it employs global neighbor sampling with caching to reduce data transfer overhead and an adaptive queue-sizing strategy to balance computation and memory efficiency. Experiments on four large-scale datasets and ten baseline models demonstrate that MQ-GNN achieves up to \\boldmath $\\bm{4.6\\,\\times}$ faster training time and 30% improved GPU utilization while maintaining competitive accuracy. These results establish MQ-GNN as a scalable and efficient solution for multi-GPU GNN training.",
      "authors": [
        "Irfan Ullah",
        "Young-Koo Lee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "published": "2026-01-08 08:19:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04707v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04705v1",
      "title": "A zone-based training approach for last-mile routing using Graph Neural Networks and Pointer Networks",
      "abstract": "Rapid e-commerce growth has pushed last-mile delivery networks to their limits, where small routing gains translate into lower costs, faster service, and fewer emissions. Classical heuristics struggle to adapt when travel times are highly asymmetric (e.g., one-way streets, congestion). A deep learning-based approach to the last-mile routing problem is presented to generate geographical zones composed of stop sequences to minimize last-mile delivery times.   The presented approach is an encoder-decoder architecture. Each route is represented as a complete directed graph whose nodes are stops and whose edge weights are asymmetric travel times. A Graph Neural Network encoder produces node embeddings that captures the spatial relationships between stops. A Pointer Network decoder then takes the embeddings and the route's start node to sequentially select the next stops, assigning a probability to each unvisited node as the next destination.   Cells of a Discrete Global Grid System which contain route stops in the training data are obtained and clustered to generate geographical zones of similar size in which the process of training and inference are divided. Subsequently, a different instance of the model is trained per zone only considering the stops of the training routes which are included in that zone.   This approach is evaluated using the Los Angeles routes from the 2021 Amazon Last Mile Routing Challenge. Results from general and zone-based training are compared, showing a reduction in the average predicted route length in the zone-based training compared to the general training. The performance improvement of the zone-based approach becomes more pronounced as the number of stops per route increases.",
      "authors": [
        "Àngel Ruiz-Fas",
        "Carlos Granell",
        "José Francisco Ramos",
        "Joaquín Huerta",
        "Sergio Trilles"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 08:18:32+00:00",
      "link": "https://arxiv.org/pdf/2601.04705v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04703v1",
      "title": "Beyond Monolithic Architectures: A Multi-Agent Search and Knowledge Optimization Framework for Agentic Search",
      "abstract": "Agentic search has emerged as a promising paradigm for complex information seeking by enabling Large Language Models (LLMs) to interleave reasoning with tool use. However, prevailing systems rely on monolithic agents that suffer from structural bottlenecks, including unconstrained reasoning outputs that inflate trajectories, sparse outcome-level rewards that complicate credit assignment, and stochastic search noise that destabilizes learning. To address these challenges, we propose \\textbf{M-ASK} (Multi-Agent Search and Knowledge), a framework that explicitly decouples agentic search into two complementary roles: Search Behavior Agents, which plan and execute search actions, and Knowledge Management Agents, which aggregate, filter, and maintain a compact internal context. This decomposition allows each agent to focus on a well-defined subtask and reduces interference between search and context construction. Furthermore, to enable stable coordination, M-ASK employs turn-level rewards to provide granular supervision for both search decisions and knowledge updates. Experiments on multi-hop QA benchmarks demonstrate that M-ASK outperforms strong baselines, achieving not only superior answer accuracy but also significantly more stable training dynamics.\\footnote{The source code for M-ASK is available at https://github.com/chenyiqun/M-ASK.}",
      "authors": [
        "Yiqun Chen",
        "Lingyong Yan",
        "Zixuan Yang",
        "Erhan Zhang",
        "Jiashu Zhao",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Jiaxin Mao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 08:13:27+00:00",
      "link": "https://arxiv.org/pdf/2601.04703v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04699v1",
      "title": "SeqWalker: Sequential-Horizon Vision-and-Language Navigation with Hierarchical Planning",
      "abstract": "Sequential-Horizon Vision-and-Language Navigation (SH-VLN) presents a challenging scenario where agents should sequentially execute multi-task navigation guided by complex, long-horizon language instructions. Current vision-and-language navigation models exhibit significant performance degradation with such multi-task instructions, as information overload impairs the agent's ability to attend to observationally relevant details. To address this problem, we propose SeqWalker, a navigation model built on a hierarchical planning framework. Our SeqWalker features: i) A High-Level Planner that dynamically selects global instructions into contextually relevant sub-instructions based on the agent's current visual observations, thus reducing cognitive load; ii) A Low-Level Planner incorporating an Exploration-Verification strategy that leverages the inherent logical structure of instructions for trajectory error correction. To evaluate SH-VLN performance, we also extend the IVLN dataset and establish a new benchmark. Extensive experiments are performed to demonstrate the superiority of the proposed SeqWalker.",
      "authors": [
        "Zebin Han",
        "Xudong Wang",
        "Baichen Liu",
        "Qi Lyu",
        "Zhenduo Shang",
        "Jiahua Dong",
        "Lianqing Liu",
        "Zhi Han"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-01-08 08:09:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04699v1",
      "tags": [
        "keyword:RL",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04698v1",
      "title": "TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning",
      "abstract": "Travel planning is a sophisticated decision-making process that requires synthesizing multifaceted information to construct itineraries. However, existing travel planning approaches face several challenges: (1) Pruning candidate points of interest (POIs) while maintaining a high recall rate; (2) A single reasoning path restricts the exploration capability within the feasible solution space for travel planning; (3) Simultaneously optimizing hard constraints and soft constraints remains a significant difficulty. To address these challenges, we propose TourPlanner, a comprehensive framework featuring multi-path reasoning and constraint-gated reinforcement learning. Specifically, we first introduce a Personalized Recall and Spatial Optimization (PReSO) workflow to construct spatially-aware candidate POIs' set. Subsequently, we propose Competitive consensus Chain-of-Thought (CCoT), a multi-path reasoning paradigm that improves the ability of exploring the feasible solution space. To further refine the plan, we integrate a sigmoid-based gating mechanism into the reinforcement learning stage, which dynamically prioritizes soft-constraint satisfaction only after hard constraints are met. Experimental results on travel planning benchmarks demonstrate that TourPlanner achieves state-of-the-art performance, significantly surpassing existing methods in both feasibility and user-preference alignment.",
      "authors": [
        "Yinuo Wang",
        "Mining Tan",
        "Wenxiang Jiao",
        "Xiaoxi Li",
        "Hao Wang",
        "Xuanyu Zhang",
        "Yuan Lu",
        "Weiming Dong"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 08:08:35+00:00",
      "link": "https://arxiv.org/pdf/2601.04698v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04696v1",
      "title": "A Method for Constructing a Digital Transformation Driving Mechanism Based on Semantic Understanding of Large Models",
      "abstract": "In the process of digital transformation, enterprises are faced with problems such as insufficient semantic understanding of unstructured data and lack of intelligent decision-making basis in driving mechanisms. This study proposes a method that combines a large language model (LLM) and a knowledge graph. First, a fine-tuned BERT (Bidirectional Encoder Representations from Transformers) model is used to perform entity recognition and relationship extraction on multi-source heterogeneous texts, and GPT-4 is used to generate semantically enhanced vector representations; secondly, a two-layer graph neural network (GNN) architecture is designed to fuse the semantic vectors output by LLM with business metadata to construct a dynamic and scalable enterprise knowledge graph; then reinforcement learning is introduced to optimize decision path generation, and the reward function is used to drive the mechanism iteration. In the case of the manufacturing industry, this mechanism reduced the response time for equipment failure scenarios from 7.8 hours to 3.7 hours, the F1 value reached 94.3%, and the compensation for decision errors in the annual digital transformation cost decreased by 45.3%. This method significantly enhances the intelligence level and execution efficiency of the digital transformation driving mechanism by integrating large model semantic understanding with structured knowledge.",
      "authors": [
        "Huayi Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 08:06:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04696v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04695v1",
      "title": "Tape: A Cellular Automata Benchmark for Evaluating Rule-Shift Generalization in Reinforcement Learning",
      "abstract": "We present Tape, a controlled reinforcement-learning benchmark designed to isolate out-of-distribution (OOD) failure under latent rule shifts.Tape is derived from one-dimensional cellular automata, enabling precise train/test splits where observation and action spaces are held fixed while transition rules change. Using a reproducible evaluation pipeline, we compare model-free baselines, model-based planning with learned world models, and task-inference (meta-RL) methods. A consistent pattern emerges: methods that are strong in-distribution (ID) can collapse under heldout-rule OOD, and high-variance OOD evaluation can make rankings unstable unless experiments are sufficiently replicated.We provide (i) standardized OOD protocols, (ii) statistical reporting requirements (seeds, confidence intervals, and hypothesis tests), and (iii) information-theoretic identities connecting entropy reduction to conditional mutual information and expected posterior KL divergence, clarifying what \"uncertainty reduction\" objectives can and cannot guarantee under rule shifts.",
      "authors": [
        "Enze Pan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 08:05:42+00:00",
      "link": "https://arxiv.org/pdf/2601.04695v1",
      "tags": [
        "keyword:RL",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04694v1",
      "title": "ResMAS: Resilience Optimization in LLM-based Multi-agent Systems",
      "abstract": "Large Language Model-based Multi-Agent Systems (LLM-based MAS), where multiple LLM agents collaborate to solve complex tasks, have shown impressive performance in many areas. However, MAS are typically distributed across different devices or environments, making them vulnerable to perturbations such as agent failures. While existing works have studied the adversarial attacks and corresponding defense strategies, they mainly focus on reactively detecting and mitigating attacks after they occur rather than proactively designing inherently resilient systems. In this work, we study the resilience of LLM-based MAS under perturbations and find that both the communication topology and prompt design significantly influence system resilience. Motivated by these findings, we propose ResMAS: a two-stage framework for enhancing MAS resilience. First, we train a reward model to predict the MAS's resilience, based on which we train a topology generator to automatically design resilient topology for specific tasks through reinforcement learning. Second, we introduce a topology-aware prompt optimization method that refines each agent's prompt based on its connections and interactions with other agents. Extensive experiments across a range of tasks show that our approach substantially improves MAS resilience under various constraints. Moreover, our framework demonstrates strong generalization ability to new tasks and models, highlighting its potential for building resilient MASs.",
      "authors": [
        "Zhilun Zhou",
        "Zihan Liu",
        "Jiahe Liu",
        "Qingyu Shao",
        "Yihan Wang",
        "Kun Shao",
        "Depeng Jin",
        "Fengli Xu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 08:03:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04694v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04693v1",
      "title": "Thunder-KoNUBench: A Corpus-Aligned Benchmark for Korean Negation Understanding",
      "abstract": "Although negation is known to challenge large language models (LLMs), benchmarks for evaluating negation understanding, especially in Korean, are scarce. We conduct a corpus-based analysis of Korean negation and show that LLM performance degrades under negation. We then introduce Thunder-KoNUBench, a sentence-level benchmark that reflects the empirical distribution of Korean negation phenomena. Evaluating 47 LLMs, we analyze the effects of model size and instruction tuning, and show that fine-tuning on Thunder-KoNUBench improves negation understanding and broader contextual comprehension in Korean.",
      "authors": [
        "Sungmok Jung",
        "Yeonkyoung So",
        "Joonhak Lee",
        "Sangho Kim",
        "Yelim Ahn",
        "Jaejin Lee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 08:02:52+00:00",
      "link": "https://arxiv.org/pdf/2601.04693v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04688v1",
      "title": "ToolGate: Contract-Grounded and Verified Tool Execution for LLMs",
      "abstract": "Large Language Models (LLMs) augmented with external tools have demonstrated remarkable capabilities in complex reasoning tasks. However, existing frameworks rely heavily on natural language reasoning to determine when tools can be invoked and whether their results should be committed, lacking formal guarantees for logical safety and verifiability. We present \\textbf{ToolGate}, a forward execution framework that provides logical safety guarantees and verifiable state evolution for LLM tool calling. ToolGate maintains an explicit symbolic state space as a typed key-value mapping representing trusted world information throughout the reasoning process. Each tool is formalized as a Hoare-style contract consisting of a precondition and a postcondition, where the precondition gates tool invocation by checking whether the current state satisfies the required conditions, and the postcondition determines whether the tool's result can be committed to update the state through runtime verification. Our approach guarantees that the symbolic state evolves only through verified tool executions, preventing invalid or hallucinated results from corrupting the world representation. Experimental validation demonstrates that ToolGate significantly improves the reliability and verifiability of tool-augmented LLM systems while maintaining competitive performance on complex multi-step reasoning tasks. This work establishes a foundation for building more trustworthy and debuggable AI systems that integrate language models with external tools.",
      "authors": [
        "Yanming Liu",
        "Xinyue Peng",
        "Jiannan Cao",
        "Xinyi Wang",
        "Songhang Deng",
        "Jintao Chen",
        "Jianwei Yin",
        "Xuhong Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.FL"
      ],
      "published": "2026-01-08 07:56:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04688v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04686v1",
      "title": "Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead",
      "abstract": "Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.",
      "authors": [
        "Oluwatosin Oseni",
        "Shengjie Wang",
        "Jun Zhu",
        "Micah Corah"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-01-08 07:55:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04686v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04676v1",
      "title": "DB-MSMUNet:Dual Branch Multi-scale Mamba UNet for Pancreatic CT Scans Segmentation",
      "abstract": "Accurate segmentation of the pancreas and its lesions in CT scans is crucial for the precise diagnosis and treatment of pancreatic cancer. However, it remains a highly challenging task due to several factors such as low tissue contrast with surrounding organs, blurry anatomical boundaries, irregular organ shapes, and the small size of lesions. To tackle these issues, we propose DB-MSMUNet (Dual-Branch Multi-scale Mamba UNet), a novel encoder-decoder architecture designed specifically for robust pancreatic segmentation. The encoder is constructed using a Multi-scale Mamba Module (MSMM), which combines deformable convolutions and multi-scale state space modeling to enhance both global context modeling and local deformation adaptation. The network employs a dual-decoder design: the edge decoder introduces an Edge Enhancement Path (EEP) to explicitly capture boundary cues and refine fuzzy contours, while the area decoder incorporates a Multi-layer Decoder (MLD) to preserve fine-grained details and accurately reconstruct small lesions by leveraging multi-scale deep semantic features. Furthermore, Auxiliary Deep Supervision (ADS) heads are added at multiple scales to both decoders, providing more accurate gradient feedback and further enhancing the discriminative capability of multi-scale features. We conduct extensive experiments on three datasets: the NIH Pancreas dataset, the MSD dataset, and a clinical pancreatic tumor dataset provided by collaborating hospitals. DB-MSMUNet achieves Dice Similarity Coefficients of 89.47%, 87.59%, and 89.02%, respectively, outperforming most existing state-of-the-art methods in terms of segmentation accuracy, edge preservation, and robustness across different datasets. These results demonstrate the effectiveness and generalizability of the proposed method for real-world pancreatic CT segmentation tasks.",
      "authors": [
        "Qiu Guan",
        "Zhiqiang Yang",
        "Dezhang Ye",
        "Yang Chen",
        "Xinli Xu",
        "Ying Tang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 07:41:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04676v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04675v1",
      "title": "LLM-Guided Quantified SMT Solving over Uninterpreted Functions",
      "abstract": "Quantified formulas with Uninterpreted Functions (UFs) over non-linear real arithmetic pose fundamental challenges for Satisfiability Modulo Theories (SMT) solving. Traditional quantifier instantiation methods struggle because they lack semantic understanding of UF constraints, forcing them to search through unbounded solution spaces with limited guidance. We present AquaForte, a framework that leverages Large Language Models to provide semantic guidance for UF instantiation by generating instantiated candidates for function definitions that satisfy the constraints, thereby significantly reducing the search space and complexity for solvers. Our approach preprocesses formulas through constraint separation, uses structured prompts to extract mathematical reasoning from LLMs, and integrates the results with traditional SMT algorithms through adaptive instantiation. AquaForte maintains soundness through systematic validation: LLM-guided instantiations yielding SAT solve the original problem, while UNSAT results generate exclusion clauses for iterative refinement. Completeness is preserved by fallback to traditional solvers augmented with learned constraints. Experimental evaluation on SMT-COMP benchmarks demonstrates that AquaForte solves numerous instances where state-of-the-art solvers like Z3 and CVC5 timeout, with particular effectiveness on satisfiable formulas. Our work shows that LLMs can provide valuable mathematical intuition for symbolic reasoning, establishing a new paradigm for SMT constraint solving.",
      "authors": [
        "Kunhang Lv",
        "Yuhang Dong",
        "Rui Han",
        "Fuqi Jia",
        "Feifei Ma",
        "Jian Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 07:40:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04675v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04673v1",
      "title": "Estimating Causal Effects in Gaussian Linear SCMs with Finite Data",
      "abstract": "Estimating causal effects from observational data remains a fundamental challenge in causal inference, especially in the presence of latent confounders. This paper focuses on estimating causal effects in Gaussian Linear Structural Causal Models (GL-SCMs), which are widely used due to their analytical tractability. However, parameter estimation in GL-SCMs is often infeasible with finite data, primarily due to overparameterization. To address this, we introduce the class of Centralized Gaussian Linear SCMs (CGL-SCMs), a simplified yet expressive subclass where exogenous variables follow standardized distributions. We show that CGL-SCMs are equally expressive in terms of causal effect identifiability from observational distributions and present a novel EM-based estimation algorithm that can learn CGL-SCM parameters and estimate identifiable causal effects from finite observational samples. Our theoretical analysis is validated through experiments on synthetic data and benchmark causal graphs, demonstrating that the learned models accurately recover causal distributions.",
      "authors": [
        "Aurghya Maiti",
        "Prateek Jain"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-01-08 07:37:10+00:00",
      "link": "https://arxiv.org/pdf/2601.04673v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04672v1",
      "title": "Agri-R1: Empowering Generalizable Agricultural Reasoning in Vision-Language Models with Reinforcement Learning",
      "abstract": "Agricultural disease diagnosis challenges VLMs, as conventional fine-tuning requires extensive labels, lacks interpretability, and generalizes poorly. While reasoning improves model robustness, existing methods rely on costly expert annotations and rarely address the open-ended, diverse nature of agricultural queries. To address these limitations, we propose \\textbf{Agri-R1}, a reasoning-enhanced large model for agriculture. Our framework automates high-quality reasoning data generation via vision-language synthesis and LLM-based filtering, using only 19\\% of available samples. Training employs Group Relative Policy Optimization (GRPO) with a novel proposed reward function that integrates domain-specific lexicons and fuzzy matching to assess both correctness and linguistic flexibility in open-ended responses. Evaluated on CDDMBench, our resulting 3B-parameter model achieves performance competitive with 7B- to 13B-parameter baselines, showing a +23.2\\% relative gain in disease recognition accuracy, +33.3\\% in agricultural knowledge QA, and a +26.10-point improvement in cross-domain generalization over standard fine-tuning. Ablation studies confirm that the synergy between structured reasoning data and GRPO-driven exploration underpins these gains, with benefits scaling as question complexity increases.",
      "authors": [
        "Wentao Zhang",
        "Lifei Wang",
        "Lina Lu",
        "MingKun Xu",
        "Shangyang Li",
        "Yanchao Yang",
        "Tao Fang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.CL"
      ],
      "published": "2026-01-08 07:34:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04672v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04670v1",
      "title": "Learning Dynamics in RL Post-Training for Language Models",
      "abstract": "Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL post-training, we analyze the learning dynamics of RL post-training from a perspective that has been studied in supervised learning but remains underexplored in RL. We adopt an empirical neural tangent kernel (NTK) framework and decompose the NTK into two components to characterize how RL updates propagate across training samples. Our analysis reveals that limited variability in feature representations can cause RL updates to systematically increase model confidence, providing an explanation for the commonly observed reduction in output diversity after RL post-training. Furthermore, we show that effective learning in this regime depends on rapidly shaping the classifier, which directly affects the gradient component of the NTK. Motivated by these insights, we propose classifier-first reinforcement learning (CF-RL), a simple two-stage training strategy that prioritizes classifier updates before standard RL optimization. Experimental results validate our theoretical analysis by demonstrating increased model confidence and accelerated optimization under CF-RL. Additional analysis shows that the mechanism underlying CF-RL differs from that of linear-probing-then-fine-tuning in supervised learning. Overall, our study formalizes the learning dynamics of RL post-training and motivates further analysis and improvement.",
      "authors": [
        "Akiyoshi Tomihari"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 07:32:15+00:00",
      "link": "https://arxiv.org/pdf/2601.04670v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04668v1",
      "title": "Optimizing Path Planning using Deep Reinforcement Learning for UGVs in Precision Agriculture",
      "abstract": "This study focuses on optimizing path planning for unmanned ground vehicles (UGVs) in precision agriculture using deep reinforcement learning (DRL) techniques in continuous action spaces. The research begins with a review of traditional grid-based methods, such as A* and Dijkstra's algorithms, and discusses their limitations in dynamic agricultural environments, highlighting the need for adaptive learning strategies. The study then explores DRL approaches, including Deep Q-Networks (DQN), which demonstrate improved adaptability and performance in two-dimensional simulations. Enhancements such as Double Q-Networks and Dueling Networks are evaluated to further improve decision-making. Building on these results, the focus shifts to continuous action space models, specifically Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep Deterministic Policy Gradient (TD3), which are tested in increasingly complex environments. Experiments conducted in a three-dimensional environment using ROS and Gazebo demonstrate the effectiveness of continuous DRL algorithms in navigating dynamic agricultural scenarios. Notably, the pretrained TD3 agent achieves a 95 percent success rate in dynamic environments, demonstrating the robustness of the proposed approach in handling moving obstacles while ensuring safety for both crops and the robot.",
      "authors": [
        "Laukik Patade",
        "Rohan Rane",
        "Sandeep Pillai"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-01-08 07:28:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04668v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04646v1",
      "title": "Succeeding at Scale: Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search",
      "abstract": "Large-scale multi-tenant retrieval systems amass vast user query logs yet critically lack the curated relevance labels required for effective domain adaptation. This \"dark data\" problem is exacerbated by the operational cost of model updates: jointly fine-tuning query and document encoders requires re-indexing the entire corpus, which is prohibitive in multi-tenant environments with thousands of isolated indices. To address these dual challenges, we introduce \\textbf{DevRev Search}, a passage retrieval benchmark for technical customer support constructed through a fully automatic pipeline. We employ a \\textbf{fusion-based candidate generation} strategy, pooling results from diverse sparse and dense retrievers, and utilize an LLM-as-a-Judge to perform rigorous \\textbf{consistency filtering} and relevance assignment. We further propose a practical \\textbf{Index-Preserving Adaptation} strategy: by fine-tuning only the query encoder via Low-Rank Adaptation (LoRA), we achieve competitive performance improvements while keeping the document index frozen. Our experiments on DevRev Search and SciFact demonstrate that targeting specific transformer layers in the query encoder yields optimal quality-efficiency trade-offs, offering a scalable path for personalized enterprise search.",
      "authors": [
        "Prateek Jain",
        "Shabari S Nair",
        "Ritesh Goru",
        "Prakhar Agarwal",
        "Ajay Yadav",
        "Yoga Sri Varshan Varadharajan",
        "Constantine Caramanis"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 06:44:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04646v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04643v1",
      "title": "MMFCTUB: Multi-Modal Financial Credit Table Understanding Benchmark",
      "abstract": "The advent of multi-modal language models (MLLMs) has spurred research into their application across various table understanding tasks. However, their performance in credit table understanding (CTU) for financial credit review remains largely unexplored due to the following barriers: low data consistency, high annotation costs stemming from domain-specific knowledge and complex calculations, and evaluation paradigm gaps between benchmark and real-world scenarios. To address these challenges, we introduce MMFCTUB (Multi-Modal Financial Credit Table Understanding Benchmark), a practical benchmark, encompassing more than 7,600 high quality CTU samples across 5 table types. MMFCTUB employ a minimally supervised pipeline that adheres to inter-table constraints and maintains data distributions consistency. The benchmark leverages capacity-driven questions and mask-and-recovery strategy to evaluate models' cross-table structure perception, domain knowledge utilization, and numerical calculation capabilities. Utilizing MMFCTUB, we conduct comprehensive evaluations of both proprietary and open-source MLLMs, revealing their strengths and limitations in CTU tasks. MMFCTUB serves as a valuable resource for the research community, facilitating rigorous evaluation of MLLMs in the domain of CTU.",
      "authors": [
        "Cui Yakun",
        "Yanting Zhang",
        "Zhu Lei",
        "Jian Xie",
        "Zhizhuo Kou",
        "Hang Du",
        "Zhenghao Zhu",
        "Sirui Han"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-01-08 06:34:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04643v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04638v1",
      "title": "SpeechMedAssist: Efficiently and Effectively Adapting Speech Language Models for Medical Consultation",
      "abstract": "Medical consultations are intrinsically speech-centric. However, most prior works focus on long-text-based interactions, which are cumbersome and patient-unfriendly. Recent advances in speech language models (SpeechLMs) have enabled more natural speech-based interaction, yet the scarcity of medical speech data and the inefficiency of directly fine-tuning on speech data jointly hinder the adoption of SpeechLMs in medical consultation. In this paper, we propose SpeechMedAssist, a SpeechLM natively capable of conducting speech-based multi-turn interactions with patients. By exploiting the architectural properties of SpeechLMs, we decouple the conventional one-stage training into a two-stage paradigm consisting of (1) Knowledge & Capability Injection via Text and (2) Modality Re-alignment with Limited Speech Data, thereby reducing the requirement for medical speech data to only 10k synthesized samples. To evaluate SpeechLMs for medical consultation scenarios, we design a benchmark comprising both single-turn question answering and multi-turn simulated interactions. Experimental results show that our model outperforms all baselines in both effectiveness and robustness in most evaluation settings.",
      "authors": [
        "Sirry Chen",
        "Jieyi Wang",
        "Wei Chen",
        "Zhongyu Wei"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 06:14:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04638v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04620v1",
      "title": "AgentDevel: Reframing Self-Evolving LLM Agents as Release Engineering",
      "abstract": "Recent progress in large language model (LLM) agents has largely focused on embedding self-improvement mechanisms inside the agent or searching over many concurrent variants. While these approaches can raise aggregate scores, they often yield unstable and hard-to-audit improvement trajectories, making it difficult to guarantee non-regression or to reason about failures across versions. We reframe agent improvement as \\textbf{release engineering}: agents are treated as shippable artifacts, and improvement is externalized into a regression-aware release pipeline. We introduce \\textbf{AgentDevel}, a release engineering pipeline that iteratively runs the current agent, produces implementation-blind, symptom-level quality signals from execution traces, synthesizes a single release candidate (RC) via executable diagnosis, and promotes it under flip-centered gating. AgentDevel features three core designs: (i) an implementation-blind LLM critic that characterizes failure appearances without accessing agent internals, (ii) script-based executable diagnosis that aggregates dominant symptom patterns and produces auditable engineering specifications, and (iii) flip-centered gating that prioritizes pass to fail regressions and fail to pass fixes as first-class evidence. Unlike population-based search or in-agent self-refinement, AgentDevel maintains a single canonical version line and emphasizes non-regression as a primary objective. Experiments on execution-heavy benchmarks demonstrate that AgentDevel yields stable improvements with significantly fewer regressions while producing reproducible, auditable artifacts. Overall, AgentDevel provides a practical development discipline for building, debugging, and releasing LLM agents as software development.",
      "authors": [
        "Di Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 05:49:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04620v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04610v1",
      "title": "Evaluating Human and Machine Confidence in Phishing Email Detection: A Comparative Study",
      "abstract": "Identifying deceptive content like phishing emails demands sophisticated cognitive processes that combine pattern recognition, confidence assessment, and contextual analysis. This research examines how human cognition and machine learning models work together to distinguish phishing emails from legitimate ones. We employed three interpretable algorithms Logistic Regression, Decision Trees, and Random Forests training them on both TF-IDF features and semantic embeddings, then compared their predictions against human evaluations that captured confidence ratings and linguistic observations. Our results show that machine learning models provide good accuracy rates, but their confidence levels vary significantly. Human evaluators, on the other hand, use a greater variety of language signs and retain more consistent confidence. We also found that while language proficiency has minimal effect on detection performance, aging does. These findings offer helpful direction for creating transparent AI systems that complement human cognitive functions, ultimately improving human-AI cooperation in challenging content analysis tasks.",
      "authors": [
        "Paras Jain",
        "Khushi Dhar",
        "Olyemi E. Amujo",
        "Esa M. Rantanen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 05:30:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04610v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04607v1",
      "title": "HUR-MACL: High-Uncertainty Region-Guided Multi-Architecture Collaborative Learning for Head and Neck Multi-Organ Segmentation",
      "abstract": "Accurate segmentation of organs at risk in the head and neck is essential for radiation therapy, yet deep learning models often fail on small, complexly shaped organs. While hybrid architectures that combine different models show promise, they typically just concatenate features without exploiting the unique strengths of each component. This results in functional overlap and limited segmentation accuracy. To address these issues, we propose a high uncertainty region-guided multi-architecture collaborative learning (HUR-MACL) model for multi-organ segmentation in the head and neck. This model adaptively identifies high uncertainty regions using a convolutional neural network, and for these regions, Vision Mamba as well as Deformable CNN are utilized to jointly improve their segmentation accuracy. Additionally, a heterogeneous feature distillation loss was proposed to promote collaborative learning between the two architectures in high uncertainty regions to further enhance performance. Our method achieves SOTA results on two public datasets and one private dataset.",
      "authors": [
        "Xiaoyu Liu",
        "Siwen Wei",
        "Linhao Qu",
        "Mingyuan Pan",
        "Chengsheng Zhang",
        "Yonghong Shi",
        "Zhijian Song"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 05:25:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04607v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04592v1",
      "title": "Density Matrix RNN (DM-RNN): A Quantum Information Theoretic Framework for Modeling Musical Context and Polyphony",
      "abstract": "Classical Recurrent Neural Networks (RNNs) summarize musical context into a deterministic hidden state vector, imposing an information bottleneck that fails to capture the inherent ambiguity in music. We propose the Density Matrix RNN (DM-RNN), a novel theoretical architecture utilizing the Density Matrix. This allows the model to maintain a statistical ensemble of musical interpretations (a mixed state), capturing both classical probabilities and quantum coherences. We rigorously define the temporal dynamics using Quantum Channels (CPTP maps). Crucially, we detail a parameterization strategy based on the Choi-Jamiolkowski isomorphism, ensuring the learned dynamics remain physically valid (CPTP) by construction. We introduce an analytical framework using Von Neumann Entropy to quantify musical uncertainty and Quantum Mutual Information (QMI) to measure entanglement between voices. The DM-RNN provides a mathematically rigorous framework for modeling complex, ambiguous musical structures.",
      "authors": [
        "Joonwon Seo",
        "Mariana Montiel"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.SD",
        "math-ph"
      ],
      "published": "2026-01-08 04:44:04+00:00",
      "link": "https://arxiv.org/pdf/2601.04592v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04589v1",
      "title": "MiLDEdit: Reasoning-Based Multi-Layer Design Document Editing",
      "abstract": "Real-world design documents (e.g., posters) are inherently multi-layered, combining decoration, text, and images. Editing them from natural-language instructions requires fine-grained, layer-aware reasoning to identify relevant layers and coordinate modifications. Prior work largely overlooks multi-layer design document editing, focusing instead on single-layer image editing or multi-layer generation, which assume a flat canvas and lack the reasoning needed to determine what and where to modify. To address this gap, we introduce the Multi-Layer Document Editing Agent (MiLDEAgent), a reasoning-based framework that combines an RL-trained multimodal reasoner for layer-wise understanding with an image editor for targeted modifications. To systematically benchmark this setting, we introduce the MiLDEBench, a human-in-the-loop corpus of over 20K design documents paired with diverse editing instructions. The benchmark is complemented by a task-specific evaluation protocol, MiLDEEval, which spans four dimensions including instruction following, layout consistency, aesthetics, and text rendering. Extensive experiments on 14 open-source and 2 closed-source models reveal that existing approaches fail to generalize: open-source models often cannot complete multi-layer document editing tasks, while closed-source models suffer from format violations. In contrast, MiLDEAgent achieves strong layer-aware reasoning and precise editing, significantly outperforming all open-source baselines and attaining performance comparable to closed-source models, thereby establishing the first strong baseline for multi-layer document editing.",
      "authors": [
        "Zihao Lin",
        "Wanrong Zhu",
        "Jiuxiang Gu",
        "Jihyung Kil",
        "Christopher Tensmeyer",
        "Lin Zhang",
        "Shilong Liu",
        "Ruiyi Zhang",
        "Lifu Huang",
        "Vlad I. Morariu",
        "Tong Sun"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 04:38:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04589v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04583v1",
      "title": "Autonomous Agents on Blockchains: Standards, Execution Models, and Trust Boundaries",
      "abstract": "Advances in large language models have enabled agentic AI systems that can reason, plan, and interact with external tools to execute multi-step workflows, while public blockchains have evolved into a programmable substrate for value transfer, access control, and verifiable state transitions. Their convergence introduces a high-stakes systems challenge: designing standard, interoperable, and secure interfaces that allow agents to observe on-chain state, formulate transaction intents, and authorize execution without exposing users, protocols, or organizations to unacceptable security, governance, or economic risks. This survey systematizes the emerging landscape of agent-blockchain interoperability through a systematic literature review, identifying 317 relevant works from an initial pool of over 3000 records. We contribute a five-part taxonomy of integration patterns spanning read-only analytics, simulation and intent generation, delegated execution, autonomous signing, and multi-agent workflows; a threat model tailored to agent-driven transaction pipelines that captures risks ranging from prompt injection and policy misuse to key compromise, adversarial execution dynamics, and multi-agent collusion; and a comparative capability matrix analyzing more than 20 representative systems across 13 dimensions, including custody models, permissioning, policy enforcement, observability, and recovery. Building on the gaps revealed by this analysis, we outline a research roadmap centered on two interface abstractions: a Transaction Intent Schema for portable and unambiguous goal specification, and a Policy Decision Record for auditable, verifiable policy enforcement across execution environments. We conclude by proposing a reproducible evaluation suite and benchmarks for assessing the safety, reliability, and economic robustness of agent-mediated on-chain execution.",
      "authors": [
        "Saad Alqithami"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-01-08 04:29:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04583v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04582v1",
      "title": "Aligning Text, Code, and Vision: A Multi-Objective Reinforcement Learning Framework for Text-to-Visualization",
      "abstract": "Text-to-Visualization (Text2Vis) systems translate natural language queries over tabular data into concise answers and executable visualizations. While closed-source LLMs generate functional code, the resulting charts often lack semantic alignment and clarity, qualities that can only be assessed post-execution. Open-source models struggle even more, frequently producing non-executable or visually poor outputs. Although supervised fine-tuning can improve code executability, it fails to enhance overall visualization quality, as traditional SFT loss cannot capture post-execution feedback. To address this gap, we propose RL-Text2Vis, the first reinforcement learning framework for Text2Vis generation. Built on Group Relative Policy Optimization (GRPO), our method uses a novel multi-objective reward that jointly optimizes textual accuracy, code validity, and visualization quality using post-execution feedback. By training Qwen2.5 models (7B and 14B), RL-Text2Vis achieves a 22% relative improvement in chart quality over GPT-4o on the Text2Vis benchmark and boosts code execution success from 78% to 97% relative to its zero-shot baseline. Our models significantly outperform strong zero-shot and supervised baselines and also demonstrate robust generalization to out-of-domain datasets like VIS-Eval and NVBench. These results establish GRPO as an effective strategy for structured, multimodal reasoning in visualization generation. We release our code at https://github.com/vis-nlp/RL-Text2Vis.",
      "authors": [
        "Mizanur Rahman",
        "Mohammed Saidul Islam",
        "Md Tahmid Rahman Laskar",
        "Shafiq Joty",
        "Enamul Hoque"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 04:29:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04582v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04574v1",
      "title": "FeedEval: Pedagogically Aligned Evaluation of LLM-Generated Essay Feedback",
      "abstract": "Going beyond the prediction of numerical scores, recent research in automated essay scoring has increasingly emphasized the generation of high-quality feedback that provides justification and actionable guidance. To mitigate the high cost of expert annotation, prior work has commonly relied on LLM-generated feedback to train essay assessment models. However, such feedback is often incorporated without explicit quality validation, resulting in the propagation of noise in downstream applications. To address this limitation, we propose FeedEval, an LLM-based framework for evaluating LLM-generated essay feedback along three pedagogically grounded dimensions: specificity, helpfulness, and validity. FeedEval employs dimension-specialized LLM evaluators trained on datasets curated in this study to assess multiple feedback candidates and select high-quality feedback for downstream use. Experiments on the ASAP++ benchmark show that FeedEval closely aligns with human expert judgments and that essay scoring models trained with FeedEval-filtered high-quality feedback achieve superior scoring performance. Furthermore, revision experiments using small LLMs show that the high-quality feedback identified by FeedEval leads to more effective essay revisions. We will release our code and curated datasets upon accepted.",
      "authors": [
        "Seongyeub Chu",
        "Jongwoo Kim",
        "Munyong Yi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 04:04:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04574v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04568v1",
      "title": "Neurosymbolic Retrievers for Retrieval-augmented Generation",
      "abstract": "Retrieval Augmented Generation (RAG) has made significant strides in overcoming key limitations of large language models, such as hallucination, lack of contextual grounding, and issues with transparency. However, traditional RAG systems consist of three interconnected neural components - the retriever, re-ranker, and generator - whose internal reasoning processes remain opaque. This lack of transparency complicates interpretability, hinders debugging efforts, and erodes trust, especially in high-stakes domains where clear decision-making is essential. To address these challenges, we introduce the concept of Neurosymbolic RAG, which integrates symbolic reasoning using a knowledge graph with neural retrieval techniques. This new framework aims to answer two primary questions: (a) Can retrievers provide a clear and interpretable basis for document selection? (b) Can symbolic knowledge enhance the clarity of the retrieval process? We propose three methods to improve this integration. First is MAR (Knowledge Modulation Aligned Retrieval) that employs modulation networks to refine query embeddings using interpretable symbolic features, thereby making document matching more explicit. Second, KG-Path RAG enhances queries by traversing knowledge graphs to improve overall retrieval quality and interpretability. Lastly, Process Knowledge-infused RAG utilizes domain-specific tools to reorder retrieved content based on validated workflows. Preliminary results from mental health risk assessment tasks indicate that this neurosymbolic approach enhances both transparency and overall performance",
      "authors": [
        "Yash Saxena",
        "Manas Gaur"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2026-01-08 03:53:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04568v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04566v1",
      "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents",
      "abstract": "Large language model (LLM) agents execute tasks through multi-step workflows that combine planning, memory, and tool use. While this design enables autonomy, it also expands the attack surface for backdoor threats. Backdoor triggers injected into specific stages of an agent workflow can persist through multiple intermediate states and adversely influence downstream outputs. However, existing studies remain fragmented and typically analyze individual attack vectors in isolation, leaving the cross-stage interaction and propagation of backdoor triggers poorly understood from an agent-centric perspective. To fill this gap, we propose \\textbf{BackdoorAgent}, a modular and stage-aware framework that provides a unified, agent-centric view of backdoor threats in LLM agents. BackdoorAgent structures the attack surface into three functional stages of agentic workflows, including \\textbf{planning attacks}, \\textbf{memory attacks}, and \\textbf{tool-use attacks}, and instruments agent execution to enable systematic analysis of trigger activation and propagation across different stages. Building on this framework, we construct a standardized benchmark spanning four representative agent applications: \\textbf{Agent QA}, \\textbf{Agent Code}, \\textbf{Agent Web}, and \\textbf{Agent Drive}, covering both language-only and multimodal settings. Our empirical analysis shows that \\textit{triggers implanted at a single stage can persist across multiple steps and propagate through intermediate states.} For instance, when using a GPT-based backbone, we observe trigger persistence in 43.58\\% of planning attacks, 77.97\\% of memory attacks, and 60.28\\% of tool-stage attacks, highlighting the vulnerabilities of the agentic workflow itself to backdoor threats. To facilitate reproducibility and future research, our code and benchmark are publicly available at GitHub.",
      "authors": [
        "Yunhao Feng",
        "Yige Li",
        "Yutao Wu",
        "Yingshui Tan",
        "Yanming Guo",
        "Yifan Ding",
        "Kun Zhai",
        "Xingjun Ma",
        "Yugang Jiang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 03:49:39+00:00",
      "link": "https://arxiv.org/pdf/2601.04566v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04564v1",
      "title": "When Tone and Words Disagree: Towards Robust Speech Emotion Recognition under Acoustic-Semantic Conflict",
      "abstract": "Speech Emotion Recognition (SER) systems often assume congruence between vocal emotion and lexical semantics. However, in real-world interactions, acoustic-semantic conflict is common yet overlooked, where the emotion conveyed by tone contradicts the literal meaning of spoken words. We show that state-of-the-art SER models, including ASR-based, self-supervised learning (SSL) approaches and Audio Language Models (ALMs), suffer performance degradation under such conflicts due to semantic bias or entangled acoustic-semantic representations. To address this, we propose the Fusion Acoustic-Semantic (FAS) framework, which explicitly disentangles acoustic and semantic pathways and bridges them through a lightweight, query-based attention module. To enable systematic evaluation, we introduce the Conflict in Acoustic-Semantic Emotion (CASE), the first dataset dominated by clear and interpretable acoustic-semantic conflicts in varied scenarios. Extensive experiments demonstrate that FAS consistently outperforms existing methods in both in-domain and zero-shot settings. Notably, on the CASE benchmark, conventional SER models fail dramatically, while FAS sets a new SOTA with 59.38% accuracy. Our code and datasets is available at https://github.com/24DavidHuang/FAS.",
      "authors": [
        "Dawei Huang",
        "Yongjie Lv",
        "Ruijie Xiong",
        "Chunxiang Jin",
        "Xiaojiang Peng"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD"
      ],
      "published": "2026-01-08 03:47:21+00:00",
      "link": "https://arxiv.org/pdf/2601.04564v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04562v1",
      "title": "Reasoning Over Space: Enabling Geographic Reasoning for LLM-Based Generative Next POI Recommendation",
      "abstract": "Generative recommendation with large language models (LLMs) reframes prediction as sequence generation, yet existing LLM-based recommenders remain limited in leveraging geographic signals that are crucial in mobility and local-services scenarios. Here, we present Reasoning Over Space (ROS), a framework that utilizes geography as a vital decision variable within the reasoning process. ROS introduces a Hierarchical Spatial Semantic ID (SID) that discretizes coarse-to-fine locality and POI semantics into compositional tokens, and endows LLM with a three-stage Mobility Chain-of-Thought (CoT) paradigm that models user personality, constructs an intent-aligned candidate space, and performs locality informed pruning. We further align the model with real world geography via spatial-guided Reinforcement Learning (RL). Experiments on three widely used location-based social network (LBSN) datasets show that ROS achieves over 10% relative gains in hit rate over strongest LLM-based baselines and improves cross-city transfer, despite using a smaller backbone model.",
      "authors": [
        "Dongyi Lv",
        "Qiuyu Ding",
        "Heng-Da Xu",
        "Zhaoxu Sun",
        "Zhi Wang",
        "Feng Xiong",
        "Mu Xu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 03:46:03+00:00",
      "link": "https://arxiv.org/pdf/2601.04562v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04554v1",
      "title": "Exploring Recommender System Evaluation: A Multi-Modal User Agent Framework for A/B Testing",
      "abstract": "In recommender systems, online A/B testing is a crucial method for evaluating the performance of different models. However, conducting online A/B testing often presents significant challenges, including substantial economic costs, user experience degradation, and considerable time requirements. With the Large Language Models' powerful capacity, LLM-based agent shows great potential to replace traditional online A/B testing. Nonetheless, current agents fail to simulate the perception process and interaction patterns, due to the lack of real environments and visual perception capability. To address these challenges, we introduce a multi-modal user agent for A/B testing (A/B Agent). Specifically, we construct a recommendation sandbox environment for A/B testing, enabling multimodal and multi-page interactions that align with real user behavior on online platforms. The designed agent leverages multimodal information perception, fine-grained user preferences, and integrates profiles, action memory retrieval, and a fatigue system to simulate complex human decision-making. We validated the potential of the agent as an alternative to traditional A/B testing from three perspectives: model, data, and features. Furthermore, we found that the data generated by A/B Agent can effectively enhance the capabilities of recommendation models. Our code is publicly available at https://github.com/Applied-Machine-Learning-Lab/ABAgent.",
      "authors": [
        "Wenlin Zhang",
        "Xiangyang Li",
        "Qiyuan Ge",
        "Kuicai Dong",
        "Pengyue Jia",
        "Xiaopeng Li",
        "Zijian Zhang",
        "Maolin Wang",
        "Yichao Wang",
        "Huifeng Guo",
        "Ruiming Tang",
        "Xiangyu Zhao"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-08 03:33:43+00:00",
      "link": "https://arxiv.org/pdf/2601.04554v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04547v1",
      "title": "Data-Driven Terramechanics Approach Towards a Realistic Real-Time Simulator for Lunar Rovers",
      "abstract": "High-fidelity simulators for the lunar surface provide a digital environment for extensive testing of rover operations and mission planning. However, current simulators focus on either visual realism or physical accuracy, which limits their capability to replicate lunar conditions comprehensively. This work addresses that gap by combining high visual fidelity with realistic terrain interaction for a realistic representation of rovers on the lunar surface. Because direct simulation of wheel-soil interactions is computationally expensive, a data-driven approach was adopted, using regression models for slip and sinkage from data collected in both full-rover and single-wheel experiments and simulations. The resulting regression-based terramechanics model accurately reproduced steady-state and dynamic slip, as well as sinkage behavior, on flat terrain and slopes up to 20 degrees, with validation against field test results. Additionally, improvements were made to enhance the realism of terrain deformation and wheel trace visualization. This method supports real-time applications that require physically plausible terrain response alongside high visual fidelity.",
      "authors": [
        "Jakob M. Kern",
        "James M. Hurrell",
        "Shreya Santra",
        "Keisuke Takehana",
        "Kentaro Uno",
        "Kazuya Yoshida"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 03:23:31+00:00",
      "link": "https://arxiv.org/pdf/2601.04547v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04540v1",
      "title": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
      "abstract": "Recent advancements in large language models (LLMs) have automated various software engineering tasks, with benchmarks emerging to evaluate their capabilities. However, for adaptation, a critical activity during code reuse, there is no benchmark to assess LLMs' performance, leaving their practical utility in this area unclear. To fill this gap, we propose AdaptEval, a benchmark designed to evaluate LLMs on code snippet adaptation. Unlike existing benchmarks, AdaptEval incorporates the following three distinctive features: First, Practical Context. Tasks in AdaptEval are derived from developers' practices, preserving rich contextual information from Stack Overflow and GitHub communities. Second, Multi-granularity Annotation. Each task is annotated with requirements at both task and adaptation levels, supporting the evaluation of LLMs across diverse adaptation scenarios. Third, Fine-grained Evaluation. AdaptEval includes a two-tier testing framework combining adaptation-level and function-level tests, which enables evaluating LLMs' performance across various individual adaptations. Based on AdaptEval, we conduct the first empirical study to evaluate six instruction-tuned LLMs and especially three reasoning LLMs on code snippet adaptation. Experimental results demonstrate that AdaptEval enables the assessment of LLMs' adaptation capabilities from various perspectives. It also provides critical insights into their current limitations, particularly their struggle to follow explicit instructions. We hope AdaptEval can facilitate further investigation and enhancement of LLMs' capabilities in code snippet adaptation, supporting their real-world applications.",
      "authors": [
        "Tanghaoran Zhang",
        "Xinjun Mao",
        "Shangwen Wang",
        "Yuxin Zhao",
        "Yao Lu",
        "Jin Zhang",
        "Zhang Zhang",
        "Kang Yang",
        "Yue Yu"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-01-08 03:13:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04540v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04537v1",
      "title": "Not All Steps are Informative: On the Linearity of LLMs' RLVR Training",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has become a central component of large language model (LLM) post-training. Unlike supervised fine-tuning (SFT), RLVR lets an LLM generate multiple candidate solutions and reinforces those that lead to a verifiably correct final answer. However, in practice, RLVR often requires thousands of training steps to reach strong performance, incurring substantial computation largely attributed to prolonged exploration. In this work, we make a surprising observation: during RLVR, LLMs evolve in a strongly linear manner. Specifically, both model weights and model output log-probabilities exhibit strong linear correlations with RL training steps. This suggests that RLVR predominantly amplifies trends that emerge early in training, rather than continuously discovering new behaviors throughout the entire optimization trajectory. Motivated by this linearity, we investigate whether future model states can be predicted from intermediate checkpoints via extrapolation, avoiding continued expensive training. We show that Weight Extrapolation produces models with performance comparable to standard RL training while requiring significantly less computation. Moreover, Logits Extrapolation consistently outperforms continued RL training on all four benchmarks by extrapolating beyond the step range where RL training remains stable.",
      "authors": [
        "Tianle Wang",
        "Zhongyuan Wu",
        "Shenghao Jin",
        "Hao Xu",
        "Wei Chen",
        "Ning Miao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-01-08 03:06:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04537v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04525v1",
      "title": "GRACE: Reinforcement Learning for Grounded Response and Abstention under Contextual Evidence",
      "abstract": "Retrieval-Augmented Generation (RAG) integrates external knowledge to enhance Large Language Models (LLMs), yet systems remain susceptible to two critical flaws: providing correct answers without explicit grounded evidence and producing fabricated responses when the retrieved context is insufficient. While prior research has addressed these issues independently, a unified framework that integrates evidence-based grounding and reliable abstention is currently lacking. In this paper, we propose GRACE, a reinforcement-learning framework that simultaneously mitigates both types of flaws. GRACE employs a data construction method that utilizes heterogeneous retrievers to generate diverse training samples without manual annotation. A multi-stage gated reward function is then employed to train the model to assess evidence sufficiency, extract key supporting evidence, and provide answers or explicitly abstain. Experimental results on two benchmarks demonstrate that GRACE achieves state-of-the-art overall accuracy and strikes a favorable balance between accurate response and rejection, while requiring only 10% of the annotation costs of prior methods. Our code is available at https://github.com/YiboZhao624/Grace..",
      "authors": [
        "Yibo Zhao",
        "Jiapeng Zhu",
        "Zichen Ding",
        "Xiang Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 02:47:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04525v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04521v1",
      "title": "TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation",
      "abstract": "The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical language models that generate molecules as SMILES strings are vulnerable to compounding token errors: many samples are unparseable or chemically implausible, and hard constraints meant to prevent failure can restrict exploration. To address this gap, we introduce TSSR, a Two-Stage, Swap-Reward-driven reinforcement learning (RL) framework for character-level SMILES generation. Stage one rewards local token swaps that repair syntax, promoting transitions from invalid to parseable strings. Stage two provides chemistry-aware feedback from RDKit diagnostics, rewarding reductions in valence, aromaticity, and connectivity issues. The reward decomposes into interpretable terms (swap efficiency, error reduction, distance to validity), is model agnostic, and requires no task-specific labels or hand-crafted grammars. We evaluated TSSR on the MOSES benchmark using a GRU policy trained with PPO in both pure RL (P-RL) from random initialization and fine-tuning RL (F-RL) starting from a pretrained chemical language model, assessing 10,000 generated SMILES per run. In P-RL, TSSR significantly improves syntactic validity, chemical validity, and novelty. In F-RL, TSSR preserves drug-likeness and synthesizability while increasing validity and novelty. Token-level analysis shows that syntax edits and chemistry fixes act jointly to reduce RDKit detected errors. TSSR converts a sparse terminal objective into a denser and more interpretable reward, improving both syntactic and chemical quality without reducing diversity. TSSR is dataset-agnostic and can be adapted to various reinforcement learning approaches.",
      "authors": [
        "Jacob Ede Levine",
        "Yun Lyan Luo",
        "Sai Chandra Kosaraju"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 02:35:22+00:00",
      "link": "https://arxiv.org/pdf/2601.04521v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04520v1",
      "title": "FaceRefiner: High-Fidelity Facial Texture Refinement with Differentiable Rendering-based Style Transfer",
      "abstract": "Recent facial texture generation methods prefer to use deep networks to synthesize image content and then fill in the UV map, thus generating a compelling full texture from a single image. Nevertheless, the synthesized texture UV map usually comes from a space constructed by the training data or the 2D face generator, which limits the methods' generalization ability for in-the-wild input images. Consequently, their facial details, structures and identity may not be consistent with the input. In this paper, we address this issue by proposing a style transfer-based facial texture refinement method named FaceRefiner. FaceRefiner treats the 3D sampled texture as style and the output of a texture generation method as content. The photo-realistic style is then expected to be transferred from the style image to the content image. Different from current style transfer methods that only transfer high and middle level information to the result, our style transfer method integrates differentiable rendering to also transfer low level (or pixel level) information in the visible face regions. The main benefit of such multi-level information transfer is that, the details, structures and semantics in the input can thus be well preserved. The extensive experiments on Multi-PIE, CelebA and FFHQ datasets demonstrate that our refinement method can improve the texture quality and the face identity preserving ability, compared with state-of-the-arts.",
      "authors": [
        "Chengyang Li",
        "Baoping Cheng",
        "Yao Cheng",
        "Haocheng Zhang",
        "Renshuai Liu",
        "Yinglin Zheng",
        "Jing Liao",
        "Xuan Cheng"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 02:34:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04520v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04519v1",
      "title": "TokenSeg: Efficient 3D Medical Image Segmentation via Hierarchical Visual Token Compression",
      "abstract": "Three-dimensional medical image segmentation is a fundamental yet computationally demanding task due to the cubic growth of voxel processing and the redundant computation on homogeneous regions. To address these limitations, we propose \\textbf{TokenSeg}, a boundary-aware sparse token representation framework for efficient 3D medical volume segmentation. Specifically, (1) we design a \\emph{multi-scale hierarchical encoder} that extracts 400 candidate tokens across four resolution levels to capture both global anatomical context and fine boundary details; (2) we introduce a \\emph{boundary-aware tokenizer} that combines VQ-VAE quantization with importance scoring to select 100 salient tokens, over 60\\% of which lie near tumor boundaries; and (3) we develop a \\emph{sparse-to-dense decoder} that reconstructs full-resolution masks through token reprojection, progressive upsampling, and skip connections. Extensive experiments on a 3D breast DCE-MRI dataset comprising 960 cases demonstrate that TokenSeg achieves state-of-the-art performance with 94.49\\% Dice and 89.61\\% IoU, while reducing GPU memory and inference latency by 64\\% and 68\\%, respectively. To verify the generalization capability, our evaluations on MSD cardiac and brain MRI benchmark datasets demonstrate that TokenSeg consistently delivers optimal performance across heterogeneous anatomical structures. These results highlight the effectiveness of anatomically informed sparse representation for accurate and efficient 3D medical image segmentation.",
      "authors": [
        "Sen Zeng",
        "Hong Zhou",
        "Zheng Zhu",
        "Yang Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 02:32:48+00:00",
      "link": "https://arxiv.org/pdf/2601.04519v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04518v1",
      "title": "Integrating Distribution Matching into Semi-Supervised Contrastive Learning for Labeled and Unlabeled Data",
      "abstract": "The advancement of deep learning has greatly improved supervised image classification. However, labeling data is costly, prompting research into unsupervised learning methods such as contrastive learning. In real-world scenarios, fully unlabeled datasets are rare, making semi-supervised learning (SSL) highly relevant in scenarios where a small amount of labeled data coexists with a large volume of unlabeled data. A well-known semi-supervised contrastive learning approach involves assigning pseudo-labels to unlabeled data. This study aims to enhance pseudo-label-based SSL by incorporating distribution matching between labeled and unlabeled feature embeddings to improve image classification accuracy across multiple datasets.",
      "authors": [
        "Shogo Nakayama",
        "Masahiro Okuda"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 02:32:12+00:00",
      "link": "https://arxiv.org/pdf/2601.04518v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04511v1",
      "title": "Multiagent Reinforcement Learning with Neighbor Action Estimation",
      "abstract": "Multiagent reinforcement learning, as a prominent intelligent paradigm, enables collaborative decision-making within complex systems. However, existing approaches often rely on explicit action exchange between agents to evaluate action value functions, which is frequently impractical in real-world engineering environments due to communication constraints, latency, energy consumption, and reliability requirements. From an artificial intelligence perspective, this paper proposes an enhanced multiagent reinforcement learning framework that employs action estimation neural networks to infer agent behaviors. By integrating a lightweight action estimation module, each agent infers neighboring agents' behaviors using only locally observable information, enabling collaborative policy learning without explicit action sharing. This approach is fully compatible with standard TD3 algorithms and scalable to larger multiagent systems. At the engineering application level, this framework has been implemented and validated in dual-arm robotic manipulation tasks: two robotic arms collaboratively lift objects. Experimental results demonstrate that this approach significantly enhances the robustness and deployment feasibility of real-world robotic systems while reducing dependence on information infrastructure. Overall, this research advances the development of decentralized multiagent artificial intelligence systems while enabling AI to operate effectively in dynamic, information-constrained real-world environments.",
      "authors": [
        "Zhenglong Luo",
        "Zhiyong Chen",
        "Aoxiang Liu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "published": "2026-01-08 02:26:57+00:00",
      "link": "https://arxiv.org/pdf/2601.04511v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04509v1",
      "title": "A General Neural Backbone for Mixed-Integer Linear Optimization via Dual Attention",
      "abstract": "Mixed-integer linear programming (MILP), a widely used modeling framework for combinatorial optimization, are central to many scientific and engineering applications, yet remains computationally challenging at scale. Recent advances in deep learning address this challenge by representing MILP instances as variable-constraint bipartite graphs and applying graph neural networks (GNNs) to extract latent structural patterns and enhance solver efficiency. However, this architecture is inherently limited by the local-oriented mechanism, leading to restricted representation power and hindering neural approaches for MILP. Here we present an attention-driven neural architecture that learns expressive representations beyond the pure graph view. A dual-attention mechanism is designed to perform parallel self- and cross-attention over variables and constraints, enabling global information exchange and deeper representation learning. We apply this general backbone to various downstream tasks at the instance level, element level, and solving state level. Extensive experiments across widely used benchmarks show consistent improvements of our approach over state-of-the-art baselines, highlighting attention-based neural architectures as a powerful foundation for learning-enhanced mixed-integer linear optimization.",
      "authors": [
        "Peixin Huang",
        "Yaoxin Wu",
        "Yining Ma",
        "Cathy Wu",
        "Wen Song",
        "Wei Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 02:23:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04509v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04507v1",
      "title": "A Semi-supervised Molecular Learning Framework for Activity Cliff Estimation",
      "abstract": "Machine learning (ML) enables accurate and fast molecular property predictions, which are of interest in drug discovery and material design. Their success is based on the principle of similarity at its heart, assuming that similar molecules exhibit close properties. However, activity cliffs challenge this principle, and their presence leads to a sharp decline in the performance of existing ML algorithms, particularly graph-based methods. To overcome this obstacle under a low-data scenario, we propose a novel semi-supervised learning (SSL) method dubbed SemiMol, which employs predictions on numerous unannotated data as pseudo-signals for subsequent training. Specifically, we introduce an additional instructor model to evaluate the accuracy and trustworthiness of proxy labels because existing pseudo-labeling approaches require probabilistic outputs to reveal the model's confidence and fail to be applied in regression tasks. Moreover, we design a self-adaptive curriculum learning algorithm to progressively move the target model toward hard samples at a controllable pace. Extensive experiments on 30 activity cliff datasets demonstrate that SemiMol significantly enhances graph-based ML architectures and outpasses state-of-the-art pretraining and SSL baselines.",
      "authors": [
        "Fang Wu"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "published": "2026-01-08 02:20:25+00:00",
      "link": "https://arxiv.org/pdf/2601.04507v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04506v1",
      "title": "Surface-based Molecular Design with Multi-modal Flow Matching",
      "abstract": "Therapeutic peptides show promise in targeting previously undruggable binding sites, with recent advancements in deep generative models enabling full-atom peptide co-design for specific protein receptors. However, the critical role of molecular surfaces in protein-protein interactions (PPIs) has been underexplored. To bridge this gap, we propose an omni-design peptides generation paradigm, called SurfFlow, a novel surface-based generative algorithm that enables comprehensive co-design of sequence, structure, and surface for peptides. SurfFlow employs a multi-modality conditional flow matching (CFM) architecture to learn distributions of surface geometries and biochemical properties, enhancing peptide binding accuracy. Evaluated on the comprehensive PepMerge benchmark, SurfFlow consistently outperforms full-atom baselines across all metrics. These results highlight the advantages of considering molecular surfaces in de novo peptide discovery and demonstrate the potential of integrating multiple protein modalities for more effective therapeutic peptide discovery.",
      "authors": [
        "Fang Wu",
        "Zhengyuan Zhou",
        "Shuting Jin",
        "Xiangxiang Zeng",
        "Jure Leskovec",
        "Jinbo Xu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "published": "2026-01-08 02:19:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04506v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04505v1",
      "title": "CircuitLM: A Multi-Agent LLM-Aided Design Framework for Generating Circuit Schematics from Natural Language Prompts",
      "abstract": "Generating accurate circuit schematics from high-level natural language descriptions remains a persistent challenge in electronics design, as large language models (LLMs) frequently hallucinate in granular details, violate electrical constraints, and produce non-machine-readable outputs. We present CircuitLM, a novel multi-agent LLM-aided circuit design pipeline that translates user prompts into structured, visually interpretable CircuitJSON schematics through five sequential stages: (i) LLM-based component identification, (ii) canonical pinout retrieval, (iii) chain-of-thought reasoning by an electronics expert agent, (iv) JSON schematic synthesis, and (v) force-directed SVG visualization. Anchored by a curated, embedding-powered component knowledge base. While LLMs often violate electrical constraints, CircuitLM bridges this gap by grounding generation in a verified and dynamically extensible component database, initially comprising 50 components. To ensure safety, we incorporate a hybrid evaluation framework, namely Dual-Metric Circuit Validation (DMCV), validated against human-expert assessments, which achieves high fidelity in microcontroller-centric designs. We evaluate the system on 100 diverse embedded-systems prompts across six LLMs and introduce DMCV to assess both structural and electrical validity. This work bridges natural language input to deployable hardware designs, enabling reliable circuit prototyping by non-experts. Our code and data will be made public upon acceptance.",
      "authors": [
        "Khandakar Shakib Al Hasan",
        "Syed Rifat Raiyan",
        "Hasin Mahtab Alvee",
        "Wahid Sadik"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "eess.SY"
      ],
      "published": "2026-01-08 02:18:43+00:00",
      "link": "https://arxiv.org/pdf/2601.04505v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04500v1",
      "title": "GUITester: Enabling GUI Agents for Exploratory Defect Discovery",
      "abstract": "Exploratory GUI testing is essential for software quality but suffers from high manual costs. While Multi-modal Large Language Model (MLLM) agents excel in navigation, they fail to autonomously discover defects due to two core challenges: \\textit{Goal-Oriented Masking}, where agents prioritize task completion over reporting anomalies, and \\textit{Execution-Bias Attribution}, where system defects are misidentified as agent errors. To address these, we first introduce \\textbf{GUITestBench}, the first interactive benchmark for this task, featuring 143 tasks across 26 defects. We then propose \\textbf{GUITester}, a multi-agent framework that decouples navigation from verification via two modules: (i) a \\textit{Planning-Execution Module (PEM)} that proactively probes for defects via embedded testing intents, and (ii) a \\textit{Hierarchical Reflection Module (HRM)} that resolves attribution ambiguity through interaction history analysis. GUITester achieves an F1-score of 48.90\\% (Pass@3) on GUITestBench, outperforming state-of-the-art baselines (33.35\\%). Our work demonstrates the feasibility of autonomous exploratory testing and provides a robust foundation for future GUI quality assurance~\\footnote{Our code is now available in~\\href{https://github.com/ADaM-BJTU/GUITestBench}{https://github.com/ADaM-BJTU/GUITestBench}}.",
      "authors": [
        "Yifei Gao",
        "Jiang Wu",
        "Xiaoyi Chen",
        "Yifan Yang",
        "Zhe Cui",
        "Tianyi Ma",
        "Jiaming Zhang",
        "Jitao Sang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 02:07:53+00:00",
      "link": "https://arxiv.org/pdf/2601.04500v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04497v1",
      "title": "Vision-Language Agents for Interactive Forest Change Analysis",
      "abstract": "Modern forest monitoring workflows increasingly benefit from the growing availability of high-resolution satellite imagery and advances in deep learning. Two persistent challenges in this context are accurate pixel-level change detection and meaningful semantic change captioning for complex forest dynamics. While large language models (LLMs) are being adapted for interactive data exploration, their integration with vision-language models (VLMs) for remote sensing image change interpretation (RSICI) remains underexplored. To address this gap, we introduce an LLM-driven agent for integrated forest change analysis that supports natural language querying across multiple RSICI tasks. The proposed system builds upon a multi-level change interpretation (MCI) vision-language backbone with LLM-based orchestration. To facilitate adaptation and evaluation in forest environments, we further introduce the Forest-Change dataset, which comprises bi-temporal satellite imagery, pixel-level change masks, and multi-granularity semantic change captions generated using a combination of human annotation and rule-based methods. Experimental results show that the proposed system achieves mIoU and BLEU-4 scores of 67.10% and 40.17% on the Forest-Change dataset, and 88.13% and 34.41% on LEVIR-MCI-Trees, a tree-focused subset of LEVIR-MCI benchmark for joint change detection and captioning. These results highlight the potential of interactive, LLM-driven RSICI systems to improve accessibility, interpretability, and efficiency of forest change analysis. All data and code are publicly available at https://github.com/JamesBrockUoB/ForestChat.",
      "authors": [
        "James Brock",
        "Ce Zhang",
        "Nantheera Anantrasirichai"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 02:02:36+00:00",
      "link": "https://arxiv.org/pdf/2601.04497v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04487v1",
      "title": "Understanding Gaming the System by Analyzing Self-Regulated Learning in Think-Aloud Protocols",
      "abstract": "In digital learning systems, gaming the system refers to occasions when students attempt to succeed in an educational task by systematically taking advantage of system features rather than engaging meaningfully with the content. Often viewed as a form of behavioral disengagement, gaming the system is negatively associated with short- and long-term learning outcomes. However, little research has explored this phenomenon beyond its behavioral representation, leaving questions such as whether students are cognitively disengaged or whether they engage in different self-regulated learning (SRL) strategies when gaming largely unanswered. This study employs a mixed-methods approach to examine students' cognitive engagement and SRL processes during gaming versus non-gaming periods, using utterance length and SRL codes inferred from think-aloud protocols collected while students interacted with an intelligent tutoring system for chemistry. We found that gaming does not simply reflect a lack of cognitive effort; during gaming, students often produced longer utterances, were more likely to engage in processing information and realizing errors, but less likely to engage in planning, and exhibited reactive rather than proactive self-regulatory strategies. These findings provide empirical evidence supporting the interpretation that gaming may represent a maladaptive form of SRL. With this understanding, future work can address gaming and its negative impacts by designing systems that target maladaptive self-regulation to promote better learning.",
      "authors": [
        "Jiayi Zhang",
        "Conrad Borchers",
        "Canwen Wang",
        "Vishal Kumar",
        "Leah Teffera",
        "Bruce M. McLaren",
        "Ryan S. Baker"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "published": "2026-01-08 01:45:56+00:00",
      "link": "https://arxiv.org/pdf/2601.04487v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04486v1",
      "title": "Decision-Aware Trust Signal Alignment for SOC Alert Triage",
      "abstract": "Detection systems that utilize machine learning are progressively implemented at Security Operations Centers (SOCs) to help an analyst to filter through high volumes of security alerts. Practically, such systems tend to reveal probabilistic results or confidence scores which are ill-calibrated and hard to read when under pressure. Qualitative and survey based studies of SOC practice done before reveal that poor alert quality and alert overload greatly augment the burden on the analyst, especially when tool outputs are not coherent with decision requirements, or signal noise. One of the most significant limitations is that model confidence is usually shown without expressing that there are asymmetric costs in decision making where false alarms are much less harmful than missed attacks. The present paper presents a decision-sensitive trust signal correspondence scheme of SOC alert triage. The framework combines confidence that has been calibrated, lightweight uncertainty cues, and cost-sensitive decision thresholds into coherent decision-support layer, instead of making changes to detection models. To enhance probabilistic consistency, the calibration is done using the known post-hoc methods and the uncertainty cues give conservative protection in situations where model certainty is low. To measure the model-independent performance of the suggested model, we apply the Logistic Regression and the Random Forest classifiers to the UNSW-NB15 intrusion detection benchmark. According to simulation findings, false negatives are greatly amplified by the presence of misaligned displays of confidence, whereas cost weighted loss decreases by orders of magnitude between models with decision aligned trust signals. Lastly, we describe a human-in-the-loop study plan that would allow empirically assessing the decision-making of the analysts with aligned and misaligned trust interfaces.",
      "authors": [
        "Israt Jahan Chowdhury",
        "Md Abu Yousuf Tanvir"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC"
      ],
      "published": "2026-01-08 01:41:54+00:00",
      "link": "https://arxiv.org/pdf/2601.04486v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04483v1",
      "title": "Hybrid Federated Learning for Noise-Robust Training",
      "abstract": "Federated learning (FL) and federated distillation (FD) are distributed learning paradigms that train UE models with enhanced privacy, each offering different trade-offs between noise robustness and learning speed. To mitigate their respective weaknesses, we propose a hybrid federated learning (HFL) framework in which each user equipment (UE) transmits either gradients or logits, and the base station (BS) selects the per-round weights of FL and FD updates. We derive convergence of HFL framework and introduce two methods to exploit degrees of freedom (DoF) in HFL, which are (i) adaptive UE clustering via Jenks optimization and (ii) adaptive weight selection via a damped Newton method. Numerical results show that HFL achieves superior test accuracy at low SNR when both DoF are exploited.",
      "authors": [
        "Yongjun Kim",
        "Hyeongjun Park",
        "Hwanjin Kim",
        "Junil Choi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "eess.SP"
      ],
      "published": "2026-01-08 01:34:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04483v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04476v1",
      "title": "Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing",
      "abstract": "Recent hardware acceleration advances have enabled powerful specialized accelerators for finite element computations, spiking neural network inference, and sparse tensor operations. However, existing approaches face fundamental limitations: (1) finite element methods lack comprehensive rounding error analysis for reduced-precision implementations and use fixed precision assignment strategies that cannot adapt to varying numerical conditioning; (2) spiking neural network accelerators cannot handle non-spike operations and suffer from bit-width escalation as network depth increases; and (3) FPGA tensor accelerators optimize only for dense computations while requiring manual configuration for each sparsity pattern. To address these challenges, we introduce \\textbf{Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing}, a novel framework that integrates three enhanced modules with memory-guided adaptation for efficient mixed-workload processing on unified platforms. Our approach employs memory-guided precision selection to overcome fixed precision limitations, integrates experience-driven bit-width management and dynamic parallelism adaptation for enhanced spiking neural network acceleration, and introduces curriculum learning for automatic sparsity pattern discovery. Extensive experiments on FEniCS, COMSOL, ANSYS benchmarks, MNIST, CIFAR-10, CIFAR-100, DVS-Gesture datasets, and COCO 2017 demonstrate 2.8\\% improvement in numerical accuracy, 47\\% throughput increase, 34\\% energy reduction, and 45-65\\% throughput improvement compared to specialized accelerators. Our work enables unified processing of finite element methods, spiking neural networks, and sparse computations on a single platform while eliminating data transfer overhead between separate units.",
      "authors": [
        "Chuanzhen Wang",
        "Leo Zhang",
        "Eric Liu"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR"
      ],
      "published": "2026-01-08 01:28:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04476v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04474v1",
      "title": "Computational Compliance for AI Regulation: Blueprint for a New Research Domain",
      "abstract": "The era of AI regulation (AIR) is upon us. But AI systems, we argue, will not be able to comply with these regulations at the necessary speed and scale by continuing to rely on traditional, analogue methods of compliance. Instead, we posit that compliance with these regulations will only realistically be achieved computationally: that is, with algorithms that run across the life cycle of an AI system, automatically steering it toward AIR compliance in the face of dynamic conditions. Yet despite their (we would argue) inevitability, the research community has yet to specify exactly how these algorithms for computational AIR compliance should behave - or how we should benchmark their performance. To fill these gaps, we specify a set of design goals for such algorithms. In addition, we specify a benchmark dataset that can be used to quantitatively measure whether individual algorithms satisfy these design goals. By delivering this blueprint, we hope to give shape to an important but uncrystallized new domain of research - and, in doing so, incite necessary investment in it.",
      "authors": [
        "Bill Marino",
        "Nicholas D. Lane"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 01:22:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04474v1",
      "tags": [
        "keyword:RL",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04473v1",
      "title": "Convergence Rates for Learning Pseudo-Differential Operators",
      "abstract": "This paper establishes convergence rates for learning elliptic pseudo-differential operators, a fundamental operator class in partial differential equations and mathematical physics. In a wavelet-Galerkin framework, we formulate learning over this class as a structured infinite-dimensional regression problem with multiscale sparsity. Building on this structure, we propose a sparse, data- and computation-efficient estimator, which leverages a novel matrix compression scheme tailored to the learning task and a nested-support strategy to balance approximation and estimation errors. In addition to obtaining convergence rates for the estimator, we show that the learned operator induces an efficient and stable Galerkin solver whose numerical error matches its statistical accuracy. Our results therefore contribute to bringing together operator learning, data-driven solvers, and wavelet methods in scientific computing.",
      "authors": [
        "Jiaheng Chen",
        "Daniel Sanz-Alonso"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.LG",
        "math.NA",
        "stat.ML"
      ],
      "published": "2026-01-08 01:21:08+00:00",
      "link": "https://arxiv.org/pdf/2601.04473v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04462v1",
      "title": "Meta-probabilistic Modeling",
      "abstract": "While probabilistic graphical models can discover latent structure in data, their effectiveness hinges on choosing well-specified models. Identifying such models is challenging in practice, often requiring iterative checking and revision through trial and error. To this end, we propose meta-probabilistic modeling (MPM), a meta-learning algorithm that learns generative model structure directly from multiple related datasets. MPM uses a hierarchical architecture where global model specifications are shared across datasets while local parameters remain dataset-specific. For learning and inference, we propose a tractable VAE-inspired surrogate objective, and optimize it through bi-level optimization: local variables are updated analytically via coordinate ascent, while global parameters are trained with gradient-based methods. We evaluate MPM on object-centric image modeling and sequential text modeling, demonstrating that it adapts generative models to data while recovering meaningful latent representations.",
      "authors": [
        "Kevin Zhang",
        "Yixin Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 00:34:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04462v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04458v1",
      "title": "Using Large Language Models to Detect Socially Shared Regulation of Collaborative Learning",
      "abstract": "The field of learning analytics has made notable strides in automating the detection of complex learning processes in multimodal data. However, most advancements have focused on individualized problem-solving instead of collaborative, open-ended problem-solving, which may offer both affordances (richer data) and challenges (low cohesion) to behavioral prediction. Here, we extend predictive models to automatically detect socially shared regulation of learning (SSRL) behaviors in collaborative computational modeling environments using embedding-based approaches. We leverage large language models (LLMs) as summarization tools to generate task-aware representations of student dialogue aligned with system logs. These summaries, combined with text-only embeddings, context-enriched embeddings, and log-derived features, were used to train predictive models. Results show that text-only embeddings often achieve stronger performance in detecting SSRL behaviors related to enactment or group dynamics (e.g., off-task behavior or requesting assistance). In contrast, contextual and multimodal features provide complementary benefits for constructs such as planning and reflection. Overall, our findings highlight the promise of embedding-based models for extending learning analytics by enabling scalable detection of SSRL behaviors, ultimately supporting real-time feedback and adaptive scaffolding in collaborative learning environments that teachers value.",
      "authors": [
        "Jiayi Zhang",
        "Conrad Borchers",
        "Clayton Cohn",
        "Namrata Srivastava",
        "Caitlin Snyder",
        "Siyuan Guo",
        "Ashwin T S",
        "Naveeduddin Mohammed",
        "Haley Noh",
        "Gautam Biswas"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 00:30:46+00:00",
      "link": "https://arxiv.org/pdf/2601.04458v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04449v1",
      "title": "Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries",
      "abstract": "Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.",
      "authors": [
        "Daniel Sierra-Botero",
        "Ana Molina-Taborda",
        "Leonardo Espinosa-Leal",
        "Alexander Karpenko",
        "Alejandro Hernandez",
        "Olga Lopez-Acevedo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 23:35:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04449v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04445v1",
      "title": "SpectraFormer: an Attention-Based Raman Unmixing Tool for Accessing the Graphene Buffer-Layer Signature on SiC",
      "abstract": "Raman spectroscopy is a key tool for graphene characterization, yet its application to graphene grown on silicon carbide (SiC) is strongly limited by the intense and variable second-order Raman response of the substrate. This limitation is critical for buffer layer graphene, a semiconducting interfacial phase, whose vibrational signatures are overlapped with the SiC background and challenging to be reliably accessed using conventional reference-based subtraction, due to strong spatial and experimental variability of the substrate signal. Here we present SpectraFormer, a transformer-based deep learning model that reconstructs the SiC Raman substrate contribution directly from post-growth partially masked spectroscopic data without relying on explicit reference measurements. By learning global correlations across the entire Raman shift range, the model captures the statistical structure of the SiC background and enables accurate reconstruction of its contribution in mixed spectra. Subtraction of the reconstructed substrate signal reveals weak vibrational features associated with ZLG that are inaccessible through conventional analysis methods. The extracted spectra are validated by ab initio vibrational calculations, allowing assignment of the resolved features to specific modes and confirming their physical consistency. By leveraging a state-of-the-art attention-based deep learning architecture, this approach establishes a robust, reference-free framework for Raman analysis of graphene on SiC and provides a foundation, compatible with real-time data acquisition, to its integration into automated, closed-loop AI-assisted growth optimization.",
      "authors": [
        "Dmitriy Poteryayev",
        "Pietro Novelli",
        "Annalisa Coriolano",
        "Riccardo Dettori",
        "Valentina Tozzini",
        "Fabio Beltram",
        "Massimiliano Pontil",
        "Antonio Rossi",
        "Stiven Forti",
        "Camilla Coletti"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 23:20:19+00:00",
      "link": "https://arxiv.org/pdf/2601.04445v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04442v1",
      "title": "Addressing Overthinking in Large Vision-Language Models via Gated Perception-Reasoning Optimization",
      "abstract": "Large Vision-Language Models (LVLMs) have exhibited strong reasoning capabilities through chain-of-thought mechanisms that generate step-by-step rationales. However, such slow-thinking approaches often lead to overthinking, where models produce excessively verbose responses even for simple queries, resulting in test-time inefficiency and even degraded accuracy. Prior work has attempted to mitigate this issue via adaptive reasoning strategies, but these methods largely overlook a fundamental bottleneck: visual perception failures. We argue that stable reasoning critically depends on low-level visual grounding, and that reasoning errors often originate from imperfect perception rather than insufficient deliberation. To address this limitation, we propose Gated Perception-Reasoning Optimization (GPRO), a meta-reasoning controller that dynamically routes computation among three decision paths at each generation step: a lightweight fast path, a slow perception path for re-examining visual inputs, and a slow reasoning path for internal self-reflection. To learn this distinction, we derive large-scale failure attribution supervision from approximately 790k samples, using teacher models to distinguish perceptual hallucinations from reasoning errors. We then train the controller with multi-objective reinforcement learning to optimize the trade-off between task accuracy and computational cost under uncertainty. Experiments on five benchmarks demonstrate that GPRO substantially improves both accuracy and efficiency, outperforming recent slow-thinking methods while generating significantly shorter responses.",
      "authors": [
        "Xingjian Diao",
        "Zheyuan Liu",
        "Chunhui Zhang",
        "Weiyi Wu",
        "Keyi Kong",
        "Lin Shi",
        "Kaize Ding",
        "Soroush Vosoughi",
        "Jiang Gui"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.CL"
      ],
      "published": "2026-01-07 23:05:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04442v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04441v1",
      "title": "Improving and Accelerating Offline RL in Large Discrete Action Spaces with Structured Policy Initialization",
      "abstract": "Reinforcement learning in discrete combinatorial action spaces requires searching over exponentially many joint actions to simultaneously select multiple sub-actions that form coherent combinations. Existing approaches either simplify policy learning by assuming independence across sub-actions, which often yields incoherent or invalid actions, or attempt to learn action structure and control jointly, which is slow and unstable. We introduce Structured Policy Initialization (SPIN), a two-stage framework that first pre-trains an Action Structure Model (ASM) to capture the manifold of valid actions, then freezes this representation and trains lightweight policy heads for control. On challenging discrete DM Control benchmarks, SPIN improves average return by up to 39% over the state of the art while reducing time to convergence by up to 12.8$\\times$.",
      "authors": [
        "Matthew Landers",
        "Taylor W. Killian",
        "Thomas Hartvigsen",
        "Afsaneh Doryab"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 22:57:21+00:00",
      "link": "https://arxiv.org/pdf/2601.04441v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04428v1",
      "title": "CRUNet-MR-Univ: A Foundation Model for Diverse Cardiac MRI Reconstruction",
      "abstract": "In recent years, deep learning has attracted increasing attention in the field of Cardiac MRI (CMR) reconstruction due to its superior performance over traditional methods, particularly in handling higher acceleration factors, highlighting its potential for real-world clinical applications. However, current deep learning methods remain limited in generalizability. CMR scans exhibit wide variability in image contrast, sampling patterns, scanner vendors, anatomical structures, and disease types. Most existing models are designed to handle only a single or narrow subset of these variations, leading to performance degradation when faced with distribution shifts. Therefore, it is beneficial to develop a unified model capable of generalizing across diverse CMR scenarios. To this end, we propose CRUNet-MR-Univ, a foundation model that leverages spatio-temporal correlations and prompt-based priors to effectively handle the full diversity of CMR scans. Our approach consistently outperforms baseline methods across a wide range of settings, highlighting its effectiveness and promise.",
      "authors": [
        "Donghang Lyu",
        "Marius Staring",
        "Hildo Lamb",
        "Mariya Doneva"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 22:23:56+00:00",
      "link": "https://arxiv.org/pdf/2601.04428v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04416v1",
      "title": "Transitive Expert Error and Routing Problems in Complex AI Systems",
      "abstract": "Domain expertise enhances judgment within boundaries but creates systematic vulnerabilities specifically at borders. We term this Transitive Expert Error (TEE), distinct from Dunning-Kruger effects, requiring calibrated expertise as precondition. Mechanisms enabling reliable within-domain judgment become liabilities when structural similarity masks causal divergence. Two core mechanisms operate: structural similarity bias causes experts to overweight surface features (shared vocabulary, patterns, formal structure) while missing causal architecture differences; authority persistence maintains confidence across competence boundaries through social reinforcement and metacognitive failures (experts experience no subjective uncertainty as pattern recognition operates smoothly on familiar-seeming inputs.) These mechanism intensify under three conditions: shared vocabulary masking divergent processes, social pressure for immediate judgment, and delayed feedback. These findings extend to AI routing architectures (MoE systems, multi-model orchestration, tool-using agents, RAG systems) exhibiting routing-induced failures (wrong specialist selected) and coverage-induced failures (no appropriate specialist exists). Both produce a hallucination phenotype: confident, coherent, structurally plausible but causally incorrect outputs at domain boundaries. In human systems where mechanisms are cognitive black boxes; AI architectures make them explicit and addressable. We propose interventions: multi-expert activation with disagreement detection (router level), boundary-aware calibration (specialist level), and coverage gap detection (training level). TEE has detectable signatures (routing patterns, confidence-accuracy dissociations, domain-inappropriate content) enabling monitoring and mitigation. What remains intractable in human cognition becomes addressable through architectural design.",
      "authors": [
        "Forest Mars"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 21:53:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04416v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04413v1",
      "title": "Distribution-Guided and Constrained Quantum Machine Unlearning",
      "abstract": "Machine unlearning aims to remove the influence of specific training data from a learned model without full retraining. While recent work has begun to explore unlearning in quantum machine learning, existing approaches largely rely on fixed, uniform target distributions and do not explicitly control the trade-off between forgetting and retained model behaviour. In this work, we propose a distribution-guided framework for class-level quantum machine unlearning that treats unlearning as a constrained optimization problem. Our method introduces a tunable target distribution derived from model similarity statistics, decoupling the suppression of forgotten-class confidence from assumptions about redistribution among retained classes. We further incorporate an anchor-based preservation constraint that explicitly maintains predictive behaviour on selected retained data, yielding a controlled optimization trajectory that limits deviation from the original model. We evaluate the approach on variational quantum classifiers trained on the Iris and Covertype datasets. Results demonstrate sharp suppression of forgotten-class confidence, minimal degradation of retained-class performance, and closer alignment with the gold retrained model baselines compared to uniform-target unlearning. These findings highlight the importance of target design and constraint-based formulations for reliable and interpretable quantum machine unlearning.",
      "authors": [
        "Nausherwan Malik",
        "Zubair Khalid",
        "Muhammad Faryad"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "quant-ph"
      ],
      "published": "2026-01-07 21:44:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04413v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04411v1",
      "title": "Rate or Fate? RLV$^\\varepsilon$R: Reinforcement Learning with Verifiable Noisy Rewards",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) is a simple but powerful paradigm for training LLMs: sample a completion, verify it, and update. In practice, however, the verifier is almost never clean--unit tests probe only limited corner cases; human and synthetic labels are imperfect; and LLM judges (e.g., RLAIF) are noisy and can be exploited--and this problem worsens on harder domains (especially coding) where tests are sparse and increasingly model-generated. We ask a pragmatic question: does the verification noise merely slow down the learning (rate), or can it flip the outcome (fate)?   To address this, we develop an analytically tractable multi-armed bandit view of RLVR dynamics, instantiated with GRPO and validated in controlled experiments. Modeling false positives and false negatives and grouping completions into recurring reasoning modes yields a replicator-style (natural-selection) flow on the probability simplex. The dynamics decouples into within-correct-mode competition and a one-dimensional evolution for the mass on incorrect modes, whose drift is determined solely by Youden's index J=TPR-FPR. This yields a sharp phase transition: when J>0, the incorrect mass is driven toward extinction (learning); when J=0, the process is neutral; and when J<0, incorrect modes amplify until they dominate (anti-learning and collapse). In the learning regime J>0, noise primarily rescales convergence time (\"rate, not fate\"). Experiments on verifiable programming tasks under synthetic noise reproduce the predicted J=0 boundary. Beyond noise, the framework offers a general lens for analyzing RLVR stability, convergence, and algorithmic interventions.",
      "authors": [
        "Ali Rad",
        "Khashayar Filom",
        "Darioush Keivan",
        "Peyman Mohajerin Esfahani",
        "Ehsan Kamalinejad"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 21:31:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04411v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04401v1",
      "title": "Transformer-based Multi-agent Reinforcement Learning for Separation Assurance in Structured and Unstructured Airspaces",
      "abstract": "Conventional optimization-based metering depends on strict adherence to precomputed schedules, which limits the flexibility required for the stochastic operations of Advanced Air Mobility (AAM). In contrast, multi-agent reinforcement learning (MARL) offers a decentralized, adaptive framework that can better handle uncertainty, required for safe aircraft separation assurance. Despite this advantage, current MARL approaches often overfit to specific airspace structures, limiting their adaptability to new configurations. To improve generalization, we recast the MARL problem in a relative polar state space and train a transformer encoder model across diverse traffic patterns and intersection angles. The learned model provides speed advisories to resolve conflicts while maintaining aircraft near their desired cruising speeds. In our experiments, we evaluated encoder depths of 1, 2, and 3 layers in both structured and unstructured airspaces, and found that a single encoder configuration outperformed deeper variants, yielding near-zero near mid-air collision rates and shorter loss-of-separation infringements than the deeper configurations. Additionally, we showed that the same configuration outperforms a baseline model designed purely with attention. Together, our results suggest that the newly formulated state representation, novel design of neural network architecture, and proposed training strategy provide an adaptable and scalable decentralized solution for aircraft separation assurance in both structured and unstructured airspaces.",
      "authors": [
        "Arsyi Aziz",
        "Peng Wei"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-01-07 21:18:28+00:00",
      "link": "https://arxiv.org/pdf/2601.04401v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04397v1",
      "title": "Performance Analysis of Image Classification on Bangladeshi Datasets",
      "abstract": "Convolutional Neural Networks (CNNs) have demonstrated remarkable success in image classification tasks; however, the choice between designing a custom CNN from scratch and employing established pre-trained architectures remains an important practical consideration. In this work, we present a comparative analysis of a custom-designed CNN and several widely used deep learning architectures, including VGG-16, ResNet-50, and MobileNet, for an image classification task. The custom CNN is developed and trained from scratch, while the popular architectures are employed using transfer learning under identical experimental settings. All models are evaluated using standard performance metrics such as accuracy, precision, recall, and F1-score. Experimental results show that pre-trained CNN architectures consistently outperform the custom CNN in terms of classification accuracy and convergence speed, particularly when training data is limited. However, the custom CNN demonstrates competitive performance with significantly fewer parameters and reduced computational complexity. This study highlights the trade-offs between model complexity, performance, and computational efficiency, and provides practical insights into selecting appropriate CNN architectures for image classification problems.",
      "authors": [
        "Mohammed Sami Khan",
        "Fabiha Muniat",
        "Rowzatul Zannat"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 21:15:16+00:00",
      "link": "https://arxiv.org/pdf/2601.04397v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04392v1",
      "title": "Enhanced-FQL($λ$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay",
      "abstract": "This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($λ$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach employs an interpretable fuzzy rule base instead of complex neural architectures, while maintaining competitive performance through two key innovations: a fuzzified Bellman equation with eligibility traces for stable multi-step credit assignment, and a memory-efficient segment-based experience replay mechanism for enhanced sample efficiency. Theoretical analysis proves the proposed method convergence under standard assumptions. Extensive evaluations in continuous control domains demonstrate that Enhanced-FQL($λ$) achieves superior sample efficiency and reduced variance compared to n-step fuzzy TD and fuzzy SARSA($λ$) baselines, while maintaining substantially lower computational complexity than deep RL alternatives such as DDPG. The framework's inherent interpretability, combined with its computational efficiency and theoretical convergence guarantees, makes it particularly suitable for safety-critical applications where transparency and resource constraints are essential.",
      "authors": [
        "Mohsen Jalaeian-Farimani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "eess.SY",
        "math.OC"
      ],
      "published": "2026-01-07 20:59:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04392v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04390v1",
      "title": "SciFig: Towards Automating Scientific Figure Generation",
      "abstract": "Creating high-quality figures and visualizations for scientific papers is a time-consuming task that requires both deep domain knowledge and professional design skills. Despite over 2.5 million scientific papers published annually, the figure generation process remains largely manual. We introduce $\\textbf{SciFig}$, an end-to-end AI agent system that generates publication-ready pipeline figures directly from research paper texts. SciFig uses a hierarchical layout generation strategy, which parses research descriptions to identify component relationships, groups related elements into functional modules, and generates inter-module connections to establish visual organization. Furthermore, an iterative chain-of-thought (CoT) feedback mechanism progressively improves layouts through multiple rounds of visual analysis and reasoning. We introduce a rubric-based evaluation framework that analyzes 2,219 real scientific figures to extract evaluation rubrics and automatically generates comprehensive evaluation criteria. SciFig demonstrates remarkable performance: achieving 70.1$\\%$ overall quality on dataset-level evaluation and 66.2$\\%$ on paper-specific evaluation, and consistently high scores across metrics such as visual clarity, structural organization, and scientific accuracy. SciFig figure generation pipeline and our evaluation benchmark will be open-sourced.",
      "authors": [
        "Siyuan Huang",
        "Yutong Gao",
        "Juyang Bai",
        "Yifan Zhou",
        "Zi Yin",
        "Xinxin Liu",
        "Rama Chellappa",
        "Chun Pong Lau",
        "Sayan Nag",
        "Cheng Peng",
        "Shraman Pramanick"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 20:56:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04390v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04389v1",
      "title": "MiJaBench: Revealing Minority Biases in Large Language Models via Hate Speech Jailbreaking",
      "abstract": "Current safety evaluations of large language models (LLMs) create a dangerous illusion of universality, aggregating \"Identity Hate\" into scalar scores that mask systemic vulnerabilities against specific populations. To expose this selective safety, we introduce MiJaBench, a bilingual (English and Portuguese) adversarial benchmark comprising 44,000 prompts across 16 minority groups. By generating 528,000 prompt-response pairs from 12 state-of-the-art LLMs, we curate MiJaBench-Align, revealing that safety alignment is not a generalized semantic capability but a demographic hierarchy: defense rates fluctuate by up to 33\\% within the same model solely based on the target group. Crucially, we demonstrate that model scaling exacerbates these disparities, suggesting that current alignment techniques do not create principle of non-discrimination but reinforces memorized refusal boundaries only for specific groups, challenging the current scaling laws of security. We release all datasets and scripts to encourage research into granular demographic alignment at GitHub.",
      "authors": [
        "Iago Alves Brito",
        "Walcy Santos Rezende Rios",
        "Julia Soares Dollis",
        "Diogo Fernandes Costa Silva",
        "Arlindo Rodrigues Galvão Filho"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 20:53:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04389v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04378v1",
      "title": "Aligned explanations in neural networks",
      "abstract": "Feature attribution is the dominant paradigm for explaining deep neural networks. However, most existing methods only loosely reflect the model's prediction-making process, thereby merely white-painting the black box. We argue that explanatory alignment is a key aspect of trustworthiness in prediction tasks: explanations must be directly linked to predictions, rather than serving as post-hoc rationalizations. We present model readability as a design principle enabling alignment, and PiNets as a modeling framework to pursue it in a deep learning context. PiNets are pseudo-linear networks that produce instance-wise linear predictions in an arbitrary feature space, making them linearly readable. We illustrate their use on image classification and segmentation tasks, demonstrating how PiNets produce explanations that are faithful across multiple criteria in addition to alignment.",
      "authors": [
        "Corentin Lobet",
        "Francesca Chiaromonte"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV",
        "stat.ML"
      ],
      "published": "2026-01-07 20:35:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04378v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04367v1",
      "title": "Graph Integrated Transformers for Community Detection in Social Networks",
      "abstract": "Community detection is crucial for applications like targeted marketing and recommendation systems. Traditional methods rely on network structure, and embedding-based models integrate semantic information. However, there is a challenge when a model leverages local and global information from complex structures like social networks. Graph Neural Networks (GNNs) and Transformers have shown superior performance in capturing local and global relationships. In this paper, We propose Graph Integrated Transformer for Community Detection (GIT-CD), a hybrid model combining GNNs and Transformer-based attention mechanisms to enhance community detection in social networks. Specifically, the GNN module captures local graph structures, while the Transformer module models long-range dependencies. A self-optimizing clustering module refines community assignments using K-Means, silhouette loss, and KL divergence minimization. Experimental results on benchmark datasets show that GIT-CD outperforms state-of-the-art models, making it a robust approach for detecting meaningful communities in complex social networks.",
      "authors": [
        "Heba Zahran",
        "M. Omair Shafiq"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "published": "2026-01-07 20:13:32+00:00",
      "link": "https://arxiv.org/pdf/2601.04367v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04366v1",
      "title": "Machine Learning Model for Sparse PCM Completion",
      "abstract": "In this paper, we propose a machine learning model for sparse pairwise comparison matrices (PCMs), combining classical PCM approaches with graph-based learning techniques. Numerical results are provided to demonstrate the effectiveness and scalability of the proposed method.",
      "authors": [
        "Selcuk Koyuncu",
        "Ronak Nouri",
        "Stephen Providence"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-01-07 20:13:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04366v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04365v1",
      "title": "Survival Dynamics of Neural and Programmatic Policies in Evolutionary Reinforcement Learning",
      "abstract": "In evolutionary reinforcement learning tasks (ERL), agent policies are often encoded as small artificial neural networks (NERL). Such representations lack explicit modular structure, limiting behavioral interpretation. We investigate whether programmatic policies (PERL), implemented as soft, differentiable decision lists (SDDL), can match the performance of NERL. To support reproducible evaluation, we provide the first fully specified and open-source reimplementation of the classic 1992 Artificial Life (ALife) ERL testbed. We conduct a rigorous survival analysis across 4000 independent trials utilizing Kaplan-Meier curves and Restricted Mean Survival Time (RMST) metrics absent in the original study. We find a statistically significant difference in survival probability between PERL and NERL. PERL agents survive on average 201.69 steps longer than NERL agents. Moreover, SDDL agents using learning alone (no evolution) survive on average 73.67 steps longer than neural agents using both learning and evaluation. These results demonstrate that programmatic policies can exceed the survival performance of neural policies in ALife.",
      "authors": [
        "Anton Roupassov-Ruiz",
        "Yiyang Zuo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 20:09:28+00:00",
      "link": "https://arxiv.org/pdf/2601.04365v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04361v1",
      "title": "Causally-Aware Information Bottleneck for Domain Adaptation",
      "abstract": "We tackle a common domain adaptation setting in causal systems. In this setting, the target variable is observed in the source domain but is entirely missing in the target domain. We aim to impute the target variable in the target domain from the remaining observed variables under various shifts. We frame this as learning a compact, mechanism-stable representation. This representation preserves information relevant for predicting the target while discarding spurious variation. For linear Gaussian causal models, we derive a closed-form Gaussian Information Bottleneck (GIB) solution. This solution reduces to a canonical correlation analysis (CCA)-style projection and offers Directed Acyclic Graph (DAG)-aware options when desired. For nonlinear or non-Gaussian data, we introduce a Variational Information Bottleneck (VIB) encoder-predictor. This approach scales to high dimensions and can be trained on source data and deployed zero-shot to the target domain. Across synthetic and real datasets, our approach consistently attains accurate imputations, supporting practical use in high-dimensional causal models and furnishing a unified, lightweight toolkit for causal domain adaptation.",
      "authors": [
        "Mohammad Ali Javidian"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 19:54:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04361v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04352v1",
      "title": "Comparative Analysis of Custom CNN Architectures versus Pre-trained Models and Transfer Learning: A Study on Five Bangladesh Datasets",
      "abstract": "This study presents a comprehensive comparative analysis of custom-built Convolutional Neural Networks (CNNs) against popular pre-trained architectures (ResNet-18 and VGG-16) using both feature extraction and transfer learning approaches. We evaluated these models across five diverse image classification datasets from Bangladesh: Footpath Vision, Auto Rickshaw Detection, Mango Image Classification, Paddy Variety Recognition, and Road Damage Detection. Our experimental results demonstrate that transfer learning with fine-tuning consistently outperforms both custom CNNs built from scratch and feature extraction methods, achieving accuracy improvements ranging from 3% to 76% across different datasets. Notably, ResNet-18 with fine-tuning achieved perfect 100% accuracy on the Road Damage BD dataset. While custom CNNs offer advantages in model size (3.4M parameters vs. 11-134M for pre-trained models) and training efficiency on simpler tasks, pre-trained models with transfer learning provide superior performance, particularly on complex classification tasks with limited training data. This research provides practical insights for practitioners in selecting appropriate deep learning approaches based on dataset characteristics, computational resources, and performance requirements.",
      "authors": [
        "Ibrahim Tanvir",
        "Alif Ruslan",
        "Sartaj Solaiman"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-07 19:36:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04352v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04339v1",
      "title": "Unified Text-Image Generation with Weakness-Targeted Post-Training",
      "abstract": "Unified multimodal generation architectures that jointly produce text and images have recently emerged as a promising direction for text-to-image (T2I) synthesis. However, many existing systems rely on explicit modality switching, generating reasoning text before switching manually to image generation. This separate, sequential inference process limits cross-modal coupling and prohibits automatic multimodal generation. This work explores post-training to achieve fully unified text-image generation, where models autonomously transition from textual reasoning to visual synthesis within a single inference process. We examine the impact of joint text-image generation on T2I performance and the relative importance of each modality during post-training. We additionally explore different post-training data strategies, showing that a targeted dataset addressing specific limitations achieves superior results compared to broad image-caption corpora or benchmark-aligned data. Using offline, reward-weighted post-training with fully self-generated synthetic data, our approach enables improvements in multimodal image generation across four diverse T2I benchmarks, demonstrating the effectiveness of reward-weighting both modalities and strategically designed post-training data.",
      "authors": [
        "Jiahui Chen",
        "Philippe Hansen-Estruch",
        "Xiaochuang Han",
        "Yushi Hu",
        "Emily Dinan",
        "Amita Kamath",
        "Michal Drozdzal",
        "Reyhane Askari-Hemmat",
        "Luke Zettlemoyer",
        "Marjan Ghazvininejad"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 19:19:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04339v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04334v1",
      "title": "Autonomous Reasoning for Spacecraft Control: A Large Language Model Framework with Group Relative Policy Optimization",
      "abstract": "This paper presents a learning-based guidance-and-control approach that couples a reasoning-enabled Large Language Model (LLM) with Group Relative Policy Optimization (GRPO). A two-stage procedure consisting of Supervised Fine-Tuning (SFT) to learn formatting and control primitives, followed by GRPO for interaction-driven policy improvement, trains controllers for each environment. The framework is demonstrated on four control problems spanning a gradient of dynamical complexity, from canonical linear systems through nonlinear oscillatory dynamics to three-dimensional spacecraft attitude control with gyroscopic coupling and thrust constraints. Results demonstrate that an LLM with explicit reasoning, optimized via GRPO, can synthesize feasible stabilizing policies under consistent training settings across both linear and nonlinear systems. The two-stage training methodology enables models to generate control sequences while providing human-readable explanations of their decision-making process. This work establishes a foundation for applying GRPO-based reasoning to autonomous control systems, with potential applications in aerospace and other safety-critical domains.",
      "authors": [
        "Amit Jain",
        "Richard Linares"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "math.OC"
      ],
      "published": "2026-01-07 19:13:22+00:00",
      "link": "https://arxiv.org/pdf/2601.04334v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04177v1",
      "title": "Hierarchical GNN-Based Multi-Agent Learning for Dynamic Queue-Jump Lane and Emergency Vehicle Corridor Formation",
      "abstract": "Emergency vehicles require rapid passage through congested traffic, yet existing strategies fail to adapt to dynamic conditions. We propose a novel hierarchical graph neural network (GNN)-based multi-agent reinforcement learning framework to coordinate connected vehicles for emergency corridor formation. Our approach uses a high-level planner for global strategy and low-level controllers for trajectory execution, utilizing graph attention networks to scale with variable agent counts. Trained via Multi-Agent Proximal Policy Optimization (MAPPO), the system reduces emergency vehicle travel time by 28.3% compared to baselines and 44.6% compared to uncoordinated traffic in simulations. The design achieves near-zero collision rates (0.3%) while maintaining 81% of background traffic efficiency. Ablation and generalization studies confirm the framework's robustness across diverse scenarios. These results demonstrate the effectiveness of combining GNNs with hierarchical learning for intelligent transportation systems.",
      "authors": [
        "Haoran Su"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "eess.SY"
      ],
      "published": "2026-01-07 18:43:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04177v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04176v1",
      "title": "Robust Physics Discovery from Highly Corrupted Data: A PINN Framework Applied to the Nonlinear Schrödinger Equation",
      "abstract": "We demonstrate a deep learning framework capable of recovering physical parameters from the Nonlinear Schrodinger Equation (NLSE) under severe noise conditions. By integrating Physics-Informed Neural Networks (PINNs) with automatic differentiation, we achieve reconstruction of the nonlinear coefficient beta with less than 0.2 percent relative error using only 500 sparse, randomly sampled data points corrupted by 20 percent additive Gaussian noise, a regime where traditional finite difference methods typically fail due to noise amplification in numerical derivatives. We validate the method's generalization capabilities across different physical regimes (beta between 0.5 and 2.0) and varying data availability (between 100 and 1000 training points), demonstrating consistent sub-1 percent accuracy. Statistical analysis over multiple independent runs confirms robustness (standard deviation less than 0.15 percent for beta equals 1.0). The complete pipeline executes in approximately 80 minutes on modest cloud GPU resources (NVIDIA Tesla T4), making the approach accessible for widespread adoption. Our results indicate that physics-based regularization acts as an effective filter against high measurement uncertainty, positioning PINNs as a viable alternative to traditional optimization methods for inverse problems in spatiotemporal dynamics where experimental data is scarce and noisy. All code is made publicly available to facilitate reproducibility.",
      "authors": [
        "Pietro de Oliveira Esteves"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.comp-ph"
      ],
      "published": "2026-01-07 18:43:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04176v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04171v1",
      "title": "Agentic Rubrics as Contextual Verifiers for SWE Agents",
      "abstract": "Verification is critical for improving agents: it provides the reward signal for Reinforcement Learning and enables inference-time gains through Test-Time Scaling (TTS). Despite its importance, verification in software engineering (SWE) agent settings often relies on code execution, which can be difficult to scale due to environment setup overhead. Scalable alternatives such as patch classifiers and heuristic methods exist, but they are less grounded in codebase context and harder to interpret. To this end, we explore Agentic Rubrics: an expert agent interacts with the repository to create a context-grounded rubric checklist, and candidate patches are then scored against it without requiring test execution. On SWE-Bench Verified under parallel TTS evaluation, Agentic Rubrics achieve a score of 54.2% on Qwen3-Coder-30B-A3B and 40.6% on Qwen3-32B, with at least a +3.5 percentage-point gain over the strongest baseline in our comparison set. We further analyze rubric behavior, showing that rubric scores are consistent with ground-truth tests while also flagging issues that tests do not capture. Our ablations show that agentic context gathering is essential for producing codebase-specific, unambiguous criteria. Together, these results suggest that Agentic Rubrics provide an efficient, scalable, and granular verification signal for SWE agents.",
      "authors": [
        "Mohit Raghavendra",
        "Anisha Gunjal",
        "Bing Liu",
        "Yunzhong He"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 18:38:23+00:00",
      "link": "https://arxiv.org/pdf/2601.04171v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04160v2",
      "title": "All That Glisters Is Not Gold: A Benchmark for Reference-Free Counterfactual Financial Misinformation Detection",
      "abstract": "We introduce RFC Bench, a benchmark for evaluating large language models on financial misinformation under realistic news. RFC Bench operates at the paragraph level and captures the contextual complexity of financial news where meaning emerges from dispersed cues. The benchmark defines two complementary tasks: reference free misinformation detection and comparison based diagnosis using paired original perturbed inputs. Experiments reveal a consistent pattern: performance is substantially stronger when comparative context is available, while reference free settings expose significant weaknesses, including unstable predictions and elevated invalid outputs. These results indicate that current models struggle to maintain coherent belief states without external grounding. By highlighting this gap, RFC Bench provides a structured testbed for studying reference free reasoning and advancing more reliable financial misinformation detection in real world settings.",
      "authors": [
        "Yuechen Jiang",
        "Zhiwei Liu",
        "Yupeng Cao",
        "Yueru He",
        "Chen Xu",
        "Ziyang Xu",
        "Zhiyang Deng",
        "Prayag Tiwari",
        "Xi Chen",
        "Alejandro Lopez-Lira",
        "Jimin Huang",
        "Junichi Tsujii",
        "Sophia Ananiadou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CE",
        "q-fin.CP"
      ],
      "published": "2026-01-07 18:18:28+00:00",
      "link": "https://arxiv.org/pdf/2601.04160v2",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04131v1",
      "title": "ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models",
      "abstract": "Large Language Models (LLMs) encode vast amounts of parametric knowledge during pre-training. As world knowledge evolves, effective deployment increasingly depends on their ability to faithfully follow externally retrieved context. When such evidence conflicts with the model's internal knowledge, LLMs often default to memorized facts, producing unfaithful outputs. In this work, we introduce ContextFocus, a lightweight activation steering approach that improves context faithfulness in such knowledge-conflict settings while preserving fluency and efficiency. Unlike prior approaches, our solution requires no model finetuning and incurs minimal inference-time overhead, making it highly efficient. We evaluate ContextFocus on the ConFiQA benchmark, comparing it against strong baselines including ContextDPO, COIECD, and prompting-based methods. Furthermore, we show that our method is complementary to prompting strategies and remains effective on larger models. Extensive experiments show that ContextFocus significantly improves contextual-faithfulness. Our results highlight the effectiveness, robustness, and efficiency of ContextFocus in improving contextual-faithfulness of LLM outputs.",
      "authors": [
        "Nikhil Anand",
        "Shwetha Somasundaram",
        "Anirudh Phukan",
        "Apoorv Saxena",
        "Koyel Mukherjee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 17:45:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04131v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04126v2",
      "title": "InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training",
      "abstract": "GUI agents that interact with graphical interfaces on behalf of users represent a promising direction for practical AI assistants. However, training such agents is hindered by the scarcity of suitable environments. We present InfiniteWeb, a system that automatically generates functional web environments at scale for GUI agent training. While LLMs perform well on generating a single webpage, building a realistic and functional website with many interconnected pages faces challenges. We address these challenges through unified specification, task-centric test-driven development, and a combination of website seed with reference design image to ensure diversity. Our system also generates verifiable task evaluators enabling dense reward signals for reinforcement learning. Experiments show that InfiniteWeb surpasses commercial coding agents at realistic website construction, and GUI agents trained on our generated environments achieve significant performance improvements on OSWorld and Online-Mind2Web, demonstrating the effectiveness of proposed system.",
      "authors": [
        "Ziyun Zhang",
        "Zezhou Wang",
        "Xiaoyi Zhang",
        "Zongyu Guo",
        "Jiahao Li",
        "Bin Li",
        "Yan Lu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-07 17:40:08+00:00",
      "link": "https://arxiv.org/pdf/2601.04126v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04120v1",
      "title": "A Single-Loop Bilevel Deep Learning Method for Optimal Control of Obstacle Problems",
      "abstract": "Optimal control of obstacle problems arises in a wide range of applications and is computationally challenging due to its nonsmoothness, nonlinearity, and bilevel structure. Classical numerical approaches rely on mesh-based discretization and typically require solving a sequence of costly subproblems. In this work, we propose a single-loop bilevel deep learning method, which is mesh-free, scalable to high-dimensional and complex domains, and avoids repeated solution of discretized subproblems. The method employs constraint-embedding neural networks to approximate the state and control and preserves the bilevel structure. To train the neural networks efficiently, we propose a Single-Loop Stochastic First-Order Bilevel Algorithm (S2-FOBA), which eliminates nested optimization and does not rely on restrictive lower-level uniqueness assumptions. We analyze the convergence behavior of S2-FOBA under mild assumptions. Numerical experiments on benchmark examples, including distributed and obstacle control problems with regular and irregular obstacles on complex domains, demonstrate that the proposed method achieves satisfactory accuracy while reducing computational cost compared to classical numerical methods.",
      "authors": [
        "Yongcun Song",
        "Shangzhi Zeng",
        "Jin Zhang",
        "Lvgang Zhang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-01-07 17:30:42+00:00",
      "link": "https://arxiv.org/pdf/2601.04120v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04118v2",
      "title": "GeoReason: Aligning Thinking And Answering In Remote Sensing Vision-Language Models Via Logical Consistency Reinforcement Learning",
      "abstract": "The evolution of Remote Sensing Vision-Language Models(RS-VLMs) emphasizes the importance of transitioning from perception-centric recognition toward high-level deductive reasoning to enhance cognitive reliability in complex spatial tasks. However, current models often suffer from logical hallucinations, where correct answers are derived from flawed reasoning chains or rely on positional shortcuts rather than spatial logic. This decoupling undermines reliability in strategic spatial decision-making. To address this, we present GeoReason, a framework designed to synchronize internal thinking with final decisions. We first construct GeoReason-Bench, a logic-driven dataset containing 4,000 reasoning trajectories synthesized from geometric primitives and expert knowledge. We then formulate a two-stage training strategy: (1) Supervised Knowledge Initialization to equip the model with reasoning syntax and domain expertise, and (2) Consistency-Aware Reinforcement Learning to refine deductive reliability. This second stage integrates a novel Logical Consistency Reward, which penalizes logical drift via an option permutation strategy to anchor decisions in verifiable reasoning traces. Experimental results demonstrate that our framework significantly enhances the cognitive reliability and interpretability of RS-VLMs, achieving state-of-the-art performance compared to other advanced methods.",
      "authors": [
        "Wenshuai Li",
        "Xiantai Xiang",
        "Zixiao Wen",
        "Guangyao Zhou",
        "Ben Niu",
        "Feng Wang",
        "Lijia Huang",
        "Qiantong Wang",
        "Yuxin Hu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 17:26:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04118v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04083v2",
      "title": "Cells on Autopilot: Adaptive Cell (Re)Selection via Reinforcement Learning",
      "abstract": "The widespread deployment of 5G networks, together with the coexistence of 4G/LTE networks, provides mobile devices a diverse set of candidate cells to connect to. However, associating mobile devices to cells to maximize overall network performance, a.k.a. cell (re)selection, remains a key challenge for mobile operators. Today, cell (re)selection parameters are typically configured manually based on operator experience and rarely adapted to dynamic network conditions. In this work, we ask: Can an agent automatically learn and adapt cell (re)selection parameters to consistently improve network performance? We present a reinforcement learning (RL)-based framework called CellPilot that adaptively tunes cell (re)selection parameters by learning spatiotemporal patterns of mobile network dynamics. Our study with real-world data demonstrates that even a lightweight RL agent can outperform conventional heuristic reconfigurations by up to 167%, while generalizing effectively across different network scenarios. These results indicate that data-driven approaches can significantly improve cell (re)selection configurations and enhance mobile network performance.",
      "authors": [
        "Marvin Illian",
        "Ramin Khalili",
        "Antonio A. de A. Rocha",
        "Lin Wang"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI",
        "cs.LG"
      ],
      "published": "2026-01-07 16:51:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04083v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04065v1",
      "title": "Unsupervised Modular Adaptive Region Growing and RegionMix Classification for Wind Turbine Segmentation",
      "abstract": "Reliable operation of wind turbines requires frequent inspections, as even minor surface damages can degrade aerodynamic performance, reduce energy output, and accelerate blade wear. Central to automating these inspections is the accurate segmentation of turbine blades from visual data. This task is traditionally addressed through dense, pixel-wise deep learning models. However, such methods demand extensive annotated datasets, posing scalability challenges. In this work, we introduce an annotation-efficient segmentation approach that reframes the pixel-level task into a binary region classification problem. Image regions are generated using a fully unsupervised, interpretable Modular Adaptive Region Growing technique, guided by image-specific Adaptive Thresholding and enhanced by a Region Merging process that consolidates fragmented areas into coherent segments. To improve generalization and classification robustness, we introduce RegionMix, an augmentation strategy that synthesizes new training samples by combining distinct regions. Our framework demonstrates state-of-the-art segmentation accuracy and strong cross-site generalization by consistently segmenting turbine blades across distinct windfarms.",
      "authors": [
        "Raül Pérez-Gonzalo",
        "Riccardo Magro",
        "Andreas Espersen",
        "Antonio Agudo"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-07 16:29:52+00:00",
      "link": "https://arxiv.org/pdf/2601.04065v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04058v1",
      "title": "Minimum distance classification for nonlinear dynamical systems",
      "abstract": "We address the problem of classifying trajectory data generated by some nonlinear dynamics, where each class corresponds to a distinct dynamical system. We propose Dynafit, a kernel-based method for learning a distance metric between training trajectories and the underlying dynamics. New observations are assigned to the class with the most similar dynamics according to the learned metric. The learning algorithm approximates the Koopman operator which globally linearizes the dynamics in a (potentially infinite) feature space associated with a kernel function. The distance metric is computed in feature space independently of its dimensionality by using the kernel trick common in machine learning. We also show that the kernel function can be tailored to incorporate partial knowledge of the dynamics when available. Dynafit is applicable to various classification tasks involving nonlinear dynamical systems and sensors. We illustrate its effectiveness on three examples: chaos detection with the logistic map, recognition of handwritten dynamics and of visual dynamic textures.",
      "authors": [
        "Dominique Martinez"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:21:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04058v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04057v1",
      "title": "Using Legacy Polysomnography Data to Train a Radar System to Quantify Sleep in Older Adults and People living with Dementia",
      "abstract": "Objective: Ultra-wideband radar technology offers a promising solution for unobtrusive and cost-effective in-home sleep monitoring. However, the limited availability of radar sleep data poses challenges in building robust models that generalize across diverse cohorts and environments. This study proposes a novel deep transfer learning framework to enhance sleep stage classification using radar data. Methods: An end-to-end neural network was developed to classify sleep stages based on nocturnal respiratory and motion signals. The network was trained using a combination of large-scale polysomnography (PSG) datasets and radar data. A domain adaptation approach employing adversarial learning was utilized to bridge the knowledge gap between PSG and radar signals. Validation was performed on a radar dataset of 47 older adults (mean age: 71.2), including 18 participants with prodromal or mild Alzheimer disease. Results: The proposed network structure achieves an accuracy of 79.5% with a Kappa value of 0.65 when classifying wakefulness, rapid eye movement, light sleep and deep sleep. Experimental results confirm that our deep transfer learning approach significantly enhances automatic sleep staging performance in the target domain. Conclusion: This method effectively addresses challenges associated with data variability and limited sample size, substantially improving the reliability of automatic sleep staging models, especially in contexts where radar data is limited. Significance: The findings underscore the viability of UWB radar as a nonintrusive, forward-looking sleep assessment tool that could significantly benefit care for older people and people with neurodegenerative disorders.",
      "authors": [
        "M. Yin",
        "K. G. Ravindran",
        "C. Hadjipanayi",
        "A. Bannon",
        "A. Rapeaux",
        "C. Della Monica",
        "T. S. Lande",
        "Derk-Jan Dijk",
        "T. G. Constandinou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:21:27+00:00",
      "link": "https://arxiv.org/pdf/2601.04057v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04051v1",
      "title": "Symbolic Regression for Shared Expressions: Introducing Partial Parameter Sharing",
      "abstract": "Symbolic Regression aims to find symbolic expressions that describe datasets. Due to better interpretability, it is a machine learning paradigm particularly powerful for scientific discovery. In recent years, several works have expanded the concept to allow the description of similar phenomena using a single expression with varying sets of parameters, thereby introducing categorical variables. Some previous works allow only \"non-shared\" (category-value-specific) parameters, and others also incorporate \"shared\" (category-value-agnostic) parameters. We expand upon those efforts by considering multiple categorical variables, and introducing intermediate levels of parameter sharing. With two categorical variables, an intermediate level of parameter sharing emerges, i.e., parameters which are shared across either category but change across the other. The new approach potentially decreases the number of parameters, while revealing additional information about the problem. Using a synthetic, fitting-only example, we test the limits of this setup in terms of data requirement reduction and transfer learning. As a real-world symbolic regression example, we demonstrate the benefits of the proposed approach on an astrophysics dataset used in a previous study, which considered only one categorical variable. We achieve a similar fit quality but require significantly fewer individual parameters, and extract additional information about the problem.",
      "authors": [
        "Viktor Martinek",
        "Roland Herzog"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:12:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04051v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04043v1",
      "title": "When Helpers Become Hazards: A Benchmark for Analyzing Multimodal LLM-Powered Safety in Daily Life",
      "abstract": "As Multimodal Large Language Models (MLLMs) become an indispensable assistant in human life, the unsafe content generated by MLLMs poses a danger to human behavior, perpetually overhanging human society like a sword of Damocles. To investigate and evaluate the safety impact of MLLMs responses on human behavior in daily life, we introduce SaLAD, a multimodal safety benchmark which contains 2,013 real-world image-text samples across 10 common categories, with a balanced design covering both unsafe scenarios and cases of oversensitivity. It emphasizes realistic risk exposure, authentic visual inputs, and fine-grained cross-modal reasoning, ensuring that safety risks cannot be inferred from text alone. We further propose a safety-warning-based evaluation framework that encourages models to provide clear and informative safety warnings, rather than generic refusals. Results on 18 MLLMs demonstrate that the top-performing models achieve a safe response rate of only 57.2% on unsafe queries. Moreover, even popular safety alignment methods limit effectiveness of the models in our scenario, revealing the vulnerabilities of current MLLMs in identifying dangerous behaviors in daily life. Our dataset is available at https://github.com/xinyuelou/SaLAD.",
      "authors": [
        "Xinyue Lou",
        "Jinan Xu",
        "Jingyi Yin",
        "Xiaolong Wang",
        "Zhaolu Kang",
        "Youwei Liao",
        "Yixuan Wang",
        "Xiangyu Shi",
        "Fengran Mo",
        "Su Yao",
        "Kaiyu Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 15:59:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04043v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04036v1",
      "title": "Analyzing and Improving Cross-lingual Knowledge Transfer for Machine Translation",
      "abstract": "Multilingual machine translation systems aim to make knowledge accessible across languages, yet learning effective cross-lingual representations remains challenging. These challenges are especially pronounced for low-resource languages, where limited parallel data constrains generalization and transfer. Understanding how multilingual models share knowledge across languages requires examining the interaction between representations, data availability, and training strategies. In this thesis, we study cross-lingual knowledge transfer in neural models and develop methods to improve robustness and generalization in multilingual settings, using machine translation as a central testbed. We analyze how similarity between languages influences transfer, how retrieval and auxiliary supervision can strengthen low-resource translation, and how fine-tuning on parallel data can introduce unintended trade-offs in large language models. We further examine the role of language diversity during training and show that increasing translation coverage improves generalization and reduces off-target behavior. Together, this work highlights how modeling choices and data composition shape multilingual learning and offers insights toward more inclusive and resilient multilingual NLP systems.",
      "authors": [
        "David Stap"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 15:51:54+00:00",
      "link": "https://arxiv.org/pdf/2601.04036v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04293v1",
      "title": "A Systematic Mapping Study on the Debugging of Autonomous Driving Systems",
      "abstract": "As Autonomous Driving Systems (ADS) progress towards commercial deployment, there is an increasing focus on ensuring their safety and reliability. While considerable research has been conducted on testing methods for detecting faults in ADS, very little attention has been paid to debugging in ADS. Debugging is an essential process that follows test failures to localise and repair the faults in the systems to maintain their safety and reliability. This Systematic Mapping Study (SMS) aims to provide a detailed overview of the current landscape of ADS debugging, highlighting existing approaches and identifying gaps in research. The study also proposes directions for future work and standards for problem definition and terminology in the field. Our findings reveal various methods for ADS debugging and highlight the current fragmented yet promising landscape.",
      "authors": [
        "Nathan Shaw",
        "Sanjeetha Pennada",
        "Robert M Hierons",
        "Donghwan Shin"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-07 15:50:55+00:00",
      "link": "https://arxiv.org/pdf/2601.04293v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04033v1",
      "title": "Thinking with Frames: Generative Video Distortion Evaluation via Frame Reward Model",
      "abstract": "Recent advances in video reward models and post-training strategies have improved text-to-video (T2V) generation. While these models typically assess visual quality, motion quality, and text alignment, they often overlook key structural distortions, such as abnormal object appearances and interactions, which can degrade the overall quality of the generative video. To address this gap, we introduce REACT, a frame-level reward model designed specifically for structural distortions evaluation in generative videos. REACT assigns point-wise scores and attribution labels by reasoning over video frames, focusing on recognizing distortions. To support this, we construct a large-scale human preference dataset, annotated based on our proposed taxonomy of structural distortions, and generate additional data using a efficient Chain-of-Thought (CoT) synthesis pipeline. REACT is trained with a two-stage framework: ((1) supervised fine-tuning with masked loss for domain knowledge injection, followed by (2) reinforcement learning with Group Relative Policy Optimization (GRPO) and pairwise rewards to enhance reasoning capability and align output scores with human preferences. During inference, a dynamic sampling mechanism is introduced to focus on frames most likely to exhibit distortion. We also present REACT-Bench, a benchmark for generative video distortion evaluation. Experimental results demonstrate that REACT complements existing reward models in assessing structutal distortion, achieving both accurate quantitative evaluations and interpretable attribution analysis.",
      "authors": [
        "Yuan Wang",
        "Borui Liao",
        "Huijuan Huang",
        "Jinda Lu",
        "Ouxiang Li",
        "Kuien Liu",
        "Meng Wang",
        "Xiang Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 15:47:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04033v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04025v1",
      "title": "Simulated Students in Tutoring Dialogues: Substance or Illusion?",
      "abstract": "Advances in large language models (LLMs) enable many new innovations in education. However, evaluating the effectiveness of new technology requires real students, which is time-consuming and hard to scale up. Therefore, many recent works on LLM-powered tutoring solutions have used simulated students for both training and evaluation, often via simple prompting. Surprisingly, little work has been done to ensure or even measure the quality of simulated students. In this work, we formally define the student simulation task, propose a set of evaluation metrics that span linguistic, behavioral, and cognitive aspects, and benchmark a wide range of student simulation methods on these metrics. We experiment on a real-world math tutoring dialogue dataset, where both automated and human evaluation results show that prompting strategies for student simulation perform poorly; supervised fine-tuning and preference optimization yield much better but still limited performance, motivating future work on this challenging task.",
      "authors": [
        "Alexander Scarlatos",
        "Jaewook Lee",
        "Simon Woodhead",
        "Andrew Lan"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CY"
      ],
      "published": "2026-01-07 15:44:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04025v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04011v1",
      "title": "Flexible-Duplex Cell-Free Architecture for Secure Uplink Communications in Low-Altitude Wireless Networks",
      "abstract": "Low-altitude wireless networks (LAWNs) are expected to play a central role in future 6G infrastructures, yet uplink transmissions of uncrewed aerial vehicles (UAVs) remain vulnerable to eavesdropping due to their limited transmit power, constrained antenna resources, and highly exposed air-ground propagation conditions. To address this fundamental bottleneck, we propose a flexible-duplex cell-free (CF) architecture in which each distributed access point (AP) can dynamically operate either as a receive AP for UAV uplink collection or as a transmit AP that generates cooperative artificial noise (AN) for secrecy enhancement. Such AP-level duplex flexibility introduces an additional spatial degree of freedom that enables distributed and adaptive protection against wiretapping in LAWNs. Building upon this architecture, we formulate a max-min secrecy-rate problem that jointly optimizes AP mode selection, receive combining, and AN covariance design. This tightly coupled and nonconvex optimization is tackled by first deriving the optimal receive combiners in closed form, followed by developing a penalty dual decomposition (PDD) algorithm with guaranteed convergence to a stationary solution. To further reduce computational burden, we propose a low-complexity sequential scheme that determines AP modes via a heuristic metric and then updates the AN covariance matrices through closed-form iterations embedded in the PDD framework. Simulation results show that the proposed flexible-duplex architecture yields substantial secrecy-rate gains over CF systems with fixed AP roles. The joint optimization method attains the highest secrecy performance, while the low-complexity approach achieves over 90% of the optimal performance with an order-of-magnitude lower computational complexity, offering a practical solution for secure uplink communications in LAWNs.",
      "authors": [
        "Wei Shi",
        "Wei Xu",
        "Yongming Huang",
        "Jiacheng Yao",
        "Wenhao Hu",
        "Dongming Wang"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "eess.SP"
      ],
      "published": "2026-01-07 15:20:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04011v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04005v1",
      "title": "Padé Neurons for Efficient Neural Models",
      "abstract": "Neural networks commonly employ the McCulloch-Pitts neuron model, which is a linear model followed by a point-wise non-linear activation. Various researchers have already advanced inherently non-linear neuron models, such as quadratic neurons, generalized operational neurons, generative neurons, and super neurons, which offer stronger non-linearity compared to point-wise activation functions. In this paper, we introduce a novel and better non-linear neuron model called Padé neurons (Paons), inspired by Padé approximants. Paons offer several advantages, such as diversity of non-linearity, since each Paon learns a different non-linear function of its inputs, and layer efficiency, since Paons provide stronger non-linearity in much fewer layers compared to piecewise linear approximation. Furthermore, Paons include all previously proposed neuron models as special cases, thus any neuron model in any network can be replaced by Paons. We note that there has been a proposal to employ the Padé approximation as a generalized point-wise activation function, which is fundamentally different from our model. To validate the efficacy of Paons, in our experiments, we replace classic neurons in some well-known neural image super-resolution, compression, and classification models based on the ResNet architecture with Paons. Our comprehensive experimental results and analyses demonstrate that neural models built by Paons provide better or equal performance than their classic counterparts with a smaller number of layers. The PyTorch implementation code for Paon is open-sourced at https://github.com/onur-keles/Paon.",
      "authors": [
        "Onur Keleş",
        "A. Murat Tekalp"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "eess.IV"
      ],
      "published": "2026-01-07 15:15:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04005v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03997v2",
      "title": "VotIE: Information Extraction from Meeting Minutes",
      "abstract": "Municipal meeting minutes record key decisions in local democratic processes. Unlike parliamentary proceedings, which typically adhere to standardized formats, they encode voting outcomes in highly heterogeneous, free-form narrative text that varies widely across municipalities, posing significant challenges for automated extraction. In this paper, we introduce VotIE (Voting Information Extraction), a new information extraction task aimed at identifying structured voting events in narrative deliberative records, and establish the first benchmark for this task using Portuguese municipal minutes, building on the recently introduced CitiLink corpus. Our experiments yield two key findings. First, under standard in-domain evaluation, fine-tuned encoders, specifically XLM-R-CRF, achieve the strongest performance, reaching 93.2\\% macro F1, outperforming generative approaches. Second, in a cross-municipality setting that evaluates transfer to unseen administrative contexts, these models suffer substantial performance degradation, whereas few-shot LLMs demonstrate greater robustness, with significantly smaller declines in performance. Despite this generalization advantage, the high computational cost of generative models currently constrains their practicality. As a result, lightweight fine-tuned encoders remain a more practical option for large-scale, real-world deployment. To support reproducible research in administrative NLP, we publicly release our benchmark, trained models, and evaluation framework.",
      "authors": [
        "José Pedro Evans",
        "Luís Filipe Cunha",
        "Purificação Silvano",
        "Alípio Jorge",
        "Nuno Guimarães",
        "Sérgio Nunes",
        "Ricardo Campos"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 15:06:53+00:00",
      "link": "https://arxiv.org/pdf/2601.03997v2",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03986v1",
      "title": "Benchmark^2: Systematic Evaluation of LLM Benchmarks",
      "abstract": "The rapid proliferation of benchmarks for evaluating large language models (LLMs) has created an urgent need for systematic methods to assess benchmark quality itself. We propose Benchmark^2, a comprehensive framework comprising three complementary metrics: (1) Cross-Benchmark Ranking Consistency, measuring whether a benchmark produces model rankings aligned with peer benchmarks; (2) Discriminability Score, quantifying a benchmark's ability to differentiate between models; and (3) Capability Alignment Deviation, identifying problematic instances where stronger models fail but weaker models succeed within the same model family. We conduct extensive experiments across 15 benchmarks spanning mathematics, reasoning, and knowledge domains, evaluating 11 LLMs across four model families. Our analysis reveals significant quality variations among existing benchmarks and demonstrates that selective benchmark construction based on our metrics can achieve comparable evaluation performance with substantially reduced test sets.",
      "authors": [
        "Qi Qian",
        "Chengsong Huang",
        "Jingwen Xu",
        "Changze Lv",
        "Muling Wu",
        "Wenhao Liu",
        "Xiaohua Wang",
        "Zhenghua Wang",
        "Zisu Huang",
        "Muzhao Tian",
        "Jianhan Xu",
        "Kun Hu",
        "He-Da Wang",
        "Yao Hu",
        "Xuanjing Huang",
        "Xiaoqing Zheng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 14:59:03+00:00",
      "link": "https://arxiv.org/pdf/2601.03986v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03981v1",
      "title": "RADAR: Retrieval-Augmented Detector with Adversarial Refinement for Robust Fake News Detection",
      "abstract": "To efficiently combat the spread of LLM-generated misinformation, we present RADAR, a retrieval-augmented detector with adversarial refinement for robust fake news detection. Our approach employs a generator that rewrites real articles with factual perturbations, paired with a lightweight detector that verifies claims using dense passage retrieval. To enable effective co-evolution, we introduce verbal adversarial feedback (VAF). Rather than relying on scalar rewards, VAF issues structured natural-language critiques; these guide the generator toward more sophisticated evasion attempts, compelling the detector to adapt and improve. On a fake news detection benchmark, RADAR achieves 86.98% ROC-AUC, significantly outperforming general-purpose LLMs with retrieval. Ablation studies confirm that detector-side retrieval yields the largest gains, while VAF and few-shot demonstrations provide critical signals for robust training.",
      "authors": [
        "Song-Duo Ma",
        "Yi-Hung Liu",
        "Hsin-Yu Lin",
        "Pin-Yu Chen",
        "Hong-Yan Huang",
        "Shau-Yung Hsu",
        "Yun-Nung Chen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 14:52:15+00:00",
      "link": "https://arxiv.org/pdf/2601.03981v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03977v1",
      "title": "Stage-specific cancer survival prediction enriched by explainable machine learning",
      "abstract": "Despite the fact that cancer survivability rates vary greatly between stages, traditional survival prediction models have frequently been trained and assessed using examples from all combined phases of the disease. This method may result in an overestimation of performance and ignore the stage-specific variations. Using the SEER dataset, we created and verified explainable machine learning (ML) models to predict stage-specific cancer survivability in colorectal, stomach, and liver cancers. ML-based cancer survival analysis has been a long-standing topic in the literature; however, studies involving the explainability and transparency of ML survivability models are limited. Our use of explainability techniques, including SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME), enabled us to illustrate significant feature-cancer stage interactions that would have remained hidden in traditional black-box models. We identified how certain demographic and clinical variables influenced survival differently across cancer stages and types. These insights provide not only transparency but also clinical relevance, supporting personalized treatment planning. By focusing on stage-specific models, this study provides new insights into the most important factors at each stage of cancer, offering transparency and potential clinical relevance to support personalized treatment planning.",
      "authors": [
        "Parisa Poorhasani",
        "Bogdan Iancu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 14:44:04+00:00",
      "link": "https://arxiv.org/pdf/2601.03977v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03976v1",
      "title": "On-Device Deep Reinforcement Learning for Decentralized Task Offloading Performance trade-offs in the training process",
      "abstract": "Allowing less capable devices to offload computational tasks to more powerful devices or servers enables the development of new applications that may not run correctly on the device itself. Deciding where and why to run each of those applications is a complex task. Therefore, different approaches have been adopted to make offloading decisions. In this work, we propose a decentralized Deep Reinforcement Learning (DRL) agent to address the selection of computing locations. Unlike most existing work, we analyze it in a real testbed composed of various edge devices running the agent to determine where to execute each task. These devices are connected to a Multi-Access Edge Computing (MEC) server and a Cloud server through 5G communications. We evaluate not only the agent's performance in meeting task requirements but also the implications of running this type of agent locally, assessing the trade-offs of training locally versus remotely in terms of latency and energy consumption.",
      "authors": [
        "Gorka Nieto",
        "Idoia de la Iglesia",
        "Cristina Perfecto",
        "Unai Lopez-Novoa"
      ],
      "primary_category": "cs.ET",
      "categories": [
        "cs.ET",
        "eess.SY"
      ],
      "published": "2026-01-07 14:43:35+00:00",
      "link": "https://arxiv.org/pdf/2601.03976v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03969v1",
      "title": "Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models",
      "abstract": "Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing efficient reasoning methods relying on explicit length penalties often introduce optimization conflicts and leave the generative mechanisms driving overthinking largely unexamined. In this paper, we identify a phenomenon termed length shift where models increasingly generate unnecessary reasoning on trivial inputs during training. To address this, we introduce Dynamic Outlier Truncation (DOT), a training-time intervention that selectively suppresses redundant tokens. This method targets only the extreme tail of response lengths within fully correct rollout groups while preserving long-horizon reasoning capabilities for complex problems. To complement this intervention and ensure stable convergence, we further incorporate auxiliary KL regularization and predictive dynamic sampling. Experimental results across multiple model scales demonstrate that our approach significantly pushes the efficiency-performance Pareto frontier outward. Notably, on the AIME-24, our method reduces inference token usage by 78% while simultaneously increasing accuracy compared to the initial policy and surpassing state-of-the-art efficient reasoning methods.",
      "authors": [
        "Wei Wu",
        "Liyi Chen",
        "Congxi Xiao",
        "Tianfu Wang",
        "Qimeng Wang",
        "Chengqiang Lu",
        "Yan Gao",
        "Yi Wu",
        "Yao Hu",
        "Hui Xiong"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 14:31:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03969v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04287v1",
      "title": "Online Action-Stacking Improves Reinforcement Learning Performance for Air Traffic Control",
      "abstract": "We introduce online action-stacking, an inference-time wrapper for reinforcement learning policies that produces realistic air traffic control commands while allowing training on a much smaller discrete action space. Policies are trained with simple incremental heading or level adjustments, together with an action-damping penalty that reduces instruction frequency and leads agents to issue commands in short bursts. At inference, online action-stacking compiles these bursts of primitive actions into domain-appropriate compound clearances. Using Proximal Policy Optimisation and the BluebirdDT digital twin platform, we train agents to navigate aircraft along lateral routes, manage climb and descent to target flight levels, and perform two-aircraft collision avoidance under a minimum separation constraint. In our lateral navigation experiments, action stacking greatly reduces the number of issued instructions relative to a damped baseline and achieves comparable performance to a policy trained with a 37-dimensional action space, despite operating with only five actions. These results indicate that online action-stacking helps bridge a key gap between standard reinforcement learning formulations and operational ATC requirements, and provides a simple mechanism for scaling to more complex control scenarios.",
      "authors": [
        "Ben Carvell",
        "George De Ath",
        "Eseoghene Benjamin",
        "Richard Everson"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "published": "2026-01-07 14:28:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04287v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04285v1",
      "title": "A Future Capabilities Agent for Tactical Air Traffic Control",
      "abstract": "Escalating air traffic demand is driving the adoption of automation to support air traffic controllers, but existing approaches face a trade-off between safety assurance and interpretability. Optimisation-based methods such as reinforcement learning offer strong performance but are difficult to verify and explain, while rules-based systems are transparent yet rarely check safety under uncertainty. This paper outlines Agent Mallard, a forward-planning, rules-based agent for tactical control in systemised airspace that embeds a stochastic digital twin directly into its conflict-resolution loop. Mallard operates on predefined GPS-guided routes, reducing continuous 4D vectoring to discrete choices over lanes and levels, and constructs hierarchical plans from an expert-informed library of deconfliction strategies. A depth-limited backtracking search uses causal attribution, topological plan splicing, and monotonic axis constraints to seek a complete safe plan for all aircraft, validating each candidate manoeuvre against uncertain execution scenarios (e.g., wind variation, pilot response, communication loss) before commitment.   Preliminary walkthroughs with UK controllers and initial tests in the BluebirdDT airspace digital twin indicate that Mallard's behaviour aligns with expert reasoning and resolves conflicts in simplified scenarios. The architecture is intended to combine model-based safety assessment, interpretable decision logic, and tractable computational performance in future structured en-route environments.",
      "authors": [
        "Paul Kent",
        "George De Ath",
        "Martin Layton",
        "Allen Hart",
        "Richard Everson",
        "Ben Carvell"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-01-07 14:19:46+00:00",
      "link": "https://arxiv.org/pdf/2601.04285v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03955v1",
      "title": "ResTok: Learning Hierarchical Residuals in 1D Visual Tokenizers for Autoregressive Image Generation",
      "abstract": "Existing 1D visual tokenizers for autoregressive (AR) generation largely follow the design principles of language modeling, as they are built directly upon transformers whose priors originate in language, yielding single-hierarchy latent tokens and treating visual data as flat sequential token streams. However, this language-like formulation overlooks key properties of vision, particularly the hierarchical and residual network designs that have long been essential for convergence and efficiency in visual models. To bring \"vision\" back to vision, we propose the Residual Tokenizer (ResTok), a 1D visual tokenizer that builds hierarchical residuals for both image tokens and latent tokens. The hierarchical representations obtained through progressively merging enable cross-level feature fusion at each layer, substantially enhancing representational capacity. Meanwhile, the semantic residuals between hierarchies prevent information overlap, yielding more concentrated latent distributions that are easier for AR modeling. Cross-level bindings consequently emerge without any explicit constraints. To accelerate the generation process, we further introduce a hierarchical AR generator that substantially reduces sampling steps by predicting an entire level of latent tokens at once rather than generating them strictly token-by-token. Extensive experiments demonstrate that restoring hierarchical residual priors in visual tokenization significantly improves AR image generation, achieving a gFID of 2.34 on ImageNet-256 with only 9 sampling steps. Code is available at https://github.com/Kwai-Kolors/ResTok.",
      "authors": [
        "Xu Zhang",
        "Cheng Da",
        "Huan Yang",
        "Kun Gai",
        "Ming Lu",
        "Zhan Ma"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 14:09:18+00:00",
      "link": "https://arxiv.org/pdf/2601.03955v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03948v2",
      "title": "Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification",
      "abstract": "Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to achieve remarkable reasoning in domains like mathematics and coding, where verifiable rewards provide clear signals. However, extending this paradigm to financial decision is challenged by the market's stochastic nature: rewards are verifiable but inherently noisy, causing standard RL to degenerate into reward hacking. To address this, we propose Trade-R1, a model training framework that bridges verifiable rewards to stochastic environments via process-level reasoning verification. Our key innovation is a verification method that transforms the problem of evaluating reasoning over lengthy financial documents into a structured Retrieval-Augmented Generation (RAG) task. We construct a triangular consistency metric, assessing pairwise alignment between retrieved evidence, reasoning chains, and decisions to serve as a validity filter for noisy market returns. We explore two reward integration strategies: Fixed-effect Semantic Reward (FSR) for stable alignment signals, and Dynamic-effect Semantic Reward (DSR) for coupled magnitude optimization. Experiments on different country asset selection demonstrate that our paradigm reduces reward hacking, with DSR achieving superior cross-market generalization while maintaining the highest reasoning consistency.",
      "authors": [
        "Rui Sun",
        "Yifan Sun",
        "Sheng Xu",
        "Li Zhao",
        "Jing Li",
        "Daxin Jiang",
        "Cheng Hua",
        "Zuo Bai"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "q-fin.TR"
      ],
      "published": "2026-01-07 14:03:22+00:00",
      "link": "https://arxiv.org/pdf/2601.03948v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03940v1",
      "title": "Large-Scale Aspect-Based Sentiment Analysis with Reasoning-Infused LLMs",
      "abstract": "We introduce Arctic-ABSA, a collection of powerful models for real-life aspect-based sentiment analysis (ABSA). Our models are tailored to commercial needs, trained on a large corpus of public data alongside carefully generated synthetic data, resulting in a dataset 20 times larger than SemEval14. We extend typical ABSA models by expanding the number of sentiment classes from the standard three (positive, negative, neutral) to five, adding mixed and unknown classes, while also jointly predicting overall text sentiment and supporting multiple languages. We experiment with reasoning injection by fine-tuning on Chain-of-Thought (CoT) examples and introduce a novel reasoning pretraining technique for encoder-only models that significantly improves downstream fine-tuning and generalization. Our 395M-parameter encoder and 8B-parameter decoder achieve up to 10 percentage points higher accuracy than GPT-4o and Claude 3.5 Sonnet, while setting new state-of-the-art results on the SemEval14 benchmark. A single multilingual model maintains 87-91% accuracy across six languages without degrading English performance. We release ABSA-mix, a large-scale benchmark aggregating 17 public ABSA datasets across 92 domains.",
      "authors": [
        "Paweł Liskowski",
        "Krzysztof Jankowski"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 13:58:29+00:00",
      "link": "https://arxiv.org/pdf/2601.03940v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03926v1",
      "title": "Doc-PP: Document Policy Preservation Benchmark for Large Vision-Language Models",
      "abstract": "The deployment of Large Vision-Language Models (LVLMs) for real-world document question answering is often constrained by dynamic, user-defined policies that dictate information disclosure based on context. While ensuring adherence to these explicit constraints is critical, existing safety research primarily focuses on implicit social norms or text-only settings, overlooking the complexities of multimodal documents. In this paper, we introduce Doc-PP (Document Policy Preservation Benchmark), a novel benchmark constructed from real-world reports requiring reasoning across heterogeneous visual and textual elements under strict non-disclosure policies. Our evaluation highlights a systemic Reasoning-Induced Safety Gap: models frequently leak sensitive information when answers must be inferred through complex synthesis or aggregated across modalities, effectively circumventing existing safety constraints. Furthermore, we identify that providing extracted text improves perception but inadvertently facilitates leakage. To address these vulnerabilities, we propose DVA (Decompose-Verify-Aggregation), a structural inference framework that decouples reasoning from policy verification. Experimental results demonstrate that DVA significantly outperforms standard prompting defenses, offering a robust baseline for policy-compliant document understanding",
      "authors": [
        "Haeun Jang",
        "Hwan Chang",
        "Hwanhee Lee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 13:45:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03926v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03924v1",
      "title": "A low-complexity method for efficient depth-guided image deblurring",
      "abstract": "Image deblurring is a challenging problem in imaging due to its highly ill-posed nature. Deep learning models have shown great success in tackling this problem but the quest for the best image quality has brought their computational complexity up, making them impractical on anything but powerful servers. Meanwhile, recent works have shown that mobile Lidars can provide complementary information in the form of depth maps that enhance deblurring quality. In this paper, we introduce a novel low-complexity neural network for depth-guided image deblurring. We show that the use of the wavelet transform to separate structural details and reduce spatial redundancy as well as efficient feature conditioning on the depth information are essential ingredients in developing a low-complexity model. Experimental results show competitive image quality against recent state-of-the-art models while reducing complexity by up to two orders of magnitude.",
      "authors": [
        "Ziyao Yi",
        "Diego Valsesia",
        "Tiziano Bianchi",
        "Enrico Magli"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "published": "2026-01-07 13:45:20+00:00",
      "link": "https://arxiv.org/pdf/2601.03924v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03915v1",
      "title": "HemBLIP: A Vision-Language Model for Interpretable Leukemia Cell Morphology Analysis",
      "abstract": "Microscopic evaluation of white blood cell morphology is central to leukemia diagnosis, yet current deep learning models often act as black boxes, limiting clinical trust and adoption. We introduce HemBLIP, a vision language model designed to generate interpretable, morphology aware descriptions of peripheral blood cells. Using a newly constructed dataset of 14k healthy and leukemic cells paired with expert-derived attribute captions, we adapt a general-purpose VLM via both full fine-tuning and LoRA based parameter efficient training, and benchmark against the biomedical foundation model MedGEMMA. HemBLIP achieves higher caption quality and morphological accuracy, while LoRA adaptation provides further gains with significantly reduced computational cost. These results highlight the promise of vision language models for transparent and scalable hematological diagnostics.",
      "authors": [
        "Julie van Logtestijn",
        "Petru Manescu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 13:31:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03915v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03914v1",
      "title": "When Models Decide and When They Bind: A Two-Stage Computation for Multiple-Choice Question-Answering",
      "abstract": "Multiple-choice question answering (MCQA) is easy to evaluate but adds a meta-task: models must both solve the problem and output the symbol that *represents* the answer, conflating reasoning errors with symbol-binding failures. We study how language models implement MCQA internally using representational analyses (PCA, linear probes) as well as causal interventions. We find that option-boundary (newline) residual states often contain strong linearly decodable signals related to per-option correctness. Winner-identity probing reveals a two-stage progression: the winning *content position* becomes decodable immediately after the final option is processed, while the *output symbol* is represented closer to the answer emission position. Tests under symbol and content permutations support a two-stage mechanism in which models first select a winner in content space and then bind or route that winner to the appropriate symbol to emit.",
      "authors": [
        "Hugh Mee Wong",
        "Rick Nouwen",
        "Albert Gatt"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 13:27:48+00:00",
      "link": "https://arxiv.org/pdf/2601.03914v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03910v1",
      "title": "An Algebraic Representation Theorem for Linear GENEOs in Geometric Machine Learning",
      "abstract": "Geometric and Topological Deep Learning are rapidly growing research areas that enhance machine learning through the use of geometric and topological structures. Within this framework, Group Equivariant Non-Expansive Operators (GENEOs) have emerged as a powerful class of operators for encoding symmetries and designing efficient, interpretable neural architectures. Originally introduced in Topological Data Analysis, GENEOs have since found applications in Deep Learning as tools for constructing equivariant models with reduced parameter complexity. GENEOs provide a unifying framework bridging Geometric and Topological Deep Learning and include the operator computing persistence diagrams as a special case. Their theoretical foundations rely on group actions, equivariance, and compactness properties of operator spaces, grounding them in algebra and geometry while enabling both mathematical rigor and practical relevance. While a previous representation theorem characterized linear GENEOs acting on data of the same type, many real-world applications require operators between heterogeneous data spaces. In this work, we address this limitation by introducing a new representation theorem for linear GENEOs acting between different perception pairs, based on generalized T-permutant measures. Under mild assumptions on the data domains and group actions, our result provides a complete characterization of such operators. We also prove the compactness and convexity of the space of linear GENEOs. We further demonstrate the practical impact of this theory by applying the proposed framework to improve the performance of autoencoders, highlighting the relevance of GENEOs in modern machine learning applications.",
      "authors": [
        "Francesco Conti",
        "Patrizio Frosini",
        "Nicola Quercioli"
      ],
      "primary_category": "math.RT",
      "categories": [
        "math.RT",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 13:21:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03910v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04282v1",
      "title": "LEGATO: Good Identity Unlearning Is Continuous",
      "abstract": "Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.",
      "authors": [
        "Qiang Chen",
        "Chun-Wun Cheng",
        "Xiu Su",
        "Hongyan Xu",
        "Xi Lin",
        "Shan You",
        "Angelica I. Aviles-Rivero",
        "Yi Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 13:15:25+00:00",
      "link": "https://arxiv.org/pdf/2601.04282v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03895v1",
      "title": "Adaptive-Boundary-Clipping GRPO: Ensuring Bounded Ratios for Stable and Generalizable Training",
      "abstract": "Group Relative Policy Optimization (GRPO) has emerged as a popular algorithm for reinforcement learning with large language models (LLMs). However, upon analyzing its clipping mechanism, we argue that it is suboptimal in certain scenarios. With appropriate modifications, GRPO can be significantly enhanced to improve both flexibility and generalization. To this end, we propose Adaptive-Boundary-Clipping GRPO (ABC-GRPO), an asymmetric and adaptive refinement of the original GRPO framework. We demonstrate that ABC-GRPO achieves superior performance over standard GRPO on mathematical reasoning tasks using the Qwen3 LLMs. Moreover, ABC-GRPO maintains substantially higher entropy throughout training, thereby preserving the model's exploration capacity and mitigating premature convergence. The implementation code is available online to ease reproducibility https://github.com/chi2liu/ABC-GRPO.",
      "authors": [
        "Chi Liu",
        "Xin Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 13:04:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03895v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03884v1",
      "title": "FLNet: Flood-Induced Agriculture Damage Assessment using Super Resolution of Satellite Images",
      "abstract": "Distributing government relief efforts after a flood is challenging. In India, the crops are widely affected by floods; therefore, making rapid and accurate crop damage assessment is crucial for effective post-disaster agricultural management. Traditional manual surveys are slow and biased, while current satellite-based methods face challenges like cloud cover and low spatial resolution. Therefore, to bridge this gap, this paper introduced FLNet, a novel deep learning based architecture that used super-resolution to enhance the 10 m spatial resolution of Sentinel-2 satellite images into 3 m resolution before classifying damage. We tested our model on the Bihar Flood Impacted Croplands Dataset (BFCD-22), and the results showed an improved critical \"Full Damage\" F1-score from 0.83 to 0.89, nearly matching the 0.89 score of commercial high-resolution imagery. This work presented a cost-effective and scalable solution, paving the way for a nationwide shift from manual to automated, high-fidelity damage assessment.",
      "authors": [
        "Sanidhya Ghosal",
        "Anurag Sharma",
        "Sushil Ghildiyal",
        "Mukesh Saini"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 12:51:28+00:00",
      "link": "https://arxiv.org/pdf/2601.03884v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04279v1",
      "title": "Generation of synthetic delay time series for air transport applications",
      "abstract": "The generation of synthetic data is receiving increasing attention from the scientific community, thanks to its ability to solve problems like data scarcity and privacy, and is starting to find applications in air transport. We here tackle the problem of generating synthetic, yet realistic, time series of delays at airports, starting from large collections of operations in Europe and the US. We specifically compare three models, two of them based on state of the art Deep Learning algorithms, and one simplified Genetic Algorithm approach. We show how the latter can generate time series that are almost indistinguishable from real ones, while maintaining a high variability. We further validate the resulting time series in a problem of detecting delay propagations between airports. We finally make the synthetic data available to the scientific community.",
      "authors": [
        "Pau Esteve",
        "Massimiliano Zanin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 12:43:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04279v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03875v1",
      "title": "Staged Voxel-Level Deep Reinforcement Learning for 3D Medical Image Segmentation with Noisy Annotations",
      "abstract": "Deep learning has achieved significant advancements in medical image segmentation. Currently, obtaining accurate segmentation outcomes is critically reliant on large-scale datasets with high-quality annotations. However, noisy annotations are frequently encountered owing to the complex morphological structures of organs in medical images and variations among different annotators, which can substantially limit the efficacy of segmentation models. Motivated by the fact that medical imaging annotator can correct labeling errors during segmentation based on prior knowledge, we propose an end-to-end Staged Voxel-Level Deep Reinforcement Learning (SVL-DRL) framework for robust medical image segmentation under noisy annotations. This framework employs a dynamic iterative update strategy to automatically mitigate the impact of erroneous labels without requiring manual intervention. The key advancements of SVL-DRL over existing works include: i) formulating noisy annotations as a voxel-dependent problem and addressing it through a novel staged reinforcement learning framework which guarantees robust model convergence; ii) incorporating a voxel-level asynchronous advantage actor-critic (vA3C) module that conceptualizes each voxel as an autonomous agent, which allows each agent to dynamically refine its own state representation during training, thereby directly mitigating the influence of erroneous labels; iii) designing a novel action space for the agents, along with a composite reward function that strategically combines the Dice value and a spatial continuity metric to significantly boost segmentation accuracy while maintain semantic integrity. Experiments on three public medical image datasets demonstrates State-of-The-Art (SoTA) performance under various experimental settings, with an average improvement of over 3\\% in both Dice and IoU scores.",
      "authors": [
        "Yuyang Fu",
        "Xiuzhen Guo",
        "Ji Shi"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "published": "2026-01-07 12:39:54+00:00",
      "link": "https://arxiv.org/pdf/2601.03875v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03858v1",
      "title": "What Does Loss Optimization Actually Teach, If Anything? Knowledge Dynamics in Continual Pre-training of LLMs",
      "abstract": "Continual Pre-Training (CPT) is widely used for acquiring and updating factual knowledge in LLMs. This practice treats loss as a proxy for knowledge learning, while offering no grounding into how it changes during training. We study CPT as a knowledge learning process rather than a solely optimization problem. We construct a controlled, distribution-matched benchmark of factual documents and interleave diagnostic probes directly into the CPT loop, enabling epoch-level measurement of knowledge acquisition dynamics and changes in Out-Of-Domain (OOD) general skills (e.g., math). We further analyze how CPT reshapes knowledge circuits during training. Across three instruction-tuned LLMs and multiple CPT strategies, optimization and learning systematically diverge as loss decreases monotonically while factual learning is unstable and non-monotonic. Acquired facts are rarely consolidated, learning is strongly conditioned on prior exposure, and OOD performance degrades from early epochs. Circuit analysis reveals rapid reconfiguration of knowledge pathways across epochs, providing an explanation for narrow acquisition windows and systematic forgetting. These results show that loss optimization is misaligned with learning progress in CPT and motivate evaluation of stopping criteria based on task-level learning dynamics.",
      "authors": [
        "Seyed Mahed Mousavi",
        "Simone Alghisi",
        "Giuseppe Riccardi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 12:14:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03858v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03853v1",
      "title": "From No-Regret to Strategically Robust Learning in Repeated Auctions",
      "abstract": "In Bayesian single-item auctions, a monotone bidding strategy--one that prescribes a higher bid for a higher value type--can be equivalently represented as a partition of the quantile space into consecutive intervals corresponding to increasing bids. Kumar et al. (2024) prove that agile online gradient descent (OGD), when used to update a monotone bidding strategy through its quantile representation, is strategically robust in repeated first-price auctions: when all bidders employ agile OGD in this way, the auctioneer's average revenue per round is at most the revenue of Myerson's optimal auction, regardless of how she adjusts the reserve price over time.   In this work, we show that this strategic robustness guarantee is not unique to agile OGD or to the first-price auction: any no-regret learning algorithm, when fed gradient feedback with respect to the quantile representation, is strategically robust, even if the auction format changes every round, provided the format satisfies allocation monotonicity and voluntary participation. In particular, the multiplicative weights update (MWU) algorithm simultaneously achieves the optimal regret guarantee and the best-known strategic robustness guarantee. At a technical level, our results are established via a simple relation that bridges Myerson's auction theory and standard no-regret learning theory. This showcases the potential of translating standard regret guarantees into strategic robustness guarantees for specific games, without explicitly minimizing any form of swap regret.",
      "authors": [
        "Junyao Zhao"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT",
        "cs.LG",
        "econ.TH"
      ],
      "published": "2026-01-07 12:09:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03853v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03850v1",
      "title": "Investigating the Grounding Bottleneck for a Large-Scale Configuration Problem: Existing Tools and Constraint-Aware Guessing",
      "abstract": "Answer set programming (ASP) aims to realize the AI vision: The user specifies the problem, and the computer solves it. Indeed, ASP has made this vision true in many application domains. However, will current ASP solving techniques scale up for large configuration problems? As a benchmark for such problems, we investigated the configuration of electronic systems, which may comprise more than 30,000 components. We show the potential and limits of current ASP technology, focusing on methods that address the so-called grounding bottleneck, i.e., the sharp increase of memory demands in the size of the problem instances. To push the limits, we investigated the incremental solving approach, which proved effective in practice. However, even in the incremental approach, memory demands impose significant limits. Based on an analysis of grounding, we developed the method constraint-aware guessing, which significantly reduced the memory need.",
      "authors": [
        "Veronika Semmelrock",
        "Gerhard Friedrich"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 12:08:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03850v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03849v1",
      "title": "Automated Theorem Proving for Prolog Verification",
      "abstract": "LPTP (Logic Program Theorem Prover) is an interactive natural-deduction-based theorem  prover for pure Prolog programs with negation as failure, unification with the occurs check, and a restricted but extensible set of built-in predicates. With LPTP, one can formally prove termination  and partial correctness of such Prolog programs. LPTP was designed in the mid-1990's by Robert F. Staerk.  It is written in ISO-Prolog and comes with an Emacs user-interface.    From a theoretical point of view, in his publications about LPTP, Staerk associates a set of first-order axioms IND(P) to the considered Prolog program P.  IND(P) contains the Clark's equality theory for P,  definitions of success, failure and termination for each user-defined logic procedure in P,  axioms relating these three points of view, and an axiom schema for  proving inductive properties. LPTP is thus a dedicated proof editor where these axioms are hard-wired.    We propose to translate these axioms as first-order formulas (FOFs), and apply automated theorem provers to  check the property of interest. Using  FOF  as an intermediary language, we experiment the use of automated theorem  provers for Prolog program verification. We evaluate the approach over  a benchmark of about 400 properties of Prolog  programs from the library available with LPTP. Both the  compiler which generates a set of FOF files from a given input  Prolog program together with its properties and the benchmark are publicly available.",
      "authors": [
        "Fred Mesnard",
        "Thierry Marianne",
        "Étienne Payet"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "cs.PL"
      ],
      "published": "2026-01-07 12:08:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03849v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03848v1",
      "title": "Implementing the First-Order Logic of Here and There",
      "abstract": "We present automated theorem provers for the first-order logic of here and there (HT). They are based on a native sequent calculus for the logic of HT and an axiomatic embedding of the logic of HT into intuitionistic logic. The analytic proof search in the sequent calculus is optimized by using free variables and skolemization. The embedding is used in combination with sequent, tableau and connection calculi for intuitionistic first-order logic. All provers are evaluated on a large benchmark set of first-order formulas, providing a foundation for the development of more efficient HT provers.",
      "authors": [
        "Jens Otten",
        "Torsten Schaub"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.PL"
      ],
      "published": "2026-01-07 12:08:15+00:00",
      "link": "https://arxiv.org/pdf/2601.03848v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03845v1",
      "title": "Formally Explaining Decision Tree Models with Answer Set Programming",
      "abstract": "Decision tree models, including random forests and gradient-boosted decision trees, are widely used in machine learning due to their high predictive performance.  However, their complex structures often make them difficult to interpret, especially in safety-critical applications where model decisions require formal justification.  Recent work has demonstrated that logical and abductive explanations can be derived through automated reasoning techniques.  In this paper, we propose a method for generating various types of explanations, namely, sufficient, contrastive, majority, and tree-specific explanations, using Answer Set Programming (ASP).  Compared to SAT-based approaches, our ASP-based method offers greater flexibility in encoding user preferences and supports enumeration of all possible explanations.  We empirically evaluate the approach on a diverse set of datasets and demonstrate its effectiveness and limitations compared to existing methods.",
      "authors": [
        "Akihiro Takemura",
        "Masayuki Otani",
        "Katsumi Inoue"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "published": "2026-01-07 12:07:45+00:00",
      "link": "https://arxiv.org/pdf/2601.03845v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03844v1",
      "title": "XAI-LAW: A Logic Programming Tool for Modeling, Explaining, and Learning Legal Decisions",
      "abstract": "We propose an approach to model articles of the Italian Criminal Code (ICC), using Answer Set Programming (ASP), and to semi-automatically learn legal rules from examples based on prior judicial decisions. The developed tool is intended to support legal experts during the criminal trial phase by providing reasoning and possible legal outcomes. The methodology involves analyzing and encoding articles of the ICC in ASP, including \"crimes against the person\" and property offenses. The resulting model is validated on a set of previous verdicts and refined as necessary. During the encoding process, contradictions may arise; these are properly handled by the system, which also generates possible decisions for new cases and provides explanations through a tool that leverages the \"supportedness\" of stable models. The automatic explainability offered by the tool can also be used to clarify the logic behind judicial decisions, making the decision-making process more interpretable. Furthermore, the tool integrates an inductive logic programming system for ASP, which is employed to generalize legal rules from case examples.",
      "authors": [
        "Agostino Dovier",
        "Talissa Dreossi",
        "Andrea Formisano",
        "Benedetta Strizzolo"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 12:07:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03844v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03822v1",
      "title": "ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition",
      "abstract": "Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets.",
      "authors": [
        "Muyang Zhao",
        "Qi Qi",
        "Hao Sun"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 11:30:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03822v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04270v1",
      "title": "Predictable Gradient Manifolds in Deep Learning: Temporal Path-Length and Intrinsic Rank as a Complexity Regime",
      "abstract": "Deep learning optimization exhibits structure that is not captured by worst-case gradient bounds. Empirically, gradients along training trajectories are often temporally predictable and evolve within a low-dimensional subspace. In this work we formalize this observation through a measurable framework for predictable gradient manifolds.   We introduce two computable quantities: a prediction-based path length that measures how well gradients can be forecast from past information, and a predictable rank that quantifies the intrinsic temporal dimension of gradient increments. We show how classical online and nonconvex optimization guarantees can be restated so that convergence and regret depend explicitly on these quantities, rather than on worst-case variation.   Across convolutional networks, vision transformers, language models, and synthetic control tasks, we find that gradient trajectories are locally predictable and exhibit strong low-rank structure over time. These properties are stable across architectures and optimizers, and can be diagnosed directly from logged gradients using lightweight random projections.   Our results provide a unifying lens for understanding optimization dynamics in modern deep learning, reframing standard training as operating in a low-complexity temporal regime. This perspective suggests new directions for adaptive optimizers, rank-aware tracking, and prediction-based algorithm design grounded in measurable properties of real training runs.",
      "authors": [
        "Anherutowa Calvo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 11:23:55+00:00",
      "link": "https://arxiv.org/pdf/2601.04270v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04268v1",
      "title": "Making Tunable Parameters State-Dependent in Weather and Climate Models with Reinforcement Learning",
      "abstract": "Weather and climate models rely on parametrisations to represent unresolved sub-grid processes. Traditional schemes rely on fixed coefficients that are weakly constrained and tuned offline, contributing to persistent biases that limit their ability to adapt to the underlying physics. This study presents a framework that learns components of parametrisation schemes online as a function of the evolving model state using reinforcement learning (RL) and evaluates the resulting RL-driven parameter updates across a hierarchy of idealised testbeds spanning a simple climate bias correction (SCBC), a radiative-convective equilibrium (RCE), and a zonal mean energy balance model (EBM) with both single-agent and federated multi-agent settings. Across nine RL algorithms, Truncated Quantile Critics (TQC), Deep Deterministic Policy Gradient (DDPG), and Twin Delayed DDPG (TD3) achieved the highest skill and the most stable convergence across configurations, with performance assessed against a static baseline using area-weighted RMSE, temperature profile and pressure-level diagnostics. For the EBM, single-agent RL outperformed static parameter tuning with the strongest gains in tropical and mid-latitude bands, while federated RL on multi-agent setups enabled geographically specialised control and faster convergence, with a six-agent DDPG configuration using frequent aggregation yielding the lowest area-weighted RMSE across the tropics and mid-latitudes. The learnt corrections were also physically meaningful as agents modulated EBM radiative parameters to reduce meridional biases, adjusted RCE lapse rates to match vertical temperature errors, and stabilised SCBC heating increments to limit drift. Overall, results highlight RL to deliver skilful state-dependent, and regime-aware parametrisations, offering a scalable pathway for online learning within numerical models.",
      "authors": [
        "Pritthijit Nath",
        "Sebastian Schemm",
        "Henry Moss",
        "Peter Haynes",
        "Emily Shuckburgh",
        "Mark J. Webb"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.ao-ph"
      ],
      "published": "2026-01-07 11:19:16+00:00",
      "link": "https://arxiv.org/pdf/2601.04268v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03812v1",
      "title": "AI Generated Text Detection",
      "abstract": "The rapid development of large language models has led to an increase in AI-generated text, with students increasingly using LLM-generated content as their own work, which violates academic integrity. This paper presents an evaluation of AI text detection methods, including both traditional machine learning models and transformer-based architectures. We utilize two datasets, HC3 and DAIGT v2, to build a unified benchmark and apply a topic-based data split to prevent information leakage. This approach ensures robust generalization across unseen domains. Our experiments show that TF-IDF logistic regression achieves a reasonable baseline accuracy of 82.87%. However, deep learning models outperform it. The BiLSTM classifier achieves an accuracy of 88.86%, while DistilBERT achieves a similar accuracy of 88.11% with the highest ROC-AUC score of 0.96, demonstrating the strongest overall performance. The results indicate that contextual semantic modeling is significantly superior to lexical features and highlight the importance of mitigating topic memorization through appropriate evaluation protocols. The limitations of this work are primarily related to dataset diversity and computational constraints. In future work, we plan to expand dataset diversity and utilize parameter-efficient fine-tuning methods such as LoRA. We also plan to explore smaller or distilled models and employ more efficient batching strategies and hardware-aware optimization.",
      "authors": [
        "Adilkhan Alikhanov",
        "Aidar Amangeldi",
        "Diar Demeubay",
        "Dilnaz Akhmetzhan",
        "Nurbek Moldakhmetov",
        "Omar Polat",
        "Galymzhan Zharas"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 11:18:10+00:00",
      "link": "https://arxiv.org/pdf/2601.03812v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03808v1",
      "title": "From Brute Force to Semantic Insight: Performance-Guided Data Transformation Design with LLMs",
      "abstract": "Large language models (LLMs) have achieved notable performance in code synthesis; however, data-aware augmentation remains a limiting factor, handled via heuristic design or brute-force approaches. We introduce a performance-aware, closed-loop solution in the NNGPT ecosystem of projects that enables LLMs to autonomously engineer optimal transformations by internalizing empirical performance cues. We fine-tune LLMs with Low-Rank Adaptation on a novel repository of more than 6,000 empirically evaluated PyTorch augmentation functions, each annotated solely by downstream model accuracy. Training uses pairwise performance ordering (better-worse transformations), enabling alignment through empirical feedback without reinforcement learning, reward models, or symbolic objectives. This reduces the need for exhaustive search, achieving up to 600x times fewer evaluated candidates than brute-force discovery while maintaining competitive peak accuracy and shifting generation from random synthesis to task-aligned design. Ablation studies show that structured Chain-of-Thought prompting introduces syntactic noise and degrades performance, whereas direct prompting ensures stable optimization in performance-critical code tasks. Qualitative and quantitative analyses demonstrate that the model internalizes semantic performance cues rather than memorizing syntax. These results show that LLMs can exhibit task-level reasoning through non-textual feedback loops, bypassing explicit symbolic rewards.",
      "authors": [
        "Usha Shrestha",
        "Dmitry Ignatov",
        "Radu Timofte"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-07 11:13:02+00:00",
      "link": "https://arxiv.org/pdf/2601.03808v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03802v1",
      "title": "Quantum vs. Classical Machine Learning: A Benchmark Study for Financial Prediction",
      "abstract": "In this paper, we present a reproducible benchmarking framework that systematically compares QML models with architecture-matched classical counterparts across three financial tasks: (i) directional return prediction on U.S. and Turkish equities, (ii) live-trading simulation with Quantum LSTMs versus classical LSTMs on the S\\&P 500, and (iii) realized volatility forecasting using Quantum Support Vector Regression. By standardizing data splits, features, and evaluation metrics, our study provides a fair assessment of when current-generation QML models can match or exceed classical methods. Our results reveal that quantum approaches show performance gains when data structure and circuit design are well aligned. In directional classification, hybrid quantum neural networks surpass the parameter-matched ANN by \\textbf{+3.8 AUC} and \\textbf{+3.4 accuracy points} on \\texttt{AAPL} stock and by \\textbf{+4.9 AUC} and \\textbf{+3.6 accuracy points} on Turkish stock \\texttt{KCHOL}. In live trading, the QLSTM achieves higher risk-adjusted returns in \\textbf{two of four} S\\&P~500 regimes. For volatility forecasting, an angle-encoded QSVR attains the \\textbf{lowest QLIKE} on \\texttt{KCHOL} and remains within $\\sim$0.02-0.04 QLIKE of the best classical kernels on \\texttt{S\\&P~500} and \\texttt{AAPL}. Our benchmarking framework clearly identifies the scenarios where current QML architectures offer tangible improvements and where established classical methods continue to dominate.",
      "authors": [
        "Rehan Ahmad",
        "Muhammad Kashif",
        "Nouhaila Innan",
        "Muhammad Shafique"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "quant-ph"
      ],
      "published": "2026-01-07 11:02:03+00:00",
      "link": "https://arxiv.org/pdf/2601.03802v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03801v1",
      "title": "Physically Consistent Machine Learning for Melting Temperature Prediction of Refractory High-Entropy Alloys",
      "abstract": "Predicting the melting temperature (Tm) of multi-component and high-entropy alloys (HEAs) is critical for high-temperature applications but computationally expensive using traditional CALPHAD or DFT methods. In this work, we develop a gradient-boosted decision tree (XGBoost) model to predict Tm for complex alloys based on elemental properties. To ensure physical consistency, we address the issue of data leakage by excluding temperature-dependent thermodynamic descriptors (such as Gibbs free energy of mixing) and instead rely on physically motivated elemental features. The optimized model achieves a coefficient of determination (R2) of 0.948 and a Mean Squared Error (MSE) of 9928 which is about 5% relative error for HEAs on a validation set of approximately 1300 compositions. Crucially, we validate the model using the Valence Electron Concentration (VEC) rule. Without explicit constraints during training, the model successfully captures the known stability transition between BCC and FCC phases at a VEC of approximately 6.87. These results demonstrate that data-driven models, when properly feature-engineered, can capture fundamental metallurgical principles for rapid alloy screening.",
      "authors": [
        "Mohd Hasnain"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.LG"
      ],
      "published": "2026-01-07 10:59:24+00:00",
      "link": "https://arxiv.org/pdf/2601.03801v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03792v1",
      "title": "VietMed-MCQ: A Consistency-Filtered Data Synthesis Framework for Vietnamese Traditional Medicine Evaluation",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in general medical domains. However, their performance significantly degrades in specialized, culturally specific domains such as Vietnamese Traditional Medicine (VTM), primarily due to the scarcity of high-quality, structured benchmarks. In this paper, we introduce VietMed-MCQ, a novel multiple-choice question dataset generated via a Retrieval-Augmented Generation (RAG) pipeline with an automated consistency check mechanism. Unlike previous synthetic datasets, our framework incorporates a dual-model validation approach to ensure reasoning consistency through independent answer verification, though the substring-based evidence checking has known limitations. The complete dataset of 3,190 questions spans three difficulty levels and underwent validation by one medical expert and four students, achieving 94.2 percent approval with substantial inter-rater agreement (Fleiss' kappa = 0.82). We benchmark seven open-source models on VietMed-MCQ. Results reveal that general-purpose models with strong Chinese priors outperform Vietnamese-centric models, highlighting cross-lingual conceptual transfer, while all models still struggle with complex diagnostic reasoning. Our code and dataset are publicly available to foster research in low-resource medical domains.",
      "authors": [
        "Huynh Trung Kiet",
        "Dao Sy Duy Minh",
        "Nguyen Dinh Ha Duong",
        "Le Hoang Minh Huy",
        "Long Nguyen",
        "Dien Dinh"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 10:49:56+00:00",
      "link": "https://arxiv.org/pdf/2601.03792v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03790v1",
      "title": "NeoAMT: Neologism-Aware Agentic Machine Translation with Reinforcement Learning",
      "abstract": "Neologism-aware machine translation aims to translate source sentences containing neologisms into target languages. This field remains underexplored compared with general machine translation (MT). In this paper, we propose an agentic framework, NeoAMT, for neologism-aware machine translation using a Wiktionary search tool. Specifically, we first create a new dataset for neologism-aware machine translation and develop a search tool based on Wiktionary. The new dataset covers 16 languages and 75 translation directions and is derived from approximately 10 million records of an English Wiktionary dump. The retrieval corpus of the search tool is also constructed from around 3 million cleaned records of the Wiktionary dump. We then use it for training the translation agent with reinforcement learning (RL) and evaluating the accuracy of neologism-aware machine translation. Based on this, we also propose an RL training framework that contains a novel reward design and an adaptive rollout generation approach by leveraging \"translation difficulty\" to further improve the translation quality of translation agents using our search tool.",
      "authors": [
        "Zhongtao Miao",
        "Kaiyan Zhao",
        "Masaaki Nagata",
        "Yoshimasa Tsuruoka"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 10:49:00+00:00",
      "link": "https://arxiv.org/pdf/2601.03790v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03783v1",
      "title": "HearSay Benchmark: Do Audio LLMs Leak What They Hear?",
      "abstract": "While Audio Large Language Models (ALLMs) have achieved remarkable progress in understanding and generation, their potential privacy implications remain largely unexplored. This paper takes the first step to investigate whether ALLMs inadvertently leak user privacy solely through acoustic voiceprints and introduces $\\textit{HearSay}$, a comprehensive benchmark constructed from over 22,000 real-world audio clips. To ensure data quality, the benchmark is meticulously curated through a rigorous pipeline involving automated profiling and human verification, guaranteeing that all privacy labels are grounded in factual records. Extensive experiments on $\\textit{HearSay}$ yield three critical findings: $\\textbf{Significant Privacy Leakage}$: ALLMs inherently extract private attributes from voiceprints, reaching 92.89% accuracy on gender and effectively profiling social attributes. $\\textbf{Insufficient Safety Mechanisms}$: Alarmingly, existing safeguards are severely inadequate; most models fail to refuse privacy-intruding requests, exhibiting near-zero refusal rates for physiological traits. $\\textbf{Reasoning Amplifies Risk}$: Chain-of-Thought (CoT) reasoning exacerbates privacy risks in capable models by uncovering deeper acoustic correlations. These findings expose critical vulnerabilities in ALLMs, underscoring the urgent need for targeted privacy alignment. The codes and dataset are available at https://github.com/JinWang79/HearSay_Benchmark",
      "authors": [
        "Jin Wang",
        "Liang Lin",
        "Kaiwen Luo",
        "Weiliu Wang",
        "Yitian Chen",
        "Moayad Aloqaily",
        "Xuehai Tang",
        "Zhenhong Zhou",
        "Kun Wang",
        "Li Sun",
        "Qingsong Wen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 10:33:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03783v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03781v1",
      "title": "MVP: Enhancing Video Large Language Models via Self-supervised Masked Video Prediction",
      "abstract": "Reinforcement learning based post-training paradigms for Video Large Language Models (VideoLLMs) have achieved significant success by optimizing for visual-semantic tasks such as captioning or VideoQA. However, while these approaches effectively enhance perception abilities, they primarily target holistic content understanding, often lacking explicit supervision for intrinsic temporal coherence and inter-frame correlations. This tendency limits the models' ability to capture intricate dynamics and fine-grained visual causality. To explicitly bridge this gap, we propose a novel post-training objective: Masked Video Prediction (MVP). By requiring the model to reconstruct a masked continuous segment from a set of challenging distractors, MVP forces the model to attend to the sequential logic and temporal context of events. To support scalable training, we introduce a scalable data synthesis pipeline capable of transforming arbitrary video corpora into MVP training samples, and further employ Group Relative Policy Optimization (GRPO) with a fine-grained reward function to enhance the model's understanding of video context and temporal properties. Comprehensive evaluations demonstrate that MVP enhances video reasoning capabilities by directly reinforcing temporal reasoning and causal understanding.",
      "authors": [
        "Xiaokun Sun",
        "Zezhong Wu",
        "Zewen Ding",
        "Linli Xu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 10:25:48+00:00",
      "link": "https://arxiv.org/pdf/2601.03781v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03780v1",
      "title": "Assessing and Improving the Representativeness of Code Generation Benchmarks Using Knowledge Units (KUs) of Programming Languages -- An Empirical Study",
      "abstract": "Large Language Models (LLMs) such as GPT-4, Claude and LLaMA have shown impressive performance in code generation, typically evaluated using benchmarks (e.g., HumanEval). However, effective code generation requires models to understand and apply a wide range of language concepts. If the concepts exercised in benchmarks are not representative of those used in real-world projects, evaluations may yield incomplete. Despite this concern, the representativeness of code concepts in benchmarks has not been systematically examined.   To address this gap, we present the first empirical study that analyzes the representativeness of code generation benchmarks through the lens of Knowledge Units (KUs) - cohesive sets of programming language capabilities provided by language constructs and APIs. We analyze KU coverage in two widely used Python benchmarks, HumanEval and MBPP, and compare them with 30 real-world Python projects. Our results show that each benchmark covers only half of the identified 20 KUs, whereas projects exercise all KUs with relatively balanced distributions. In contrast, benchmark tasks exhibit highly skewed KU distributions.   To mitigate this misalignment, we propose a prompt-based LLM framework that synthesizes KU-based tasks to rebalance benchmark KU distributions and better align them with real-world usage. Using this framework, we generate 440 new tasks and augment existing benchmarks. The augmented benchmarks substantially improve KU coverage and achieve over a 60% improvement in distributional alignment. Evaluations of state-of-the-art LLMs on these augmented benchmarks reveal consistent and statistically significant performance drops (12.54-44.82%), indicating that existing benchmarks overestimate LLM performance due to their limited KU coverage. Our findings provide actionable guidance for building more realistic evaluations of LLM code-generation capabilities.",
      "authors": [
        "Md Ahasanuzzaman",
        "Bram Adams",
        "Emad Fallahzadeh",
        "Gustavo A. Oliva",
        "Ahmed E. Hassan"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-07 10:23:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03780v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03774v1",
      "title": "Scalable Machine Learning Force Fields for Macromolecular Systems Through Long-Range Aware Message Passing",
      "abstract": "Machine learning force fields (MLFFs) have revolutionized molecular simulations by providing quantum mechanical accuracy at the speed of molecular mechanical computations. However, a fundamental reliance of these models on fixed-cutoff architectures limits their applicability to macromolecular systems where long-range interactions dominate. We demonstrate that this locality constraint causes force prediction errors to scale monotonically with system size, revealing a critical architectural bottleneck. To overcome this, we establish the systematically designed MolLR25 ({Mol}ecules with {L}ong-{R}ange effect) benchmark up to 1200 atoms, generated using high-fidelity DFT, and introduce E2Former-LSR, an equivariant transformer that explicitly integrates long-range attention blocks. E2Former-LSR exhibits stable error scaling, achieves superior fidelity in capturing non-covalent decay, and maintains precision on complex protein conformations. Crucially, its efficient design provides up to 30% speedup compared to purely local models. This work validates the necessity of non-local architectures for generalizable MLFFs, enabling high-fidelity molecular dynamics for large-scale chemical and biological systems.",
      "authors": [
        "Chu Wang",
        "Lin Huang",
        "Xinran Wei",
        "Tao Qin",
        "Arthur Jiang",
        "Lixue Cheng",
        "Jia Zhang"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "physics.bio-ph"
      ],
      "published": "2026-01-07 10:12:34+00:00",
      "link": "https://arxiv.org/pdf/2601.03774v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03753v1",
      "title": "Probabilistic Transformers for Joint Modeling of Global Weather Dynamics and Decision-Centric Variables",
      "abstract": "Weather forecasts sit upstream of high-stakes decisions in domains such as grid operations, aviation, agriculture, and emergency response. Yet forecast users often face a difficult trade-off. Many decision-relevant targets are functionals of the atmospheric state variables, such as extrema, accumulations, and threshold exceedances, rather than state variables themselves. As a result, users must estimate these targets via post-processing, which can be suboptimal and can introduce structural bias. The core issue is that decisions depend on distributions over these functionals that the model is not trained to learn directly.   In this work, we introduce GEM-2, a probabilistic transformer that jointly learns global atmospheric dynamics alongside a suite of variables that users directly act upon. Using this training recipe, we show that a lightweight (~275M params) and computationally efficient (~20-100x training speedup relative to state-of-the-art) transformer trained on the CRPS objective can directly outperform operational numerical weather prediction (NWP) models and be competitive with ML models that rely on expensive multi-step diffusion processes or require bespoke multi-stage fine-tuning strategies. We further demonstrate state-of-the-art economic value metrics under decision-theoretic evaluation, stable convergence to climatology at S2S and seasonal timescales, and a surprising insensitivity to many commonly assumed architectural and training design choices.",
      "authors": [
        "Paulius Rauba",
        "Viktor Cikojevic",
        "Fran Bartolic",
        "Sam Levang",
        "Ty Dickinson",
        "Chase Dwelle"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 09:43:36+00:00",
      "link": "https://arxiv.org/pdf/2601.03753v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03743v1",
      "title": "O-Researcher: An Open Ended Deep Research Model via Multi-Agent Distillation and Agentic RL",
      "abstract": "The performance gap between closed-source and open-source large language models (LLMs) is largely attributed to disparities in access to high-quality training data. To bridge this gap, we introduce a novel framework for the automated synthesis of sophisticated, research-grade instructional data. Our approach centers on a multi-agent workflow where collaborative AI agents simulate complex tool-integrated reasoning to generate diverse and high-fidelity data end-to-end. Leveraging this synthesized data, we develop a two-stage training strategy that integrates supervised fine-tuning with a novel reinforcement learning method, designed to maximize model alignment and capability. Extensive experiments demonstrate that our framework empowers open-source models across multiple scales, enabling them to achieve new state-of-the-art performance on the major deep research benchmark. This work provides a scalable and effective pathway for advancing open-source LLMs without relying on proprietary data or models.",
      "authors": [
        "Yi Yao",
        "He Zhu",
        "Piaohong Wang",
        "Jincheng Ren",
        "Xinlong Yang",
        "Qianben Chen",
        "Xiaowan Li",
        "Dingfeng Shi",
        "Jiaxian Li",
        "Qiexiang Wang",
        "Sinuo Wang",
        "Xinpeng Liu",
        "Jiaqi Wu",
        "Minghao Liu",
        "Wangchunshu Zhou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 09:31:10+00:00",
      "link": "https://arxiv.org/pdf/2601.03743v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03741v1",
      "title": "I2E: From Image Pixels to Actionable Interactive Environments for Text-Guided Image Editing",
      "abstract": "Existing text-guided image editing methods primarily rely on end-to-end pixel-level inpainting paradigm. Despite its success in simple scenarios, this paradigm still significantly struggles with compositional editing tasks that require precise local control and complex multi-object spatial reasoning. This paradigm is severely limited by 1) the implicit coupling of planning and execution, 2) the lack of object-level control granularity, and 3) the reliance on unstructured, pixel-centric modeling. To address these limitations, we propose I2E, a novel \"Decompose-then-Action\" paradigm that revisits image editing as an actionable interaction process within a structured environment. I2E utilizes a Decomposer to transform unstructured images into discrete, manipulable object layers and then introduces a physics-aware Vision-Language-Action Agent to parse complex instructions into a series of atomic actions via Chain-of-Thought reasoning. Further, we also construct I2E-Bench, a benchmark designed for multi-instance spatial reasoning and high-precision editing. Experimental results on I2E-Bench and multiple public benchmarks demonstrate that I2E significantly outperforms state-of-the-art methods in handling complex compositional instructions, maintaining physical plausibility, and ensuring multi-turn editing stability.",
      "authors": [
        "Jinghan Yu",
        "Junhao Xiao",
        "Chenyu Zhu",
        "Jiaming Li",
        "Jia Li",
        "HanMing Deng",
        "Xirui Wang",
        "Guoli Jia",
        "Jianjun Li",
        "Zhiyuan Ma",
        "Xiang Bai",
        "Bowen Zhou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 09:29:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03741v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03736v1",
      "title": "HyperCOD: The First Challenging Benchmark and Baseline for Hyperspectral Camouflaged Object Detection",
      "abstract": "RGB-based camouflaged object detection struggles in real-world scenarios where color and texture cues are ambiguous. While hyperspectral image offers a powerful alternative by capturing fine-grained spectral signatures, progress in hyperspectral camouflaged object detection (HCOD) has been critically hampered by the absence of a dedicated, large-scale benchmark. To spur innovation, we introduce HyperCOD, the first challenging benchmark for HCOD. Comprising 350 high-resolution hyperspectral images, It features complex real-world scenarios with minimal objects, intricate shapes, severe occlusions, and dynamic lighting to challenge current models. The advent of foundation models like the Segment Anything Model (SAM) presents a compelling opportunity. To adapt the Segment Anything Model (SAM) for HCOD, we propose HyperSpectral Camouflage-aware SAM (HSC-SAM). HSC-SAM ingeniously reformulates the hyperspectral image by decoupling it into a spatial map fed to SAM's image encoder and a spectral saliency map that serves as an adaptive prompt. This translation effectively bridges the modality gap. Extensive experiments show that HSC-SAM sets a new state-of-the-art on HyperCOD and generalizes robustly to other public HSI datasets. The HyperCOD dataset and our HSC-SAM baseline provide a robust foundation to foster future research in this emerging area.",
      "authors": [
        "Shuyan Bai",
        "Tingfa Xu",
        "Peifu Liu",
        "Yuhao Qiu",
        "Huiyan Bai",
        "Huan Chen",
        "Yanyan Peng",
        "Jianan Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 09:26:32+00:00",
      "link": "https://arxiv.org/pdf/2601.03736v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03733v1",
      "title": "RadDiff: Describing Differences in Radiology Image Sets with Natural Language",
      "abstract": "Understanding how two radiology image sets differ is critical for generating clinical insights and for interpreting medical AI systems. We introduce RadDiff, a multimodal agentic system that performs radiologist-style comparative reasoning to describe clinically meaningful differences between paired radiology studies. RadDiff builds on a proposer-ranker framework from VisDiff, and incorporates four innovations inspired by real diagnostic workflows: (1) medical knowledge injection through domain-adapted vision-language models; (2) multimodal reasoning that integrates images with their clinical reports; (3) iterative hypothesis refinement across multiple reasoning rounds; and (4) targeted visual search that localizes and zooms in on salient regions to capture subtle findings. To evaluate RadDiff, we construct RadDiffBench, a challenging benchmark comprising 57 expert-validated radiology study pairs with ground-truth difference descriptions. On RadDiffBench, RadDiff achieves 47% accuracy, and 50% accuracy when guided by ground-truth reports, significantly outperforming the general-domain VisDiff baseline. We further demonstrate RadDiff's versatility across diverse clinical tasks, including COVID-19 phenotype comparison, racial subgroup analysis, and discovery of survival-related imaging features. Together, RadDiff and RadDiffBench provide the first method-and-benchmark foundation for systematically uncovering meaningful differences in radiological data.",
      "authors": [
        "Xiaoxian Shen",
        "Yuhui Zhang",
        "Sahithi Ankireddy",
        "Xiaohan Wang",
        "Maya Varma",
        "Henry Guo",
        "Curtis Langlotz",
        "Serena Yeung-Levy"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "published": "2026-01-07 09:25:04+00:00",
      "link": "https://arxiv.org/pdf/2601.03733v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03731v1",
      "title": "From Laboratory to Real-World Applications: Benchmarking Agentic Code Reasoning at the Repository Level",
      "abstract": "As large language models (LLMs) evolve into autonomous agents, evaluating repository-level reasoning, the ability to maintain logical consistency across massive, real-world, interdependent file systems, has become critical. Current benchmarks typically fluctuate between isolated code snippets and black-box evaluations. We present RepoReason, a white-box diagnostic benchmark centered on abductive assertion verification. To eliminate memorization while preserving authentic logical depth, we implement an execution-driven mutation framework that utilizes the environment as a semantic oracle to regenerate ground-truth states. Furthermore, we establish a fine-grained diagnostic system using dynamic program slicing, quantifying reasoning via three orthogonal metrics: $ESV$ (reading load), $MCL$ (simulation depth), and $DFI$ (integration width). Comprehensive evaluations of frontier models (e.g., Claude-4.5-Sonnet, DeepSeek-v3.1-Terminus) reveal a prevalent aggregation deficit, where integration width serves as the primary cognitive bottleneck. Our findings provide granular white-box insights for optimizing the next generation of agentic software engineering.",
      "authors": [
        "Jia Li",
        "Yuxin Su",
        "Michael R. Lyu"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-01-07 09:22:28+00:00",
      "link": "https://arxiv.org/pdf/2601.03731v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03725v1",
      "title": "EDCO: Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning",
      "abstract": "Domain-specific large language models (LLMs), typically developed by fine-tuning a pre-trained general-purpose LLM on specialized datasets, represent a significant advancement in applied AI. A common strategy in LLM fine-tuning is curriculum learning, which pre-orders training samples based on metrics like difficulty to improve learning efficiency compared to a random sampling strategy. However, most existing methods for LLM fine-tuning rely on a static curriculum, designed prior to training, which lacks adaptability to the model's evolving needs during fine-tuning. To address this, we propose EDCO, a novel framework based on two key concepts: inference entropy and dynamic curriculum orchestration. Inspired by recent findings that maintaining high answer entropy benefits long-term reasoning gains, EDCO prioritizes samples with high inference entropy in a continuously adapted curriculum. EDCO integrates three core components: an efficient entropy estimator that uses prefix tokens to approximate full-sequence entropy, an entropy-based curriculum generator that selects data points with the highest inference entropy, and an LLM trainer that optimizes the model on the selected curriculum. Comprehensive experiments in communication, medicine and law domains, EDCO outperforms traditional curriculum strategies for fine-tuning Qwen3-4B and Llama3.2-3B models under supervised and reinforcement learning settings. Furthermore, the proposed efficient entropy estimation reduces computational time by 83.5% while maintaining high accuracy.",
      "authors": [
        "Jing-Cheng Pang",
        "Liu Sun",
        "Chang Zhou",
        "Xian Tang",
        "Haichuan Ma",
        "Kun Jiang",
        "Jianlong Wang",
        "Kai Zhang",
        "Sijie Wu",
        "Haoran Cai",
        "Chenwei Wu",
        "Xubin Li",
        "Xin Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 09:20:05+00:00",
      "link": "https://arxiv.org/pdf/2601.03725v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03723v1",
      "title": "ETR: Outcome-Guided Elastic Trust Regions for Policy Optimization",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an important paradigm for unlocking reasoning capabilities in large language models, exemplified by the success of OpenAI o1 and DeepSeek-R1. Currently, Group Relative Policy Optimization (GRPO) stands as the dominant algorithm in this domain due to its stable training and critic-free efficiency. However, we argue that GRPO suffers from a structural limitation: it imposes a uniform, static trust region constraint across all samples. This design implicitly assumes signal homogeneity, a premise misaligned with the heterogeneous nature of outcome-driven learning, where advantage magnitudes and variances fluctuate significantly. Consequently, static constraints fail to fully exploit high-quality signals while insufficiently suppressing noise, often precipitating rapid entropy collapse. To address this, we propose \\textbf{E}lastic \\textbf{T}rust \\textbf{R}egions (\\textbf{ETR}), a dynamic mechanism that aligns optimization constraints with signal quality. ETR constructs a signal-aware landscape through dual-level elasticity: at the micro level, it scales clipping boundaries based on advantage magnitude to accelerate learning from high-confidence paths; at the macro level, it leverages group variance to implicitly allocate larger update budgets to tasks in the optimal learning zone. Extensive experiments on AIME and MATH benchmarks demonstrate that ETR consistently outperforms GRPO, achieving superior accuracy while effectively mitigating policy entropy degradation to ensure sustained exploration.",
      "authors": [
        "Shijie Zhang",
        "Kevin Zhang",
        "Zheyuan Gu",
        "Xiang Guo",
        "Rujun Guo",
        "Shaoyu Liu",
        "Guanjun Jiang",
        "Xiaozhao Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 09:19:53+00:00",
      "link": "https://arxiv.org/pdf/2601.03723v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03715v1",
      "title": "R$^3$L: Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification",
      "abstract": "Reinforcement learning drives recent advances in LLM reasoning and agentic capabilities, yet current approaches struggle with both exploration and exploitation. Exploration suffers from low success rates on difficult tasks and high costs of repeated rollouts from scratch. Exploitation suffers from coarse credit assignment and training instability: Trajectory-level rewards penalize valid prefixes for later errors, and failure-dominated groups overwhelm the few positive signals, leaving optimization without constructive direction. To this end, we propose R$^3$L, Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification. To synthesize high-quality trajectories, R$^3$L shifts from stochastic sampling to active synthesis via reflect-then-retry, leveraging language feedback to diagnose errors, transform failed attempts into successful ones, and reduce rollout costs by restarting from identified failure points. With errors diagnosed and localized, Pivotal Credit Assignment updates only the diverging suffix where contrastive signals exist, excluding the shared prefix from gradient update. Since failures dominate on difficult tasks and reflect-then-retry produces off-policy data, risking training instability, Positive Amplification upweights successful trajectories to ensure positive signals guide the optimization process. Experiments on agentic and reasoning tasks demonstrate 5\\% to 52\\% relative improvements over baselines while maintaining training stability. Our code is released at https://github.com/shiweijiezero/R3L.",
      "authors": [
        "Weijie Shi",
        "Yanxi Chen",
        "Zexi Li",
        "Xuchen Pan",
        "Yuchang Sun",
        "Jiajie Xu",
        "Xiaofang Zhou",
        "Yaliang Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 09:04:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03715v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03714v2",
      "title": "Visual Merit or Linguistic Crutch? A Close Look at DeepSeek-OCR",
      "abstract": "DeepSeek-OCR utilizes an optical 2D mapping approach to achieve high-ratio vision-text compression, claiming to decode text tokens exceeding ten times the input visual tokens. While this suggests a promising solution for the LLM long-context bottleneck, we investigate a critical question: \"Visual merit or linguistic crutch - which drives DeepSeek-OCR's performance?\" By employing sentence-level and word-level semantic corruption, we isolate the model's intrinsic OCR capabilities from its language priors. Results demonstrate that without linguistic support, DeepSeek-OCR's performance plummets from approximately 90% to 20%. Comparative benchmarking against 13 baseline models reveals that traditional pipeline OCR methods exhibit significantly higher robustness to such semantic perturbations than end-to-end methods. Furthermore, we find that lower visual token counts correlate with increased reliance on priors, exacerbating hallucination risks. Context stress testing also reveals a total model collapse around 10,000 text tokens, suggesting that current optical compression techniques may paradoxically aggravate the long-context bottleneck. This study empirically defines DeepSeek-OCR's capability boundaries and offers essential insights for future optimizations of the vision-text compression paradigm. We release all data, results and scripts used in this study at https://github.com/dududuck00/DeepSeekOCR.",
      "authors": [
        "Yunhao Liang",
        "Ruixuan Ying",
        "Bo Li",
        "Hong Li",
        "Kai Yan",
        "Qingwen Li",
        "Min Yang",
        "Okamoto Satoshi",
        "Zhe Cui",
        "Shiwen Ni"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CV"
      ],
      "published": "2026-01-07 09:01:23+00:00",
      "link": "https://arxiv.org/pdf/2601.03714v2",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03708v1",
      "title": "MHRC-Bench: A Multilingual Hardware Repository-Level Code Completion benchmark",
      "abstract": "Large language models (LLMs) have achieved strong performance on code completion tasks in general-purpose programming languages. However, existing repository-level code completion benchmarks focus almost exclusively on software code and largely overlook hardware description languages. In this work, we present \\textbf{MHRC-Bench}, consisting of \\textbf{MHRC-Bench-Train} and \\textbf{MHRC-Bench-Eval}, the first benchmark designed for multilingual hardware code completion at the repository level. Our benchmark targets completion tasks and covers three major hardware design coding styles. Each completion target is annotated with code-structure-level and hardware-oriented semantic labels derived from concrete syntax tree analysis. We conduct a comprehensive evaluation of models on MHRC-Bench-Eval. Comprehensive evaluation results and analysis demonstrate the effectiveness of MHRC-Bench.",
      "authors": [
        "Qingyun Zou",
        "Jiahao Cui",
        "Nuo Chen",
        "Bingsheng He",
        "Weng-Fai Wong"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "published": "2026-01-07 08:46:10+00:00",
      "link": "https://arxiv.org/pdf/2601.03708v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03707v1",
      "title": "AirNav: A Large-Scale Real-World UAV Vision-and-Language Navigation Dataset with Natural and Diverse Instructions",
      "abstract": "Existing Unmanned Aerial Vehicle (UAV) Vision-Language Navigation (VLN) datasets face issues such as dependence on virtual environments, lack of naturalness in instructions, and limited scale. To address these challenges, we propose AirNav, a large-scale UAV VLN benchmark constructed from real urban aerial data, rather than synthetic environments, with natural and diverse instructions. Additionally, we introduce the AirVLN-R1, which combines Supervised Fine-Tuning and Reinforcement Fine-Tuning to enhance performance and generalization. The feasibility of the model is preliminarily evaluated through real-world tests. Our dataset and code are publicly available.",
      "authors": [
        "Hengxing Cai",
        "Yijie Rao",
        "Ligang Huang",
        "Zanyang Zhong",
        "Jinhan Dong",
        "Jingjun Tan",
        "Wenhao Lu",
        "Renxin Zhong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 08:46:09+00:00",
      "link": "https://arxiv.org/pdf/2601.03707v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03704v1",
      "title": "Investigating Knowledge Distillation Through Neural Networks for Protein Binding Affinity Prediction",
      "abstract": "The trade-off between predictive accuracy and data availability makes it difficult to predict protein--protein binding affinity accurately. The lack of experimentally resolved protein structures limits the performance of structure-based machine learning models, which generally outperform sequence-based methods. In order to overcome this constraint, we suggest a regression framework based on knowledge distillation that uses protein structural data during training and only needs sequence data during inference. The suggested method uses binding affinity labels and intermediate feature representations to jointly supervise the training of a sequence-based student network under the guidance of a structure-informed teacher network. Leave-One-Complex-Out (LOCO) cross-validation was used to assess the framework on a non-redundant protein--protein binding affinity benchmark dataset. A maximum Pearson correlation coefficient (P_r) of 0.375 and an RMSE of 2.712 kcal/mol were obtained by sequence-only baseline models, whereas a P_r of 0.512 and an RMSE of 2.445 kcal/mol were obtained by structure-based models. With a P_r of 0.481 and an RMSE of 2.488 kcal/mol, the distillation-based student model greatly enhanced sequence-only performance. Improved agreement and decreased bias were further confirmed by thorough error analyses. With the potential to close the performance gap between sequence-based and structure-based models as larger datasets become available, these findings show that knowledge distillation is an efficient method for transferring structural knowledge to sequence-based predictors. The source code for running inference with the proposed distillation-based binding affinity predictor can be accessed at https://github.com/wajidarshad/ProteinAffinityKD.",
      "authors": [
        "Wajid Arshad Abbasi",
        "Syed Ali Abbas",
        "Maryum Bibi",
        "Saiqa Andleeb",
        "Muhammad Naveed Akhtar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM",
        "q-bio.MN",
        "q-bio.QM"
      ],
      "published": "2026-01-07 08:43:08+00:00",
      "link": "https://arxiv.org/pdf/2601.03704v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03703v1",
      "title": "TreeAdv: Tree-Structured Advantage Redistribution for Group-Based RL",
      "abstract": "Reinforcement learning with group-based objectives, such as Group Relative Policy Optimization (GRPO), is a common framework for aligning large language models on complex reasoning tasks. However, standard GRPO treats each rollout trajectory as an independent flat sequence and assigns a single sequence-level advantage to all tokens, which leads to sample inefficiency and a length bias toward verbose, redundant chains of thought without improving logical depth. We introduce TreeAdv (Tree-Structured Advantage Redistribution for Group-Based RL), which makes the tree structure of group rollouts explicit for both exploration and advantage assignment. Specifically, TreeAdv builds a group of trees (a forest) based on an entropy-driven sampling method where each tree branches at high-uncertainty decisions while sharing low-uncertainty tokens across rollouts. Then, TreeAdv aggregates token-level advantages for internal tree segments by redistributing the advantages of complete rollouts (all leaf nodes), and TreeAdv can easily apply to group-based objectives such as GRPO or GSPO. Across 10 math reasoning benchmarks, TreeAdv consistently outperforms GRPO and GSPO, while using substantially fewer generated tokens under identical supervision, data, and decoding budgets.",
      "authors": [
        "Lang Cao",
        "Hui Ruan",
        "Yongqian Li",
        "Peng Chao",
        "Wu Ning",
        "Haonan Song",
        "Renhong Chen",
        "Yitong Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 08:42:14+00:00",
      "link": "https://arxiv.org/pdf/2601.03703v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03699v1",
      "title": "RedBench: A Universal Dataset for Comprehensive Red Teaming of Large Language Models",
      "abstract": "As large language models (LLMs) become integral to safety-critical applications, ensuring their robustness against adversarial prompts is paramount. However, existing red teaming datasets suffer from inconsistent risk categorizations, limited domain coverage, and outdated evaluations, hindering systematic vulnerability assessments. To address these challenges, we introduce RedBench, a universal dataset aggregating 37 benchmark datasets from leading conferences and repositories, comprising 29,362 samples across attack and refusal prompts. RedBench employs a standardized taxonomy with 22 risk categories and 19 domains, enabling consistent and comprehensive evaluations of LLM vulnerabilities. We provide a detailed analysis of existing datasets, establish baselines for modern LLMs, and open-source the dataset and evaluation code. Our contributions facilitate robust comparisons, foster future research, and promote the development of secure and reliable LLMs for real-world deployment. Code: https://github.com/knoveleng/redeval",
      "authors": [
        "Quy-Anh Dang",
        "Chris Ngo",
        "Truong-Son Hy"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 08:34:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03699v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03689v1",
      "title": "A Pre-trained Reaction Embedding Descriptor Capturing Bond Transformation Patterns",
      "abstract": "With the rise of data-driven reaction prediction models, effective reaction descriptors are crucial for bridging the gap between real-world chemistry and digital representations. However, general-purpose, reaction-wise descriptors remain scarce. This study introduces RXNEmb, a novel reaction-level descriptor derived from RXNGraphormer, a model pre-trained to distinguish real reactions from fictitious ones with erroneous bond changes, thereby learning intrinsic bond formation and cleavage patterns. We demonstrate its utility by data-driven re-clustering of the USPTO-50k dataset, yielding a classification that more directly reflects bond-change similarities than rule-based categories. Combined with dimensionality reduction, RXNEmb enables visualization of reaction space diversity. Furthermore, attention weight analysis reveals the model's focus on chemically critical sites, providing mechanistic insight. RXNEmb serves as a powerful, interpretable tool for reaction fingerprinting and analysis, paving the way for more data-centric approaches in reaction analysis and discovery.",
      "authors": [
        "Weiqi Liu",
        "Fenglei Cao",
        "Yuan Qi",
        "Li-Cheng Xu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph"
      ],
      "published": "2026-01-07 08:24:08+00:00",
      "link": "https://arxiv.org/pdf/2601.03689v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03686v1",
      "title": "Dual-Attention Heterogeneous GNN for Multi-robot Collaborative Area Search via Deep Reinforcement Learning",
      "abstract": "In multi-robot collaborative area search, a key challenge is to dynamically balance the two objectives of exploring unknown areas and covering specific targets to be rescued. Existing methods are often constrained by homogeneous graph representations, thus failing to model and balance these distinct tasks. To address this problem, we propose a Dual-Attention Heterogeneous Graph Neural Network (DA-HGNN) trained using deep reinforcement learning. Our method constructs a heterogeneous graph that incorporates three entity types: robot nodes, frontier nodes, and interesting nodes, as well as their historical states. The dual-attention mechanism comprises the relational-aware attention and type-aware attention operations. The relational-aware attention captures the complex spatio-temporal relationships among robots and candidate goals. Building on this relational-aware heterogeneous graph, the type-aware attention separately computes the relevance between robots and each goal type (frontiers vs. points of interest), thereby decoupling the exploration and coverage from the unified tasks. Extensive experiments conducted in interactive 3D scenarios within the iGibson simulator, leveraging the Gibson and MatterPort3D datasets, validate the superior scalability and generalization capability of the proposed approach.",
      "authors": [
        "Lina Zhu",
        "Jiyu Cheng",
        "Yuehu Liu",
        "Wei Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-07 08:18:49+00:00",
      "link": "https://arxiv.org/pdf/2601.03686v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03683v1",
      "title": "Rethinking Recurrent Neural Networks for Time Series Forecasting: A Reinforced Recurrent Encoder with Prediction-Oriented Proximal Policy Optimization",
      "abstract": "Time series forecasting plays a crucial role in contemporary engineering information systems for supporting decision-making across various industries, where Recurrent Neural Networks (RNNs) have been widely adopted due to their capability in modeling sequential data. Conventional RNN-based predictors adopt an encoder-only strategy with sliding historical windows as inputs to forecast future values. However, this approach treats all time steps and hidden states equally without considering their distinct contributions to forecasting, leading to suboptimal performance. To address this limitation, we propose a novel Reinforced Recurrent Encoder with Prediction-oriented Proximal Policy Optimization, RRE-PPO4Pred, which significantly improves time series modeling capacity and forecasting accuracy of the RNN models. The core innovations of this method are: (1) A novel Reinforced Recurrent Encoder (RRE) framework that enhances RNNs by formulating their internal adaptation as a Markov Decision Process, creating a unified decision environment capable of learning input feature selection, hidden skip connection, and output target selection; (2) An improved Prediction-oriented Proximal Policy Optimization algorithm, termed PPO4Pred, which is equipped with a Transformer-based agent for temporal reasoning and develops a dynamic transition sampling strategy to enhance sampling efficiency; (3) A co-evolutionary optimization paradigm to facilitate the learning of the RNN predictor and the policy agent, providing adaptive and interactive time series modeling. Comprehensive evaluations on five real-world datasets indicate that our method consistently outperforms existing baselines, and attains accuracy better than state-of-the-art Transformer models, thus providing an advanced time series predictor in engineering informatics.",
      "authors": [
        "Xin Lai",
        "Shiming Deng",
        "Lu Yu",
        "Yumin Lai",
        "Shenghao Qiao",
        "Xinze Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "published": "2026-01-07 08:16:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03683v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03682v1",
      "title": "From Implicit to Explicit: Token-Efficient Logical Supervision for Mathematical Reasoning in LLMs",
      "abstract": "Recent studies reveal that large language models (LLMs) exhibit limited logical reasoning abilities in mathematical problem-solving, instead often relying on pattern-matching and memorization. We systematically analyze this limitation, focusing on logical relationship understanding, which is a core capability underlying genuine logical reasoning, and reveal that errors related to this capability account for over 90\\% of incorrect predictions, with Chain-of-Thought Supervised Fine-Tuning (CoT-SFT) failing to substantially reduce these errors. To address this bottleneck, we propose First-Step Logical Reasoning (FSLR), a lightweight training framework targeting logical relationship understanding. Our key insight is that the first planning step-identifying which variables to use and which operation to apply-encourages the model to derive logical relationships directly from the problem statement. By training models on this isolated step, FSLR provides explicit supervision for logical relationship understanding, unlike CoT-SFT which implicitly embeds such relationships within complete solution trajectories. Extensive experiments across multiple models and datasets demonstrate that FSLR consistently outperforms CoT-SFT under both in-distribution and out-of-distribution settings, with average improvements of 3.2\\% and 4.6\\%, respectively. Moreover, FSLR achieves 4-6x faster training and reduces training token consumption by over 80\\%.",
      "authors": [
        "Shaojie Wang",
        "Liang Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 08:15:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03682v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03676v1",
      "title": "Towards Compositional Generalization of LLMs via Skill Taxonomy Guided Data Synthesis",
      "abstract": "Large Language Models (LLMs) and agent-based systems often struggle with compositional generalization due to a data bottleneck in which complex skill combinations follow a long-tailed, power-law distribution, limiting both instruction-following performance and generalization in agent-centric tasks. To address this challenge, we propose STEPS, a Skill Taxonomy guided Entropy-based Post-training data Synthesis framework for generating compositionally challenging data. STEPS explicitly targets compositional generalization by uncovering latent relationships among skills and organizing them into an interpretable, hierarchical skill taxonomy using structural information theory. Building on this taxonomy, we formulate data synthesis as a constrained information maximization problem, selecting skill combinations that maximize marginal structural information within the hierarchy while preserving semantic coherence. Experiments on challenging instruction-following benchmarks show that STEPS outperforms existing data synthesis baselines, while also yielding improved compositional generalization in downstream agent-based evaluations.",
      "authors": [
        "Yifan Wei",
        "Li Du",
        "Xiaoyan Yu",
        "Yang Feng",
        "Angsheng Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 07:58:51+00:00",
      "link": "https://arxiv.org/pdf/2601.03676v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03673v1",
      "title": "Disentangling Aleatoric and Epistemic Uncertainty in Physics-Informed Neural Networks. Application to Insulation Material Degradation Prognostics",
      "abstract": "Physics-Informed Neural Networks (PINNs) provide a framework for integrating physical laws with data. However, their application to Prognostics and Health Management (PHM) remains constrained by the limited uncertainty quantification (UQ) capabilities. Most existing PINN-based prognostics approaches are deterministic or account only for epistemic uncertainty, limiting their suitability for risk-aware decision-making. This work introduces a heteroscedastic Bayesian Physics-Informed Neural Network (B-PINN) framework that jointly models epistemic and aleatoric uncertainty, yielding full predictive posteriors for spatiotemporal insulation material ageing estimation. The approach integrates Bayesian Neural Networks (BNNs) with physics-based residual enforcement and prior distributions, enabling probabilistic inference within a physics-informed learning architecture. The framework is evaluated on transformer insulation ageing application, validated with a finite-element thermal model and field measurements from a solar power plant, and benchmarked against deterministic PINNs, dropout-based PINNs (d-PINNs), and alternative B-PINN variants. Results show that the proposed B-PINN provides improved predictive accuracy and better-calibrated uncertainty estimates than competing approaches. A systematic sensitivity study further analyzes the impact of boundary-condition, initial-condition, and residual sampling strategies on accuracy, calibration, and generalization. Overall, the findings highlight the potential of Bayesian physics-informed learning to support uncertainty-aware prognostics and informed decision-making in transformer asset management.",
      "authors": [
        "Ibai Ramirez",
        "Jokin Alcibar",
        "Joel Pino",
        "Mikel Sanz",
        "Jose I. Aizpurua"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:54:09+00:00",
      "link": "https://arxiv.org/pdf/2601.03673v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03672v1",
      "title": "Sandwich Reasoning: An Answer-Reasoning-Answer Approach for Low-Latency Query Correction",
      "abstract": "Query correction is a critical entry point in modern search pipelines, demanding high accuracy strictly within real-time latency constraints. Chain-of-Thought (CoT) reasoning improves accuracy but incurs prohibitive latency for real-time query correction. A potential solution is to output an answer before reasoning to reduce latency; however, under autoregressive decoding, the early answer is independent of subsequent reasoning, preventing the model from leveraging its reasoning capability to improve accuracy. To address this issue, we propose Sandwich Reasoning (SandwichR), a novel approach that explicitly aligns a fast initial answer with post-hoc reasoning, enabling low-latency query correction without sacrificing reasoning-aware accuracy. SandwichR follows an Answer-Reasoning-Answer paradigm, producing an initial correction, an explicit reasoning process, and a final refined correction. To align the initial answer with post-reasoning insights, we design a consistency-aware reinforcement learning (RL) strategy: a dedicated consistency reward enforces alignment between the initial and final corrections, while margin-based rejection sampling prioritizes borderline samples where reasoning drives the most impactful corrective gains. Additionally, we construct a high-quality query correction dataset, addressing the lack of specialized benchmarks for complex query correction. Experimental results demonstrate that SandwichR achieves SOTA accuracy comparable to standard CoT while delivering a 40-70% latency reduction, resolving the latency-accuracy trade-off in online search.",
      "authors": [
        "Chen Zhang",
        "Kepu Zhang",
        "Jiatong Zhang",
        "Xiao Zhang",
        "Jun Xu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 07:52:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03672v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03670v1",
      "title": "DisastQA: A Comprehensive Benchmark for Evaluating Question Answering in Disaster Management",
      "abstract": "Accurate question answering (QA) in disaster management requires reasoning over uncertain and conflicting information, a setting poorly captured by existing benchmarks built on clean evidence. We introduce DisastQA, a large-scale benchmark of 3,000 rigorously verified questions (2,000 multiple-choice and 1,000 open-ended) spanning eight disaster types. The benchmark is constructed via a human-LLM collaboration pipeline with stratified sampling to ensure balanced coverage. Models are evaluated under varying evidence conditions, from closed-book to noisy evidence integration, enabling separation of internal knowledge from reasoning under imperfect information. For open-ended QA, we propose a human-verified keypoint-based evaluation protocol emphasizing factual completeness over verbosity. Experiments with 20 models reveal substantial divergences from general-purpose leaderboards such as MMLU-Pro. While recent open-weight models approach proprietary systems in clean settings, performance degrades sharply under realistic noise, exposing critical reliability gaps for disaster response. All code, data, and evaluation resources are available at https://github.com/TamuChen18/DisastQA_open.",
      "authors": [
        "Zhitong Chen",
        "Kai Yin",
        "Xiangjue Dong",
        "Chengkai Liu",
        "Xiangpeng Li",
        "Yiming Xiao",
        "Bo Li",
        "Junwei Ma",
        "Ali Mostafavi",
        "James Caverlee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 07:46:42+00:00",
      "link": "https://arxiv.org/pdf/2601.03670v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03668v1",
      "title": "Discontinuous Galerkin finite element operator network for solving non-smooth PDEs",
      "abstract": "We introduce Discontinuous Galerkin Finite Element Operator Network (DG--FEONet), a data-free operator learning framework that combines the strengths of the discontinuous Galerkin (DG) method with neural networks to solve parametric partial differential equations (PDEs) with discontinuous coefficients and non-smooth solutions. Unlike traditional operator learning models such as DeepONet and Fourier Neural Operator, which require large paired datasets and often struggle near sharp features, our approach minimizes the residual of a DG-based weak formulation using the Symmetric Interior Penalty Galerkin (SIPG) scheme. DG-FEONet predicts element-wise solution coefficients via a neural network, enabling data-free training without the need for precomputed input-output pairs. We provide theoretical justification through convergence analysis and validate the model's performance on a series of one- and two-dimensional PDE problems, demonstrating accurate recovery of discontinuities, strong generalization across parameter space, and reliable convergence rates. Our results highlight the potential of combining local discretization schemes with machine learning to achieve robust, singularity-aware operator approximation in challenging PDE settings.",
      "authors": [
        "Kapil Chawla",
        "Youngjoon Hong",
        "Jae Yong Lee",
        "Sanghyun Lee"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 07:43:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03668v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03661v1",
      "title": "AMIR-GRPO: Inducing Implicit Preference Signals into GRPO",
      "abstract": "Reinforcement learning has become the primary paradigm for aligning large language models (LLMs) on complex reasoning tasks, with group relative policy optimization (GRPO) widely used in large-scale post-training. However, GRPO faces structural limitations in reasoning-heavy settings: sequence-level advantage normalization introduces systematic length bias, penalties for low-quality trajectories are diluted, and the scalar objective discards rich pairwise preference information embedded in within-group reward rankings. As a result, valuable supervision from costly rollouts remains underutilized.   We propose AMIR-GRPO, which augments GRPO with an implicit DPO-style contrastive regularizer constructed directly from intra-group reward rankings, requiring no additional annotations. This mechanism amplifies suppression of low-reward trajectories, attenuates response-level length bias, and transforms each rollout group into a denser set of supervision constraints. Across multiple mathematical reasoning benchmarks, AMIR-GRPO consistently outperforms strong GRPO baselines, yields clearer separation between correct and incorrect reasoning chains, and delivers broader coverage gains beyond the subset of instances solved by standard GRPO.",
      "authors": [
        "Amir Hossein Yari",
        "Fajri Koto"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:22:58+00:00",
      "link": "https://arxiv.org/pdf/2601.03661v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03660v1",
      "title": "MGPC: Multimodal Network for Generalizable Point Cloud Completion With Modality Dropout and Progressive Decoding",
      "abstract": "Point cloud completion aims to recover complete 3D geometry from partial observations caused by limited viewpoints and occlusions. Existing learning-based works, including 3D Convolutional Neural Network (CNN)-based, point-based, and Transformer-based methods, have achieved strong performance on synthetic benchmarks. However, due to the limitations of modality, scalability, and generative capacity, their generalization to novel objects and real-world scenarios remains challenging. In this paper, we propose MGPC, a generalizable multimodal point cloud completion framework that integrates point clouds, RGB images, and text within a unified architecture. MGPC introduces an innovative modality dropout strategy, a Transformer-based fusion module, and a novel progressive generator to improve robustness, scalability, and geometric modeling capability. We further develop an automatic data generation pipeline and construct MGPC-1M, a large-scale benchmark with over 1,000 categories and one million training pairs. Extensive experiments on MGPC-1M and in-the-wild data demonstrate that the proposed method consistently outperforms prior baselines and exhibits strong generalization under real-world conditions.",
      "authors": [
        "Jiangyuan Liu",
        "Hongxuan Ma",
        "Yuhao Zhao",
        "Zhe Liu",
        "Jian Wang",
        "Wei Zou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 07:16:46+00:00",
      "link": "https://arxiv.org/pdf/2601.03660v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03655v1",
      "title": "VideoMemory: Toward Consistent Video Generation via Memory Integration",
      "abstract": "Maintaining consistent characters, props, and environments across multiple shots is a central challenge in narrative video generation. Existing models can produce high-quality short clips but often fail to preserve entity identity and appearance when scenes change or when entities reappear after long temporal gaps. We present VideoMemory, an entity-centric framework that integrates narrative planning with visual generation through a Dynamic Memory Bank. Given a structured script, a multi-agent system decomposes the narrative into shots, retrieves entity representations from memory, and synthesizes keyframes and videos conditioned on these retrieved states. The Dynamic Memory Bank stores explicit visual and semantic descriptors for characters, props, and backgrounds, and is updated after each shot to reflect story-driven changes while preserving identity. This retrieval-update mechanism enables consistent portrayal of entities across distant shots and supports coherent long-form generation. To evaluate this setting, we construct a 54-case multi-shot consistency benchmark covering character-, prop-, and background-persistent scenarios. Extensive experiments show that VideoMemory achieves strong entity-level coherence and high perceptual quality across diverse narrative sequences.",
      "authors": [
        "Jinsong Zhou",
        "Yihua Du",
        "Xinli Xu",
        "Luozhou Wang",
        "Zijie Zhuang",
        "Yehang Zhang",
        "Shuaibo Li",
        "Xiaojun Hu",
        "Bolan Su",
        "Ying-cong Chen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 07:10:32+00:00",
      "link": "https://arxiv.org/pdf/2601.03655v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03646v2",
      "title": "ReLA: Representation Learning and Aggregation for Job Scheduling with Reinforcement Learning",
      "abstract": "Job scheduling is widely used in real-world manufacturing systems to assign ordered job operations to machines under various constraints. Existing solutions remain limited by long running time or insufficient schedule quality, especially when problem scale increases. In this paper, we propose ReLA, a reinforcement-learning (RL) scheduler built on structured representation learning and aggregation. ReLA first learns diverse representations from scheduling entities, including job operations and machines, using two intra-entity learning modules with self-attention and convolution and one inter-entity learning module with cross-attention. These modules are applied in a multi-scale architecture, and their outputs are aggregated to support RL decision-making. Across experiments on small, medium, and large job instances, ReLA achieves the best makespan in most tested settings over the latest solutions. On non-large instances, ReLA reduces the optimality gap of the SOTA baseline by 13.0%, while on large-scale instances it reduces the gap by 78.6%, with the average optimality gaps lowered to 7.3% and 2.1%, respectively. These results confirm that ReLA's learned representations and aggregation provide strong decision support for RL scheduling, and enable fast job completion and decision-making for real-world applications.",
      "authors": [
        "Zhengyi Kwan",
        "Wei Zhang",
        "Aik Beng Ng",
        "Zhengkui Wang",
        "Simon See"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 06:50:56+00:00",
      "link": "https://arxiv.org/pdf/2601.03646v2",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03640v1",
      "title": "Verbatim Data Transcription Failures in LLM Code Generation: A State-Tracking Stress Test",
      "abstract": "Many real-world software tasks require exact transcription of provided data into code, such as cryptographic constants, protocol test vectors, allowlists, and calibration tables. These tasks are operationally sensitive because small omissions or alterations can remain silent while producing syntactically valid programs. This paper introduces a deliberately minimal transcription-to-code benchmark to isolate this reliability concern in LLM-based code generation. Given a list of high-precision decimal constants, a model must generate Python code that embeds the constants verbatim and performs a simple aggregate computation. We describe the prompting variants, evaluation protocol based on exact-string inclusion, and analysis framework used to characterize state-tracking and long-horizon generation failures. The benchmark is intended as a compact stress test that complements existing code-generation evaluations by focusing on data integrity rather than algorithmic reasoning.",
      "authors": [
        "Mohd Ariful Haque",
        "Kishor Datta Gupta",
        "Mohammad Ashiqur Rahman",
        "Roy George"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.CR"
      ],
      "published": "2026-01-07 06:38:34+00:00",
      "link": "https://arxiv.org/pdf/2601.03640v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03637v2",
      "title": "CrackSegFlow: Controllable Flow Matching Synthesis for Generalizable Crack Segmentation with a 50K Image-Mask Benchmark",
      "abstract": "Automated crack segmentation is essential for condition assessment, yet deployment is limited by scarce pixel-level labels and domain shift. We present CrackSegFlow, a controllable flow-matching synthesis framework that generates crack images conditioned on binary masks with mask-image alignment. The renderer combines topology-preserving mask injection with edge gating to maintain thin-structure continuity and suppress false positives. A class-conditional flow-matching mask model synthesizes masks with control over crack coverage, enabling balanced, topology-diverse data without manual annotation. We inject masks into crack-free backgrounds to diversify illumination and reduce false positives. On five datasets with a CNN-Transformer backbone, incorporating synthesized pairs improves in-domain performance by 5.37 mIoU and 5.13 F1, and target-guided cross-domain synthesis yields gains of 13.12 mIoU and 14.82 F1 using target mask statistics. We also release CSF-50K, 50,000 image-mask pairs for benchmarking.",
      "authors": [
        "Babak Asadi",
        "Peiyang Wu",
        "Mani Golparvar-Fard",
        "Ramez Hajj"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 06:28:16+00:00",
      "link": "https://arxiv.org/pdf/2601.03637v2",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03633v1",
      "title": "MFC-RFNet: A Multi-scale Guided Rectified Flow Network for Radar Sequence Prediction",
      "abstract": "Accurate and high-resolution precipitation nowcasting from radar echo sequences is crucial for disaster mitigation and economic planning, yet it remains a significant challenge. Key difficulties include modeling complex multi-scale evolution, correcting inter-frame feature misalignment caused by displacement, and efficiently capturing long-range spatiotemporal context without sacrificing spatial fidelity. To address these issues, we present the Multi-scale Feature Communication Rectified Flow (RF) Network (MFC-RFNet), a generative framework that integrates multi-scale communication with guided feature fusion. To enhance multi-scale fusion while retaining fine detail, a Wavelet-Guided Skip Connection (WGSC) preserves high-frequency components, and a Feature Communication Module (FCM) promotes bidirectional cross-scale interaction. To correct inter-frame displacement, a Condition-Guided Spatial Transform Fusion (CGSTF) learns spatial transforms from conditioning echoes to align shallow features. The backbone adopts rectified flow training to learn near-linear probability-flow trajectories, enabling few-step sampling with stable fidelity. Additionally, lightweight Vision-RWKV (RWKV) blocks are placed at the encoder tail, the bottleneck, and the first decoder layer to capture long-range spatiotemporal dependencies at low spatial resolutions with moderate compute. Evaluations on four public datasets (SEVIR, MeteoNet, Shanghai, and CIKM) demonstrate consistent improvements over strong baselines, yielding clearer echo morphology at higher rain-rate thresholds and sustained skill at longer lead times. These results suggest that the proposed synergy of RF training with scale-aware communication, spatial alignment, and frequency-aware fusion presents an effective and robust approach for radar-based nowcasting.",
      "authors": [
        "Wenjie Luo",
        "Chuanhu Deng",
        "Chaorong Li",
        "Rongyao Deng",
        "Qiang Yang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 06:24:26+00:00",
      "link": "https://arxiv.org/pdf/2601.03633v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03627v2",
      "title": "Evaluating the Pre-Consultation Ability of LLMs using Diagnostic Guidelines",
      "abstract": "We introduce EPAG, a benchmark dataset and framework designed for Evaluating the Pre-consultation Ability of LLMs using diagnostic Guidelines. LLMs are evaluated directly through HPI-diagnostic guideline comparison and indirectly through disease diagnosis. In our experiments, we observe that small open-source models fine-tuned with a well-curated, task-specific dataset can outperform frontier LLMs in pre-consultation. Additionally, we find that increased amount of HPI (History of Present Illness) does not necessarily lead to improved diagnostic performance. Further experiments reveal that the language of pre-consultation influences the characteristics of the dialogue. By open-sourcing our dataset and evaluation pipeline on https://github.com/seemdog/EPAG, we aim to contribute to the evaluation and further development of LLM applications in real-world clinical settings.",
      "authors": [
        "Jean Seo",
        "Gibaeg Kim",
        "Kihun Shin",
        "Seungseop Lim",
        "Hyunkyung Lee",
        "Wooseok Han",
        "Jongwon Lee",
        "Eunho Yang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 06:15:21+00:00",
      "link": "https://arxiv.org/pdf/2601.03627v2",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03626v1",
      "title": "Learning from Limited Labels: Transductive Graph Label Propagation for Indian Music Analysis",
      "abstract": "Supervised machine learning frameworks rely on extensive labeled datasets for robust performance on real-world tasks. However, there is a lack of large annotated datasets in audio and music domains, as annotating such recordings is resource-intensive, laborious, and often require expert domain knowledge. In this work, we explore the use of label propagation (LP), a graph-based semi-supervised learning technique, for automatically labeling the unlabeled set in an unsupervised manner. By constructing a similarity graph over audio embeddings, we propagate limited label information from a small annotated subset to a larger unlabeled corpus in a transductive, semi-supervised setting. We apply this method to two tasks in Indian Art Music (IAM): Raga identification and Instrument classification. For both these tasks, we integrate multiple public datasets along with additional recordings we acquire from Prasar Bharati Archives to perform LP. Our experiments demonstrate that LP significantly reduces labeling overhead and produces higher-quality annotations compared to conventional baseline methods, including those based on pretrained inductive models. These results highlight the potential of graph-based semi-supervised learning to democratize data annotation and accelerate progress in music information retrieval.",
      "authors": [
        "Parampreet Singh",
        "Akshay Raina",
        "Sayeedul Islam Sheikh",
        "Vipul Arora"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.LG"
      ],
      "published": "2026-01-07 06:12:48+00:00",
      "link": "https://arxiv.org/pdf/2601.03626v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04262v1",
      "title": "Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis",
      "abstract": "Safety alignment in Large Language Models (LLMs) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geometry to resolve these conflicts, yet they overlook Modular Heterogeneity within Transformers, specifically that the functional sensitivity and degree of conflict vary substantially across different attention heads. Such global approaches impose uniform update rules across all parameters, often resulting in suboptimal trade-offs by indiscriminately updating utility sensitive heads that exhibit intense gradient conflicts. To address this limitation, we propose Conflict-Aware Sparse Tuning (CAST), a framework that integrates head-level diagnosis with sparse fine-tuning. CAST first constructs a pre-alignment conflict map by synthesizing Optimization Conflict and Functional Sensitivity, which then guides the selective update of parameters. Experiments reveal that alignment conflicts in LLMs are not uniformly distributed. We find that the drop in general capabilities mainly comes from updating a small group of ``high-conflict'' heads. By simply skipping these heads during training, we significantly reduce this loss without compromising safety, offering an interpretable and parameter-efficient approach to improving the safety-utility trade-off.",
      "authors": [
        "Wang Cai",
        "Yilin Wen",
        "Jinchang Hou",
        "Du Su",
        "Guoqiu Wang",
        "Zhonghou Lv",
        "Chenfu Bao",
        "Yunfang Wu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 06:09:52+00:00",
      "link": "https://arxiv.org/pdf/2601.04262v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03612v1",
      "title": "Mathematical Foundations of Polyphonic Music Generation via Structural Inductive Bias",
      "abstract": "This monograph introduces a novel approach to polyphonic music generation by addressing the \"Missing Middle\" problem through structural inductive bias. Focusing on Beethoven's piano sonatas as a case study, we empirically verify the independence of pitch and hand attributes using normalized mutual information (NMI=0.167) and propose the Smart Embedding architecture, achieving a 48.30% reduction in parameters. We provide rigorous mathematical proofs using information theory (negligible loss bounded at 0.153 bits), Rademacher complexity (28.09% tighter generalization bound), and category theory to demonstrate improved stability and generalization. Empirical results show a 9.47% reduction in validation loss, confirmed by SVD analysis and an expert listening study (N=53). This dual theoretical and applied framework bridges gaps in AI music generation, offering verifiable insights for mathematically grounded deep learning.",
      "authors": [
        "Joonwon Seo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "published": "2026-01-07 05:40:09+00:00",
      "link": "https://arxiv.org/pdf/2601.03612v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03610v1",
      "title": "Investigation into respiratory sound classification for an imbalanced data set using hybrid LSTM-KAN architectures",
      "abstract": "Respiratory sounds captured via auscultation contain critical clues for diagnosing pulmonary conditions. Automated classification of these sounds faces challenges due to subtle acoustic differences and severe class imbalance in clinical datasets. This study investigates respiratory sound classification with a focus on mitigating pronounced class imbalance. We propose a hybrid deep learning model that combines a Long Short-Term Memory (LSTM) network for sequential feature encoding with a Kolmogorov-Arnold Network (KAN) for classification. The model is integrated with a comprehensive feature extraction pipeline and targeted imbalance mitigation strategies. Experiments were conducted on a public respiratory sound database comprising six classes with a highly skewed distribution. Techniques such as focal loss, class-specific data augmentation, and Synthetic Minority Over-sampling Technique (SMOTE) were employed to enhance minority class recognition. The proposed Hybrid LSTM-KAN model achieves an overall accuracy of 94.6 percent and a macro-averaged F1 score of 0.703, despite the dominant COPD class accounting for over 86 percent of the data. Improved detection performance is observed for minority classes compared to baseline approaches, demonstrating the effectiveness of the proposed architecture for imbalanced respiratory sound classification.",
      "authors": [
        "Nithinkumar K.",
        "Anand R"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "published": "2026-01-07 05:37:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03610v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03607v1",
      "title": "Locomotion Beyond Feet",
      "abstract": "Most locomotion methods for humanoid robots focus on leg-based gaits, yet natural bipeds frequently rely on hands, knees, and elbows to establish additional contacts for stability and support in complex environments. This paper introduces Locomotion Beyond Feet, a comprehensive system for whole-body humanoid locomotion across extremely challenging terrains, including low-clearance spaces under chairs, knee-high walls, knee-high platforms, and steep ascending and descending stairs. Our approach addresses two key challenges: contact-rich motion planning and generalization across diverse terrains. To this end, we combine physics-grounded keyframe animation with reinforcement learning. Keyframes encode human knowledge of motor skills, are embodiment-specific, and can be readily validated in simulation or on hardware, while reinforcement learning transforms these references into robust, physically accurate motions. We further employ a hierarchical framework consisting of terrain-specific motion-tracking policies, failure recovery mechanisms, and a vision-based skill planner. Real-world experiments demonstrate that Locomotion Beyond Feet achieves robust whole-body locomotion and generalizes across obstacle sizes, obstacle instances, and terrain sequences.",
      "authors": [
        "Tae Hoon Yang",
        "Haochen Shi",
        "Jiacheng Hu",
        "Zhicong Zhang",
        "Daniel Jiang",
        "Weizhuo Wang",
        "Yao He",
        "Zhen Wu",
        "Yuming Chen",
        "Yifan Hou",
        "Monroe Kennedy",
        "Shuran Song",
        "C. Karen Liu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-07 05:36:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03607v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03605v1",
      "title": "DiVA: Fine-grained Factuality Verification with Agentic-Discriminative Verifier",
      "abstract": "Despite the significant advancements of Large Language Models (LLMs), their factuality remains a critical challenge, fueling growing interest in factuality verification. Existing research on factuality verification primarily conducts binary judgments (e.g., correct or incorrect), which fails to distinguish varying degrees of error severity. This limits its utility for applications such as fine-grained evaluation and preference optimization. To bridge this gap, we propose the Agentic Discriminative Verifier (DiVA), a hybrid framework that synergizes the agentic search capabilities of generative models with the precise scoring aptitude of discriminative models. We also construct a new benchmark, FGVeriBench, as a robust testbed for fine-grained factuality verification. Experimental results on FGVeriBench demonstrate that our DiVA significantly outperforms existing methods on factuality verification for both general and multi-hop questions.",
      "authors": [
        "Hui Huang",
        "Muyun Yang",
        "Yuki Arase"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 05:35:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03605v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03604v1",
      "title": "Interleaved Tool-Call Reasoning for Protein Function Understanding",
      "abstract": "Recent advances in large language models (LLMs) have highlighted the effectiveness of chain-of-thought reasoning in symbolic domains such as mathematics and programming. However, our study shows that directly transferring such text-based reasoning paradigms to protein function understanding is ineffective: reinforcement learning mainly amplifies superficial keyword patterns while failing to introduce new biological knowledge, resulting in limited generalization. We argue that protein function prediction is a knowledge-intensive scientific task that fundamentally relies on external biological priors and computational tools rather than purely internal reasoning. To address this gap, we propose PFUA, a tool-augmented protein reasoning agent that unifies problem decomposition, tool invocation, and grounded answer generation. Instead of relying on long unconstrained reasoning traces, PFUA integrates domain-specific tools to produce verifiable intermediate evidence. Experiments on four benchmarks demonstrate that PFUA consistently outperforms text-only reasoning models with an average performance improvement of 103%.",
      "authors": [
        "Chuanliu Fan",
        "Zicheng Ma",
        "Huanran Meng",
        "Aijia Zhang",
        "Wenjie Du",
        "Jun Zhang",
        "Yi Qin Gao",
        "Ziqiang Cao",
        "Guohong Fu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 05:34:38+00:00",
      "link": "https://arxiv.org/pdf/2601.03604v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03603v1",
      "title": "A Comparative Study of Traditional Machine Learning, Deep Learning, and Large Language Models for Mental Health Forecasting using Smartphone Sensing Data",
      "abstract": "Smartphone sensing offers an unobtrusive and scalable way to track daily behaviors linked to mental health, capturing changes in sleep, mobility, and phone use that often precede symptoms of stress, anxiety, or depression. While most prior studies focus on detection that responds to existing conditions, forecasting mental health enables proactive support through Just-in-Time Adaptive Interventions. In this paper, we present the first comprehensive benchmarking study comparing traditional machine learning (ML), deep learning (DL), and large language model (LLM) approaches for mental health forecasting using the College Experience Sensing (CES) dataset, the most extensive longitudinal dataset of college student mental health to date. We systematically evaluate models across temporal windows, feature granularities, personalization strategies, and class imbalance handling. Our results show that DL models, particularly Transformer (Macro-F1 = 0.58), achieve the best overall performance, while LLMs show strength in contextual reasoning but weaker temporal modeling. Personalization substantially improves forecasts of severe mental health states. By revealing how different modeling approaches interpret phone sensing behavioral data over time, this work lays the groundwork for next-generation, adaptive, and human-centered mental health technologies that can advance both research and real-world well-being.",
      "authors": [
        "Kaidong Feng",
        "Zhu Sun",
        "Roy Ka-Wei Lee",
        "Xun Jiang",
        "Yin-Leng Theng",
        "Yi Ding"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 05:33:00+00:00",
      "link": "https://arxiv.org/pdf/2601.03603v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03594v1",
      "title": "Jailbreaking LLMs & VLMs: Mechanisms, Evaluation, and Unified Defense",
      "abstract": "This paper provides a systematic survey of jailbreak attacks and defenses on Large Language Models (LLMs) and Vision-Language Models (VLMs), emphasizing that jailbreak vulnerabilities stem from structural factors such as incomplete training data, linguistic ambiguity, and generative uncertainty. It further differentiates between hallucinations and jailbreaks in terms of intent and triggering mechanisms. We propose a three-dimensional survey framework: (1) Attack dimension-including template/encoding-based, in-context learning manipulation, reinforcement/adversarial learning, LLM-assisted and fine-tuned attacks, as well as prompt- and image-level perturbations and agent-based transfer in VLMs; (2) Defense dimension-encompassing prompt-level obfuscation, output evaluation, and model-level alignment or fine-tuning; and (3) Evaluation dimension-covering metrics such as Attack Success Rate (ASR), toxicity score, query/time cost, and multimodal Clean Accuracy and Attribute Success Rate. Compared with prior works, this survey spans the full spectrum from text-only to multimodal settings, consolidating shared mechanisms and proposing unified defense principles: variant-consistency and gradient-sensitivity detection at the perception layer, safety-aware decoding and output review at the generation layer, and adversarially augmented preference alignment at the parameter layer. Additionally, we summarize existing multimodal safety benchmarks and discuss future directions, including automated red teaming, cross-modal collaborative defense, and standardized evaluation.",
      "authors": [
        "Zejian Chen",
        "Chaozhuo Li",
        "Chao Li",
        "Xi Zhang",
        "Litian Zhang",
        "Yiming He"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-07 05:25:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03594v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03590v1",
      "title": "Can LLMs See Without Pixels? Benchmarking Spatial Intelligence from Textual Descriptions",
      "abstract": "Recent advancements in Spatial Intelligence (SI) have predominantly relied on Vision-Language Models (VLMs), yet a critical question remains: does spatial understanding originate from visual encoders or the fundamental reasoning backbone? Inspired by this question, we introduce SiT-Bench, a novel benchmark designed to evaluate the SI performance of Large Language Models (LLMs) without pixel-level input, comprises over 3,800 expert-annotated items across five primary categories and 17 subtasks, ranging from egocentric navigation and perspective transformation to fine-grained robotic manipulation. By converting single/multi-view scenes into high-fidelity, coordinate-aware textual descriptions, we challenge LLMs to perform symbolic textual reasoning rather than visual pattern matching. Evaluation results of state-of-the-art (SOTA) LLMs reveals that while models achieve proficiency in localized semantic tasks, a significant \"spatial gap\" remains in global consistency. Notably, we find that explicit spatial reasoning significantly boosts performance, suggesting that LLMs possess latent world-modeling potential. Our proposed dataset SiT-Bench serves as a foundational resource to foster the development of spatially-grounded LLM backbones for future VLMs and embodied agents. Our code and benchmark will be released at https://github.com/binisalegend/SiT-Bench .",
      "authors": [
        "Zhongbin Guo",
        "Zhen Yang",
        "Yushan Li",
        "Xinyue Zhang",
        "Wenyu Gao",
        "Jiacheng Wang",
        "Chengzhi Li",
        "Xiangrui Liu",
        "Ping Jian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 05:13:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03590v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03584v1",
      "title": "Local Gradient Regulation Stabilizes Federated Learning under Client Heterogeneity",
      "abstract": "Federated learning (FL) enables collaborative model training across distributed clients without sharing raw data, yet its stability is fundamentally challenged by statistical heterogeneity in realistic deployments. Here, we show that client heterogeneity destabilizes FL primarily by distorting local gradient dynamics during client-side optimization, causing systematic drift that accumulates across communication rounds and impedes global convergence. This observation highlights local gradients as a key regulatory lever for stabilizing heterogeneous FL systems. Building on this insight, we develop a general client-side perspective that regulates local gradient contributions without incurring additional communication overhead. Inspired by swarm intelligence, we instantiate this perspective through Exploratory--Convergent Gradient Re-aggregation (ECGR), which balances well-aligned and misaligned gradient components to preserve informative updates while suppressing destabilizing effects. Theoretical analysis and extensive experiments, including evaluations on the LC25000 medical imaging dataset, demonstrate that regulating local gradient dynamics consistently stabilizes federated learning across state-of-the-art methods under heterogeneous data distributions.",
      "authors": [
        "Ping Luo",
        "Jiahuan Wang",
        "Ziqing Wen",
        "Tao Sun",
        "Dongsheng Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.DC"
      ],
      "published": "2026-01-07 04:58:18+00:00",
      "link": "https://arxiv.org/pdf/2601.03584v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03578v1",
      "title": "PsychEthicsBench: Evaluating Large Language Models Against Australian Mental Health Ethics",
      "abstract": "The increasing integration of large language models (LLMs) into mental health applications necessitates robust frameworks for evaluating professional safety alignment. Current evaluative approaches primarily rely on refusal-based safety signals, which offer limited insight into the nuanced behaviors required in clinical practice. In mental health, clinically inadequate refusals can be perceived as unempathetic and discourage help-seeking. To address this gap, we move beyond refusal-centric metrics and introduce \\texttt{PsychEthicsBench}, the first principle-grounded benchmark based on Australian psychology and psychiatry guidelines, designed to evaluate LLMs' ethical knowledge and behavioral responses through multiple-choice and open-ended tasks with fine-grained ethicality annotations. Empirical results across 14 models reveal that refusal rates are poor indicators of ethical behavior, revealing a significant divergence between safety triggers and clinical appropriateness. Notably, we find that domain-specific fine-tuning can degrade ethical robustness, as several specialized models underperform their base backbones in ethical alignment. PsychEthicsBench provides a foundation for systematic, jurisdiction-aware evaluation of LLMs in mental health, encouraging more responsible development in this domain.",
      "authors": [
        "Yaling Shen",
        "Stephanie Fong",
        "Yiwen Jiang",
        "Zimu Wang",
        "Feilong Tang",
        "Qingyang Xu",
        "Xiangyu Zhao",
        "Zhongxing Xu",
        "Jiahe Liu",
        "Jinpeng Hu",
        "Dominic Dwyer",
        "Zongyuan Ge"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 04:49:02+00:00",
      "link": "https://arxiv.org/pdf/2601.03578v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03570v1",
      "title": "How Do Large Language Models Learn Concepts During Continual Pre-Training?",
      "abstract": "Human beings primarily understand the world through concepts (e.g., dog), abstract mental representations that structure perception, reasoning, and learning. However, how large language models (LLMs) acquire, retain, and forget such concepts during continual pretraining remains poorly understood. In this work, we study how individual concepts are acquired and forgotten, as well as how multiple concepts interact through interference and synergy. We link these behavioral dynamics to LLMs' internal Concept Circuits, computational subgraphs associated with specific concepts, and incorporate Graph Metrics to characterize circuit structure. Our analysis reveals: (1) LLMs concept circuits provide a non-trivial, statistically significant signal of concept learning and forgetting; (2) Concept circuits exhibit a stage-wise temporal pattern during continual pretraining, with an early increase followed by gradual decrease and stabilization; (3) concepts with larger learning gains tend to exhibit greater forgetting under subsequent training; (4) semantically similar concepts induce stronger interference than weakly related ones; (5) conceptual knowledge differs in their transferability, with some significantly facilitating the learning of others. Together, our findings offer a circuit-level view of concept learning dynamics and inform the design of more interpretable and robust concept-aware training strategies for LLMs.",
      "authors": [
        "Barry Menglong Yao",
        "Sha Li",
        "Yunzhi Yao",
        "Minqian Liu",
        "Zaishuo Xia",
        "Qifan Wang",
        "Lifu Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 04:29:15+00:00",
      "link": "https://arxiv.org/pdf/2601.03570v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03569v1",
      "title": "Local Intrinsic Dimensionality of Ground Motion Data for Early Detection of Complex Catastrophic Slope Failure",
      "abstract": "Local Intrinsic Dimensionality (LID) has shown strong potential for identifying anomalies and outliers in high-dimensional data across a wide range of real-world applications, including landslide failure detection in granular media. Early and accurate identification of failure zones in landslide-prone areas is crucial for effective geohazard mitigation. While existing approaches typically rely on surface displacement data analyzed through statistical or machine learning techniques, they often fall short in capturing both the spatial correlations and temporal dynamics that are inherent in such data. To address this gap, we focus on ground-monitored landslides and introduce a novel approach that jointly incorporates spatial and temporal information, enabling the detection of complex landslides and including multiple successive failures occurring in distinct areas of the same slope. To be specific, our method builds upon an existing LID-based technique, known as sLID. We extend its capabilities in three key ways. (1) Kinematic enhancement: we incorporate velocity into the sLID computation to better capture short-term temporal dependencies and deformation rate relationships. (2) Spatial fusion: we apply Bayesian estimation to aggregate sLID values across spatial neighborhoods, effectively embedding spatial correlations into the LID scores. (3) Temporal modeling: we introduce a temporal variant, tLID, that learns long-term dynamics from time series data, providing a robust temporal representation of displacement behavior. Finally, we integrate both components into a unified framework, referred to as spatiotemporal LID (stLID), to identify samples that are anomalous in either or both dimensions. Extensive experiments show that stLID consistently outperforms existing methods in failure detection precision and lead-time.",
      "authors": [
        "Yuansan Liu",
        "Antoinette Tordesillas",
        "James Bailey"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.AP"
      ],
      "published": "2026-01-07 04:29:05+00:00",
      "link": "https://arxiv.org/pdf/2601.03569v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03566v1",
      "title": "Provably Convergent Decentralized Optimization over Directed Graphs under Generalized Smoothness",
      "abstract": "Decentralized optimization has become a fundamental tool for large-scale learning systems; however, most existing methods rely on the classical Lipschitz smoothness assumption, which is often violated in problems with rapidly varying gradients. Motivated by this limitation, we study decentralized optimization under the generalized $(L_0, L_1)$-smoothness framework, in which the Hessian norm is allowed to grow linearly with the gradient norm, thereby accommodating rapidly varying gradients beyond classical Lipschitz smoothness. We integrate gradient-tracking techniques with gradient clipping and carefully design the clipping threshold to ensure accurate convergence over directed communication graphs under generalized smoothness. In contrast to existing distributed optimization results under generalized smoothness that require a bounded gradient dissimilarity assumption, our results remain valid even when the gradient dissimilarity is unbounded, making the proposed framework more applicable to realistic heterogeneous data environments. We validate our approach via numerical experiments on standard benchmark datasets, including LIBSVM and CIFAR-10, using regularized logistic regression and convolutional neural networks, demonstrating superior stability and faster convergence over existing methods.",
      "authors": [
        "Yanan Bo",
        "Yongqiang Wang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-01-07 04:25:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03566v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03550v1",
      "title": "ReEfBench: Quantifying the Reasoning Efficiency of LLMs",
      "abstract": "Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework for the non-intrusive, comprehensive process-centric evaluation of reasoning. (2) Through this lens, we identify four distinct behavioral prototypes and diagnose the failure modes. (3) We examine the impact of inference mode, training strategy, and model scale. Our analysis reveals that extended token generation is not a prerequisite for deep reasoning. Furthermore, we reveal critical constraints: mixing long and short CoT data in training risks in premature saturation and collapse, while distillation into smaller models captures behavioral length but fails to replicate logical efficacy due to intrinsic capacity limits.",
      "authors": [
        "Zhizhang Fu",
        "Yuancheng Gu",
        "Chenkai Hu",
        "Hanmeng Liu",
        "Yue Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 03:33:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03550v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03543v1",
      "title": "EvolMem: A Cognitive-Driven Benchmark for Multi-Session Dialogue Memory",
      "abstract": "Despite recent advances in understanding and leveraging long-range conversational memory, existing benchmarks still lack systematic evaluation of large language models(LLMs) across diverse memory dimensions, particularly in multi-session settings. In this work, we propose EvolMem, a new benchmark for assessing multi-session memory capabilities of LLMs and agent systems. EvolMem is grounded in cognitive psychology and encompasses both declarative and non-declarative memory, further decomposed into multiple fine-grained abilities. To construct the benchmark, we introduce a hybrid data synthesis framework that consists of topic-initiated generation and narrative-inspired transformations. This framework enables scalable generation of multi-session conversations with controllable complexity, accompanied by sample-specific evaluation guidelines. Extensive evaluation reveals that no LLM consistently outperforms others across all memory dimensions. Moreover, agent memory mechanisms do not necessarily enhance LLMs' capabilities and often exhibit notable efficiency limitations. Data and code will be released at https://github.com/shenye7436/EvolMem.",
      "authors": [
        "Ye Shen",
        "Dun Pei",
        "Yiqiu Guo",
        "Junying Wang",
        "Yijin Guo",
        "Zicheng Zhang",
        "Qi Jia",
        "Jun Zhou",
        "Guangtao Zhai"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 03:14:42+00:00",
      "link": "https://arxiv.org/pdf/2601.03543v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03540v1",
      "title": "DeepSynth-Eval: Objectively Evaluating Information Consolidation in Deep Survey Writing",
      "abstract": "The evolution of Large Language Models (LLMs) towards autonomous agents has catalyzed progress in Deep Research. While retrieval capabilities are well-benchmarked, the post-retrieval synthesis stage--where agents must digest massive amounts of context and consolidate fragmented evidence into coherent, long-form reports--remains under-evaluated due to the subjectivity of open-ended writing. To bridge this gap, we introduce DeepSynth-Eval, a benchmark designed to objectively evaluate information consolidation capabilities. We leverage high-quality survey papers as gold standards, reverse-engineering research requests and constructing \"Oracle Contexts\" from their bibliographies to isolate synthesis from retrieval noise. We propose a fine-grained evaluation protocol using General Checklists (for factual coverage) and Constraint Checklists (for structural organization), transforming subjective judgment into verifiable metrics. Experiments across 96 tasks reveal that synthesizing information from hundreds of references remains a significant challenge. Our results demonstrate that agentic plan-and-write workflows significantly outperform single-turn generation, effectively reducing hallucinations and improving adherence to complex structural constraints.",
      "authors": [
        "Hongzhi Zhang",
        "Yuanze Hu",
        "Tinghai Zhang",
        "Jia Fu",
        "Tao Wang",
        "Junwei Jing",
        "Zhaoxin Fan",
        "Qi Wang",
        "Ruiming Tang",
        "Han Li",
        "Guorui Zhou",
        "Kun Gai"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 03:07:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03540v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03531v1",
      "title": "PALM-Bench: A Comprehensive Benchmark for Personalized Audio-Language Models",
      "abstract": "Large Audio-Language Models (LALMs) have demonstrated strong performance in audio understanding and generation. Yet, our extensive benchmarking reveals that their behavior is largely generic (e.g., summarizing spoken content) and fails to adequately support personalized question answering (e.g., summarizing what my best friend says). In contrast, human conditions their interpretation and decision-making on each individual's personal context. To bridge this gap, we formalize the task of Personalized LALMs (PALM) for recognizing personal concepts and reasoning within personal context. Moreover, we create the first benchmark (PALM-Bench) to foster the methodological advances in PALM and enable structured evaluation on several tasks across multi-speaker scenarios. Our extensive experiments on representative open-source LALMs, show that existing training-free prompting and supervised fine-tuning strategies, while yield improvements, remains limited in modeling personalized knowledge and transferring them across tasks robustly. Data and code will be released.",
      "authors": [
        "Yuwen Wang",
        "Xinyuan Qian",
        "Tian-Hao Zhang",
        "Jiaran Gao",
        "Yuchen Pan",
        "Xin Wang",
        "Zhou Pan",
        "Chen Wei",
        "Yiming Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 02:44:38+00:00",
      "link": "https://arxiv.org/pdf/2601.03531v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03525v1",
      "title": "VeRPO: Verifiable Dense Reward Policy Optimization for Code Generation",
      "abstract": "Effective reward design is a central challenge in Reinforcement Learning (RL) for code generation. Mainstream pass/fail outcome rewards enforce functional correctness via executing unit tests, but the resulting sparsity limits potential performance gains. While recent work has explored external Reward Models (RM) to generate richer, continuous rewards, the learned RMs suffer from reward misalignment and prohibitive computational cost. In this paper, we introduce \\textbf{VeRPO} (\\textbf{V}erifiable D\\textbf{e}nse \\textbf{R}eward \\textbf{P}olicy \\textbf{O}ptimization), a novel RL framework for code generation that synthesizes \\textit{robust and dense rewards fully grounded in verifiable execution feedback}. The core idea of VeRPO is constructing dense rewards from weighted partial success: by dynamically estimating the difficulty weight of each unit test based on the execution statistics during training, a dense reward is derived from the sum of weights of the passed unit tests. To solidify the consistency between partial success and end-to-end functional correctness, VeRPO further integrates the dense signal with global execution outcomes, establishing a robust and dense reward paradigm relying solely on verifiable execution feedback. Extensive experiments across diverse benchmarks and settings demonstrate that VeRPO consistently outperforms outcome-driven and RM-based baselines, achieving up to +8.83\\% gain in pass@1 with negligible time cost (< 0.02\\%) and zero GPU memory overhead.",
      "authors": [
        "Longwen Wang",
        "Xuan'er Wu",
        "Xiaohui Hu",
        "Yirui Liu",
        "Yuankai Fan",
        "Kaidong Yu",
        "Qizhen Weng",
        "Wei Xi",
        "Xuelong Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 02:29:49+00:00",
      "link": "https://arxiv.org/pdf/2601.03525v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03520v1",
      "title": "A Reinforcement Learning-Based Model for Mapping and Goal-Directed Navigation Using Multiscale Place Fields",
      "abstract": "Autonomous navigation in complex and partially observable environments remains a central challenge in robotics. Several bio-inspired models of mapping and navigation based on place cells in the mammalian hippocampus have been proposed. This paper introduces a new robust model that employs parallel layers of place fields at multiple spatial scales, a replay-based reward mechanism, and dynamic scale fusion. Simulations show that the model improves path efficiency and accelerates learning compared to single-scale baselines, highlighting the value of multiscale spatial representations for adaptive robot navigation.",
      "authors": [
        "Bekarys Dukenbaev",
        "Andrew Gerstenslager",
        "Alexander Johnson",
        "Ali A. Minai"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-07 02:10:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03520v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04259v1",
      "title": "IGA-LWP: An Iterative Gradient-based Adversarial Attack for Link Weight Prediction",
      "abstract": "Link weight prediction extends classical link prediction by estimating the strength of interactions rather than merely their existence, and it underpins a wide range of applications such as traffic engineering, social recommendation, and scientific collaboration analysis. However, the robustness of link weight prediction against adversarial perturbations remains largely unexplored.In this paper, we formalize the link weight prediction attack problem as an optimization task that aims to maximize the prediction error on a set of target links by adversarially manipulating the weight values of a limited number of links. Based on this formulation, we propose an iterative gradient-based attack framework for link weight prediction, termed IGA-LWP. By employing a self-attention-enhanced graph autoencoder as a surrogate predictor, IGA-LWP leverages backpropagated gradients to iteratively identify and perturb a small subset of links. Extensive experiments on four real-world weighted networks demonstrate that IGA-LWP significantly degrades prediction accuracy on target links compared with baseline methods. Moreover, the adversarial networks generated by IGA-LWP exhibit strong transferability across several representative link weight prediction models. These findings expose a fundamental vulnerability in weighted network inference and highlight the need for developing robust link weight prediction methods.",
      "authors": [
        "Cunlai Pu",
        "Xingyu Gao",
        "Jinbi Liang",
        "Jianhui Guo",
        "Xiangbo Shu",
        "Yongxiang Xia",
        "Rajput Ramiz Sharafat"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI"
      ],
      "published": "2026-01-07 02:09:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04259v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03517v1",
      "title": "Semantic Belief-State World Model for 3D Human Motion Prediction",
      "abstract": "Human motion prediction has traditionally been framed as a sequence regression problem where models extrapolate future joint coordinates from observed pose histories. While effective over short horizons this approach does not separate observation reconstruction with dynamics modeling and offers no explicit representation of the latent causes governing motion. As a result, existing methods exhibit compounding drift, mean-pose collapse, and poorly calibrated uncertainty when rolled forward beyond the training regime. Here we propose a Semantic Belief-State World Model (SBWM) that reframes human motion prediction as latent dynamical simulation on the human body manifold. Rather than predicting poses directly, SBWM maintains a recurrent probabilistic belief state whose evolution is learned independently of pose reconstruction and explicitly aligned with the SMPL-X anatomical parameterization. This alignment imposes a structural information bottleneck that prevents the latent state from encoding static geometry or sensor noise, forcing it to capture motion dynamics, intent, and control-relevant structure. Inspired by belief-state world models developed for model-based reinforcement learning, SBWM adapts stochastic latent transitions and rollout-centric training to the domain of human motion. In contrast to RSSM-based, transformer, and diffusion approaches optimized for reconstruction fidelity, SBWM prioritizes stable forward simulation. We demonstrate coherent long-horizon rollouts, and competitive accuracy at substantially lower computational cost. These results suggest that treating the human body as part of the world models state space rather than its output fundamentally changes how motion is simulated, and predicted.",
      "authors": [
        "Sarim Chaudhry"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 02:06:26+00:00",
      "link": "https://arxiv.org/pdf/2601.03517v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03515v1",
      "title": "Mem-Gallery: Benchmarking Multimodal Long-Term Conversational Memory for MLLM Agents",
      "abstract": "Long-term memory is a critical capability for multimodal large language model (MLLM) agents, particularly in conversational settings where information accumulates and evolves over time. However, existing benchmarks either evaluate multi-session memory in text-only conversations or assess multimodal understanding within localized contexts, failing to evaluate how multimodal memory is preserved, organized, and evolved across long-term conversational trajectories. Thus, we introduce Mem-Gallery, a new benchmark for evaluating multimodal long-term conversational memory in MLLM agents. Mem-Gallery features high-quality multi-session conversations grounded in both visual and textual information, with long interaction horizons and rich multimodal dependencies. Building on this dataset, we propose a systematic evaluation framework that assesses key memory capabilities along three functional dimensions: memory extraction and test-time adaptation, memory reasoning, and memory knowledge management. Extensive benchmarking across thirteen memory systems reveals several key findings, highlighting the necessity of explicit multimodal information retention and memory organization, the persistent limitations in memory reasoning and knowledge management, as well as the efficiency bottleneck of current models.",
      "authors": [
        "Yuanchen Bei",
        "Tianxin Wei",
        "Xuying Ning",
        "Yanjun Zhao",
        "Zhining Liu",
        "Xiao Lin",
        "Yada Zhu",
        "Hendrik Hamann",
        "Jingrui He",
        "Hanghang Tong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 02:03:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03515v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03509v1",
      "title": "Evolving Programmatic Skill Networks",
      "abstract": "We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\\footnote{We plan to open-source the code.",
      "authors": [
        "Haochen Shi",
        "Xingdi Yuan",
        "Bang Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "published": "2026-01-07 01:43:25+00:00",
      "link": "https://arxiv.org/pdf/2601.03509v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03505v1",
      "title": "Beyond Perplexity: A Lightweight Benchmark for Knowledge Retention in Supervised Fine-Tuning",
      "abstract": "Supervised Fine-Tuning (SFT) is a standard approach for injecting domain knowledge into Large Language Models (LLMs). However, relying on validation perplexity to monitor training is often insufficient, as it confounds stylistic mimicry with genuine factual internalization. To address this, we introduce the Knowledge Retention (KR) Test , a lightweight, corpus-grounded evaluation framework designed to distinguish factual learning from linguistics. KR-Test utilizes automatically generated contrastive examples to measure likelihood preferences for correct versus incorrect continuations, requiring no instruction tuning or generative decoding. We validate the framework's integrity through a \"blind vs. oracle\" baseline analysis. Furthermore, we demonstrate the diagnostic capabilities of KR-Test by analyzing the training dynamics of Low-Rank Adaptation (LoRA). By exposing the fine-grained dissociation between linguistic convergence and knowledge retention, KR-Test enhances the interpretability of fine-tuning dynamics.",
      "authors": [
        "Soheil Zibakhsh Shabgahi",
        "Pedram Aghazadeh",
        "Farinaz Koushanfar"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 01:34:28+00:00",
      "link": "https://arxiv.org/pdf/2601.03505v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03496v1",
      "title": "STELLA: Self-Reflective Terminology-Aware Framework for Building an Aerospace Information Retrieval Benchmark",
      "abstract": "Tasks in the aerospace industry heavily rely on searching and reusing large volumes of technical documents, yet there is no public information retrieval (IR) benchmark that reflects the terminology- and query-intent characteristics of this domain. To address this gap, this paper proposes the STELLA (Self-Reflective TErminoLogy-Aware Framework for BuiLding an Aerospace Information Retrieval Benchmark) framework. Using this framework, we introduce the STELLA benchmark, an aerospace-specific IR evaluation set constructed from NASA Technical Reports Server (NTRS) documents via a systematic pipeline that comprises document layout detection, passage chunking, terminology dictionary construction, synthetic query generation, and cross-lingual extension. The framework generates two types of queries: the Terminology Concordant Query (TCQ), which includes the terminology verbatim to evaluate lexical matching, and the Terminology Agnostic Query (TAQ), which utilizes the terminology's description to assess semantic matching. This enables a disentangled evaluation of the lexical and semantic matching capabilities of embedding models. In addition, we combine Chain-of-Density (CoD) and the Self-Reflection method with query generation to improve quality and implement a hybrid cross-lingual extension that reflects real user querying practices. Evaluation of seven embedding models on the STELLA benchmark shows that large decoder-based embedding models exhibit the strongest semantic understanding, while lexical matching methods such as BM25 remain highly competitive in domains where exact lexical matching technical term is crucial. The STELLA benchmark provides a reproducible foundation for reliable performance evaluation and improvement of embedding models in aerospace-domain IR tasks. The STELLA benchmark can be found in https://huggingface.co/datasets/telepix/STELLA.",
      "authors": [
        "Bongmin Kim"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2026-01-07 01:23:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03496v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03495v1",
      "title": "Cyberattack Detection in Virtualized Microgrids Using LightGBM and Knowledge-Distilled Classifiers",
      "abstract": "Modern microgrids depend on distributed sensing and communication interfaces, making them increasingly vulnerable to cyber physical disturbances that threaten operational continuity and equipment safety. In this work, a complete virtual microgrid was designed and implemented in MATLAB/Simulink, integrating heterogeneous renewable sources and secondary controller layers. A structured cyberattack framework was developed using MGLib to inject adversarial signals directly into the secondary control pathways. Multiple attack classes were emulated, including ramp, sinusoidal, additive, coordinated stealth, and denial of service behaviors. The virtual environment was used to generate labeled datasets under both normal and attack conditions. The datasets trained Light Gradient Boosting Machine (LightGBM) models to perform two functions: detecting the presence of an intrusion (binary) and distinguishing among attack types (multiclass). The multiclass model attained 99.72% accuracy and a 99.62% F1 score, while the binary model attained 94.8% accuracy and a 94.3% F1 score. A knowledge-distillation step reduced the size of the multiclass model, allowing faster predictions with only a small drop in performance. Real-time tests showed a processing delay of about 54 to 67 ms per 1000 samples, demonstrating suitability for CPU-based edge deployment in microgrid controllers. The results confirm that lightweight machine learning based intrusion detection methods can provide fast, accurate, and efficient cyberattack detection without relying on complex deep learning models. Key contributions include: (1) development of a complete MATLAB-based virtual microgrid, (2) structured attack injection at the control layer, (3) creation of multiclass labeled datasets, and (4) design of low-cost AI models suitable for practical microgrid cybersecurity.",
      "authors": [
        "Osasumwen Cedric Ogiesoba-Eguakun",
        "Suman Rath"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "published": "2026-01-07 01:23:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03495v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03483v1",
      "title": "CALM: Culturally Self-Aware Language Models",
      "abstract": "Cultural awareness in language models is the capacity to understand and adapt to diverse cultural contexts. However, most existing approaches treat culture as static background knowledge, overlooking its dynamic and evolving nature. This limitation reduces their reliability in downstream tasks that demand genuine cultural sensitivity. In this work, we introduce CALM, a novel framework designed to endow language models with cultural self-awareness. CALM disentangles task semantics from explicit cultural concepts and latent cultural signals, shaping them into structured cultural clusters through contrastive learning. These clusters are then aligned via cross-attention to establish fine-grained interactions among related cultural features and are adaptively integrated through a Mixture-of-Experts mechanism along culture-specific dimensions. The resulting unified representation is fused with the model's original knowledge to construct a culturally grounded internal identity state, which is further enhanced through self-prompted reflective learning, enabling continual adaptation and self-correction. Extensive experiments conducted on multiple cross-cultural benchmark datasets demonstrate that CALM consistently outperforms state-of-the-art methods.",
      "authors": [
        "Lingzhi Shen",
        "Xiaohao Cai",
        "Yunfei Long",
        "Imran Razzak",
        "Guanming Chen",
        "Shoaib Jameel"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "published": "2026-01-07 00:28:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03483v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03481v1",
      "title": "Self-Explaining Hate Speech Detection with Moral Rationales",
      "abstract": "Hate speech detection models rely on surface-level lexical features, increasing vulnerability to spurious correlations and limiting robustness, cultural contextualization, and interpretability. We propose Supervised Moral Rationale Attention (SMRA), the first self-explaining hate speech detection framework to incorporate moral rationales as direct supervision for attention alignment. Based on Moral Foundations Theory, SMRA aligns token-level attention with expert-annotated moral rationales, guiding models to attend to morally salient spans rather than spurious lexical patterns. Unlike prior rationale-supervised or post-hoc approaches, SMRA integrates moral rationale supervision directly into the training objective, producing inherently interpretable and contextualized explanations. To support our framework, we also introduce HateBRMoralXplain, a Brazilian Portuguese benchmark dataset annotated with hate labels, moral categories, token-level moral rationales, and socio-political metadata. Across binary hate speech detection and multi-label moral sentiment classification, SMRA consistently improves performance (e.g., +0.9 and +1.5 F1, respectively) while substantially enhancing explanation faithfulness, increasing IoU F1 (+7.4 pp) and Token F1 (+5.0 pp). Although explanations become more concise, sufficiency improves (+2.3 pp) and fairness remains stable, indicating more faithful rationales without performance or bias trade-offs",
      "authors": [
        "Francielle Vargas",
        "Jackson Trager",
        "Diego Alves",
        "Surendrabikram Thapa",
        "Matteo Guida",
        "Berk Atil",
        "Daryna Dementieva",
        "Andrew Smart",
        "Ameeta Agrawal"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 00:17:16+00:00",
      "link": "https://arxiv.org/pdf/2601.03481v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03477v1",
      "title": "Hybrid Approach for Driver Behavior Analysis with Machine Learning, Feature Optimization, and Explainable AI",
      "abstract": "Progressive driver behavior analytics is crucial for improving road safety and mitigating the issues caused by aggressive or inattentive driving. Previous studies have employed machine learning and deep learning techniques, which often result in low feature optimization, thereby compromising both high performance and interpretability. To fill these voids, this paper proposes a hybrid approach to driver behavior analysis that uses a 12,857-row and 18-column data set taken from Kaggle. After applying preprocessing techniques such as label encoding, random oversampling, and standard scaling, 13 machine learning algorithms were tested. The Random Forest Classifier achieved an accuracy of 95%. After deploying the LIME technique in XAI, the top 10 features with the most significant positive and negative influence on accuracy were identified, and the same algorithms were retrained. The accuracy of the Random Forest Classifier decreased slightly to 94.2%, confirming that the efficiency of the model can be improved without sacrificing performance. This hybrid model can provide a return on investment in terms of the predictive power and explainability of the driver behavior process.",
      "authors": [
        "Mehedi Hasan Shuvo",
        "Md. Raihan Tapader",
        "Nur Mohammad Tamjid",
        "Sajjadul Islam",
        "Ahnaf Atef Choudhury",
        "Jia Uddin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 00:12:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03477v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05204v1",
      "title": "Extended Heun Hierarchy in Quantum Seiberg-Witten Geometry",
      "abstract": "We investigate the quantum geometry of the Seiberg-Witten curve for $\\mathcal{N}=2$, $\\mathrm{SU(2)}^n$ linear quiver gauge theories. By applying the Weyl quantization prescription to the algebraic curve, we derive the corresponding second-order differential equation and demonstrate that it is isomorphic to the Extended Heun Equation with $n+3$ regular singular points. The physical parameters of the gauge theory are linked to the canonical coefficients of the Heun equation via a polynomial representation of the Seiberg-Witten curve. This framework provides the necessary mathematical foundation to apply non-perturbative gauge-theoretic techniques, such as instanton counting, to spectral problems in gravitational physics, most notably for higher-dimensional black holes.",
      "authors": [
        "Peng Yang",
        "Yi-Rong Wang",
        "Kilar Zhang"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "astro-ph.HE",
        "gr-qc",
        "hep-ph",
        "math-ph"
      ],
      "published": "2026-01-08 18:29:02+00:00",
      "link": "https://arxiv.org/pdf/2601.05204v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05146v1",
      "title": "A simple rigorous integrator for semilinear parabolic PDEs",
      "abstract": "Simulations of the dynamics generated by partial differential equations (PDEs) provide approximate, numerical solutions to initial value problems. Such simulations are ubiquitous in scientific computing, but the correctness of the results is usually not guaranteed. We propose a new method for the rigorous integration of parabolic PDEs, i.e., the derivation of rigorous and explicit error bounds between the numerically obtained approximate solution and the exact one, which is then proven to exist over the entire time interval considered. These guaranteed error bounds are obtained a posteriori, using a fixed point reformulation based on a piece-wise in time constant approximation of the linearization around the numerical solution. Our setup leads to relatively simple-to-understand estimates, which has several advantages. Most critically, it allows us to optimize various aspects of the proof, and in particular to provide an adaptive time-stepping strategy. In case the solution converges to a stable hyperbolic equilibrium, we are also able to prove this convergence, applying our rigorous integrator with a final, infinitely long timestep. We showcase the ability of our method to rigorously integrate over relatively long time intervals, and to capture non-trivial dynamics, via examples on the Swift--Hohenberg equation, the Ohta--Kawasaki equation and the Kuramoto--Sivashinsky equation. We expect that the simplicity and efficiency of the approach will enable generalization to a wide variety of other parabolic PDEs, as well as applications to boundary value problems.",
      "authors": [
        "Jan Bouwe van den Berg",
        "Maxime Breden"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "math.AP",
        "math.DS"
      ],
      "published": "2026-01-08 17:34:40+00:00",
      "link": "https://arxiv.org/pdf/2601.05146v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04865v1",
      "title": "Forming invariant stochastic differential systems with a given first integral",
      "abstract": "This article proposes a method for forming invariant stochastic differential systems, namely dynamic systems with trajectories belonging to a given smooth manifold. The Itô or Stratonovich stochastic differential equations with the Wiener component describe dynamic systems, and the manifold is implicitly defined by a differentiable function. A convenient implementation of the algorithm for forming invariant stochastic differential systems within symbolic computation environments characterizes the proposed method. It is based on determining a basis associated with a tangent hyperplane to the manifold. The article discusses the problem of basis degeneration and examines variants that allow for the simple construction of a basis that does not degenerate. Examples of invariant stochastic differential systems are given, and numerical simulations are performed for them.",
      "authors": [
        "Konstantin A. Rybakov"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-01-08 12:00:00+00:00",
      "link": "https://arxiv.org/pdf/2601.04865v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04783v1",
      "title": "Szegő Mapping and Hermite--Padé Polynomials for Multiple Orthogonality on the Unit Circle",
      "abstract": "We investigate generalized Laurent multiple orthogonal polynomials on the unit circle satisfying simultaneous orthogonality conditions with respect to $r$ probability measures or linear functionals on the unit circle. We show that these polynomials can be characterized as solutions of a general two-point Hermite--Padé approximation problem.   We derive Szegő-type recurrence relations, establish compatibility conditions for the associated recurrence coefficients, and obtain Christoffel--Darboux formulas as well as Heine-type determinantal representations.   Furthermore, by extending the Szegő mapping and the Geronimus relations, we relate these Laurent multiple orthogonal polynomials to multiple orthogonal polynomials on the real line, thereby making explicit the connection between multiple orthogonality on the unit circle and on the real line.",
      "authors": [
        "Rostyslav Kozhan",
        "Marcus Vaktnäs"
      ],
      "primary_category": "math.CA",
      "categories": [
        "math.CA",
        "math.SP"
      ],
      "published": "2026-01-08 10:05:16+00:00",
      "link": "https://arxiv.org/pdf/2601.04783v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04530v1",
      "title": "On identity Seidel switches",
      "abstract": "Seidel switching is a classical operation on graphs which plays a central role in the theory of two-graphs, signed graphs, and switching classes. In this paper we focus on those switches which leave a given graph invariant up to isomorphism. We call such subsets of the vertex set \\emph{identity Seidel switches}. After recalling basic properties of Seidel switching and the associated abelian group structure, we introduce Seidel equivalence classes of graphs and then study the structure of the family of identity Seidel switches of a fixed graph. We show that this family forms a 14 pages; 2--group under composition, and we obtain structural constraints on graphs in which many vertices or edges give rise to identity switches. In particular, we derive necessary conditions in terms of degree parameters, and we characterize certain edge-identity switches via an automorphism of an induced subgraph. Several constructions and examples are presented, and some open problems are proposed.",
      "authors": [
        "Severino V. Gervacio"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-01-08 02:54:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04530v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04496v1",
      "title": "Adaptive Multi-Grade Deep Learning for Highly Oscillatory Fredholm Integral Equations of the Second Kind",
      "abstract": "This paper studies the use of Multi-Grade Deep Learning (MGDL) for solving highly oscillatory Fredholm integral equations of the second kind. We provide rigorous error analyses of continuous and discrete MGDL models, showing that the discrete model retains the convergence and stability of its continuous counterpart under sufficiently small quadrature error. We identify the DNN training error as the primary source of approximation error, motivating a novel adaptive MGDL algorithm that selects the network grade based on training performance. Numerical experiments with highly oscillatory (including wavenumber 500) and singular solutions confirm the accuracy, effectiveness and robustness of the proposed approach.",
      "authors": [
        "Jie Jiang",
        "Yuesheng Xu"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-08 02:00:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04496v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04408v1",
      "title": "G-KdVNet: ANN-ADM Surrogate for Geophysical KdV Equation",
      "abstract": "This article explores the impact of the Coriolis constant on the interpretation of the Korteweg-de Vries (KdV) equation. It introduces an intelligent computing approach, viz., G-KdVNet, to approximate the KdV equation. The Adomian decomposition method (ADM) has been applied to generate the training data for G-KdVNet. When we compared it with benchmark methods, it achieved superior performance, with absolute errors of up to 0.001 for unseen data. Additionally, tabular and graphical representations have been included to offer deeper insights into the effects of the Coriolis parameter.",
      "authors": [
        "Mrutyunjaya Sahoo",
        "Arup Kumar Sahoo",
        "Snehashish Chakraverty"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS"
      ],
      "published": "2026-01-07 21:28:19+00:00",
      "link": "https://arxiv.org/pdf/2601.04408v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04173v1",
      "title": "Trace regularity of solutions to the Navier equations",
      "abstract": "We present results on the trace regularity of the stress vector on the boundary of an elastic solid satisfying the time-dependent, displacement-traction problem for the Navier equations of linear elasticity in a bounded domain of $\\mathbb{R}^3$. Specifically, the solid's displacement is subject to Dirichlet- and Neumann-type conditions on different portions of its boundary and possibly non-zero body forces and initial data. Our regularity results are reminiscent of the so-called \"hidden trace regularity\" results for solutions to the scalar wave equation obtained in [12].",
      "authors": [
        "Jerin Tasnim Farin",
        "Giusy Mazzone"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-07 18:42:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04173v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04105v1",
      "title": "Time Reparametrization and Chaotic Dynamics in Conformable $C_0$-Semigroups",
      "abstract": "Conformable derivatives provide a fractional-looking calculus that remains local and admits a simple representation through classical derivatives with explicit weights. In this paper we develop a systematic operator-theoretic perspective showing that conformable time evolution is, in essence, a classical $C_0$-semigroup observed through a nonlinear clock. We introduce the conformable time map $ψ(t)=t^α/α$ and prove that every $C_0$--$α$-semigroup $\\{T_α(t)\\}_{t\\ge0}$ can be written as $T_α(t)=T(ψ(t))$ for a uniquely determined classical $C_0$-semigroup $\\{T(s)\\}_{s\\ge0}$, with generators agreeing on a common domain. This correspondence yields a one-to-one transfer of mild solutions and shows that orbit-based linear dynamics are invariant under conformable reparametrization. In particular, $α$-hypercyclicity and $α$--chaos coincide with the usual notions for the associated classical semigroup. As a consequence, we obtain a conformable version of the Desch--Schappacher--Webb spectral criterion for chaos. We also place the analysis in the natural functional setting provided by conformable Lebesgue spaces $L^{p,α}$ and their explicit isometric identification with standard $L^p$ spaces, which allows one to transport estimates and spectral arguments without loss. The results clarify which dynamical phenomena in conformable models are genuinely new and which are inherited from classical semigroup dynamics via a nonlinear change of time.",
      "authors": [
        "Mohamed Khoulane",
        "Aziz El Ghazouani",
        "M'hamed El Omari"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "math.DS",
        "math.FA"
      ],
      "published": "2026-01-07 17:11:23+00:00",
      "link": "https://arxiv.org/pdf/2601.04105v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03920v1",
      "title": "Adaptive thresholding for wavelet-based nonparametric heteroskedastic variance estimation on the sphere",
      "abstract": "This paper investigates the nonparametric estimation of a heteroskedastic variance function on the sphere in a regression framework, assuming the variance belongs to a Besov regularity class. A needlet-based estimator is proposed, combining multiresolution analysis with hard thresholding. The method exploits the spatial and spectral localization of needlets to adapt to unknown smoothness and is shown to attain minimax-optimal convergence rates over Besov spaces.",
      "authors": [
        "Claudio Durastanti",
        "Radomyra Shevchenko"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST"
      ],
      "published": "2026-01-07 13:41:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03920v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03906v1",
      "title": "Exact Continuous Reformulations of Logic Constraints in Nonlinear Optimization and Optimal Control Problems",
      "abstract": "Many nonlinear optimal control and optimization problems involve constraints that combine continuous dynamics with discrete logic conditions. Standard approaches typically rely on mixed-integer programming, which introduces scalability challenges and requires specialized solvers. This paper presents an exact reformulation of broad classes of logical constraints as binary-variable-free expressions whose differentiability properties coincide with those of the underlying predicates, enabling their direct integration into nonlinear programming models. Our approach rewrites arbitrary logical propositions into conjunctive normal form, converts them into equivalent max--min constraints, and applies a smoothing procedure that preserves the exact feasible set. The method is evaluated on two benchmark problems, a quadrotor trajectory optimization with obstacle avoidance and a hybrid two-tank system with temporal logic constraints, and is shown to obtain optimal solutions more consistently and efficiently than existing binary variable elimination techniques.",
      "authors": [
        "Jad Wehbeh",
        "Eric C. Kerrigan"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "math.OC"
      ],
      "published": "2026-01-07 13:16:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03906v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03876v1",
      "title": "Graded Bridgeman dilogarithm identities on hyperbolic surfaces",
      "abstract": "We establish graded versions of Bridgeman's dilogarithm identity for hyperbolic cone surfaces, including surfaces with only cusps and cone points, and provide applications to the study of orthogeodesics.",
      "authors": [
        "Ara Basmajian",
        "Nhat Minh Doan",
        "Hugo Parlier",
        "Ser Peow Tan"
      ],
      "primary_category": "math.GT",
      "categories": [
        "math.GT",
        "math.DG"
      ],
      "published": "2026-01-07 12:40:34+00:00",
      "link": "https://arxiv.org/pdf/2601.03876v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03759v1",
      "title": "Connecting Max-entropy With Computational Geometry, LP And SDP",
      "abstract": "We consider the well-known max-(relative) entropy problem $Θ$(y) = infQ$\\ll$P DKL(Q P ) with Kullback-Leibler divergence on a domain $Ω$ $\\subset$ R d , and with ''moment'' constraints h dQ = y, y $\\in$ R m . We show that when m $\\le$ d, $Θ$ is the Cram{é}r transform of a function v that solves a simply related computational geometry problem. Also, and remarkably, to the canonical LP: min x$\\ge$0 {c T x\\,: A x = y}, with A $\\in$ R mxd , one may associate a max-entropy problem with a suitably chosen reference measure P on R d + and linear mapping h(x) = Ax, such that its associated perspective function $ε$ $Θ$(y/$ε$) is the optimal value of the log-barrier formulation (with parameter $ε$) of the dual LP (and so it converges to the LP optimal value as $ε$ $\\rightarrow$ 0). An analogous result also holds for the canonical SDP: min X 0 { C, X\\,: A(X) = y }.",
      "authors": [
        "Jean B Lasserre"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-07 09:48:10+00:00",
      "link": "https://arxiv.org/pdf/2601.03759v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03755v1",
      "title": "$BV$-Estimates for Non-Linear Parabolic PDE with Linear Drift",
      "abstract": "In the present work, we establish space Bounded Variation $(BV)$ regularity of the solution for a non-linear parabolic partial differential equations involving a linear drift term. We study the problem in a bounded domain with mixed Dirichlet-Neumann boundary conditions, a general non-linearity and reasonable assumptions on the data. Our results also cover, as a particular case, the linear transport equation in a bounded domain with an outward-pointing drift vector field on the boundary.",
      "authors": [
        "El Mahdi Erraji",
        "Noureddine Igbida",
        "Fahd Karami",
        "Driss Meskine"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-07 09:45:32+00:00",
      "link": "https://arxiv.org/pdf/2601.03755v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03747v1",
      "title": "Matrix Riccati BSDEs with singular terminal condition and stochastic LQ control with linear terminal constraint",
      "abstract": "We analyze a class of multidimensional linear-quadratic stochastic control problems with random coefficients, motivated by multi-asset optimal trade execution. The problems feature non-diffusive controlled state dynamics and a terminal constraint that restricts the terminal state to a prescribed random linear subspace. We derive the associated Riccati backward stochastic differential equation (BSDE) and identify a suitable formalization of its singular terminal condition. Via a penalization approach, we establish existence of a minimal supersolution of the Riccati BSDE and use it to characterize both the value function and the optimal control. We analyze the asymptotic behavior of the supersolution near terminal time and discuss special cases where closed-form solutions can be obtained.",
      "authors": [
        "Julia Ackermann",
        "Thomas Kruse",
        "Petr Petrov",
        "Alexandre Popier"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "math.PR"
      ],
      "published": "2026-01-07 09:37:25+00:00",
      "link": "https://arxiv.org/pdf/2601.03747v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03742v1",
      "title": "Mean-field limits for interacting particles on general adaptive dynamical networks",
      "abstract": "We study the large-population limit of interacting particle systems evolving on adaptive dynamical networks, motivated in particular by models of opinion dynamics. In such systems, agents interact through weighted graphs whose structure evolves over time in a coupled manner with the agents' states, leading to non-exchangeable dynamics. In the dense-graph regime, we show that the asymptotic behavior is described by a Vlasov-type equation posed on an extended phase space that includes both the agents' states and identities and the evolving interaction weights. We establish this limiting equation through two complementary approaches. The first follows the mean-field methodology in the spirit of Sznitman [28]. In this framework, we impose the additional assumption that the weight dynamics is independent of one of the agent's states, an assumption that remains well motivated from a modeling perspective and allows for a direct derivation of the mean-field limit. The second approach is based on the graph limit framework and is formulated in a deterministic setting. This perspective makes it possible to remove the aforementioned restriction on the weight dynamics and to handle more general interaction structures. Our analysis includes wellposedness and stability results for the limiting Vlasov-type equation, as well as quantitative estimates ensuring the propagation of independence. We further clarify the relationship between the continuum (graph limit) formulation and the mean-field limit, thereby providing a unified description of the asymptotic dynamics of interacting particle systems on adaptive dynamical networks.",
      "authors": [
        "Nathalie Ayi"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-07 09:30:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03742v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04913v1",
      "title": "Bayesian Additive Regression Tree Copula Processes for Scalable Distributional Prediction",
      "abstract": "We show how to construct the implied copula process of response values from a Bayesian additive regression tree (BART) model with prior on the leaf node variances. This copula process, defined on the covariate space, can be paired with any marginal distribution for the dependent variable to construct a flexible distributional BART model. Bayesian inference is performed via Markov chain Monte Carlo on an augmented posterior, where we show that key sampling steps can be realized as those of Chipman et al. (2010), preserving scalability and computational efficiency even though the copula process is high dimensional. The posterior predictive distribution from the copula process model is derived in closed form as the push-forward of the posterior predictive distribution of the underlying BART model with an optimal transport map. Under suitable conditions, we establish posterior consistency for the regression function and posterior means and prove convergence in distribution of the predictive process and conditional expectation. Simulation studies demonstrate improved accuracy of distributional predictions compared to the original BART model and leading benchmarks. Applications to five real datasets with 506 to 515,345 observations and 8 to 90 covariates further highlight the efficacy and scalability of our proposed BART copula process model.",
      "authors": [
        "Jan Martin Wenkel",
        "Michael Stanley Smith",
        "Nadja Klein"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-08 13:11:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04913v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04608v1",
      "title": "Forecasting the U.S. Treasury Yield Curve: A Distributionally Robust Machine Learning Approach",
      "abstract": "We study U.S. Treasury yield curve forecasting under distributional uncertainty and recast forecasting as an operations research and managerial decision problem. Rather than minimizing average forecast error, the forecaster selects a decision rule that minimizes worst case expected loss over an ambiguity set of forecast error distributions. To this end, we propose a distributionally robust ensemble forecasting framework that integrates parametric factor models with high dimensional nonparametric machine learning models through adaptive forecast combinations. The framework consists of three machine learning components. First, a rolling window Factor Augmented Dynamic Nelson Siegel model captures level, slope, and curvature dynamics using principal components extracted from economic indicators. Second, Random Forest models capture nonlinear interactions among macro financial drivers and lagged Treasury yields. Third, distributionally robust forecast combination schemes aggregate heterogeneous forecasts under moment uncertainty, penalizing downside tail risk via expected shortfall and stabilizing second moment estimation through ridge regularized covariance matrices. The severity of the worst case criterion is adjustable, allowing the forecaster to regulate the trade off between robustness and statistical efficiency. Using monthly data, we evaluate out of sample forecasts across maturities and horizons from one to twelve months ahead. Adaptive combinations deliver superior performance at short horizons, while Random Forest forecasts dominate at longer horizons. Extensions to global sovereign bond yields confirm the stability and generalizability of the proposed framework.",
      "authors": [
        "Jinjun Liu",
        "Ming-Yen Cheng"
      ],
      "primary_category": "q-fin.MF",
      "categories": [
        "q-fin.MF",
        "q-fin.CP",
        "stat.ML"
      ],
      "published": "2026-01-08 05:26:43+00:00",
      "link": "https://arxiv.org/pdf/2601.04608v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04138v1",
      "title": "On the Distributed Estimation for Scalar-on-Function Regression Models",
      "abstract": "This paper proposes distributed estimation procedures for three scalar-on-function regression models: the functional linear model (FLM), the functional non-parametric model (FNPM), and the functional partial linear model (FPLM). The framework addresses two key challenges in functional data analysis, namely the high computational cost of large samples and limitations on sharing raw data across institutions. Monte Carlo simulations show that the distributed estimators substantially reduce computation time while preserving high estimation and prediction accuracy for all three models. When block sizes become too small, the FPLM exhibits overfitting, leading to narrower prediction intervals and reduced empirical coverage probability. An example of an empirical study using the \\textit{tecator} dataset further supports these findings.",
      "authors": [
        "Peilun He",
        "Han Lin Shang",
        "Nan Zou"
      ],
      "primary_category": "stat.CO",
      "categories": [
        "stat.CO"
      ],
      "published": "2026-01-07 17:51:46+00:00",
      "link": "https://arxiv.org/pdf/2601.04138v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04101v1",
      "title": "Ridge Estimation of High Dimensional Two-Way Fixed Effect Regression",
      "abstract": "We study a ridge estimator for the high-dimensional two-way fixed effect regression model with a sparse bipartite network. We develop concentration inequalities showing that when the ridge parameters increase as the log of the network size, the bias, and the variance-covariance matrix of the vector of estimated fixed effects converge to deterministic equivalents that depend only on the expected network. We provide simulations and an application using administrative data on wages for worker-firm matches.",
      "authors": [
        "Junnan He",
        "Jean-Marc Robin"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM",
        "stat.ME"
      ],
      "published": "2026-01-07 17:06:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04101v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03927v1",
      "title": "A comprehensive review and analysis of different modeling approaches for financial index tracking problem",
      "abstract": "Index tracking, also known as passive investing, has gained significant traction in financial markets due to its cost-effective and efficient approach to replicating the performance of a specific market index. This review paper provides a comprehensive overview of the various modeling approaches and strategies developed for index tracking, highlighting the strengths and limitations of each approach. We categorize the index tracking models into three broad frameworks: optimization-based models, statistical-based models and machine learning based data-driven approach. A comprehensive empirical study conducted on the S\\&P 500 dataset demonstrates that the tracking error volatility model under the optimization-based framework delivers the most precise index tracking, the convex co-integration model, under the statistical-based framework achieves the strongest return-risk balance, and the deep neural network with fixed noise model within the data-driven framework provides a competitive performance with notably low turnover and high computational efficiency. By combining a critical review of the existing literature with comparative empirical analysis, this paper aims to provide insights into the evolving landscape of index tracking and its practical implications for investors and fund managers.",
      "authors": [
        "Vrinda Dhingra",
        "Amita Sharma",
        "Anubha Goel"
      ],
      "primary_category": "q-fin.PM",
      "categories": [
        "q-fin.PM",
        "stat.ML"
      ],
      "published": "2026-01-07 13:47:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03927v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03815v1",
      "title": "High-Dimensional Precision Matrix Quadratic Forms: Estimation Framework for $p > n$",
      "abstract": "We propose a novel estimation framework for quadratic functionals of precision matrices in high-dimensional settings, particularly in regimes where the feature dimension $p$ exceeds the sample size $n$. Traditional moment-based estimators with bias correction remain consistent when $p<n$ (i.e., $p/n \\to c <1$). However, they break down entirely once $p>n$, highlighting a fundamental distinction between the two regimes due to rank deficiency and high-dimensional complexity. Our approach resolves these issues by combining a spectral-moment representation with constrained optimization, resulting in consistent estimation under mild moment conditions.   The proposed framework provides a unified approach for inference on a broad class of high-dimensional statistical measures. We illustrate its utility through two representative examples: the optimal Sharpe ratio in portfolio optimization and the multiple correlation coefficient in regression analysis. Simulation studies demonstrate that the proposed estimator effectively overcomes the fundamental $p>n$ barrier where conventional methods fail.",
      "authors": [
        "Shizhe Hong",
        "Weiming Li",
        "Guangming Pan"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-07 11:19:28+00:00",
      "link": "https://arxiv.org/pdf/2601.03815v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03777v1",
      "title": "Multi-agent Optimization of Non-cooperative Multimodal Mobility Systems",
      "abstract": "While multimodal mobility systems have the potential to bring many benefits to travelers, drivers, the environment, and traffic congestion, such systems typically involve multiple non-cooperative decision-makers who may selfishly optimize their own objectives without considering the overall system benefits. This paper aims to investigate market-based interactions of travelers and ride-sourcing drivers in the context of multimodal mobility systems. We propose a unified mathematical modeling framework to capture the decentralized travelers and drivers' decision-making process and balance the network's demand and supply by equilibrium pricing. Such a model allows analyses of the impact of decentralized decision-making on multimodal mobility efficiencies. The proposed formulation can be further convexified to efficiently compute the equilibrium ride-sourcing prices. We conduct numerical experiments on different settings of transportation networks to gain policy insights. We find that travelers prefer ride-sourcing and multimodal transportation more than the driving option when they are more sensitive to prices. We also find that travelers may need to be subsidized to use multimodal transportation when there is fewer transit hubs in the network or, ride-sourcing drivers become too sensitive to the prices. However, we find that more transit hubs in the network increases the total empty VMT of ride-sourcing drivers by increasing the total relocation time. The proposed model can be used by policymakers and platform operators to design pricing and subsidy schemes that align individual decision-making with system-level efficiency and evaluate the trade-offs between accessibility and environmental impacts in multimodal transportation networks.",
      "authors": [
        "Md Nafees Fuad Rafi",
        "Zhaomiao Guo"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "eess.SY"
      ],
      "published": "2026-01-07 10:14:49+00:00",
      "link": "https://arxiv.org/pdf/2601.03777v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03760v1",
      "title": "Non-Homogeneous Markov-Switching Generalized Additive Models for Location, Scale, and Shape",
      "abstract": "We propose an extension of Markov-switching generalized additive models for location, scale, and shape (MS-GAMLSS) that allows covariates to influence not only the parameters of the state-dependent distributions but also the state transition probabilities. Traditional MS-GAMLSS, which combine distributional regression with hidden Markov models, typically assume time-homogeneous (i.e., constant) transition probabilities, thereby preventing regime shifts from responding to covariate-driven changes. Our approach overcomes this limitation by modeling the transition probabilities as smooth functions of covariates, enabling a flexible, data-driven characterization of covariate-dependent regime dynamics. Estimation is carried out within a penalized likelihood framework, where automatic smoothness selection controls model complexity and guards against overfitting. We evaluate the proposed methodology through simulations and applications to daily Lufthansa stock prices and Spanish energy prices. Our results show that incorporating macroeconomic indicators into the transition probabilities yields additional insights into market dynamics. Data and R code to reproduce the results are available online.",
      "authors": [
        "Katharina Ammann",
        "Timo Adam",
        "Jan-Ole Koslik"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-07 09:52:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03760v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03674v1",
      "title": "Multi-transport Distributional Regression",
      "abstract": "We study distribution-on-distribution regression problems in which a response distribution depends on multiple distributional predictors. Such settings arise naturally in applications where the outcome distribution is driven by several heterogeneous distributional sources, yet remain challenging due to the nonlinear geometry of the Wasserstein space. We propose an intrinsic regression framework that aggregates predictor-specific transported distributions through a weighted Fréchet mean in the Wasserstein space. The resulting model admits multiple distributional predictors, assigns interpretable weights quantifying their relative contributions, and defines a flexible regression operator that is invariant to auxiliary construction choices, such as the selection of a reference distribution. From a theoretical perspective, we establish identifiability of the induced regression operator and derive asymptotic guarantees for its estimation under a predictive Wasserstein semi-norm, which directly characterizes convergence of the composite prediction map. Extensive simulation studies and a real data application demonstrate the improved predictive performance and interpretability of the proposed approach compared with existing Wasserstein regression methods.",
      "authors": [
        "Yuanying Chen",
        "Tongyu Li",
        "Yang Bai",
        "Zhenhua Lin"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-07 07:54:20+00:00",
      "link": "https://arxiv.org/pdf/2601.03674v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03532v2",
      "title": "Propagating Surrogate Uncertainty in Bayesian Inverse Problems",
      "abstract": "Standard Bayesian inference schemes are infeasible for inverse problems with computationally expensive forward models. A common solution is to replace the model with a cheaper surrogate. To avoid overconfident conclusions, it is essential to acknowledge the surrogate approximation by propagating its uncertainty. At present, a variety of distinct uncertainty propagation methods have been suggested, with little understanding of how they vary. To fill this gap, we propose a mixture distribution termed the expected posterior (EP) as a general baseline for uncertainty-aware posterior approximation, justified by decision theoretic and modular Bayesian inference arguments. We then investigate the expected unnormalized posterior (EUP), a popular heuristic alternative, analyzing when it may deviate from the EP baseline. Our results show that this heuristic can break down when the surrogate uncertainty is highly non-uniform over the design space, as can be the case when the log-likelihood is emulated by a Gaussian process. Finally, we present the random kernel preconditioned Crank-Nicolson (RKpCN) algorithm, an approximate Markov chain Monte Carlo scheme that provides practical EP approximation in the challenging setting involving infinite-dimensional Gaussian process surrogates.",
      "authors": [
        "Andrew Gerard Roberts",
        "Michael Dietze",
        "Jonathan H. Huggins"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "stat.CO"
      ],
      "published": "2026-01-07 02:45:34+00:00",
      "link": "https://arxiv.org/pdf/2601.03532v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04896v1",
      "title": "Deep Reinforcement Learning for Optimum Order Execution: Mitigating Risk and Maximizing Returns",
      "abstract": "Optimal Order Execution is a well-established problem in finance that pertains to the flawless execution of a trade (buy or sell) for a given volume within a specified time frame. This problem revolves around optimizing returns while minimizing risk, yet recent research predominantly focuses on addressing one aspect of this challenge. In this paper, we introduce an innovative approach to Optimal Order Execution within the US market, leveraging Deep Reinforcement Learning (DRL) to effectively address this optimization problem holistically. Our study assesses the performance of our model in comparison to two widely employed execution strategies: Volume Weighted Average Price (VWAP) and Time Weighted Average Price (TWAP). Our experimental findings clearly demonstrate that our DRL-based approach outperforms both VWAP and TWAP in terms of return on investment and risk management. The model's ability to adapt dynamically to market conditions, even during periods of market stress, underscores its promise as a robust solution.",
      "authors": [
        "Khabbab Zakaria",
        "Jayapaulraj Jerinsh",
        "Andreas Maier",
        "Patrick Krauss",
        "Stefano Pasquali",
        "Dhagash Mehta"
      ],
      "primary_category": "q-fin.CP",
      "categories": [
        "q-fin.CP"
      ],
      "published": "2026-01-08 12:49:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04896v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04602v1",
      "title": "Forecasting Equity Correlations with Hybrid Transformer Graph Neural Network",
      "abstract": "This paper studies forward-looking stock-stock correlation forecasting for S\\&P 500 constituents and evaluates whether learned correlation forecasts can improve graph-based clustering used in basket trading strategies. We cast 10-day ahead correlation prediction in Fisher-z space and train a Temporal-Heterogeneous Graph Neural Network (THGNN) to predict residual deviations from a rolling historical baseline. The architecture combines a Transformer-based temporal encoder, which captures non-stationary, complex, temporal dependencies, with an edge-aware graph attention network that propagates cross-asset information over the equity network. Inputs span daily returns, technicals, sector structure, previous correlations, and macro signals, enabling regime-aware forecasts and attention-based feature and neighbor importance to provide interpretability. Out-of-sample results from 2019-2024 show that the proposed model meaningfully reduces correlation forecasting error relative to rolling-window estimates. When integrated into a graph-based clustering framework, forward-looking correlations produce adaptable and economically meaningfully baskets, particularly during periods of market stress. These findings suggest that improvements in correlation forecasts translate into meaningful gains during portfolio construction tasks.",
      "authors": [
        "Jack Fanshawe",
        "Rumi Masih",
        "Alexander Cameron"
      ],
      "primary_category": "q-fin.CP",
      "categories": [
        "q-fin.CP",
        "q-fin.TR"
      ],
      "published": "2026-01-08 05:16:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04602v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04062v2",
      "title": "Smart Predict--then--Optimize Paradigm for Portfolio Optimization in Real Markets",
      "abstract": "Improvements in return forecast accuracy do not always lead to proportional improvements in portfolio decision quality, especially under realistic trading frictions and constraints. This paper adopts the Smart Predict--then--Optimize (SPO) paradigm for portfolio optimization in real markets, which explicitly aligns the learning objective with downstream portfolio decision quality rather than pointwise prediction accuracy. Within this paradigm, predictive models are trained using an SPO-based surrogate loss that directly reflects the performance of the resulting investment decisions. To preserve interpretability and robustness, we employ linear predictors built on return-based and technical-indicator features and integrate them with portfolio optimization models that incorporate transaction costs, turnover control, and regularization. We evaluate the proposed approach on U.S. ETF data (2015--2025) using a rolling-window backtest with monthly rebalancing. Empirical results show that decision-focused training consistently improves risk-adjusted performance over predict--then--optimize baselines and classical optimization benchmarks, and yields strong robustness during adverse market regimes (e.g., the 2020 COVID-19). These findings highlight the practical value of the Smart Predict--then--Optimize paradigm for portfolio optimization in realistic and non-stationary financial environments.",
      "authors": [
        "Wang Yi",
        "Takashi Hasuike"
      ],
      "primary_category": "q-fin.PM",
      "categories": [
        "q-fin.PM"
      ],
      "published": "2026-01-07 16:28:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04062v2",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05087v1",
      "title": "Online Bayesian Learning of Agent Behavior in Differential Games",
      "abstract": "This work introduces an online Bayesian game-theoretic method for behavior identification in multi-agent dynamical systems. By casting Hamilton-Jacobi-Bellman optimality conditions as linear-in-parameter residuals, the method enables fast sequential Bayesian updates, uncertainty-aware inference, and robust prediction from limited, noisy data-without history stacks. The approach accommodates nonlinear dynamics and nonquadratic value functions through basis expansions, providing flexible models. Experiments, including linear-quadratic and nonlinear shared-control scenarios, demonstrate accurate prediction with quantified uncertainty, highlighting the method's relevance for adaptive interaction and real-time decision making.",
      "authors": [
        "Francesco Bianchin",
        "Robert Lefringhausen",
        "Sandra Hirche"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-08 16:35:43+00:00",
      "link": "https://arxiv.org/pdf/2601.05087v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04957v1",
      "title": "Safe Reinforcement Learning Beyond Baseline Control: A Hierarchical Framework for Space Triangle Tethered Formation System",
      "abstract": "Triangular tethered formation system (TTFS) provide a promising platform for deep space exploration and distributed sensing due to its intrinsic spatial-orientation stability and capability of adjusting distances among node satellites through deployment and retrieval of tethers. However, due to the coupled tether-satellite dynamics and disturbance sensitivity of TTFS, traditional control methods struggle to achieve a balanced trade-off among configuration accuracy requirements, tension constraints, and energy efficiency consumption throughout the deployment process.In this paper, a novel model-reference reinforcement learning control framework is proposed for TTFS. By integrating baseline model-based control with a Soft Actor-Critic (SAC) compensator, the proposed method simultaneously achieves high-precision tracking, fuel efficiency, and compliance with tension limits. A hierarchical training scheme is developed to address the convergence difficulties arising from strongly coupled states in centralized training, while tailored reward functions, reset conditions, and normalization criteria are designed to accelerate training convergence. Closed-loop stability of the overall control law is rigorously proven using Lyapunov methods. Simulation results demonstrate that the proposed controller reduces steady-state tracking errors by over 96% for tethers and 99% for node satellites, while cutting fuel consumption by two orders of magnitude compared with the baseline method. These results validate the effectiveness and stability of the proposed approach for TTFS deployment control.",
      "authors": [
        "Xinyi Tao",
        "Panfeng Huang",
        "Fan Zhang"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-08 14:02:34+00:00",
      "link": "https://arxiv.org/pdf/2601.04957v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04581v1",
      "title": "Spectral point transformer for significant wave height estimation from sea clutter",
      "abstract": "This paper presents a method for estimating significant wave height (Hs) from sparse S_pectral P_oint using a T_ransformer-based approach (SPT). Based on empirical observations that only a minority of spectral points with strong power contribute to wave energy, the proposed SPT effectively integrates geometric and spectral characteristics of ocean surface waves to estimate Hs through multi-dimensional feature representation. The experiment reveals an intriguing phenomenon: the learned features of SPT align well with physical dispersion relations, where the contribution-score map of selected points is concentrated along dispersion curves. Compared to conventional vision networks that process image sequences and full spectra, SPT demonstrates superior performance in Hs regression while consuming significantly fewer computational resources. On a consumer-grade GPU, SPT completes the training of regression model for 1080 sea clutter image sequences within 4 minutes, showcasing its potential to reduce deployment costs for radar wave-measuring systems. The open-source implementation of SPT will be available at https://github.com/joeyee/spt",
      "authors": [
        "Yi Zhou",
        "Li Wang",
        "Hang Su",
        "Tian Wang"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-08 04:26:19+00:00",
      "link": "https://arxiv.org/pdf/2601.04581v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04069v1",
      "title": "Hybrid Downlink Beamforming with Outage Constraints under Imperfect CSI using Model-Driven Deep Learning",
      "abstract": "We consider energy-efficient multi-user hybrid downlink beamforming (BF) and power allocation under imperfect channel state information (CSI) and probabilistic outage constraints. In this domain, classical optimization methods resort to computationally costly conic optimization problems. Meanwhile, generic deep network (DN) architectures lack interpretability and require large training data sets to generalize well. In this paper, we therefore propose a lightweight model-aided deep learning architecture based on a greedy selection algorithm for analog beam codewords. The architecture relies on an instance-adaptive augmentation of the signal model to estimate the impact of the CSI error. To learn the DN parameters, we derive a novel and efficient implicit representation of the nested constrained BF problem and prove sufficient conditions for the existence of the corresponding gradient. In the loss function, we utilize an annealing-based approximation of the outage compared to conventional quantile-based loss terms. This approximation adaptively anneals towards the exact probabilistic constraint depending on the current level of quality of service (QoS) violation. Simulations validate that the proposed DN can achieve the nominal outage level under CSI error due to channel estimation and channel compression, while allocating less power than benchmarks. Thereby, a single trained model generalizes to different numbers of users, QoS requirements and levels of CSI quality. We further show that the adaptive annealing-based loss function can accelerate the training and yield a better power-outage trade-off.",
      "authors": [
        "Lukas Schynol",
        "Marius Pesavento"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-07 16:33:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04069v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03745v1",
      "title": "Two-stage Multi-beam Training for Multiuser Millimeter-Wave Communications",
      "abstract": "In this letter, we study an efficient multi-beam training method for multiuser millimeter-wave communication systems. Unlike the conventional single-beam training method that relies on exhaustive search, multi-beam training design faces a key challenge in balancing the trade-off between beam training overhead and success beam-identification rate, exacerbated by severe inter-beam interference. To tackle this challenge, we propose a new two-stage multi-beam training method with two distinct multi-beam patterns to enable fast and accurate user angle identification. Specifically, in the first stage, the antenna array is divided into sparse subarrays to generate multiple beams (with high array gains), for identifying candidate user angles. In the second stage, the array is redivided into dense subarrays to generate flexibly steered wide beams, for which a cross-validation method is employed to effectively resolve the remaining angular ambiguity in the first stage. Last, numerical results demonstrate that the proposed method significantly improves the success beam-identification rate compared to existing multi-beam training methods, while retaining or even reducing the required beam training overhead.",
      "authors": [
        "Weijia Wang",
        "Changsheng You",
        "Xiaodan Shao",
        "Rui Zhang"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-07 09:33:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03745v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03712v2",
      "title": "TellWhisper: Tell Whisper Who Speaks When",
      "abstract": "Multi-speaker automatic speech recognition (MASR) aims to predict ''who spoke when and what'' from multi-speaker speech, a key technology for multi-party dialogue understanding. However, most existing approaches decouple temporal modeling and speaker modeling when addressing ''when'' and ''who'': some inject speaker cues before encoding (e.g., speaker masking), which can cause irreversible information loss; others fuse identity by mixing speaker posteriors after encoding, which may entangle acoustic content with speaker identity. This separation is brittle under rapid turn-taking and overlapping speech, often leading to degraded performance. To address these limitations, we propose TellWhisper, a unified framework that jointly models speaker identity and temporal within the speech encoder. Specifically, we design TS-RoPE, a time-speaker rotary positional encoding: time coordinates are derived from frame indices, while speaker coordinates are derived from speaker activity and pause cues. By applying region-specific rotation angles, the model explicitly captures per-speaker continuity, speaker-turn transitions, and state dynamics, enabling the attention mechanism to simultaneously attend to ''when'' and ''who''. Moreover, to estimate frame-level speaker activity, we develop Hyper-SD, which casts speaker classification in hyperbolic space to enhance inter-class separation and refine speaker-activity estimates. Extensive experiments demonstrate the effectiveness of the proposed approach.",
      "authors": [
        "Yifan Hu",
        "Peiji Yang",
        "Zhisheng Wang",
        "Yicheng Zhong",
        "Rui Liu"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS"
      ],
      "published": "2026-01-07 08:58:45+00:00",
      "link": "https://arxiv.org/pdf/2601.03712v2",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03639v1",
      "title": "Zak-OTFS ISAC with Bistatic Sensing via Semi-Blind Atomic Norm Denoising Scheme",
      "abstract": "Integrated sensing and communication (ISAC) through Zak-transform-based orthogonal time frequency space (Zak-OTFS) modulation is a promising solution for high-mobility scenarios. Realizing accurate bistatic sensing and robust communication necessitates precise channel estimation; however, this remains a formidable challenge in doubly dispersive environments, where fractional delay-Doppler shifts induce severe channel spreading. This paper proposes a semi-blind atomic norm denoising scheme for Zak-OTFS ISAC with bistatic sensing. We first derive the discrete-time input-output (I/O) relationship of Zak-OTFS under fractional delay-Doppler shifts and rectangular windowing. Based on this I/O relation, we formulate the joint channel parameter estimation and data detection task as an atomic norm denoising problem, utilizing the negative square penalty method to handle the non-convex discrete constellation constraints. To solve this problem efficiently, we develop an accelerated iterative algorithm that integrates majorization-minimization, accelerated projected gradient, and inexact accelerated proximal gradient methods. We provide a rigorous convergence proof for the proposed algorithm. Simulation results demonstrate that the proposed scheme achieves super-resolution sensing accuracy and communication performance approaching the perfect channel state information lower bound.",
      "authors": [
        "Kecheng Zhang",
        "Weijie Yuan",
        "Maria Sabrina Greco"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-07 06:33:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03639v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03486v1",
      "title": "Adaptive Model-Based Reinforcement Learning for Orbit Feedback Control in NSLS-II Storage Ring",
      "abstract": "The National Synchrotron Light Source II (NSLS-II) uses highly stable electron beam to produce high-quality X-ray beams with high brightness and low-emittance synchrotron radiation. The traditional algorithm to stabilize the beam applies singular value decomposition (SVD) on the orbit response matrix to remove noise and extract actions. Supervised learning has been studied on NSLS-II storage ring stabilization and other accelerator facilities recently. Several problems, for example, machine status drifting, environment noise, and non-linear accelerator dynamics, remain unresolved in the SVD-based and supervised learning algorithms. To address these problems, we propose an adaptive training framework based on model-based reinforcement learning. This framework consists of two types of optimizations: trajectory optimization attempts to minimize the expected total reward in a differentiable environment, and online model optimization learns non-linear machine dynamics through the agent-environment interaction. Through online training, this framework tracks the internal status drifting in the electron beam ring. Simulation and real in-facility experiments on NSLS-II reveal that our method stabilizes the beam position and minimizes the alignment error, defined as the root mean square (RMS) error between adjusted beam positions and the reference position, down to ~1$μ$m.",
      "authors": [
        "Zeyu Dong",
        "Yuke Tian",
        "Yu Sun"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-07 00:49:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03486v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04438v1",
      "title": "The Endogenous Grid Method for Epstein-Zin Preferences",
      "abstract": "The endogenous grid method (EGM) accelerates dynamic programming by inverting the Euler equation, but it appears incompatible with Epstein-Zin preferences where the value function enters the Euler equation. This paper shows that a power transformation resolves the difficulty. The resulting algorithm requires no root-finding, achieves speed gains of one to two orders of magnitude over value function iteration, and improves accuracy by more than one order of magnitude. Holding accuracy constant, the speedup is two to three orders of magnitude. VFI and time iteration face a speed-accuracy tradeoff; EGM sidesteps it entirely.",
      "authors": [
        "Alan Lujan"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN"
      ],
      "published": "2026-01-07 22:52:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04438v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03750v1",
      "title": "Multivariate kernel regression in vector and product metric spaces",
      "abstract": "This paper derives limit properties of nonparametric kernel regression estimators without requiring existence of density for regressors in $\\mathbb{R}^{q}.$ In functional regression limit properties are established for multivariate functional regression. The rate and asymptotic normality for the Nadaraya-Watson (NW) estimator is established for distributions of regressors in $\\mathbb{R}^{q}$ that allow for mass points, factor structure, multicollinearity and nonlinear dependence, as well as fractal distribution; when bounded density exists we provide statistical guarantees for the standard rate and the asymptotic normality without requiring smoothness. We demonstrate faster convergence associated with dimension reducing types of singularity, such as a fractal distribution or a factor structure in the regressors. The paper extends asymptotic normality of kernel functional regression to multivariate regression over a product of any number of metric spaces. Finite sample evidence confirms rate improvement due to singularity in regression over $\\mathbb{R}^{q}.$ For functional regression the simulations underline the importance of accounting for multiple functional regressors. We demonstrate the applicability and advantages of the NW estimator in our empirical study, which reexamines the job training program evaluation based on the LaLonde data.",
      "authors": [
        "Marcia Schafgans",
        "Victoria Zinde-Walsh"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM"
      ],
      "published": "2026-01-07 09:40:54+00:00",
      "link": "https://arxiv.org/pdf/2601.03750v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03598v1",
      "title": "Uncovering Sparse Financial Networks with Information Criteria",
      "abstract": "Empirical measures of financial connectedness based on Forecast Error Variance Decompositions (FEVDs) often yield dense network structures that obscure true transmission channels and complicate the identification of systemic risk. This paper proposes a novel information-criterion-based approach to uncover sparse, economically meaningful financial networks. By reformulating FEVD-based connectedness as a regression problem, we develop a model selection framework that consistently recovers the active set of spillover channels. We extend this method to generalized FEVDs to accommodate correlated shocks and introduce a data-driven procedure for tuning the penalty parameter using pseudo-out-of-sample forecast performance. Monte Carlo simulations demonstrate the approach's effectiveness with finite samples and its robustness to approximately sparse networks and heavy-tailed errors. Applications to global stock markets, S&P 500 sectoral indices, and commodity futures highlight the prevalence of sparse networks in empirical settings.",
      "authors": [
        "Fu Ouyang",
        "Thomas T. Yang",
        "Wenying Yao"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM"
      ],
      "published": "2026-01-07 05:29:18+00:00",
      "link": "https://arxiv.org/pdf/2601.03598v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05160v1",
      "title": "Revisiting the scale dependence of the Reynolds number in correlated fluctuating fluids",
      "abstract": "For the incompressible Navier--Stokes equation, the Reynolds number ($\\mathrm{Re}$) is a dimensionless parameter quantifying the relative importance of inertial over viscous forces. In the low-$\\mathrm{Re}$ regime ($\\mathrm{Re} \\ll 1$), the flow dynamics are commonly approximated by the linear Stokes equation. Here we show that, within the framework of spatially fluctuating hydrodynamics, this linearization breaks down when the thermal noise is spatially correlated, even if $\\mathrm{Re} \\ll 1$. We perform direct numerical simulations of spatially correlated fluctuating hydrodynamics in both one and two dimensions. In one dimension, the linearized dynamics exhibit significantly slower relaxation of high-wavenumber Fourier modes than the full nonlinear dynamics. In two dimensions, an analogous discrepancy arises in the particle velocity autocorrelation function, which decays more slowly in the correlated linear Stokes case than in the correlated nonlinear Navier--Stokes case. In both settings, spatial correlations inhibit viscous momentum diffusion at small scales, leading to prolonged relaxation under the linear dynamics, whereas nonlinear mode coupling accelerates small-scale relaxation. Thus, the interplay between nonlinear coupling and viscous damping becomes scale dependent, invalidating the use of a single global Reynolds number. Taken together, these findings show that, for spatially correlated fluctuating fluids, the effective Reynolds number must be reinterpreted as a scale-dependent quantity.",
      "authors": [
        "Sijie Huang",
        "Ayush Saurabh",
        "Steve Pressé"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "physics.bio-ph"
      ],
      "published": "2026-01-08 17:49:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05160v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04821v1",
      "title": "Bi-level Multi-criteria Optimization for Risk-informed Radiotherapy",
      "abstract": "In radiation therapy (RT) treatment planning, multi-criteria optimization (MCO) supports efficient plan selection but is usually solved for population-based dosimetric criteria and ignores patient-specific biological risk, potentially compromising outcomes in high-risk patients. We propose risk-guided MCO, a one-shot method that embeds a clinical risk model into conventional MCO, enabling interactive navigation between dosimetric and biological endpoints. The proposed algorithm uses a special order relation to fuse the classical MCO sandwiching algorithm with bi-level optimization, restricting the Pareto set to plans that achieve improvement in the secondary risk objective for user-defined, acceptable loss in primary clinical objectives. Thus, risk-guided MCO generates risk-optimized counterparts of clinical plans in a single run rather than by sequential or lexicographic planning. To assess the performance, we retrospectively analyzed 19 lung cancer patients treated with RT. The endpoint was the risk of grade 2+ radiation pneumonitis (RP), modeled using bootstrapped stepwise logistics regression with interaction terms, including baseline lung function, smoking history, and dosimetric factors. The risk-guided plans yielded a mean reduction of 8.0% in total lung V20 and 9.5% in right lung V5, translating into an average RP risk reduction of 7.7% (range=0.3%-20.1%), with small changes in target coverage (mean -1.2 D98[%] for CTV) and modest increase in heart dose (mean +1.74 Gy). This study presents the first proof-of-concept for integrating biological risk models directly within multi-criteria RT planning, enabling an interactive balance between established population-wide dose protocols and individualized outcome prediction. Our results demonstrate that the risk-informed MCO can reduce the risk of RP while maintaining target coverage.",
      "authors": [
        "Mara Schubert",
        "Katrin Teichert",
        "Zhongxing Liao",
        "Thomas Bortfeld",
        "Ali Ajdari"
      ],
      "primary_category": "physics.med-ph",
      "categories": [
        "physics.med-ph"
      ],
      "published": "2026-01-08 10:57:53+00:00",
      "link": "https://arxiv.org/pdf/2601.04821v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04735v1",
      "title": "sidmkit: A Reproducible Toolkit for SIDM Phenomenology and Galaxy Rotation-Curve Modeling",
      "abstract": "Self-interacting dark matter (SIDM) is a well-motivated extension of cold dark matter that can modify halo structure on galactic and group scales while remaining consistent with large-scale structure. However, practical SIDM work often requires bridging several layers, including microphysical scattering models, velocity-dependent effective cross sections, phenomenological astrophysical constraints, and (separately) data-driven halo fits, such as rotation curves. In this paper, we describe \\texttt{sidmkit}, a transparent and reproducible Python package designed to support SIDM ``micro$\\rightarrow$macro'' calculations and to provide a robust batch pipeline for fitting rotation curves in the SPARC data. On the SIDM side, \\texttt{sidmkit} implements velocity-dependent momentum-transfer cross sections for a Yukawa interaction using standard analytic approximations (Born, classical, and Hulthén-based) with a numerical partial-wave option for spot checks. It also provides consistent velocity-moment averaging for Maxwellian relative speeds, scattering-rate utilities, and curated literature \\emph{summary} constraints for regression tests and exploratory scans. On the rotation-curve side, we implement bounded non-linear least squares fits of NFW and Burkert halo models to SPARC baryonic decompositions, with optional mass-to-light priors and information-criterion summaries (AIC/BIC). For the demonstration dataset, we process 191 \\texttt{rotmod} galaxies (LTG+ETG bundles) and fit both NFW and Burkert models (382 total fits). We find that Burkert is preferred by $Δ\\mathrm{BIC} > 0$ for $65.4\\%$ of galaxies, with ``strong'' preference ($Δ\\mathrm{BIC}>6$) in $32.5\\%$ of galaxies;",
      "authors": [
        "Nalin Dhiman"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "physics.comp-ph"
      ],
      "published": "2026-01-08 08:56:56+00:00",
      "link": "https://arxiv.org/pdf/2601.04735v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04400v1",
      "title": "JAX-Shock: A Differentiable, GPU-Accelerated, Shock-Capturing Neural Solver for Compressible Flow Simulation",
      "abstract": "Understanding shock-solid interactions remains a central challenge in compressiblefluiddynamics. WepresentJAX-Shock: afully-differentiable,GPU-accelerated, high-order shock-capturing solver for efficient simulation of the compressible Navier-Stokes equations. Built entirely in JAX, the framework leverages automatic differentiation to enable gradient-based optimization, parameter inference, and end-to-end training of deep learning-augmented models. The solver integrates fifth-order WENO reconstruction with an HLLC flux to resolve shocks and discontinuities with high fidelity. To handle complex geometries, an immersed boundary method is implemented for accurate representation of solid interfaces within the compressible flow field. In addition, we introduce a neural flux module trained to augment the numerical fluxes with data-driven corrections, significantly improving accuracy and generalization. JAX-Shock also supports sequence-to-sequence learning for shock interaction prediction and reverse-mode inference to identify key physical parameters from data. Compared with purely data-driven approaches, JAX-Shock enhances generalization while preserving physical consistency. The framework establishes a flexible platform for differentiable physics, learning-based modeling, and inverse design in compressible flow regimes dominated by complex shock-solid interactions.",
      "authors": [
        "Bo Zhang"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-01-07 21:18:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04400v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04172v1",
      "title": "Stochastic Path Compression for Spectral Tensor Networks on Cyclic Graphs",
      "abstract": "We develop a new approach to compress cyclic tensor networks called stochastic path compression (SPC) that uses an iterative importance sampling procedure to target edges with large bond-dimensions. Closed random walks in SPC form compression pathways that spatially localize large bond-dimensions in the tensor network. Analogous to the phase separation of two immiscible liquids, SPC separates the graph of bond-dimensions into spatially distinct high and low density regions. When combined with our integral decimation algorithm, SPC facilitates the accurate compression of cyclic tensor networks with continuous degrees of freedom. To benchmark and illustrate the methods, we compute the absolute thermodynamics of $q$-state clock models on two-dimensional square lattices and an XY model on a Watts-Strogatz graph, which is a small-world network with random connectivity between spins.",
      "authors": [
        "Ryan T. Grimm",
        "Joel D. Eaves"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "physics.comp-ph"
      ],
      "published": "2026-01-07 18:39:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04172v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03964v1",
      "title": "Toward Quantum-Aware Machine Learning: Improved Prediction of Quantum Dissipative Dynamics via Complex Valued Neural Networks",
      "abstract": "Accurately modeling quantum dissipative dynamics remains challenging due to environmental complexity and non-Markovian memory effects. Although machine learning provides a promising alternative to conventional simulation techniques, most existing models employ real-valued neural networks (RVNNs) that inherently mismatch the complex-valued nature of quantum mechanics. By decoupling the real and imaginary parts of the density matrix, RVNNs can obscure essential amplitude-phase correlations, compromising physical consistency. Here, we introduce complex-valued neural networks (CVNNs) as a physics-consistent framework for learning quantum dissipative dynamics. CVNNs operate directly on complex-valued inputs, preserve the algebraic structure of quantum states, and naturally encode quantum coherences. Through numerical benchmarks on the spin-boson model and several variants of the Fenna-Matthews-Olson complex, we demonstrate that CVNNs outperform RVNNs in convergence speed, training stability, and physical fidelity -- including significantly improved trace conservation and Hermiticity. These advantages increase with system size and coherence complexity, establishing CVNNs as a robust, scalable, quantum-aware classical approach for simulating open quantum systems in the pre-fault-tolerant quantum era.",
      "authors": [
        "Muhammad Atif",
        "Arif Ullah",
        "Ming Yang"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph"
      ],
      "published": "2026-01-07 14:26:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03964v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03922v1",
      "title": "Integration and Resource Estimation of Cryoelectronics for Superconducting Fault-Tolerant Quantum Computers",
      "abstract": "Scaling superconducting quantum computers to the fault-tolerant regime calls for a commensurate scaling of the classical control and readout stack. Today's systems largely rely on room-temperature, rack-based instrumentation connected to dilution-refrigerator cryostats through many coaxial cables. Looking ahead, superconducting fault-tolerant quantum computers (FTQCs) will likely adopt a heterogeneous quantum-classical architecture that places selected electronics at cryogenic stages -- for example, cryo-CMOS at 4~K and superconducting digital logic at 4~K and/or mK stages -- to curb wiring and thermal-load overheads. This review distills key requirements, surveys representative room-temperature and cryogenic approaches, and provides a transparent first-order accounting framework for cryoelectronics. Using an RSA-2048-scale benchmark as a concrete reference point, we illustrate how scaling targets motivate constraints on multiplexing and stage-wise cryogenic power, and discuss implications for functional partitioning across room-temperature electronics, cryo-CMOS, and superconducting logic.",
      "authors": [
        "Shiro Kawabata"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.mes-hall",
        "cond-mat.supr-con",
        "physics.app-ph"
      ],
      "published": "2026-01-07 13:42:21+00:00",
      "link": "https://arxiv.org/pdf/2601.03922v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03870v1",
      "title": "Turbulence demonstrates height variations in closely spaced deep-sea mooring lines",
      "abstract": "It may be important to precisely know heights of moored oceanographic instrumentation. For example, moorings can be closely spaced or accidentally be located on small rocks or in small gullies. Height variations O(1 m) will yield registration of different values when conditions such as small-scale density stratification vary strongly. Such little height variations may prove difficult to measure in the deep sea, requiring high-accuracy pressure sensors preferably on all instruments in a mooring-array. In this paper, an alternative method for relative height determination is presented using high-resolution temperature sensors moored on multiple densely-spaced lines in the deep Western Mediterranean. While it was anticipated that height variations between lines could be detected under near-homogeneous conditions via adiabatic lapse rate O(0.0001degrC m-1) by the 0.00003degrC-noise-level sensors, such was prevented by the impossibility of properly correcting for short-term bias due to electronic drift. Instead, a satisfactory height determination was found during a period of relatively strong stratification and large turbulence activity. By band-pass filtering data of the highest-resolved turbulent motions across the strongest temperature gradient, significant height variations were detectable to within +/-0.2 m.",
      "authors": [
        "Hans van Haren"
      ],
      "primary_category": "physics.ao-ph",
      "categories": [
        "physics.ao-ph"
      ],
      "published": "2026-01-07 12:32:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03870v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03830v1",
      "title": "DeepBessel: deep learning-based full-field vibration profilometry using single-shot time-averaged interference microscopy",
      "abstract": "Full-field vibration profilometry is essential for dynamic characterizing microelectromechanical systems (MEMS/MOEMS). Time-averaged interferometry (TAI) encodes spatial information about MEMS or MOEMS vibration amplitude in the interferogram's amplitude modulation using Bessel function (besselogram). Classical approaches for interferogram analysis are specialized for cosine function fringe patterns and therefore introduce reconstruction errors for besselogram decoding. This paper presents the DeepBessel: a deep learning-based approach for single-shot TAI interferogram analysis. A convolutional neural network (CNN) was trained using synthetic data, where the input consisted of besselograms, and the output corresponded to the underlying vibration amplitude distribution. Numerical validation and experimental testing demonstrated that DeepBessel significantly reduces reconstruction errors compared to the state-of-the-art approaches, e.g., Hilbert Spiral Transform (HST) method. The proposed network effectively mitigates errors caused by the mismatch between the Bessel and cosine functions. The results indicate that deep learning can improve the accuracy of full-field vibration measurements, offering new possibilities for optical metrology in MEMS or MOEMS applications.",
      "authors": [
        "Maria Cywinska",
        "Wiktor Forjasz",
        "Emilia Wdowiak",
        "Michal Jozwik",
        "Adam Styk",
        "Krzysztof Patorski",
        "Maciej Trusiak"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-01-07 11:49:37+00:00",
      "link": "https://arxiv.org/pdf/2601.03830v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03613v1",
      "title": "PhysicsFormer: An Efficient and Fast Attention-Based Physics Informed Neural Network for Solving Incompressible Navier Stokes Equations",
      "abstract": "Traditional experimental and numerical approaches for fluid dynamics problems often suffer from high computational cost, mesh sensitivity, and limited capability in capturing complex physical behaviors. Moreover, conventional physics-informed neural networks (PINNs) frequently struggle in chaotic and highly unsteady flow regimes. In this work, we propose \\textit{PhysicsFormer}, a fast and efficient transformer-based physics-informed framework that incorporates multi-head encoder-decoder cross-attention. Unlike multilayer perceptron-based PINNs, PhysicsFormer operates on sequential representations constructed from spatio-temporal data, enabling effective learning of long-range temporal dependencies and improved propagation of initial condition information. A data-embedding strategy is employed to convert spatio-temporal points into pseudo-sequences, while a dynamics-weighted loss function replaces the standard PINNs formulation. Owing to its parallel learning structure, PhysicsFormer demonstrates superior computational efficiency compared to existing transformer-based approaches. The framework is validated on Burgers' equation and flow reconstruction governed by the Navier-Stokes equations, achieving mean squared errors on the order of $10^{-6}$. In addition, an inverse problem involving parameter identification in the two-dimensional incompressible Navier-Stokes equations is investigated. For clean data, PhysicsFormer achieves zero identification error for both $λ_1$ and $λ_2$; under $1\\%$ Gaussian noise, the errors are $0.07\\%$ for $λ_1$ and $0\\%$ for $λ_2$. These results demonstrate that PhysicsFormer provides a reliable and computationally efficient surrogate modeling framework for time-dependent fluid flow problems.",
      "authors": [
        "Biswanath Barman",
        "Debdeep Chatterjee",
        "Rajendra K. Ray"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-01-07 05:41:50+00:00",
      "link": "https://arxiv.org/pdf/2601.03613v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03591v1",
      "title": "Interplay of activity and non-reciprocity in tracer dynamics: From non-equilibrium fluctuation-dissipation to giant diffusion",
      "abstract": "Non-reciprocal interactions play a key role in shaping transport in active and passive systems, giving rise to striking nonequilibrium behavior. Here, we study the dynamics of a tracer -- active or passive -- embedded in a bath of active or passive particles, coupled through non-reciprocal interactions. Starting from the microscopic stochastic dynamics of the full system, we derive an overdamped generalized Langevin equation for the tracer, incorporating a non-Markovian memory kernel that captures bath-mediated correlations. This framework enables us to compute the tracer's velocity and displacement response, derive a generalized nonequilibrium fluctuation-dissipation relation that quantifies deviations from equilibrium behavior, and determine the mean-squared displacement (MSD). We find that while the MSD becomes asymptotically diffusive, the effective diffusivity depends non-monotonically on the degree of non-reciprocity and diverges at an intermediate value. This regime of giant diffusivity provides a generic mechanism for enhanced transport in active soft matter and has direct implications for biological systems exhibiting chase-and-run or predator-prey interactions. Our analytical predictions are supported by numerical simulations of active Brownian particles, highlighting experimentally accessible signatures of non-reciprocal interactions in soft matter.",
      "authors": [
        "Subhajit Paul",
        "Debasish Chaudhuri"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "cond-mat.soft",
        "physics.bio-ph"
      ],
      "published": "2026-01-07 05:21:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03591v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04755v1",
      "title": "Scalable Dielectric Tensor Predictions for Inorganic Materials using Equivariant Graph Neural Networks",
      "abstract": "Accurate prediction of dielectric tensors is essential for accelerating the discovery of next-generation inorganic dielectric materials. Existing machine learning approaches, such as equivariant graph neural networks, typically rely on specially-designed network architectures to enforce O(3) equivariance. However, to preserve equivariance, these specially-designed models restrict the update of equivariant features during message passing to linear transformations or gated equivariant nonlinearities. The inability to implicitly characterize more complex nonlinear structures may reduce the predictive accuracy of the model. In this study, we introduce a frame-averaging-based approach to achieve equivariant dielectric tensor prediction. We propose GoeCTP, an O(3)-equivariant framework that predicts dielectric tensors without imposing any structural restrictions on the backbone network. We benchmark its performance against several state-of-the-art models and further employ it for large-scale virtual screening of thermodynamically stable materials from the Materials Project database. GoeCTP successfully identifies various promising candidates, such as Zr(InBr$_3$)$_2$ (band gap $E_g = 2.41$ eV, dielectric constant $\\overline{\\varepsilon} = 194.72$) and SeI$_2$ (anisotropy ratio $α_r = 96.763$), demonstrating its accuracy and efficiency in accelerating the discovery of advanced inorganic dielectric materials.",
      "authors": [
        "Haowei Hua",
        "Chen Liang",
        "Ding Pan",
        "Shengchao Liu",
        "Irwin King",
        "Koji Tsuda",
        "Wanyu Lin"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-08 09:20:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04755v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04702v1",
      "title": "Chaos in high-dimensional dynamical systems with tunable non-reciprocity",
      "abstract": "High-dimensional dynamical systems of interacting degrees of freedom are ubiquitous in the study of complex systems. When the directed interactions are totally uncorrelated, sufficiently strong and non-linear, many of these systems exhibit a chaotic attractor characterized by a positive maximal Lyapunov exponent (MLE). On the contrary, when the interactions are completely symmetric, the dynamics takes the form of a gradient descent on a carefully defined cost function, and it exhibits slow dynamics and aging. In this work, we consider the intermediate case in which the interactions are partially symmetric, with a parameter α tuning the degree of non-reciprocity. We show that for any value of α for which the corresponding system has non-reciprocal interactions, the dynamics lands on a chaotic attractor. Correspondingly, the MLE is a non-monotonous function of the degree of non-reciprocity. This implies that conservative forcing deriving from the gradient field of a rough energy landscape can make the system more chaotic.",
      "authors": [
        "Samantha Fournier",
        "Pierfrancesco Urbani"
      ],
      "primary_category": "cond-mat.dis-nn",
      "categories": [
        "cond-mat.dis-nn"
      ],
      "published": "2026-01-08 08:13:25+00:00",
      "link": "https://arxiv.org/pdf/2601.04702v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04640v1",
      "title": "Construction of asymptotic quantum many-body scar states in the SU($N$) Hubbard model",
      "abstract": "We construct asymptotic quantum many-body scars (AQMBS) in one-dimensional SU($N$) Hubbard chains ($N\\geq 3$) by embedding the scar subspace into an auxiliary Hilbert subspace $\\mathcal{H}_P$ and identifying a parent Hamiltonian within it, together with a corresponding extension of the restricted spectrum-generating algebra to the multi-ladder case. Unlike previous applications of the parent-Hamiltonian scheme, we show that the parent Hamiltonian becomes the SU($N$) ferromagnetic Heisenberg model rather than the spin-1/2 case, so that its gapless magnons realize explicit AQMBS of the original model. Working in the doublon-holon subspace, we derive this mapping, obtain the one-magnon dispersion for periodic and open boundaries, and prove (i) orthogonality to the tower of scar states, (ii) vanishing energy variance in the thermodynamic limit, and (iii) subvolume entanglement entropy with rigorous MPS/MPO bounds. Our results broaden the parent-Hamiltonian family for AQMBS beyond spin-1/2 and provide analytic, low-entanglement excitations in SU($N$)-symmetric systems.",
      "authors": [
        "Daiki Hashimoto",
        "Masaya Kunimi",
        "Tetsuro Nikuni"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech"
      ],
      "published": "2026-01-08 06:21:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04640v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04345v1",
      "title": "Scalable cold-atom quantum simulator of a $3+1$D U$(1)$ lattice gauge theory with dynamical matter",
      "abstract": "The stated overarching goal of the highly active field of quantum simulation of high-energy physics (HEP) is to achieve the capability to study \\textit{ab-initio} real-time microscopic dynamics of $3+1$D quantum chromodynamics (QCD). However, existing experimental realizations and theoretical proposals for future ones have remained restricted to one or two spatial dimensions. Here, we take a big step towards this goal by proposing a concrete experimentally feasible scalable cold-atom quantum simulator of a U$(1)$ quantum link model of quantum electrodynamics (QED) in three spatial dimensions, employing \\textit{linear gauge protection} to stabilize gauge invariance. Using tree tensor network simulations, we benchmark the performance of this quantum simulator through near- and far-from-equilibrium observables, showing excellent agreement with the ideal gauge theory. Additionally, we introduce a method for \\textit{analog quantum error mitigation} that accounts for unwanted first-order tunneling processes, vastly improving agreement between quantum-simulator and ideal-gauge-theory results. Our findings pave the way towards realistic quantum simulators of $3+1$D lattice gauge theories that can probe regimes well beyond classical simulability.",
      "authors": [
        "Simone Orlando",
        "Guo-Xian Su",
        "Bing Yang",
        "Jad C. Halimeh"
      ],
      "primary_category": "cond-mat.quant-gas",
      "categories": [
        "cond-mat.quant-gas",
        "hep-lat",
        "quant-ph"
      ],
      "published": "2026-01-07 19:32:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04345v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03933v1",
      "title": "Material exploration through active learning -- METAL",
      "abstract": "The discovery and design of new materials are paramount in the development of green technologies. High entropy oxides represent one such group that has only been tentatively explored, mainly due to the inherent problem of navigating vast compositional spaces. Thanks to the emergence of machine learning, however, suitable tools are now readily available. Here, the task of finding oxygen carriers for chemical looping processes has been tackled by leveraging active learning-based strategies combined with first-principles calculations. High efficiency and efficacy have, moreover, been achieved by exploiting the power of recently developed machine learning interatomic potentials. Firstly, the proposed approaches were validated based on an established computational framework for identifying high entropy perovskites that can be used in chemical looping air separation and dry reforming. Chief among the insights thus gained was the identification of the best performing strategies, in the form of greedy or Thompson-based sampling based on uncertainty estimates obtained from Gaussian processes. Building on this newfound knowledge, the concept was applied to a more complex problem, namely the discovery of high entropy oxygen carriers for chemical looping oxygen uncoupling. This resulted in both qualitative as well as quantitative outcomes, including lists of specific materials with high oxygen transfer capacities and configurational entropies. Specifically, the best candidates were based on the known oxygen carrier CaMnO3 but also contained a variety of additional species, of which some, e.g., Ti; Co; Cu; and Ti, were expected while others were not, e.g., Y and Sm. The results suggest that adopting active learning approaches is critical in materials discovery, given that these methods are already shifting research practice and soon will be the norm.",
      "authors": [
        "Joakim Brorsson",
        "Henrik Klein Moberg",
        "Joel Hildingsson",
        "Jonatan Gastaldi",
        "Tobias Mattisson",
        "Anders Hellman"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-07 13:52:11+00:00",
      "link": "https://arxiv.org/pdf/2601.03933v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04106v1",
      "title": "Effect of event classification on the Tsallis-thermometer",
      "abstract": "We analyze identified hadron spectra in pp collisions at $\\sqrt{s} = 13$ TeV measured by ALICE within a non-extensive statistical framework. Spectra classified by multiplicity, flattenicity, and spherocity were fitted with the Tsallis-Pareto distribution, and the parameters were studied on the Tsallis-thermometer. Multiplicity and flattenicity classes follow a previously observed scaling, while the non-extensivity parameter shows a distinct sensitivity to the spherocity. A data-driven parametrization confirms a proportionality between the Tsallis temperature and mean transverse momentum, offering a simple estimate of the effective temperature. These results highlight the ability of the Tsallis-thermometer to capture both multiplicity and event-shape effects, linking soft and hard processes in small systems.",
      "authors": [
        "Laszlo Gyulai",
        "Gabor Biro",
        "Robert Vertesi",
        "Gergely Gabor Barnafoldi"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-01-07 17:11:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04106v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03912v1",
      "title": "Beyond Form Factors: Precise Angular Tests in Hadronic $τ$ Decays",
      "abstract": "Semileptonic $τ$ decays mainly proceed via interactions between charged lepton and quark currents. The hadronization of the quark current is intrinsically nonperturbative and generally cannot be addressed analytically. In these proceedings, we propose using symmetry arguments alone to construct clean angular observables, which, within the Standard Model and in the absence of long-distance electromagnetic corrections, remain form-factor independent. These predictions can be experimentally tested, and any observed deviation could signal either effects of physics beyond the Standard Model or provide a clean benchmark for long-distance electromagnetic corrections. We also perform a first estimate of the expected impact of new physics in an EFT framework.",
      "authors": [
        "E. Estrada",
        "E. Passemar",
        "S. Paz",
        "A. Rodríguez-Sánchez",
        "P. Roig"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-ex"
      ],
      "published": "2026-01-07 13:26:27+00:00",
      "link": "https://arxiv.org/pdf/2601.03912v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04290v1",
      "title": "A Relativistic MOND",
      "abstract": "We present a minimal relativistic completion of MOND in which (i) General Relativity is recovered exactly in the high-acceleration regime, while (ii) the Bekenstein--Milgrom (AQUAL) equation emerges in the low-acceleration regime, without introducing additional propagating fields beyond those already present in a right-handed gauge sector. The construction is motivated by an $E_6\\times E_6$ framework in which $SU(3)_R\\rightarrow SU(2)_R\\times U(1)_{Y'}\\rightarrow U(1)_{\\rm dem}$, leaving a healthy repulsive $U(1)_{\\rm dem}$ interaction whose charge is the square-root mass label. Gravity itself arises from the $SU(2)_R$ connection via a Plebanski/MacDowell--Mansouri mechanism, yielding an emergent tetrad and the Einstein--Hilbert action. MOND is implemented by an infrared (IR) metric deformation $ΔS_{\\rm IR}[g]$ that is UV-vanishing (so GR is recovered) while its deep-MOND/static limit is fixed by a symmetry principle: in three spatial dimensions, the deep-MOND action is conformally invariant with a 10-parameter group isomorphic to $SO(4,1)$ (the de Sitter group). The single MOND acceleration scale is set by a de Sitter radius selected dynamically in the IR, $a_0=c^2/(ξ\\,\\ell_{\\rm dS})$ with $ξ={ O}(1)$ fixed by matching to the static limit. MOND resides in perturbations and quasistatic systems; the homogeneous FRW background is controlled by the IR vacuum kinematics rather than an ad hoc cosmological constant.",
      "authors": [
        "Tejinder P. Singh"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "astro-ph.CO",
        "astro-ph.GA"
      ],
      "published": "2026-01-07 15:08:50+00:00",
      "link": "https://arxiv.org/pdf/2601.04290v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05203v1",
      "title": "Symbolically regressing dark matter halo profiles using weak lensing",
      "abstract": "The structure of dark matter haloes is often described by radial density profiles motivated by cosmological simulations. These are typically assumed to have a fixed functional form (e.g. NFW), with some free parameters that can be constrained with observations. However, relying on simulations has the disadvantage that the resulting profiles depend on the dark matter model and the baryonic physics implementation, which are highly uncertain. Instead, we present a method to constrain halo density profiles directly from observations. This is done using a symbolic regression algorithm called Exhaustive Symbolic Regression (ESR). ESR searches for the optimal analytic expression to fit data, combining both accuracy and simplicity. We apply ESR to a sample of 149 galaxy clusters from the HSC-XXL survey to identify which functional forms perform best across the entire sample of clusters. We identify density profiles that statistically outperform NFW under a minimum-description-length criterion. Within the radial range probed by the weak-lensing data ($R \\sim 0.3 - 3$ h$^{-1}$ Mpc), the highest-ranked ESR profiles exhibit shallow inner behaviour and a maximum in the density profile. As a practical application, we show how the best-fitting ESR models can be used to obtain enclosed mass estimates. We find masses that are, on average, higher than those derived using NFW, highlighting a source of potential bias when assuming the wrong density profile. These results have important knock-on effects for analyses that utilise clusters, for example cosmological constraints on $σ_8$ and $Ω_m$ from cluster abundance and clustering. Beyond the HSC dataset, the method is readily applicable to any data constraining the dark matter distribution in galaxies and galaxy clusters, such as other weak lensing surveys, galactic rotation curves, or complementary probes.",
      "authors": [
        "Alicia Martín",
        "Tariq Yasin",
        "Deaglan J. Bartlett",
        "Harry Desmond",
        "Pedro G. Ferreira"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "astro-ph.GA"
      ],
      "published": "2026-01-08 18:26:43+00:00",
      "link": "https://arxiv.org/pdf/2601.05203v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04939v1",
      "title": "Multi-Messenger Studies with High-Energy Neutrinos and Gamma Rays: The WST Opportunity",
      "abstract": "The search for the sources of ultra-high-energy cosmic rays (UHECRs) using high-energy neutrinos represents a frontier in high-energy astrophysics. However, a critical bottleneck remains: the ability to rapidly survey the sizable sky areas defined by the localization uncertainties of neutrino detectors and to provide rapid spectroscopic classification of the multitude of optical transients found within them.   By deploying a large field-of-view with high-multiplex Multi-Object Spectroscopy (MOS) on a large aperture telescope, one can instantaneously cover neutrino error circles, thus providing crucial spectroscopic classifications of potential counterparts discovered, for example, by the Vera C. Rubin Observatory (LSST) with unprecedented efficiency. Furthermore, simultaneous operation of a giant panoramic central Integral Field Spectrograph (IFS) would allow for detailed kinematic and environmental characterization of primary candidates. This facility would unlock deep synergies between next-generation neutrino telescopes (IceCube-Gen2, KM3NeT) and gamma-ray observatories (CTAO), transforming unique multi-messenger alerts into a comprehensive physical understanding.",
      "authors": [
        "Fabian Schüssler",
        "Sofia Bisero",
        "Bernardo Cornejo",
        "Filippo D'Ammando",
        "Richard I. Anderson",
        "Ilja Jaroschewski",
        "Silvia Piranomonte",
        "Fatemeh Zahra Majid"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.HE"
      ],
      "published": "2026-01-08 13:43:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04939v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04773v1",
      "title": "Optimization of Deep Learning Models for Radio Galaxy Classification",
      "abstract": "Modern radio telescope surveys, capable of detecting billions of galaxies in wide-field surveys, have made manual morphological classification impracticable. This applies in particular when the Square Kilometre Array Observatory (SKAO) becomes operable in 2027, which is expected to close an important gap in our understanding of the Epoch of Reionization (EoR) and other areas of astrophysics. To this end, foreground objects, contaminants of the 21-cm signal, need to be identified and subtracted. Source finding and identification is thus an important albeit challenging task. We investigate the ability of AI and deep learning (DL) methods that have been previously trained on other data domains to localize and classify radio galaxies with minimal changes to their architectures. Various well-known pretrained neural network architectures for image classification and object detection are trained and fine-tuned and their performance is evaluated on a public radio galaxy dataset derived from the Radio Galaxy Zoo. A comparison between convolutional neural network (CNN)- and transformer-based algorithms is performed. The best performing architecture is systematically optimized and an uncertainty estimation is performed by means of an ensemble analysis. Radio source classification performance nearly comparable to the current leading customized models can be obtained using existing standard pretrained DL architectures, without modification and increase in complexity of the model architectures but rather adaptation of the data, by combining various transformations on replicated image channels. Using an ensemble of models can also further improve performance to over 90% accuracy, on par with top-performing models in the literature. The results can be transferred to other survey data, e.g. from the Murchison Wide-field Array (MWA), and in the future be used to study the EoR with the SKAO.",
      "authors": [
        "Philipp Denzel",
        "Manuel Weiss",
        "Elena Gavagnin",
        "Frank-Peter Schilling"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-01-08 09:55:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04773v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04552v1",
      "title": "Studies in Astronomical Time Series Analysis: The Double Lomb-Scargle Periodogram and Super Resolution",
      "abstract": "Multiple-frequency periodograms -- based on time series models consisting of two or more independent sinusoids -- have long been discussed. What is new here is the presentation of a practical, simple-to-use computational framework implementing this concept. Our algorithms have super resolution that evades the Rayleigh criterion, as well as provision for statistical weighting and tapering. They can be used for essentially any time series (e.g. time-tagged events or point measurements) with arbitrary sampling -- even or uneven. Examples of super resolution of synthetic data, sunspot numbers, and the rich pulsations of white dwarf J0135+5722, demonstrate practical applications. Appendices derive generalized periodograms using an arbitrary number of arbitrary basis functions (following Bretthorst, 1988)and define several examples of non-sinusoidal bases for these ``omnigrams.'' Application beyond the frequency domain is demonstrated with an autoregressive model exhibiting super resolution in the time domain. A GitHub repository containing omnigram code, and symbolic algebra scripts for generating it, will soon be available.",
      "authors": [
        "Jeffrey D. Scargle",
        "Sarah Wagner"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-01-08 03:29:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04552v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04032v1",
      "title": "Two-source terrestrial planet formation with a sweeping secular resonance",
      "abstract": "The models that most successfully reproduce the orbital architecture of the Solar System terrestrial planets start from a narrow annulus of material that grows into embryos and then planets. However, it is not clear how this ring model can be made consistent with the chemical structure of the inner Solar System, which shows a reduced-to-oxidized gradient from Mercury to Mars and a parallel gradient in the asteroid belt. We propose that there were two primary reservoirs in the early inner Solar System: a narrow, refractory enriched ring inside of 1 au, and a less massive, extended planetesimal disk outside of 1 au with oxidation states ranging from enstatite chondrites to ordinary chondrites. We show through a suite of N-body simulations that an inwardly sweeping secular resonance, caused by aerodynamic drag and perturbations from a mean-motion resonant Jupiter and Saturn, gathers the outer planetesimal disk into a narrow ring that migrates radially, forms Mars, and contributes oxidized material to proto-Earth. Remaining unaccreted planetesimals can be implanted into the asteroid belt as the parent bodies of aubrites and non-carbonaceous iron meteorites, while the most reduced material is not implanted and thus unsampled in the meteorite collection. This model explains the oxidation and isotopic gradients within the inner Solar System within the context of a low-viscosity, magnetic wind-driven disk.",
      "authors": [
        "Max Goldberg",
        "David Nesvorný",
        "Alessandro Morbidelli"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP"
      ],
      "published": "2026-01-07 15:47:09+00:00",
      "link": "https://arxiv.org/pdf/2601.04032v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05047v1",
      "title": "Challenges and Research Directions for Large Language Model Inference Hardware",
      "abstract": "Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup communication. While our focus is datacenter AI, we also review their applicability for mobile devices.",
      "authors": [
        "Xiaoyu Ma",
        "David Patterson"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 15:52:11+00:00",
      "link": "https://arxiv.org/pdf/2601.05047v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05038v1",
      "title": "ArcAligner: Adaptive Recursive Aligner for Compressed Context Embeddings in RAG",
      "abstract": "Retrieval-Augmented Generation (RAG) helps LLMs stay accurate, but feeding long documents into a prompt makes the model slow and expensive. This has motivated context compression, ranging from token pruning and summarization to embedding-based compression. While researchers have tried ''compressing'' these documents into smaller summaries or mathematical embeddings, there is a catch: the more you compress the data, the more the LLM struggles to understand it. To address this challenge, we propose ArcAligner (Adaptive recursive context *Aligner*), a lightweight module integrated into the language model layers to help the model better utilize highly compressed context representations for downstream generation. It uses an adaptive ''gating'' system that only adds extra processing power when the information is complex, keeping the system fast. Across knowledge-intensive QA benchmarks, ArcAligner consistently beats compression baselines at comparable compression rates, especially on multi-hop and long-tail settings. The source code is publicly available.",
      "authors": [
        "Jianbo Li",
        "Yi Jiang",
        "Sendong Zhao",
        "Bairui Hu",
        "Haochun Wang",
        "Bing Qin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 15:44:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05038v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05027v1",
      "title": "OptiSet: Unified Optimizing Set Selection and Ranking for Retrieval-Augmented Generation",
      "abstract": "Retrieval-Augmented Generation (RAG) improves generation quality by incorporating evidence retrieved from large external corpora. However, most existing methods rely on statically selecting top-k passages based on individual relevance, which fails to exploit combinatorial gains among passages and often introduces substantial redundancy. To address this limitation, we propose OptiSet, a set-centric framework that unifies set selection and set-level ranking for RAG. OptiSet adopts an \"Expand-then-Refine\" paradigm: it first expands a query into multiple perspectives to enable a diverse candidate pool and then refines the candidate pool via re-selection to form a compact evidence set. We then devise a self-synthesis strategy without strong LLM supervision to derive preference labels from the set conditional utility changes of the generator, thereby identifying complementary and redundant evidence. Finally, we introduce a set-list wise training strategy that jointly optimizes set selection and set-level ranking, enabling the model to favor compact, high-gain evidence sets. Extensive experiments demonstrate that OptiSet improves performance on complex combinatorial problems and makes generation more efficient. The source code is publicly available.",
      "authors": [
        "Yi Jiang",
        "Sendong Zhao",
        "Jianbo Li",
        "Bairui Hu",
        "Yanrui Du",
        "Haochun Wang",
        "Bing Qin"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 15:35:01+00:00",
      "link": "https://arxiv.org/pdf/2601.05027v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05017v1",
      "title": "HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference",
      "abstract": "Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.",
      "authors": [
        "Xiaopeng Luo",
        "Zexi Tan",
        "Zhuowei Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 15:18:36+00:00",
      "link": "https://arxiv.org/pdf/2601.05017v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05016v1",
      "title": "From Idea to Co-Creation: A Planner-Actor-Critic Framework for Agent Augmented 3D Modeling",
      "abstract": "We present a framework that extends the Actor-Critic architecture to creative 3D modeling through multi-agent self-reflection and human-in-the-loop supervision. While existing approaches rely on single-prompt agents that directly execute modeling commands via tools like Blender MCP, our approach introduces a Planner-Actor-Critic architecture. In this design, the Planner coordinates modeling steps, the Actor executes them, and the Critic provides iterative feedback, while human users act as supervisors and advisors throughout the process. Through systematic comparison between single-prompt modeling and our reflective multi-agent approach, we demonstrate improvements in geometric accuracy, aesthetic quality, and task completion rates across diverse 3D modeling scenarios. Our evaluation reveals that critic-guided reflection, combined with human supervisory input, reduces modeling errors and increases complexity and quality of the result compared to direct single-prompt execution. This work establishes that structured agent self-reflection, when augmented by human oversight and advisory guidance, produces higher-quality 3D models while maintaining efficient workflow integration through real-time Blender synchronization.",
      "authors": [
        "Jin Gao",
        "Saichandu Juluri"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GR",
        "cs.HC"
      ],
      "published": "2026-01-08 15:18:12+00:00",
      "link": "https://arxiv.org/pdf/2601.05016v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05014v1",
      "title": "The RoboSense Challenge: Sense Anything, Navigate Anywhere, Adapt Across Platforms",
      "abstract": "Autonomous systems are increasingly deployed in open and dynamic environments -- from city streets to aerial and indoor spaces -- where perception models must remain reliable under sensor noise, environmental variation, and platform shifts. However, even state-of-the-art methods often degrade under unseen conditions, highlighting the need for robust and generalizable robot sensing. The RoboSense 2025 Challenge is designed to advance robustness and adaptability in robot perception across diverse sensing scenarios. It unifies five complementary research tracks spanning language-grounded decision making, socially compliant navigation, sensor configuration generalization, cross-view and cross-modal correspondence, and cross-platform 3D perception. Together, these tasks form a comprehensive benchmark for evaluating real-world sensing reliability under domain shifts, sensor failures, and platform discrepancies. RoboSense 2025 provides standardized datasets, baseline models, and unified evaluation protocols, enabling large-scale and reproducible comparison of robust perception methods. The challenge attracted 143 teams from 85 institutions across 16 countries, reflecting broad community engagement. By consolidating insights from 23 winning solutions, this report highlights emerging methodological trends, shared design principles, and open challenges across all tracks, marking a step toward building robots that can sense reliably, act robustly, and adapt across platforms in real-world environments.",
      "authors": [
        "Lingdong Kong",
        "Shaoyuan Xie",
        "Zeying Gong",
        "Ye Li",
        "Meng Chu",
        "Ao Liang",
        "Yuhao Dong",
        "Tianshuai Hu",
        "Ronghe Qiu",
        "Rong Li",
        "Hanjiang Hu",
        "Dongyue Lu",
        "Wei Yin",
        "Wenhao Ding",
        "Linfeng Li",
        "Hang Song",
        "Wenwei Zhang",
        "Yuexin Ma",
        "Junwei Liang",
        "Zhedong Zheng",
        "Lai Xing Ng",
        "Benoit R. Cottereau",
        "Wei Tsang Ooi",
        "Ziwei Liu",
        "Zhanpeng Zhang",
        "Weichao Qiu",
        "Wei Zhang",
        "Ji Ao",
        "Jiangpeng Zheng",
        "Siyu Wang",
        "Guang Yang",
        "Zihao Zhang",
        "Yu Zhong",
        "Enzhu Gao",
        "Xinhan Zheng",
        "Xueting Wang",
        "Shouming Li",
        "Yunkai Gao",
        "Siming Lan",
        "Mingfei Han",
        "Xing Hu",
        "Dusan Malic",
        "Christian Fruhwirth-Reisinger",
        "Alexander Prutsch",
        "Wei Lin",
        "Samuel Schulter",
        "Horst Possegger",
        "Linfeng Li",
        "Jian Zhao",
        "Zepeng Yang",
        "Yuhang Song",
        "Bojun Lin",
        "Tianle Zhang",
        "Yuchen Yuan",
        "Chi Zhang",
        "Xuelong Li",
        "Youngseok Kim",
        "Sihwan Hwang",
        "Hyeonjun Jeong",
        "Aodi Wu",
        "Xubo Luo",
        "Erjia Xiao",
        "Lingfeng Zhang",
        "Yingbo Tang",
        "Hao Cheng",
        "Renjing Xu",
        "Wenbo Ding",
        "Lei Zhou",
        "Long Chen",
        "Hangjun Ye",
        "Xiaoshuai Hao",
        "Shuangzhi Li",
        "Junlong Shen",
        "Xingyu Li",
        "Hao Ruan",
        "Jinliang Lin",
        "Zhiming Luo",
        "Yu Zang",
        "Cheng Wang",
        "Hanshi Wang",
        "Xijie Gong",
        "Yixiang Yang",
        "Qianli Ma",
        "Zhipeng Zhang",
        "Wenxiang Shi",
        "Jingmeng Zhou",
        "Weijun Zeng",
        "Kexin Xu",
        "Yuchen Zhang",
        "Haoxiang Fu",
        "Ruibin Hu",
        "Yanbiao Ma",
        "Xiyan Feng",
        "Wenbo Zhang",
        "Lu Zhang",
        "Yunzhi Zhuge",
        "Huchuan Lu",
        "You He",
        "Seungjun Yu",
        "Junsung Park",
        "Youngsun Lim",
        "Hyunjung Shim",
        "Faduo Liang",
        "Zihang Wang",
        "Yiming Peng",
        "Guanyu Zong",
        "Xu Li",
        "Binghao Wang",
        "Hao Wei",
        "Yongxin Ma",
        "Yunke Shi",
        "Shuaipeng Liu",
        "Dong Kong",
        "Yongchun Lin",
        "Huitong Yang",
        "Liang Lei",
        "Haoang Li",
        "Xinliang Zhang",
        "Zhiyong Wang",
        "Xiaofeng Wang",
        "Yuxia Fu",
        "Yadan Luo",
        "Djamahl Etchegaray",
        "Yang Li",
        "Congfei Li",
        "Yuxiang Sun",
        "Wenkai Zhu",
        "Wang Xu",
        "Linru Li",
        "Longjie Liao",
        "Jun Yan",
        "Benwu Wang",
        "Xueliang Ren",
        "Xiaoyu Yue",
        "Jixian Zheng",
        "Jinfeng Wu",
        "Shurui Qin",
        "Wei Cong",
        "Yao He"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 15:16:18+00:00",
      "link": "https://arxiv.org/pdf/2601.05014v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05009v1",
      "title": "An Empirical Investigation of Robustness in Large Language Models under Tabular Distortions",
      "abstract": "We investigate how large language models (LLMs) fail when tabular data in an otherwise canonical representation is subjected to semantic and structural distortions. Our findings reveal that LLMs lack an inherent ability to detect and correct subtle distortions in table representations. Only when provided with an explicit prior, via a system prompt, do models partially adjust their reasoning strategies and correct some distortions, though not consistently or completely. To study this phenomenon, we introduce a small, expert-curated dataset that explicitly evaluates LLMs on table question answering (TQA) tasks requiring an additional error-correction step prior to analysis. Our results reveal systematic differences in how LLMs ingest and interpret tabular information under distortion, with even SoTA models such as GPT-5.2 model exhibiting a drop of minimum 22% accuracy under distortion. These findings raise important questions for future research, particularly regarding when and how models should autonomously decide to realign tabular inputs, analogous to human behavior, without relying on explicit prompts or tabular data pre-processing.",
      "authors": [
        "Avik Dutta",
        "Harshit Nigam",
        "Hosein Hasanbeig",
        "Arjun Radhakrishna",
        "Sumit Gulwani"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 15:10:32+00:00",
      "link": "https://arxiv.org/pdf/2601.05009v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04992v1",
      "title": "Learning from Mistakes: Negative Reasoning Samples Enhance Out-of-Domain Generalization",
      "abstract": "Supervised fine-tuning (SFT) on chain-of-thought (CoT) trajectories demonstrations is a common approach for enabling reasoning in large language models. Standard practices typically only retain trajectories with correct final answers (positives) while ignoring the rest (negatives). We argue that this paradigm discards substantial supervision and exacerbates overfitting, limiting out-of-domain (OOD) generalization. Specifically, we surprisingly find that incorporating negative trajectories into SFT yields substantial OOD generalization gains over positive-only training, as these trajectories often retain valid intermediate reasoning despite incorrect final answers. To understand this effect in depth, we systematically analyze data, training dynamics, and inference behavior, identifying 22 recurring patterns in negative chains that serve a dual role: they moderate loss descent to mitigate overfitting during training and boost policy entropy by 35.67% during inference to facilitate exploration. Motivated by these observations, we further propose Gain-based LOss Weighting (GLOW), an adaptive, sample-aware scheme that exploits such distinctive training dynamics by rescaling per-sample loss based on inter-epoch progress. Empirically, GLOW efficiently leverages unfiltered trajectories, yielding a 5.51% OOD gain over positive-only SFT on Qwen2.5-7B and boosting MMLU from 72.82% to 76.47% as an RL initialization.",
      "authors": [
        "Xueyun Tian",
        "Minghua Ma",
        "Bingbing Xu",
        "Nuoyan Lyu",
        "Wei Li",
        "Heng Dong",
        "Zheng Chu",
        "Yuanzhuo Wang",
        "Huawei Shen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 14:49:10+00:00",
      "link": "https://arxiv.org/pdf/2601.04992v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04984v1",
      "title": "OceanSplat: Object-aware Gaussian Splatting with Trinocular View Consistency for Underwater Scene Reconstruction",
      "abstract": "We introduce OceanSplat, a novel 3D Gaussian Splatting-based approach for accurately representing 3D geometry in underwater scenes. To overcome multi-view inconsistencies caused by underwater optical degradation, our method enforces trinocular view consistency by rendering horizontally and vertically translated camera views relative to each input view and aligning them via inverse warping. Furthermore, these translated camera views are used to derive a synthetic epipolar depth prior through triangulation, which serves as a self-supervised depth regularizer. These geometric constraints facilitate the spatial optimization of 3D Gaussians and preserve scene structure in underwater environments. We also propose a depth-aware alpha adjustment that modulates the opacity of 3D Gaussians during early training based on their $z$-component and viewing direction, deterring the formation of medium-induced primitives. With our contributions, 3D Gaussians are disentangled from the scattering medium, enabling robust representation of object geometry and significantly reducing floating artifacts in reconstructed underwater scenes. Experiments on real-world underwater and simulated scenes demonstrate that OceanSplat substantially outperforms existing methods for both scene reconstruction and restoration in scattering media.",
      "authors": [
        "Minseong Kweon",
        "Jinsun Park"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 14:38:39+00:00",
      "link": "https://arxiv.org/pdf/2601.04984v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04954v1",
      "title": "Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following",
      "abstract": "A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\\% in performance while achieving a 58\\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.",
      "authors": [
        "Yirong Zeng",
        "Yufei Liu",
        "Xiao Ding",
        "Yutai Hou",
        "Yuxian Wang",
        "Haonan Song",
        "Wu Ning",
        "Dandan Tu",
        "Qixun Zhang",
        "Bibo Cai",
        "Yuxiang He",
        "Ting Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 14:00:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04954v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04945v1",
      "title": "T-Retriever: Tree-based Hierarchical Retrieval Augmented Generation for Textual Graphs",
      "abstract": "Retrieval-Augmented Generation (RAG) has significantly enhanced Large Language Models' ability to access external knowledge, yet current graph-based RAG approaches face two critical limitations in managing hierarchical information: they impose rigid layer-specific compression quotas that damage local graph structures, and they prioritize topological structure while neglecting semantic content. We introduce T-Retriever, a novel framework that reformulates attributed graph retrieval as tree-based retrieval using a semantic and structure-guided encoding tree. Our approach features two key innovations: (1) Adaptive Compression Encoding, which replaces artificial compression quotas with a global optimization strategy that preserves the graph's natural hierarchical organization, and (2) Semantic-Structural Entropy ($S^2$-Entropy), which jointly optimizes for both structural cohesion and semantic consistency when creating hierarchical partitions. Experiments across diverse graph reasoning benchmarks demonstrate that T-Retriever significantly outperforms state-of-the-art RAG methods, providing more coherent and contextually relevant responses to complex queries.",
      "authors": [
        "Chunyu Wei",
        "Huaiyu Qin",
        "Siyuan He",
        "Yunhai Wang",
        "Yueguo Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 13:49:12+00:00",
      "link": "https://arxiv.org/pdf/2601.04945v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04941v1",
      "title": "Cardinality augmented loss functions",
      "abstract": "Class imbalance is a common and pernicious issue for the training of neural networks. Often, an imbalanced majority class can dominate training to skew classifier performance towards the majority outcome. To address this problem we introduce cardinality augmented loss functions, derived from cardinality-like invariants in modern mathematics literature such as magnitude and the spread. These invariants enrich the concept of cardinality by evaluating the `effective diversity' of a metric space, and as such represent a natural solution to overly homogeneous training data. In this work, we establish a methodology for applying cardinality augmented loss functions in the training of neural networks and report results on both artificially imbalanced datasets as well as a real-world imbalanced material science dataset. We observe significant performance improvement among minority classes, as well as improvement in overall performance metrics.",
      "authors": [
        "Miguel O'Malley"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 13:43:55+00:00",
      "link": "https://arxiv.org/pdf/2601.04941v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04932v1",
      "title": "GenProve: Learning to Generate Text with Fine-Grained Provenance",
      "abstract": "Large language models (LLM) often hallucinate, and while adding citations is a common solution, it is frequently insufficient for accountability as users struggle to verify how a cited source supports a generated claim. Existing methods are typically coarse-grained and fail to distinguish between direct quotes and complex reasoning. In this paper, we introduce Generation-time Fine-grained Provenance, a task where models must generate fluent answers while simultaneously producing structured, sentence-level provenance triples. To enable this, we present ReFInE (Relation-aware Fine-grained Interpretability & Evidence), a dataset featuring expert verified annotations that distinguish between Quotation, Compression, and Inference. Building on ReFInE, we propose GenProve, a framework that combines Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO). By optimizing a composite reward for answer fidelity and provenance correctness, GenProve significantly outperforms 14 strong LLMs in joint evaluation. Crucially, our analysis uncovers a reasoning gap where models excel at surface-level quotation but struggle significantly with inference-based provenance, suggesting that verifiable reasoning remains a frontier challenge distinct from surface-level citation.",
      "authors": [
        "Jingxuan Wei",
        "Xingyue Wang",
        "Yanghaoyu Liao",
        "Jie Dong",
        "Yuchen Liu",
        "Caijun Jia",
        "Bihui Yu",
        "Junnan Zhu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 13:30:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04932v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04919v1",
      "title": "What Students Ask, How a Generative AI Assistant Responds: Exploring Higher Education Students' Dialogues on Learning Analytics Feedback",
      "abstract": "Learning analytics dashboards (LADs) aim to support students' regulation of learning by translating complex data into feedback. Yet students, especially those with lower self-regulated learning (SRL) competence, often struggle to engage with and interpret analytics feedback. Conversational generative artificial intelligence (GenAI) assistants have shown potential to scaffold this process through real-time, personalised, dialogue-based support. Further advancing this potential, we explored authentic dialogues between students and GenAI assistant integrated into LAD during a 10-week semester. The analysis focused on questions students with different SRL levels posed, the relevance and quality of the assistant's answers, and how students perceived the assistant's role in their learning. Findings revealed distinct query patterns. While low SRL students sought clarification and reassurance, high SRL students queried technical aspects and requested personalised strategies. The assistant provided clear and reliable explanations but limited in personalisation, handling emotionally charged queries, and integrating multiple data points for tailored responses. Findings further extend that GenAI interventions can be especially valuable for low SRL students, offering scaffolding that supports engagement with feedback and narrows gaps with their higher SRL peers. At the same time, students' reflections underscored the importance of trust, need for greater adaptivity, context-awareness, and technical refinement in future systems.",
      "authors": [
        "Yildiz Uzun",
        "Andrea Gauthier",
        "Mutlu Cukurova"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "published": "2026-01-08 13:17:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04919v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04891v1",
      "title": "Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform",
      "abstract": "Vision Language Models (VLMs) have shown strong performance on multimodal reasoning tasks, yet most evaluations focus on short videos and assume unconstrained computational resources. In industrial settings such as pharmaceutical content understanding, practitioners must process long-form videos under strict GPU, latency, and cost constraints, where many existing approaches fail to scale. In this work, we present an industrial GenAI framework that processes over 200,000 PDFs, 25,326 videos across eight formats (e.g., MP4, M4V, etc.), and 888 multilingual audio files in more than 20 languages. Our study makes three contributions: (i) an industrial large-scale architecture for multimodal reasoning in pharmaceutical domains; (ii) empirical analysis of over 40 VLMs on two leading benchmarks (Video-MME and MMBench) and proprietary dataset of 25,326 videos across 14 disease areas; and (iii) four findings relevant to long-form video reasoning: the role of multimodality, attention mechanism trade-offs, temporal reasoning limits, and challenges of video splitting under GPU constraints. Results show 3-8 times efficiency gains with SDPA attention on commodity GPUs, multimodality improving up to 8/12 task domains (especially length-dependent tasks), and clear bottlenecks in temporal alignment and keyframe detection across open- and closed-source VLMs. Rather than proposing a new \"A+B\" model, this paper characterizes practical limits, trade-offs, and failure patterns of current VLMs under realistic deployment constraints, and provide actionable guidance for both researchers and practitioners designing scalable multimodal systems for long-form video understanding in industrial domains.",
      "authors": [
        "Suyash Mishra",
        "Qiang Li",
        "Srikanth Patil",
        "Satyanarayan Pati",
        "Baddu Narendra"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 12:42:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04891v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04890v1",
      "title": "Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers",
      "abstract": "Applying weight decay (WD) to matrix layers is standard practice in large-language-model pretraining. Prior work suggests that stochastic gradient noise induces a Brownian-like expansion of the weight matrices W, whose growth is counteracted by WD, leading to a WD-noise equilibrium with a certain weight norm ||W||. In this work, we view the equilibrium norm as a harmful artifact of the training procedure, and address it by introducing learnable multipliers to learn the optimal scale. First, we attach a learnable scalar multiplier to W and confirm that the WD-noise equilibrium norm is suboptimal: the learned scale adapts to data and improves performance. We then argue that individual row and column norms are similarly constrained, and free their scale by introducing learnable per-row and per-column multipliers. Our method can be viewed as a learnable, more expressive generalization of muP multipliers. It outperforms a well-tuned muP baseline, reduces the computational overhead of multiplier tuning, and surfaces practical questions such as forward-pass symmetries and the width-scaling of the learned multipliers. Finally, we validate learnable multipliers with both Adam and Muon optimizers, where it shows improvement in downstream evaluations matching the improvement of the switching from Adam to Muon.",
      "authors": [
        "Maksim Velikanov",
        "Ilyas Chahed",
        "Jingwei Zuo",
        "Dhia Eddine Rhaiem",
        "Younes Belkada",
        "Hakim Hacid"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 12:41:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04890v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04889v1",
      "title": "Faithful Summarisation under Disagreement via Belief-Level Aggregation",
      "abstract": "Opinion and multi-document summarisation often involve genuinely conflicting viewpoints, yet many existing approaches, particularly LLM-based systems, implicitly smooth disagreement and over-represent majority opinions. This limits the faithfulness of generated summaries in opinion-heavy settings. We introduce a disagreement-aware synthesis pipeline that separates belief-level aggregation from language generation. Documents are first represented as structured belief sets and aggregated using distance-based belief merging operators that explicitly model conflict. Large language models are then used only to realise the aggregated beliefs as natural language summaries. We evaluate the approach across multiple model families and scales, comparing it to methods that perform explicit aggregation during generation. Our results show that while sufficiently large models can match belief-level aggregation when aggregation is handled at generation time, this behaviour is not stable across architectures or capacities. In contrast, belief-level aggregation combined with simple prompting yields consistently strong disagreement-aware performance across models, while maintaining fluent and grounded summaries.",
      "authors": [
        "Favour Yahdii Aghaebe",
        "Tanefa Apekey",
        "Elizabeth Williams",
        "Nafise Sadat Moosavi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 12:40:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04889v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04888v1",
      "title": "SmartSearch: Process Reward-Guided Query Refinement for Search Agents",
      "abstract": "Large language model (LLM)-based search agents have proven promising for addressing knowledge-intensive problems by incorporating information retrieval capabilities. Existing works largely focus on optimizing the reasoning paradigms of search agents, yet the quality of intermediate search queries during reasoning remains overlooked. As a result, the generated queries often remain inaccurate, leading to unexpected retrieval results and ultimately limiting search agents' overall effectiveness. To mitigate this issue, we introduce SmartSearch, a framework built upon two key mechanisms: (1) Process rewards, which provide fine-grained supervision for the quality of each intermediate search query through Dual-Level Credit Assessment. (2) Query refinement, which promotes the optimization of query generation by selectively refining low-quality search queries and regenerating subsequent search rounds based on these refinements. To enable the search agent to progressively internalize the ability to improve query quality under the guidance of process rewards, we design a three-stage curriculum learning framework. This framework guides the agent through a progression from imitation, to alignment, and ultimately to generalization. Experimental results show that SmartSearch consistently surpasses existing baselines, and additional quantitative analyses further confirm its significant gains in both search efficiency and query quality. The code is available at https://github.com/MYVAE/SmartSearch.",
      "authors": [
        "Tongyu Wen",
        "Guanting Dong",
        "Zhicheng Dou"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 12:39:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04888v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04885v1",
      "title": "CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters",
      "abstract": "As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \\textbf{Mean Collapse}, converging to a generic average that fails to represent diverse groups. We attribute this to \\textbf{Cultural Sparsity}, where gradient interference prevents dense parameters from spanning distinct cultural modes. To resolve this, we propose \\textbf{\\textsc{CuMA}} (\\textbf{Cu}ltural \\textbf{M}ixture of \\textbf{A}dapters), a framework that frames alignment as a \\textbf{conditional capacity separation} problem. By incorporating demographic-aware routing, \\textsc{CuMA} internalizes a \\textit{Latent Cultural Topology} to explicitly disentangle conflicting gradients into specialized expert subspaces. Extensive evaluations on WorldValuesBench, Community Alignment, and PRISM demonstrate that \\textsc{CuMA} achieves state-of-the-art performance, significantly outperforming both dense baselines and semantic-only MoEs. Crucially, our analysis confirms that \\textsc{CuMA} effectively mitigates mean collapse, preserving cultural diversity. Our code is available at https://github.com/Throll/CuMA.",
      "authors": [
        "Ao Sun",
        "Xiaoyu Wang",
        "Zhe Tan",
        "Yu Li",
        "Jiachen Zhu",
        "Shu Su",
        "Yuheng Jia"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 12:30:43+00:00",
      "link": "https://arxiv.org/pdf/2601.04885v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04879v1",
      "title": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis",
      "abstract": "Synthesizing informative commercial reports from massive and noisy web sources is critical for high-stakes business decisions. Although current deep research agents achieve notable progress, their reports still remain limited in terms of quality, reliability, and coverage. In this work, we propose Mind2Report, a cognitive deep research agent that emulates the commercial analyst to synthesize expert-level reports. Specifically, it first probes fine-grained intent, then searches web sources and records distilled information on the fly, and subsequently iteratively synthesizes the report. We design Mind2Report as a training-free agentic workflow that augments general large language models (LLMs) with dynamic memory to support these long-form cognitive processes. To rigorously evaluate Mind2Report, we further construct QRC-Eval comprising 200 real-world commercial tasks and establish a holistic evaluation strategy to assess report quality, reliability, and coverage. Experiments demonstrate that Mind2Report outperforms leading baselines, including OpenAI and Gemini deep research agents. Although this is a preliminary study, we expect it to serve as a foundation for advancing the future design of commercial deep research agents. Our code and data are available at https://github.com/Melmaphother/Mind2Report.",
      "authors": [
        "Mingyue Cheng",
        "Daoyu Wang",
        "Qi Liu",
        "Shuo Yu",
        "Xiaoyu Tao",
        "Yuqian Wang",
        "Chengzhong Chu",
        "Yu Duan",
        "Mingkang Long",
        "Enhong Chen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 12:27:52+00:00",
      "link": "https://arxiv.org/pdf/2601.04879v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04878v1",
      "title": "Higher-Order Knowledge Representations for Agentic Scientific Reasoning",
      "abstract": "Scientific inquiry requires systems-level reasoning that integrates heterogeneous experimental data, cross-domain knowledge, and mechanistic evidence into coherent explanations. While Large Language Models (LLMs) offer inferential capabilities, they often depend on retrieval-augmented contexts that lack structural depth. Traditional Knowledge Graphs (KGs) attempt to bridge this gap, yet their pairwise constraints fail to capture the irreducible higher-order interactions that govern emergent physical behavior. To address this, we introduce a methodology for constructing hypergraph-based knowledge representations that faithfully encode multi-entity relationships. Applied to a corpus of ~1,100 manuscripts on biocomposite scaffolds, our framework constructs a global hypergraph of 161,172 nodes and 320,201 hyperedges, revealing a scale-free topology (power law exponent ~1.23) organized around highly connected conceptual hubs. This representation prevents the combinatorial explosion typical of pairwise expansions and explicitly preserves the co-occurrence context of scientific formulations. We further demonstrate that equipping agentic systems with hypergraph traversal tools, specifically using node-intersection constraints, enables them to bridge semantically distant concepts. By exploiting these higher-order pathways, the system successfully generates grounded mechanistic hypotheses for novel composite materials, such as linking cerium oxide to PCL scaffolds via chitosan intermediates. This work establishes a \"teacherless\" agentic reasoning system where hypergraph topology acts as a verifiable guardrail, accelerating scientific discovery by uncovering relationships obscured by traditional graph methods.",
      "authors": [
        "Isabella A. Stewart",
        "Markus J. Buehler"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 12:25:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04878v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04864v1",
      "title": "Key-Value Pair-Free Continual Learner via Task-Specific Prompt-Prototype",
      "abstract": "Continual learning aims to enable models to acquire new knowledge while retaining previously learned information. Prompt-based methods have shown remarkable performance in this domain; however, they typically rely on key-value pairing, which can introduce inter-task interference and hinder scalability. To overcome these limitations, we propose a novel approach employing task-specific Prompt-Prototype (ProP), thereby eliminating the need for key-value pairs. In our method, task-specific prompts facilitate more effective feature learning for the current task, while corresponding prototypes capture the representative features of the input. During inference, predictions are generated by binding each task-specific prompt with its associated prototype. Additionally, we introduce regularization constraints during prompt initialization to penalize excessively large values, thereby enhancing stability. Experiments on several widely used datasets demonstrate the effectiveness of the proposed method. In contrast to mainstream prompt-based approaches, our framework removes the dependency on key-value pairs, offering a fresh perspective for future continual learning research.",
      "authors": [
        "Haihua Luo",
        "Xuming Ran",
        "Zhengji Li",
        "Huiyan Xue",
        "Tingting Jiang",
        "Jiangrong Shen",
        "Tommi Kärkkäinen",
        "Qi Xu",
        "Fengyu Cong"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 11:59:35+00:00",
      "link": "https://arxiv.org/pdf/2601.04864v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04859v1",
      "title": "A Navigational Approach for Comprehensive RAG via Traversal over Proposition Graphs",
      "abstract": "Standard RAG pipelines based on chunking excel at simple factual retrieval but fail on complex multi-hop queries due to a lack of structural connectivity. Conversely, initial strategies that interleave retrieval with reasoning often lack global corpus awareness, while Knowledge Graph (KG)-based RAG performs strongly on complex multi-hop tasks but suffers on fact-oriented single-hop queries. To bridge this gap, we propose a novel RAG framework: ToPG (Traversal over Proposition Graphs). ToPG models its knowledge base as a heterogeneous graph of propositions, entities, and passages, effectively combining the granular fact density of propositions with graph connectivity. We leverage this structure using iterative Suggestion-Selection cycles, where the Suggestion phase enables a query-aware traversal of the graph, and the Selection phase provides LLM feedback to prune irrelevant propositions and seed the next iteration. Evaluated on three distinct QA tasks (Simple, Complex, and Abstract QA), ToPG demonstrates strong performance across both accuracy- and quality-based metrics. Overall, ToPG shows that query-aware graph traversal combined with factual granularity is a critical component for efficient structured RAG systems. ToPG is available at https://github.com/idiap/ToPG.",
      "authors": [
        "Maxime Delmas",
        "Lei Xu",
        "André Freitas"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 11:50:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04859v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04854v1",
      "title": "Token Maturation: Autoregressive Language Generation via Continuous Token Dynamics",
      "abstract": "Autoregressive language models are conventionally defined over discrete token sequences, committing to a specific token at every generation step. This early discretization forces uncertainty to be resolved through token-level sampling, often leading to instability, repetition, and sensitivity to decoding heuristics.   In this work, we introduce a continuous autoregressive formulation of language generation in which tokens are represented as continuous vectors that \\emph{mature} over multiple update steps before being discretized. Rather than sampling tokens, the model evolves continuous token representations through a deterministic dynamical process, committing to a discrete token only when the representation has sufficiently converged. Discrete text is recovered via hard decoding, while uncertainty is maintained and resolved in the continuous space.   We show that this maturation process alone is sufficient to produce coherent and diverse text using deterministic decoding (argmax), without reliance on token-level sampling, diffusion-style denoising, or auxiliary stabilization mechanisms. Additional perturbations, such as stochastic dynamics or history smoothing, can be incorporated naturally but are not required for the model to function.   To our knowledge, this is the first autoregressive language model that generates text by evolving continuous token representations to convergence prior to discretization, enabling stable generation without token-level sampling.",
      "authors": [
        "Oshri Naparstek"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 11:44:34+00:00",
      "link": "https://arxiv.org/pdf/2601.04854v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04833v1",
      "title": "When AI Settles Down: Late-Stage Stability as a Signature of AI-Generated Text Detection",
      "abstract": "Zero-shot detection methods for AI-generated text typically aggregate token-level statistics across entire sequences, overlooking the temporal dynamics inherent to autoregressive generation. We analyze over 120k text samples and reveal Late-Stage Volatility Decay: AI-generated text exhibits rapidly stabilizing log probability fluctuations as generation progresses, while human writing maintains higher variability throughout. This divergence peaks in the second half of sequences, where AI-generated text shows 24--32\\% lower volatility. Based on this finding, we propose two simple features: Derivative Dispersion and Local Volatility, which computed exclusively from late-stage statistics. Without perturbation sampling or additional model access, our method achieves state-of-the-art performance on EvoBench and MAGE benchmarks and demonstrates strong complementarity with existing global methods.",
      "authors": [
        "Ke Sun",
        "Guangsheng Bao",
        "Han Cui",
        "Yue Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 11:11:00+00:00",
      "link": "https://arxiv.org/pdf/2601.04833v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04825v1",
      "title": "Illumination Angular Spectrum Encoding for Controlling the Functionality of Diffractive Networks",
      "abstract": "Diffractive neural networks have recently emerged as a promising framework for all-optical computing. However, these networks are typically trained for a single task, limiting their potential adoption in systems requiring multiple functionalities. Existing approaches to achieving multi-task functionality either modify the mechanical configuration of the network per task or use a different illumination wavelength or polarization state for each task. In this work, we propose a new control mechanism, which is based on the illumination's angular spectrum. Specifically, we shape the illumination using an amplitude mask that selectively controls its angular spectrum. We employ different illumination masks for achieving different network functionalities, so that the mask serves as a unique task encoder. Interestingly, we show that effective control can be achieved over a very narrow angular range, within the paraxial regime. We numerically illustrate the proposed approach by training a single diffractive network to perform multiple image-to-image translation tasks. In particular, we demonstrate translating handwritten digits into typeset digits of different values, and translating handwritten English letters into typeset numbers and typeset Greek letters, where the type of the output is determined by the illumination's angular components. As we show, the proposed framework can work under different coherence conditions, and can be combined with existing control strategies, such as different wavelengths. Our results establish the illumination angular spectrum as a powerful degree of freedom for controlling diffractive networks, enabling a scalable and versatile framework for multi-task all-optical computing.",
      "authors": [
        "Matan Kleiner",
        "Lior Michaeli",
        "Tomer Michaeli"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 11:00:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04825v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04823v1",
      "title": "DR-LoRA: Dynamic Rank LoRA for Mixture-of-Experts Adaptation",
      "abstract": "Mixture-of-Experts (MoE) has become a prominent paradigm for scaling Large Language Models (LLMs). Parameter-efficient fine-tuning (PEFT), such as LoRA, is widely adopted to adapt pretrained MoE LLMs to downstream tasks. However, existing approaches assign identical LoRA ranks to all experts, overlooking the intrinsic functional specialization within MoE LLMs. This uniform allocation leads to resource mismatch, task-relevant experts are under-provisioned while less relevant ones receive redundant parameters. We propose a Dynamic Rank LoRA framework named DR-LoRA, which dynamically grows expert LoRA ranks during fine-tuning based on task-specific demands. DR-LoRA employs an Expert Saliency Scoring mechanism that integrates expert routing frequency and LoRA rank importance to quantify each expert's demand for additional capacity. Experts with higher saliency scores are prioritized for rank expansion, enabling the automatic formation of a heterogeneous rank distribution tailored to the target task. Experiments on multiple benchmarks demonstrate that DR-LoRA consistently outperforms standard LoRA and static allocation strategies under the same parameter budget, achieving superior task performance with more efficient parameter utilization.",
      "authors": [
        "Guanzhi Deng",
        "Bo Li",
        "Ronghao Chen",
        "Huacan Wang",
        "Linqi Song",
        "Lijie Wen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 10:58:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04823v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04819v1",
      "title": "AECV-Bench: Benchmarking Multimodal Models on Architectural and Engineering Drawings Understanding",
      "abstract": "AEC drawings encode geometry and semantics through symbols, layout conventions, and dense annotation, yet it remains unclear whether modern multimodal and vision-language models can reliably interpret this graphical language. We present AECV-Bench, a benchmark for evaluating multimodal and vision-language models on realistic AEC artefacts via two complementary use cases: (i) object counting on 120 high-quality floor plans (doors, windows, bedrooms, toilets), and (ii) drawing-grounded document QA spanning 192 question-answer pairs that test text extraction (OCR), instance counting, spatial reasoning, and comparative reasoning over common drawing regions. Object-counting performance is reported using per-field exact-match accuracy and MAPE results, while document-QA performance is reported using overall accuracy and per-category breakdowns with an LLM-as-a-judge scoring pipeline and targeted human adjudication for edge cases. Evaluating a broad set of state-of-the-art models under a unified protocol, we observe a stable capability gradient; OCR and text-centric document QA are strongest (up to 0.95 accuracy), spatial reasoning is moderate, and symbol-centric drawing understanding - especially reliable counting of doors and windows - remains unsolved (often 0.40-0.55 accuracy) with substantial proportional errors. These results suggest that current systems function well as document assistants but lack robust drawing literacy, motivating domain-specific representations and tool-augmented, human-in-the-loop workflows for an efficient AEC automation.",
      "authors": [
        "Aleksei Kondratenko",
        "Mussie Birhane",
        "Houssame E. Hsain",
        "Guido Maciocci"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 10:54:32+00:00",
      "link": "https://arxiv.org/pdf/2601.04819v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04807v1",
      "title": "Parallelizing Node-Level Explainability in Graph Neural Networks",
      "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable performance in a wide range of tasks, such as node classification, link prediction, and graph classification, by exploiting the structural information in graph-structured data. However, in node classification, computing node-level explainability becomes extremely time-consuming as the size of the graph increases, while batching strategies often degrade explanation quality. This paper introduces a novel approach to parallelizing node-level explainability in GNNs through graph partitioning. By decomposing the graph into disjoint subgraphs, we enable parallel computation of explainability for node neighbors, significantly improving the scalability and efficiency without affecting the correctness of the results, provided sufficient memory is available. For scenarios where memory is limited, we further propose a dropout-based reconstruction mechanism that offers a controllable trade-off between memory usage and explanation fidelity. Experimental results on real-world datasets demonstrate substantial speedups, enabling scalable and transparent explainability for large-scale GNN models.",
      "authors": [
        "Oscar Llorente",
        "Jaime Boal",
        "Eugenio F. Sánchez-Úbeda",
        "Antonio Diaz-Cano",
        "Miguel Familiar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 10:39:48+00:00",
      "link": "https://arxiv.org/pdf/2601.04807v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04792v1",
      "title": "PyramidalWan: On Making Pretrained Video Model Pyramidal for Efficient Inference",
      "abstract": "Recently proposed pyramidal models decompose the conventional forward and backward diffusion processes into multiple stages operating at varying resolutions. These models handle inputs with higher noise levels at lower resolutions, while less noisy inputs are processed at higher resolutions. This hierarchical approach significantly reduces the computational cost of inference in multi-step denoising models. However, existing open-source pyramidal video models have been trained from scratch and tend to underperform compared to state-of-the-art systems in terms of visual plausibility. In this work, we present a pipeline that converts a pretrained diffusion model into a pyramidal one through low-cost finetuning, achieving this transformation without degradation in quality of output videos. Furthermore, we investigate and compare various strategies for step distillation within pyramidal models, aiming to further enhance the inference efficiency. Our results are available at https://qualcomm-ai-research.github.io/PyramidalWan.",
      "authors": [
        "Denis Korzhenkov",
        "Adil Karjauv",
        "Animesh Karnewar",
        "Mohsen Ghafoorian",
        "Amirhossein Habibian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 10:16:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04792v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04791v1",
      "title": "Measurement-Consistent Langevin Corrector: A Remedy for Latent Diffusion Inverse Solvers",
      "abstract": "With recent advances in generative models, diffusion models have emerged as powerful priors for solving inverse problems in each domain. Since Latent Diffusion Models (LDMs) provide generic priors, several studies have explored their potential as domain-agnostic zero-shot inverse solvers. Despite these efforts, existing latent diffusion inverse solvers suffer from their instability, exhibiting undesirable artifacts and degraded quality. In this work, we first identify the instability as a discrepancy between the solver's and true reverse diffusion dynamics, and show that reducing this gap stabilizes the solver. Building on this, we introduce Measurement-Consistent Langevin Corrector (MCLC), a theoretically grounded plug-and-play correction module that remedies the LDM-based inverse solvers through measurement-consistent Langevin updates. Compared to prior approaches that rely on linear manifold assumptions, which often do not hold in latent space, MCLC operates without this assumption, leading to more stable and reliable behavior. We experimentally demonstrate the effectiveness of MCLC and its compatibility with existing solvers across diverse image restoration tasks. Additionally, we analyze blob artifacts and offer insights into their underlying causes. We highlight that MCLC is a key step toward more robust zero-shot inverse problem solvers.",
      "authors": [
        "Lee Hyoseok",
        "Sohwi Lim",
        "Eunju Cha",
        "Tae-Hyun Oh"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 10:15:35+00:00",
      "link": "https://arxiv.org/pdf/2601.04791v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04785v1",
      "title": "SRU-Pix2Pix: A Fusion-Driven Generator Network for Medical Image Translation with Few-Shot Learning",
      "abstract": "Magnetic Resonance Imaging (MRI) provides detailed tissue information, but its clinical application is limited by long acquisition time, high cost, and restricted resolution. Image translation has recently gained attention as a strategy to address these limitations. Although Pix2Pix has been widely applied in medical image translation, its potential has not been fully explored. In this study, we propose an enhanced Pix2Pix framework that integrates Squeeze-and-Excitation Residual Networks (SEResNet) and U-Net++ to improve image generation quality and structural fidelity. SEResNet strengthens critical feature representation through channel attention, while U-Net++ enhances multi-scale feature fusion. A simplified PatchGAN discriminator further stabilizes training and refines local anatomical realism. Experimental results demonstrate that under few-shot conditions with fewer than 500 images, the proposed method achieves consistent structural fidelity and superior image quality across multiple intra-modality MRI translation tasks, showing strong generalization ability. These results suggest an effective extension of Pix2Pix for medical image translation.",
      "authors": [
        "Xihe Qiu",
        "Yang Dai",
        "Xiaoyu Tan",
        "Sijia Li",
        "Fenghao Sun",
        "Lu Gan",
        "Liang Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 10:10:03+00:00",
      "link": "https://arxiv.org/pdf/2601.04785v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04778v1",
      "title": "CounterVid: Counterfactual Video Generation for Mitigating Action and Temporal Hallucinations in Video-Language Models",
      "abstract": "Video-language models (VLMs) achieve strong multimodal understanding but remain prone to hallucinations, especially when reasoning about actions and temporal order. Existing mitigation strategies, such as textual filtering or random video perturbations, often fail to address the root cause: over-reliance on language priors rather than fine-grained visual dynamics. We propose a scalable framework for counterfactual video generation that synthesizes videos differing only in actions or temporal structure while preserving scene context. Our pipeline combines multimodal LLMs for action proposal and editing guidance with diffusion-based image and video models to generate semantic hard negatives at scale. Using this framework, we build CounterVid, a synthetic dataset of ~26k preference pairs targeting action recognition and temporal reasoning. We further introduce MixDPO, a unified Direct Preference Optimization approach that jointly leverages textual and visual preferences. Fine-tuning Qwen2.5-VL with MixDPO yields consistent improvements, notably in temporal ordering, and transfers effectively to standard video hallucination benchmarks. Code and models will be made publicly available.",
      "authors": [
        "Tobia Poppi",
        "Burak Uzkent",
        "Amanmeet Garg",
        "Lucas Porto",
        "Garin Kessler",
        "Yezhou Yang",
        "Marcella Cornia",
        "Lorenzo Baraldi",
        "Rita Cucchiara",
        "Florian Schiffers"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "published": "2026-01-08 10:03:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04778v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04777v1",
      "title": "GeM-VG: Towards Generalized Multi-image Visual Grounding with Multimodal Large Language Models",
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated impressive progress in single-image grounding and general multi-image understanding. Recently, some methods begin to address multi-image grounding. However, they are constrained by single-target localization and limited types of practical tasks, due to the lack of unified modeling for generalized grounding tasks. Therefore, we propose GeM-VG, an MLLM capable of Generalized Multi-image Visual Grounding. To support this, we systematically categorize and organize existing multi-image grounding tasks according to their reliance of cross-image cues and reasoning, and introduce the MG-Data-240K dataset, addressing the limitations of existing datasets regarding target quantity and image relation. To tackle the challenges of robustly handling diverse multi-image grounding tasks, we further propose a hybrid reinforcement finetuning strategy that integrates chain-of-thought (CoT) reasoning and direct answering, considering their complementary strengths. This strategy adopts an R1-like algorithm guided by a carefully designed rule-based reward, effectively enhancing the model's overall perception and reasoning capabilities. Extensive experiments demonstrate the superior generalized grounding capabilities of our model. For multi-image grounding, it outperforms the previous leading MLLMs by 2.0% and 9.7% on MIG-Bench and MC-Bench, respectively. In single-image grounding, it achieves a 9.1% improvement over the base model on ODINW. Furthermore, our model retains strong capabilities in general multi-image understanding.",
      "authors": [
        "Shurong Zheng",
        "Yousong Zhu",
        "Hongyin Zhao",
        "Fan Yang",
        "Yufei Zhan",
        "Ming Tang",
        "Jinqiao Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 09:58:35+00:00",
      "link": "https://arxiv.org/pdf/2601.04777v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04766v1",
      "title": "Revisiting Judge Decoding from First Principles via Training-Free Distributional Divergence",
      "abstract": "Judge Decoding accelerates LLM inference by relaxing the strict verification of Speculative Decoding, yet it typically relies on expensive and noisy supervision. In this work, we revisit this paradigm from first principles, revealing that the ``criticality'' scores learned via costly supervision are intrinsically encoded in the draft-target distributional divergence. We theoretically prove a structural correspondence between learned linear judges and Kullback-Leibler (KL) divergence, demonstrating they rely on the same underlying logit primitives. Guided by this, we propose a simple, training-free verification mechanism based on KL divergence. Extensive experiments across reasoning and coding benchmarks show that our method matches or outperforms complex trained judges (e.g., AutoJudge), offering superior robustness to domain shifts and eliminating the supervision bottleneck entirely.",
      "authors": [
        "Shengyin Sun",
        "Yiming Li",
        "Renxi Liu",
        "Weizhe Lin",
        "Hui-Ling Zhen",
        "Xianzhi Yu",
        "Mingxuan Yuan",
        "Chen Ma"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 09:34:54+00:00",
      "link": "https://arxiv.org/pdf/2601.04766v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04764v1",
      "title": "Orion-RAG: Path-Aligned Hybrid Retrieval for Graphless Data",
      "abstract": "Retrieval-Augmented Generation (RAG) has proven effective for knowledge synthesis, yet it encounters significant challenges in practical scenarios where data is inherently discrete and fragmented. In most environments, information is distributed across isolated files like reports and logs that lack explicit links. Standard search engines process files independently, ignoring the connections between them. Furthermore, manually building Knowledge Graphs is impractical for such vast data. To bridge this gap, we present Orion-RAG. Our core insight is simple yet effective: we do not need heavy algorithms to organize this data. Instead, we use a low-complexity strategy to extract lightweight paths that naturally link related concepts. We demonstrate that this streamlined approach suffices to transform fragmented documents into semi-structured data, enabling the system to link information across different files effectively. Extensive experiments demonstrate that Orion-RAG consistently outperforms mainstream frameworks across diverse domains, supporting real-time updates and explicit Human-in-the-Loop verification with high cost-efficiency. Experiments on FinanceBench demonstrate superior precision with a 25.2% relative improvement over strong baselines.",
      "authors": [
        "Zhen Chen",
        "Weihao Xie",
        "Peilin Chen",
        "Shiqi Wang",
        "Jianping Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 09:32:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04764v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04757v1",
      "title": "Structural Indexing of Relational Databases for the Evaluation of Free-Connex Acyclic Conjunctive Queries",
      "abstract": "We present an index structure to boost the evaluation of free-connex acyclic conjunctive queries (fc-ACQs) over relational databases. The main ingredient of the index associated with a given database $D$ is an auxiliary database $D_{col}$. Our main result states that for any fc-ACQ $Q$ over $D$, we can count the number of answers of $Q$ or enumerate them with constant delay after a preprocessing phase that takes time linear in the size of $D_{col}$.   Unlike previous indexing methods based on values or order (e.g., B+ trees), our index is based on structural symmetries among tuples in a database, and the size of $D_{col}$ is related to the number of colors assigned to $D$ by Scheidt and Schweikardt's \"relational color refinement\" (2025). In the particular case of graphs, this coincides with the minimal size of an equitable partition of the graph. For example, the size of $D_{col}$ is logarithmic in the case of binary trees and constant for regular graphs. Even in the worst-case that $D$ has no structural symmetries among tuples at all, the size of $D_{col}$ is still linear in the size of $D$.   Given that the size of $D_{col}$ is bounded by the size of $D$ and can be much smaller (even constant for some families of databases), our index is the first foundational result on indexing internal structural symmetries of a database to evaluate all fc-ACQs with performance potentially strictly smaller than the database size.",
      "authors": [
        "Cristian Riveros",
        "Benjamin Scheidt",
        "Nicole Schweikardt"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.LO"
      ],
      "published": "2026-01-08 09:25:48+00:00",
      "link": "https://arxiv.org/pdf/2601.04757v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04754v1",
      "title": "ProFuse: Efficient Cross-View Context Fusion for Open-Vocabulary 3D Gaussian Splatting",
      "abstract": "We present ProFuse, an efficient context-aware framework for open-vocabulary 3D scene understanding with 3D Gaussian Splatting (3DGS). The pipeline enhances cross-view consistency and intra-mask cohesion within a direct registration setup, adding minimal overhead and requiring no render-supervised fine-tuning. Instead of relying on a pretrained 3DGS scene, we introduce a dense correspondence-guided pre-registration phase that initializes Gaussians with accurate geometry while jointly constructing 3D Context Proposals via cross-view clustering. Each proposal carries a global feature obtained through weighted aggregation of member embeddings, and this feature is fused onto Gaussians during direct registration to maintain per-primitive language coherence across views. With associations established in advance, semantic fusion requires no additional optimization beyond standard reconstruction, and the model retains geometric refinement without densification. ProFuse achieves strong open-vocabulary 3DGS understanding while completing semantic attachment in about five minutes per scene, which is two times faster than SOTA.",
      "authors": [
        "Yen-Jen Chiou",
        "Wei-Tse Cheng",
        "Yuan-Fu Yang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 09:20:46+00:00",
      "link": "https://arxiv.org/pdf/2601.04754v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04752v1",
      "title": "Skeletonization-Based Adversarial Perturbations on Large Vision Language Model's Mathematical Text Recognition",
      "abstract": "This work explores the visual capabilities and limitations of foundation models by introducing a novel adversarial attack method utilizing skeletonization to reduce the search space effectively. Our approach specifically targets images containing text, particularly mathematical formula images, which are more challenging due to their LaTeX conversion and intricate structure. We conduct a detailed evaluation of both character and semantic changes between original and adversarially perturbed outputs to provide insights into the models' visual interpretation and reasoning abilities. The effectiveness of our method is further demonstrated through its application to ChatGPT, which shows its practical implications in real-world scenarios.",
      "authors": [
        "Masatomo Yoshida",
        "Haruto Namura",
        "Nicola Adami",
        "Masahiro Okuda"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 09:15:27+00:00",
      "link": "https://arxiv.org/pdf/2601.04752v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04750v1",
      "title": "Cognitive Infrastructure: A Unified DCIM Framework for AI Data Centers",
      "abstract": "This work presents DCIM 3.0, a unified framework integrating semantic reasoning, predictive analytics, autonomous orchestration, and unified connectivity for next-generation AI data center management. The framework addresses critical challenges in infrastructure automation, sustainability, and digital-twin design through knowledge graph-based intelligence, thermal modeling, and the Unified Device Connectivity Protocol (UDCP).Keywords-Data Center Infrastructure Management, DCIM, AI Data Centers, Knowledge Graphs, Digital Twin, Thermal Management, Infrastructure Automation, Sustainability, GPU Computing, Data Center",
      "authors": [
        "Krishna Chaitanya Sunkara"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.NI"
      ],
      "published": "2026-01-08 09:14:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04750v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04748v1",
      "title": "When Single-Agent with Skills Replace Multi-Agent Systems and When They Fail",
      "abstract": "Multi-agent AI systems have proven effective for complex reasoning. These systems are compounded by specialized agents, which collaborate through explicit communication, but incur substantial computational overhead. A natural question arises: can we achieve similar modularity benefits with a single agent that selects from a library of skills? We explore this question by viewing skills as internalized agent behaviors. From this perspective, a multi-agent system can be compiled into an equivalent single-agent system, trading inter-agent communication for skill selection. Our preliminary experiments suggest this approach can substantially reduce token usage and latency while maintaining competitive accuracy on reasoning benchmarks. However, this efficiency raises a deeper question that has received little attention: how does skill selection scale as libraries grow?   Drawing on principles from cognitive science, we propose that LLM skill selection exhibits bounded capacity analogous to human decision-making. We investigate the scaling behavior of skill selection and observe a striking pattern. Rather than degrading gradually, selection accuracy remains stable up to a critical library size, then drops sharply, indicating a phase transition reminiscent of capacity limits in human cognition. Furthermore, we find evidence that semantic confusability among similar skills, rather than library size alone, plays a central role in this degradation. This perspective suggests that hierarchical organization, which has long helped humans manage complex choices, may similarly benefit AI systems. Our initial results with hierarchical routing support this hypothesis. This work opens new questions about the fundamental limits of semantic-based skill selection in LLMs and offers a cognitive-grounded framework and practical guidelines for designing scalable skill-based agents.",
      "authors": [
        "Xiaoxiao Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-01-08 09:14:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04748v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04742v1",
      "title": "Tool-MAD: A Multi-Agent Debate Framework for Fact Verification with Diverse Tool Augmentation and Adaptive Retrieval",
      "abstract": "Large Language Models (LLMs) suffer from hallucinations and factual inaccuracies, especially in complex reasoning and fact verification tasks. Multi-Agent Debate (MAD) systems aim to improve answer accuracy by enabling multiple LLM agents to engage in dialogue, promoting diverse reasoning and mutual verification. However, existing MAD frameworks primarily rely on internal knowledge or static documents, making them vulnerable to hallucinations. While MADKE introduces external evidence to mitigate this, its one-time retrieval mechanism limits adaptability to new arguments or emerging information during the debate. To address these limitations, We propose Tool-MAD, a multi-agent debate framework that enhances factual verification by assigning each agent a distinct external tool, such as a search API or RAG module. Tool-MAD introduces three key innovations: (1) a multi-agent debate framework where agents leverage heterogeneous external tools, encouraging diverse perspectives, (2) an adaptive query formulation mechanism that iteratively refines evidence retrieval based on the flow of the debate, and (3) the integration of Faithfulness and Answer Relevance scores into the final decision process, allowing the Judge agent to quantitatively assess the coherence and question alignment of each response and effectively detect hallucinations. Experimental results on four fact verification benchmarks demonstrate that Tool-MAD consistently outperforms state-of-the-art MAD frameworks, achieving up to 5.5% accuracy improvement. Furthermore, in medically specialized domains, Tool-MAD exhibits strong robustness and adaptability across various tool configurations and domain conditions, confirming its potential for broader real-world fact-checking applications.",
      "authors": [
        "Seyeon Jeong",
        "Yeonjun Choi",
        "JongWook Kim",
        "Beakcheol Jang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 09:07:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04742v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04734v1",
      "title": "AIVD: Adaptive Edge-Cloud Collaboration for Accurate and Efficient Industrial Visual Detection",
      "abstract": "Multimodal large language models (MLLMs) demonstrate exceptional capabilities in semantic understanding and visual reasoning, yet they still face challenges in precise object localization and resource-constrained edge-cloud deployment. To address this, this paper proposes the AIVD framework, which achieves unified precise localization and high-quality semantic generation through the collaboration between lightweight edge detectors and cloud-based MLLMs. To enhance the cloud MLLM's robustness against edge cropped-box noise and scenario variations, we design an efficient fine-tuning strategy with visual-semantic collaborative augmentation, significantly improving classification accuracy and semantic consistency. Furthermore, to maintain high throughput and low latency across heterogeneous edge devices and dynamic network conditions, we propose a heterogeneous resource-aware dynamic scheduling algorithm. Experimental results demonstrate that AIVD substantially reduces resource consumption while improving MLLM classification performance and semantic generation quality. The proposed scheduling strategy also achieves higher throughput and lower latency across diverse scenarios.",
      "authors": [
        "Yunqing Hu",
        "Zheming Yang",
        "Chang Zhao",
        "Qi Guo",
        "Meng Gao",
        "Pengcheng Li",
        "Wen Ji"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 08:56:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04734v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04731v1",
      "title": "Miner:Mining Intrinsic Mastery for Data-Efficient RL in Large Reasoning Models",
      "abstract": "Current critic-free RL methods for large reasoning models suffer from severe inefficiency when training on positive homogeneous prompts (where all rollouts are correct), resulting in waste of rollouts due to zero advantage estimates. We introduce a radically simple yet powerful solution to \\uline{M}ine \\uline{in}trinsic mast\\uline{er}y (Miner), that repurposes the policy's intrinsic uncertainty as a self-supervised reward signal, with no external supervision, auxiliary models, or additional inference cost. Our method pioneers two key innovations: (1) a token-level focal credit assignment mechanism that dynamically amplifies gradients on critical uncertain tokens while suppressing overconfident ones, and (2) adaptive advantage calibration to seamlessly integrate intrinsic and verifiable rewards. Evaluated across six reasoning benchmarks on Qwen3-4B and Qwen3-8B base models, Miner achieves state-of-the-art performance among the other four algorithms, yielding up to \\textbf{4.58} absolute gains in Pass@1 and \\textbf{6.66} gains in Pass@K compared to GRPO. Comparison with other methods targeted at exploration enhancement further discloses the superiority of the two newly proposed innovations. This demonstrates that latent uncertainty exploitation is both necessary and sufficient for efficient and scalable RL training of reasoning models.",
      "authors": [
        "Shuyang Jiang",
        "Yuhao Wang",
        "Ya Zhang",
        "Yanfeng Wang",
        "Yu Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 08:52:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04731v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04726v1",
      "title": "Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning",
      "abstract": "Large language models (LLMs) are increasingly deployed as intelligent agents that reason, plan, and interact with their environments. To effectively scale to long-horizon scenarios, a key capability for such agents is a memory mechanism that can retain, organize, and retrieve past experiences to support downstream decision-making. However, most existing approaches organize and store memories in a flat manner and rely on simple similarity-based retrieval techniques. Even when structured memory is introduced, existing methods often struggle to explicitly capture the logical relationships among experiences or memory units. Moreover, memory access is largely detached from the constructed structure and still depends on shallow semantic retrieval, preventing agents from reasoning logically over long-horizon dependencies. In this work, we propose CompassMem, an event-centric memory framework inspired by Event Segmentation Theory. CompassMem organizes memory as an Event Graph by incrementally segmenting experiences into events and linking them through explicit logical relations. This graph serves as a logic map, enabling agents to perform structured and goal-directed navigation over memory beyond superficial retrieval, progressively gathering valuable memories to support long-horizon reasoning. Experiments on LoCoMo and NarrativeQA demonstrate that CompassMem consistently improves both retrieval and reasoning performance across multiple backbone models.",
      "authors": [
        "Yuyang Hu",
        "Jiongnan Liu",
        "Jiejun Tan",
        "Yutao Zhu",
        "Zhicheng Dou"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 08:44:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04726v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04722v1",
      "title": "Does Provenance Interact?",
      "abstract": "Data provenance (the process of determining the origin and derivation of data outputs) has applications across multiple domains including explaining database query results and auditing scientific workflows. Despite decades of research, provenance tracing remains challenging due to computational costs and storage overhead. In streaming systems such as Apache Flink, provenance graphs can grow super-linearly with data volume, posing significant scalability challenges. Temporal provenance is a promising direction, attaching timestamps to provenance information, enabling time-focused queries without maintaining complete historical records. However, existing temporal provenance methods primarily focus on system-level debugging, leaving a gap in data management applications. This paper proposes an agenda that uses Temporal Interaction Networks (TINs) to represent temporal provenance efficiently. We demonstrate TINs' applicability across streaming systems, transportation networks, and financial networks. We classify data into discrete and liquid types, define five temporal provenance query types, and propose a state-based indexing approach. Our vision outlines research directions toward making temporal provenance a practical tool for large-scale dataflows.",
      "authors": [
        "Chrysanthi Kosyfaki",
        "Ruiyuan Zhang",
        "Nikos Mamoulis",
        "Xiaofang Zhou"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-01-08 08:37:09+00:00",
      "link": "https://arxiv.org/pdf/2601.04722v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04700v1",
      "title": "PRISM: A Unified Framework for Post-Training LLMs Without Verifiable Rewards",
      "abstract": "Current techniques for post-training Large Language Models (LLMs) rely either on costly human supervision or on external verifiers to boost performance on tasks such as mathematical reasoning and code generation. However, as LLMs improve their problem-solving, any further improvement will potentially require high-quality solutions to difficult problems that are not available to humans. As a result, learning from unlabeled data is becoming increasingly attractive in the research community. Existing methods extract learning signal from a model's consistency, either by majority voting or by converting the model's internal confidence into reward. Although internal consistency metric such as entropy or self-certainty require no human intervention, as we show in this work, these are unreliable signals for large-scale and long-term training. To address the unreliability, we propose PRISM, a unified training framework that uses a Process Reward Model (PRM) to guide learning alongside model's internal confidence in the absence of ground-truth labels. We show that effectively combining PRM with self-certainty can lead to both stable training and better test-time performance, and also keep the model's internal confidence in check.",
      "authors": [
        "Mukesh Ghimire",
        "Aosong Feng",
        "Liwen You",
        "Youzhi Luo",
        "Fang Liu",
        "Xuan Zhu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 08:09:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04700v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04682v1",
      "title": "HATIR: Heat-Aware Diffusion for Turbulent Infrared Video Super-Resolution",
      "abstract": "Infrared video has been of great interest in visual tasks under challenging environments, but often suffers from severe atmospheric turbulence and compression degradation. Existing video super-resolution (VSR) methods either neglect the inherent modality gap between infrared and visible images or fail to restore turbulence-induced distortions. Directly cascading turbulence mitigation (TM) algorithms with VSR methods leads to error propagation and accumulation due to the decoupled modeling of degradation between turbulence and resolution. We introduce HATIR, a Heat-Aware Diffusion for Turbulent InfraRed Video Super-Resolution, which injects heat-aware deformation priors into the diffusion sampling path to jointly model the inverse process of turbulent degradation and structural detail loss. Specifically, HATIR constructs a Phasor-Guided Flow Estimator, rooted in the physical principle that thermally active regions exhibit consistent phasor responses over time, enabling reliable turbulence-aware flow to guide the reverse diffusion process. To ensure the fidelity of structural recovery under nonuniform distortions, a Turbulence-Aware Decoder is proposed to selectively suppress unstable temporal cues and enhance edge-aware feature aggregation via turbulence gating and structure-aware attention. We built FLIR-IVSR, the first dataset for turbulent infrared VSR, comprising paired LR-HR sequences from a FLIR T1050sc camera (1024 X 768) spanning 640 diverse scenes with varying camera and object motion conditions. This encourages future research in infrared VSR. Project page: https://github.com/JZ0606/HATIR",
      "authors": [
        "Yang Zou",
        "Xingyue Zhu",
        "Kaiqi Han",
        "Jun Ma",
        "Xingyuan Li",
        "Zhiying Jiang",
        "Jinyuan Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 07:49:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04682v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04651v1",
      "title": "Adversarial Yet Cooperative: Multi-Perspective Reasoning in Retrieved-Augmented Language Models",
      "abstract": "Recent advances in synergizing large reasoning models (LRMs) with retrieval-augmented generation (RAG) have shown promising results, yet two critical challenges remain: (1) reasoning models typically operate from a single, unchallenged perspective, limiting their ability to conduct deep, self-correcting reasoning over external documents, and (2) existing training paradigms rely excessively on outcome-oriented rewards, which provide insufficient signal for shaping the complex, multi-step reasoning process. To address these issues, we propose an Reasoner-Verifier framework named Adversarial Reasoning RAG (ARR). The Reasoner and Verifier engage in reasoning on retrieved evidence and critiquing each other's logic while being guided by process-aware advantage that requires no external scoring model. This reward combines explicit observational signals with internal model uncertainty to jointly optimize reasoning fidelity and verification rigor. Experiments on multiple benchmarks demonstrate the effectiveness of our method.",
      "authors": [
        "Can Xu",
        "Lingyong Yan",
        "Jiayi Wu",
        "Haosen Wang",
        "Shuaiqiang Wang",
        "Yuchen Li",
        "Jizhou Huang",
        "Dawei Yin",
        "Xiang Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.MA"
      ],
      "published": "2026-01-08 06:57:03+00:00",
      "link": "https://arxiv.org/pdf/2601.04651v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04633v1",
      "title": "MAGA-Bench: Machine-Augment-Generated Text via Alignment Detection Benchmark",
      "abstract": "Large Language Models (LLMs) alignment is constantly evolving. Machine-Generated Text (MGT) is becoming increasingly difficult to distinguish from Human-Written Text (HWT). This has exacerbated abuse issues such as fake news and online fraud. Fine-tuned detectors' generalization ability is highly dependent on dataset quality, and simply expanding the sources of MGT is insufficient. Further augment of generation process is required. According to HC-Var's theory, enhancing the alignment of generated text can not only facilitate attacks on existing detectors to test their robustness, but also help improve the generalization ability of detectors fine-tuned on it. Therefore, we propose \\textbf{M}achine-\\textbf{A}ugment-\\textbf{G}enerated Text via \\textbf{A}lignment (MAGA). MAGA's pipeline achieves comprehensive alignment from prompt construction to reasoning process, among which \\textbf{R}einforced \\textbf{L}earning from \\textbf{D}etectors \\textbf{F}eedback (RLDF), systematically proposed by us, serves as a key component. In our experiments, the RoBERTa detector fine-tuned on MAGA training set achieved an average improvement of 4.60\\% in generalization detection AUC. MAGA Dataset caused an average decrease of 8.13\\% in the AUC of the selected detectors, expecting to provide indicative significance for future research on the generalization detection ability of detectors.",
      "authors": [
        "Anyang Song",
        "Ying Cheng",
        "Yiqian Xu",
        "Rui Feng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 06:07:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04633v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04632v1",
      "title": "From National Curricula to Cultural Awareness: Constructing Open-Ended Culture-Specific Question Answering Dataset",
      "abstract": "Large language models (LLMs) achieve strong performance on many tasks, but their progress remains uneven across languages and cultures, often reflecting values latent in English-centric training data. To enable practical cultural alignment, we propose a scalable approach that leverages national social studies curricula as a foundation for culture-aware supervision. We introduce CuCu, an automated multi-agent LLM framework that transforms national textbook curricula into open-ended, culture-specific question-answer pairs. Applying CuCu to the Korean national social studies curriculum, we construct KCaQA, comprising 34.1k open-ended QA pairs. Our quantitative and qualitative analyses suggest that KCaQA covers culture-specific topics and produces responses grounded in local sociocultural contexts.",
      "authors": [
        "Haneul Yoo",
        "Won Ik Cho",
        "Geunhye Kim",
        "Jiyoon Han"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 06:04:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04632v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04618v1",
      "title": "Adaptive Retrieval for Reasoning-Intensive Retrieval",
      "abstract": "We study leveraging adaptive retrieval to ensure sufficient \"bridge\" documents are retrieved for reasoning-intensive retrieval. Bridge documents are those that contribute to the reasoning process yet are not directly relevant to the initial query. While existing reasoning-based reranker pipelines attempt to surface these documents in ranking, they suffer from bounded recall. Naive solution with adaptive retrieval into these pipelines often leads to planning error propagation. To address this, we propose REPAIR, a framework that bridges this gap by repurposing reasoning plans as dense feedback signals for adaptive retrieval. Our key distinction is enabling mid-course correction during reranking through selective adaptive retrieval, retrieving documents that support the pivotal plan. Experimental results on reasoning-intensive retrieval and complex QA tasks demonstrate that our method outperforms existing baselines by 5.6%pt.",
      "authors": [
        "Jongho Kim",
        "Jaeyoung Kim",
        "Seung-won Hwang",
        "Jihyuk Kim",
        "Yu Jin Kim",
        "Moontae Lee"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-08 05:46:50+00:00",
      "link": "https://arxiv.org/pdf/2601.04618v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04616v1",
      "title": "DeepHalo: A Neural Choice Model with Controllable Context Effects",
      "abstract": "Modeling human decision-making is central to applications such as recommendation, preference learning, and human-AI alignment. While many classic models assume context-independent choice behavior, a large body of behavioral research shows that preferences are often influenced by the composition of the choice set itself -- a phenomenon known as the context effect or Halo effect. These effects can manifest as pairwise (first-order) or even higher-order interactions among the available alternatives. Recent models that attempt to capture such effects either focus on the featureless setting or, in the feature-based setting, rely on restrictive interaction structures or entangle interactions across all orders, which limits interpretability. In this work, we propose DeepHalo, a neural modeling framework that incorporates features while enabling explicit control over interaction order and principled interpretation of context effects. Our model enables systematic identification of interaction effects by order and serves as a universal approximator of context-dependent choice functions when specialized to a featureless setting. Experiments on synthetic and real-world datasets demonstrate strong predictive performance while providing greater transparency into the drivers of choice.",
      "authors": [
        "Shuhan Zhang",
        "Zhi Wang",
        "Rui Gao",
        "Shuang Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 05:46:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04616v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04611v1",
      "title": "Character-R1: Enhancing Role-Aware Reasoning in Role-Playing Agents via RLVR",
      "abstract": "Current role-playing agents (RPAs) are typically constructed by imitating surface-level behaviors, but this approach lacks internal cognitive consistency, often causing out-of-character errors in complex situations. To address this, we propose Character-R1, a framework designed to provide comprehensive verifiable reward signals for effective role-aware reasoning, which are missing in recent studies. Specifically, our framework comprises three core designs: (1) Cognitive Focus Reward, which enforces explicit label-based analysis of 10 character elements (e.g., worldview) to structure internal cognition; (2) Reference-Guided Reward, which utilizes overlap-based metrics with reference responses as optimization anchors to enhance exploration and performance; and (3) Character-Conditioned Reward Normalization, which adjusts reward distributions based on character categories to ensure robust optimization across heterogeneous roles. Extensive experiments demonstrate that Character-R1 significantly outperforms existing methods in knowledge, memory and others.",
      "authors": [
        "Yihong Tang",
        "Kehai Chen",
        "Xuefeng Bai",
        "Benyou Wang",
        "Zeming Liu",
        "Haifeng Wang",
        "Min Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 05:33:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04611v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04597v1",
      "title": "THaLLE-ThaiLLM: Domain-Specialized Small LLMs for Finance and Thai -- Technical Report",
      "abstract": "Large Language Models (LLMs) have demonstrated significant potential across various domains, particularly in banking and finance, where they can automate complex tasks and enhance decision-making at scale. Due to privacy, security, and regulatory concerns, organizations often prefer on-premise deployment of LLMs. The ThaiLLM initiative aims to enhance Thai language capabilities in open-LLMs, enabling Thai industry to leverage advanced language models. However, organizations often face a trade-off between deploying multiple specialized models versus the prohibitive expense of training a single multi-capability model. To address this, we explore model merging as a resource-efficient alternative for developing high-performance, multi-capability LLMs. We present results from two key experiments: first, merging Qwen-8B with ThaiLLM-8B demonstrates how ThaiLLM-8B enhances Thai general capabilities, showing an uplift of M3 and M6 O-NET exams over the general instruction-following Qwen-8B. Second, we merge Qwen-8B with both ThaiLLM-8B and THaLLE-CFA-8B. This combination results in further improvements in performance across both general and financial domains, by demonstrating an uplift in both M3 and M6 O-NET, Flare-CFA, and Thai-IC benchmarks. The report showcases the viability of model merging for efficiently creating multi-capability LLMs.",
      "authors": [
        "KBTG Labs",
        ":",
        "Anuruth Lertpiya",
        "Danupat Khamnuansin",
        "Kantapong Sucharitpongpan",
        "Pornchanan Balee",
        "Tawunrat Chalothorn",
        "Thadpong Pongthawornkamol",
        "Monchai Lertsutthiwong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 05:01:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04597v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04587v1",
      "title": "FedKDX: Federated Learning with Negative Knowledge Distillation for Enhanced Healthcare AI Systems",
      "abstract": "This paper introduces FedKDX, a federated learning framework that addresses limitations in healthcare AI through Negative Knowledge Distillation (NKD). Unlike existing approaches that focus solely on positive knowledge transfer, FedKDX captures both target and non-target information to improve model generalization in healthcare applications. The framework integrates multiple knowledge transfer techniques--including traditional knowledge distillation, contrastive learning, and NKD--within a unified architecture that maintains privacy while reducing communication costs. Through experiments on healthcare datasets (SLEEP, UCI-HAR, and PAMAP2), FedKDX demonstrates improved accuracy (up to 2.53% over state-of-the-art methods), faster convergence, and better performance on non-IID data distributions. Theoretical analysis supports NKD's contribution to addressing statistical heterogeneity in distributed healthcare data. The approach shows promise for privacy-sensitive medical applications under regulatory frameworks like HIPAA and GDPR, offering a balanced solution between performance and practical implementation requirements in decentralized healthcare settings. The code and model are available at https://github.com/phamdinhdat-ai/Fed_2024.",
      "authors": [
        "Quang-Tu Pham",
        "Hoang-Dieu Vu",
        "Dinh-Dat Pham",
        "Hieu H. Pham"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 04:35:28+00:00",
      "link": "https://arxiv.org/pdf/2601.04587v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04577v1",
      "title": "Sci-Reasoning: A Dataset Decoding AI Innovation Patterns",
      "abstract": "While AI innovation accelerates rapidly, the intellectual process behind breakthroughs -- how researchers identify gaps, synthesize prior work, and generate insights -- remains poorly understood. The lack of structured data on scientific reasoning hinders systematic analysis and development of AI research agents. We introduce Sci-Reasoning, the first dataset capturing the intellectual synthesis behind high-quality AI research. Using community-validated quality signals and an LLM-accelerated, human-verified pipeline, we trace Oral and Spotlight papers across NeurIPS, ICML, and ICLR (2023-2025) to its key predecessors, articulating specific reasoning links in a structured format. Our analysis identifies 15 distinct thinking patterns, with three dominant strategies accounting for 52.7%: Gap-Driven Reframing (24.2%), Cross-Domain Synthesis (18.0%), and Representation Shift (10.5%). The most powerful innovation recipes combine multiple patterns: Gap-Driven Reframing + Representation Shift, Cross-Domain Synthesis + Representation Shift, and Gap-Driven Reframing + Cross-Domain Synthesis. This dataset enables quantitative studies of scientific progress and provides structured reasoning trajectories for training the next generation AI research agents.",
      "authors": [
        "Jiachen Liu",
        "Maestro Harmon",
        "Zechen Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 04:12:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04577v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04572v1",
      "title": "Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation",
      "abstract": "Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.   To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.",
      "authors": [
        "Xiaowei Mao",
        "Huihu Ding",
        "Yan Lin",
        "Tingrui Wu",
        "Shengnan Guo",
        "Dazhuo Qiu",
        "Feiling Fang",
        "Jilin Hu",
        "Huaiyu Wan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 04:03:32+00:00",
      "link": "https://arxiv.org/pdf/2601.04572v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04571v1",
      "title": "Enhancing Multimodal Retrieval via Complementary Information Extraction and Alignment",
      "abstract": "Multimodal retrieval has emerged as a promising yet challenging research direction in recent years. Most existing studies in multimodal retrieval focus on capturing information in multimodal data that is similar to their paired texts, but often ignores the complementary information contained in multimodal data. In this study, we propose CIEA, a novel multimodal retrieval approach that employs Complementary Information Extraction and Alignment, which transforms both text and images in documents into a unified latent space and features a complementary information extractor designed to identify and preserve differences in the image representations. We optimize CIEA using two complementary contrastive losses to ensure semantic integrity and effectively capture the complementary information contained in images. Extensive experiments demonstrate the effectiveness of CIEA, which achieves significant improvements over both divide-and-conquer models and universal dense retrieval models. We provide an ablation study, further discussions, and case studies to highlight the advancements achieved by CIEA. To promote further research in the community, we have released the source code at https://github.com/zengdlong/CIEA.",
      "authors": [
        "Delong Zeng",
        "Yuexiang Xie",
        "Yaliang Li",
        "Ying Shen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.MM"
      ],
      "published": "2026-01-08 04:02:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04571v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04569v1",
      "title": "Industrial Data-Service-Knowledge Governance: Toward Integrated and Trusted Intelligence for Industry 5.0",
      "abstract": "The convergence of artificial intelligence, cyber-physical systems, and cross-enterprise data ecosystems has propelled industrial intelligence to unprecedented scales. Yet, the absence of a unified trust foundation across data, services, and knowledge layers undermines reliability, accountability, and regulatory compliance in real-world deployments. While existing surveys address isolated aspects, such as data governance, service orchestration, and knowledge representation, none provides a holistic, cross-layer perspective on trustworthiness tailored to industrial settings. To bridge this gap, we present \\textsc{Trisk} (TRusted Industrial Data-Service-Knowledge governance), a novel conceptual and taxonomic framework for trustworthy industrial intelligence. Grounded in a five-dimensional trust model (quality, security, privacy, fairness, and explainability), \\textsc{Trisk} unifies 120+ representative studies along three orthogonal axes: governance scope (data, service, and knowledge), architectural paradigm (centralized, federated, or edge-embedded), and enabling technology (knowledge graphs, zero-trust policies, causal inference, etc.). We systematically analyze how trust propagates across digital layers, identify critical gaps in semantic interoperability, runtime policy enforcement, and operational/information technologies alignment, and evaluate the maturity of current industrial implementations. Finally, we articulate a forward-looking research agenda for Industry 5.0, advocating for an integrated governance fabric that embeds verifiable trust semantics into every layer of the industrial intelligence stack. This survey serves as both a foundational reference for researchers and a practical roadmap for engineers to deploy trustworthy AI in complex and multi-stakeholder environments.",
      "authors": [
        "Hailiang Zhao",
        "Ziqi Wang",
        "Daojiang Hu",
        "Zhiwei Ling",
        "Wenzhuo Qian",
        "Jiahui Zhai",
        "Yuhao Yang",
        "Zhipeng Gao",
        "Mingyi Liu",
        "Kai Di",
        "Xinkui Zhao",
        "Zhongjie Wang",
        "Jianwei Yin",
        "MengChu Zhou",
        "Shuiguang Deng"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-01-08 03:53:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04569v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04544v1",
      "title": "TCAndon-Router: Adaptive Reasoning Router for Multi-Agent Collaboration",
      "abstract": "Multi-Agent Systems(MAS) have become a powerful paradigm for building high performance intelligent applications. Within these systems, the router responsible for determining which expert agents should handle a given query plays a crucial role in overall performance. Existing routing strategies generally fall into two categories: performance routing, which balances latency and cost across models of different sizes, and task routing, which assigns queries to domain-specific experts to improve accuracy. In real-world enterprise applications, task routing is more suitable; however, most existing approaches rely on static single-label decisions, which introduce two major limitations: (i) difficulty in seamlessly integrating new agents as business domains expand, and (ii) routing conflicts caused by overlapping agent capabilities, ultimately degrading accuracy and robustness.To address these challenges, we propose TCAndon-Router(TCAR): an adaptive reasoning router for multi-agent collaboration. Unlike traditional routers, TCAR supports dynamic agent onboarding and first generates a natural-language reasoning chain before predicting a set of candidate agents capable of handling the query. In addition, we design a collaborative execution pipeline in which selected agents independently produce responses, which are then aggregated and refined into a single high-quality response by a dedicated Refining Agent.Experiments on public datasets and real enterprise data demonstrate that TCAR significantly improves routing accuracy, reduces routing conflicts, and remains robust in ambiguous scenarios. We have released TCAR at https://huggingface.co/tencent/TCAndon-Router to support future research on explainable and collaborative multi-agent routing.",
      "authors": [
        "Jiuzhou Zhao",
        "Chunrong Chen",
        "Chenqi Qiao",
        "Lebin Zheng",
        "Minqi Han",
        "Yanchi Liu Yongzhou Xu Xiaochuan Xu Min Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 03:17:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04544v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04539v1",
      "title": "Paradoxical noise preference in RNNs",
      "abstract": "In recurrent neural networks (RNNs) used to model biological neural networks, noise is typically introduced during training to emulate biological variability and regularize learning. The expectation is that removing the noise at test time should preserve or improve performance. Contrary to this intuition, we find that continuous-time recurrent neural networks (CTRNNs) often perform best at a nonzero noise level, specifically, the same level used during training. This noise preference typically arises when noise is injected inside the neural activation function; networks trained with noise injected outside the activation function perform best with zero noise. Through analyses of simple function approximation, maze navigation, and single neuron regulator tasks, we show that the phenomenon stems from noise-induced shifts of fixed points (stationary distributions) in the underlying stochastic dynamics of the RNNs. These fixed point shifts are noise-level dependent and bias the network outputs when the noise is removed, degrading performance. Analytical and numerical results show that the bias arises when neural states operate near activation function nonlinearities, where noise is asymmetrically attenuated, and that performance optimization incentivizes operation near these nonlinearities. Thus, networks can overfit to the stochastic training environment itself rather than just to the input-output data. The phenomenon is distinct from stochastic resonance, wherein nonzero noise enhances signal processing. Our findings reveal that training noise can become an integral part of the computation learned by recurrent networks, with implications for understanding neural population dynamics and for the design of robust artificial RNNs.",
      "authors": [
        "Noah Eckstein",
        "Manoj Srinivasan"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 03:11:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04539v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04526v1",
      "title": "Advancing Language Models for Code-related Tasks",
      "abstract": "Recent advances in language models (LMs) have driven significant progress in various software engineering tasks. However, existing LMs still struggle with complex programming scenarios due to limitations in data quality, model architecture, and reasoning capability. This research systematically addresses these challenges through three complementary directions: (1) improving code data quality with a code difference-guided adversarial augmentation technique (CODA) and a code denoising technique (CodeDenoise); (2) enhancing model architecture via syntax-guided code LMs (LEAM and LEAM++); and (3) advancing model reasoning with a prompting technique (muFiX) and an agent-based technique (Specine). These techniques aim to promote the practical adoption of LMs in software development and further advance intelligent software engineering.",
      "authors": [
        "Zhao Tian"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 02:48:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04526v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04524v1",
      "title": "BioPIE: A Biomedical Protocol Information Extraction Dataset for High-Reasoning-Complexity Experiment Question Answer",
      "abstract": "Question Answer (QA) systems for biomedical experiments facilitate cross-disciplinary communication, and serve as a foundation for downstream tasks, e.g., laboratory automation. High Information Density (HID) and Multi-Step Reasoning (MSR) pose unique challenges for biomedical experimental QA. While extracting structured knowledge, e.g., Knowledge Graphs (KGs), can substantially benefit biomedical experimental QA. Existing biomedical datasets focus on general or coarsegrained knowledge and thus fail to support the fine-grained experimental reasoning demanded by HID and MSR. To address this gap, we introduce Biomedical Protocol Information Extraction Dataset (BioPIE), a dataset that provides procedure-centric KGs of experimental entities, actions, and relations at a scale that supports reasoning over biomedical experiments across protocols. We evaluate information extraction methods on BioPIE, and implement a QA system that leverages BioPIE, showcasing performance gains on test, HID, and MSR question sets, showing that the structured experimental knowledge in BioPIE underpins both AI-assisted and more autonomous biomedical experimentation.",
      "authors": [
        "Haofei Hou",
        "Shunyi Zhao",
        "Fanxu Meng",
        "Kairui Yang",
        "Lecheng Ruan",
        "Qining Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 02:44:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04524v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04516v1",
      "title": "LinguaGame: A Linguistically Grounded Game-Theoretic Paradigm for Multi-Agent Dialogue Generation",
      "abstract": "Large Language Models (LLMs) have enabled Multi-Agent Systems (MASs) where agents interact through natural language to solve complex tasks or simulate multi-party dialogues. Recent work on LLM-based MASs has mainly focused on architecture design, such as role assignment and workflow orchestration. In contrast, this paper targets the interaction process itself, aiming to improve agents' communication efficiency by helping them convey their intended meaning more effectively through language. To this end, we propose LinguaGame, a linguistically-grounded game-theoretic paradigm for multi-agent dialogue generation. Our approach models dialogue as a signalling game over communicative intents and strategies, solved with a training-free equilibrium approximation algorithm for inference-time decision adjustment. Unlike prior game-theoretic MASs, whose game designs are often tightly coupled with task-specific objectives, our framework relies on linguistically informed reasoning with minimal task-specific coupling. Specifically, it treats dialogue as intentional and strategic communication, requiring agents to infer what others aim to achieve (intents) and how they pursue those goals (strategies). We evaluate our framework in simulated courtroom proceedings and debates, with human expert assessments showing significant gains in communication efficiency.",
      "authors": [
        "Yuxiao Ye",
        "Yiming Zhang",
        "Yiran Ma",
        "Huiyuan Xie",
        "Huining Zhu",
        "Zhiyuan Liu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 02:30:43+00:00",
      "link": "https://arxiv.org/pdf/2601.04516v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04498v1",
      "title": "IGenBench: Benchmarking the Reliability of Text-to-Infographic Generation",
      "abstract": "Infographics are composite visual artifacts that combine data visualizations with textual and illustrative elements to communicate information. While recent text-to-image (T2I) models can generate aesthetically appealing images, their reliability in generating infographics remains unclear. Generated infographics may appear correct at first glance but contain easily overlooked issues, such as distorted data encoding or incorrect textual content. We present IGENBENCH, the first benchmark for evaluating the reliability of text-to-infographic generation, comprising 600 curated test cases spanning 30 infographic types. We design an automated evaluation framework that decomposes reliability verification into atomic yes/no questions based on a taxonomy of 10 question types. We employ multimodal large language models (MLLMs) to verify each question, yielding question-level accuracy (Q-ACC) and infographic-level accuracy (I-ACC). We comprehensively evaluate 10 state-of-the-art T2I models on IGENBENCH. Our systematic analysis reveals key insights for future model development: (i) a three-tier performance hierarchy with the top model achieving Q-ACC of 0.90 but I-ACC of only 0.49; (ii) data-related dimensions emerging as universal bottlenecks (e.g., Data Completeness: 0.21); and (iii) the challenge of achieving end-to-end correctness across all models. We release IGENBENCH at https://igen-bench.vercel.app/.",
      "authors": [
        "Yinghao Tang",
        "Xueding Liu",
        "Boyuan Zhang",
        "Tingfeng Lan",
        "Yupeng Xie",
        "Jiale Lao",
        "Yiyao Wang",
        "Haoxuan Li",
        "Tingting Gao",
        "Bo Pan",
        "Luoxuan Weng",
        "Xiuqi Huang",
        "Minfeng Zhu",
        "Yingchaojie Feng",
        "Yuyu Luo",
        "Wei Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-01-08 02:06:53+00:00",
      "link": "https://arxiv.org/pdf/2601.04498v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04494v1",
      "title": "Differential Locally Injective Grid Deformation and Optimization",
      "abstract": "Grids are a general representation for capturing regularly-spaced information, but since they are uniform in space, they cannot dynamically allocate resolution to regions with varying levels of detail. There has been some exploration of indirect grid adaptivity by replacing uniform grids with tetrahedral meshes or locally subdivided grids, as inversion-free deformation of grids is difficult. This work develops an inversion-free grid deformation method that optimizes differential weight to adaptively compress space. The method is the first to optimize grid vertices as differential elements using vertex-colorings, decomposing a dense input linear system into many independent sets of vertices which can be optimized concurrently. This method is then also extended to optimize UV meshes with convex boundaries. Experimentally, this differential representation leads to a smoother optimization manifold than updating extrinsic vertex coordinates. By optimizing each sets of vertices in a coloring separately, local injectivity checks are straightforward since the valid region for each vertex is fixed. This enables the use of optimizers such as Adam, as each vertex can be optimized independently of other vertices. We demonstrate the generality and efficacy of this approach through applications in isosurface extraction for inverse rendering, image compaction, and mesh parameterization.",
      "authors": [
        "Julian Knodt",
        "Seung-Hwan Baek"
      ],
      "primary_category": "cs.GR",
      "categories": [
        "cs.GR"
      ],
      "published": "2026-01-08 01:58:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04494v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04455v1",
      "title": "Re-Rankers as Relevance Judges",
      "abstract": "Using large language models (LLMs) to predict relevance judgments has shown promising results. Most studies treat this task as a distinct research line, e.g., focusing on prompt design for predicting relevance labels given a query and passage. However, predicting relevance judgments is essentially a form of relevance prediction, a problem extensively studied in tasks such as re-ranking. Despite this potential overlap, little research has explored reusing or adapting established re-ranking methods to predict relevance judgments, leading to potential resource waste and redundant development. To bridge this gap, we reproduce re-rankers in a re-ranker-as-relevance-judge setup. We design two adaptation strategies: (i) using binary tokens (e.g., \"true\" and \"false\") generated by a re-ranker as direct judgments, and (ii) converting continuous re-ranking scores into binary labels via thresholding. We perform extensive experiments on TREC-DL 2019 to 2023 with 8 re-rankers from 3 families, ranging from 220M to 32B, and analyse the evaluation bias exhibited by re-ranker-based judges. Results show that re-ranker-based relevance judges, under both strategies, can outperform UMBRELA, a state-of-the-art LLM-based relevance judge, in around 40% to 50% of the cases; they also exhibit strong self-preference towards their own and same-family re-rankers, as well as cross-family bias.",
      "authors": [
        "Chuan Meng",
        "Jiqun Liu",
        "Mohammad Aliannejadi",
        "Fengran Mo",
        "Jeff Dalton",
        "Maarten de Rijke"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 00:02:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04455v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04447v1",
      "title": "When Predictions Shape Reality: A Socio-Technical Synthesis of Performative Predictions in Machine Learning",
      "abstract": "Machine learning models are increasingly used in high-stakes domains where their predictions can actively shape the environments in which they operate, a phenomenon known as performative prediction. This dynamic, in which the deployment of the model influences the very outcome it seeks to predict, can lead to unintended consequences, including feedback loops, performance issues, and significant societal risks. While the literature in the field has grown rapidly in recent years, a socio-technical synthesis that systemises the phenomenon concepts and provides practical guidance has been lacking. This Systematisation of Knowledge (SoK) addresses this gap by providing a comprehensive review of the literature on performative predictions. We provide an overview of the primary mechanisms through which performativity manifests, present a typology of associated risks, and survey the proposed solutions offered in the literature. Our primary contribution is the ``Performative Strength vs. Impact Matrix\" assessment framework. This practical tool is designed to help practitioners assess the potential influence and severity of performativity on their deployed predictive models and select the appropriate level of algorithmic or human intervention.",
      "authors": [
        "Gal Fybish",
        "Teo Susnjak"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 23:28:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04447v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04424v1",
      "title": "Gavel: Agent Meets Checklist for Evaluating LLMs on Long-Context Legal Summarization",
      "abstract": "Large language models (LLMs) now support contexts of up to 1M tokens, but their effectiveness on complex long-context tasks remains unclear. In this paper, we study multi-document legal case summarization, where a single case often spans many documents totaling 100K-500K tokens. We introduce Gavel-Ref, a reference-based evaluation framework with multi-value checklist evaluation over 26 items, as well as residual fact and writing-style evaluations. Using Gavel-Ref, we go beyond the single aggregate scores reported in prior work and systematically evaluate 12 frontier LLMs on 100 legal cases ranging from 32K to 512K tokens, primarily from 2025. Our results show that even the strongest model, Gemini 2.5 Pro, achieves only around 50 of $S_{\\text{Gavel-Ref}}$, highlighting the difficulty of the task. Models perform well on simple checklist items (e.g., filing date) but struggle on multi-value or rare ones such as settlements and monitor reports. As LLMs continue to improve and may surpass human-written summaries -- making human references less reliable -- we develop Gavel-Agent, an efficient and autonomous agent scaffold that equips LLMs with six tools to navigate and extract checklists directly from case documents. With Qwen3, Gavel-Agent reduces token usage by 36% while resulting in only a 7% drop in $S_{\\text{checklist}}$ compared to end-to-end extraction with GPT-4.1.",
      "authors": [
        "Yao Dou",
        "Wei Xu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 22:08:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04424v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04423v1",
      "title": "Learning Multinomial Logits in $O(n \\log n)$ time",
      "abstract": "A Multinomial Logit (MNL) model is composed of a finite universe of items $[n]=\\{1,..., n\\}$, each assigned a positive weight. A query specifies an admissible subset -- called a slate -- and the model chooses one item from that slate with probability proportional to its weight. This query model is also known as the Plackett-Luce model or conditional sampling oracle in the literature. Although MNLs have been studied extensively, a basic computational question remains open: given query access to slates, how efficiently can we learn weights so that, for every slate, the induced choice distribution is within total variation distance $\\varepsilon$ of the ground truth? This question is central to MNL learning and has direct implications for modern recommender system interfaces.   We provide two algorithms for this task, one with adaptive queries and one with non-adaptive queries. Each algorithm outputs an MNL $M'$ that induces, for each slate $S$, a distribution $M'_S$ on $S$ that is within $\\varepsilon$ total variation distance of the true distribution. Our adaptive algorithm makes $O\\left(\\frac{n}{\\varepsilon^{3}}\\log n\\right)$ queries, while our non-adaptive algorithm makes $O\\left(\\frac{n^{2}}{\\varepsilon^{3}}\\log n \\log\\frac{n}{\\varepsilon}\\right)$ queries. Both algorithms query only slates of size two and run in time proportional to their query complexity.   We complement these upper bounds with lower bounds of $Ω\\left(\\frac{n}{\\varepsilon^{2}}\\log n\\right)$ for adaptive queries and $Ω\\left(\\frac{n^{2}}{\\varepsilon^{2}}\\log n\\right)$ for non-adaptive queries, thus proving that our adaptive algorithm is optimal in its dependence on the support size $n$, while the non-adaptive one is tight within a $\\log n$ factor.",
      "authors": [
        "Flavio Chierichetti",
        "Mirko Giacchini",
        "Ravi Kumar",
        "Silvio Lattanzi",
        "Alessandro Panconesi",
        "Erasmo Tani",
        "Andrew Tomkins"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.LG",
        "math.ST",
        "stat.ML"
      ],
      "published": "2026-01-07 22:07:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04423v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04404v1",
      "title": "3D-Agent:Tri-Modal Multi-Agent Collaboration for Scalable 3D Object Annotation",
      "abstract": "Driven by applications in autonomous driving robotics and augmented reality 3D object annotation presents challenges beyond 2D annotation including spatial complexity occlusion and viewpoint inconsistency Existing approaches based on single models often struggle to address these issues effectively We propose Tri MARF a novel framework that integrates tri modal inputs including 2D multi view images textual descriptions and 3D point clouds within a multi agent collaborative architecture to enhance large scale 3D annotation Tri MARF consists of three specialized agents a vision language model agent for generating multi view descriptions an information aggregation agent for selecting optimal descriptions and a gating agent that aligns textual semantics with 3D geometry for refined captioning Extensive experiments on Objaverse LVIS Objaverse XL and ABO demonstrate that Tri MARF substantially outperforms existing methods achieving a CLIPScore of 88 point 7 compared to prior state of the art methods retrieval accuracy of 45 point 2 and 43 point 8 on ViLT R at 5 and a throughput of up to 12000 objects per hour on a single NVIDIA A100 GPU",
      "authors": [
        "Jusheng Zhang",
        "Yijia Fan",
        "Zimo Wen",
        "Jian Wang",
        "Keze Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 21:23:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04404v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04395v1",
      "title": "The Overlooked Role of Graded Relevance Thresholds in Multilingual Dense Retrieval",
      "abstract": "Dense retrieval models are typically fine-tuned with contrastive learning objectives that require binary relevance judgments, even though relevance is inherently graded. We analyze how graded relevance scores and the threshold used to convert them into binary labels affect multilingual dense retrieval. Using a multilingual dataset with LLM-annotated relevance scores, we examine monolingual, multilingual mixture, and cross-lingual retrieval scenarios. Our findings show that the optimal threshold varies systematically across languages and tasks, often reflecting differences in resource level. A well-chosen threshold can improve effectiveness, reduce the amount of fine-tuning data required, and mitigate annotation noise, whereas a poorly chosen one can degrade performance. We argue that graded relevance is a valuable but underutilized signal for dense retrieval, and that threshold calibration should be treated as a principled component of the fine-tuning pipeline.",
      "authors": [
        "Tomer Wullach",
        "Ori Shapira",
        "Amir DN Cohen"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-07 21:14:48+00:00",
      "link": "https://arxiv.org/pdf/2601.04395v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04377v1",
      "title": "Disco-RAG: Discourse-Aware Retrieval-Augmented Generation",
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as an important means of enhancing the performance of large language models (LLMs) in knowledge-intensive tasks. However, most existing RAG strategies treat retrieved passages in a flat and unstructured way, which prevents the model from capturing structural cues and constrains its ability to synthesize knowledge from dispersed evidence across documents. To overcome these limitations, we propose Disco-RAG, a discourse-aware framework that explicitly injects discourse signals into the generation process. Our method constructs intra-chunk discourse trees to capture local hierarchies and builds inter-chunk rhetorical graphs to model cross-passage coherence. These structures are jointly integrated into a planning blueprint that conditions the generation. Experiments on question answering and long-document summarization benchmarks show the efficacy of our approach. Disco-RAG achieves state-of-the-art results on the benchmarks without fine-tuning. These findings underscore the important role of discourse structure in advancing RAG systems.",
      "authors": [
        "Dongqi Liu",
        "Hang Ding",
        "Qiming Feng",
        "Jian Li",
        "Xurong Xie",
        "Zhucun Xue",
        "Chengjie Wang",
        "Jiangning Zhang",
        "Yabiao Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 20:32:50+00:00",
      "link": "https://arxiv.org/pdf/2601.04377v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04359v1",
      "title": "PackCache: A Training-Free Acceleration Method for Unified Autoregressive Video Generation via Compact KV-Cache",
      "abstract": "A unified autoregressive model is a Transformer-based framework that addresses diverse multimodal tasks (e.g., text, image, video) as a single sequence modeling problem under a shared token space. Such models rely on the KV-cache mechanism to reduce attention computation from O(T^2) to O(T); however, KV-cache size grows linearly with the number of generated tokens, and it rapidly becomes the dominant bottleneck limiting inference efficiency and generative length. Unified autoregressive video generation inherits this limitation. Our analysis reveals that KV-cache tokens exhibit distinct spatiotemporal properties: (i) text and conditioning-image tokens act as persistent semantic anchors that consistently receive high attention, and (ii) attention to previous frames naturally decays with temporal distance. Leveraging these observations, we introduce PackCache, a training-free KV-cache management method that dynamically compacts the KV cache through three coordinated mechanisms: condition anchoring that preserves semantic references, cross-frame decay modeling that allocates cache budget according to temporal distance, and spatially preserving position embedding that maintains coherent 3D structure under cache removal. In terms of efficiency, PackCache accelerates end-to-end generation by 1.7-2.2x on 48-frame long sequences, showcasing its strong potential for enabling longer-sequence video generation. Notably, the final four frames - the portion most impacted by the progressively expanding KV-cache and thus the most expensive segment of the clip - PackCache delivers a 2.6x and 3.7x acceleration on A40 and H200, respectively, for 48-frame videos.",
      "authors": [
        "Kunyang Li",
        "Mubarak Shah",
        "Yuzhang Shang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 19:51:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04359v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04350v1",
      "title": "RIGOURATE: Quantifying Scientific Exaggeration with Evidence-Aligned Claim Evaluation",
      "abstract": "Scientific rigour tends to be sidelined in favour of bold statements, leading authors to overstate claims beyond what their results support. We present RIGOURATE, a two-stage multimodal framework that retrieves supporting evidence from a paper's body and assigns each claim an overstatement score. The framework consists of a dataset of over 10K claim-evidence sets from ICLR and NeurIPS papers, annotated using eight LLMs, with overstatement scores calibrated using peer-review comments and validated through human evaluation. It employes a fine-tuned reranker for evidence retrieval and a fine-tuned model to predict overstatement scores with justification. Compared to strong baselines, RIGOURATE enables improved evidence retrieval and overstatement detection. Overall, our work operationalises evidential proportionality and supports clearer, more transparent scientific communication.",
      "authors": [
        "Joseph James",
        "Chenghao Xiao",
        "Yucheng Li",
        "Nafise Sadat Moosavi",
        "Chenghua Lin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 19:36:08+00:00",
      "link": "https://arxiv.org/pdf/2601.04350v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04349v1",
      "title": "Hybrid Cloud Architectures for Research Computing: Applications and Use Cases",
      "abstract": "Scientific research increasingly depends on robust and scalable IT infrastructures to support complex computational workflows. With the proliferation of services provided by research infrastructures, NRENs, and commercial cloud providers, researchers must navigate a fragmented ecosystem of computing environments, balancing performance, cost, scalability, and accessibility. Hybrid cloud architectures offer a compelling solution by integrating multiple computing environments to enhance flexibility, resource efficiency, and access to specialised hardware.   This paper provides a comprehensive overview of hybrid cloud deployment models, focusing on grid and cloud platforms (OpenPBS, SLURM, OpenStack, Kubernetes) and workflow management tools (Nextflow, Snakemake, CWL). We explore strategies for federated computing, multi-cloud orchestration, and workload scheduling, addressing key challenges such as interoperability, data security, reproducibility, and network performance. Drawing on implementations from life sciences, as coordinated by the ELIXIR Compute Platform and their integration into a wider EOSC context, we propose a roadmap for accelerating hybrid cloud adoption in research computing, emphasising governance frameworks and technical solutions that can drive sustainable and scalable infrastructure development.",
      "authors": [
        "Xaver Stiensmeier",
        "Alexander Kanitz",
        "Jan Krüger",
        "Santiago Insua",
        "Adrián Rošinec",
        "Viktória Spišáková",
        "Lukáš Hejtmánek",
        "David Yuan",
        "Gavin Farrell",
        "Jonathan Tedds",
        "Juha Törnroos",
        "Harald Wagener",
        "Alex Sczyrba",
        "Nils Hoffmann",
        "Matej Antol"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC"
      ],
      "published": "2026-01-07 19:35:10+00:00",
      "link": "https://arxiv.org/pdf/2601.04349v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04348v1",
      "title": "SCAR-GS: Spatial Context Attention for Residuals in Progressive Gaussian Splatting",
      "abstract": "Recent advances in 3D Gaussian Splatting have allowed for real-time, high-fidelity novel view synthesis. Nonetheless, these models have significant storage requirements for large and medium-sized scenes, hindering their deployment over cloud and streaming services. Some of the most recent progressive compression techniques for these models rely on progressive masking and scalar quantization techniques to reduce the bitrate of Gaussian attributes using spatial context models. While effective, scalar quantization may not optimally capture the correlations of high-dimensional feature vectors, which can potentially limit the rate-distortion performance.   In this work, we introduce a novel progressive codec for 3D Gaussian Splatting that replaces traditional methods with a more powerful Residual Vector Quantization approach to compress the primitive features. Our key contribution is an auto-regressive entropy model, guided by a multi-resolution hash grid, that accurately predicts the conditional probability of each successive transmitted index, allowing for coarse and refinement layers to be compressed with high efficiency.",
      "authors": [
        "Diego Revilla",
        "Pooja Suresh",
        "Anand Bhojan",
        "Ooi Wei Tsang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.GR"
      ],
      "published": "2026-01-07 19:34:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04348v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04342v1",
      "title": "ReHyAt: Recurrent Hybrid Attention for Video Diffusion Transformers",
      "abstract": "Recent advances in video diffusion models have shifted towards transformer-based architectures, achieving state-of-the-art video generation but at the cost of quadratic attention complexity, which severely limits scalability for longer sequences. We introduce ReHyAt, a Recurrent Hybrid Attention mechanism that combines the fidelity of softmax attention with the efficiency of linear attention, enabling chunk-wise recurrent reformulation and constant memory usage. Unlike the concurrent linear-only SANA Video, ReHyAt's hybrid design allows efficient distillation from existing softmax-based models, reducing the training cost by two orders of magnitude to ~160 GPU hours, while being competitive in the quality. Our light-weight distillation and finetuning pipeline provides a recipe that can be applied to future state-of-the-art bidirectional softmax-based models. Experiments on VBench and VBench-2.0, as well as a human preference study, demonstrate that ReHyAt achieves state-of-the-art video quality while reducing attention cost from quadratic to linear, unlocking practical scalability for long-duration and on-device video generation. Project page is available at https://qualcomm-ai-research.github.io/rehyat.",
      "authors": [
        "Mohsen Ghafoorian",
        "Amirhossein Habibian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 19:26:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04342v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04336v1",
      "title": "Pilot Study on Student Public Opinion Regarding GAI",
      "abstract": "The emergence of generative AI (GAI) has sparked diverse opinions regarding its appropriate use across various domains, including education. This pilot study investigates university students' perceptions of GAI in higher education classrooms, aiming to lay the groundwork for understanding these attitudes. With a participation rate of approximately 4.4%, the study highlights the challenges of engaging students in GAI-related research and underscores the need for larger sample sizes in future studies. By gaining insights into student perspectives, instructors can better prepare to integrate discussions of GAI into their classrooms, fostering informed and critical engagement with this transformative technology.",
      "authors": [
        "William Franz Lamberti",
        "Sunbin Kim",
        "Samantha Rose Lawrence"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.HC",
        "stat.AP"
      ],
      "published": "2026-01-07 19:16:50+00:00",
      "link": "https://arxiv.org/pdf/2601.04336v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04302v1",
      "title": "Embedding Textual Information in Images Using Quinary Pixel Combinations",
      "abstract": "This paper presents a novel technique for embedding textual data into images using quinary combinations of pixel intensities in RGB space. Existing methods predominantly rely on least and most significant bit (LSB & MSB) manipulation, Pixel Value Differencing (PVD), spatial perturbations in RGB channels, transform domain based methods, Quantization methods, Edge and Region based methods and more recently through deep learning methods and generative AI techniques for hiding textual information in spatial domain of images. Most of them are dependent on pixel intensity flipping over multiple pixels, such as LSB and combination of LSB based methodologies, and on transform coefficients, often resulting in the form of noise. Encoding and Decoding are deterministic in most of the existing approaches and are computationally heavy in case of higher models such as deep learning and gen AI approaches. The proposed method works on quinary pixel intensity combinations in RGB space, where five controlled different pixel intensity variations in each of the R, G, and B channels formulate up to one hundred and twenty five distinct pixel intensity combinations. These combinations are mapped to textual symbols, enabling the representation of uppercase and lowercase alphabetic characters, numeric digits, whitespace, and commonly used special characters. Different metrics such as MSE, MAE, SNR, PSNR, SSIM, Histogram Comparison and Heatmap analysis, were evaluated for both original and encoded images resulting in no significant distortion in the images. Furthermore, the method achieves improved embedding efficiency by encoding a complete textual symbol within a single RGB pixel, in contrast to LSB and MSB based approaches that typically require multiple pixels or multi-step processes, as well as transform and learning based methods that incur higher computational overhead.",
      "authors": [
        "A V Uday Kiran Kandala"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 18:58:00+00:00",
      "link": "https://arxiv.org/pdf/2601.04302v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04191v1",
      "title": "Embedding Autonomous Agents in Resource-Constrained Robotic Platforms",
      "abstract": "Many embedded devices operate under resource constraints and in dynamic environments, requiring local decision-making capabilities. Enabling devices to make independent decisions in such environments can improve the responsiveness of the system and reduce the dependence on constant external control. In this work, we integrate an autonomous agent, programmed using AgentSpeak, with a small two-wheeled robot that explores a maze using its own decision-making and sensor data. Experimental results show that the agent successfully solved the maze in 59 seconds using 287 reasoning cycles, with decision phases taking less than one millisecond. These results indicate that the reasoning process is efficient enough for real-time execution on resource-constrained hardware. This integration demonstrates how high-level agent-based control can be applied to resource-constrained embedded systems for autonomous operation.",
      "authors": [
        "Negar Halakou",
        "Juan F. Gutierrez",
        "Ye Sun",
        "Han Jiang",
        "Xueming Wu",
        "Yilun Song",
        "Andres Gomez"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-01-07 18:57:32+00:00",
      "link": "https://arxiv.org/pdf/2601.04191v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04301v1",
      "title": "Quantifying the Effect of Test Set Contamination on Generative Evaluations",
      "abstract": "As frontier AI systems are pretrained on web-scale data, test set contamination has become a critical concern for accurately assessing their capabilities. While research has thoroughly investigated the impact of test set contamination on discriminative evaluations like multiple-choice question-answering, comparatively little research has studied the impact of test set contamination on generative evaluations. In this work, we quantitatively assess the effect of test set contamination on generative evaluations through the language model lifecycle. We pretrain language models on mixtures of web data and the MATH benchmark, sweeping model sizes and number of test set replicas contaminating the pretraining corpus; performance improves with contamination and model size. Using scaling laws, we make a surprising discovery: including even a single test set replica enables models to achieve lower loss than the irreducible error of training on the uncontaminated corpus. We then study further training: overtraining with fresh data reduces the effects of contamination, whereas supervised finetuning on the training set can either increase or decrease performance on test data, depending on the amount of pretraining contamination. Finally, at inference, we identify factors that modulate memorization: high sampling temperatures mitigate contamination effects, and longer solutions are exponentially more difficult to memorize than shorter ones, presenting a contrast with discriminative evaluations, where solutions are only a few tokens in length. By characterizing how generation and memorization interact, we highlight a new layer of complexity for trustworthy evaluation of AI systems.",
      "authors": [
        "Rylan Schaeffer",
        "Joshua Kazdan",
        "Baber Abbasi",
        "Ken Ziyu Liu",
        "Brando Miranda",
        "Ahmed Ahmed",
        "Abhay Puri",
        "Niloofar Mireshghallah",
        "Sanmi Koyejo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-01-07 18:46:22+00:00",
      "link": "https://arxiv.org/pdf/2601.04301v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04170v1",
      "title": "Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions",
      "abstract": "Multi-agent Large Language Model (LLM) systems have emerged as powerful architectures for complex task decomposition and collaborative problem-solving. However, their long-term behavioral stability remains largely unexamined. This study introduces the concept of agent drift, defined as the progressive degradation of agent behavior, decision quality, and inter-agent coherence over extended interaction sequences. We present a comprehensive theoretical framework for understanding drift phenomena, proposing three distinct manifestations: semantic drift (progressive deviation from original intent), coordination drift (breakdown in multi-agent consensus mechanisms), and behavioral drift (emergence of unintended strategies).   We introduce the Agent Stability Index (ASI), a novel composite metric framework for quantifying drift across twelve dimensions, including response consistency, tool usage patterns, reasoning pathway stability, and inter-agent agreement rates. Through simulation-based analysis and theoretical modeling, we demonstrate how unchecked agent drift can lead to substantial reductions in task completion accuracy and increased human intervention requirements.   We propose three mitigation strategies: episodic memory consolidation, drift-aware routing protocols, and adaptive behavioral anchoring. Theoretical analysis suggests these approaches can significantly reduce drift-related errors while maintaining system throughput. This work establishes a foundational methodology for monitoring, measuring, and mitigating agent drift in production agentic AI systems, with direct implications for enterprise deployment reliability and AI safety research.",
      "authors": [
        "Abhishek Rath"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 18:37:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04170v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04157v1",
      "title": "FLEx: Language Modeling with Few-shot Language Explanations",
      "abstract": "Language models have become effective at a wide range of tasks, from math problem solving to open-domain question answering. However, they still make mistakes, and these mistakes are often repeated across related queries. Natural language explanations can help correct these errors, but collecting them at scale may be infeasible, particularly in domains where expert annotators are required. To address this issue, we introduce FLEx ($\\textbf{F}$ew-shot $\\textbf{L}$anguage $\\textbf{Ex}$planations), a method for improving model behavior using a small number of explanatory examples. FLEx selects representative model errors using embedding-based clustering, verifies that the associated explanations correct those errors, and summarizes them into a prompt prefix that is prepended at inference-time. This summary guides the model to avoid similar errors on new inputs, without modifying model weights. We evaluate FLEx on CounterBench, GSM8K, and ReasonIF. We find that FLEx consistently outperforms chain-of-thought (CoT) prompting across all three datasets and reduces up to 83\\% of CoT's remaining errors.",
      "authors": [
        "Adar Avsian",
        "Christopher Richardson",
        "Anirudh Sundar",
        "Larry Heck"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-07 18:12:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04157v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04153v1",
      "title": "Diffusion-DRF: Differentiable Reward Flow for Video Diffusion Fine-Tuning",
      "abstract": "Direct Preference Optimization (DPO) has recently improved Text-to-Video (T2V) generation by enhancing visual fidelity and text alignment. However, current methods rely on non-differentiable preference signals from human annotations or learned reward models. This reliance makes training label-intensive, bias-prone, and easy-to-game, which often triggers reward hacking and unstable training. We propose Diffusion-DRF, a differentiable reward flow for fine-tuning video diffusion models using a frozen, off-the-shelf Vision-Language Model (VLM) as a training-free critic. Diffusion-DRF directly backpropagates VLM feedback through the diffusion denoising chain, converting logit-level responses into token-aware gradients for optimization. We propose an automated, aspect-structured prompting pipeline to obtain reliable multi-dimensional VLM feedback, while gradient checkpointing enables efficient updates through the final denoising steps. Diffusion-DRF improves video quality and semantic alignment while mitigating reward hacking and collapse -- without additional reward models or preference datasets. It is model-agnostic and readily generalizes to other diffusion-based generative tasks.",
      "authors": [
        "Yifan Wang",
        "Yanyu Li",
        "Sergey Tulyakov",
        "Yun Fu",
        "Anil Kag"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 18:05:08+00:00",
      "link": "https://arxiv.org/pdf/2601.04153v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04137v1",
      "title": "Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test",
      "abstract": "As world models gain momentum in Embodied AI, an increasing number of works explore using video foundation models as predictive world models for downstream embodied tasks like 3D prediction or interactive generation. However, before exploring these downstream tasks, video foundation models still have two critical questions unanswered: (1) whether their generative generalization is sufficient to maintain perceptual fidelity in the eyes of human observers, and (2) whether they are robust enough to serve as a universal prior for real-world embodied agents. To provide a standardized framework for answering these questions, we introduce the Embodied Turing Test benchmark: WoW-World-Eval (Wow,wo,val). Building upon 609 robot manipulation data, Wow-wo-val examines five core abilities, including perception, planning, prediction, generalization, and execution. We propose a comprehensive evaluation protocol with 22 metrics to assess the models' generation ability, which achieves a high Pearson Correlation between the overall score and human preference (>0.93) and establishes a reliable foundation for the Human Turing Test. On Wow-wo-val, models achieve only 17.27 on long-horizon planning and at best 68.02 on physical consistency, indicating limited spatiotemporal consistency and physical reasoning. For the Inverse Dynamic Model Turing Test, we first use an IDM to evaluate the video foundation models' execution accuracy in the real world. However, most models collapse to $\\approx$ 0% success, while WoW maintains a 40.74% success rate. These findings point to a noticeable gap between the generated videos and the real world, highlighting the urgency and necessity of benchmarking World Model in Embodied AI.",
      "authors": [
        "Chun-Kai Fan",
        "Xiaowei Chi",
        "Xiaozhu Ju",
        "Hao Li",
        "Yong Bao",
        "Yu-Kai Wang",
        "Lizhang Chen",
        "Zhiyuan Jiang",
        "Kuangzhi Ge",
        "Ying Li",
        "Weishi Mi",
        "Qingpo Wuwu",
        "Peidong Jia",
        "Yulin Luo",
        "Kevin Zhang",
        "Zhiyuan Qin",
        "Yong Dai",
        "Sirui Han",
        "Yike Guo",
        "Shanghang Zhang",
        "Jian Tang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-07 17:50:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04137v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04121v1",
      "title": "MORPHFED: Federated Learning for Cross-institutional Blood Morphology Analysis",
      "abstract": "Automated blood morphology analysis can support hematological diagnostics in low- and middle-income countries (LMICs) but remains sensitive to dataset shifts from staining variability, imaging differences, and rare morphologies. Building centralized datasets to capture this diversity is often infeasible due to privacy regulations and data-sharing restrictions. We introduce a federated learning framework for white blood cell morphology analysis that enables collaborative training across institutions without exchanging training data. Using blood films from multiple clinical sites, our federated models learn robust, domain-invariant representations while preserving complete data privacy. Evaluations across convolutional and transformer-based architectures show that federated training achieves strong cross-site performance and improved generalization to unseen institutions compared to centralized training. These findings highlight federated learning as a practical and privacy-preserving approach for developing equitable, scalable, and generalizable medical imaging AI in resource-limited healthcare environments.",
      "authors": [
        "Gabriel Ansah",
        "Eden Ruffell",
        "Delmiro Fernandez-Reyes",
        "Petru Manescu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-01-07 17:32:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04121v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04110v1",
      "title": "Causal Data Augmentation for Robust Fine-Tuning of Tabular Foundation Models",
      "abstract": "Fine-tuning tabular foundation models (TFMs) under data scarcity is challenging, as early stopping on even scarcer validation data often fails to capture true generalization performance. We propose CausalMixFT, a method that enhances fine-tuning robustness and downstream performance by generating structurally consistent synthetic samples using Structural Causal Models (SCMs) fitted on the target dataset. This approach augments limited real data with causally informed synthetic examples, preserving feature dependencies while expanding training diversity. Evaluated across 33 classification datasets from TabArena and over 2300 fine-tuning runs, our CausalMixFT method consistently improves median normalized ROC-AUC from 0.10 (standard fine-tuning) to 0.12, outperforming purely statistical generators such as CTGAN (-0.01), TabEBM (-0.04), and TableAugment (-0.09). Moreover, it narrows the median validation-test performance correlation gap from 0.67 to 0.30, enabling more reliable validation-based early stopping, a key step toward improving fine-tuning stability under data scarcity. These results demonstrate that incorporating causal structure into data augmentation provides an effective and principled route to fine-tuning tabular foundation models in low-data regimes.",
      "authors": [
        "Magnus Bühler",
        "Lennart Purucker",
        "Frank Hutter"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 17:16:39+00:00",
      "link": "https://arxiv.org/pdf/2601.04110v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04100v1",
      "title": "Quantifying the Impact of Modules and Their Interactions in the PSO-X Framework",
      "abstract": "The PSO-X framework incorporates dozens of modules that have been proposed for solving single-objective continuous optimization problems using particle swarm optimization. While modular frameworks enable users to automatically generate and configure algorithms tailored to specific optimization problems, the complexity of this process increases with the number of modules in the framework and the degrees of freedom defined for their interaction. Understanding how modules affect the performance of algorithms for different problems is critical to making the process of finding effective implementations more efficient and identifying promising areas for further investigation. Despite their practical applications and scientific relevance, there is a lack of empirical studies investigating which modules matter most in modular optimization frameworks and how they interact. In this paper, we analyze the performance of 1424 particle swarm optimization algorithms instantiated from the PSO-X framework on the 25 functions in the CEC'05 benchmark suite with 10 and 30 dimensions. We use functional ANOVA to quantify the impact of modules and their combinations on performance in different problem classes. In practice, this allows us to identify which modules have greater influence on PSO-X performance depending on problem features such as multimodality, mathematical transformations and varying dimensionality. We then perform a cluster analysis to identify groups of problem classes that share similar module effect patterns. Our results show low variability in the importance of modules in all problem classes, suggesting that particle swarm optimization performance is driven by a few influential modules.",
      "authors": [
        "Christian L. Camacho-Villalón",
        "Ana Nikolikj",
        "Katharina Dost",
        "Eva Tuba",
        "Sašo Džeroski",
        "Tome Eftimov"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "published": "2026-01-07 17:06:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04100v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04094v1",
      "title": "The Bathtub of European AI Governance: Identifying Technical Sandboxes as the Micro-Foundation of Regulatory Learning",
      "abstract": "The EU AI Act adopts a horizontal and adaptive approach to govern AI technologies characterised by rapid development and unpredictable emerging capabilities. To maintain relevance, the Act embeds provisions for regulatory learning. However, these provisions operate within a complex network of actors and mechanisms that lack a clearly defined technical basis for scalable information flow. This paper addresses this gap by establishing a theoretical model of regulatory learning space defined by the AI Act, decomposed into micro, meso, and macro levels. Drawing from this functional perspective of this model, we situate the diverse stakeholders - ranging from the EU Commission at the macro level to AI developers at the micro level - within the transitions of enforcement (macro-micro) and evidence aggregation (micro-macro). We identify AI Technical Sandboxes as the essential engine for evidence generation at the micro level, providing the necessary data to drive scalable learning across all levels of the model. By providing an extensive discussion of the requirements and challenges for AITSes to serve as this micro-level evidence generator, we aim to bridge the gap between legislative commands and technical operationalisation, thereby enabling a structured discourse between technical and legal experts.",
      "authors": [
        "Tom Deckenbrunnen",
        "Alessio Buscemi",
        "Marco Almada",
        "Alfredo Capozucca",
        "German Castignani"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "published": "2026-01-07 17:01:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04094v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04090v1",
      "title": "Gen3R: 3D Scene Generation Meets Feed-Forward Reconstruction",
      "abstract": "We present Gen3R, a method that bridges the strong priors of foundational reconstruction models and video diffusion models for scene-level 3D generation. We repurpose the VGGT reconstruction model to produce geometric latents by training an adapter on its tokens, which are regularized to align with the appearance latents of pre-trained video diffusion models. By jointly generating these disentangled yet aligned latents, Gen3R produces both RGB videos and corresponding 3D geometry, including camera poses, depth maps, and global point clouds. Experiments demonstrate that our approach achieves state-of-the-art results in single- and multi-image conditioned 3D scene generation. Additionally, our method can enhance the robustness of reconstruction by leveraging generative priors, demonstrating the mutual benefit of tightly coupling reconstruction and generative models.",
      "authors": [
        "Jiaxin Huang",
        "Yuanbo Yang",
        "Bangbang Yang",
        "Lin Ma",
        "Yuewen Ma",
        "Yiyi Liao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 16:57:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04090v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04085v1",
      "title": "CSSG: Measuring Code Similarity with Semantic Graphs",
      "abstract": "Existing code similarity metrics, such as BLEU, CodeBLEU, and TSED, largely rely on surface-level string overlap or abstract syntax tree structures, and often fail to capture deeper semantic relationships between programs.We propose CSSG (Code Similarity using Semantic Graphs), a novel metric that leverages program dependence graphs to explicitly model control dependencies and variable interactions, providing a semantics-aware representation of code.Experiments on the CodeContests+ dataset show that CSSG consistently outperforms existing metrics in distinguishing more similar code from less similar code under both monolingual and cross-lingual settings, demonstrating that dependency-aware graph representations offer a more effective alternative to surface-level or syntax-based similarity measures.",
      "authors": [
        "Jingwen Xu",
        "Yiyang Lu",
        "Changze Lv",
        "Zisu Huang",
        "Zhengkang Guo",
        "Zhengyuan Wang",
        "Muzhao Tian",
        "Xuanjing Huang",
        "Xiaoqing Zheng"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "published": "2026-01-07 16:54:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04085v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04068v2",
      "title": "Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models",
      "abstract": "Aligning text-to-video diffusion models with human preferences is crucial for generating high-quality videos. Existing Direct Preference Otimization (DPO) methods rely on multi-sample ranking and task-specific critic models, which is inefficient and often yields ambiguous global supervision. To address these limitations, we propose LocalDPO, a novel post-training framework that constructs localized preference pairs from real videos and optimizes alignment at the spatio-temporal region level. We design an automated pipeline to efficiently collect preference pair data that generates preference pairs with a single inference per prompt, eliminating the need for external critic models or manual annotation. Specifically, we treat high-quality real videos as positive samples and generate corresponding negatives by locally corrupting them with random spatio-temporal masks and restoring only the masked regions using the frozen base model. During training, we introduce a region-aware DPO loss that restricts preference learning to corrupted areas for rapid convergence. Experiments on Wan2.1 and CogVideoX demonstrate that LocalDPO consistently improves video fidelity, temporal coherence and human preference scores over other post-training approaches, establishing a more efficient and fine-grained paradigm for video generator alignment.",
      "authors": [
        "Zitong Huang",
        "Kaidong Zhang",
        "Yukang Ding",
        "Chao Gao",
        "Rui Ding",
        "Ying Chen",
        "Wangmeng Zuo"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 16:32:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04068v2",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04061v1",
      "title": "CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos",
      "abstract": "Generalist Vision-Language-Action models are currently hindered by the scarcity of robotic data compared to the abundance of human video demonstrations. Existing Latent Action Models attempt to leverage video data but often suffer from visual entanglement, capturing noise rather than manipulation skills. To address this, we propose Contrastive Latent Action Pretraining (CLAP), a framework that aligns the visual latent space from videos with a proprioceptive latent space from robot trajectories. By employing contrastive learning, CLAP maps video transitions onto a quantized, physically executable codebook. Building on this representation, we introduce a dual-formulation VLA framework offering both CLAP-NTP, an autoregressive model excelling at instruction following and object generalization, and CLAP-RF, a Rectified Flow-based policy designed for high-frequency, precise manipulation. Furthermore, we propose a Knowledge Matching (KM) regularization strategy to mitigate catastrophic forgetting during fine-tuning. Extensive experiments demonstrate that CLAP significantly outperforms strong baselines, enabling the effective transfer of skills from human videos to robotic execution. Project page: https://lin-shan.com/CLAP/.",
      "authors": [
        "Chubin Zhang",
        "Jianan Wang",
        "Zifeng Gao",
        "Yue Su",
        "Tianru Dai",
        "Cai Zhou",
        "Jiwen Lu",
        "Yansong Tang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "published": "2026-01-07 16:26:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04061v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04060v1",
      "title": "ComfySearch: Autonomous Exploration and Reasoning for ComfyUI Workflows",
      "abstract": "AI-generated content has progressed from monolithic models to modular workflows, especially on platforms like ComfyUI, allowing users to customize complex creative pipelines. However, the large number of components in ComfyUI and the difficulty of maintaining long-horizon structural consistency under strict graph constraints frequently lead to low pass rates and workflows of limited quality. To tackle these limitations, we present ComfySearch, an agentic framework that can effectively explore the component space and generate functional ComfyUI pipelines via validation-guided workflow construction. Experiments demonstrate that ComfySearch substantially outperforms existing methods on complex and creative tasks, achieving higher executability (pass) rates, higher solution rates, and stronger generalization.",
      "authors": [
        "Jinwei Su",
        "Qizhen Lan",
        "Zeyu Wang",
        "Yinghui Xia",
        "Hairu Wen",
        "Yiqun Duan",
        "Xi Xiao",
        "Tianyu Shi",
        "Yang Jingsong",
        "Lewei He"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 16:24:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04060v1",
      "tags": [
        "keyword:RL",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04056v1",
      "title": "Bridging the Discrete-Continuous Gap: Unified Multimodal Generation via Coupled Manifold Discrete Absorbing Diffusion",
      "abstract": "The bifurcation of generative modeling into autoregressive approaches for discrete data (text) and diffusion approaches for continuous data (images) hinders the development of truly unified multimodal systems. While Masked Language Models (MLMs) offer efficient bidirectional context, they traditionally lack the generative fidelity of autoregressive models and the semantic continuity of diffusion models. Furthermore, extending masked generation to multimodal settings introduces severe alignment challenges and training instability. In this work, we propose \\textbf{CoM-DAD} (\\textbf{Co}upled \\textbf{M}anifold \\textbf{D}iscrete \\textbf{A}bsorbing \\textbf{D}iffusion), a novel probabilistic framework that reformulates multimodal generation as a hierarchical dual-process. CoM-DAD decouples high-level semantic planning from low-level token synthesis. First, we model the semantic manifold via a continuous latent diffusion process; second, we treat token generation as a discrete absorbing diffusion process, regulated by a \\textbf{Variable-Rate Noise Schedule}, conditioned on these evolving semantic priors. Crucially, we introduce a \\textbf{Stochastic Mixed-Modal Transport} strategy that aligns disparate modalities without requiring heavy contrastive dual-encoders. Our method demonstrates superior stability over standard masked modeling, establishing a new paradigm for scalable, unified text-image generation.",
      "authors": [
        "Yuanfeng Xu",
        "Yuhao Chen",
        "Liang Lin",
        "Guangrun Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 16:21:19+00:00",
      "link": "https://arxiv.org/pdf/2601.04056v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04054v1",
      "title": "LinkD: AutoRegressive Diffusion Model for Mechanical Linkage Synthesis",
      "abstract": "Designing mechanical linkages to achieve target end-effector trajectories presents a fundamental challenge due to the intricate coupling between continuous node placements, discrete topological configurations, and nonlinear kinematic constraints. The highly nonlinear motion-to-configuration relationship means small perturbations in joint positions drastically alter trajectories, while the combinatorially expanding design space renders conventional optimization and heuristic methods computationally intractable. We introduce an autoregressive diffusion framework that exploits the dyadic nature of linkage assembly by representing mechanisms as sequentially constructed graphs, where nodes correspond to joints and edges to rigid links. Our approach combines a causal transformer with a Denoising Diffusion Probabilistic Model (DDPM), both conditioned on target trajectories encoded via a transformer encoder. The causal transformer autoregressively predicts discrete topology node-by-node, while the DDPM refines each node's spatial coordinates and edge connectivity to previously generated nodes. This sequential generation enables adaptive trial-and-error synthesis where problematic nodes exhibiting kinematic locking or collisions can be selectively regenerated, allowing autonomous correction of degenerate configurations during design. Our graph-based, data-driven methodology surpasses traditional optimization approaches, enabling scalable inverse design that generalizes to mechanisms with arbitrary node counts. We demonstrate successful synthesis of linkage systems containing up to 20 nodes with extensibility to N-node architectures. This work advances autoregressive graph generation methodologies and computational kinematic synthesis, establishing new paradigms for scalable inverse design of complex mechanical systems.",
      "authors": [
        "Yayati Jadhav",
        "Amir Barati Farimani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:19:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04054v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04052v1",
      "title": "Stable Language Guidance for Vision-Language-Action Models",
      "abstract": "Vision-Language-Action (VLA) models have demonstrated impressive capabilities in generalized robotic control; however, they remain notoriously brittle to linguistic perturbations. We identify a critical ``modality collapse'' phenomenon where strong visual priors overwhelm sparse linguistic signals, causing agents to overfit to specific instruction phrasings while ignoring the underlying semantic intent. To address this, we propose \\textbf{Residual Semantic Steering (RSS)}, a probabilistic framework that disentangles physical affordance from semantic execution. RSS introduces two theoretical innovations: (1) \\textbf{Monte Carlo Syntactic Integration}, which approximates the true semantic posterior via dense, LLM-driven distributional expansion, and (2) \\textbf{Residual Affordance Steering}, a dual-stream decoding mechanism that explicitly isolates the causal influence of language by subtracting the visual affordance prior. Theoretical analysis suggests that RSS effectively maximizes the mutual information between action and intent while suppressing visual distractors. Empirical results across diverse manipulation benchmarks demonstrate that RSS achieves state-of-the-art robustness, maintaining performance even under adversarial linguistic perturbations.",
      "authors": [
        "Zhihao Zhan",
        "Yuhao Chen",
        "Jiaying Zhou",
        "Qinhan Lv",
        "Hao Liu",
        "Keze Wang",
        "Liang Lin",
        "Guangrun Wang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CL"
      ],
      "published": "2026-01-07 16:16:10+00:00",
      "link": "https://arxiv.org/pdf/2601.04052v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04035v1",
      "title": "MobileDreamer: Generative Sketch World Model for GUI Agent",
      "abstract": "Mobile GUI agents have shown strong potential in real-world automation and practical applications. However, most existing agents remain reactive, making decisions mainly from current screen, which limits their performance on long-horizon tasks. Building a world model from repeated interactions enables forecasting action outcomes and supports better decision making for mobile GUI agents. This is challenging because the model must predict post-action states with spatial awareness while remaining efficient enough for practical deployment. In this paper, we propose MobileDreamer, an efficient world-model-based lookahead framework to equip the GUI agents based on the future imagination provided by the world model. It consists of textual sketch world model and rollout imagination for GUI agent. Textual sketch world model forecasts post-action states through a learning process to transform digital images into key task-related sketches, and designs a novel order-invariant learning strategy to preserve the spatial information of GUI elements. The rollout imagination strategy for GUI agent optimizes the action-selection process by leveraging the prediction capability of world model. Experiments on Android World show that MobileDreamer achieves state-of-the-art performance and improves task success by 5.25%. World model evaluations further verify that our textual sketch modeling accurately forecasts key GUI elements.",
      "authors": [
        "Yilin Cao",
        "Yufeng Zhong",
        "Zhixiong Zeng",
        "Liming Zheng",
        "Jing Huang",
        "Haibo Qiu",
        "Peng Shi",
        "Wenji Mao",
        "Wan Guanglu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 15:51:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04035v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04019v1",
      "title": "Modeling Behavioral Patterns in News Recommendations Using Fuzzy Neural Networks",
      "abstract": "News recommender systems are increasingly driven by black-box models, offering little transparency for editorial decision-making. In this work, we introduce a transparent recommender system that uses fuzzy neural networks to learn human-readable rules from behavioral data for predicting article clicks. By extracting the rules at configurable thresholds, we can control rule complexity and thus, the level of interpretability. We evaluate our approach on two publicly available news datasets (i.e., MIND and EB-NeRD) and show that we can accurately predict click behavior compared to several established baselines, while learning human-readable rules. Furthermore, we show that the learned rules reveal news consumption patterns, enabling editors to align content curation goals with target audience behavior.",
      "authors": [
        "Kevin Innerebner",
        "Stephan Bartl",
        "Markus Reiter-Haas",
        "Elisabeth Lex"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.IR"
      ],
      "published": "2026-01-07 15:34:15+00:00",
      "link": "https://arxiv.org/pdf/2601.04019v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03992v1",
      "title": "A Scheduling Framework for Efficient MoE Inference on Edge GPU-NDP Systems",
      "abstract": "Mixture-of-Experts (MoE) models facilitate edge deployment by decoupling model capacity from active computation, yet their large memory footprint drives the need for GPU systems with near-data processing (NDP) capabilities that offload experts to dedicated processing units. However, deploying MoE models on such edge-based GPU-NDP systems faces three critical challenges: 1) severe load imbalance across NDP units due to non-uniform expert selection and expert parallelism, 2) insufficient GPU utilization during expert computation within NDP units, and 3) extensive data pre-profiling necessitated by unpredictable expert activation patterns for pre-fetching. To address these challenges, this paper proposes an efficient inference framework featuring three key optimizations. First, the underexplored tensor parallelism in MoE inference is exploited to partition and compute large expert parameters across multiple NDP units simultaneously towards edge low-batch scenarios. Second, a load-balancing-aware scheduling algorithm distributes expert computations across NDP units and GPU to maximize resource utilization. Third, a dataset-free pre-fetching strategy proactively loads frequently accessed experts to minimize activation delays. Experimental results show that our framework enables GPU-NDP systems to achieve 2.41x on average and up to 2.56x speedup in end-to-end latency compared to state-of-the-art approaches, significantly enhancing MoE inference efficiency in resource-constrained environments.",
      "authors": [
        "Qi Wu",
        "Chao Fang",
        "Jiayuan Chen",
        "Ye Lin",
        "Yueqi Zhang",
        "Yichuan Bai",
        "Yuan Du",
        "Li Du"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "published": "2026-01-07 15:02:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03992v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03988v1",
      "title": "Using Small Language Models to Reverse-Engineer Machine Learning Pipelines Structures",
      "abstract": "Background: Extracting the stages that structure Machine Learning (ML) pipelines from source code is key for gaining a deeper understanding of data science practices. However, the diversity caused by the constant evolution of the ML ecosystem (e.g., algorithms, libraries, datasets) makes this task challenging. Existing approaches either depend on non-scalable, manual labeling, or on ML classifiers that do not properly support the diversity of the domain. These limitations highlight the need for more flexible and reliable solutions.   Objective: We evaluate whether Small Language Models (SLMs) can leverage their code understanding and classification abilities to address these limitations, and subsequently how they can advance our understanding of data science practices.   Method: We conduct a confirmatory study based on two reference works selected for their relevance regarding current state-of-the-art's limitations. First, we compare several SLMs using Cochran's Q test. The best-performing model is then evaluated against the reference studies using two distinct McNemar's tests. We further analyze how variations in taxonomy definitions affect performance through an additional Cochran's Q test. Finally, a goodness-of-fit analysis is conducted using Pearson's chi-squared tests to compare our insights on data science practices with those from prior studies.",
      "authors": [
        "Nicolas Lacroix",
        "Mireille Blay-Fornarino",
        "Sébastien Mosser",
        "Frederic Precioso"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.LG"
      ],
      "published": "2026-01-07 15:00:22+00:00",
      "link": "https://arxiv.org/pdf/2601.03988v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04288v1",
      "title": "Human-in-the-Loop Testing of AI Agents for Air Traffic Control with a Regulated Assessment Framework",
      "abstract": "We present a rigorous, human-in-the-loop evaluation framework for assessing the performance of AI agents on the task of Air Traffic Control, grounded in a regulator-certified simulator-based curriculum used for training and testing real-world trainee controllers. By leveraging legally regulated assessments and involving expert human instructors in the evaluation process, our framework enables a more authentic and domain-accurate measurement of AI performance. This work addresses a critical gap in the existing literature: the frequent misalignment between academic representations of Air Traffic Control and the complexities of the actual operational environment. It also lays the foundations for effective future human-machine teaming paradigms by aligning machine performance with human assessment targets.",
      "authors": [
        "Ben Carvell",
        "Marc Thomas",
        "Andrew Pace",
        "Christopher Dorney",
        "George De Ath",
        "Richard Everson",
        "Nick Pepper",
        "Adam Keane",
        "Samuel Tomlinson",
        "Richard Cannon"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-01-07 14:50:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04288v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03956v1",
      "title": "CoINS: Counterfactual Interactive Navigation via Skill-Aware VLM",
      "abstract": "Recent Vision-Language Models (VLMs) have demonstrated significant potential in robotic planning. However, they typically function as semantic reasoners, lacking an intrinsic understanding of the specific robot's physical capabilities. This limitation is particularly critical in interactive navigation, where robots must actively modify cluttered environments to create traversable paths. Existing VLM-based navigators are predominantly confined to passive obstacle avoidance, failing to reason about when and how to interact with objects to clear blocked paths. To bridge this gap, we propose Counterfactual Interactive Navigation via Skill-aware VLM (CoINS), a hierarchical framework that integrates skill-aware reasoning and robust low-level execution. Specifically, we fine-tune a VLM, named InterNav-VLM, which incorporates skill affordance and concrete constraint parameters into the input context and grounds them into a metric-scale environmental representation. By internalizing the logic of counterfactual reasoning through fine-tuning on the proposed InterNav dataset, the model learns to implicitly evaluate the causal effects of object removal on navigation connectivity, thereby determining interaction necessity and target selection. To execute the generated high-level plans, we develop a comprehensive skill library through reinforcement learning, specifically introducing traversability-oriented strategies to manipulate diverse objects for path clearance. A systematic benchmark in Isaac Sim is proposed to evaluate both the reasoning and execution aspects of interactive navigation. Extensive simulations and real-world experiments demonstrate that CoINS significantly outperforms representative baselines, achieving a 17\\% higher overall success rate and over 80\\% improvement in complex long-horizon scenarios compared to the best-performing baseline",
      "authors": [
        "Kangjie Zhou",
        "Zhejia Wen",
        "Zhiyong Zhuo",
        "Zike Yan",
        "Pengying Wu",
        "Ieng Hou U",
        "Shuaiyang Li",
        "Han Gao",
        "Kang Ding",
        "Wenhan Cao",
        "Wei Pan",
        "Chang Liu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-07 14:10:46+00:00",
      "link": "https://arxiv.org/pdf/2601.03956v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03919v2",
      "title": "A Gap Between Decision Trees and Neural Networks",
      "abstract": "We study when geometric simplicity of decision boundaries, used here as a notion of interpretability, can conflict with accurate approximation of axis-aligned decision trees by shallow neural networks. Decision trees induce rule-based, axis-aligned decision regions (finite unions of boxes), whereas shallow ReLU networks are typically trained as score models whose predictions are obtained by thresholding. We analyze the infinite-width, bounded-norm, single-hidden-layer ReLU class through the Radon total variation ($\\mathrm{R}\\mathrm{TV}$) seminorm, which controls the geometric complexity of level sets.   We first show that the hard tree indicator $1_A$ has infinite $\\mathrm{R}\\mathrm{TV}$. Moreover, two natural split-wise continuous surrogates--piecewise-linear ramp smoothing and sigmoidal (logistic) smoothing--also have infinite $\\mathrm{R}\\mathrm{TV}$ in dimensions $d>1$, while Gaussian convolution yields finite $\\mathrm{R}\\mathrm{TV}$ but with an explicit exponential dependence on $d$.   We then separate two goals that are often conflated: classification after thresholding (recovering the decision set) versus score learning (learning a calibrated score close to $1_A$). For classification, we construct a smooth barrier score $S_A$ with finite $\\mathrm{R}\\mathrm{TV}$ whose fixed threshold $τ=1$ exactly recovers the box. Under a mild tube-mass condition near $\\partial A$, we prove an $L_1(P)$ calibration bound that decays polynomially in a sharpness parameter, along with an explicit $\\mathrm{R}\\mathrm{TV}$ upper bound in terms of face measures. Experiments on synthetic unions of rectangles illustrate the resulting accuracy--complexity tradeoff and how threshold selection shifts where training lands along it.",
      "authors": [
        "Akash Kumar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-01-07 13:40:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03919v2",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03908v1",
      "title": "Decide Then Retrieve: A Training-Free Framework with Uncertainty-Guided Triggering and Dual-Path Retrieval",
      "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge, but existing approaches indiscriminately trigger retrieval and rely on single-path evidence construction, often introducing noise and limiting performance gains. In this work, we propose Decide Then Retrieve (DTR), a training-free framework that adaptively determines when retrieval is necessary and how external information should be selected. DTR leverages generation uncertainty to guide retrieval triggering and introduces a dual-path retrieval mechanism with adaptive information selection to better handle sparse and ambiguous queries. Extensive experiments across five open-domain QA benchmarks, multiple model scales, and different retrievers demonstrate that DTR consistently improves EM and F1 over standard RAG and strong retrieval-enhanced baselines, while reducing unnecessary retrievals. The code and data used in this paper are available at https://github.com/ChenWangHKU/DTR.",
      "authors": [
        "Wang Chen",
        "Guanqiang Qi",
        "Weikang Li",
        "Yang Li",
        "Deguo Xia",
        "Jizhou Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 13:20:59+00:00",
      "link": "https://arxiv.org/pdf/2601.03908v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03905v2",
      "title": "Current Agents Fail to Leverage World Model as Tool for Foresight",
      "abstract": "Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answering tasks, we observe that some agents rarely invoke simulation (fewer than 1%), frequently misuse predicted rollouts (approximately 15%), and often exhibit inconsistent or even degraded performance (up to 5%) when simulation is available or enforced. Attribution analysis further indicates that the primary bottleneck lies in the agents' capacity to decide when to simulate, how to interpret predicted outcomes, and how to integrate foresight into downstream reasoning. These findings underscore the need for mechanisms that foster calibrated, strategic interaction with world models, paving the way toward more reliable anticipatory cognition in future agent systems.",
      "authors": [
        "Cheng Qian",
        "Emre Can Acikgoz",
        "Bingxuan Li",
        "Xiusi Chen",
        "Yuji Zhang",
        "Bingxiang He",
        "Qinyu Luo",
        "Dilek Hakkani-Tür",
        "Gokhan Tur",
        "Yunzhu Li",
        "Heng Ji"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-07 13:15:23+00:00",
      "link": "https://arxiv.org/pdf/2601.03905v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03889v1",
      "title": "Spectral Manifold Regularization for Stable and Modular Routing in Deep MoE Architectures",
      "abstract": "Mixture of Experts (MoE) architectures enable efficient scaling of neural networks but suffer from expert collapse, where routing converges to a few dominant experts. This reduces model capacity and causes catastrophic interference during adaptation. We propose the Spectrally-Regularized Mixture of Experts (SR-MoE), which imposes geometric constraints on the routing manifold to enforce structural modularity. Our method uses dual regularization: spectral norm constraints bound routing function Lipschitz continuity, while stable rank penalties preserve high-dimensional feature diversity in expert selection. We evaluate SR-MoE across architectural scales and dataset complexities using modular one-shot adaptation tasks. Results show that traditional linear gating fails with increasing depth (accuracy drops up to 4.72% due to expert entanglement), while SR-MoE maintains structural integrity (mean interference -0.32%). Our spectral constraints facilitate positive knowledge transfer, enabling localized expert updates without global performance decay. SR-MoE provides a general solution for building high-capacity, modular networks capable of stable lifelong learning.",
      "authors": [
        "Ibrahim Delibasoglu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 12:59:37+00:00",
      "link": "https://arxiv.org/pdf/2601.03889v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03885v1",
      "title": "Local Interpolation via Low-Rank Tensor Trains",
      "abstract": "Tensor Train (TT) decompositions provide a powerful framework to compress grid-structured data, such as sampled function values, on regular Cartesian grids. Such high compression, in turn, enables efficient high-dimensional computations. Exact TT representations are only available for simple analytic functions. Furthermore, global polynomial or Fourier expansions typically yield TT-ranks that grow proportionally with the number of basis terms. State-of-the-art methods are often prohibitively expensive or fail to recover the underlying low-rank structure. We propose a low-rank TT interpolation framework that, given a TT describing a discrete (scalar-, vector-, or tensor-valued) function on a coarse regular grid with $n$ cores, constructs a finer-scale version of the same function represented by a TT with $n+m$ cores, where the last $m$ cores maintain constant rank. Our method guarantees a $\\ell^{2}$-norm error bound independent of the total number of cores, achieves exponential compression at fixed accuracy, and admits logarithmic complexity with respect of the number of grid points. We validate its performance through numerical experiments, including 1D, 2D, and 3D applications such as: 2D and 3D airfoil mask embeddings, image super-resolution, and synthetic noise fields such as 3D synthetic turbulence. In particular, we generate fractal noise fields directly in TT format with logarithmic complexity and memory. This work opens a path to scalable TT-native solvers with complex geometries and multiscale generative models, with implications from scientific simulation to imaging and real-time graphics.",
      "authors": [
        "Siddhartha E. Guzman",
        "Egor Tiunov",
        "Leandro Aolita"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "cs.GR"
      ],
      "published": "2026-01-07 12:54:06+00:00",
      "link": "https://arxiv.org/pdf/2601.03885v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03882v1",
      "title": "Feature-Aware One-Shot Federated Learning via Hierarchical Token Sequences",
      "abstract": "One-shot federated learning (OSFL) reduces the communication cost and privacy risks of iterative federated learning by constructing a global model with a single round of communication. However, most existing methods struggle to achieve robust performance on real-world domains such as medical imaging, or are inefficient when handling non-IID (Independent and Identically Distributed) data. To address these limitations, we introduce FALCON, a framework that enhances the effectiveness of OSFL over non-IID image data. The core idea of FALCON is to leverage the feature-aware hierarchical token sequences generation and knowledge distillation into OSFL. First, each client leverages a pretrained visual encoder with hierarchical scale encoding to compress images into hierarchical token sequences, which capture multi-scale semantics. Second, a multi-scale autoregressive transformer generator is used to model the distribution of these token sequences and generate the synthetic sequences. Third, clients upload the synthetic sequences along with the local classifier trained on the real token sequences to the server. Finally, the server incorporates knowledge distillation into global training to reduce reliance on precise distribution modeling. Experiments on medical and natural image datasets validate the effectiveness of FALCON in diverse non-IID scenarios, outperforming the best OSFL baselines by 9.58% in average accuracy.",
      "authors": [
        "Shudong Liu",
        "Hanwen Zhang",
        "Xiuling Wang",
        "Yuesheng Zhu",
        "Guibo Luo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 12:48:16+00:00",
      "link": "https://arxiv.org/pdf/2601.03882v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03878v1",
      "title": "Understanding Specification-Driven Code Generation with LLMs: An Empirical Study Design",
      "abstract": "Large Language Models (LLMs) are increasingly integrated into software development workflows, yet their behavior in structured, specification-driven processes remains poorly understood. This paper presents an empirical study design using CURRANTE, a Visual Studio Code extension that enables a human-in-the-loop workflow for LLM-assisted code generation. The tool guides developers through three sequential stages--Specification, Tests, and Function--allowing them to define requirements, generate and refine test suites, and produce functions that satisfy those tests. Participants will solve medium-difficulty problems from the LiveCodeBench dataset, while the tool records fine-grained interaction logs, effectiveness metrics (e.g., pass rate, all-pass completion), efficiency indicators (e.g., time-to-pass), and iteration behaviors. The study aims to analyze how human intervention in specification and test refinement influences the quality and dynamics of LLM-generated code. The results will provide empirical insights into the design of next-generation development environments that align human reasoning with model-driven code generation.",
      "authors": [
        "Giovanni Rosa",
        "David Moreno-Lumbreras",
        "Gregorio Robles",
        "Jesús M. González-Barahona"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-07 12:46:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03878v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04278v1",
      "title": "From Domains to Instances: Dual-Granularity Data Synthesis for LLM Unlearning",
      "abstract": "Although machine unlearning is essential for removing private, harmful, or copyrighted content from LLMs, current benchmarks often fail to faithfully represent the true \"forgetting scope\" learned by the model. We formalize two distinct unlearning granularities, domain-level and instance-level, and propose BiForget, an automated framework for synthesizing high-quality forget sets. Unlike prior work relying on external generators, BiForget exploits the target model per se to elicit data that matches its internal knowledge distribution through seed-guided and adversarial prompting. Our experiments across diverse benchmarks show that it achieves a superior balance of relevance, diversity, and efficiency. Quantitatively, in the Harry Potter domain, it improves relevance by ${\\sim}20$ and diversity by ${\\sim}$0.05 while halving the total data size compared to SOTAs. Ultimately, it facilitates more robust forgetting and better utility preservation, providing a more rigorous foundation for evaluating LLM unlearning.",
      "authors": [
        "Xiaoyu Xu",
        "Minxin Du",
        "Zitong Li",
        "Zi Liang",
        "Zhibiao Guo",
        "Shiyu Zhang",
        "Peizhao Hu",
        "Qingqing Ye",
        "Haibo Hu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-01-07 12:41:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04278v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03872v1",
      "title": "Atlas: Orchestrating Heterogeneous Models and Tools for Multi-Domain Complex Reasoning",
      "abstract": "The integration of large language models (LLMs) with external tools has significantly expanded the capabilities of AI agents. However, as the diversity of both LLMs and tools increases, selecting the optimal model-tool combination becomes a high-dimensional optimization challenge. Existing approaches often rely on a single model or fixed tool-calling logic, failing to exploit the performance variations across heterogeneous model-tool pairs. In this paper, we present ATLAS (Adaptive Tool-LLM Alignment and Synergistic Invocation), a dual-path framework for dynamic tool usage in cross-domain complex reasoning. ATLAS operates via a dual-path approach: (1) \\textbf{training-free cluster-based routing} that exploits empirical priors for domain-specific alignment, and (2) \\textbf{RL-based multi-step routing} that explores autonomous trajectories for out-of-distribution generalization. Extensive experiments across 15 benchmarks demonstrate that our method outperforms closed-source models like GPT-4o, surpassing existing routing methods on both in-distribution (+10.1%) and out-of-distribution (+13.1%) tasks. Furthermore, our framework shows significant gains in visual reasoning by orchestrating specialized multi-modal tools.",
      "authors": [
        "Jinyang Wu",
        "Guocheng Zhai",
        "Ruihan Jin",
        "Jiahao Yuan",
        "Yuhao Shen",
        "Shuai Zhang",
        "Zhengqi Wen",
        "Jianhua Tao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 12:38:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03872v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03869v1",
      "title": "Bayesian Monocular Depth Refinement via Neural Radiance Fields",
      "abstract": "Monocular depth estimation has applications in many fields, such as autonomous navigation and extended reality, making it an essential computer vision task. However, current methods often produce smooth depth maps that lack the fine geometric detail needed for accurate scene understanding. We propose MDENeRF, an iterative framework that refines monocular depth estimates using depth information from Neural Radiance Fields (NeRFs). MDENeRF consists of three components: (1) an initial monocular estimate for global structure, (2) a NeRF trained on perturbed viewpoints, with per-pixel uncertainty, and (3) Bayesian fusion of the noisy monocular and NeRF depths. We derive NeRF uncertainty from the volume rendering process to iteratively inject high-frequency fine details. Meanwhile, our monocular prior maintains global structure. We demonstrate superior performance on key metrics and experiments using indoor scenes from the SUN RGB-D dataset.",
      "authors": [
        "Arun Muthukkumar"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.GR",
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-01-07 12:32:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03869v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04275v1",
      "title": "Shadow Unlearning: A Neuro-Semantic Approach to Fidelity-Preserving Faceless Forgetting in LLMs",
      "abstract": "Machine unlearning aims to selectively remove the influence of specific training samples to satisfy privacy regulations such as the GDPR's 'Right to be Forgotten'. However, many existing methods require access to the data being removed, exposing it to membership inference attacks and potential misuse of Personally Identifiable Information (PII). We address this critical challenge by proposing Shadow Unlearning, a novel paradigm of approximate unlearning, that performs machine unlearning on anonymized forget data without exposing PII. We further propose a novel privacy-preserving framework, Neuro-Semantic Projector Unlearning (NSPU) to achieve Shadow unlearning. To evaluate our method, we compile Multi-domain Fictitious Unlearning (MuFU) forget set across five diverse domains and introduce an evaluation stack to quantify the trade-off between knowledge retention and unlearning effectiveness. Experimental results on various LLMs show that NSPU achieves superior unlearning performance, preserves model utility, and enhances user privacy. Additionally, the proposed approach is at least 10 times more computationally efficient than standard unlearning approaches. Our findings foster a new direction for privacy-aware machine unlearning that balances data protection and model fidelity.",
      "authors": [
        "Dinesh Srivasthav P",
        "Ashok Urlana",
        "Rahul Mishra",
        "Bala Mallikarjunarao Garlapati",
        "Ponnurangam Kumaraguru"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 12:11:25+00:00",
      "link": "https://arxiv.org/pdf/2601.04275v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03847v1",
      "title": "xDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming",
      "abstract": "Explainable artificial intelligence (xAI) has gained significant attention in recent years. Among other things, explainablility for deep neural networks has been a topic of intensive research due to the meteoric rise in prominence of deep neural networks and their \"black-box\" nature. xAI approaches can be characterized along different dimensions such as their scope (global versus local explanations) or underlying methodologies (statistic-based versus rule-based strategies). Methods generating global explanations aim to provide reasoning process applicable to all possible output classes while local explanation methods focus only on a single, specific class. SHAP (SHapley Additive exPlanations), a well-known statistical technique, identifies important features of a network. Deep neural network rule extraction method constructs IF-THEN rules that link input conditions to a class. Another approach focuses on generating counterfactuals which help explain how small changes to an input can affect the model's predictions. However, these techniques primarily focus on the input-output relationship and thus neglect the structure of the network in explanation generation.   In this work, we propose xDNN(ASP), an explanation generation system for deep neural networks that provides global explanations. Given a neural network model and its training data, xDNN(ASP) extracts a logic program under answer set semantics that-in the ideal case-represents the trained model, i.e., answer sets of the extracted program correspond one-to-one to input-output pairs of the network. We demonstrate experimentally, using two synthetic datasets, that not only the extracted logic program maintains a high-level of accuracy in the prediction task, but it also provides valuable information for the understanding of the model such as the importance of features as well as the impact of hidden nodes on the prediction. The latter can be used as a guide for reducing the number of nodes used in hidden layers, i.e., providing a means for optimizing the network.",
      "authors": [
        "Ly Ly Trieu",
        "Tran Cao Son"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 12:08:00+00:00",
      "link": "https://arxiv.org/pdf/2601.03847v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03846v1",
      "title": "When Numbers Start Talking: Implicit Numerical Coordination Among LLM-Based Agents",
      "abstract": "LLMs-based agents increasingly operate in multi-agent environments where strategic interaction and coordination are required. While existing work has largely focused on individual agents or on interacting agents sharing explicit communication, less is known about how interacting agents coordinate implicitly. In particular, agents may engage in covert communication, relying on indirect or non-linguistic signals embedded in their actions rather than on explicit messages. This paper presents a game-theoretic study of covert communication in LLM-driven multi-agent systems. We analyse interactions across four canonical game-theoretic settings under different communication regimes, including explicit, restricted, and absent communication. Considering heterogeneous agent personalities and both one-shot and repeated games, we characterise when covert signals emerge and how they shape coordination and strategic outcomes.",
      "authors": [
        "Alessio Buscemi",
        "Daniele Proverbio",
        "Alessandro Di Stefano",
        "The Anh Han",
        "German Castignani",
        "Pietro Liò"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "published": "2026-01-07 12:07:48+00:00",
      "link": "https://arxiv.org/pdf/2601.03846v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03839v1",
      "title": "Logic Tensor Network-Enhanced Generative Adversarial Network",
      "abstract": "In this paper, we introduce Logic Tensor Network-Enhanced Generative Adversarial Network (LTN-GAN), a novel framework that enhances Generative Adversarial Networks (GANs) by incorporating Logic Tensor Networks (LTNs) to enforce domain-specific logical constraints during the sample generation process. Although GANs have shown remarkable success in generating realistic data, they often lack mechanisms to incorporate prior knowledge or enforce logical consistency, limiting their applicability in domains requiring rule adherence. LTNs provide a principled way to integrate first-order logic with neural networks, enabling models to reason over and satisfy logical constraints. By combining the strengths of GANs for realistic data synthesis with LTNs for logical reasoning, we gain valuable insights into how logical constraints influence the generative process while improving both the diversity and logical consistency of the generated samples. We evaluate LTN-GAN across multiple datasets, including synthetic datasets (gaussian, grid, rings) and the MNIST dataset, demonstrating that our model significantly outperforms traditional GANs in terms of adherence to predefined logical constraints while maintaining the quality and diversity of generated samples. This work highlights the potential of neuro-symbolic approaches to enhance generative modeling in knowledge-intensive domains.",
      "authors": [
        "Nijesh Upreti",
        "Vaishak Belle"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "published": "2026-01-07 12:04:49+00:00",
      "link": "https://arxiv.org/pdf/2601.03839v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03823v1",
      "title": "Step Potential Advantage Estimation: Harnessing Intermediate Confidence and Correctness for Efficient Mathematical Reasoning",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) elicits long chain-of-thought reasoning in large language models (LLMs), but outcome-based rewards lead to coarse-grained advantage estimation. While existing approaches improve RLVR via token-level entropy or sequence-level length control, they lack a semantically grounded, step-level measure of reasoning progress. As a result, LLMs fail to distinguish necessary deduction from redundant verification: they may continue checking after reaching a correct solution and, in extreme cases, overturn a correct trajectory into an incorrect final answer. To remedy the lack of process supervision, we introduce a training-free probing mechanism that extracts intermediate confidence and correctness and combines them into a Step Potential signal that explicitly estimates the reasoning state at each step. Building on this signal, we propose Step Potential Advantage Estimation (SPAE), a fine-grained credit assignment method that amplifies potential gains, penalizes potential drops, and applies penalty after potential saturates to encourage timely termination. Experiments across multiple benchmarks show SPAE consistently improves accuracy while substantially reducing response length, outperforming strong RL baselines and recent efficient reasoning and token-level advantage estimation methods. The code is available at https://github.com/cii030/SPAE-RL.",
      "authors": [
        "Fei Wu",
        "Zhenrong Zhang",
        "Qikai Chang",
        "Jianshu Zhang",
        "Quan Liu",
        "Jun Du"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 11:36:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03823v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03807v1",
      "title": "Generational Replacement and Learning for High-Performing and Diverse Populations in Evolvable Robots",
      "abstract": "Evolutionary Robotics offers the possibility to design robots to solve a specific task automatically by optimizing their morphology and control together. However, this co-optimization of body and control is challenging, because controllers need some time to adapt to the evolving morphology - which may make it difficult for new and promising designs to enter the evolving population. A solution to this is to add intra-life learning, defined as an additional controller optimization loop, to each individual in the evolving population. A related problem is the lack of diversity often seen in evolving populations as evolution narrows the search down to a few promising designs too quickly. This problem can be mitigated by implementing full generational replacement, where offspring robots replace the whole population. This solution for increasing diversity usually comes at the cost of lower performance compared to using elitism. In this work, we show that combining such generational replacement with intra-life learning can increase diversity while retaining performance. We also highlight the importance of performance metrics when studying learning in morphologically evolving robots, showing that evaluating according to function evaluations versus according to generations of evolution can give different conclusions.",
      "authors": [
        "K. Ege de Bruin",
        "Kyrre Glette",
        "Kai Olav Ellefsen"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-07 11:11:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03807v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03794v1",
      "title": "An Algorithmic Framework for Systematic Literature Reviews: A Case Study for Financial Narratives",
      "abstract": "This paper introduces an algorithmic framework for conducting systematic literature reviews (SLRs), designed to improve efficiency, reproducibility, and selection quality assessment in the literature review process. The proposed method integrates Natural Language Processing (NLP) techniques, clustering algorithms, and interpretability tools to automate and structure the selection and analysis of academic publications. The framework is applied to a case study focused on financial narratives, an emerging area in financial economics that examines how structured accounts of economic events, formed by the convergence of individual interpretations, influence market dynamics and asset prices. Drawing from the Scopus database of peer-reviewed literature, the review highlights research efforts to model financial narratives using various NLP techniques. Results reveal that while advances have been made, the conceptualization of financial narratives remains fragmented, often reduced to sentiment analysis, topic modeling, or their combination, without a unified theoretical framework. The findings underscore the value of more rigorous and dynamic narrative modeling approaches and demonstrate the effectiveness of the proposed algorithmic SLR methodology.",
      "authors": [
        "Gabin Taibi",
        "Joerg Osterrieder"
      ],
      "primary_category": "q-fin.GN",
      "categories": [
        "q-fin.GN",
        "cs.AI"
      ],
      "published": "2026-01-07 10:50:35+00:00",
      "link": "https://arxiv.org/pdf/2601.03794v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03786v1",
      "title": "Compact Example-Based Explanations for Language Models",
      "abstract": "Training data influence estimation methods quantify the contribution of training documents to a model's output, making them a promising source of information for example-based explanations. As humans cannot interpret thousands of documents, only a small subset of the training data can be presented as an explanation. Although the choice of which documents to include directly affects explanation quality, previous evaluations of such systems have largely ignored any selection strategies. To address this, we propose a novel selection relevance score, a retraining-free metric that quantifies how useful a set of examples is for explaining a model's output. We validate this score through fine-tuning experiments, confirming that it can predict whether a set of examples supports or undermines the model's predictions. Using this metric, we further show that common selection strategies often underperform random selection. Motivated by this finding, we propose a strategy that balances influence and representativeness, enabling better use of selection budgets than naively selecting the highest-ranking examples.",
      "authors": [
        "Loris Schoenegger",
        "Benjamin Roth"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-07 10:36:46+00:00",
      "link": "https://arxiv.org/pdf/2601.03786v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03776v1",
      "title": "Improving Compactness and Reducing Ambiguity of CFIRE Rule-Based Explanations",
      "abstract": "Models trained on tabular data are widely used in sensitive domains, increasing the demand for explanation methods to meet transparency needs. CFIRE is a recent algorithm in this domain that constructs compact surrogate rule models from local explanations. While effective, CFIRE may assign rules associated with different classes to the same sample, introducing ambiguity. We investigate this ambiguity and propose a post-hoc pruning strategy that removes rules with low contribution or conflicting coverage, yielding smaller and less ambiguous models while preserving fidelity. Experiments across multiple datasets confirm these improvements with minimal impact on predictive performance.",
      "authors": [
        "Sebastian Müller",
        "Tobias Schneider",
        "Ruben Kemna",
        "Vanessa Toborek"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 10:13:40+00:00",
      "link": "https://arxiv.org/pdf/2601.03776v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03769v2",
      "title": "EntroCoT: Enhancing Chain-of-Thought via Adaptive Entropy-Guided Segmentation",
      "abstract": "Chain-of-Thought (CoT) prompting has significantly enhanced the mathematical reasoning capabilities of Large Language Models. We find existing fine-tuning datasets frequently suffer from the \"answer right but reasoning wrong\" probelm, where correct final answers are derived from hallucinated, redundant, or logically invalid intermediate steps. This paper proposes EntroCoT, a unified framework for automatically identifying and refining low-quality CoT supervision traces. EntroCoT first proposes an entropy-based mechanism to segment the reasoning trace into multiple steps at uncertain junctures, and then introduces a Monte Carlo rollout-based mechanism to evaluate the marginal contribution of each step. By accurately filtering deceptive reasoning samples, EntroCoT constructs a high-quality dataset where every intermediate step in each reasoning trace facilitates the final answer. Extensive experiments on mathematical benchmarks demonstrate that fine-tuning on the subset constructed by EntroCoT consistently outperforms the baseslines of full-dataset supervision.",
      "authors": [
        "Zihang Li",
        "Yuhang Wang",
        "Yikun Zong",
        "Wenhan Yu",
        "Xiaokun Yuan",
        "Runhan Jiang",
        "Zirui Liu",
        "Tong Yang",
        "Arthur Jiang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 10:02:27+00:00",
      "link": "https://arxiv.org/pdf/2601.03769v2",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03764v1",
      "title": "Learning Shrinks the Hard Tail: Training-Dependent Inference Scaling in a Solvable Linear Model",
      "abstract": "We analyze neural scaling laws in a solvable model of last-layer fine-tuning where targets have intrinsic, instance-heterogeneous difficulty. In our Latent Instance Difficulty (LID) model, each input's target variance is governed by a latent ``precision'' drawn from a heavy-tailed distribution. While generalization loss recovers standard scaling laws, our main contribution connects this to inference. The pass@$k$ failure rate exhibits a power-law decay, $k^{-β_\\text{eff}}$, but the observed exponent $β_\\text{eff}$ is training-dependent. It grows with sample size $N$ before saturating at an intrinsic limit $β$ set by the difficulty distribution's tail. This coupling reveals that learning shrinks the ``hard tail'' of the error distribution: improvements in the model's generalization error steepen the pass@$k$ curve until irreducible target variance dominates. The LID model yields testable, closed-form predictions for this behavior, including a compute-allocation rule that favors training before saturation and inference attempts after. We validate these predictions in simulations and in two real-data proxies: CIFAR-10H (human-label variance) and a maths teacher-student distillation task.",
      "authors": [
        "Noam Levi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-01-07 10:00:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03764v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03752v1",
      "title": "Evaluation of Multilingual LLMs Personalized Text Generation Capabilities Targeting Groups and Social-Media Platforms",
      "abstract": "Capabilities of large language models to generate multilingual coherent text have continuously enhanced in recent years, which opens concerns about their potential misuse. Previous research has shown that they can be misused for generation of personalized disinformation in multiple languages. It has also been observed that personalization negatively affects detectability of machine-generated texts; however, this has been studied in the English language only. In this work, we examine this phenomenon across 10 languages, while we focus not only on potential misuse of personalization capabilities, but also on potential benefits they offer. Overall, we cover 1080 combinations of various personalization aspects in the prompts, for which the texts are generated by 16 distinct language models (17,280 texts in total). Our results indicate that there are differences in personalization quality of the generated texts when targeting demographic groups and when targeting social-media platforms across languages. Personalization towards platforms affects detectability of the generated texts in a higher scale, especially in English, where the personalization quality is the highest.",
      "authors": [
        "Dominik Macko"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 09:43:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03752v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03748v1",
      "title": "Bridging OLAP and RAG: A Multidimensional Approach to the Design of Corpus Partitioning",
      "abstract": "Retrieval-Augmented Generation (RAG) systems are increasingly deployed on large-scale document collections, often comprising millions of documents and tens of millions of text chunks. In industrial-scale retrieval platforms, scalability is typically addressed through horizontal sharding and a combination of Approximate Nearest-Neighbor search, hybrid indexing, and optimized metadata filtering. Although effective from an efficiency perspective, these mechanisms rely on bottom-up, similarity-driven organization and lack a conceptual rationale for corpus partitioning. In this paper, we claim that the design of large-scale RAG systems may benefit from the combination of two orthogonal strategies: semantic clustering, which optimizes locality in embedding space, and multidimensional partitioning, which governs where retrieval should occur based on conceptual dimensions such as time and organizational context. Although such dimensions are already implicitly present in current systems, they are used in an ad hoc and poorly structured manner. We propose the Dimensional Fact Model (DFM) as a conceptual framework to guide the design of multidimensional partitions for RAG corpora. The DFM provides a principled way to reason about facts, dimensions, hierarchies, and granularity in retrieval-oriented settings. This framework naturally supports hierarchical routing and controlled fallback strategies, ensuring that retrieval remains robust even in the presence of incomplete metadata, while transforming the search process from a 'black-box' similarity matching into a governable and deterministic workflow. This work is intended as a position paper; its goal is to bridge the gap between OLAP-style multidimensional modeling and modern RAG architectures, and to stimulate further research on principled, explainable, and governable retrieval strategies at scale.",
      "authors": [
        "Dario Maio",
        "Stefano Rizzi"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-07 09:37:36+00:00",
      "link": "https://arxiv.org/pdf/2601.03748v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03746v1",
      "title": "Whose Facts Win? LLM Source Preferences under Knowledge Conflicts",
      "abstract": "As large language models (LLMs) are more frequently used in retrieval-augmented generation pipelines, it is increasingly relevant to study their behavior under knowledge conflicts. Thus far, the role of the source of the retrieved information has gone unexamined. We address this gap with a novel framework to investigate how source preferences affect LLM resolution of inter-context knowledge conflicts in English, motivated by interdisciplinary research on credibility. With a comprehensive, tightly-controlled evaluation of 13 open-weight LLMs, we find that LLMs prefer institutionally-corroborated information (e.g., government or newspaper sources) over information from people and social media. However, these source preferences can be reversed by simply repeating information from less credible sources. To mitigate repetition effects and maintain consistent preferences, we propose a novel method that reduces repetition bias by up to 99.8%, while also maintaining at least 88.8% of original preferences. We release all data and code to encourage future work on credibility and source preferences in knowledge-intensive NLP.",
      "authors": [
        "Jakob Schuster",
        "Vagrant Gautam",
        "Katja Markert"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 09:35:35+00:00",
      "link": "https://arxiv.org/pdf/2601.03746v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03728v1",
      "title": "CSMCIR: CoT-Enhanced Symmetric Alignment with Memory Bank for Composed Image Retrieval",
      "abstract": "Composed Image Retrieval (CIR) enables users to search for target images using both a reference image and manipulation text, offering substantial advantages over single-modality retrieval systems. However, existing CIR methods suffer from representation space fragmentation: queries and targets comprise heterogeneous modalities and are processed by distinct encoders, forcing models to bridge misaligned representation spaces only through post-hoc alignment, which fundamentally limits retrieval performance. This architectural asymmetry manifests as three distinct, well-separated clusters in the feature space, directly demonstrating how heterogeneous modalities create fundamentally misaligned representation spaces from initialization. In this work, we propose CSMCIR, a unified representation framework that achieves efficient query-target alignment through three synergistic components. First, we introduce a Multi-level Chain-of-Thought (MCoT) prompting strategy that guides Multimodal Large Language Models to generate discriminative, semantically compatible captions for target images, establishing modal symmetry. Building upon this, we design a symmetric dual-tower architecture where both query and target sides utilize the identical shared-parameter Q-Former for cross-modal encoding, ensuring consistent feature representations and further reducing the alignment gap. Finally, this architectural symmetry enables an entropy-based, temporally dynamic Memory Bank strategy that provides high-quality negative samples while maintaining consistency with the evolving model state. Extensive experiments on four benchmark datasets demonstrate that our CSMCIR achieves state-of-the-art performance with superior training efficiency. Comprehensive ablation studies further validate the effectiveness of each proposed component.",
      "authors": [
        "Zhipeng Qian",
        "Zihan Liang",
        "Yufei Ma",
        "Ben Chen",
        "Huangyu Dai",
        "Yiwei Ma",
        "Jiayi Ji",
        "Chenyi Lei",
        "Han Li",
        "Xiaoshuai Sun"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 09:21:38+00:00",
      "link": "https://arxiv.org/pdf/2601.03728v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04266v1",
      "title": "State Backdoor: Towards Stealthy Real-world Poisoning Attack on Vision-Language-Action Model in State Space",
      "abstract": "Vision-Language-Action (VLA) models are widely deployed in safety-critical embodied AI applications such as robotics. However, their complex multimodal interactions also expose new security vulnerabilities. In this paper, we investigate a backdoor threat in VLA models, where malicious inputs cause targeted misbehavior while preserving performance on clean data. Existing backdoor methods predominantly rely on inserting visible triggers into visual modality, which suffer from poor robustness and low insusceptibility in real-world settings due to environmental variability. To overcome these limitations, we introduce the State Backdoor, a novel and practical backdoor attack that leverages the robot arm's initial state as the trigger. To optimize trigger for insusceptibility and effectiveness, we design a Preference-guided Genetic Algorithm (PGA) that efficiently searches the state space for minimal yet potent triggers. Extensive experiments on five representative VLA models and five real-world tasks show that our method achieves over 90% attack success rate without affecting benign task performance, revealing an underexplored vulnerability in embodied AI systems.",
      "authors": [
        "Ji Guo",
        "Wenbo Jiang",
        "Yansong Lin",
        "Yijing Liu",
        "Ruichen Zhang",
        "Guomin Lu",
        "Aiguo Chen",
        "Xinshuo Han",
        "Hongwei Li",
        "Dusit Niyato"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-01-07 08:54:31+00:00",
      "link": "https://arxiv.org/pdf/2601.04266v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03698v1",
      "title": "Evaluation Framework for AI Creativity: A Case Study Based on Story Generation",
      "abstract": "Evaluating creative text generation remains a challenge because existing reference-based metrics fail to capture the subjective nature of creativity. We propose a structured evaluation framework for AI story generation comprising four components (Novelty, Value, Adherence, and Resonance) and eleven sub-components. Using controlled story generation via ``Spike Prompting'' and a crowdsourced study of 115 readers, we examine how different creative components shape both immediate and reflective human creativity judgments. Our findings show that creativity is evaluated hierarchically rather than cumulatively, with different dimensions becoming salient at different stages of judgment, and that reflective evaluation substantially alters both ratings and inter-rater agreement. Together, these results support the effectiveness of our framework in revealing dimensions of creativity that are obscured by reference-based evaluation.",
      "authors": [
        "Pharath Sathya",
        "Yin Jou Huang",
        "Fei Cheng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 08:31:08+00:00",
      "link": "https://arxiv.org/pdf/2601.03698v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03693v1",
      "title": "Can AI Chatbots Provide Coaching in Engineering? Beyond Information Processing Toward Mastery",
      "abstract": "Engineering education faces a double disruption: traditional apprenticeship models that cultivated judgment and tacit skill are eroding, just as generative AI emerges as an informal coaching partner. This convergence rekindles long-standing questions in the philosophy of AI and cognition about the limits of computation, the nature of embodied rationality, and the distinction between information processing and wisdom. Building on this rich intellectual tradition, this paper examines whether AI chatbots can provide coaching that fosters mastery rather than merely delivering information. We synthesize critical perspectives from decades of scholarship on expertise, tacit knowledge, and human-machine interaction, situating them within the context of contemporary AI-driven education. Empirically, we report findings from a mixed-methods study (N = 75 students, N = 7 faculty) exploring the use of a coaching chatbot in engineering education. Results reveal a consistent boundary: participants accept AI for technical problem solving (convergent tasks; M = 3.84 on a 1-5 Likert scale) but remain skeptical of its capacity for moral, emotional, and contextual judgment (divergent tasks). Faculty express stronger concerns over risk (M = 4.71 vs. M = 4.14, p = 0.003), and privacy emerges as a key requirement, with 64-71 percent of participants demanding strict confidentiality. Our findings suggest that while generative AI can democratize access to cognitive and procedural support, it cannot replicate the embodied, value-laden dimensions of human mentorship. We propose a multiplex coaching framework that integrates human wisdom within expert-in-the-loop models, preserving the depth of apprenticeship while leveraging AI scalability to enrich the next generation of engineering education.",
      "authors": [
        "Junaid Qadir",
        "Muhammad Adil Attique",
        "Saleha Shoaib",
        "Syed Ibrahim Ghaznavi"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "published": "2026-01-07 08:28:47+00:00",
      "link": "https://arxiv.org/pdf/2601.03693v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04264v1",
      "title": "MemKD: Memory-Discrepancy Knowledge Distillation for Efficient Time Series Classification",
      "abstract": "Deep learning models, particularly recurrent neural networks and their variants, such as long short-term memory, have significantly advanced time series data analysis. These models capture complex, sequential patterns in time series, enabling real-time assessments. However, their high computational complexity and large model sizes pose challenges for deployment in resource-constrained environments, such as wearable devices and edge computing platforms. Knowledge Distillation (KD) offers a solution by transferring knowledge from a large, complex model (teacher) to a smaller, more efficient model (student), thereby retaining high performance while reducing computational demands. Current KD methods, originally designed for computer vision tasks, neglect the unique temporal dependencies and memory retention characteristics of time series models. To this end, we propose a novel KD framework termed Memory-Discrepancy Knowledge Distillation (MemKD). MemKD leverages a specialized loss function to capture memory retention discrepancies between the teacher and student models across subsequences within time series data, ensuring that the student model effectively mimics the teacher model's behaviour. This approach facilitates the development of compact, high-performing recurrent neural networks suitable for real-time, time series analysis tasks. Our extensive experiments demonstrate that MemKD significantly outperforms state-of-the-art KD methods. It reduces parameter size and memory usage by approximately 500 times while maintaining comparable performance to the teacher model.",
      "authors": [
        "Nilushika Udayangani",
        "Kishor Nandakishor",
        "Marimuthu Palaniswami"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CE"
      ],
      "published": "2026-01-07 07:45:48+00:00",
      "link": "https://arxiv.org/pdf/2601.04264v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03669v1",
      "title": "eTracer: Towards Traceable Text Generation via Claim-Level Grounding",
      "abstract": "How can system-generated responses be efficiently verified, especially in the high-stakes biomedical domain? To address this challenge, we introduce eTracer, a plug-and-play framework that enables traceable text generation by grounding claims against contextual evidence. Through post-hoc grounding, each response claim is aligned with contextual evidence that either supports or contradicts it. Building on claim-level grounding results, eTracer not only enables users to precisely trace responses back to their contextual source but also quantifies response faithfulness, thereby enabling the verifiability and trustworthiness of generated responses. Experiments show that our claim-level grounding approach alleviates the limitations of conventional grounding methods in aligning generated statements with contextual sentence-level evidence, resulting in substantial improvements in overall grounding quality and user verification efficiency. The code and data are available at https://github.com/chubohao/eTracer.",
      "authors": [
        "Bohao Chu",
        "Qianli Wang",
        "Hendrik Damm",
        "Hui Wang",
        "Ula Muhabbek",
        "Elisabeth Livingstone",
        "Christoph M. Friedrich",
        "Norbert Fuhr"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 07:44:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03669v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03665v1",
      "title": "PhysVideoGenerator: Towards Physically Aware Video Generation via Latent Physics Guidance",
      "abstract": "Current video generation models produce high-quality aesthetic videos but often struggle to learn representations of real-world physics dynamics, resulting in artifacts such as unnatural object collisions, inconsistent gravity, and temporal flickering. In this work, we propose PhysVideoGenerator, a proof-of-concept framework that explicitly embeds a learnable physics prior into the video generation process. We introduce a lightweight predictor network, PredictorP, which regresses high-level physical features extracted from a pre-trained Video Joint Embedding Predictive Architecture (V-JEPA 2) directly from noisy diffusion latents. These predicted physics tokens are injected into the temporal attention layers of a DiT-based generator (Latte) via a dedicated cross-attention mechanism. Our primary contribution is demonstrating the technical feasibility of this joint training paradigm: we show that diffusion latents contain sufficient information to recover V-JEPA 2 physical representations, and that multi-task optimization remains stable over training. This report documents the architectural design, technical challenges, and validation of training stability, establishing a foundation for future large-scale evaluation of physics-aware generative models.",
      "authors": [
        "Siddarth Nilol Kundur Satish",
        "Devesh Jaiswal",
        "Hongyu Chen",
        "Abhishek Bakshi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 07:38:58+00:00",
      "link": "https://arxiv.org/pdf/2601.03665v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04263v1",
      "title": "Learning to Reason: Temporal Saliency Distillation for Interpretable Knowledge Transfer",
      "abstract": "Knowledge distillation has proven effective for model compression by transferring knowledge from a larger network called the teacher to a smaller network called the student. Current knowledge distillation in time series is predominantly based on logit and feature aligning techniques originally developed for computer vision tasks. These methods do not explicitly account for temporal data and fall short in two key aspects. First, the mechanisms by which the transferred knowledge helps the student model learning process remain unclear due to uninterpretability of logits and features. Second, these methods transfer only limited knowledge, primarily replicating the teacher predictive accuracy. As a result, student models often produce predictive distributions that differ significantly from those of their teachers, hindering their safe substitution for teacher models. In this work, we propose transferring interpretable knowledge by extending conventional logit transfer to convey not just the right prediction but also the right reasoning of the teacher. Specifically, we induce other useful knowledge from the teacher logits termed temporal saliency which captures the importance of each input timestep to the teacher prediction. By training the student with Temporal Saliency Distillation we encourage it to make predictions based on the same input features as the teacher. Temporal Saliency Distillation requires no additional parameters or architecture specific assumptions. We demonstrate that Temporal Saliency Distillation effectively improves the performance of baseline methods while also achieving desirable properties beyond predictive accuracy. We hope our work establishes a new paradigm for interpretable knowledge distillation in time series analysis.",
      "authors": [
        "Nilushika Udayangani Hewa Dehigahawattage",
        "Kishor Nandakishor",
        "Marimuthu Palaniswami"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:24:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04263v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03658v1",
      "title": "Group and Exclusive Sparse Regularization-based Continual Learning of CNNs",
      "abstract": "We present a regularization-based approach for continual learning (CL) of fixed capacity convolutional neural networks (CNN) that does not suffer from the problem of catastrophic forgetting when learning multiple tasks sequentially. This method referred to as Group and Exclusive Sparsity based Continual Learning (GESCL) avoids forgetting of previous tasks by ensuring the stability of the CNN via a stability regularization term, which prevents filters detected as important for past tasks to deviate too much when learning a new task. On top of that, GESCL makes the network plastic via a plasticity regularization term that leverage the over-parameterization of CNNs to efficiently sparsify the network and tunes unimportant filters making them relevant for future tasks. Doing so, GESCL deals with significantly less parameters and computation compared to CL approaches that either dynamically expand the network or memorize past tasks' data. Experiments on popular CL vision benchmarks show that GESCL leads to significant improvements over state-of-the-art method in terms of overall CL performance, as measured by classification accuracy as well as in terms of avoiding catastrophic forgetting.",
      "authors": [
        "Basile Tousside",
        "Janis Mohr",
        "Jörg Frochte"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:15:11+00:00",
      "link": "https://arxiv.org/pdf/2601.03658v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03657v1",
      "title": "In Search of Grandmother Cells: Tracing Interpretable Neurons in Tabular Representations",
      "abstract": "Foundation models are powerful yet often opaque in their decision-making. A topic of continued interest in both neuroscience and artificial intelligence is whether some neurons behave like grandmother cells, i.e., neurons that are inherently interpretable because they exclusively respond to single concepts. In this work, we propose two information-theoretic measures that quantify the neuronal saliency and selectivity for single concepts. We apply these metrics to the representations of TabPFN, a tabular foundation model, and perform a simple search across neuron-concept pairs to find the most salient and selective pair. Our analysis provides the first evidence that some neurons in such models show moderate, statistically significant saliency and selectivity for high-level concepts. These findings suggest that interpretable neurons can emerge naturally and that they can, in some cases, be identified without resorting to more complex interpretability techniques.",
      "authors": [
        "Ricardo Knauer",
        "Erik Rodner"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:13:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03657v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03654v1",
      "title": "Quantum Classical Ridgelet Neural Network For Time Series Model",
      "abstract": "In this study, we present a quantum computing method that incorporates ridglet transforms into the quantum processing pipelines for time series data. Here, the Ridgelet neural network is integrated with a single-qubit quantum computing method, which improves feature extraction and forecasting capabilities. Furthermore, experimental results using financial time series data demonstrate the superior performance of our model compared to existing models.",
      "authors": [
        "Bahadur Yadav",
        "Sanjay Kumar Mohanty"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC",
        "math.QA"
      ],
      "published": "2026-01-07 07:05:34+00:00",
      "link": "https://arxiv.org/pdf/2601.03654v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03648v1",
      "title": "ELO: Efficient Layer-Specific Optimization for Continual Pretraining of Multilingual LLMs",
      "abstract": "We propose an efficient layer-specific optimization (ELO) method designed to enhance continual pretraining (CP) for specific languages in multilingual large language models (MLLMs). This approach addresses the common challenges of high computational cost and degradation of source language performance associated with traditional CP. The ELO method consists of two main stages: (1) ELO Pretraining, where a small subset of specific layers, identified in our experiments as the critically important first and last layers, are detached from the original MLLM and trained with the target language. This significantly reduces not only the number of trainable parameters but also the total parameters computed during the forward pass, minimizing GPU memory consumption and accelerating the training process. (2) Layer Alignment, where the newly trained layers are reintegrated into the original model, followed by a brief full fine-tuning step on a small dataset to align the parameters. Experimental results demonstrate that the ELO method achieves a training speedup of up to 6.46 times compared to existing methods, while improving target language performance by up to 6.2\\% on qualitative benchmarks and effectively preserving source language (English) capabilities.",
      "authors": [
        "HanGyeol Yoo",
        "ChangSu Choi",
        "Minjun Kim",
        "Seohyun Song",
        "SeungWoo Song",
        "Inho Won",
        "Jongyoul Park",
        "Cheoneum Park",
        "KyungTae Lim"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 06:55:29+00:00",
      "link": "https://arxiv.org/pdf/2601.03648v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03641v2",
      "title": "Agent-Dice: Disentangling Knowledge Updates via Geometric Consensus for Agent Continual Learning",
      "abstract": "Large Language Model (LLM)-based agents significantly extend the utility of LLMs by interacting with dynamic environments. However, enabling agents to continually learn new tasks without catastrophic forgetting remains a critical challenge, known as the stability-plasticity dilemma. In this work, we argue that this dilemma fundamentally arises from the failure to explicitly distinguish between common knowledge shared across tasks and conflicting knowledge introduced by task-specific interference. To address this, we propose Agent-Dice, a parameter fusion framework based on directional consensus evaluation. Concretely, Agent-Dice disentangles knowledge updates through a two-stage process: geometric consensus filtering to prune conflicting gradients, and curvature-based importance weighting to amplify shared semantics. We provide a rigorous theoretical analysis that establishes the validity of the proposed fusion scheme and offers insight into the origins of the stability-plasticity dilemma. Extensive experiments on GUI agents and tool-use agent domains demonstrate that Agent-Dice exhibits outstanding continual learning performance with minimal computational overhead and parameter updates. The codes are available at https://github.com/Wuzheng02/Agent-Dice.",
      "authors": [
        "Zheng Wu",
        "Xingyu Lou",
        "Xinbei Ma",
        "Yansi Li",
        "Weiwen Liu",
        "Weinan Zhang",
        "Jun Wang",
        "Zhuosheng Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 06:43:50+00:00",
      "link": "https://arxiv.org/pdf/2601.03641v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03634v1",
      "title": "Kantorovich-Type Stochastic Neural Network Operators for the Mean-Square Approximation of Certain Second-Order Stochastic Processes",
      "abstract": "Artificial neural network operators (ANNOs) have been widely used for approximating deterministic input-output functions; however, their extension to random dynamics remains comparatively unexplored. In this paper, we construct a new class of \\textbf{Kantorovich-type Stochastic Neural Network Operators (K-SNNOs)} in which randomness is incorporated not at the coefficient level, but through \\textbf{stochastic neurons} driven by stochastic integrators. This framework enables the operator to inherit the probabilistic structure of the underlying process, making it suitable for modeling and approximating stochastic signals. We establish mean-square convergence of K-SNNOs to the target stochastic process and derive quantitative error estimates expressing the rate of approximation in terms of the modulus of continuity. Numerical simulations further validate the theoretical results by demonstrating accurate reconstruction of sample paths and rapid decay of the mean square error (MSE). Graphical results, including sample-wise approximations and empirical MSE behaviour, illustrate the robustness and effectiveness of the proposed stochastic-neuron-based operator.",
      "authors": [
        "Sachin Saini",
        "Uaday Singh"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.PR"
      ],
      "published": "2026-01-07 06:25:40+00:00",
      "link": "https://arxiv.org/pdf/2601.03634v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03629v1",
      "title": "Learning Shortest Paths When Data is Scarce",
      "abstract": "Digital twins and other simulators are increasingly used to support routing decisions in large-scale networks. However, simulator outputs often exhibit systematic bias, while ground-truth measurements are costly and scarce. We study a stochastic shortest-path problem in which a planner has access to abundant synthetic samples, limited real-world observations, and an edge-similarity structure capturing expected behavioral similarity across links. We model the simulator-to-reality discrepancy as an unknown, edge-specific bias that varies smoothly over the similarity graph, and estimate it using Laplacian-regularized least squares. This approach yields calibrated edge cost estimates even in data-scarce regimes. We establish finite-sample error bounds, translate estimation error into path-level suboptimality guarantees, and propose a computable, data-driven certificate that verifies near-optimality of a candidate route. For cold-start settings without initial real data, we develop a bias-aware active learning algorithm that leverages the simulator and adaptively selects edges to measure until a prescribed accuracy is met. Numerical experiments on multiple road networks and traffic graphs further demonstrate the effectiveness of our methods.",
      "authors": [
        "Dmytro Matsypura",
        "Yu Pan",
        "Hanzhao Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 06:19:04+00:00",
      "link": "https://arxiv.org/pdf/2601.03629v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03624v1",
      "title": "Architecting Agentic Communities using Design Patterns",
      "abstract": "The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures). We focus on Agentic Communities - coordination frameworks encompassing LLM Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications. Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems. This approach provides both practical guidance and formal verification capabilities, enabling expression of organizational, legal, and ethical rules through accountability mechanisms that ensure operational and verifiable governance of inter-agent communication, negotiation, and intent modeling. We validate this framework through a clinical trial matching case study. Our goal is to provide actionable guidance to practitioners while maintaining the formal rigor essential for enterprise deployment in dynamic, multi-agent ecosystems.",
      "authors": [
        "Zoran Milosevic",
        "Fethi Rabhi"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 06:10:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03624v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03621v1",
      "title": "On the Robustness of Fairness Practices: A Causal Framework for Systematic Evaluation",
      "abstract": "Machine learning (ML) algorithms are increasingly deployed to make critical decisions in socioeconomic applications such as finance, criminal justice, and autonomous driving. However, due to their data-driven and pattern-seeking nature, ML algorithms may develop decision logic that disproportionately distributes opportunities, benefits, resources, or information among different population groups, potentially harming marginalized communities. In response to such fairness concerns, the software engineering and ML communities have made significant efforts to establish the best practices for creating fair ML software. These include fairness interventions for training ML models, such as including sensitive features, selecting non-sensitive attributes, and applying bias mitigators. But how reliably can software professionals tasked with developing data-driven systems depend on these recommendations? And how well do these practices generalize in the presence of faulty labels, missing data, or distribution shifts? These questions form the core theme of this paper.",
      "authors": [
        "Verya Monjezi",
        "Ashish Kumar",
        "Ashutosh Trivedi",
        "Gang Tan",
        "Saeid Tizpaz-Niari"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-07 06:02:53+00:00",
      "link": "https://arxiv.org/pdf/2601.03621v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03618v1",
      "title": "The Pneuma Project: Reifying Information Needs as Relational Schemas to Automate Discovery, Guide Preparation, and Align Data with Intent",
      "abstract": "Data discovery and preparation remain persistent bottlenecks in the data management lifecycle, especially when user intent is vague, evolving, or difficult to operationalize. The Pneuma Project introduces Pneuma-Seeker, a system that helps users articulate and fulfill information needs through iterative interaction with a language model-powered platform. The system reifies the user's evolving information need as a relational data model and incrementally converges toward a usable document aligned with that intent. To achieve this, the system combines three architectural ideas: context specialization to reduce LLM burden across subtasks, a conductor-style planner to assemble dynamic execution plans, and a convergence mechanism based on shared state. The system integrates recent advances in retrieval-augmented generation (RAG), agentic frameworks, and structured data preparation to support semi-automatic, language-guided workflows. We evaluate the system through LLM-based user simulations and show that it helps surface latent intent, guide discovery, and produce fit-for-purpose documents. It also acts as an emergent documentation layer, capturing institutional knowledge and supporting organizational memory.",
      "authors": [
        "Muhammad Imam Luthfi Balaka",
        "Raul Castro Fernandez"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-01-07 05:58:54+00:00",
      "link": "https://arxiv.org/pdf/2601.03618v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03617v1",
      "title": "Systematic Evaluation of Depth Backbones and Semantic Cues for Monocular Pseudo-LiDAR 3D Detection",
      "abstract": "Monocular 3D object detection offers a low-cost alternative to LiDAR, yet remains less accurate due to the difficulty of estimating metric depth from a single image. We systematically evaluate how depth backbones and feature engineering affect a monocular Pseudo-LiDAR pipeline on the KITTI validation split. Specifically, we compare NeWCRFs (supervised metric depth) against Depth Anything V2 Metric-Outdoor (Base) under an identical pseudo-LiDAR generation and PointRCNN detection protocol. NeWCRFs yields stronger downstream 3D detection, achieving 10.50\\% AP$_{3D}$ at IoU$=0.7$ on the Moderate split using grayscale intensity (Exp~2). We further test point-cloud augmentations using appearance cues (grayscale intensity) and semantic cues (instance segmentation confidence). Contrary to the expectation that semantics would substantially close the gap, these features provide only marginal gains, and mask-based sampling can degrade performance by removing contextual geometry. Finally, we report a depth-accuracy-versus-distance diagnostic using ground-truth 2D boxes (including Ped/Cyc), highlighting that coarse depth correctness does not fully predict strict 3D IoU. Overall, under an off-the-shelf LiDAR detector, depth-backbone choice and geometric fidelity dominate performance, outweighing secondary feature injection.",
      "authors": [
        "Samson Oseiwe Ajadalu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-01-07 05:57:19+00:00",
      "link": "https://arxiv.org/pdf/2601.03617v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03606v1",
      "title": "Policy-Guided Search on Tree-of-Thoughts for Efficient Problem Solving with Bounded Language Model Queries",
      "abstract": "Recent studies explored integrating state-space search algorithms with Language Models (LM) to perform look-ahead on the token generation process, the ''Tree-of-Thoughts'' (ToT), generated by LMs, thereby improving performance on problem-solving tasks. However, the affiliated search algorithms often overlook the significant computational costs associated with LM inference, particularly in scenarios with constrained computational budgets. Consequently, we address the problem of improving LM performance on problem-solving tasks under limited computational budgets. We demonstrate how the probabilities assigned to thoughts by LMs can serve as a heuristic to guide search within the ToT framework, thereby reducing the number of thought evaluations. Building on this insight, we adapt a heuristic search algorithm, Levin Tree Search (LTS), to the ToT framework, which leverages LMs as policies to guide the tree exploration efficiently. We extend the theoretical results of LTS by showing that, for ToT (a pruned tree), LTS guarantees a bound on the number of states expanded, and consequently, on the number of thoughts generated. Additionally, we analyze the sensitivity of this bound to the temperature values commonly used in the final softmax layer of the LM. Empirical evaluation under a fixed LM query budget demonstrates that LTS consistently achieves comparable or higher accuracy than baseline search algorithms within the ToT framework, across three domains (Blocksworld, PrOntoQA, Array Sorting) and four distinct LMs. These findings highlight the efficacy of LTS on ToT, particularly in enabling cost-effective and time-efficient problem-solving, making it well-suited for latency-critical and resource-constrained applications.",
      "authors": [
        "Sumedh Pendurkar",
        "Guni Sharon"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 05:35:16+00:00",
      "link": "https://arxiv.org/pdf/2601.03606v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03597v1",
      "title": "From Chains to Graphs: Self-Structured Reasoning for General-Domain LLMs",
      "abstract": "Large Language Models (LLMs) show strong reasoning ability in open-domain question answering, yet their reasoning processes are typically linear and often logically inconsistent. In contrast, real-world reasoning requires integrating multiple premises and solving subproblems in parallel. Existing methods, such as Chain-of-Thought (CoT), express reasoning in a linear textual form, which may appear coherent but frequently leads to inconsistent conclusions. Recent approaches rely on externally provided graphs and do not explore how LLMs can construct and use their own graph-structured reasoning, particularly in open-domain QA. To fill this gap, we novelly explore graph-structured reasoning of LLMs in general-domain question answering. We propose Self-Graph Reasoning (SGR), a framework that enables LLMs to explicitly represent their reasoning process as a structured graph before producing the final answer. We further construct a graph-structured reasoning dataset that merges multiple candidate reasoning graphs into refined graph structures for model training. Experiments on five QA benchmarks across both general and specialized domains show that SGR consistently improves reasoning consistency and yields a 17.74% gain over the base model. The LLaMA-3.3-70B model fine-tuned with SGR performs comparably to GPT-4o and surpasses Claude-3.5-Haiku, demonstrating the effectiveness of graph-structured reasoning.",
      "authors": [
        "Yingjian Chen",
        "Haoran Liu",
        "Yinhong Liu",
        "Sherry T. Tong",
        "Aosong Feng",
        "Jinghui Lu",
        "Juntao Zhang",
        "Yusuke Iwasawa",
        "Yutaka Matsuo",
        "Irene Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 05:27:41+00:00",
      "link": "https://arxiv.org/pdf/2601.03597v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03596v1",
      "title": "Adaptive Attention Distillation for Robust Few-Shot Segmentation under Environmental Perturbations",
      "abstract": "Few-shot segmentation (FSS) aims to rapidly learn novel class concepts from limited examples to segment specific targets in unseen images, and has been widely applied in areas such as medical diagnosis and industrial inspection. However, existing studies largely overlook the complex environmental factors encountered in real world scenarios-such as illumination, background, and camera viewpoint-which can substantially increase the difficulty of test images. As a result, models trained under laboratory conditions often fall short of practical deployment requirements. To bridge this gap, in this paper, an environment-robust FSS setting is introduced that explicitly incorporates challenging test cases arising from complex environments-such as motion blur, small objects, and camouflaged targets-to enhance model's robustness under realistic, dynamic conditions. An environment robust FSS benchmark (ER-FSS) is established, covering eight datasets across multiple real world scenarios. In addition, an Adaptive Attention Distillation (AAD) method is proposed, which repeatedly contrasts and distills key shared semantics between known (support) and unknown (query) images to derive class-specific attention for novel categories. This strengthens the model's ability to focus on the correct targets in complex environments, thereby improving environmental robustness. Comparative experiments show that AAD improves mIoU by 3.3% - 8.5% across all datasets and settings, demonstrating superior performance and strong generalization. The source code and dataset are available at: https://github.com/guoqianyu-alberta/Adaptive-Attention-Distillation-for-FSS.",
      "authors": [
        "Qianyu Guo",
        "Jingrong Wu",
        "Jieji Ren",
        "Weifeng Ge",
        "Wenqiang Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 05:27:12+00:00",
      "link": "https://arxiv.org/pdf/2601.03596v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03595v1",
      "title": "Controllable LLM Reasoning via Sparse Autoencoder-Based Steering",
      "abstract": "Large Reasoning Models (LRMs) exhibit human-like cognitive reasoning strategies (e.g. backtracking, cross-verification) during reasoning process, which improves their performance on complex tasks. Currently, reasoning strategies are autonomously selected by LRMs themselves. However, such autonomous selection often produces inefficient or even erroneous reasoning paths. To make reasoning more reliable and flexible, it is important to develop methods for controlling reasoning strategies. Existing methods struggle to control fine-grained reasoning strategies due to conceptual entanglement in LRMs' hidden states. To address this, we leverage Sparse Autoencoders (SAEs) to decompose strategy-entangled hidden states into a disentangled feature space. To identify the few strategy-specific features from the vast pool of SAE features, we propose SAE-Steering, an efficient two-stage feature identification pipeline. SAE-Steering first recalls features that amplify the logits of strategy-specific keywords, filtering out over 99\\% of features, and then ranks the remaining features by their control effectiveness. Using the identified strategy-specific features as control vectors, SAE-Steering outperforms existing methods by over 15\\% in control effectiveness. Furthermore, controlling reasoning strategies can redirect LRMs from erroneous paths to correct ones, achieving a 7\\% absolute accuracy improvement.",
      "authors": [
        "Yi Fang",
        "Wenjie Wang",
        "Mingfeng Xue",
        "Boyi Deng",
        "Fengli Xu",
        "Dayiheng Liu",
        "Fuli Feng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 05:26:26+00:00",
      "link": "https://arxiv.org/pdf/2601.03595v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03577v1",
      "title": "Variational Inference, Entropy, and Orthogonality: A Unified Theory of Mixture-of-Experts",
      "abstract": "Mixture-of-Experts models enable large language models to scale efficiently, as they only activate a subset of experts for each input. Their core mechanisms, Top-k routing and auxiliary load balancing, remain heuristic, however, lacking a cohesive theoretical underpinning to support them. To this end, we build the first unified theoretical framework that rigorously derives these practices as optimal sparse posterior approximation and prior regularization from a Bayesian perspective, while simultaneously framing them as mechanisms to minimize routing ambiguity and maximize channel capacity from an information-theoretic perspective. We also pinpoint the inherent combinatorial hardness of routing, defining it as the NP-hard sparse subset selection problem. We rigorously prove the existence of a \"Coherence Barrier\"; when expert representations exhibit high mutual coherence, greedy routing strategies theoretically fail to recover the optimal expert subset. Importantly, we formally verify that imposing geometric orthogonality in the expert feature space is sufficient to narrow the divide between the NP-hard global optimum and polynomial-time greedy approximation. Our comparative analyses confirm orthogonality regularization as the optimal engineering relaxation for large-scale models. Our work offers essential theoretical support and technical assurance for a deeper understanding and novel designs of MoE.",
      "authors": [
        "Ye Su",
        "Yong Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 04:45:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03577v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04260v1",
      "title": "Towards a Mechanistic Understanding of Propositional Logical Reasoning in Large Language Models",
      "abstract": "Understanding how Large Language Models (LLMs) perform logical reasoning internally remains a fundamental challenge. While prior mechanistic studies focus on identifying taskspecific circuits, they leave open the question of what computational strategies LLMs employ for propositional reasoning. We address this gap through comprehensive analysis of Qwen3 (8B and 14B) on PropLogic-MI, a controlled dataset spanning 11 propositional logic rule categories across one-hop and two-hop reasoning. Rather than asking ''which components are necessary,'' we ask ''how does the model organize computation?'' Our analysis reveals a coherent computational architecture comprising four interlocking mechanisms: Staged Computation (layer-wise processing phases), Information Transmission (information flow aggregation at boundary tokens), Fact Retrospection (persistent re-access of source facts), and Specialized Attention Heads (functionally distinct head types). These mechanisms generalize across model scales, rule types, and reasoning depths, providing mechanistic evidence that LLMs employ structured computational strategies for logical reasoning.",
      "authors": [
        "Danchun Chen",
        "Qiyao Yan",
        "Liangming Pan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 04:20:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04260v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03561v2",
      "title": "Green's-Function Spherical Neural Operators for Biological Heterogeneity",
      "abstract": "Spherical deep learning has been widely applied to a broad range of real-world problems. Existing approaches often face challenges in balancing strong spherical geometric inductive biases with the need to model real-world heterogeneity. To solve this while retaining spherical geometry, we first introduce a designable Green's function framework (DGF) to provide new spherical operator solution strategy: Design systematic Green's functions under rotational group. Based on DGF, to model biological heterogeneity, we propose Green's-Function Spherical Neural Operator (GSNO) fusing 3 operator solutions: (1) Equivariant Solution derived from Equivariant Green's Function for symmetry-consistent modeling; (2) Invariant Solution derived from Invariant Green's Function to eliminate nuisance heterogeneity, e.g., consistent background field; (3) Anisotropic Solution derived from Anisotropic Green's Function to model anisotropic systems, especially fibers with preferred direction. Therefore, the resulting model, GSNO can adapt to real-world heterogeneous systems with nuisance variability and anisotropy while retaining spectral efficiency. Evaluations on spherical MNIST, Shallow Water Equation, diffusion MRI fiber prediction, cortical parcellation and molecule structure modeling demonstrate the superiority of GSNO.",
      "authors": [
        "Hao Tang",
        "Hao Chen",
        "Hao Li",
        "Chao Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 04:01:25+00:00",
      "link": "https://arxiv.org/pdf/2601.03561v2",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03559v1",
      "title": "DiffCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs",
      "abstract": "Chain-of-Thought (CoT) reasoning improves multi-step mathematical problem solving in large language models but remains vulnerable to exposure bias and error accumulation, as early mistakes propagate irreversibly through autoregressive decoding. In this work, we propose DiffCoT, a diffusion-styled CoT framework that reformulates CoT reasoning as an iterative denoising process. DiffCoT integrates diffusion principles at the reasoning-step level via a sliding-window mechanism, enabling unified generation and retrospective correction of intermediate steps while preserving token-level autoregression. To maintain causal consistency, we further introduce a causal diffusion noise schedule that respects the temporal structure of reasoning chains. Extensive experiments on three multi-step CoT reasoning benchmarks across diverse model backbones demonstrate that DiffCoT consistently outperforms existing CoT preference optimization methods, yielding improved robustness and error-correction capability in CoT reasoning.",
      "authors": [
        "Shidong Cao",
        "Hongzhan Lin",
        "Yuxuan Gu",
        "Ziyang Luo",
        "Jing Ma"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 03:58:42+00:00",
      "link": "https://arxiv.org/pdf/2601.03559v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03555v1",
      "title": "SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models",
      "abstract": "Training reliable tool-augmented agents remains a significant challenge, largely due to the difficulty of credit assignment in multi-step reasoning. While process-level reward models offer a promising direction, existing LLM-based judges often produce noisy and inconsistent signals because they lack fine-grained, task-specific rubrics to distinguish high-level planning from low-level execution. In this work, we introduce SCRIBE (Skill-Conditioned Reward with Intermediate Behavioral Evaluation), a reinforcement learning framework that intervenes at a novel mid-level abstraction. SCRIBE grounds reward modeling in a curated library of skill prototypes, transforming open-ended LLM evaluation into a constrained verification problem. By routing each subgoal to a corresponding prototype, the reward model is equipped with precise, structured rubrics that substantially reduce reward variance.   Experimental results show that SCRIBE achieves state-of-the-art performance across a range of reasoning and tool-use benchmarks. In particular, it improves the AIME25 accuracy of a Qwen3-4B model from 43.3% to 63.3%, and significantly increases success rates in complex multi-turn tool interactions.   Further analysis of training dynamics reveals a co-evolution across abstraction levels, where mastery of mid-level skills consistently precedes the emergence of effective high-level planning behaviors. Finally, we demonstrate that SCRIBE is additive to low-level tool optimizations, providing a scalable and complementary pathway toward more autonomous and reliable tool-using agents.",
      "authors": [
        "Yuxuan Jiang",
        "Francis Ferraro"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 03:49:48+00:00",
      "link": "https://arxiv.org/pdf/2601.03555v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03528v1",
      "title": "CloudMatch: Weak-to-Strong Consistency Learning for Semi-Supervised Cloud Detection",
      "abstract": "Due to the high cost of annotating accurate pixel-level labels, semi-supervised learning has emerged as a promising approach for cloud detection. In this paper, we propose CloudMatch, a semi-supervised framework that effectively leverages unlabeled remote sensing imagery through view-consistency learning combined with scene-mixing augmentations. An observation behind CloudMatch is that cloud patterns exhibit structural diversity and contextual variability across different scenes and within the same scene category. Our key insight is that enforcing prediction consistency across diversely augmented views, incorporating both inter-scene and intra-scene mixing, enables the model to capture the structural diversity and contextual richness of cloud patterns. Specifically, CloudMatch generates one weakly augmented view along with two complementary strongly augmented views for each unlabeled image: one integrates inter-scene patches to simulate contextual variety, while the other employs intra-scene mixing to preserve semantic coherence. This approach guides pseudolabel generation and enhances generalization. Extensive experiments show that CloudMatch achieves good performance, demonstrating its capability to utilize unlabeled data efficiently and advance semi-supervised cloud detection.",
      "authors": [
        "Jiayi Zhao",
        "Changlu Chen",
        "Jingsheng Li",
        "Tianxiang Xue",
        "Kun Zhan"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 02:31:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03528v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03511v1",
      "title": "IntroLM: Introspective Language Models via Prefilling-Time Self-Evaluation",
      "abstract": "A major challenge for the operation of large language models (LLMs) is how to predict whether a specific LLM will produce sufficiently high-quality output for a given query. Existing approaches rely on external classifiers, most commonly BERT based models, which suffer from limited context windows, constrained representational capacity, and additional computational overhead. We propose IntroLM, a method that enables causal language models to predict their own output quality during the prefilling phase without affecting generation using introspective tokens. By introducing token conditional LoRA that activates only for the introspective token, the model learns to predict the output quality for a given query while preserving the original backbone behavior and avoiding external evaluators. On question answering benchmarks, IntroLM applied to Qwen3 8B achieves a ROC AUC of 90 precent for success prediction, outperforming a DeBERTa classifier by 14 precent. When integrated into multi model routing systems, IntroLM achieves superior cost performance tradeoffs, reducing latency by up to 33 precent and large model usage by up to 50 precent at matched reliability.",
      "authors": [
        "Hossein Hosseini Kasnavieh",
        "Gholamreza Haffari",
        "Chris Leckie",
        "Adel N. Toosi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 01:48:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03511v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03500v1",
      "title": "SDCD: Structure-Disrupted Contrastive Decoding for Mitigating Hallucinations in Large Vision-Language Models",
      "abstract": "Large Vision-Language Models (LVLMs) demonstrate significant progress in multimodal understanding and reasoning, yet object hallucination remains a critical challenge. While existing research focuses on mitigating language priors or high-level statistical biases, they often overlook the internal complexities of the visual encoding process. We identify that visual statistical bias, arising from the inherent Bag-of-Patches behavior of Vision Encoders under weak structural supervision, acts as a contributing factor of object hallucinations. Under this bias, models prioritize local texture features within individual patches over holistic geometric structures. This tendency may induce spurious visual confidence and result in hallucinations. To address this, we introduce a training-free algorithm called Structure-Disrupted Contrastive Decoding (SDCD), which performs contrastive calibration of the output distribution by introducing a shuffled structure-disrupted view. By penalizing tokens that maintain high confidence under this structure-less view, SDCD effectively suppresses the texture-driven bias. Experimental results demonstrate that SDCD significantly mitigates hallucinations across multiple benchmarks and enhances the overall multimodal capabilities of LVLMs.",
      "authors": [
        "Yuxuan Xia",
        "Siheng Wang",
        "Peng Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 01:27:58+00:00",
      "link": "https://arxiv.org/pdf/2601.03500v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03994v1",
      "title": "pintervals: an R package for model-agnostic prediction intervals",
      "abstract": "The \\pkg{pintervals} package aims to provide a unified framework for constructing prediction intervals and calibrating predictions in a model-agnostic setting using set-aside calibration data. It comprises routines to construct conformal as well as parametric and bootstrapped prediction intervals from any model that outputs point predictions. Several R packages and functions already exist for constructing prediction intervals, but they often focus on specific modeling frameworks or types of predictions, or require manual customization for different models or applications. By providing a consistent interface for a variety of prediction interval construction approaches (all model-agnostic), \\pkg{pintervals} allows researchers to apply and compare them across different modeling frameworks and applications.",
      "authors": [
        "David Randahl",
        "Anders Hjort",
        "Jonathan P. Williams"
      ],
      "primary_category": "stat.AP",
      "categories": [
        "stat.AP",
        "stat.CO",
        "stat.ME"
      ],
      "published": "2026-01-07 15:04:51+00:00",
      "link": "https://arxiv.org/pdf/2601.03994v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04914v1",
      "title": "Analytic Regularity and Approximation Limits of Coefficient-Constrained Shallow Networks",
      "abstract": "We study approximation limits of single-hidden-layer neural networks with analytic activation functions under global coefficient constraints. Under uniform $\\ell^1$ bounds, or more generally sub-exponential growth of the coefficients, we show that such networks generate model classes with strong quantitative regularity, leading to uniform analyticity of the realized functions. As a consequence, up to an exponentially small residual term, the error of best network approximation on generic target functions is bounded from below by the error of best polynomial approximation. In particular, networks with analytic activation functions with controlled coefficients cannot outperform classical polynomial approximation rates on non-analytic targets. The underlying rigidity phenomenon extends to smoother, non-analytic activations satisfying Gevrey-type regularity assumptions, yielding sub-exponential variants of the approximation barrier. The analysis is entirely deterministic and relies on a comparison argument combined with classical Bernstein-type estimates; extensions to higher dimensions are also discussed.",
      "authors": [
        "Jean-Gabriel Attali"
      ],
      "primary_category": "q-fin.MF",
      "categories": [
        "q-fin.MF"
      ],
      "published": "2026-01-08 13:13:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04914v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04775v1",
      "title": "Towards a Unified Theoretical Framework for Self-Supervised MRI Reconstruction",
      "abstract": "The demand for high-resolution, non-invasive imaging continues to drive innovation in magnetic resonance imaging (MRI), yet prolonged acquisition times hinder accessibility and real-time applications. While deep learning-based reconstruction methods have accelerated MRI, their predominant supervised paradigm depends on fully-sampled reference data that are challenging to acquire. Recently, self-supervised learning (SSL) approaches have emerged as promising alternatives, but most are empirically designed and fragmented. Therefore, we introduce UNITS (Unified Theory for Self-supervision), a general framework for self-supervised MRI reconstruction. UNITS unifies prior SSL strategies within a common formalism, enabling consistent interpretation and systematic benchmarking. We prove that SSL can achieve the same expected performance as supervised learning. Under this theoretical guarantee, we introduce sampling stochasticity and flexible data utilization, which improve network generalization under out-of-domain distributions and stabilize training. Together, these contributions establish UNITS as a theoretical foundation and a practical paradigm for interpretable, generalizable, and clinically applicable self-supervised MRI reconstruction.",
      "authors": [
        "Siying Xu",
        "Kerstin Hammernik",
        "Daniel Rueckert",
        "Sergios Gatidis",
        "Thomas Küstner"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV"
      ],
      "published": "2026-01-08 09:57:39+00:00",
      "link": "https://arxiv.org/pdf/2601.04775v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03767v1",
      "title": "Output Consensus on Periodic References for Constrained Multi-agent Systems Under a Switching Network",
      "abstract": "This work addresses the output consensus problem of constrained heterogeneous multi-agent systems under a switching network with potential communication delay, where outputs are periodic and characterized by a linear exosystem. Since periodic references have more complex dynamics, it is more challenging to track periodic references and achieve consensus on them. In this paper, a model predictive control method incorporating an artificial reference and a modified cost is proposed to track periodic references, which maintains recursive feasibility even when reference switches. Moreover, consensus protocols are proposed to achieve consensus on periodic references in different scenarios, in which global information such as the set of globally admissible references and the global time index are not involved. Theoretical analysis proves that constrained output consensus is asymptotically achieved with the proposed algorithm as the references of each agent converge and agents track their references while maintaining constraint satisfaction. Finally, numerical examples are provided to verify the effectiveness of the proposed algorithm.",
      "authors": [
        "Shibo Han",
        "Bonan Hou",
        "Chong Jin Ong"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-07 10:00:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03767v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03558v1",
      "title": "Artificial Intelligence and Skills: Evidence from Contrastive Learning in Online Job Vacancies",
      "abstract": "We investigate the impact of artificial intelligence (AI) adoption on skill requirements using 14 million online job vacancies from Chinese listed firms (2018-2022). Employing a novel Extreme Multi-Label Classification (XMLC) algorithm trained via contrastive learning and LLM-driven data augmentation, we map vacancy requirements to the ESCO framework. By benchmarking occupation-skill relationships against 2018 O*NET-ESCO mappings, we document a robust causal relationship between AI adoption and the expansion of skill portfolios. Our analysis identifies two distinct mechanisms. First, AI reduces information asymmetry in the labor market, enabling firms to specify current occupation-specific requirements with greater precision. Second, AI empowers firms to anticipate evolving labor market dynamics. We find that AI adoption significantly increases the demand for \"forward-looking\" skills--those absent from 2018 standards but subsequently codified in 2022 updates. This suggests that AI allows firms to lead, rather than follow, the formal evolution of occupational standards. Our findings highlight AI's dual role as both a stabilizer of current recruitment information and a catalyst for proactive adaptation to future skill shifts.",
      "authors": [
        "Hangyu Chen",
        "Yongming Sun",
        "Yiming Yuan"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN"
      ],
      "published": "2026-01-07 03:55:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03558v1",
      "tags": [
        "query:大厂llm"
      ]
    }
  ],
  "queries": [
    {
      "type": "llm_query",
      "tag": "大厂llm",
      "paper_tag": "query:大厂llm",
      "query_text": "我希望找一些大厂出的大模型技术论文或者技术报告",
      "sim_scores": {
        "2601.05163v1": {
          "score": 0.024497309544038517,
          "rank": 1
        },
        "2601.05191v1": {
          "score": 0.02075268817204301,
          "rank": 2
        },
        "2601.05125v1": {
          "score": 0.02069672131147541,
          "rank": 3
        },
        "2601.05103v1": {
          "score": 0.020449699554177168,
          "rank": 4
        },
        "2601.05192v1": {
          "score": 0.02039337474120083,
          "rank": 5
        },
        "2601.05170v1": {
          "score": 0.01951265943270512,
          "rank": 6
        },
        "2601.05099v1": {
          "score": 0.019401133947554924,
          "rank": 7
        },
        "2601.05184v1": {
          "score": 0.019375873311597576,
          "rank": 8
        },
        "2601.05051v1": {
          "score": 0.01867479293639631,
          "rank": 9
        },
        "2601.05200v1": {
          "score": 0.017652944539736995,
          "rank": 10
        },
        "2601.05187v1": {
          "score": 0.017089910775566233,
          "rank": 11
        },
        "2601.05101v1": {
          "score": 0.01641641641641642,
          "rank": 12
        },
        "2601.05251v1": {
          "score": 0.01639344262295082,
          "rank": 13
        },
        "2601.03540v1": {
          "score": 0.01639344262295082,
          "rank": 14
        },
        "2601.05106v1": {
          "score": 0.016254277441431954,
          "rank": 15
        },
        "2601.05249v1": {
          "score": 0.016129032258064516,
          "rank": 16
        },
        "2601.03743v1": {
          "score": 0.016129032258064516,
          "rank": 17
        },
        "2601.05250v1": {
          "score": 0.015873015873015872,
          "rank": 18
        },
        "2601.03986v1": {
          "score": 0.015873015873015872,
          "rank": 19
        },
        "2601.05248v1": {
          "score": 0.015625,
          "rank": 20
        },
        "2601.04879v1": {
          "score": 0.015625,
          "rank": 21
        },
        "2601.05247v1": {
          "score": 0.015384615384615385,
          "rank": 22
        },
        "2601.03496v1": {
          "score": 0.015384615384615385,
          "rank": 23
        },
        "2601.05246v1": {
          "score": 0.015151515151515152,
          "rank": 24
        },
        "2601.05245v1": {
          "score": 0.014925373134328358,
          "rank": 25
        },
        "2601.03748v1": {
          "score": 0.014925373134328358,
          "rank": 26
        },
        "2601.05091v1": {
          "score": 0.014844136566056407,
          "rank": 27
        },
        "2601.05244v1": {
          "score": 0.014705882352941176,
          "rank": 28
        },
        "2601.04891v1": {
          "score": 0.014705882352941176,
          "rank": 29
        },
        "2601.05243v1": {
          "score": 0.014492753623188406,
          "rank": 30
        },
        "2601.04632v1": {
          "score": 0.014492753623188406,
          "rank": 31
        },
        "2601.05242v1": {
          "score": 0.014285714285714285,
          "rank": 32
        },
        "2601.03618v1": {
          "score": 0.014285714285714285,
          "rank": 33
        },
        "2601.05241v1": {
          "score": 0.014084507042253521,
          "rank": 34
        },
        "2601.04932v1": {
          "score": 0.014084507042253521,
          "rank": 35
        },
        "2601.05240v1": {
          "score": 0.013888888888888888,
          "rank": 36
        },
        "2601.03908v1": {
          "score": 0.013888888888888888,
          "rank": 37
        },
        "2601.05239v1": {
          "score": 0.0136986301369863,
          "rank": 38
        },
        "2601.04696v1": {
          "score": 0.0136986301369863,
          "rank": 39
        },
        "2601.05237v1": {
          "score": 0.013513513513513514,
          "rank": 40
        },
        "2601.03511v1": {
          "score": 0.013513513513513514,
          "rank": 41
        },
        "2601.05232v1": {
          "score": 0.013333333333333334,
          "rank": 42
        },
        "2601.04888v1": {
          "score": 0.013333333333333334,
          "rank": 43
        },
        "2601.05230v1": {
          "score": 0.013157894736842105,
          "rank": 44
        },
        "2601.03812v1": {
          "score": 0.013157894736842105,
          "rank": 45
        },
        "2601.05227v1": {
          "score": 0.012987012987012988,
          "rank": 46
        },
        "2601.05225v1": {
          "score": 0.01282051282051282,
          "rank": 47
        },
        "2601.04764v1": {
          "score": 0.01282051282051282,
          "rank": 48
        },
        "2601.05219v1": {
          "score": 0.012658227848101266,
          "rank": 49
        },
        "2601.04377v1": {
          "score": 0.012658227848101266,
          "rank": 50
        },
        "2601.05217v1": {
          "score": 0.0125,
          "rank": 51
        },
        "2601.05215v1": {
          "score": 0.012345679012345678,
          "rank": 52
        },
        "2601.05214v1": {
          "score": 0.012195121951219513,
          "rank": 53
        },
        "2601.03794v1": {
          "score": 0.012195121951219513,
          "rank": 54
        },
        "2601.05212v1": {
          "score": 0.012048192771084338,
          "rank": 55
        },
        "2601.05208v1": {
          "score": 0.011904761904761904,
          "rank": 56
        },
        "2601.04823v1": {
          "score": 0.011904761904761904,
          "rank": 57
        },
        "2601.05205v1": {
          "score": 0.011764705882352941,
          "rank": 58
        },
        "2601.04859v1": {
          "score": 0.011764705882352941,
          "rank": 59
        },
        "2601.05202v1": {
          "score": 0.011627906976744186,
          "rank": 60
        },
        "2601.03676v1": {
          "score": 0.011627906976744186,
          "rank": 61
        },
        "2601.05201v1": {
          "score": 0.011494252873563218,
          "rank": 62
        },
        "2601.04597v1": {
          "score": 0.011494252873563218,
          "rank": 63
        },
        "2601.05047v1": {
          "score": 0.011363636363636364,
          "rank": 64
        },
        "2601.05199v1": {
          "score": 0.011235955056179775,
          "rank": 65
        },
        "2601.04568v1": {
          "score": 0.011235955056179775,
          "rank": 66
        },
        "2601.05195v1": {
          "score": 0.011111111111111112,
          "rank": 67
        },
        "2601.04945v1": {
          "score": 0.011111111111111112,
          "rank": 68
        },
        "2601.05194v1": {
          "score": 0.01098901098901099,
          "rank": 69
        },
        "2601.04526v1": {
          "score": 0.01098901098901099,
          "rank": 70
        },
        "2601.04577v1": {
          "score": 0.010869565217391304,
          "rank": 71
        },
        "2601.04919v1": {
          "score": 0.010752688172043012,
          "rank": 72
        },
        "2601.04646v1": {
          "score": 0.010638297872340425,
          "rank": 73
        },
        "2601.04424v1": {
          "score": 0.010526315789473684,
          "rank": 74
        },
        "2601.05181v1": {
          "score": 0.010416666666666666,
          "rank": 75
        },
        "2601.04036v1": {
          "score": 0.010416666666666666,
          "rank": 76
        },
        "2601.05180v1": {
          "score": 0.010309278350515464,
          "rank": 77
        },
        "2601.03752v1": {
          "score": 0.010309278350515464,
          "rank": 78
        },
        "2601.05175v1": {
          "score": 0.01020408163265306,
          "rank": 79
        },
        "2601.04060v1": {
          "score": 0.01020408163265306,
          "rank": 80
        },
        "2601.05174v1": {
          "score": 0.010101010101010102,
          "rank": 81
        },
        "2601.04498v1": {
          "score": 0.010101010101010102,
          "rank": 82
        },
        "2601.05173v1": {
          "score": 0.01,
          "rank": 83
        },
        "2601.05172v1": {
          "score": 0.009900990099009901,
          "rank": 84
        },
        "2601.04768v1": {
          "score": 0.009900990099009901,
          "rank": 85
        },
        "2601.05171v1": {
          "score": 0.00980392156862745,
          "rank": 86
        },
        "2601.03988v1": {
          "score": 0.009708737864077669,
          "rank": 87
        },
        "2601.05167v1": {
          "score": 0.009615384615384616,
          "rank": 88
        },
        "2601.03725v1": {
          "score": 0.009615384615384616,
          "rank": 89
        },
        "2601.05166v1": {
          "score": 0.009523809523809525,
          "rank": 90
        },
        "2601.05165v1": {
          "score": 0.009433962264150943,
          "rank": 91
        },
        "2601.04458v1": {
          "score": 0.009433962264150943,
          "rank": 92
        },
        "2601.03624v1": {
          "score": 0.009345794392523364,
          "rank": 93
        },
        "2601.05162v1": {
          "score": 0.009259259259259259,
          "rank": 94
        },
        "2601.04700v1": {
          "score": 0.009259259259259259,
          "rank": 95
        },
        "2601.05159v1": {
          "score": 0.009174311926605505,
          "rank": 96
        },
        "2601.03926v1": {
          "score": 0.009174311926605505,
          "rank": 97
        },
        "2601.05157v1": {
          "score": 0.00909090909090909,
          "rank": 98
        },
        "2601.04651v1": {
          "score": 0.00909090909090909,
          "rank": 99
        },
        "2601.05152v1": {
          "score": 0.009009009009009009,
          "rank": 100
        },
        "2601.05151v1": {
          "score": 0.008928571428571428,
          "rank": 101
        },
        "2601.04582v1": {
          "score": 0.008928571428571428,
          "rank": 102
        },
        "2601.05150v1": {
          "score": 0.008849557522123894,
          "rank": 103
        },
        "2601.05149v1": {
          "score": 0.008771929824561403,
          "rank": 104
        },
        "2601.04742v1": {
          "score": 0.008771929824561403,
          "rank": 105
        },
        "2601.05148v1": {
          "score": 0.008695652173913044,
          "rank": 106
        },
        "2601.03606v1": {
          "score": 0.008695652173913044,
          "rank": 107
        },
        "2601.05144v1": {
          "score": 0.008620689655172414,
          "rank": 108
        },
        "2601.05143v1": {
          "score": 0.008547008547008548,
          "rank": 109
        },
        "2601.04571v1": {
          "score": 0.008547008547008548,
          "rank": 110
        },
        "2601.05138v1": {
          "score": 0.00847457627118644,
          "rank": 111
        },
        "2601.03746v1": {
          "score": 0.00847457627118644,
          "rank": 112
        },
        "2601.05137v1": {
          "score": 0.008403361344537815,
          "rank": 113
        },
        "2601.04703v1": {
          "score": 0.008403361344537815,
          "rank": 114
        },
        "2601.05134v1": {
          "score": 0.008333333333333333,
          "rank": 115
        },
        "2601.04618v1": {
          "score": 0.008333333333333333,
          "rank": 116
        },
        "2601.05127v1": {
          "score": 0.008264462809917356,
          "rank": 117
        },
        "2601.04633v1": {
          "score": 0.008264462809917356,
          "rank": 118
        },
        "2601.04819v1": {
          "score": 0.00819672131147541,
          "rank": 119
        },
        "2601.05124v1": {
          "score": 0.008130081300813009,
          "rank": 120
        },
        "2601.04395v1": {
          "score": 0.008130081300813009,
          "rank": 121
        },
        "2601.05116v1": {
          "score": 0.008064516129032258,
          "rank": 122
        },
        "2601.03597v1": {
          "score": 0.008064516129032258,
          "rank": 123
        },
        "2601.05114v1": {
          "score": 0.008,
          "rank": 124
        },
        "2601.04750v1": {
          "score": 0.008,
          "rank": 125
        },
        "2601.05111v1": {
          "score": 0.007936507936507936,
          "rank": 126
        },
        "2601.05009v1": {
          "score": 0.007936507936507936,
          "rank": 127
        },
        "2601.05110v1": {
          "score": 0.007874015748031496,
          "rank": 128
        },
        "2601.04889v1": {
          "score": 0.007874015748031496,
          "rank": 129
        },
        "2601.05109v1": {
          "score": 0.0078125,
          "rank": 130
        },
        "2601.04853v1": {
          "score": 0.0078125,
          "rank": 131
        },
        "2601.05108v1": {
          "score": 0.007751937984496124,
          "rank": 132
        },
        "2601.05107v1": {
          "score": 0.007692307692307693,
          "rank": 133
        },
        "2601.05039v1": {
          "score": 0.007692307692307693,
          "rank": 134
        },
        "2601.04131v1": {
          "score": 0.007633587786259542,
          "rank": 135
        },
        "2601.05105v1": {
          "score": 0.007575757575757576,
          "rank": 136
        },
        "2601.04574v1": {
          "score": 0.007575757575757576,
          "rank": 137
        },
        "2601.05104v1": {
          "score": 0.007518796992481203,
          "rank": 138
        },
        "2601.03515v1": {
          "score": 0.007518796992481203,
          "rank": 139
        },
        "2601.04094v1": {
          "score": 0.007462686567164179,
          "rank": 140
        },
        "2601.04569v1": {
          "score": 0.007407407407407408,
          "rank": 141
        },
        "2601.04349v1": {
          "score": 0.007352941176470588,
          "rank": 142
        },
        "2601.05098v1": {
          "score": 0.0072992700729927005,
          "rank": 143
        },
        "2601.03872v1": {
          "score": 0.0072992700729927005,
          "rank": 144
        },
        "2601.05095v1": {
          "score": 0.007246376811594203,
          "rank": 145
        },
        "2601.03698v1": {
          "score": 0.007246376811594203,
          "rank": 146
        },
        "2601.05093v1": {
          "score": 0.007194244604316547,
          "rank": 147
        },
        "2601.03648v1": {
          "score": 0.007194244604316547,
          "rank": 148
        },
        "2601.05092v1": {
          "score": 0.007142857142857143,
          "rank": 149
        },
        "2601.05027v1": {
          "score": 0.007142857142857143,
          "rank": 150
        },
        "2601.04734v1": {
          "score": 0.0070921985815602835,
          "rank": 151
        },
        "2601.05084v1": {
          "score": 0.007042253521126761,
          "rank": 152
        },
        "2601.05038v1": {
          "score": 0.007042253521126761,
          "rank": 153
        },
        "2601.05083v1": {
          "score": 0.006993006993006993,
          "rank": 154
        },
        "2601.03699v1": {
          "score": 0.006993006993006993,
          "rank": 155
        },
        "2601.05082v1": {
          "score": 0.006944444444444444,
          "rank": 156
        },
        "2601.04720v1": {
          "score": 0.006944444444444444,
          "rank": 157
        },
        "2601.05081v1": {
          "score": 0.006896551724137931,
          "rank": 158
        },
        "2601.04801v1": {
          "score": 0.006896551724137931,
          "rank": 159
        },
        "2601.05076v1": {
          "score": 0.00684931506849315,
          "rank": 160
        },
        "2601.04336v1": {
          "score": 0.00684931506849315,
          "rank": 161
        },
        "2601.05075v1": {
          "score": 0.006802721088435374,
          "rank": 162
        },
        "2601.04726v1": {
          "score": 0.006802721088435374,
          "rank": 163
        },
        "2601.05074v1": {
          "score": 0.006756756756756757,
          "rank": 164
        },
        "2601.04019v1": {
          "score": 0.006756756756756757,
          "rank": 165
        },
        "2601.05073v1": {
          "score": 0.006711409395973154,
          "rank": 166
        },
        "2601.03878v1": {
          "score": 0.006711409395973154,
          "rank": 167
        },
        "2601.05072v1": {
          "score": 0.006666666666666667,
          "rank": 168
        },
        "2601.03558v1": {
          "score": 0.006666666666666667,
          "rank": 169
        },
        "2601.05065v1": {
          "score": 0.006622516556291391,
          "rank": 170
        },
        "2601.04260v1": {
          "score": 0.006622516556291391,
          "rank": 171
        },
        "2601.05063v1": {
          "score": 0.006578947368421052,
          "rank": 172
        },
        "2601.04390v1": {
          "score": 0.006578947368421052,
          "rank": 173
        },
        "2601.05062v1": {
          "score": 0.006535947712418301,
          "rank": 174
        },
        "2601.04861v1": {
          "score": 0.006535947712418301,
          "rank": 175
        },
        "2601.05059v1": {
          "score": 0.006493506493506494,
          "rank": 176
        },
        "2601.04707v1": {
          "score": 0.006493506493506494,
          "rank": 177
        },
        "2601.05057v1": {
          "score": 0.0064516129032258064,
          "rank": 178
        },
        "2601.05053v1": {
          "score": 0.00641025641025641,
          "rank": 179
        },
        "2601.04157v1": {
          "score": 0.00641025641025641,
          "rank": 180
        },
        "2601.05052v1": {
          "score": 0.006369426751592357,
          "rank": 181
        },
        "2601.04885v1": {
          "score": 0.006369426751592357,
          "rank": 182
        },
        "2601.03940v1": {
          "score": 0.006329113924050633,
          "rank": 183
        },
        "2601.05050v1": {
          "score": 0.006289308176100629,
          "rank": 184
        },
        "2601.05049v1": {
          "score": 0.00625,
          "rank": 185
        },
        "2601.03605v1": {
          "score": 0.00625,
          "rank": 186
        }
      },
      "ranked": [
        {
          "paper_id": "2601.04131v1",
          "score": 1.0,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04696v1",
          "score": 1.0,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04720v1",
          "score": 0.9739328771586835,
          "star_rating": 5
        },
        {
          "paper_id": "2601.05049v1",
          "score": 0.9739328771586835,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03743v1",
          "score": 0.9486932820266152,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04597v1",
          "score": 0.9486932820266152,
          "star_rating": 5
        },
        {
          "paper_id": "2601.05047v1",
          "score": 0.9242424242424242,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04260v1",
          "score": 0.9242424242424242,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04424v1",
          "score": 0.9005439005439005,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03511v1",
          "score": 0.9005439005439005,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03676v1",
          "score": 0.8775635139271503,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05009v1",
          "score": 0.8775635139271503,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05106v1",
          "score": 0.8552691090004522,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05062v1",
          "score": 0.8552691090004522,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04377v1",
          "score": 0.8336304218657159,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03624v1",
          "score": 0.8336304218657159,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04885v1",
          "score": 0.8126189430537256,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03597v1",
          "score": 0.8126189430537256,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05050v1",
          "score": 0.7922077922077921,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04526v1",
          "score": 0.7922077922077921,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05110v1",
          "score": 0.7723716033575188,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04651v1",
          "score": 0.7723716033575188,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05191v1",
          "score": 0.7530864197530863,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05184v1",
          "score": 0.7530864197530863,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05148v1",
          "score": 0.7343295973432958,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05124v1",
          "score": 0.7343295973432958,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03986v1",
          "score": 0.7160797160797161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03878v1",
          "score": 0.7160797160797161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05076v1",
          "score": 0.6983164983164983,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04891v1",
          "score": 0.6983164983164983,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05201v1",
          "score": 0.6810207336523124,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04700v1",
          "score": 0.6810207336523124,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03725v1",
          "score": 0.6641742096287551,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03515v1",
          "score": 0.6641742096287551,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03699v1",
          "score": 0.6477596477596477,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03648v1",
          "score": 0.6477596477596477,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04157v1",
          "score": 0.6317606444188721,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03872v1",
          "score": 0.6317606444188721,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05075v1",
          "score": 0.6161616161616161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05053v1",
          "score": 0.6161616161616161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05027v1",
          "score": 0.6009477490958971,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04823v1",
          "score": 0.6009477490958971,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03940v1",
          "score": 0.5861049519586105,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05175v1",
          "score": 0.5861049519586105,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05240v1",
          "score": 0.571619812583668,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03926v1",
          "score": 0.571619812583668,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05144v1",
          "score": 0.5574795574795574,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04726v1",
          "score": 0.5574795574795574,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05159v1",
          "score": 0.5436720142602495,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05167v1",
          "score": 0.5436720142602495,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03908v1",
          "score": 0.5301855766972046,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04633v1",
          "score": 0.5301855766972046,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03746v1",
          "score": 0.5170091721815859,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04458v1",
          "score": 0.5170091721815859,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03752v1",
          "score": 0.5041322314049587,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03605v1",
          "score": 0.5041322314049587,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04632v1",
          "score": 0.49154466008398584,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05248v1",
          "score": 0.49154466008398584,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05187v1",
          "score": 0.4792368125701459,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04888v1",
          "score": 0.4792368125701459,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04932v1",
          "score": 0.4671994671994672,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04861v1",
          "score": 0.4671994671994672,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05192v1",
          "score": 0.4554238032498901,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03748v1",
          "score": 0.4554238032498901,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04945v1",
          "score": 0.44390137938525037,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04734v1",
          "score": 0.44390137938525037,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04568v1",
          "score": 0.4326241134751772,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05246v1",
          "score": 0.4326241134751772,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05171v1",
          "score": 0.4215842636895268,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05101v1",
          "score": 0.4215842636895268,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05219v1",
          "score": 0.4107744107744107,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04703v1",
          "score": 0.4107744107744107,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04853v1",
          "score": 0.40018744142455476,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03540v1",
          "score": 0.40018744142455476,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04879v1",
          "score": 0.3898165326736754,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05172v1",
          "score": 0.3898165326736754,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05038v1",
          "score": 0.37965513723089483,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05114v1",
          "score": 0.37965513723089483,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05214v1",
          "score": 0.3696969696969697,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05052v1",
          "score": 0.3696969696969697,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05073v1",
          "score": 0.3599359935993599,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05125v1",
          "score": 0.3599359935993599,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05149v1",
          "score": 0.35036640918993855,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04574v1",
          "score": 0.35036640918993855,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05170v1",
          "score": 0.34098264195351563,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04801v1",
          "score": 0.34098264195351563,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04036v1",
          "score": 0.3317793317793318,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05107v1",
          "score": 0.3317793317793318,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05174v1",
          "score": 0.3227513227513228,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03698v1",
          "score": 0.3227513227513228,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03606v1",
          "score": 0.31389365351629495,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05059v1",
          "score": 0.31389365351629495,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05138v1",
          "score": 0.3052015481922023,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04889v1",
          "score": 0.3052015481922023,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05109v1",
          "score": 0.2966704077815188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04571v1",
          "score": 0.2966704077815188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03812v1",
          "score": 0.28829580205726996,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04750v1",
          "score": 0.28829580205726996,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04395v1",
          "score": 0.2800734618916436,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05039v1",
          "score": 0.2800734618916436,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05127v1",
          "score": 0.27199927199927193,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05143v1",
          "score": 0.27199927199927193,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05230v1",
          "score": 0.26406926406926395,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05051v1",
          "score": 0.26406926406926395,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05104v1",
          "score": 0.2562796102619111,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04060v1",
          "score": 0.2562796102619111,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04577v1",
          "score": 0.24862661704766958,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05162v1",
          "score": 0.24862661704766958,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04768v1",
          "score": 0.2411067193675889,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05232v1",
          "score": 0.2411067193675889,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05134v1",
          "score": 0.2337164750957854,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04764v1",
          "score": 0.2337164750957854,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04582v1",
          "score": 0.22645255978589315,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05163v1",
          "score": 0.22645255978589315,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04646v1",
          "score": 0.219311761684643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05250v1",
          "score": 0.219311761684643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05242v1",
          "score": 0.21229097699685928,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04094v1",
          "score": 0.21229097699685928,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04819v1",
          "score": 0.20538720538720534,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04569v1",
          "score": 0.20538720538720534,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05111v1",
          "score": 0.1985975457049837,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05227v1",
          "score": 0.1985975457049837,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05205v1",
          "score": 0.1919191919191919,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05116v1",
          "score": 0.1919191919191919,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05200v1",
          "score": 0.18534942925186831,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05157v1",
          "score": 0.18534942925186831,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03618v1",
          "score": 0.17888563049853365,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04618v1",
          "score": 0.17888563049853365,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04707v1",
          "score": 0.1725252525252525,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03558v1",
          "score": 0.1725252525252525,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05241v1",
          "score": 0.16626583293249952,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05247v1",
          "score": 0.16626583293249952,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04742v1",
          "score": 0.16010498687664038,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05239v1",
          "score": 0.16010498687664038,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05208v1",
          "score": 0.154040404040404,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05099v1",
          "score": 0.154040404040404,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03988v1",
          "score": 0.1480698457442643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05137v1",
          "score": 0.1480698457442643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05083v1",
          "score": 0.1421911421911422,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05237v1",
          "score": 0.1421911421911422,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05150v1",
          "score": 0.13640218983730426,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05105v1",
          "score": 0.13640218983730426,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05215v1",
          "score": 0.13070094888276704,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05063v1",
          "score": 0.13070094888276704,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05251v1",
          "score": 0.12508544087491447,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05243v1",
          "score": 0.12508544087491447,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04859v1",
          "score": 0.119553746419418,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04019v1",
          "score": 0.119553746419418,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05152v1",
          "score": 0.11410400299289188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05180v1",
          "score": 0.11410400299289188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04498v1",
          "score": 0.10873440285204986,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05245v1",
          "score": 0.10873440285204986,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05244v1",
          "score": 0.10344319103443185,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04919v1",
          "score": 0.10344319103443185,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03496v1",
          "score": 0.09822866344605471,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05225v1",
          "score": 0.09822866344605471,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05212v1",
          "score": 0.09308916503161108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05092v1",
          "score": 0.09308916503161108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05249v1",
          "score": 0.08802308802308796,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04336v1",
          "score": 0.08802308802308796,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05098v1",
          "score": 0.08302887026291277,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05095v1",
          "score": 0.08302887026291277,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05103v1",
          "score": 0.07810499359795132,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05151v1",
          "score": 0.07810499359795132,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04390v1",
          "score": 0.07324998234089139,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05081v1",
          "score": 0.07324998234089139,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05165v1",
          "score": 0.06846240179573505,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05199v1",
          "score": 0.06846240179573505,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03794v1",
          "score": 0.06374085684430507,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05202v1",
          "score": 0.06374085684430507,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05166v1",
          "score": 0.05908399059083983,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05074v1",
          "score": 0.05908399059083983,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05108v1",
          "score": 0.05449048306191157,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05194v1",
          "score": 0.049959049959049956,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04349v1",
          "score": 0.04548844146159577,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05065v1",
          "score": 0.04107744107744108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05057v1",
          "score": 0.03672486453943404,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05072v1",
          "score": 0.03242955874534815,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05173v1",
          "score": 0.02819040073942033,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05093v1",
          "score": 0.02400629673356947,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05181v1",
          "score": 0.01987618116650371,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05217v1",
          "score": 0.015799015799015742,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05082v1",
          "score": 0.011773788843852535,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05084v1",
          "score": 0.007799514128628008,
          "star_rating": 1
        },
        {
          "paper_id": "2601.05091v1",
          "score": 0.003875230290324629,
          "star_rating": 1
        },
        {
          "paper_id": "2601.05195v1",
          "score": 0.0,
          "star_rating": 1
        }
      ]
    },
    {
      "type": "keyword",
      "tag": "resnet",
      "paper_tag": "keyword:resnet",
      "query_text": "resnet",
      "sim_scores": {
        "2601.04270v1": {
          "score": 0.03125763125763126,
          "rank": 1
        },
        "2601.04727v1": {
          "score": 0.03021353930031804,
          "rank": 2
        },
        "2601.05052v1": {
          "score": 0.02964426877470356,
          "rank": 3
        },
        "2601.05227v1": {
          "score": 0.02786377708978328,
          "rank": 4
        },
        "2601.04352v1": {
          "score": 0.02738245361196181,
          "rank": 5
        },
        "2601.04397v1": {
          "score": 0.026625704045058884,
          "rank": 6
        },
        "2601.04707v1": {
          "score": 0.024643874643874644,
          "rank": 7
        },
        "2601.04005v1": {
          "score": 0.024634110998406025,
          "rank": 8
        },
        "2601.03924v1": {
          "score": 0.0243593353984793,
          "rank": 9
        },
        "2601.04509v1": {
          "score": 0.023558758314855877,
          "rank": 10
        },
        "2601.03686v1": {
          "score": 0.023333333333333334,
          "rank": 11
        },
        "2601.03955v1": {
          "score": 0.023214285714285715,
          "rank": 12
        },
        "2601.05249v1": {
          "score": 0.020923520923520924,
          "rank": 13
        },
        "2601.03714v2": {
          "score": 0.019569288389513106,
          "rank": 14
        },
        "2601.03875v1": {
          "score": 0.019112874143526866,
          "rank": 15
        },
        "2601.04912v1": {
          "score": 0.018681318681318684,
          "rank": 16
        },
        "2601.04496v1": {
          "score": 0.01796550622804216,
          "rank": 17
        },
        "2601.04361v1": {
          "score": 0.017116145271485077,
          "rank": 18
        },
        "2601.03566v1": {
          "score": 0.0170995670995671,
          "rank": 19
        },
        "2601.03889v1": {
          "score": 0.01639344262295082,
          "rank": 20
        },
        "2601.04518v1": {
          "score": 0.016214449166394244,
          "rank": 21
        },
        "2601.03658v1": {
          "score": 0.016129032258064516,
          "rank": 22
        },
        "2601.04378v1": {
          "score": 0.015944498539435248,
          "rank": 23
        },
        "2601.04069v1": {
          "score": 0.015625,
          "rank": 24
        },
        "2601.03660v1": {
          "score": 0.015625,
          "rank": 25
        },
        "2601.04120v1": {
          "score": 0.015343064015630388,
          "rank": 26
        },
        "2601.04668v1": {
          "score": 0.015151515151515152,
          "rank": 27
        },
        "2601.04914v1": {
          "score": 0.014705882352941176,
          "rank": 28
        },
        "2601.03683v1": {
          "score": 0.014547185780787135,
          "rank": 29
        },
        "2601.03839v1": {
          "score": 0.014492753623188406,
          "rank": 30
        },
        "2601.04918v1": {
          "score": 0.014285714285714285,
          "rank": 31
        },
        "2601.04716v1": {
          "score": 0.014084507042253521,
          "rank": 32
        },
        "2601.03914v1": {
          "score": 0.013888888888888888,
          "rank": 33
        },
        "2601.04855v1": {
          "score": 0.013888888888888888,
          "rank": 34
        },
        "2601.03976v1": {
          "score": 0.013825324180015256,
          "rank": 35
        },
        "2601.03612v1": {
          "score": 0.0136986301369863,
          "rank": 36
        },
        "2601.05246v1": {
          "score": 0.0136986301369863,
          "rank": 37
        },
        "2601.03673v1": {
          "score": 0.013513513513513514,
          "rank": 38
        },
        "2601.05251v1": {
          "score": 0.013513513513513514,
          "rank": 39
        },
        "2601.04607v1": {
          "score": 0.013333333333333334,
          "rank": 40
        },
        "2601.04896v1": {
          "score": 0.013157894736842105,
          "rank": 41
        },
        "2601.04734v1": {
          "score": 0.012987012987012988,
          "rank": 42
        },
        "2601.03822v1": {
          "score": 0.01282051282051282,
          "rank": 43
        },
        "2601.03665v1": {
          "score": 0.01282051282051282,
          "rank": 44
        },
        "2601.04519v1": {
          "score": 0.012658227848101266,
          "rank": 45
        },
        "2601.03781v1": {
          "score": 0.012658227848101266,
          "rank": 46
        },
        "2601.04710v1": {
          "score": 0.0125,
          "rank": 47
        },
        "2601.04348v1": {
          "score": 0.0125,
          "rank": 48
        },
        "2601.04011v1": {
          "score": 0.012345679012345678,
          "rank": 49
        },
        "2601.04153v1": {
          "score": 0.012345679012345678,
          "rank": 50
        },
        "2601.04264v1": {
          "score": 0.012195121951219513,
          "rank": 51
        },
        "2601.04842v1": {
          "score": 0.012048192771084338,
          "rank": 52
        },
        "2601.04263v1": {
          "score": 0.012048192771084338,
          "rank": 53
        },
        "2601.04462v1": {
          "score": 0.011904761904761904,
          "rank": 54
        },
        "2601.04342v1": {
          "score": 0.011904761904761904,
          "rank": 55
        },
        "2601.03584v1": {
          "score": 0.011764705882352941,
          "rank": 56
        },
        "2601.05125v1": {
          "score": 0.011764705882352941,
          "rank": 57
        },
        "2601.03850v1": {
          "score": 0.011627906976744186,
          "rank": 58
        },
        "2601.04792v1": {
          "score": 0.011627906976744186,
          "rank": 59
        },
        "2601.04282v1": {
          "score": 0.011494252873563218,
          "rank": 60
        },
        "2601.04090v1": {
          "score": 0.011494252873563218,
          "rank": 61
        },
        "2601.03520v1": {
          "score": 0.011363636363636364,
          "rank": 62
        },
        "2601.03992v1": {
          "score": 0.011235955056179775,
          "rank": 63
        },
        "2601.04640v1": {
          "score": 0.011111111111111112,
          "rank": 64
        },
        "2601.03885v1": {
          "score": 0.011111111111111112,
          "rank": 65
        },
        "2601.05063v1": {
          "score": 0.010869565217391304,
          "rank": 66
        },
        "2601.03869v1": {
          "score": 0.010869565217391304,
          "rank": 67
        },
        "2601.04445v1": {
          "score": 0.010752688172043012,
          "rank": 68
        },
        "2601.04807v1": {
          "score": 0.010638297872340425,
          "rank": 69
        },
        "2601.04400v1": {
          "score": 0.010526315789473684,
          "rank": 70
        },
        "2601.04775v1": {
          "score": 0.010526315789473684,
          "rank": 71
        },
        "2601.04676v1": {
          "score": 0.010416666666666666,
          "rank": 72
        },
        "2601.04359v1": {
          "score": 0.010416666666666666,
          "rank": 73
        },
        "2601.04783v1": {
          "score": 0.010309278350515464,
          "rank": 74
        },
        "2601.04890v1": {
          "score": 0.010309278350515464,
          "rank": 75
        },
        "2601.04720v1": {
          "score": 0.01020408163265306,
          "rank": 76
        },
        "2601.05049v1": {
          "score": 0.01020408163265306,
          "rank": 77
        },
        "2601.04293v1": {
          "score": 0.010101010101010102,
          "rank": 78
        },
        "2601.05116v1": {
          "score": 0.010101010101010102,
          "rank": 79
        },
        "2601.04494v1": {
          "score": 0.01,
          "rank": 80
        },
        "2601.04279v1": {
          "score": 0.009900990099009901,
          "rank": 81
        },
        "2601.03633v1": {
          "score": 0.00980392156862745,
          "rank": 82
        },
        "2601.03500v1": {
          "score": 0.00980392156862745,
          "rank": 83
        },
        "2601.04290v1": {
          "score": 0.009615384615384616,
          "rank": 84
        },
        "2601.04719v1": {
          "score": 0.009523809523809525,
          "rank": 85
        },
        "2601.05138v1": {
          "score": 0.009433962264150943,
          "rank": 86
        },
        "2601.04530v1": {
          "score": 0.009345794392523364,
          "rank": 87
        },
        "2601.04476v1": {
          "score": 0.009345794392523364,
          "rank": 88
        },
        "2601.04754v1": {
          "score": 0.009259259259259259,
          "rank": 89
        },
        "2601.03646v2": {
          "score": 0.009174311926605505,
          "rank": 90
        },
        "2601.04825v1": {
          "score": 0.009174311926605505,
          "rank": 91
        },
        "2601.04390v1": {
          "score": 0.00909090909090909,
          "rank": 92
        },
        "2601.04278v1": {
          "score": 0.00909090909090909,
          "rank": 93
        },
        "2601.04520v1": {
          "score": 0.009009009009009009,
          "rank": 94
        },
        "2601.04791v1": {
          "score": 0.009009009009009009,
          "rank": 95
        },
        "2601.04068v2": {
          "score": 0.008928571428571428,
          "rank": 96
        },
        "2601.04773v1": {
          "score": 0.008849557522123894,
          "rank": 97
        },
        "2601.03870v1": {
          "score": 0.008771929824561403,
          "rank": 98
        },
        "2601.04785v1": {
          "score": 0.008771929824561403,
          "rank": 99
        },
        "2601.03884v1": {
          "score": 0.008695652173913044,
          "rank": 100
        },
        "2601.04705v1": {
          "score": 0.008620689655172414,
          "rank": 101
        },
        "2601.04891v1": {
          "score": 0.008620689655172414,
          "rank": 102
        },
        "2601.03759v1": {
          "score": 0.008547008547008548,
          "rank": 103
        },
        "2601.05174v1": {
          "score": 0.008547008547008548,
          "rank": 104
        },
        "2601.05150v1": {
          "score": 0.00847457627118644,
          "rank": 105
        },
        "2601.03639v1": {
          "score": 0.008403361344537815,
          "rank": 106
        },
        "2601.04984v1": {
          "score": 0.008403361344537815,
          "rank": 107
        },
        "2601.03830v1": {
          "score": 0.008333333333333333,
          "rank": 108
        },
        "2601.03910v1": {
          "score": 0.008264462809917356,
          "rank": 109
        },
        "2601.04052v1": {
          "score": 0.008264462809917356,
          "rank": 110
        },
        "2601.04268v1": {
          "score": 0.00819672131147541,
          "rank": 111
        },
        "2601.04442v1": {
          "score": 0.00819672131147541,
          "rank": 112
        },
        "2601.04592v1": {
          "score": 0.008130081300813009,
          "rank": 113
        },
        "2601.04572v1": {
          "score": 0.008130081300813009,
          "rank": 114
        },
        "2601.04056v1": {
          "score": 0.008064516129032258,
          "rank": 115
        },
        "2601.04768v1": {
          "score": 0.008,
          "rank": 116
        },
        "2601.05017v1": {
          "score": 0.008,
          "rank": 117
        },
        "2601.04813v1": {
          "score": 0.007936507936507936,
          "rank": 118
        },
        "2601.04867v1": {
          "score": 0.007874015748031496,
          "rank": 119
        },
        "2601.05200v1": {
          "score": 0.007874015748031496,
          "rank": 120
        },
        "2601.03495v1": {
          "score": 0.0078125,
          "rank": 121
        },
        "2601.03617v1": {
          "score": 0.0078125,
          "rank": 122
        },
        "2601.03610v1": {
          "score": 0.007751937984496124,
          "rank": 123
        },
        "2601.04275v1": {
          "score": 0.007751937984496124,
          "rank": 124
        },
        "2601.04602v1": {
          "score": 0.007692307692307693,
          "rank": 125
        },
        "2601.04032v1": {
          "score": 0.007633587786259542,
          "rank": 126
        },
        "2601.04061v1": {
          "score": 0.007633587786259542,
          "rank": 127
        },
        "2601.04939v1": {
          "score": 0.007575757575757576,
          "rank": 128
        },
        "2601.03919v2": {
          "score": 0.007518796992481203,
          "rank": 129
        },
        "2601.04881v1": {
          "score": 0.007462686567164179,
          "rank": 130
        },
        "2601.03728v1": {
          "score": 0.007462686567164179,
          "rank": 131
        },
        "2601.03668v1": {
          "score": 0.007407407407407408,
          "rank": 132
        },
        "2601.04682v1": {
          "score": 0.007352941176470588,
          "rank": 133
        },
        "2601.03853v1": {
          "score": 0.0072992700729927005,
          "rank": 134
        },
        "2601.04651v1": {
          "score": 0.0072992700729927005,
          "rank": 135
        },
        "2601.05241v1": {
          "score": 0.007246376811594203,
          "rank": 136
        },
        "2601.04401v1": {
          "score": 0.007194244604316547,
          "rank": 137
        },
        "2601.04065v1": {
          "score": 0.007142857142857143,
          "rank": 138
        },
        "2601.03743v1": {
          "score": 0.007142857142857143,
          "rank": 139
        },
        "2601.04862v1": {
          "score": 0.0070921985815602835,
          "rank": 140
        },
        "2601.04539v1": {
          "score": 0.0070921985815602835,
          "rank": 141
        },
        "2601.04057v1": {
          "score": 0.007042253521126761,
          "rank": 142
        },
        "2601.04646v1": {
          "score": 0.007042253521126761,
          "rank": 143
        },
        "2601.03603v1": {
          "score": 0.006993006993006993,
          "rank": 144
        },
        "2601.04302v1": {
          "score": 0.006993006993006993,
          "rank": 145
        },
        "2601.05202v1": {
          "score": 0.006944444444444444,
          "rank": 146
        },
        "2601.05237v1": {
          "score": 0.006944444444444444,
          "rank": 147
        },
        "2601.04428v1": {
          "score": 0.006896551724137931,
          "rank": 148
        },
        "2601.03858v1": {
          "score": 0.006896551724137931,
          "rank": 149
        },
        "2601.03517v1": {
          "score": 0.00684931506849315,
          "rank": 150
        },
        "2601.04824v1": {
          "score": 0.00684931506849315,
          "rank": 151
        },
        "2601.03483v1": {
          "score": 0.006802721088435374,
          "rank": 152
        },
        "2601.04172v1": {
          "score": 0.006802721088435374,
          "rank": 153
        },
        "2601.03712v2": {
          "score": 0.006756756756756757,
          "rank": 154
        },
        "2601.03577v1": {
          "score": 0.006756756756756757,
          "rank": 155
        },
        "2601.04728v1": {
          "score": 0.006711409395973154,
          "rank": 156
        },
        "2601.05127v1": {
          "score": 0.006711409395973154,
          "rank": 157
        },
        "2601.04259v1": {
          "score": 0.006666666666666667,
          "rank": 158
        },
        "2601.03528v1": {
          "score": 0.006666666666666667,
          "rank": 159
        },
        "2601.03682v1": {
          "score": 0.006622516556291391,
          "rank": 160
        },
        "2601.04537v1": {
          "score": 0.006622516556291391,
          "rank": 161
        },
        "2601.03629v1": {
          "score": 0.006578947368421052,
          "rank": 162
        },
        "2601.03676v1": {
          "score": 0.006535947712418301,
          "rank": 163
        },
        "2601.04582v1": {
          "score": 0.006535947712418301,
          "rank": 164
        },
        "2601.03596v1": {
          "score": 0.006493506493506494,
          "rank": 165
        },
        "2601.05084v1": {
          "score": 0.0064516129032258064,
          "rank": 166
        },
        "2601.04752v1": {
          "score": 0.0064516129032258064,
          "rank": 167
        },
        "2601.03927v1": {
          "score": 0.00641025641025641,
          "rank": 168
        },
        "2601.04777v1": {
          "score": 0.00641025641025641,
          "rank": 169
        },
        "2601.03876v1": {
          "score": 0.006369426751592357,
          "rank": 170
        },
        "2601.04864v1": {
          "score": 0.006369426751592357,
          "rank": 171
        },
        "2601.03540v1": {
          "score": 0.006329113924050633,
          "rank": 172
        },
        "2601.04506v1": {
          "score": 0.006289308176100629,
          "rank": 173
        },
        "2601.04778v1": {
          "score": 0.006289308176100629,
          "rank": 174
        },
        "2601.03774v1": {
          "score": 0.00625,
          "rank": 175
        },
        "2601.04054v1": {
          "score": 0.00625,
          "rank": 176
        }
      },
      "ranked": [
        {
          "paper_id": "2601.04352v1",
          "score": 1.0,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03683v1",
          "score": 1.0,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04785v1",
          "score": 0.9739328771586835,
          "star_rating": 5
        },
        {
          "paper_id": "2601.05063v1",
          "score": 0.9739328771586835,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03955v1",
          "score": 0.9486932820266152,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03596v1",
          "score": 0.9486932820266152,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04397v1",
          "score": 0.9242424242424242,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04539v1",
          "score": 0.9242424242424242,
          "star_rating": 5
        },
        {
          "paper_id": "2601.05052v1",
          "score": 0.9005439005439005,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03528v1",
          "score": 0.9005439005439005,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04052v1",
          "score": 0.8775635139271503,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04754v1",
          "score": 0.8775635139271503,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03633v1",
          "score": 0.8552691090004522,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03919v2",
          "score": 0.8552691090004522,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03869v1",
          "score": 0.8336304218657159,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04792v1",
          "score": 0.8336304218657159,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04592v1",
          "score": 0.8126189430537256,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04518v1",
          "score": 0.8126189430537256,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04519v1",
          "score": 0.7922077922077921,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04727v1",
          "score": 0.7922077922077921,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04348v1",
          "score": 0.7723716033575188,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04264v1",
          "score": 0.7723716033575188,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03617v1",
          "score": 0.7530864197530863,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03658v1",
          "score": 0.7530864197530863,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04607v1",
          "score": 0.7343295973432958,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05049v1",
          "score": 0.7343295973432958,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04520v1",
          "score": 0.7160797160797161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04476v1",
          "score": 0.7160797160797161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04842v1",
          "score": 0.6983164983164983,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04263v1",
          "score": 0.6983164983164983,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04676v1",
          "score": 0.6810207336523124,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04914v1",
          "score": 0.6810207336523124,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03610v1",
          "score": 0.6641742096287551,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04890v1",
          "score": 0.6641742096287551,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03500v1",
          "score": 0.6477596477596477,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04428v1",
          "score": 0.6477596477596477,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04270v1",
          "score": 0.6317606444188721,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04891v1",
          "score": 0.6317606444188721,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04065v1",
          "score": 0.6161616161616161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03520v1",
          "score": 0.6161616161616161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05116v1",
          "score": 0.6009477490958971,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04867v1",
          "score": 0.6009477490958971,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04057v1",
          "score": 0.5861049519586105,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03774v1",
          "score": 0.5861049519586105,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03884v1",
          "score": 0.571619812583668,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04777v1",
          "score": 0.571619812583668,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04775v1",
          "score": 0.5574795574795574,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05084v1",
          "score": 0.5574795574795574,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03924v1",
          "score": 0.5436720142602495,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04090v1",
          "score": 0.5436720142602495,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04069v1",
          "score": 0.5301855766972046,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03728v1",
          "score": 0.5301855766972046,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03665v1",
          "score": 0.5170091721815859,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05251v1",
          "score": 0.5170091721815859,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04509v1",
          "score": 0.5041322314049587,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05127v1",
          "score": 0.5041322314049587,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04773v1",
          "score": 0.49154466008398584,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03830v1",
          "score": 0.49154466008398584,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04682v1",
          "score": 0.4792368125701459,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04061v1",
          "score": 0.4792368125701459,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03660v1",
          "score": 0.4671994671994672,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04302v1",
          "score": 0.4671994671994672,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03875v1",
          "score": 0.4554238032498901,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03673v1",
          "score": 0.4554238032498901,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04734v1",
          "score": 0.44390137938525037,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05138v1",
          "score": 0.44390137938525037,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04068v2",
          "score": 0.4326241134751772,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05246v1",
          "score": 0.4326241134751772,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05237v1",
          "score": 0.4215842636895268,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03646v2",
          "score": 0.4215842636895268,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03910v1",
          "score": 0.4107744107744107,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03889v1",
          "score": 0.4107744107744107,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04824v1",
          "score": 0.40018744142455476,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03584v1",
          "score": 0.40018744142455476,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04496v1",
          "score": 0.3898165326736754,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04120v1",
          "score": 0.3898165326736754,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04918v1",
          "score": 0.37965513723089483,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04378v1",
          "score": 0.37965513723089483,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04342v1",
          "score": 0.3696969696969697,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03566v1",
          "score": 0.3696969696969697,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04864v1",
          "score": 0.3599359935993599,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03668v1",
          "score": 0.3599359935993599,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04282v1",
          "score": 0.35036640918993855,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04005v1",
          "score": 0.35036640918993855,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03517v1",
          "score": 0.34098264195351563,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05125v1",
          "score": 0.34098264195351563,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04984v1",
          "score": 0.3317793317793318,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04275v1",
          "score": 0.3317793317793318,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04825v1",
          "score": 0.3227513227513228,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03629v1",
          "score": 0.3227513227513228,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04494v1",
          "score": 0.31389365351629495,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04572v1",
          "score": 0.31389365351629495,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03686v1",
          "score": 0.3052015481922023,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04719v1",
          "score": 0.3052015481922023,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03914v1",
          "score": 0.2966704077815188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04778v1",
          "score": 0.2966704077815188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05174v1",
          "score": 0.28829580205726996,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05241v1",
          "score": 0.28829580205726996,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04462v1",
          "score": 0.2800734618916436,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04442v1",
          "score": 0.2800734618916436,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04259v1",
          "score": 0.27199927199927193,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04912v1",
          "score": 0.27199927199927193,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04361v1",
          "score": 0.26406926406926395,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04506v1",
          "score": 0.26406926406926395,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04855v1",
          "score": 0.2562796102619111,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03682v1",
          "score": 0.2562796102619111,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05249v1",
          "score": 0.24862661704766958,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04728v1",
          "score": 0.24862661704766958,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03992v1",
          "score": 0.2411067193675889,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03858v1",
          "score": 0.2411067193675889,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04400v1",
          "score": 0.2337164750957854,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03743v1",
          "score": 0.2337164750957854,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04768v1",
          "score": 0.22645255978589315,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04646v1",
          "score": 0.22645255978589315,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04602v1",
          "score": 0.219311761684643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05200v1",
          "score": 0.219311761684643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04279v1",
          "score": 0.21229097699685928,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04752v1",
          "score": 0.21229097699685928,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04032v1",
          "score": 0.20538720538720534,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04359v1",
          "score": 0.20538720538720534,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04278v1",
          "score": 0.1985975457049837,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04056v1",
          "score": 0.1985975457049837,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03976v1",
          "score": 0.1919191919191919,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04390v1",
          "score": 0.1919191919191919,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03839v1",
          "score": 0.18534942925186831,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04807v1",
          "score": 0.18534942925186831,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03712v2",
          "score": 0.17888563049853365,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04054v1",
          "score": 0.17888563049853365,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04172v1",
          "score": 0.1725252525252525,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03714v2",
          "score": 0.1725252525252525,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05017v1",
          "score": 0.16626583293249952,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05202v1",
          "score": 0.16626583293249952,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04710v1",
          "score": 0.16010498687664038,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03885v1",
          "score": 0.16010498687664038,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04445v1",
          "score": 0.154040404040404,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03876v1",
          "score": 0.154040404040404,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04153v1",
          "score": 0.1480698457442643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03927v1",
          "score": 0.1480698457442643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04783v1",
          "score": 0.1421911421911422,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03483v1",
          "score": 0.1421911421911422,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04651v1",
          "score": 0.13640218983730426,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03781v1",
          "score": 0.13640218983730426,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03540v1",
          "score": 0.13070094888276704,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04939v1",
          "score": 0.13070094888276704,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04705v1",
          "score": 0.12508544087491447,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04537v1",
          "score": 0.12508544087491447,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04791v1",
          "score": 0.119553746419418,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05227v1",
          "score": 0.119553746419418,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03676v1",
          "score": 0.11410400299289188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04881v1",
          "score": 0.11410400299289188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04582v1",
          "score": 0.10873440285204986,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04896v1",
          "score": 0.10873440285204986,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04720v1",
          "score": 0.10344319103443185,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04268v1",
          "score": 0.09822866344605471,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03577v1",
          "score": 0.09308916503161108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03603v1",
          "score": 0.08802308802308796,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04530v1",
          "score": 0.08302887026291277,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03822v1",
          "score": 0.07810499359795132,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04813v1",
          "score": 0.07324998234089139,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03850v1",
          "score": 0.06846240179573505,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04862v1",
          "score": 0.06374085684430507,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03612v1",
          "score": 0.05908399059083983,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04716v1",
          "score": 0.05449048306191157,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03853v1",
          "score": 0.049959049959049956,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04707v1",
          "score": 0.04548844146159577,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04011v1",
          "score": 0.04107744107744108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04290v1",
          "score": 0.03672486453943404,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04401v1",
          "score": 0.03242955874534815,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04640v1",
          "score": 0.02819040073942033,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05150v1",
          "score": 0.02400629673356947,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03495v1",
          "score": 0.01987618116650371,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04668v1",
          "score": 0.015799015799015742,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03759v1",
          "score": 0.011773788843852535,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03639v1",
          "score": 0.007799514128628008,
          "star_rating": 1
        },
        {
          "paper_id": "2601.04293v1",
          "score": 0.003875230290324629,
          "star_rating": 1
        },
        {
          "paper_id": "2601.03870v1",
          "score": 0.0,
          "star_rating": 1
        }
      ]
    },
    {
      "type": "keyword",
      "tag": "符号回归（示例）",
      "paper_tag": "keyword:符号回归（示例）",
      "query_text": "symbolic regression",
      "sim_scores": {
        "2601.04051v1": {
          "score": 0.03278688524590164,
          "rank": 1
        },
        "2601.04799v1": {
          "score": 0.03225806451612903,
          "rank": 2
        },
        "2601.05051v1": {
          "score": 0.03125763125763126,
          "rank": 3
        },
        "2601.03910v1": {
          "score": 0.028612012987012988,
          "rank": 4
        },
        "2601.03674v1": {
          "score": 0.0266900790166813,
          "rank": 5
        },
        "2601.04568v1": {
          "score": 0.02658450704225352,
          "rank": 6
        },
        "2601.04509v1": {
          "score": 0.025849212924606464,
          "rank": 7
        },
        "2601.04473v1": {
          "score": 0.025158227848101268,
          "rank": 8
        },
        "2601.04176v1": {
          "score": 0.02478580171358629,
          "rank": 9
        },
        "2601.03750v1": {
          "score": 0.02402186421173763,
          "rank": 10
        },
        "2601.05227v1": {
          "score": 0.023873015873015872,
          "rank": 11
        },
        "2601.03808v1": {
          "score": 0.023200757575757576,
          "rank": 12
        },
        "2601.04789v1": {
          "score": 0.023018203170874926,
          "rank": 13
        },
        "2601.04670v1": {
          "score": 0.021994824747118325,
          "rank": 14
        },
        "2601.03812v1": {
          "score": 0.02149425287356322,
          "rank": 15
        },
        "2601.03845v1": {
          "score": 0.019430760810071154,
          "rank": 16
        },
        "2601.03858v1": {
          "score": 0.019258987527512837,
          "rank": 17
        },
        "2601.04918v1": {
          "score": 0.018527278461053294,
          "rank": 18
        },
        "2601.04675v1": {
          "score": 0.01787984742530197,
          "rank": 19
        },
        "2601.03566v1": {
          "score": 0.017655677655677656,
          "rank": 20
        },
        "2601.04801v1": {
          "score": 0.01748358528019545,
          "rank": 21
        },
        "2601.04058v1": {
          "score": 0.016946778711484593,
          "rank": 22
        },
        "2601.03613v1": {
          "score": 0.016612399494983054,
          "rank": 23
        },
        "2601.03550v1": {
          "score": 0.016071199897554102,
          "rank": 24
        },
        "2601.05203v1": {
          "score": 0.015151515151515152,
          "rank": 25
        },
        "2601.03682v1": {
          "score": 0.015151515151515152,
          "rank": 26
        },
        "2601.04496v1": {
          "score": 0.014925373134328358,
          "rank": 27
        },
        "2601.04610v1": {
          "score": 0.014705882352941176,
          "rank": 28
        },
        "2601.04270v1": {
          "score": 0.014705882352941176,
          "rank": 29
        },
        "2601.03598v1": {
          "score": 0.014492753623188406,
          "rank": 30
        },
        "2601.03839v1": {
          "score": 0.014492753623188406,
          "rank": 31
        },
        "2601.03486v1": {
          "score": 0.014285714285714285,
          "rank": 32
        },
        "2601.05052v1": {
          "score": 0.014285714285714285,
          "rank": 33
        },
        "2601.05033v1": {
          "score": 0.013888888888888888,
          "rank": 34
        },
        "2601.03988v1": {
          "score": 0.013888888888888888,
          "rank": 35
        },
        "2601.04138v1": {
          "score": 0.0136986301369863,
          "rank": 36
        },
        "2601.04447v1": {
          "score": 0.0136986301369863,
          "rank": 37
        },
        "2601.04101v1": {
          "score": 0.013513513513513514,
          "rank": 38
        },
        "2601.04941v1": {
          "score": 0.013513513513513514,
          "rank": 39
        },
        "2601.04507v1": {
          "score": 0.013333333333333334,
          "rank": 40
        },
        "2601.04577v1": {
          "score": 0.013333333333333334,
          "rank": 41
        },
        "2601.03919v2": {
          "score": 0.013157894736842105,
          "rank": 42
        },
        "2601.04932v1": {
          "score": 0.012987012987012988,
          "rank": 43
        },
        "2601.03509v1": {
          "score": 0.01282051282051282,
          "rank": 44
        },
        "2601.03604v1": {
          "score": 0.012345679012345678,
          "rank": 45
        },
        "2601.04833v1": {
          "score": 0.012345679012345678,
          "rank": 46
        },
        "2601.04366v1": {
          "score": 0.012195121951219513,
          "rank": 47
        },
        "2601.03847v1": {
          "score": 0.012195121951219513,
          "rank": 48
        },
        "2601.03933v1": {
          "score": 0.012048192771084338,
          "rank": 49
        },
        "2601.03743v1": {
          "score": 0.012048192771084338,
          "rank": 50
        },
        "2601.04899v1": {
          "score": 0.011904761904761904,
          "rank": 51
        },
        "2601.04581v1": {
          "score": 0.011627906976744186,
          "rank": 52
        },
        "2601.04620v1": {
          "score": 0.011363636363636364,
          "rank": 53
        },
        "2601.04413v1": {
          "score": 0.011235955056179775,
          "rank": 54
        },
        "2601.05053v1": {
          "score": 0.011235955056179775,
          "rank": 55
        },
        "2601.04821v1": {
          "score": 0.011111111111111112,
          "rank": 56
        },
        "2601.03654v1": {
          "score": 0.011111111111111112,
          "rank": 57
        },
        "2601.04731v1": {
          "score": 0.01098901098901099,
          "rank": 58
        },
        "2601.05087v1": {
          "score": 0.010869565217391304,
          "rank": 59
        },
        "2601.03595v1": {
          "score": 0.010869565217391304,
          "rank": 60
        },
        "2601.03760v1": {
          "score": 0.010752688172043012,
          "rank": 61
        },
        "2601.04264v1": {
          "score": 0.010752688172043012,
          "rank": 62
        },
        "2601.03634v1": {
          "score": 0.010638297872340425,
          "rank": 63
        },
        "2601.05194v1": {
          "score": 0.010526315789473684,
          "rank": 64
        },
        "2601.03683v1": {
          "score": 0.010526315789473684,
          "rank": 65
        },
        "2601.05151v1": {
          "score": 0.010416666666666666,
          "rank": 66
        },
        "2601.04263v1": {
          "score": 0.010416666666666666,
          "rank": 67
        },
        "2601.03755v1": {
          "score": 0.010309278350515464,
          "rank": 68
        },
        "2601.03657v1": {
          "score": 0.010309278350515464,
          "rank": 69
        },
        "2601.03747v1": {
          "score": 0.01020408163265306,
          "rank": 70
        },
        "2601.04483v1": {
          "score": 0.01020408163265306,
          "rank": 71
        },
        "2601.04521v1": {
          "score": 0.010101010101010102,
          "rank": 72
        },
        "2601.04878v1": {
          "score": 0.010101010101010102,
          "rank": 73
        },
        "2601.04915v1": {
          "score": 0.01,
          "rank": 74
        },
        "2601.04752v1": {
          "score": 0.009900990099009901,
          "rank": 75
        },
        "2601.03906v1": {
          "score": 0.00980392156862745,
          "rank": 76
        },
        "2601.04873v1": {
          "score": 0.009708737864077669,
          "rank": 77
        },
        "2601.04279v1": {
          "score": 0.009708737864077669,
          "rank": 78
        },
        "2601.03665v1": {
          "score": 0.009615384615384616,
          "rank": 79
        },
        "2601.04913v1": {
          "score": 0.009523809523809525,
          "rank": 80
        },
        "2601.03540v1": {
          "score": 0.009523809523809525,
          "rank": 81
        },
        "2601.03964v1": {
          "score": 0.009433962264150943,
          "rank": 82
        },
        "2601.04651v1": {
          "score": 0.009433962264150943,
          "rank": 83
        },
        "2601.04392v1": {
          "score": 0.009345794392523364,
          "rank": 84
        },
        "2601.04992v1": {
          "score": 0.009345794392523364,
          "rank": 85
        },
        "2601.04505v1": {
          "score": 0.009259259259259259,
          "rank": 86
        },
        "2601.03776v1": {
          "score": 0.009259259259259259,
          "rank": 87
        },
        "2601.05200v1": {
          "score": 0.009174311926605505,
          "rank": 88
        },
        "2601.04411v1": {
          "score": 0.00909090909090909,
          "rank": 89
        },
        "2601.04700v1": {
          "score": 0.00909090909090909,
          "rank": 90
        },
        "2601.03844v1": {
          "score": 0.009009009009009009,
          "rank": 91
        },
        "2601.05160v1": {
          "score": 0.008928571428571428,
          "rank": 92
        },
        "2601.04378v1": {
          "score": 0.008928571428571428,
          "rank": 93
        },
        "2601.04755v1": {
          "score": 0.008849557522123894,
          "rank": 94
        },
        "2601.03606v1": {
          "score": 0.008849557522123894,
          "rank": 95
        },
        "2601.03561v2": {
          "score": 0.008771929824561403,
          "rank": 96
        },
        "2601.04262v1": {
          "score": 0.008695652173913044,
          "rank": 97
        },
        "2601.03559v1": {
          "score": 0.008695652173913044,
          "rank": 98
        },
        "2601.04688v1": {
          "score": 0.008620689655172414,
          "rank": 99
        },
        "2601.03815v1": {
          "score": 0.008547008547008548,
          "rank": 100
        },
        "2601.03882v1": {
          "score": 0.008547008547008548,
          "rank": 101
        },
        "2601.04301v1": {
          "score": 0.00847457627118644,
          "rank": 102
        },
        "2601.03570v1": {
          "score": 0.008403361344537815,
          "rank": 103
        },
        "2601.04727v1": {
          "score": 0.008403361344537815,
          "rank": 104
        },
        "2601.03704v1": {
          "score": 0.008333333333333333,
          "rank": 105
        },
        "2601.03769v2": {
          "score": 0.008333333333333333,
          "rank": 106
        },
        "2601.03774v1": {
          "score": 0.008264462809917356,
          "rank": 107
        },
        "2601.05240v1": {
          "score": 0.00819672131147541,
          "rank": 108
        },
        "2601.04587v1": {
          "score": 0.00819672131147541,
          "rank": 109
        },
        "2601.05002v1": {
          "score": 0.008130081300813009,
          "rank": 110
        },
        "2601.03621v1": {
          "score": 0.008130081300813009,
          "rank": 111
        },
        "2601.04767v1": {
          "score": 0.008064516129032258,
          "rank": 112
        },
        "2601.03764v1": {
          "score": 0.008064516129032258,
          "rank": 113
        },
        "2601.04390v1": {
          "score": 0.008,
          "rank": 114
        },
        "2601.05049v1": {
          "score": 0.007936507936507936,
          "rank": 115
        },
        "2601.04547v1": {
          "score": 0.007874015748031496,
          "rank": 116
        },
        "2601.04766v1": {
          "score": 0.007874015748031496,
          "rank": 117
        },
        "2601.03477v1": {
          "score": 0.0078125,
          "rank": 118
        },
        "2601.04278v1": {
          "score": 0.0078125,
          "rank": 119
        },
        "2601.04334v1": {
          "score": 0.007751937984496124,
          "rank": 120
        },
        "2601.04458v1": {
          "score": 0.007751937984496124,
          "rank": 121
        },
        "2601.04449v1": {
          "score": 0.007692307692307693,
          "rank": 122
        },
        "2601.04365v1": {
          "score": 0.007692307692307693,
          "rank": 123
        },
        "2601.04476v1": {
          "score": 0.007633587786259542,
          "rank": 124
        },
        "2601.03517v1": {
          "score": 0.007575757575757576,
          "rank": 125
        },
        "2601.03802v1": {
          "score": 0.007518796992481203,
          "rank": 126
        },
        "2601.04361v1": {
          "score": 0.007518796992481203,
          "rank": 127
        },
        "2601.04552v1": {
          "score": 0.007462686567164179,
          "rank": 128
        },
        "2601.03673v1": {
          "score": 0.007462686567164179,
          "rank": 129
        },
        "2601.05204v1": {
          "score": 0.007407407407407408,
          "rank": 130
        },
        "2601.05099v1": {
          "score": 0.007407407407407408,
          "rank": 131
        },
        "2601.03591v1": {
          "score": 0.007352941176470588,
          "rank": 132
        },
        "2601.04919v1": {
          "score": 0.007352941176470588,
          "rank": 133
        },
        "2601.04062v2": {
          "score": 0.0072992700729927005,
          "rank": 134
        },
        "2601.03742v1": {
          "score": 0.007246376811594203,
          "rank": 135
        },
        "2601.03723v1": {
          "score": 0.007246376811594203,
          "rank": 136
        },
        "2601.03920v1": {
          "score": 0.007194244604316547,
          "rank": 137
        },
        "2601.04582v1": {
          "score": 0.007194244604316547,
          "rank": 138
        },
        "2601.03908v1": {
          "score": 0.007142857142857143,
          "rank": 139
        },
        "2601.04735v1": {
          "score": 0.0070921985815602835,
          "rank": 140
        },
        "2601.03885v1": {
          "score": 0.0070921985815602835,
          "rank": 141
        },
        "2601.04702v1": {
          "score": 0.007042253521126761,
          "rank": 142
        },
        "2601.04973v1": {
          "score": 0.007042253521126761,
          "rank": 143
        },
        "2601.04438v1": {
          "score": 0.006993006993006993,
          "rank": 144
        },
        "2601.04914v1": {
          "score": 0.006993006993006993,
          "rank": 145
        },
        "2601.04865v1": {
          "score": 0.006944444444444444,
          "rank": 146
        },
        "2601.04696v1": {
          "score": 0.006944444444444444,
          "rank": 147
        },
        "2601.03689v1": {
          "score": 0.006896551724137931,
          "rank": 148
        },
        "2601.03584v1": {
          "score": 0.006896551724137931,
          "rank": 149
        },
        "2601.04486v1": {
          "score": 0.00684931506849315,
          "rank": 150
        },
        "2601.04728v1": {
          "score": 0.00684931506849315,
          "rank": 151
        },
        "2601.03977v1": {
          "score": 0.006802721088435374,
          "rank": 152
        },
        "2601.04854v1": {
          "score": 0.006802721088435374,
          "rank": 153
        },
        "2601.04968v1": {
          "score": 0.006756756756756757,
          "rank": 154
        },
        "2601.03605v1": {
          "score": 0.006756756756756757,
          "rank": 155
        },
        "2601.03745v1": {
          "score": 0.006711409395973154,
          "rank": 156
        },
        "2601.03569v1": {
          "score": 0.006666666666666667,
          "rank": 157
        },
        "2601.03725v1": {
          "score": 0.006622516556291391,
          "rank": 158
        },
        "2601.04173v1": {
          "score": 0.006578947368421052,
          "rank": 159
        },
        "2601.03511v1": {
          "score": 0.006578947368421052,
          "rank": 160
        },
        "2601.03626v1": {
          "score": 0.006535947712418301,
          "rank": 161
        },
        "2601.03577v1": {
          "score": 0.006535947712418301,
          "rank": 162
        },
        "2601.05146v1": {
          "score": 0.006493506493506494,
          "rank": 163
        },
        "2601.04891v1": {
          "score": 0.006493506493506494,
          "rank": 164
        },
        "2601.04703v1": {
          "score": 0.0064516129032258064,
          "rank": 165
        },
        "2601.05027v1": {
          "score": 0.0064516129032258064,
          "rank": 166
        },
        "2601.04105v1": {
          "score": 0.00641025641025641,
          "rank": 167
        },
        "2601.04775v1": {
          "score": 0.00641025641025641,
          "rank": 168
        },
        "2601.05137v1": {
          "score": 0.006369426751592357,
          "rank": 169
        },
        "2601.04537v1": {
          "score": 0.006369426751592357,
          "rank": 170
        },
        "2601.04106v1": {
          "score": 0.006329113924050633,
          "rank": 171
        },
        "2601.03759v1": {
          "score": 0.006329113924050633,
          "rank": 172
        },
        "2601.04608v1": {
          "score": 0.006289308176100629,
          "rank": 173
        },
        "2601.05205v1": {
          "score": 0.006289308176100629,
          "rank": 174
        },
        "2601.03969v1": {
          "score": 0.00625,
          "rank": 175
        },
        "2601.04121v1": {
          "score": 0.00625,
          "rank": 176
        }
      },
      "ranked": [
        {
          "paper_id": "2601.05203v1",
          "score": 1.0,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04051v1",
          "score": 1.0,
          "star_rating": 5
        },
        {
          "paper_id": "2601.05051v1",
          "score": 0.9739328771586835,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04799v1",
          "score": 0.9739328771586835,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03509v1",
          "score": 0.9486932820266152,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04568v1",
          "score": 0.9486932820266152,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04789v1",
          "score": 0.9242424242424242,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03598v1",
          "score": 0.9242424242424242,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04620v1",
          "score": 0.9005439005439005,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03550v1",
          "score": 0.9005439005439005,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04138v1",
          "score": 0.8775635139271503,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04899v1",
          "score": 0.8775635139271503,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04610v1",
          "score": 0.8552691090004522,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03674v1",
          "score": 0.8552691090004522,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04865v1",
          "score": 0.8336304218657159,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04473v1",
          "score": 0.8336304218657159,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03802v1",
          "score": 0.8126189430537256,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03920v1",
          "score": 0.8126189430537256,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03704v1",
          "score": 0.7922077922077921,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04547v1",
          "score": 0.7922077922077921,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04915v1",
          "score": 0.7723716033575188,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03776v1",
          "score": 0.7723716033575188,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03604v1",
          "score": 0.7530864197530863,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03760v1",
          "score": 0.7530864197530863,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04365v1",
          "score": 0.7343295973432958,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04101v1",
          "score": 0.7343295973432958,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04913v1",
          "score": 0.7160797160797161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04914v1",
          "score": 0.7160797160797161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04058v1",
          "score": 0.6983164983164983,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03906v1",
          "score": 0.6983164983164983,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04552v1",
          "score": 0.6810207336523124,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03682v1",
          "score": 0.6810207336523124,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04176v1",
          "score": 0.6641742096287551,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03845v1",
          "score": 0.6641742096287551,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03517v1",
          "score": 0.6477596477596477,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04608v1",
          "score": 0.6477596477596477,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04366v1",
          "score": 0.6317606444188721,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03847v1",
          "score": 0.6317606444188721,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04688v1",
          "score": 0.6161616161616161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03654v1",
          "score": 0.6161616161616161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03750v1",
          "score": 0.6009477490958971,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04505v1",
          "score": 0.6009477490958971,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05151v1",
          "score": 0.5861049519586105,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04918v1",
          "score": 0.5861049519586105,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05087v1",
          "score": 0.571619812583668,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05194v1",
          "score": 0.571619812583668,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04675v1",
          "score": 0.5574795574795574,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03910v1",
          "score": 0.5574795574795574,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03808v1",
          "score": 0.5436720142602495,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04334v1",
          "score": 0.5436720142602495,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04279v1",
          "score": 0.5301855766972046,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05052v1",
          "score": 0.5301855766972046,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03844v1",
          "score": 0.5170091721815859,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04062v2",
          "score": 0.5170091721815859,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04509v1",
          "score": 0.5041322314049587,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04438v1",
          "score": 0.5041322314049587,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03665v1",
          "score": 0.49154466008398584,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05049v1",
          "score": 0.49154466008398584,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03919v2",
          "score": 0.4792368125701459,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03689v1",
          "score": 0.4792368125701459,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03988v1",
          "score": 0.4671994671994672,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04361v1",
          "score": 0.4671994671994672,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05033v1",
          "score": 0.4554238032498901,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03486v1",
          "score": 0.4554238032498901,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04496v1",
          "score": 0.44390137938525037,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03933v1",
          "score": 0.44390137938525037,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05240v1",
          "score": 0.4326241134751772,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04449v1",
          "score": 0.4326241134751772,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03683v1",
          "score": 0.4215842636895268,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03812v1",
          "score": 0.4215842636895268,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04728v1",
          "score": 0.4107744107744107,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05137v1",
          "score": 0.4107744107744107,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04577v1",
          "score": 0.40018744142455476,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03559v1",
          "score": 0.40018744142455476,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04263v1",
          "score": 0.3898165326736754,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04696v1",
          "score": 0.3898165326736754,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03885v1",
          "score": 0.37965513723089483,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03595v1",
          "score": 0.37965513723089483,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03743v1",
          "score": 0.3696969696969697,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05204v1",
          "score": 0.3696969696969697,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04767v1",
          "score": 0.3599359935993599,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03769v2",
          "score": 0.3599359935993599,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04378v1",
          "score": 0.35036640918993855,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05053v1",
          "score": 0.35036640918993855,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04854v1",
          "score": 0.34098264195351563,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04873v1",
          "score": 0.34098264195351563,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04447v1",
          "score": 0.3317793317793318,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03839v1",
          "score": 0.3317793317793318,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03774v1",
          "score": 0.3227513227513228,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03764v1",
          "score": 0.3227513227513228,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04390v1",
          "score": 0.31389365351629495,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03613v1",
          "score": 0.31389365351629495,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04735v1",
          "score": 0.3052015481922023,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04755v1",
          "score": 0.3052015481922023,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04801v1",
          "score": 0.2966704077815188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03673v1",
          "score": 0.2966704077815188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03634v1",
          "score": 0.28829580205726996,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05146v1",
          "score": 0.28829580205726996,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04507v1",
          "score": 0.2800734618916436,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03606v1",
          "score": 0.2800734618916436,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04700v1",
          "score": 0.27199927199927193,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04833v1",
          "score": 0.27199927199927193,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04521v1",
          "score": 0.26406926406926395,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04392v1",
          "score": 0.26406926406926395,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03657v1",
          "score": 0.2562796102619111,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03540v1",
          "score": 0.2562796102619111,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05205v1",
          "score": 0.24862661704766958,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04731v1",
          "score": 0.24862661704766958,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04703v1",
          "score": 0.2411067193675889,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03566v1",
          "score": 0.2411067193675889,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04105v1",
          "score": 0.2337164750957854,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03723v1",
          "score": 0.2337164750957854,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04270v1",
          "score": 0.22645255978589315,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03577v1",
          "score": 0.22645255978589315,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03964v1",
          "score": 0.219311761684643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04537v1",
          "score": 0.219311761684643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04582v1",
          "score": 0.21229097699685928,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04766v1",
          "score": 0.21229097699685928,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04702v1",
          "score": 0.20538720538720534,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04264v1",
          "score": 0.20538720538720534,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03626v1",
          "score": 0.1985975457049837,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03725v1",
          "score": 0.1985975457049837,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04301v1",
          "score": 0.1919191919191919,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04752v1",
          "score": 0.1919191919191919,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04973v1",
          "score": 0.18534942925186831,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04262v1",
          "score": 0.18534942925186831,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03759v1",
          "score": 0.17888563049853365,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03747v1",
          "score": 0.17888563049853365,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03621v1",
          "score": 0.1725252525252525,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03511v1",
          "score": 0.1725252525252525,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03969v1",
          "score": 0.16626583293249952,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04476v1",
          "score": 0.16626583293249952,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05027v1",
          "score": 0.16010498687664038,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04932v1",
          "score": 0.16010498687664038,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04878v1",
          "score": 0.154040404040404,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04173v1",
          "score": 0.154040404040404,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04992v1",
          "score": 0.1480698457442643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04821v1",
          "score": 0.1480698457442643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05099v1",
          "score": 0.1421911421911422,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03591v1",
          "score": 0.1421911421911422,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03742v1",
          "score": 0.13640218983730426,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03584v1",
          "score": 0.13640218983730426,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03561v2",
          "score": 0.13070094888276704,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04278v1",
          "score": 0.13070094888276704,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04651v1",
          "score": 0.12508544087491447,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05160v1",
          "score": 0.12508544087491447,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04941v1",
          "score": 0.119553746419418,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04919v1",
          "score": 0.119553746419418,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03570v1",
          "score": 0.11410400299289188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04775v1",
          "score": 0.11410400299289188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03477v1",
          "score": 0.10873440285204986,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04587v1",
          "score": 0.10873440285204986,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05002v1",
          "score": 0.10344319103443185,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03858v1",
          "score": 0.09822866344605471,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03815v1",
          "score": 0.09308916503161108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04411v1",
          "score": 0.08802308802308796,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04486v1",
          "score": 0.08302887026291277,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04670v1",
          "score": 0.07810499359795132,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05227v1",
          "score": 0.07324998234089139,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04458v1",
          "score": 0.06846240179573505,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05200v1",
          "score": 0.06374085684430507,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03977v1",
          "score": 0.05908399059083983,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04106v1",
          "score": 0.05449048306191157,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03605v1",
          "score": 0.049959049959049956,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04581v1",
          "score": 0.04548844146159577,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03908v1",
          "score": 0.04107744107744108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04483v1",
          "score": 0.03672486453943404,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03882v1",
          "score": 0.03242955874534815,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04413v1",
          "score": 0.02819040073942033,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03755v1",
          "score": 0.02400629673356947,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03569v1",
          "score": 0.01987618116650371,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03745v1",
          "score": 0.015799015799015742,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04968v1",
          "score": 0.011773788843852535,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04891v1",
          "score": 0.007799514128628008,
          "star_rating": 1
        },
        {
          "paper_id": "2601.04121v1",
          "score": 0.003875230290324629,
          "star_rating": 1
        },
        {
          "paper_id": "2601.04727v1",
          "score": 0.0,
          "star_rating": 1
        }
      ]
    },
    {
      "type": "llm_query",
      "tag": "sr-bench",
      "paper_tag": "query:sr-bench",
      "query_text": "我希望找一些跟符号回归相关的论文，我是做benchmark的希望找一些benchmark和符号回归结合的论文",
      "sim_scores": {
        "2601.03496v1": {
          "score": 0.03128054740957967,
          "rank": 1
        },
        "2601.03986v1": {
          "score": 0.03047794966520434,
          "rank": 2
        },
        "2601.04643v1": {
          "score": 0.023685515873015872,
          "rank": 3
        },
        "2601.03940v1": {
          "score": 0.02185211433971179,
          "rank": 4
        },
        "2601.04574v1": {
          "score": 0.02059518186112423,
          "rank": 5
        },
        "2601.03540v1": {
          "score": 0.020374015748031497,
          "rank": 6
        },
        "2601.04646v1": {
          "score": 0.019057088408318833,
          "rank": 7
        },
        "2601.03605v1": {
          "score": 0.018068384378544806,
          "rank": 8
        },
        "2601.04895v1": {
          "score": 0.017690058479532166,
          "rank": 9
        },
        "2601.03743v1": {
          "score": 0.01743877473652286,
          "rank": 10
        },
        "2601.04770v1": {
          "score": 0.01717342342342342,
          "rank": 11
        },
        "2601.04390v1": {
          "score": 0.01675099138520443,
          "rank": 12
        },
        "2601.04051v1": {
          "score": 0.01639344262295082,
          "rank": 13
        },
        "2601.03505v1": {
          "score": 0.01630151278038602,
          "rank": 14
        },
        "2601.05103v1": {
          "score": 0.016129032258064516,
          "rank": 15
        },
        "2601.05099v1": {
          "score": 0.015873015873015872,
          "rank": 16
        },
        "2601.04824v1": {
          "score": 0.015625,
          "rank": 17
        },
        "2601.03988v1": {
          "score": 0.015625,
          "rank": 18
        },
        "2601.03783v1": {
          "score": 0.015384615384615385,
          "rank": 19
        },
        "2601.05051v1": {
          "score": 0.015384615384615385,
          "rank": 20
        },
        "2601.03708v1": {
          "score": 0.015151515151515152,
          "rank": 21
        },
        "2601.04160v2": {
          "score": 0.014925373134328358,
          "rank": 22
        },
        "2601.04764v1": {
          "score": 0.014925373134328358,
          "rank": 23
        },
        "2601.04925v1": {
          "score": 0.014705882352941176,
          "rank": 24
        },
        "2601.04568v1": {
          "score": 0.014705882352941176,
          "rank": 25
        },
        "2601.03543v1": {
          "score": 0.014492753623188406,
          "rank": 26
        },
        "2601.03750v1": {
          "score": 0.014492753623188406,
          "rank": 27
        },
        "2601.03731v1": {
          "score": 0.014369426751592357,
          "rank": 28
        },
        "2601.03670v1": {
          "score": 0.014285714285714285,
          "rank": 29
        },
        "2601.03748v1": {
          "score": 0.014285714285714285,
          "rank": 30
        },
        "2601.04693v1": {
          "score": 0.014084507042253521,
          "rank": 31
        },
        "2601.03926v1": {
          "score": 0.013888888888888888,
          "rank": 32
        },
        "2601.04932v1": {
          "score": 0.013888888888888888,
          "rank": 33
        },
        "2601.05101v1": {
          "score": 0.0136986301369863,
          "rank": 34
        },
        "2601.03736v1": {
          "score": 0.013513513513513514,
          "rank": 35
        },
        "2601.05200v1": {
          "score": 0.013513513513513514,
          "rank": 36
        },
        "2601.04758v1": {
          "score": 0.013333333333333334,
          "rank": 37
        },
        "2601.03794v1": {
          "score": 0.013333333333333334,
          "rank": 38
        },
        "2601.04540v1": {
          "score": 0.013157894736842105,
          "rank": 39
        },
        "2601.03908v1": {
          "score": 0.013157894736842105,
          "rank": 40
        },
        "2601.03640v1": {
          "score": 0.012987012987012988,
          "rank": 41
        },
        "2601.05027v1": {
          "score": 0.012987012987012988,
          "rank": 42
        },
        "2601.04695v1": {
          "score": 0.01282051282051282,
          "rank": 43
        },
        "2601.03621v1": {
          "score": 0.01282051282051282,
          "rank": 44
        },
        "2601.03531v1": {
          "score": 0.012658227848101266,
          "rank": 45
        },
        "2601.04618v1": {
          "score": 0.012658227848101266,
          "rank": 46
        },
        "2601.03780v1": {
          "score": 0.0125,
          "rank": 47
        },
        "2601.04474v1": {
          "score": 0.012345679012345678,
          "rank": 48
        },
        "2601.05039v1": {
          "score": 0.012195121951219513,
          "rank": 49
        },
        "2601.04945v1": {
          "score": 0.012195121951219513,
          "rank": 50
        },
        "2601.04833v1": {
          "score": 0.012048192771084338,
          "rank": 51
        },
        "2601.03733v1": {
          "score": 0.011904761904761904,
          "rank": 52
        },
        "2601.05082v1": {
          "score": 0.011904761904761904,
          "rank": 53
        },
        "2601.04043v1": {
          "score": 0.011764705882352941,
          "rank": 54
        },
        "2601.03618v1": {
          "score": 0.011764705882352941,
          "rank": 55
        },
        "2601.03997v2": {
          "score": 0.011627906976744186,
          "rank": 56
        },
        "2601.03606v1": {
          "score": 0.011627906976744186,
          "rank": 57
        },
        "2601.03590v1": {
          "score": 0.011494252873563218,
          "rank": 58
        },
        "2601.04582v1": {
          "score": 0.011494252873563218,
          "rank": 59
        },
        "2601.04876v1": {
          "score": 0.011363636363636364,
          "rank": 60
        },
        "2601.05125v1": {
          "score": 0.011363636363636364,
          "rank": 61
        },
        "2601.04887v1": {
          "score": 0.011235955056179775,
          "rank": 62
        },
        "2601.04110v1": {
          "score": 0.011235955056179775,
          "rank": 63
        },
        "2601.04447v1": {
          "score": 0.011111111111111112,
          "rank": 64
        },
        "2601.05187v1": {
          "score": 0.01098901098901099,
          "rank": 65
        },
        "2601.04577v1": {
          "score": 0.01098901098901099,
          "rank": 66
        },
        "2601.04589v1": {
          "score": 0.010869565217391304,
          "rank": 67
        },
        "2601.04918v1": {
          "score": 0.010869565217391304,
          "rank": 68
        },
        "2601.03849v1": {
          "score": 0.010752688172043012,
          "rank": 69
        },
        "2601.03812v1": {
          "score": 0.010752688172043012,
          "rank": 70
        },
        "2601.04408v1": {
          "score": 0.010638297872340425,
          "rank": 71
        },
        "2601.04888v1": {
          "score": 0.010638297872340425,
          "rank": 72
        },
        "2601.04566v1": {
          "score": 0.010526315789473684,
          "rank": 73
        },
        "2601.04720v1": {
          "score": 0.010526315789473684,
          "rank": 74
        },
        "2601.04922v1": {
          "score": 0.010416666666666666,
          "rank": 75
        },
        "2601.03848v1": {
          "score": 0.010309278350515464,
          "rank": 76
        },
        "2601.04458v1": {
          "score": 0.010309278350515464,
          "rank": 77
        },
        "2601.03707v1": {
          "score": 0.01020408163265306,
          "rank": 78
        },
        "2601.04138v1": {
          "score": 0.01020408163265306,
          "rank": 79
        },
        "2601.03912v1": {
          "score": 0.010101010101010102,
          "rank": 80
        },
        "2601.04879v1": {
          "score": 0.010101010101010102,
          "rank": 81
        },
        "2601.04745v1": {
          "score": 0.01,
          "rank": 82
        },
        "2601.04100v1": {
          "score": 0.01,
          "rank": 83
        },
        "2601.03915v1": {
          "score": 0.009900990099009901,
          "rank": 84
        },
        "2601.04455v1": {
          "score": 0.009900990099009901,
          "rank": 85
        },
        "2601.03627v2": {
          "score": 0.009708737864077669,
          "rank": 86
        },
        "2601.03981v1": {
          "score": 0.009615384615384616,
          "rank": 87
        },
        "2601.03511v1": {
          "score": 0.009615384615384616,
          "rank": 88
        },
        "2601.04172v1": {
          "score": 0.009523809523809525,
          "rank": 89
        },
        "2601.04859v1": {
          "score": 0.009523809523809525,
          "rank": 90
        },
        "2601.05073v1": {
          "score": 0.009433962264150943,
          "rank": 91
        },
        "2601.04919v1": {
          "score": 0.009433962264150943,
          "rank": 92
        },
        "2601.03699v1": {
          "score": 0.009345794392523364,
          "rank": 93
        },
        "2601.04483v1": {
          "score": 0.009345794392523364,
          "rank": 94
        },
        "2601.03994v1": {
          "score": 0.009259259259259259,
          "rank": 95
        },
        "2601.05083v1": {
          "score": 0.009174311926605505,
          "rank": 96
        },
        "2601.04719v1": {
          "score": 0.00909090909090909,
          "rank": 97
        },
        "2601.04757v1": {
          "score": 0.00909090909090909,
          "rank": 98
        },
        "2601.04506v1": {
          "score": 0.009009009009009009,
          "rank": 99
        },
        "2601.05038v1": {
          "score": 0.009009009009009009,
          "rank": 100
        },
        "2601.04960v1": {
          "score": 0.008928571428571428,
          "rank": 101
        },
        "2601.03676v1": {
          "score": 0.008928571428571428,
          "rank": 102
        },
        "2601.03906v1": {
          "score": 0.008849557522123894,
          "rank": 103
        },
        "2601.04853v1": {
          "score": 0.008849557522123894,
          "rank": 104
        },
        "2601.04673v1": {
          "score": 0.008771929824561403,
          "rank": 105
        },
        "2601.04941v1": {
          "score": 0.008771929824561403,
          "rank": 106
        },
        "2601.04025v1": {
          "score": 0.008695652173913044,
          "rank": 107
        },
        "2601.05184v1": {
          "score": 0.008695652173913044,
          "rank": 108
        },
        "2601.04367v1": {
          "score": 0.008620689655172414,
          "rank": 109
        },
        "2601.04278v1": {
          "score": 0.008620689655172414,
          "rank": 110
        },
        "2601.03850v1": {
          "score": 0.008547008547008548,
          "rank": 111
        },
        "2601.03882v1": {
          "score": 0.008547008547008548,
          "rank": 112
        },
        "2601.04699v1": {
          "score": 0.00847457627118644,
          "rank": 113
        },
        "2601.04423v1": {
          "score": 0.00847457627118644,
          "rank": 114
        },
        "2601.04389v1": {
          "score": 0.008403361344537815,
          "rank": 115
        },
        "2601.04301v1": {
          "score": 0.008403361344537815,
          "rank": 116
        },
        "2601.03922v1": {
          "score": 0.008333333333333333,
          "rank": 117
        },
        "2601.04350v1": {
          "score": 0.008333333333333333,
          "rank": 118
        },
        "2601.04131v1": {
          "score": 0.00819672131147541,
          "rank": 119
        },
        "2601.04424v1": {
          "score": 0.00819672131147541,
          "rank": 120
        },
        "2601.05091v1": {
          "score": 0.008130081300813009,
          "rank": 121
        },
        "2601.05219v1": {
          "score": 0.008130081300813009,
          "rank": 122
        },
        "2601.03637v2": {
          "score": 0.008064516129032258,
          "rank": 123
        },
        "2601.04768v1": {
          "score": 0.008064516129032258,
          "rank": 124
        },
        "2601.05227v1": {
          "score": 0.008,
          "rank": 125
        },
        "2601.04794v1": {
          "score": 0.007936507936507936,
          "rank": 126
        },
        "2601.04913v1": {
          "score": 0.007936507936507936,
          "rank": 127
        },
        "2601.04377v1": {
          "score": 0.007874015748031496,
          "rank": 128
        },
        "2601.03483v1": {
          "score": 0.0078125,
          "rank": 129
        },
        "2601.05116v1": {
          "score": 0.007751937984496124,
          "rank": 130
        },
        "2601.03674v1": {
          "score": 0.007751937984496124,
          "rank": 131
        },
        "2601.05076v1": {
          "score": 0.007692307692307693,
          "rank": 132
        },
        "2601.04799v1": {
          "score": 0.007692307692307693,
          "rank": 133
        },
        "2601.04842v1": {
          "score": 0.007633587786259542,
          "rank": 134
        },
        "2601.04801v1": {
          "score": 0.007633587786259542,
          "rank": 135
        },
        "2601.03774v1": {
          "score": 0.007575757575757576,
          "rank": 136
        },
        "2601.04395v1": {
          "score": 0.007575757575757576,
          "rank": 137
        },
        "2601.03566v1": {
          "score": 0.007518796992481203,
          "rank": 138
        },
        "2601.03682v1": {
          "score": 0.007518796992481203,
          "rank": 139
        },
        "2601.04638v1": {
          "score": 0.007462686567164179,
          "rank": 140
        },
        "2601.04651v1": {
          "score": 0.007462686567164179,
          "rank": 141
        },
        "2601.04339v1": {
          "score": 0.007407407407407408,
          "rank": 142
        },
        "2601.04060v1": {
          "score": 0.007407407407407408,
          "rank": 143
        },
        "2601.04120v1": {
          "score": 0.007352941176470588,
          "rank": 144
        },
        "2601.03584v1": {
          "score": 0.007352941176470588,
          "rank": 145
        },
        "2601.03660v1": {
          "score": 0.0072992700729927005,
          "rank": 146
        },
        "2601.04524v1": {
          "score": 0.0072992700729927005,
          "rank": 147
        },
        "2601.03515v1": {
          "score": 0.007246376811594203,
          "rank": 148
        },
        "2601.05049v1": {
          "score": 0.007246376811594203,
          "rank": 149
        },
        "2601.03578v1": {
          "score": 0.007194244604316547,
          "rank": 150
        },
        "2601.04361v1": {
          "score": 0.007194244604316547,
          "rank": 151
        },
        "2601.04855v1": {
          "score": 0.007142857142857143,
          "rank": 152
        },
        "2601.03786v1": {
          "score": 0.007142857142857143,
          "rank": 153
        },
        "2601.03655v1": {
          "score": 0.0070921985815602835,
          "rank": 154
        },
        "2601.04632v1": {
          "score": 0.0070921985815602835,
          "rank": 155
        },
        "2601.04732v1": {
          "score": 0.006993006993006993,
          "rank": 156
        },
        "2601.03559v1": {
          "score": 0.006993006993006993,
          "rank": 157
        },
        "2601.05205v1": {
          "score": 0.006944444444444444,
          "rank": 158
        },
        "2601.04891v1": {
          "score": 0.006944444444444444,
          "rank": 159
        },
        "2601.04670v1": {
          "score": 0.006896551724137931,
          "rank": 160
        },
        "2601.04564v1": {
          "score": 0.00684931506849315,
          "rank": 161
        },
        "2601.05163v1": {
          "score": 0.00684931506849315,
          "rank": 162
        },
        "2601.03792v1": {
          "score": 0.006802721088435374,
          "rank": 163
        },
        "2601.04085v1": {
          "score": 0.006802721088435374,
          "rank": 164
        },
        "2601.03669v1": {
          "score": 0.006756756756756757,
          "rank": 165
        },
        "2601.04121v1": {
          "score": 0.006711409395973154,
          "rank": 166
        },
        "2601.04500v1": {
          "score": 0.006666666666666667,
          "rank": 167
        },
        "2601.04885v1": {
          "score": 0.006666666666666667,
          "rank": 168
        },
        "2601.03481v1": {
          "score": 0.006622516556291391,
          "rank": 169
        },
        "2601.04992v1": {
          "score": 0.006622516556291391,
          "rank": 170
        },
        "2601.05215v1": {
          "score": 0.006578947368421052,
          "rank": 171
        },
        "2601.04897v1": {
          "score": 0.006535947712418301,
          "rank": 172
        },
        "2601.04587v1": {
          "score": 0.006535947712418301,
          "rank": 173
        },
        "2601.05011v1": {
          "score": 0.006493506493506494,
          "rank": 174
        },
        "2601.03808v1": {
          "score": 0.006493506493506494,
          "rank": 175
        },
        "2601.03741v1": {
          "score": 0.0064516129032258064,
          "rank": 176
        },
        "2601.03728v1": {
          "score": 0.0064516129032258064,
          "rank": 177
        },
        "2601.04345v1": {
          "score": 0.00641025641025641,
          "rank": 178
        },
        "2601.04722v1": {
          "score": 0.00641025641025641,
          "rank": 179
        },
        "2601.05150v1": {
          "score": 0.006369426751592357,
          "rank": 180
        },
        "2601.03858v1": {
          "score": 0.006329113924050633,
          "rank": 181
        },
        "2601.04157v1": {
          "score": 0.006329113924050633,
          "rank": 182
        },
        "2601.04755v1": {
          "score": 0.006289308176100629,
          "rank": 183
        },
        "2601.03910v1": {
          "score": 0.006289308176100629,
          "rank": 184
        },
        "2601.04996v1": {
          "score": 0.00625,
          "rank": 185
        },
        "2601.03769v2": {
          "score": 0.00625,
          "rank": 186
        }
      },
      "ranked": [
        {
          "paper_id": "2601.04051v1",
          "score": 1.0,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04695v1",
          "score": 1.0,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04799v1",
          "score": 0.9739328771586835,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03590v1",
          "score": 0.9739328771586835,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04996v1",
          "score": 0.9486932820266152,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03780v1",
          "score": 0.9486932820266152,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03731v1",
          "score": 0.9242424242424242,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03543v1",
          "score": 0.9242424242424242,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03708v1",
          "score": 0.9005439005439005,
          "star_rating": 5
        },
        {
          "paper_id": "2601.05051v1",
          "score": 0.9005439005439005,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03986v1",
          "score": 0.8775635139271503,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04745v1",
          "score": 0.8775635139271503,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04770v1",
          "score": 0.8552691090004522,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04540v1",
          "score": 0.8552691090004522,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03496v1",
          "score": 0.8336304218657159,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03783v1",
          "score": 0.8336304218657159,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04160v2",
          "score": 0.8126189430537256,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03640v1",
          "score": 0.8126189430537256,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04568v1",
          "score": 0.7922077922077921,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04643v1",
          "score": 0.7922077922077921,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03670v1",
          "score": 0.7723716033575188,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04758v1",
          "score": 0.7723716033575188,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03926v1",
          "score": 0.7530864197530863,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03515v1",
          "score": 0.7530864197530863,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03531v1",
          "score": 0.7343295973432958,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04138v1",
          "score": 0.7343295973432958,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04693v1",
          "score": 0.7160797160797161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04389v1",
          "score": 0.7160797160797161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03540v1",
          "score": 0.6983164983164983,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03505v1",
          "score": 0.6983164983164983,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04043v1",
          "score": 0.6810207336523124,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04824v1",
          "score": 0.6810207336523124,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05215v1",
          "score": 0.6641742096287551,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03674v1",
          "score": 0.6641742096287551,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03750v1",
          "score": 0.6477596477596477,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03736v1",
          "score": 0.6477596477596477,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03850v1",
          "score": 0.6317606444188721,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04897v1",
          "score": 0.6317606444188721,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05039v1",
          "score": 0.6161616161616161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03699v1",
          "score": 0.6161616161616161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04925v1",
          "score": 0.6009477490958971,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04876v1",
          "score": 0.6009477490958971,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04474v1",
          "score": 0.5861049519586105,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04085v1",
          "score": 0.5861049519586105,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03997v2",
          "score": 0.571619812583668,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03848v1",
          "score": 0.571619812583668,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05099v1",
          "score": 0.5574795574795574,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03858v1",
          "score": 0.5574795574795574,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05101v1",
          "score": 0.5436720142602495,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04100v1",
          "score": 0.5436720142602495,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04646v1",
          "score": 0.5301855766972046,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05073v1",
          "score": 0.5301855766972046,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04577v1",
          "score": 0.5170091721815859,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03627v2",
          "score": 0.5170091721815859,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04913v1",
          "score": 0.5041322314049587,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03682v1",
          "score": 0.5041322314049587,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04500v1",
          "score": 0.49154466008398584,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03906v1",
          "score": 0.49154466008398584,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03637v2",
          "score": 0.4792368125701459,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04278v1",
          "score": 0.4792368125701459,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04301v1",
          "score": 0.4671994671994672,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03849v1",
          "score": 0.4671994671994672,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04918v1",
          "score": 0.4554238032498901,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03912v1",
          "score": 0.4554238032498901,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04895v1",
          "score": 0.44390137938525037,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03774v1",
          "score": 0.44390137938525037,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04794v1",
          "score": 0.4326241134751772,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03578v1",
          "score": 0.4326241134751772,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03808v1",
          "score": 0.4215842636895268,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03707v1",
          "score": 0.4215842636895268,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04345v1",
          "score": 0.4107744107744107,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04855v1",
          "score": 0.4107744107744107,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04801v1",
          "score": 0.40018744142455476,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05076v1",
          "score": 0.40018744142455476,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03605v1",
          "score": 0.3898165326736754,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04408v1",
          "score": 0.3898165326736754,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04524v1",
          "score": 0.37965513723089483,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03981v1",
          "score": 0.37965513723089483,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03743v1",
          "score": 0.3696969696969697,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03618v1",
          "score": 0.3696969696969697,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03676v1",
          "score": 0.3599359935993599,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04447v1",
          "score": 0.3599359935993599,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03915v1",
          "score": 0.35036640918993855,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03606v1",
          "score": 0.35036640918993855,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05205v1",
          "score": 0.34098264195351563,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04618v1",
          "score": 0.34098264195351563,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04390v1",
          "score": 0.3317793317793318,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03794v1",
          "score": 0.3317793317793318,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04172v1",
          "score": 0.3227513227513228,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03786v1",
          "score": 0.3227513227513228,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03988v1",
          "score": 0.31389365351629495,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04589v1",
          "score": 0.31389365351629495,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03910v1",
          "score": 0.3052015481922023,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04458v1",
          "score": 0.3052015481922023,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04932v1",
          "score": 0.2966704077815188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04582v1",
          "score": 0.2966704077815188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04888v1",
          "score": 0.28829580205726996,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03908v1",
          "score": 0.28829580205726996,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03621v1",
          "score": 0.2800734618916436,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04879v1",
          "score": 0.2800734618916436,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03792v1",
          "score": 0.27199927199927193,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03812v1",
          "score": 0.27199927199927193,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05116v1",
          "score": 0.26406926406926395,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05103v1",
          "score": 0.26406926406926395,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04350v1",
          "score": 0.2562796102619111,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05163v1",
          "score": 0.2562796102619111,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04757v1",
          "score": 0.24862661704766958,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05049v1",
          "score": 0.24862661704766958,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04922v1",
          "score": 0.2411067193675889,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05187v1",
          "score": 0.2411067193675889,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04673v1",
          "score": 0.2337164750957854,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04574v1",
          "score": 0.2337164750957854,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04833v1",
          "score": 0.22645255978589315,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03994v1",
          "score": 0.22645255978589315,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04025v1",
          "score": 0.219311761684643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04157v1",
          "score": 0.219311761684643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03728v1",
          "score": 0.21229097699685928,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04361v1",
          "score": 0.21229097699685928,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04945v1",
          "score": 0.20538720538720534,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03660v1",
          "score": 0.20538720538720534,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04732v1",
          "score": 0.1985975457049837,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03733v1",
          "score": 0.1985975457049837,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04651v1",
          "score": 0.1919191919191919,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04423v1",
          "score": 0.1919191919191919,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03669v1",
          "score": 0.18534942925186831,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04120v1",
          "score": 0.18534942925186831,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03769v2",
          "score": 0.17888563049853365,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04755v1",
          "score": 0.17888563049853365,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04506v1",
          "score": 0.1725252525252525,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04992v1",
          "score": 0.1725252525252525,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04131v1",
          "score": 0.16626583293249952,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04632v1",
          "score": 0.16626583293249952,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04424v1",
          "score": 0.16010498687664038,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03940v1",
          "score": 0.16010498687664038,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04699v1",
          "score": 0.154040404040404,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04768v1",
          "score": 0.154040404040404,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03481v1",
          "score": 0.1480698457442643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04719v1",
          "score": 0.1480698457442643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04941v1",
          "score": 0.1421911421911422,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05027v1",
          "score": 0.1421911421911422,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04395v1",
          "score": 0.13640218983730426,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05011v1",
          "score": 0.13640218983730426,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05219v1",
          "score": 0.13070094888276704,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03748v1",
          "score": 0.13070094888276704,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03511v1",
          "score": 0.12508544087491447,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03559v1",
          "score": 0.12508544087491447,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03655v1",
          "score": 0.119553746419418,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04853v1",
          "score": 0.119553746419418,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05038v1",
          "score": 0.11410400299289188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05200v1",
          "score": 0.11410400299289188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04842v1",
          "score": 0.10873440285204986,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04455v1",
          "score": 0.10873440285204986,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04670v1",
          "score": 0.10344319103443185,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04960v1",
          "score": 0.10344319103443185,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04060v1",
          "score": 0.09822866344605471,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03741v1",
          "score": 0.09822866344605471,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05125v1",
          "score": 0.09308916503161108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04377v1",
          "score": 0.09308916503161108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04859v1",
          "score": 0.08802308802308796,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04764v1",
          "score": 0.08802308802308796,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03584v1",
          "score": 0.08302887026291277,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03483v1",
          "score": 0.08302887026291277,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03566v1",
          "score": 0.07810499359795132,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03882v1",
          "score": 0.07810499359795132,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04720v1",
          "score": 0.07324998234089139,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04638v1",
          "score": 0.07324998234089139,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04885v1",
          "score": 0.06846240179573505,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05184v1",
          "score": 0.06846240179573505,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05083v1",
          "score": 0.06374085684430507,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04121v1",
          "score": 0.06374085684430507,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04110v1",
          "score": 0.05908399059083983,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05150v1",
          "score": 0.05908399059083983,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05227v1",
          "score": 0.05449048306191157,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04564v1",
          "score": 0.049959049959049956,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04891v1",
          "score": 0.04548844146159577,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04566v1",
          "score": 0.04107744107744108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04919v1",
          "score": 0.03672486453943404,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04722v1",
          "score": 0.03242955874534815,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04339v1",
          "score": 0.02819040073942033,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04483v1",
          "score": 0.02400629673356947,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05082v1",
          "score": 0.01987618116650371,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04367v1",
          "score": 0.015799015799015742,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04587v1",
          "score": 0.011773788843852535,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04887v1",
          "score": 0.007799514128628008,
          "star_rating": 1
        },
        {
          "paper_id": "2601.03922v1",
          "score": 0.003875230290324629,
          "star_rating": 1
        },
        {
          "paper_id": "2601.05091v1",
          "score": 0.0,
          "star_rating": 1
        }
      ]
    },
    {
      "type": "keyword",
      "tag": "RL",
      "paper_tag": "keyword:RL",
      "query_text": "reinforcement learning",
      "sim_scores": {
        "2601.04511v1": {
          "score": 0.03177805800756621,
          "rank": 1
        },
        "2601.04668v1": {
          "score": 0.03149801587301587,
          "rank": 2
        },
        "2601.04842v1": {
          "score": 0.03057889822595705,
          "rank": 3
        },
        "2601.04767v1": {
          "score": 0.03055037313432836,
          "rank": 4
        },
        "2601.03976v1": {
          "score": 0.02946912242686891,
          "rank": 5
        },
        "2601.05205v1": {
          "score": 0.028665028665028666,
          "rank": 6
        },
        "2601.03715v1": {
          "score": 0.028629032258064516,
          "rank": 7
        },
        "2601.03686v1": {
          "score": 0.028474711270410194,
          "rank": 8
        },
        "2601.04365v1": {
          "score": 0.027479766610201392,
          "rank": 9
        },
        "2601.05152v1": {
          "score": 0.02738245361196181,
          "rank": 10
        },
        "2601.04177v1": {
          "score": 0.025383141762452106,
          "rank": 11
        },
        "2601.04287v1": {
          "score": 0.02484567901234568,
          "rank": 12
        },
        "2601.04694v1": {
          "score": 0.024386724386724387,
          "rank": 13
        },
        "2601.04714v1": {
          "score": 0.023822791864028976,
          "rank": 14
        },
        "2601.04441v1": {
          "score": 0.02379619260918253,
          "rank": 15
        },
        "2601.05087v1": {
          "score": 0.02362609142270159,
          "rank": 16
        },
        "2601.04695v1": {
          "score": 0.023537414965986395,
          "rank": 17
        },
        "2601.05002v1": {
          "score": 0.02346002621231979,
          "rank": 18
        },
        "2601.05242v1": {
          "score": 0.02341091602014428,
          "rank": 19
        },
        "2601.03743v1": {
          "score": 0.02325881896885903,
          "rank": 20
        },
        "2601.03520v1": {
          "score": 0.023122094445803768,
          "rank": 21
        },
        "2601.03723v1": {
          "score": 0.02299154334038055,
          "rank": 22
        },
        "2601.04401v1": {
          "score": 0.021749408983451537,
          "rank": 23
        },
        "2601.04083v2": {
          "score": 0.02142857142857143,
          "rank": 24
        },
        "2601.04698v1": {
          "score": 0.02138930534732634,
          "rank": 25
        },
        "2601.04411v1": {
          "score": 0.021288515406162466,
          "rank": 26
        },
        "2601.05053v1": {
          "score": 0.020976764199655766,
          "rank": 27
        },
        "2601.04786v1": {
          "score": 0.020673486786018755,
          "rank": 28
        },
        "2601.03646v2": {
          "score": 0.02054794520547945,
          "rank": 29
        },
        "2601.04805v1": {
          "score": 0.019760940813572395,
          "rank": 30
        },
        "2601.03703v1": {
          "score": 0.019731800766283523,
          "rank": 31
        },
        "2601.03895v1": {
          "score": 0.019237849779086894,
          "rank": 32
        },
        "2601.04861v1": {
          "score": 0.018483709273182956,
          "rank": 33
        },
        "2601.04126v2": {
          "score": 0.01823109140182311,
          "rank": 34
        },
        "2601.04973v1": {
          "score": 0.018042071197411004,
          "rank": 35
        },
        "2601.04809v1": {
          "score": 0.017973200673995025,
          "rank": 36
        },
        "2601.04525v1": {
          "score": 0.017957020900794818,
          "rank": 37
        },
        "2601.03661v1": {
          "score": 0.017715936739659367,
          "rank": 38
        },
        "2601.04670v1": {
          "score": 0.017536231884057972,
          "rank": 39
        },
        "2601.04887v1": {
          "score": 0.017246376811594202,
          "rank": 40
        },
        "2601.04392v1": {
          "score": 0.017009719839908517,
          "rank": 41
        },
        "2601.05187v1": {
          "score": 0.016968651136036815,
          "rank": 42
        },
        "2601.03822v1": {
          "score": 0.016968325791855206,
          "rank": 43
        },
        "2601.04537v1": {
          "score": 0.016944444444444443,
          "rank": 44
        },
        "2601.03969v1": {
          "score": 0.016403361344537813,
          "rank": 45
        },
        "2601.03607v1": {
          "score": 0.015756050802779774,
          "rank": 46
        },
        "2601.04334v1": {
          "score": 0.015303765303765305,
          "rank": 47
        },
        "2601.04268v1": {
          "score": 0.014705882352941176,
          "rank": 48
        },
        "2601.04171v1": {
          "score": 0.014169535498677843,
          "rank": 49
        },
        "2601.04748v1": {
          "score": 0.013888888888888888,
          "rank": 50
        },
        "2601.04191v1": {
          "score": 0.0136986301369863,
          "rank": 51
        },
        "2601.04957v1": {
          "score": 0.013333333333333334,
          "rank": 52
        },
        "2601.03525v1": {
          "score": 0.01317214784002773,
          "rank": 53
        },
        "2601.04285v1": {
          "score": 0.013157894736842105,
          "rank": 54
        },
        "2601.04703v1": {
          "score": 0.012987012987012988,
          "rank": 55
        },
        "2601.05249v1": {
          "score": 0.01282051282051282,
          "rank": 56
        },
        "2601.04170v1": {
          "score": 0.01282051282051282,
          "rank": 57
        },
        "2601.03956v1": {
          "score": 0.012658227848101266,
          "rank": 58
        },
        "2601.04521v1": {
          "score": 0.012195121951219513,
          "rank": 59
        },
        "2601.03641v2": {
          "score": 0.012195121951219513,
          "rank": 60
        },
        "2601.04442v1": {
          "score": 0.012048192771084338,
          "rank": 61
        },
        "2601.04582v1": {
          "score": 0.011764705882352941,
          "rank": 62
        },
        "2601.03683v1": {
          "score": 0.011494252873563218,
          "rank": 63
        },
        "2601.03872v1": {
          "score": 0.011363636363636364,
          "rank": 64
        },
        "2601.03875v1": {
          "score": 0.011235955056179775,
          "rank": 65
        },
        "2601.05230v1": {
          "score": 0.011235955056179775,
          "rank": 66
        },
        "2601.04896v1": {
          "score": 0.010752688172043012,
          "rank": 67
        },
        "2601.04118v2": {
          "score": 0.010526315789473684,
          "rank": 68
        },
        "2601.04699v1": {
          "score": 0.010526315789473684,
          "rank": 69
        },
        "2601.03486v1": {
          "score": 0.010416666666666666,
          "rank": 70
        },
        "2601.03905v2": {
          "score": 0.01020408163265306,
          "rank": 71
        },
        "2601.03790v1": {
          "score": 0.009900990099009901,
          "rank": 72
        },
        "2601.03555v1": {
          "score": 0.009900990099009901,
          "rank": 73
        },
        "2601.04120v1": {
          "score": 0.00980392156862745,
          "rank": 74
        },
        "2601.04853v1": {
          "score": 0.009615384615384616,
          "rank": 75
        },
        "2601.04978v1": {
          "score": 0.009433962264150943,
          "rank": 76
        },
        "2601.03823v1": {
          "score": 0.009345794392523364,
          "rank": 77
        },
        "2601.04672v1": {
          "score": 0.009259259259259259,
          "rank": 78
        },
        "2601.05111v1": {
          "score": 0.009259259259259259,
          "rank": 79
        },
        "2601.03948v2": {
          "score": 0.00909090909090909,
          "rank": 80
        },
        "2601.04577v1": {
          "score": 0.00909090909090909,
          "rank": 81
        },
        "2601.05019v1": {
          "score": 0.009009009009009009,
          "rank": 82
        },
        "2601.05248v1": {
          "score": 0.009009009009009009,
          "rank": 83
        },
        "2601.04736v1": {
          "score": 0.008849557522123894,
          "rank": 84
        },
        "2601.03807v1": {
          "score": 0.008849557522123894,
          "rank": 85
        },
        "2601.03594v1": {
          "score": 0.008695652173913044,
          "rank": 86
        },
        "2601.03846v1": {
          "score": 0.008695652173913044,
          "rank": 87
        },
        "2601.03595v1": {
          "score": 0.008620689655172414,
          "rank": 88
        },
        "2601.03767v1": {
          "score": 0.008547008547008548,
          "rank": 89
        },
        "2601.03509v1": {
          "score": 0.00847457627118644,
          "rank": 90
        },
        "2601.04696v1": {
          "score": 0.008403361344537815,
          "rank": 91
        },
        "2601.04912v1": {
          "score": 0.008333333333333333,
          "rank": 92
        },
        "2601.05241v1": {
          "score": 0.008264462809917356,
          "rank": 93
        },
        "2601.04954v1": {
          "score": 0.008130081300813009,
          "rank": 94
        },
        "2601.03584v1": {
          "score": 0.008064516129032258,
          "rank": 95
        },
        "2601.04052v1": {
          "score": 0.008064516129032258,
          "rank": 96
        },
        "2601.04060v1": {
          "score": 0.008,
          "rank": 97
        },
        "2601.05171v1": {
          "score": 0.007936507936507936,
          "rank": 98
        },
        "2601.04611v1": {
          "score": 0.007936507936507936,
          "rank": 99
        },
        "2601.04583v1": {
          "score": 0.007874015748031496,
          "rank": 100
        },
        "2601.04288v1": {
          "score": 0.007874015748031496,
          "rank": 101
        },
        "2601.03672v1": {
          "score": 0.0078125,
          "rank": 102
        },
        "2601.03906v1": {
          "score": 0.0078125,
          "rank": 103
        },
        "2601.04069v1": {
          "score": 0.007751937984496124,
          "rank": 104
        },
        "2601.05227v1": {
          "score": 0.007751937984496124,
          "rank": 105
        },
        "2601.04036v1": {
          "score": 0.007692307692307693,
          "rank": 106
        },
        "2601.03624v1": {
          "score": 0.007692307692307693,
          "rank": 107
        },
        "2601.05014v1": {
          "score": 0.007633587786259542,
          "rank": 108
        },
        "2601.04266v1": {
          "score": 0.007575757575757576,
          "rank": 109
        },
        "2601.04608v1": {
          "score": 0.007518796992481203,
          "rank": 110
        },
        "2601.04799v1": {
          "score": 0.007518796992481203,
          "rank": 111
        },
        "2601.03604v1": {
          "score": 0.007462686567164179,
          "rank": 112
        },
        "2601.05107v1": {
          "score": 0.007462686567164179,
          "rank": 113
        },
        "2601.04554v1": {
          "score": 0.007407407407407408,
          "rank": 114
        },
        "2601.04153v1": {
          "score": 0.007407407407407408,
          "rank": 115
        },
        "2601.04270v1": {
          "score": 0.007352941176470588,
          "rank": 116
        },
        "2601.04474v1": {
          "score": 0.0072992700729927005,
          "rank": 117
        },
        "2601.04686v1": {
          "score": 0.007246376811594203,
          "rank": 118
        },
        "2601.03777v1": {
          "score": 0.007194244604316547,
          "rank": 119
        },
        "2601.04544v1": {
          "score": 0.007194244604316547,
          "rank": 120
        },
        "2601.04562v1": {
          "score": 0.007142857142857143,
          "rank": 121
        },
        "2601.04509v1": {
          "score": 0.007142857142857143,
          "rank": 122
        },
        "2601.03725v1": {
          "score": 0.0070921985815602835,
          "rank": 123
        },
        "2601.04731v1": {
          "score": 0.0070921985815602835,
          "rank": 124
        },
        "2601.03933v1": {
          "score": 0.007042253521126761,
          "rank": 125
        },
        "2601.04137v1": {
          "score": 0.007042253521126761,
          "rank": 126
        },
        "2601.03781v1": {
          "score": 0.006993006993006993,
          "rank": 127
        },
        "2601.04726v1": {
          "score": 0.006993006993006993,
          "rank": 128
        },
        "2601.04035v1": {
          "score": 0.006944444444444444,
          "rank": 129
        },
        "2601.03845v1": {
          "score": 0.006896551724137931,
          "rank": 130
        },
        "2601.04948v1": {
          "score": 0.00684931506849315,
          "rank": 131
        },
        "2601.03753v1": {
          "score": 0.006802721088435374,
          "rank": 132
        },
        "2601.04416v1": {
          "score": 0.006756756756756757,
          "rank": 133
        },
        "2601.04458v1": {
          "score": 0.006711409395973154,
          "rank": 134
        },
        "2601.04616v1": {
          "score": 0.006711409395973154,
          "rank": 135
        },
        "2601.04483v1": {
          "score": 0.006666666666666667,
          "rank": 136
        },
        "2601.04610v1": {
          "score": 0.006622516556291391,
          "rank": 137
        },
        "2601.03540v1": {
          "score": 0.006622516556291391,
          "rank": 138
        },
        "2601.03693v1": {
          "score": 0.006578947368421052,
          "rank": 139
        },
        "2601.04487v1": {
          "score": 0.006535947712418301,
          "rank": 140
        },
        "2601.03566v1": {
          "score": 0.006493506493506494,
          "rank": 141
        },
        "2601.04404v1": {
          "score": 0.006493506493506494,
          "rank": 142
        },
        "2601.04400v1": {
          "score": 0.0064516129032258064,
          "rank": 143
        },
        "2601.04996v1": {
          "score": 0.0064516129032258064,
          "rank": 144
        },
        "2601.04033v1": {
          "score": 0.00641025641025641,
          "rank": 145
        },
        "2601.05016v1": {
          "score": 0.006369426751592357,
          "rank": 146
        },
        "2601.04497v1": {
          "score": 0.006329113924050633,
          "rank": 147
        },
        "2601.03532v2": {
          "score": 0.006289308176100629,
          "rank": 148
        },
        "2601.04516v1": {
          "score": 0.006289308176100629,
          "rank": 149
        },
        "2601.03801v1": {
          "score": 0.00625,
          "rank": 150
        },
        "2601.05191v1": {
          "score": 0.00625,
          "rank": 151
        }
      },
      "ranked": [
        {
          "paper_id": "2601.04686v1",
          "score": 1.0,
          "star_rating": 5
        },
        {
          "paper_id": "2601.05152v1",
          "score": 1.0,
          "star_rating": 5
        },
        {
          "paper_id": "2601.03715v1",
          "score": 0.9739328771586835,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04896v1",
          "score": 0.9739328771586835,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04670v1",
          "score": 0.9486932820266152,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04668v1",
          "score": 0.9486932820266152,
          "star_rating": 5
        },
        {
          "paper_id": "2601.05053v1",
          "score": 0.9242424242424242,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04809v1",
          "score": 0.9242424242424242,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04842v1",
          "score": 0.9005439005439005,
          "star_rating": 5
        },
        {
          "paper_id": "2601.05002v1",
          "score": 0.9005439005439005,
          "star_rating": 5
        },
        {
          "paper_id": "2601.04411v1",
          "score": 0.8775635139271503,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04511v1",
          "score": 0.8775635139271503,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04287v1",
          "score": 0.8552691090004522,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03661v1",
          "score": 0.8552691090004522,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04525v1",
          "score": 0.8336304218657159,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04401v1",
          "score": 0.8336304218657159,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03646v2",
          "score": 0.8126189430537256,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04441v1",
          "score": 0.8126189430537256,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03486v1",
          "score": 0.7922077922077921,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05249v1",
          "score": 0.7922077922077921,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03520v1",
          "score": 0.7723716033575188,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04521v1",
          "score": 0.7723716033575188,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03948v2",
          "score": 0.7530864197530863,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04268v1",
          "score": 0.7530864197530863,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04392v1",
          "score": 0.7343295973432958,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03976v1",
          "score": 0.7343295973432958,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04957v1",
          "score": 0.7160797160797161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03875v1",
          "score": 0.7160797160797161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03790v1",
          "score": 0.6983164983164983,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03686v1",
          "score": 0.6983164983164983,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04582v1",
          "score": 0.6810207336523124,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04978v1",
          "score": 0.6810207336523124,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04083v2",
          "score": 0.6641742096287551,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04672v1",
          "score": 0.6641742096287551,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03895v1",
          "score": 0.6477596477596477,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04887v1",
          "score": 0.6477596477596477,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03525v1",
          "score": 0.6317606444188721,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05205v1",
          "score": 0.6317606444188721,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04365v1",
          "score": 0.6161616161616161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04171v1",
          "score": 0.6161616161616161,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03723v1",
          "score": 0.6009477490958971,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05019v1",
          "score": 0.6009477490958971,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04714v1",
          "score": 0.5861049519586105,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04191v1",
          "score": 0.5861049519586105,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05242v1",
          "score": 0.571619812583668,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04334v1",
          "score": 0.571619812583668,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04537v1",
          "score": 0.5574795574795574,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03509v1",
          "score": 0.5574795574795574,
          "star_rating": 4
        },
        {
          "paper_id": "2601.03703v1",
          "score": 0.5436720142602495,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05087v1",
          "score": 0.5436720142602495,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04695v1",
          "score": 0.5301855766972046,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04153v1",
          "score": 0.5301855766972046,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04767v1",
          "score": 0.5170091721815859,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04033v1",
          "score": 0.5170091721815859,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04805v1",
          "score": 0.5041322314049587,
          "star_rating": 4
        },
        {
          "paper_id": "2601.05230v1",
          "score": 0.5041322314049587,
          "star_rating": 4
        },
        {
          "paper_id": "2601.04285v1",
          "score": 0.49154466008398584,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04120v1",
          "score": 0.49154466008398584,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04698v1",
          "score": 0.4792368125701459,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05248v1",
          "score": 0.4792368125701459,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03555v1",
          "score": 0.4671994671994672,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04726v1",
          "score": 0.4671994671994672,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04954v1",
          "score": 0.4554238032498901,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05241v1",
          "score": 0.4554238032498901,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05187v1",
          "score": 0.44390137938525037,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05107v1",
          "score": 0.44390137938525037,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03823v1",
          "score": 0.4326241134751772,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03956v1",
          "score": 0.4326241134751772,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03781v1",
          "score": 0.4215842636895268,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03566v1",
          "score": 0.4215842636895268,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04786v1",
          "score": 0.4107744107744107,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03725v1",
          "score": 0.4107744107744107,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04731v1",
          "score": 0.40018744142455476,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04288v1",
          "score": 0.40018744142455476,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05016v1",
          "score": 0.3898165326736754,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04137v1",
          "score": 0.3898165326736754,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04177v1",
          "score": 0.37965513723089483,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04170v1",
          "score": 0.37965513723089483,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03743v1",
          "score": 0.3696969696969697,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03584v1",
          "score": 0.3696969696969697,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04118v2",
          "score": 0.3599359935993599,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04694v1",
          "score": 0.3599359935993599,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05171v1",
          "score": 0.35036640918993855,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04577v1",
          "score": 0.35036640918993855,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03607v1",
          "score": 0.34098264195351563,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03822v1",
          "score": 0.34098264195351563,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04736v1",
          "score": 0.3317793317793318,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03933v1",
          "score": 0.3317793317793318,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03969v1",
          "score": 0.3227513227513228,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04912v1",
          "score": 0.3227513227513228,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04611v1",
          "score": 0.31389365351629495,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03540v1",
          "score": 0.31389365351629495,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04948v1",
          "score": 0.3052015481922023,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04562v1",
          "score": 0.3052015481922023,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04699v1",
          "score": 0.2966704077815188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04400v1",
          "score": 0.2966704077815188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04126v2",
          "score": 0.28829580205726996,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04036v1",
          "score": 0.28829580205726996,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04035v1",
          "score": 0.2800734618916436,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03672v1",
          "score": 0.2800734618916436,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03604v1",
          "score": 0.27199927199927193,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04610v1",
          "score": 0.27199927199927193,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04973v1",
          "score": 0.26406926406926395,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03777v1",
          "score": 0.2562796102619111,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04703v1",
          "score": 0.24862661704766958,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04799v1",
          "score": 0.2411067193675889,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03641v2",
          "score": 0.2337164750957854,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03905v2",
          "score": 0.22645255978589315,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03683v1",
          "score": 0.219311761684643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04516v1",
          "score": 0.21229097699685928,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03807v1",
          "score": 0.20538720538720534,
          "star_rating": 3
        },
        {
          "paper_id": "2601.05014v1",
          "score": 0.1985975457049837,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04052v1",
          "score": 0.1919191919191919,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04060v1",
          "score": 0.18534942925186831,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04616v1",
          "score": 0.17888563049853365,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04748v1",
          "score": 0.1725252525252525,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04069v1",
          "score": 0.16626583293249952,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04416v1",
          "score": 0.16010498687664038,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04544v1",
          "score": 0.154040404040404,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04270v1",
          "score": 0.1480698457442643,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03594v1",
          "score": 0.1421911421911422,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04266v1",
          "score": 0.13640218983730426,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04861v1",
          "score": 0.13070094888276704,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03753v1",
          "score": 0.12508544087491447,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03767v1",
          "score": 0.119553746419418,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03906v1",
          "score": 0.11410400299289188,
          "star_rating": 3
        },
        {
          "paper_id": "2601.03624v1",
          "score": 0.10873440285204986,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04404v1",
          "score": 0.10344319103443185,
          "star_rating": 3
        },
        {
          "paper_id": "2601.04509v1",
          "score": 0.09822866344605471,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03846v1",
          "score": 0.09308916503161108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04583v1",
          "score": 0.08802308802308796,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04474v1",
          "score": 0.08302887026291277,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04608v1",
          "score": 0.07810499359795132,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05227v1",
          "score": 0.07324998234089139,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04483v1",
          "score": 0.06846240179573505,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03872v1",
          "score": 0.06374085684430507,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05191v1",
          "score": 0.05908399059083983,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03595v1",
          "score": 0.05449048306191157,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03532v2",
          "score": 0.049959049959049956,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03693v1",
          "score": 0.04548844146159577,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03845v1",
          "score": 0.04107744107744108,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04487v1",
          "score": 0.03672486453943404,
          "star_rating": 2
        },
        {
          "paper_id": "2601.05111v1",
          "score": 0.03242955874534815,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04497v1",
          "score": 0.02819040073942033,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04853v1",
          "score": 0.02400629673356947,
          "star_rating": 2
        },
        {
          "paper_id": "2601.03801v1",
          "score": 0.01987618116650371,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04554v1",
          "score": 0.015799015799015742,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04696v1",
          "score": 0.011773788843852535,
          "star_rating": 2
        },
        {
          "paper_id": "2601.04458v1",
          "score": 0.007799514128628008,
          "star_rating": 1
        },
        {
          "paper_id": "2601.04442v1",
          "score": 0.003875230290324629,
          "star_rating": 1
        },
        {
          "paper_id": "2601.04996v1",
          "score": 0.0,
          "star_rating": 1
        }
      ]
    }
  ],
  "reranked_at": "2026-01-10T17:27:56.214089",
  "llm_ranked": [
    {
      "paper_id": "2601.03723v1",
      "score": 10.0,
      "evidence": "Discusses RLVR and GRPO algorithms used in OpenAI o1 and DeepSeek-R1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03699v1",
      "score": 9.0,
      "evidence": "Universal dataset for comprehensive red teaming and evaluation of LLMs",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04411v1",
      "score": 9.0,
      "evidence": "Reinforcement learning with verifiable rewards for training LLMs",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03590v1",
      "score": 9.0,
      "evidence": "Introduces a benchmark for LLM spatial intelligence and symbolic reasoning",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04424v1",
      "score": 9.0,
      "evidence": "Evaluates frontier LLMs like Gemini on long-context benchmarks",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03895v1",
      "score": 9.0,
      "evidence": "Refines GRPO reinforcement learning for LLM training stability",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03661v1",
      "score": 9.0,
      "evidence": "Reinforcement learning alignment for large language models using GRPO",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04597v1",
      "score": 9.0,
      "evidence": "Technical report on ThaiLLM architecture and model merging methodologies",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05053v1",
      "score": 9.0,
      "evidence": "Enhances LLM reasoning using Reinforcement Learning (RLVR) and exploration strategies",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04670v1",
      "score": 9.0,
      "evidence": "Analyzes RL post-training dynamics in language models using NTK framework",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03986v1",
      "score": 9.0,
      "evidence": "presents a framework for systematic evaluation of LLM benchmarks across multiple domains",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04537v1",
      "score": 9.0,
      "evidence": "Analyzes reinforcement learning training methodologies for LLM post-training",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05002v1",
      "score": 9.0,
      "evidence": "Technical analysis of GRPO reinforcement learning used for LLM post-training",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04809v1",
      "score": 9.0,
      "evidence": "Uses Reinforcement Learning to enhance reasoning in Large Language Models",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04720v1",
      "score": 9.0,
      "evidence": "Technical report on Qwen3-VL foundation models from Alibaba, covering architecture and training",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04260v1",
      "score": 9.0,
      "evidence": "Mechanistic analysis of Qwen3 architecture and reasoning strategies, directly relevant to LLM technical reports",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04896v1",
      "score": 8.0,
      "evidence": "Deep Reinforcement Learning for financial optimization",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04287v1",
      "score": 8.0,
      "evidence": "Reinforcement learning policy optimization for control",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04686v1",
      "score": 8.0,
      "evidence": "Model-based Safe Reinforcement Learning algorithm",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03550v1",
      "score": 8.0,
      "evidence": "Proposes a neuro-symbolic framework for evaluating LLM reasoning efficiency and benchmarks",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04334v1",
      "score": 8.0,
      "evidence": "Combines LLM reasoning with Group Relative Policy Optimization for spacecraft control",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05201v1",
      "score": 8.0,
      "evidence": "Mechanistic analysis of prompt-induced hallucinations in large vision-language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04441v1",
      "score": 8.0,
      "evidence": "Framework for accelerating offline reinforcement learning in discrete action spaces",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04887v1",
      "score": 8.0,
      "evidence": "Applies actor-critic reinforcement learning to manufacturing optimization",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04511v1",
      "score": 8.0,
      "evidence": "Proposes a multiagent reinforcement learning framework with action estimation",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04668v1",
      "score": 8.0,
      "evidence": "Applies deep reinforcement learning for path planning optimization",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04521v1",
      "score": 8.0,
      "evidence": "Proposes a reinforcement learning framework for molecular generation",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04268v1",
      "score": 8.0,
      "evidence": "Utilizes reinforcement learning for state-dependent parameter tuning",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03715v1",
      "score": 8.0,
      "evidence": "Combines reinforcement learning with large language model reasoning and exploration",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04890v1",
      "score": 8.0,
      "evidence": "Technical methodology for optimizing matrix layers in large language model pretraining",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04389v1",
      "score": 8.0,
      "evidence": "Evaluates safety alignment and biases in state-of-the-art LLMs using a large-scale benchmark",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04767v1",
      "score": 8.0,
      "evidence": "Proposes a unified framework for agentic reinforcement learning in LLMs",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04996v1",
      "score": 8.0,
      "evidence": "Expert-curated benchmark for evaluating reasoning capabilities of large models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04714v1",
      "score": 8.0,
      "evidence": "Reinforcement learning and LLM integration for autonomous driving reasoning",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05019v1",
      "score": 8.0,
      "evidence": "Analyzes reasoning distillation and reinforcement learning in large language models",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05152v1",
      "score": 8.0,
      "evidence": "Directly addresses safe reinforcement learning and taxonomy of RL methods",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04365v1",
      "score": 8.0,
      "evidence": "Compares neural and programmatic policies in evolutionary reinforcement learning",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.05106v1",
      "score": 8.0,
      "evidence": "Technical architecture for multi-LLM collaboration and token-level routing",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05242v1",
      "score": 8.0,
      "evidence": "Proposes a new RL optimization method (GDPO) for aligning language models with preferences",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03858v1",
      "score": 8.0,
      "evidence": "Study of knowledge acquisition dynamics during continual pre-training of LLMs",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03531v1",
      "score": 8.0,
      "evidence": "describes a comprehensive benchmark for evaluating large language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05049v1",
      "score": 8.0,
      "evidence": "investigates learning rate configuration for large-scale pre-training of models like MoE",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04876v1",
      "score": 8.0,
      "evidence": "Describes a comprehensive evaluation benchmark for Audio-Large Language Models",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03703v1",
      "score": 8.0,
      "evidence": "Advancing RL methods like GRPO for reasoning in LLMs",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04051v1",
      "score": 8.0,
      "evidence": "Advances in symbolic regression methodology for scientific discovery",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "paper_id": "2601.03743v1",
      "score": 8.0,
      "evidence": "Technical report on training LLMs via agentic RL and distillation",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05249v1",
      "score": 8.0,
      "evidence": "Deep reinforcement learning framework for image parameter optimization",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04401v1",
      "score": 8.0,
      "evidence": "Multi-agent reinforcement learning for decentralized adaptive frameworks",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04392v1",
      "score": 8.0,
      "evidence": "Interpretable reinforcement learning framework for continuous control tasks",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03948v2",
      "score": 8.0,
      "evidence": "Applies Reinforcement Learning (RL) to LLM reasoning in stochastic environments",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04695v1",
      "score": 8.0,
      "evidence": "Standardized benchmark for evaluating generalization in reinforcement learning",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03525v1",
      "score": 8.0,
      "evidence": "Utilizes Reinforcement Learning for code generation with verifiable reward design",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03505v1",
      "score": 7.0,
      "evidence": "Evaluation framework for knowledge retention in LLMs",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04785v1",
      "score": 7.0,
      "evidence": "Medical image translation using ResNet-based architecture",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "paper_id": "2601.04043v1",
      "score": 7.0,
      "evidence": "Safety benchmark for multimodal Large Language Models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03875v1",
      "score": 7.0,
      "evidence": "Applies deep reinforcement learning to medical image segmentation with noisy labels",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03780v1",
      "score": 7.0,
      "evidence": "Empirical study on the representativeness of code generation benchmarks for LLMs",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03509v1",
      "score": 7.0,
      "evidence": "Uses LLMs to evolve symbolic programs as skills in a compositional network",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03790v1",
      "score": 7.0,
      "evidence": "Agentic machine translation framework using reinforcement learning",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03624v1",
      "score": 7.0,
      "evidence": "Architectural guidance for production-grade LLM agent systems",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03908v1",
      "score": 7.0,
      "evidence": "Framework for adaptive retrieval in LLMs to improve QA performance",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04978v1",
      "score": 7.0,
      "evidence": "Utilizes Deep Q Network (DQN) which is a core reinforcement learning algorithm",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04693v1",
      "score": 7.0,
      "evidence": "Introduces a benchmark for evaluating large language model performance and instruction tuning",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03683v1",
      "score": 7.0,
      "evidence": "Applies Proximal Policy Optimization (PPO) reinforcement learning to time series",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03640v1",
      "score": 7.0,
      "evidence": "Presents a benchmark for evaluating code generation reliability in large language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04131v1",
      "score": 7.0,
      "evidence": "Technical methodology for improving LLM faithfulness and evaluation on ConFiQA benchmark",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05110v1",
      "score": 7.0,
      "evidence": "Inference efficiency and routing strategies for Large Reasoning Models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03511v1",
      "score": 7.0,
      "evidence": "Self-evaluation methodology for output quality in large language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05076v1",
      "score": 7.0,
      "evidence": "Benchmark for privacy in large reasoning models chain-of-thought",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03540v1",
      "score": 7.0,
      "evidence": "Benchmark for evaluating information consolidation in LLM-based research agents",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03515v1",
      "score": 7.0,
      "evidence": "Benchmarking long-term memory for multimodal LLM agents",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04777v1",
      "score": 7.0,
      "evidence": "Technical architecture and evaluation of multimodal large language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04171v1",
      "score": 7.0,
      "evidence": "Utilizes reinforcement learning for agent verification and benchmark evaluation",
      "tags": [
        "keyword:RL",
        "query:sr-bench"
      ]
    },
    {
      "paper_id": "2601.03746v1",
      "score": 7.0,
      "evidence": "Evaluates 13 open-weight LLMs on knowledge conflicts and source preferences",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04842v1",
      "score": 7.0,
      "evidence": "Applies deep reinforcement learning (DQN) to wireless resource allocation",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.05191v1",
      "score": 7.0,
      "evidence": "Discusses cost-effective deployment and task-aware compression for LLM agents",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03955v1",
      "score": 7.0,
      "evidence": "Incorporates residual network designs (ResNet-like) into visual tokenizers",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "paper_id": "2601.03627v2",
      "score": 7.0,
      "evidence": "Benchmark dataset and framework for evaluating LLM diagnostic abilities",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04083v2",
      "score": 7.0,
      "evidence": "Reinforcement learning framework for adaptive cell selection in networks",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04620v1",
      "score": 7.0,
      "evidence": "Release engineering pipeline for evaluating and improving LLM agents",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03940v1",
      "score": 7.0,
      "evidence": "discusses training methodologies and reasoning injection for large language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03648v1",
      "score": 7.0,
      "evidence": "proposes optimization methods for continual pretraining of multilingual large language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04823v1",
      "score": 7.0,
      "evidence": "Technical architecture and adaptation methodologies for scaling MoE LLMs",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05009v1",
      "score": 7.0,
      "evidence": "Empirical investigation and evaluation of LLM robustness using a curated dataset",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05052v1",
      "score": 7.0,
      "evidence": "Generative model for neural network weights specifically mentioning ResNet architectures",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "paper_id": "2601.04700v1",
      "score": 7.0,
      "evidence": "Post-training methodologies for LLMs without human supervision",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04672v1",
      "score": 7.0,
      "evidence": "Applying RL and GRPO to enhance reasoning in large models",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05203v1",
      "score": 7.0,
      "evidence": "Application of symbolic regression algorithms to astrophysical data",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.04352v1",
      "score": 7.0,
      "evidence": "Comparative analysis involving ResNet-18 and transfer learning",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "paper_id": "2601.05047v1",
      "score": 7.0,
      "evidence": "Technical challenges and hardware architectures for LLM inference",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03605v1",
      "score": 7.0,
      "evidence": "Presents a new benchmark (FGVeriBench) for evaluating LLM factuality",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03731v1",
      "score": 7.0,
      "evidence": "Describes a diagnostic benchmark for evaluating LLM reasoning at repository level",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03486v1",
      "score": 7.0,
      "evidence": "Applies model-based reinforcement learning to physical control systems",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03646v2",
      "score": 7.0,
      "evidence": "Reinforcement learning scheduler using convolutional and attention-based representations",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "paper_id": "2601.05175v1",
      "score": 7.0,
      "evidence": "Explores RL-trained video models and reasoning in multimodal LLMs",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04957v1",
      "score": 7.0,
      "evidence": "Proposes a novel reinforcement learning control framework",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.05050v1",
      "score": 7.0,
      "evidence": "Evaluates the persuasive capabilities and guardrails of GPT-4o, aligning with LLM evaluation interests",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03976v1",
      "score": 7.0,
      "evidence": "Applies Deep Reinforcement Learning for decentralized task offloading decisions",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04885v1",
      "score": 7.0,
      "evidence": "Discusses alignment methodologies and architectural adaptations for Large Language Models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03686v1",
      "score": 7.0,
      "evidence": "Employs Deep Reinforcement Learning for multi-robot collaborative search tasks",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04805v1",
      "score": 7.0,
      "evidence": "Discusses reinforcement learning (RL) and large reasoning models (LRMs) which align with LLM architecture and RL interests.",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04397v1",
      "score": 7.0,
      "evidence": "Evaluates ResNet-50 performance in a comparative analysis, matching the ResNet interest.",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "paper_id": "2601.03783v1",
      "score": 6.0,
      "evidence": "Privacy benchmark for audio-based Large Language Models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04505v1",
      "score": 6.0,
      "evidence": "Technical architecture of a multi-agent LLM framework for circuit design",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05027v1",
      "score": 6.0,
      "evidence": "Improves RAG for LLMs through set-centric ranking and selection",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03878v1",
      "score": 6.0,
      "evidence": "Empirical study on LLM code generation using benchmarks",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03808v1",
      "score": 6.0,
      "evidence": "Fine-tuning LLMs for code synthesis and performance evaluation",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04745v1",
      "score": 6.0,
      "evidence": "Describes a benchmark for evaluating large language model understanding and reasoning",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04526v1",
      "score": 6.0,
      "evidence": "Discusses technical architectures and reasoning capabilities of language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03872v1",
      "score": 6.0,
      "evidence": "Focuses on orchestrating large language models for complex reasoning tasks",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04925v1",
      "score": 6.0,
      "evidence": "Introduction of Persuaficial benchmark for evaluating LLM-generated content",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04789v1",
      "score": 6.0,
      "evidence": "Combines LLM reasoning with symbolic reasoning for automated optimization",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04568v1",
      "score": 6.0,
      "evidence": "Neurosymbolic integration for large language model retrieval and reasoning",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05144v1",
      "score": 6.0,
      "evidence": "Discusses technical methodologies and reasoning phases in large language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03926v1",
      "score": 6.0,
      "evidence": "Introduces a novel benchmark for evaluating reasoning in Large Vision-Language Models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03682v1",
      "score": 6.0,
      "evidence": "Analyzes and improves mathematical reasoning in LLMs through logical supervision",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03725v1",
      "score": 6.0,
      "evidence": "Proposes dynamic curriculum orchestration for domain-specific LLM fine-tuning",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04824v1",
      "score": 6.0,
      "evidence": "Action retrieval benchmark for multimodal large language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03604v1",
      "score": 6.0,
      "evidence": "explores reinforcement learning and reasoning paradigms in large language models",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05124v1",
      "score": 6.0,
      "evidence": "discusses reasoning-guided alignment in multimodal large language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05159v1",
      "score": 6.0,
      "evidence": "Discusses technical methodologies for mitigating hallucinations in MLLMs",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04726v1",
      "score": 6.0,
      "evidence": "Explores reasoning and memory architectures for LLM-based agents",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03500v1",
      "score": 6.0,
      "evidence": "Addresses internal complexities and hallucinations in Large Vision-Language Models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04525v1",
      "score": 6.0,
      "evidence": "Uses reinforcement learning to improve LLM grounding and response reliability",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04651v1",
      "score": 6.0,
      "evidence": "Discusses reasoning architectures and training paradigms for large reasoning models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05039v1",
      "score": 6.0,
      "evidence": "Benchmarking LLM-based research agents for complex tasks",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05101v1",
      "score": 6.0,
      "evidence": "Benchmark for evaluating tool-calling capabilities of LLMs",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04770v1",
      "score": 6.0,
      "evidence": "Benchmark for LLM scientific instruction following and reasoning",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05167v1",
      "score": 6.0,
      "evidence": "Efficient reasoning framework for collaborative LLM/SLM decoding",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05148v1",
      "score": 6.0,
      "evidence": "Technical report on foundation models with comprehensive benchmarking",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03543v1",
      "score": 6.0,
      "evidence": "Benchmark for evaluating LLM memory capabilities across diverse dimensions",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04160v2",
      "score": 6.0,
      "evidence": "Benchmark for evaluating LLMs on financial misinformation detection",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04633v1",
      "score": 6.0,
      "evidence": "Benchmark for evaluating LLM alignment and machine-generated text",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04688v1",
      "score": 6.0,
      "evidence": "Discusses LLM technical architectures and symbolic state spaces for tool execution",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03520v1",
      "score": 6.0,
      "evidence": "Focuses on Reinforcement Learning for autonomous navigation and mapping",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03597v1",
      "score": 6.0,
      "evidence": "Explores reasoning architectures and graph-structured methodologies for LLMs",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03676v1",
      "score": 6.0,
      "evidence": "Discusses LLM post-training data synthesis and generalization methodologies",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05184v1",
      "score": 6.0,
      "evidence": "Analyzes performance drops and biases in LLM training loops",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05062v1",
      "score": 6.0,
      "evidence": "Discusses steering methodologies for Large Language Models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05073v1",
      "score": 6.0,
      "evidence": "Introduces a benchmark for geometric reasoning in Multimodal LLMs",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03670v1",
      "score": 6.0,
      "evidence": "A comprehensive benchmark for evaluating LLM reasoning under uncertainty, matching evaluation interests",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05240v1",
      "score": 6.0,
      "evidence": "Analyzes architectural robustness and logical consistency in Large Language Models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04540v1",
      "score": 6.0,
      "evidence": "Presents a benchmark for evaluating Large Language Models on code adaptation tasks",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05215v1",
      "score": 5.0,
      "evidence": "Benchmark for LLM agents in open-world environments",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04176v1",
      "score": 5.0,
      "evidence": "Physics discovery and parameter recovery from data is a core task in symbolic regression",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.05051v1",
      "score": 5.0,
      "evidence": "Discusses symbolic knowledge and neuro-symbolic AI in the context of LLM querying",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04052v1",
      "score": 5.0,
      "evidence": "Uses LLM-driven semantic integration for vision-language-action models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05230v1",
      "score": 5.0,
      "evidence": "Learning world models from video data for reasoning and planning agents",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04799v1",
      "score": 5.0,
      "evidence": "Evolving symbolic policies and neural weights for neuro-symbolic integration",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.04891v1",
      "score": 5.0,
      "evidence": "Describes industrial large-scale architecture and multimodal reasoning benchmarks",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04058v1",
      "score": 5.0,
      "evidence": "Kernel-based method for learning nonlinear dynamical systems",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.04675v1",
      "score": 5.0,
      "evidence": "Uses LLMs to guide SMT solvers for non-linear real arithmetic, related to symbolic reasoning",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.04377v1",
      "score": 5.0,
      "evidence": "Discusses RAG strategies to enhance performance of large language models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04473v1",
      "score": 5.0,
      "evidence": "Sparse regression framework for learning operators in mathematical physics",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.04582v1",
      "score": 5.0,
      "evidence": "Applies reinforcement learning to optimize code generation in LLM-based systems",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05205v1",
      "score": 5.0,
      "evidence": "Reinforcement learning framework for optimizing neural machine hyperparameters",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03752v1",
      "score": 5.0,
      "evidence": "Evaluation of multilingual LLM text generation capabilities",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04897v1",
      "score": 5.0,
      "evidence": "Benchmark for multimodal LLM bias and reasoning fidelity",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04758v1",
      "score": 5.0,
      "evidence": "Benchmark for LLM reasoning in specialized legal/patent domains",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05075v1",
      "score": 5.0,
      "evidence": "Methodology for improving sentence embeddings in generative LLMs",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04157v1",
      "score": 5.0,
      "evidence": "Method for improving language model behavior using explanatory examples",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04033v1",
      "score": 5.0,
      "evidence": "Introduces a reward model and dataset for evaluating generative video models",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.03708v1",
      "score": 5.0,
      "evidence": "Repository-level code completion benchmark for LLMs",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04643v1",
      "score": 5.0,
      "evidence": "Describes a multi-modal benchmark for table understanding, relevant to LLM evaluation frameworks",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04153v1",
      "score": 5.0,
      "evidence": "Proposes a differentiable reward flow for fine-tuning models using RL-like feedback",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03802v1",
      "score": 4.0,
      "evidence": "Benchmarking framework for regression and prediction tasks",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "paper_id": "2601.04914v1",
      "score": 4.0,
      "evidence": "Theoretical limits of neural networks compared to polynomial approximation relates to symbolic regression foundations",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.04519v1",
      "score": 4.0,
      "evidence": "Uses a hierarchical encoder for 3D segmentation, similar to ResNet structures",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "paper_id": "2601.04696v1",
      "score": 4.0,
      "evidence": "Application of GPT-4 and semantic understanding in enterprise driving mechanisms",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.05087v1",
      "score": 4.0,
      "evidence": "Involves Bayesian learning for agent behavior in multi-agent systems",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03517v1",
      "score": 4.0,
      "evidence": "Uses sequence regression and latent dynamical simulation for motion prediction",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.05151v1",
      "score": 4.0,
      "evidence": "Benchmarking framework for feature selection methods",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "paper_id": "2601.04577v1",
      "score": 4.0,
      "evidence": "Analyzes reasoning patterns in high-quality AI research papers from major conferences",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04279v1",
      "score": 4.0,
      "evidence": "uses genetic algorithm for time series generation which is a common method in symbolic regression",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.05099v1",
      "score": 4.0,
      "evidence": "Framework for discovering datasets from literature to facilitate research analysis",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "paper_id": "2601.03704v1",
      "score": 4.0,
      "evidence": "Regression framework using neural networks for affinity prediction",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.04727v1",
      "score": 4.0,
      "evidence": "Investigation of CNN-based architectures for image classification tasks",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "paper_id": "2601.04913v1",
      "score": 4.0,
      "evidence": "Relates to regression modeling and scalable prediction methods",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.03496v1",
      "score": 4.0,
      "evidence": "Describes a domain-specific information retrieval benchmark and evaluation framework",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "paper_id": "2601.04547v1",
      "score": 3.0,
      "evidence": "Uses regression models for data-driven physical simulation",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.03919v2",
      "score": 3.0,
      "evidence": "Analyzes decision boundaries and neural network interpretability",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "paper_id": "2601.04865v1",
      "score": 3.0,
      "evidence": "Involves symbolic computation for differential systems",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.03750v1",
      "score": 3.0,
      "evidence": "Theoretical analysis of multivariate kernel regression properties",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.04646v1",
      "score": 3.0,
      "evidence": "Focuses on retrieval benchmarks and domain adaptation for search systems",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "paper_id": "2601.04458v1",
      "score": 3.0,
      "evidence": "Uses LLMs for behavioral prediction and summarization in collaborative learning",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "paper_id": "2601.04474v1",
      "score": 3.0,
      "evidence": "Discusses benchmarking for AI regulation but lacks specific SR or LLM technical depth",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "paper_id": "2601.03665v1",
      "score": 3.0,
      "evidence": "Uses V-JEPA and latent physics guidance which relates to learning dynamics, a core component of RL",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04509v1",
      "score": 2.0,
      "evidence": "Neural backbone for optimization problems but lacks direct link to user queries",
      "tags": []
    },
    {
      "paper_id": "2601.04191v1",
      "score": 2.0,
      "evidence": "Focuses on autonomous agents and reasoning cycles in robotics",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.03848v1",
      "score": 2.0,
      "evidence": "Evaluates automated theorem provers on a large benchmark set",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "paper_id": "2601.05084v1",
      "score": 2.0,
      "evidence": "uses convolutional neural networks for intention prediction",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "paper_id": "2601.03760v1",
      "score": 2.0,
      "evidence": "Statistical modeling of additive models unrelated to symbolic regression or LLMs",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "paper_id": "2601.04539v1",
      "score": 2.0,
      "evidence": "Investigates noise in RNNs which is tangential to general RL or ResNet interests",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "paper_id": "2601.04264v1",
      "score": 2.0,
      "evidence": "Knowledge distillation for efficient time series classification using LSTM",
      "tags": []
    },
    {
      "paper_id": "2601.04607v1",
      "score": 2.0,
      "evidence": "Uses multi-architecture collaborative learning which is a distant methodological bridge to ensemble-like structures in ResNet",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "paper_id": "2601.03884v1",
      "score": 1.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03736v1",
      "score": 1.0,
      "evidence": "Focuses on a benchmark for hyperspectral object detection unrelated to SR or LLMs",
      "tags": []
    },
    {
      "paper_id": "2601.03728v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03633v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04101v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03847v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03924v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04366v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03654v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.05251v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04520v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03774v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04348v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04428v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04918v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04270v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04518v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04552v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04899v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04138v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03997v2",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04090v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03850v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04438v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03920v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03674v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.05127v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04608v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03528v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04592v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04476v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03610v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03910v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03598v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04062v2",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04676v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.05194v1",
      "score": 0.0,
      "evidence": "Clinical risk assessment using data-driven modeling unrelated to user queries",
      "tags": []
    },
    {
      "paper_id": "2601.04263v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04069v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03658v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04775v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03596v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03617v1",
      "score": 0.0,
      "evidence": "Evaluation of depth backbones for monocular 3D object detection",
      "tags": []
    },
    {
      "paper_id": "2601.04065v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03776v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.05063v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04754v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04100v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.05116v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03906v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04792v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04610v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04867v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03844v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04057v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04915v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03869v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.03845v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    },
    {
      "paper_id": "2601.04085v1",
      "score": 0.0,
      "evidence": "not relevant",
      "tags": []
    }
  ],
  "llm_ranked_at": "2026-01-10T20:46:39.660374+00:00"
}